{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2d613198",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Distrito Federal - Consumo de Cimento (t)'\n",
    "start_index = 0\n",
    "split_index = 191 #Referente aos 230 anos de input \n",
    "window_size = 36\n",
    "train_split = split_index + 1 - 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cc652c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Distrito Federal - value</th>\n",
       "      <th>Distrito Federal - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Distrito Federal - IDH</th>\n",
       "      <th>Distrito Federal - PIB - Estadual</th>\n",
       "      <th>Distrito Federal - PIB - Construção Civil</th>\n",
       "      <th>Distrito Federal - PIB - Per Capita</th>\n",
       "      <th>Distrito Federal - PIB - Preços de Mercado</th>\n",
       "      <th>Distrito Federal - Produção de Cimento (t)</th>\n",
       "      <th>Distrito Federal - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.254227</td>\n",
       "      <td>8.293882</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>0.826971</td>\n",
       "      <td>1.184017e+08</td>\n",
       "      <td>3.570616e+06</td>\n",
       "      <td>43.639430</td>\n",
       "      <td>1.092465e+08</td>\n",
       "      <td>156.625720</td>\n",
       "      <td>50.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.252655</td>\n",
       "      <td>8.287887</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>0.827063</td>\n",
       "      <td>1.185511e+08</td>\n",
       "      <td>3.573184e+06</td>\n",
       "      <td>43.651300</td>\n",
       "      <td>1.093025e+08</td>\n",
       "      <td>157.678528</td>\n",
       "      <td>48.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.250972</td>\n",
       "      <td>8.281892</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>0.827155</td>\n",
       "      <td>1.187006e+08</td>\n",
       "      <td>3.575752e+06</td>\n",
       "      <td>43.663170</td>\n",
       "      <td>1.093585e+08</td>\n",
       "      <td>159.190268</td>\n",
       "      <td>49.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.249179</td>\n",
       "      <td>8.275896</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>0.827247</td>\n",
       "      <td>1.188500e+08</td>\n",
       "      <td>3.578320e+06</td>\n",
       "      <td>43.675041</td>\n",
       "      <td>1.094145e+08</td>\n",
       "      <td>160.688376</td>\n",
       "      <td>48.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.247070</td>\n",
       "      <td>8.269901</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>0.827340</td>\n",
       "      <td>1.189994e+08</td>\n",
       "      <td>3.580889e+06</td>\n",
       "      <td>43.686911</td>\n",
       "      <td>1.094705e+08</td>\n",
       "      <td>162.847410</td>\n",
       "      <td>51.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>0.529279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.077918</td>\n",
       "      <td>77.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>0.527896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.545664</td>\n",
       "      <td>64.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>0.526069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.265413</td>\n",
       "      <td>72.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>0.523943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.486640</td>\n",
       "      <td>59.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>0.521081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.931980</td>\n",
       "      <td>59.598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Distrito Federal - value  Distrito Federal - Desemprego  \\\n",
       "0       2003-1                  0.254227                       8.293882   \n",
       "1       2003-2                  0.252655                       8.287887   \n",
       "2       2003-3                  0.250972                       8.281892   \n",
       "3       2003-4                  0.249179                       8.275896   \n",
       "4       2003-5                  0.247070                       8.269901   \n",
       "..         ...                       ...                            ...   \n",
       "235     2022-8                  0.529279                            NaN   \n",
       "236     2022-9                  0.527896                            NaN   \n",
       "237    2022-10                  0.526069                            NaN   \n",
       "238    2022-11                  0.523943                            NaN   \n",
       "239    2022-12                  0.521081                            NaN   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     Distrito Federal - IDH  Distrito Federal - PIB - Estadual  \\\n",
       "0                  0.826971                       1.184017e+08   \n",
       "1                  0.827063                       1.185511e+08   \n",
       "2                  0.827155                       1.187006e+08   \n",
       "3                  0.827247                       1.188500e+08   \n",
       "4                  0.827340                       1.189994e+08   \n",
       "..                      ...                                ...   \n",
       "235                     NaN                                NaN   \n",
       "236                     NaN                                NaN   \n",
       "237                     NaN                                NaN   \n",
       "238                     NaN                                NaN   \n",
       "239                     NaN                                NaN   \n",
       "\n",
       "     Distrito Federal - PIB - Construção Civil  \\\n",
       "0                                 3.570616e+06   \n",
       "1                                 3.573184e+06   \n",
       "2                                 3.575752e+06   \n",
       "3                                 3.578320e+06   \n",
       "4                                 3.580889e+06   \n",
       "..                                         ...   \n",
       "235                                        NaN   \n",
       "236                                        NaN   \n",
       "237                                        NaN   \n",
       "238                                        NaN   \n",
       "239                                        NaN   \n",
       "\n",
       "     Distrito Federal - PIB - Per Capita  \\\n",
       "0                              43.639430   \n",
       "1                              43.651300   \n",
       "2                              43.663170   \n",
       "3                              43.675041   \n",
       "4                              43.686911   \n",
       "..                                   ...   \n",
       "235                                  NaN   \n",
       "236                                  NaN   \n",
       "237                                  NaN   \n",
       "238                                  NaN   \n",
       "239                                  NaN   \n",
       "\n",
       "     Distrito Federal - PIB - Preços de Mercado  \\\n",
       "0                                  1.092465e+08   \n",
       "1                                  1.093025e+08   \n",
       "2                                  1.093585e+08   \n",
       "3                                  1.094145e+08   \n",
       "4                                  1.094705e+08   \n",
       "..                                          ...   \n",
       "235                                         NaN   \n",
       "236                                         NaN   \n",
       "237                                         NaN   \n",
       "238                                         NaN   \n",
       "239                                         NaN   \n",
       "\n",
       "     Distrito Federal - Produção de Cimento (t)  \\\n",
       "0                                    156.625720   \n",
       "1                                    157.678528   \n",
       "2                                    159.190268   \n",
       "3                                    160.688376   \n",
       "4                                    162.847410   \n",
       "..                                          ...   \n",
       "235                                  250.077918   \n",
       "236                                  248.545664   \n",
       "237                                  248.265413   \n",
       "238                                  247.486640   \n",
       "239                                  247.931980   \n",
       "\n",
       "     Distrito Federal - Consumo de Cimento (t)  \n",
       "0                                       50.047  \n",
       "1                                       48.110  \n",
       "2                                       49.006  \n",
       "3                                       48.445  \n",
       "4                                       51.436  \n",
       "..                                         ...  \n",
       "235                                     77.448  \n",
       "236                                     64.321  \n",
       "237                                     72.839  \n",
       "238                                     59.598  \n",
       "239                                     59.598  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_DF.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distrito Federal - value</th>\n",
       "      <th>Distrito Federal - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Distrito Federal - IDH</th>\n",
       "      <th>Distrito Federal - PIB - Estadual</th>\n",
       "      <th>Distrito Federal - PIB - Construção Civil</th>\n",
       "      <th>Distrito Federal - PIB - Per Capita</th>\n",
       "      <th>Distrito Federal - PIB - Preços de Mercado</th>\n",
       "      <th>Distrito Federal - Produção de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.765895</td>\n",
       "      <td>-0.830412</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-2.593530</td>\n",
       "      <td>-1.693822</td>\n",
       "      <td>0.396337</td>\n",
       "      <td>-2.171734</td>\n",
       "      <td>-2.205731</td>\n",
       "      <td>-1.931775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.800114</td>\n",
       "      <td>-0.833674</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-2.541888</td>\n",
       "      <td>-1.674984</td>\n",
       "      <td>0.431282</td>\n",
       "      <td>-2.081307</td>\n",
       "      <td>-2.163694</td>\n",
       "      <td>-1.908347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.836745</td>\n",
       "      <td>-0.836936</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-2.490246</td>\n",
       "      <td>-1.656145</td>\n",
       "      <td>0.466227</td>\n",
       "      <td>-1.990880</td>\n",
       "      <td>-2.121657</td>\n",
       "      <td>-1.874707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.875764</td>\n",
       "      <td>-0.840198</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-2.438604</td>\n",
       "      <td>-1.637307</td>\n",
       "      <td>0.501171</td>\n",
       "      <td>-1.900453</td>\n",
       "      <td>-2.079620</td>\n",
       "      <td>-1.841370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.921678</td>\n",
       "      <td>-0.843461</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-2.386962</td>\n",
       "      <td>-1.618468</td>\n",
       "      <td>0.536116</td>\n",
       "      <td>-1.810026</td>\n",
       "      <td>-2.037583</td>\n",
       "      <td>-1.793327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.298634</td>\n",
       "      <td>1.198041</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>0.236110</td>\n",
       "      <td>1.116166</td>\n",
       "      <td>-1.071950</td>\n",
       "      <td>-1.286229</td>\n",
       "      <td>0.817896</td>\n",
       "      <td>-0.512069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.354774</td>\n",
       "      <td>1.198255</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>0.183845</td>\n",
       "      <td>1.104850</td>\n",
       "      <td>-1.047047</td>\n",
       "      <td>-1.328476</td>\n",
       "      <td>0.799100</td>\n",
       "      <td>-0.500824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.401307</td>\n",
       "      <td>1.198470</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>0.131580</td>\n",
       "      <td>1.093534</td>\n",
       "      <td>-1.022144</td>\n",
       "      <td>-1.370723</td>\n",
       "      <td>0.780305</td>\n",
       "      <td>-0.491677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.460103</td>\n",
       "      <td>1.198684</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>0.079315</td>\n",
       "      <td>1.082218</td>\n",
       "      <td>-0.997242</td>\n",
       "      <td>-1.412970</td>\n",
       "      <td>0.761510</td>\n",
       "      <td>-0.481495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.513867</td>\n",
       "      <td>1.198898</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>0.027050</td>\n",
       "      <td>1.070902</td>\n",
       "      <td>-0.972339</td>\n",
       "      <td>-1.455217</td>\n",
       "      <td>0.742715</td>\n",
       "      <td>-0.478094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Distrito Federal - value  Distrito Federal - Desemprego  \\\n",
       "0                   -0.765895                      -0.830412   \n",
       "1                   -0.800114                      -0.833674   \n",
       "2                   -0.836745                      -0.836936   \n",
       "3                   -0.875764                      -0.840198   \n",
       "4                   -0.921678                      -0.843461   \n",
       "..                        ...                            ...   \n",
       "187                  1.298634                       1.198041   \n",
       "188                  1.354774                       1.198255   \n",
       "189                  1.401307                       1.198470   \n",
       "190                  1.460103                       1.198684   \n",
       "191                  1.513867                       1.198898   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Distrito Federal - IDH  Distrito Federal - PIB - Estadual  \\\n",
       "0                 -2.593530                          -1.693822   \n",
       "1                 -2.541888                          -1.674984   \n",
       "2                 -2.490246                          -1.656145   \n",
       "3                 -2.438604                          -1.637307   \n",
       "4                 -2.386962                          -1.618468   \n",
       "..                      ...                                ...   \n",
       "187                0.236110                           1.116166   \n",
       "188                0.183845                           1.104850   \n",
       "189                0.131580                           1.093534   \n",
       "190                0.079315                           1.082218   \n",
       "191                0.027050                           1.070902   \n",
       "\n",
       "     Distrito Federal - PIB - Construção Civil  \\\n",
       "0                                     0.396337   \n",
       "1                                     0.431282   \n",
       "2                                     0.466227   \n",
       "3                                     0.501171   \n",
       "4                                     0.536116   \n",
       "..                                         ...   \n",
       "187                                  -1.071950   \n",
       "188                                  -1.047047   \n",
       "189                                  -1.022144   \n",
       "190                                  -0.997242   \n",
       "191                                  -0.972339   \n",
       "\n",
       "     Distrito Federal - PIB - Per Capita  \\\n",
       "0                              -2.171734   \n",
       "1                              -2.081307   \n",
       "2                              -1.990880   \n",
       "3                              -1.900453   \n",
       "4                              -1.810026   \n",
       "..                                   ...   \n",
       "187                            -1.286229   \n",
       "188                            -1.328476   \n",
       "189                            -1.370723   \n",
       "190                            -1.412970   \n",
       "191                            -1.455217   \n",
       "\n",
       "     Distrito Federal - PIB - Preços de Mercado  \\\n",
       "0                                     -2.205731   \n",
       "1                                     -2.163694   \n",
       "2                                     -2.121657   \n",
       "3                                     -2.079620   \n",
       "4                                     -2.037583   \n",
       "..                                          ...   \n",
       "187                                    0.817896   \n",
       "188                                    0.799100   \n",
       "189                                    0.780305   \n",
       "190                                    0.761510   \n",
       "191                                    0.742715   \n",
       "\n",
       "     Distrito Federal - Produção de Cimento (t)  \n",
       "0                                     -1.931775  \n",
       "1                                     -1.908347  \n",
       "2                                     -1.874707  \n",
       "3                                     -1.841370  \n",
       "4                                     -1.793327  \n",
       "..                                          ...  \n",
       "187                                   -0.512069  \n",
       "188                                   -0.500824  \n",
       "189                                   -0.491677  \n",
       "190                                   -0.481495  \n",
       "191                                   -0.478094  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      46.442\n",
       "1      43.234\n",
       "2      54.587\n",
       "3      59.228\n",
       "4      63.997\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Distrito Federal - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distrito Federal - value</th>\n",
       "      <th>Distrito Federal - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Distrito Federal - IDH</th>\n",
       "      <th>Distrito Federal - PIB - Estadual</th>\n",
       "      <th>Distrito Federal - PIB - Construção Civil</th>\n",
       "      <th>Distrito Federal - PIB - Per Capita</th>\n",
       "      <th>Distrito Federal - PIB - Preços de Mercado</th>\n",
       "      <th>Distrito Federal - Produção de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.765895</td>\n",
       "      <td>-0.830412</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-2.593530</td>\n",
       "      <td>-1.693822</td>\n",
       "      <td>0.396337</td>\n",
       "      <td>-2.171734</td>\n",
       "      <td>-2.205731</td>\n",
       "      <td>-1.931775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.800114</td>\n",
       "      <td>-0.833674</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-2.541888</td>\n",
       "      <td>-1.674984</td>\n",
       "      <td>0.431282</td>\n",
       "      <td>-2.081307</td>\n",
       "      <td>-2.163694</td>\n",
       "      <td>-1.908347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.836745</td>\n",
       "      <td>-0.836936</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-2.490246</td>\n",
       "      <td>-1.656145</td>\n",
       "      <td>0.466227</td>\n",
       "      <td>-1.990880</td>\n",
       "      <td>-2.121657</td>\n",
       "      <td>-1.874707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.875764</td>\n",
       "      <td>-0.840198</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-2.438604</td>\n",
       "      <td>-1.637307</td>\n",
       "      <td>0.501171</td>\n",
       "      <td>-1.900453</td>\n",
       "      <td>-2.079620</td>\n",
       "      <td>-1.841370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.921678</td>\n",
       "      <td>-0.843461</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-2.386962</td>\n",
       "      <td>-1.618468</td>\n",
       "      <td>0.536116</td>\n",
       "      <td>-1.810026</td>\n",
       "      <td>-2.037583</td>\n",
       "      <td>-1.793327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.937260</td>\n",
       "      <td>1.309227</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>1.616226</td>\n",
       "      <td>1.235244</td>\n",
       "      <td>-1.506889</td>\n",
       "      <td>-0.747477</td>\n",
       "      <td>1.174551</td>\n",
       "      <td>0.131039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.925760</td>\n",
       "      <td>1.302282</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>1.563561</td>\n",
       "      <td>1.236423</td>\n",
       "      <td>-1.511843</td>\n",
       "      <td>-0.763990</td>\n",
       "      <td>1.168128</td>\n",
       "      <td>0.077457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.912813</td>\n",
       "      <td>1.295337</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>1.510895</td>\n",
       "      <td>1.237602</td>\n",
       "      <td>-1.516798</td>\n",
       "      <td>-0.780503</td>\n",
       "      <td>1.161706</td>\n",
       "      <td>0.032090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.906620</td>\n",
       "      <td>1.288392</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>1.458230</td>\n",
       "      <td>1.238780</td>\n",
       "      <td>-1.521752</td>\n",
       "      <td>-0.797016</td>\n",
       "      <td>1.155283</td>\n",
       "      <td>-0.032489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.901772</td>\n",
       "      <td>1.281447</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>1.405564</td>\n",
       "      <td>1.239959</td>\n",
       "      <td>-1.526706</td>\n",
       "      <td>-0.813529</td>\n",
       "      <td>1.148860</td>\n",
       "      <td>-0.058248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Distrito Federal - value  Distrito Federal - Desemprego  \\\n",
       "0                   -0.765895                      -0.830412   \n",
       "1                   -0.800114                      -0.833674   \n",
       "2                   -0.836745                      -0.836936   \n",
       "3                   -0.875764                      -0.840198   \n",
       "4                   -0.921678                      -0.843461   \n",
       "..                        ...                            ...   \n",
       "157                  0.937260                       1.309227   \n",
       "158                  0.925760                       1.302282   \n",
       "159                  0.912813                       1.295337   \n",
       "160                  0.906620                       1.288392   \n",
       "161                  0.901772                       1.281447   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     Distrito Federal - IDH  Distrito Federal - PIB - Estadual  \\\n",
       "0                 -2.593530                          -1.693822   \n",
       "1                 -2.541888                          -1.674984   \n",
       "2                 -2.490246                          -1.656145   \n",
       "3                 -2.438604                          -1.637307   \n",
       "4                 -2.386962                          -1.618468   \n",
       "..                      ...                                ...   \n",
       "157                1.616226                           1.235244   \n",
       "158                1.563561                           1.236423   \n",
       "159                1.510895                           1.237602   \n",
       "160                1.458230                           1.238780   \n",
       "161                1.405564                           1.239959   \n",
       "\n",
       "     Distrito Federal - PIB - Construção Civil  \\\n",
       "0                                     0.396337   \n",
       "1                                     0.431282   \n",
       "2                                     0.466227   \n",
       "3                                     0.501171   \n",
       "4                                     0.536116   \n",
       "..                                         ...   \n",
       "157                                  -1.506889   \n",
       "158                                  -1.511843   \n",
       "159                                  -1.516798   \n",
       "160                                  -1.521752   \n",
       "161                                  -1.526706   \n",
       "\n",
       "     Distrito Federal - PIB - Per Capita  \\\n",
       "0                              -2.171734   \n",
       "1                              -2.081307   \n",
       "2                              -1.990880   \n",
       "3                              -1.900453   \n",
       "4                              -1.810026   \n",
       "..                                   ...   \n",
       "157                            -0.747477   \n",
       "158                            -0.763990   \n",
       "159                            -0.780503   \n",
       "160                            -0.797016   \n",
       "161                            -0.813529   \n",
       "\n",
       "     Distrito Federal - PIB - Preços de Mercado  \\\n",
       "0                                     -2.205731   \n",
       "1                                     -2.163694   \n",
       "2                                     -2.121657   \n",
       "3                                     -2.079620   \n",
       "4                                     -2.037583   \n",
       "..                                          ...   \n",
       "157                                    1.174551   \n",
       "158                                    1.168128   \n",
       "159                                    1.161706   \n",
       "160                                    1.155283   \n",
       "161                                    1.148860   \n",
       "\n",
       "     Distrito Federal - Produção de Cimento (t)  \n",
       "0                                     -1.931775  \n",
       "1                                     -1.908347  \n",
       "2                                     -1.874707  \n",
       "3                                     -1.841370  \n",
       "4                                     -1.793327  \n",
       "..                                          ...  \n",
       "157                                    0.131039  \n",
       "158                                    0.077457  \n",
       "159                                    0.032090  \n",
       "160                                   -0.032489  \n",
       "161                                   -0.058248  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[start_index:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      46.442\n",
       "1      43.234\n",
       "2      54.587\n",
       "3      59.228\n",
       "4      63.997\n",
       "        ...  \n",
       "157    35.599\n",
       "158    49.981\n",
       "159    39.881\n",
       "160    48.598\n",
       "161    49.942\n",
       "Name: Distrito Federal - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[start_index:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "21b9c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(t_input, t_target, window_size, start_from):\n",
    "    \n",
    "    X_batches = []\n",
    "    y_batches = []\n",
    "\n",
    "    train_input_values = t_input.values \n",
    "\n",
    "    for i in range(len(t_input) - window_size):\n",
    "        \n",
    "        X_window = train_input_values[i:i+window_size, :]\n",
    "        y_target = t_target[start_from+i+window_size]\n",
    "\n",
    "        X_batches.append(X_window)\n",
    "        y_batches.append(y_target)\n",
    "\n",
    "    return np.array(X_batches), np.array(y_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8b281277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 36, 15)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_train, reshaped_target = create_batches(train_input, \n",
    "                                                 train_target, \n",
    "                                                 window_size, \n",
    "                                                 start_index)\n",
    "reshaped_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dc5d50dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distrito Federal - value</th>\n",
       "      <th>Distrito Federal - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Distrito Federal - IDH</th>\n",
       "      <th>Distrito Federal - PIB - Estadual</th>\n",
       "      <th>Distrito Federal - PIB - Construção Civil</th>\n",
       "      <th>Distrito Federal - PIB - Per Capita</th>\n",
       "      <th>Distrito Federal - PIB - Preços de Mercado</th>\n",
       "      <th>Distrito Federal - Produção de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.746963</td>\n",
       "      <td>0.952687</td>\n",
       "      <td>0.888984</td>\n",
       "      <td>-0.460555</td>\n",
       "      <td>-1.131704</td>\n",
       "      <td>-0.368821</td>\n",
       "      <td>0.651397</td>\n",
       "      <td>0.944085</td>\n",
       "      <td>0.045243</td>\n",
       "      <td>0.686090</td>\n",
       "      <td>0.806860</td>\n",
       "      <td>-0.638912</td>\n",
       "      <td>-0.325093</td>\n",
       "      <td>0.894339</td>\n",
       "      <td>1.712291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.759387</td>\n",
       "      <td>0.973455</td>\n",
       "      <td>0.954254</td>\n",
       "      <td>-0.440372</td>\n",
       "      <td>-0.613483</td>\n",
       "      <td>-0.328087</td>\n",
       "      <td>0.664707</td>\n",
       "      <td>0.947319</td>\n",
       "      <td>0.061828</td>\n",
       "      <td>0.670518</td>\n",
       "      <td>0.828599</td>\n",
       "      <td>-0.679356</td>\n",
       "      <td>-0.322764</td>\n",
       "      <td>0.917121</td>\n",
       "      <td>1.675940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.775249</td>\n",
       "      <td>0.994223</td>\n",
       "      <td>1.045217</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.542919</td>\n",
       "      <td>-0.176031</td>\n",
       "      <td>0.678017</td>\n",
       "      <td>0.950553</td>\n",
       "      <td>0.046225</td>\n",
       "      <td>0.654947</td>\n",
       "      <td>0.850339</td>\n",
       "      <td>-0.719800</td>\n",
       "      <td>-0.320434</td>\n",
       "      <td>0.939903</td>\n",
       "      <td>1.626852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.795874</td>\n",
       "      <td>1.014990</td>\n",
       "      <td>1.176395</td>\n",
       "      <td>-0.397019</td>\n",
       "      <td>-1.334517</td>\n",
       "      <td>-0.113037</td>\n",
       "      <td>0.691327</td>\n",
       "      <td>0.953786</td>\n",
       "      <td>0.032522</td>\n",
       "      <td>0.639375</td>\n",
       "      <td>0.872078</td>\n",
       "      <td>-0.760244</td>\n",
       "      <td>-0.318105</td>\n",
       "      <td>0.962685</td>\n",
       "      <td>1.569267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.815598</td>\n",
       "      <td>1.035758</td>\n",
       "      <td>1.303259</td>\n",
       "      <td>-0.376532</td>\n",
       "      <td>-1.511762</td>\n",
       "      <td>-0.022703</td>\n",
       "      <td>0.704637</td>\n",
       "      <td>0.957020</td>\n",
       "      <td>0.042757</td>\n",
       "      <td>0.623804</td>\n",
       "      <td>0.893818</td>\n",
       "      <td>-0.800689</td>\n",
       "      <td>-0.315775</td>\n",
       "      <td>0.985467</td>\n",
       "      <td>1.514446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.298634</td>\n",
       "      <td>1.198041</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>0.236110</td>\n",
       "      <td>1.116166</td>\n",
       "      <td>-1.071950</td>\n",
       "      <td>-1.286229</td>\n",
       "      <td>0.817896</td>\n",
       "      <td>-0.512069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.354774</td>\n",
       "      <td>1.198255</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>0.183845</td>\n",
       "      <td>1.104850</td>\n",
       "      <td>-1.047047</td>\n",
       "      <td>-1.328476</td>\n",
       "      <td>0.799100</td>\n",
       "      <td>-0.500824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.401307</td>\n",
       "      <td>1.198470</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>0.131580</td>\n",
       "      <td>1.093534</td>\n",
       "      <td>-1.022144</td>\n",
       "      <td>-1.370723</td>\n",
       "      <td>0.780305</td>\n",
       "      <td>-0.491677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.460103</td>\n",
       "      <td>1.198684</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>0.079315</td>\n",
       "      <td>1.082218</td>\n",
       "      <td>-0.997242</td>\n",
       "      <td>-1.412970</td>\n",
       "      <td>0.761510</td>\n",
       "      <td>-0.481495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.513867</td>\n",
       "      <td>1.198898</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>0.027050</td>\n",
       "      <td>1.070902</td>\n",
       "      <td>-0.972339</td>\n",
       "      <td>-1.455217</td>\n",
       "      <td>0.742715</td>\n",
       "      <td>-0.478094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Distrito Federal - value  Distrito Federal - Desemprego  \\\n",
       "126                  0.746963                       0.952687   \n",
       "127                  0.759387                       0.973455   \n",
       "128                  0.775249                       0.994223   \n",
       "129                  0.795874                       1.014990   \n",
       "130                  0.815598                       1.035758   \n",
       "..                        ...                            ...   \n",
       "187                  1.298634                       1.198041   \n",
       "188                  1.354774                       1.198255   \n",
       "189                  1.401307                       1.198470   \n",
       "190                  1.460103                       1.198684   \n",
       "191                  1.513867                       1.198898   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "126                                          0.888984   \n",
       "127                                          0.954254   \n",
       "128                                          1.045217   \n",
       "129                                          1.176395   \n",
       "130                                          1.303259   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "126                      -0.460555       -1.131704 -0.368821   0.651397   \n",
       "127                      -0.440372       -0.613483 -0.328087   0.664707   \n",
       "128                      -0.419247       -0.542919 -0.176031   0.678017   \n",
       "129                      -0.397019       -1.334517 -0.113037   0.691327   \n",
       "130                      -0.376532       -1.511762 -0.022703   0.704637   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "126                                0.944085   0.045243   \n",
       "127                                0.947319   0.061828   \n",
       "128                                0.950553   0.046225   \n",
       "129                                0.953786   0.032522   \n",
       "130                                0.957020   0.042757   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Distrito Federal - IDH  Distrito Federal - PIB - Estadual  \\\n",
       "126                0.686090                           0.806860   \n",
       "127                0.670518                           0.828599   \n",
       "128                0.654947                           0.850339   \n",
       "129                0.639375                           0.872078   \n",
       "130                0.623804                           0.893818   \n",
       "..                      ...                                ...   \n",
       "187                0.236110                           1.116166   \n",
       "188                0.183845                           1.104850   \n",
       "189                0.131580                           1.093534   \n",
       "190                0.079315                           1.082218   \n",
       "191                0.027050                           1.070902   \n",
       "\n",
       "     Distrito Federal - PIB - Construção Civil  \\\n",
       "126                                  -0.638912   \n",
       "127                                  -0.679356   \n",
       "128                                  -0.719800   \n",
       "129                                  -0.760244   \n",
       "130                                  -0.800689   \n",
       "..                                         ...   \n",
       "187                                  -1.071950   \n",
       "188                                  -1.047047   \n",
       "189                                  -1.022144   \n",
       "190                                  -0.997242   \n",
       "191                                  -0.972339   \n",
       "\n",
       "     Distrito Federal - PIB - Per Capita  \\\n",
       "126                            -0.325093   \n",
       "127                            -0.322764   \n",
       "128                            -0.320434   \n",
       "129                            -0.318105   \n",
       "130                            -0.315775   \n",
       "..                                   ...   \n",
       "187                            -1.286229   \n",
       "188                            -1.328476   \n",
       "189                            -1.370723   \n",
       "190                            -1.412970   \n",
       "191                            -1.455217   \n",
       "\n",
       "     Distrito Federal - PIB - Preços de Mercado  \\\n",
       "126                                    0.894339   \n",
       "127                                    0.917121   \n",
       "128                                    0.939903   \n",
       "129                                    0.962685   \n",
       "130                                    0.985467   \n",
       "..                                          ...   \n",
       "187                                    0.817896   \n",
       "188                                    0.799100   \n",
       "189                                    0.780305   \n",
       "190                                    0.761510   \n",
       "191                                    0.742715   \n",
       "\n",
       "     Distrito Federal - Produção de Cimento (t)  \n",
       "126                                    1.712291  \n",
       "127                                    1.675940  \n",
       "128                                    1.626852  \n",
       "129                                    1.569267  \n",
       "130                                    1.514446  \n",
       "..                                          ...  \n",
       "187                                   -0.512069  \n",
       "188                                   -0.500824  \n",
       "189                                   -0.491677  \n",
       "190                                   -0.481495  \n",
       "191                                   -0.478094  \n",
       "\n",
       "[66 rows x 15 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "test_input = input_data.iloc[train_split - window_size:split_index + 1]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "82f07fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 36, 15)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_test, reshaped_test_target = create_batches(test_input, \n",
    "                                                     target_data, \n",
    "                                                     window_size, \n",
    "                                                     train_split - window_size)\n",
    "reshaped_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c5afeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(arr, div_factor, add_factor=0):\n",
    "    split_factor = len(arr) // div_factor\n",
    "    positions_to_drop_index = []\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = len(arr) - (i * div_factor + 1)\n",
    "        positions_to_drop_index.append(pos)\n",
    "        positions_to_drop.append(pos + add_factor)\n",
    "    \n",
    "    arr_droped = arr[positions_to_drop]\n",
    "    arr_result = np.delete(arr, positions_to_drop_index, axis=0)\n",
    "    \n",
    "    return arr_result, arr_droped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede Neural Recorrente com optmizador Estocástico\n",
    "def lstm_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "#     train, train_val = validation_splitter(train_input, 9)\n",
    "#     target,target_val = validation_splitter(train_target, 9)\n",
    "#     display(train.shape)\n",
    "#     display(train_val.shape)\n",
    "#     display(target.shape)\n",
    "#     display(target_val.shape)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(180, activation='tanh', \n",
    "                             return_sequences=True, \n",
    "                             input_shape=(reshaped_train.shape[1],\n",
    "                                          reshaped_train.shape[2])),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.LSTM(36,activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train_input, \n",
    "                        train_target, \n",
    "                        epochs=10000,\n",
    "#                         validation_data=(train_val,\n",
    "#                                          target_val),\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_input, test_target):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(50)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = lstm_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1acb58be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[817943547, 2906557025, 445077704, 2244009983, 3012787981, 456809708, 521500636, 659429028, 528241868, 423278361, 3134708917, 2739007725, 1017807070, 1027587596, 2248497795, 3848838939, 345672479, 405855235, 401583285, 1824731265, 3078448465, 1249594019, 1096020684, 4255926456, 1592554518, 3559698399, 1783395378, 1961485406, 2097741708, 4290938273, 1499629638, 1913973600, 1883298464, 490903925, 2063797277, 3834420398, 1087818063, 3930115184, 2719049953, 2334590867, 490016101, 4224330493, 2866514016, 1422248659, 3371226212, 1562301077, 1842377960, 4237057586, 3124676861, 2483831429]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 19.813812255859375\n",
      "winner_seed: 817943547\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 140.46983337402344\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 21.054851531982422\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 27.82184600830078\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 28.42081642150879\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 39.872982025146484\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 29.07745361328125\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 25.770038604736328\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 31.11066436767578\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 14.960721969604492\n",
      "winner_seed: 423278361\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 36.25978469848633\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 22.794071197509766\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 28.810941696166992\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 24.35991668701172\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 60.53017044067383\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 25.149324417114258\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 38.091976165771484\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 27.55280876159668\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 30.64649200439453\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 28.882564544677734\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 25.600419998168945\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 34.625999450683594\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 1182.7388916015625\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 25.01753807067871\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 29.16619873046875\n",
      "\n",
      "\n",
      "Step: 25 ___________________________________________\n",
      "val_loss: 30.342079162597656\n",
      "\n",
      "\n",
      "Step: 26 ___________________________________________\n",
      "val_loss: 39.45858383178711\n",
      "\n",
      "\n",
      "Step: 27 ___________________________________________\n",
      "val_loss: 34.210975646972656\n",
      "\n",
      "\n",
      "Step: 28 ___________________________________________\n",
      "val_loss: 19.124256134033203\n",
      "\n",
      "\n",
      "Step: 29 ___________________________________________\n",
      "val_loss: 386.91943359375\n",
      "\n",
      "\n",
      "Step: 30 ___________________________________________\n",
      "val_loss: 277.0647888183594\n",
      "\n",
      "\n",
      "Step: 31 ___________________________________________\n",
      "val_loss: 30.206464767456055\n",
      "\n",
      "\n",
      "Step: 32 ___________________________________________\n",
      "val_loss: 27.724515914916992\n",
      "\n",
      "\n",
      "Step: 33 ___________________________________________\n",
      "val_loss: 20.814350128173828\n",
      "\n",
      "\n",
      "Step: 34 ___________________________________________\n",
      "val_loss: 14.22890853881836\n",
      "winner_seed: 2063797277\n",
      "\n",
      "\n",
      "Step: 35 ___________________________________________\n",
      "val_loss: 32.951698303222656\n",
      "\n",
      "\n",
      "Step: 36 ___________________________________________\n",
      "val_loss: 199.20938110351562\n",
      "\n",
      "\n",
      "Step: 37 ___________________________________________\n",
      "val_loss: 31.403907775878906\n",
      "\n",
      "\n",
      "Step: 38 ___________________________________________\n",
      "val_loss: 114.17018127441406\n",
      "\n",
      "\n",
      "Step: 39 ___________________________________________\n",
      "val_loss: 40.89493179321289\n",
      "\n",
      "\n",
      "Step: 40 ___________________________________________\n",
      "val_loss: 19.705074310302734\n",
      "\n",
      "\n",
      "Step: 41 ___________________________________________\n",
      "val_loss: 34.08173370361328\n",
      "\n",
      "\n",
      "Step: 42 ___________________________________________\n",
      "val_loss: 26.218387603759766\n",
      "\n",
      "\n",
      "Step: 43 ___________________________________________\n",
      "val_loss: 1068.6229248046875\n",
      "\n",
      "\n",
      "Step: 44 ___________________________________________\n",
      "val_loss: 25.12889289855957\n",
      "\n",
      "\n",
      "Step: 45 ___________________________________________\n",
      "val_loss: 28.018287658691406\n",
      "\n",
      "\n",
      "Step: 46 ___________________________________________\n",
      "val_loss: 25.166778564453125\n",
      "\n",
      "\n",
      "Step: 47 ___________________________________________\n",
      "val_loss: 573.8201293945312\n",
      "\n",
      "\n",
      "Step: 48 ___________________________________________\n",
      "val_loss: 80.07080078125\n",
      "\n",
      "\n",
      "Step: 49 ___________________________________________\n",
      "val_loss: 33.67375183105469\n",
      "\n",
      "\n",
      "final_seed: 2063797277\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(reshaped_train, reshaped_target, reshaped_test, reshaped_test_target)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 [==============================] - 2s 130ms/step - loss: 6496.3379 - val_loss: 23.6947\n",
      "Epoch 2/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1035.2225 - val_loss: 1047.6290\n",
      "Epoch 3/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 361.9496 - val_loss: 1458.6978\n",
      "Epoch 4/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 407.2618 - val_loss: 2410.1604\n",
      "Epoch 5/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 912.2489 - val_loss: 799.8702\n",
      "Epoch 6/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 534.9561 - val_loss: 1117.2872\n",
      "Epoch 7/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 323.2179 - val_loss: 1509.5021\n",
      "Epoch 8/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 267.5386 - val_loss: 327.2816\n",
      "Epoch 9/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 200.1414 - val_loss: 160.0162\n",
      "Epoch 10/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 193.9047 - val_loss: 186.0138\n",
      "Epoch 11/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 175.5681 - val_loss: 65.3666\n",
      "Epoch 12/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 208.3736 - val_loss: 456.0002\n",
      "Epoch 13/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 157.5546 - val_loss: 306.8677\n",
      "Epoch 14/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 176.0448 - val_loss: 360.9670\n",
      "Epoch 15/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 163.3227 - val_loss: 272.7161\n",
      "Epoch 16/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 145.2135 - val_loss: 395.9760\n",
      "Epoch 17/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 132.7728 - val_loss: 372.7492\n",
      "Epoch 18/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 140.6395 - val_loss: 338.9257\n",
      "Epoch 19/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 137.2811 - val_loss: 412.9905\n",
      "Epoch 20/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 151.0322 - val_loss: 613.1978\n",
      "Epoch 21/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 151.6465 - val_loss: 284.6469\n",
      "Epoch 22/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 152.4232 - val_loss: 519.9586\n",
      "Epoch 23/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 136.4686 - val_loss: 537.7797\n",
      "Epoch 24/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 138.7457 - val_loss: 289.8914\n",
      "Epoch 25/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 131.5759 - val_loss: 312.7686\n",
      "Epoch 26/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 136.2133 - val_loss: 303.4335\n",
      "Epoch 27/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 140.9339 - val_loss: 245.6985\n",
      "Epoch 28/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 136.6455 - val_loss: 289.2679\n",
      "Epoch 29/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 120.4127 - val_loss: 261.1386\n",
      "Epoch 30/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 143.9169 - val_loss: 336.0330\n",
      "Epoch 31/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 121.3314 - val_loss: 265.8131\n",
      "Epoch 32/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 118.4820 - val_loss: 238.4635\n",
      "Epoch 33/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 139.1933 - val_loss: 244.2591\n",
      "Epoch 34/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 133.2106 - val_loss: 258.7139\n",
      "Epoch 35/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 126.7241 - val_loss: 194.9075\n",
      "Epoch 36/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 129.6519 - val_loss: 189.1410\n",
      "Epoch 37/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 119.6716 - val_loss: 209.8806\n",
      "Epoch 38/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 145.5330 - val_loss: 228.6752\n",
      "Epoch 39/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 131.1566 - val_loss: 232.3792\n",
      "Epoch 40/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 133.7760 - val_loss: 364.9718\n",
      "Epoch 41/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 126.2683 - val_loss: 261.3019\n",
      "Epoch 42/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 125.9544 - val_loss: 254.2698\n",
      "Epoch 43/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 126.0019 - val_loss: 237.1582\n",
      "Epoch 44/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 121.4748 - val_loss: 225.6426\n",
      "Epoch 45/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 127.5818 - val_loss: 240.8013\n",
      "Epoch 46/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 134.1014 - val_loss: 235.8237\n",
      "Epoch 47/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 139.0783 - val_loss: 245.2229\n",
      "Epoch 48/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 117.1503 - val_loss: 238.8256\n",
      "Epoch 49/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 120.9303 - val_loss: 192.5660\n",
      "Epoch 50/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 117.9922 - val_loss: 178.2615\n",
      "Epoch 51/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 109.9172 - val_loss: 128.9699\n",
      "Epoch 52/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 136.6278 - val_loss: 169.5329\n",
      "Epoch 53/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 111.2744 - val_loss: 186.9771\n",
      "Epoch 54/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 129.8471 - val_loss: 243.7570\n",
      "Epoch 55/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 122.2865 - val_loss: 205.7223\n",
      "Epoch 56/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 112.8895 - val_loss: 185.1611\n",
      "Epoch 57/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 111.3689 - val_loss: 408.9384\n",
      "Epoch 58/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 139.5013 - val_loss: 294.4946\n",
      "Epoch 59/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 115.3159 - val_loss: 190.3706\n",
      "Epoch 60/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 132.2344 - val_loss: 270.2802\n",
      "Epoch 61/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 113.1916 - val_loss: 193.8739\n",
      "Epoch 62/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 118.7919 - val_loss: 204.4725\n",
      "Epoch 63/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 115.7032 - val_loss: 231.3595\n",
      "Epoch 64/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 121.6591 - val_loss: 202.5378\n",
      "Epoch 65/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 122.6599 - val_loss: 180.5218\n",
      "Epoch 66/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 120.2125 - val_loss: 138.4263\n",
      "Epoch 67/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 110.9412 - val_loss: 119.7341\n",
      "Epoch 68/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 112.3982 - val_loss: 242.7793\n",
      "Epoch 69/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 118.1430 - val_loss: 136.2549\n",
      "Epoch 70/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 122.7181 - val_loss: 113.7764\n",
      "Epoch 71/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 133.7206 - val_loss: 132.1928\n",
      "Epoch 72/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 110.8815 - val_loss: 170.9232\n",
      "Epoch 73/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 110.3204 - val_loss: 122.8448\n",
      "Epoch 74/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 125.6893 - val_loss: 183.9793\n",
      "Epoch 75/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 115.9741 - val_loss: 119.4734\n",
      "Epoch 76/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 113.3215 - val_loss: 210.5788\n",
      "Epoch 77/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 138.0009 - val_loss: 126.4081\n",
      "Epoch 78/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 110.0801 - val_loss: 107.1445\n",
      "Epoch 79/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 124.3636 - val_loss: 131.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 107.4795 - val_loss: 150.3761\n",
      "Epoch 81/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 103.7227 - val_loss: 124.8827\n",
      "Epoch 82/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 113.8927 - val_loss: 98.1749\n",
      "Epoch 83/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 106.5110 - val_loss: 130.0124\n",
      "Epoch 84/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 105.1590 - val_loss: 135.1997\n",
      "Epoch 85/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 109.0319 - val_loss: 149.5316\n",
      "Epoch 86/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 115.6444 - val_loss: 96.2177\n",
      "Epoch 87/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 125.2817 - val_loss: 110.0625\n",
      "Epoch 88/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 115.5590 - val_loss: 103.6878\n",
      "Epoch 89/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 111.1719 - val_loss: 214.1191\n",
      "Epoch 90/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 97.7425 - val_loss: 148.1040\n",
      "Epoch 91/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 96.2629 - val_loss: 162.5741\n",
      "Epoch 92/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 103.5010 - val_loss: 128.3468\n",
      "Epoch 93/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 110.1317 - val_loss: 148.6866\n",
      "Epoch 94/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 108.0905 - val_loss: 137.2780\n",
      "Epoch 95/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 106.1222 - val_loss: 137.7397\n",
      "Epoch 96/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 105.2242 - val_loss: 123.3529\n",
      "Epoch 97/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 118.2903 - val_loss: 125.0029\n",
      "Epoch 98/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 107.2352 - val_loss: 127.5703\n",
      "Epoch 99/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 109.9468 - val_loss: 113.9628\n",
      "Epoch 100/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 111.8705 - val_loss: 136.5216\n",
      "Epoch 101/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 105.9383 - val_loss: 92.3225\n",
      "Epoch 102/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 116.7424 - val_loss: 119.8375\n",
      "Epoch 103/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 108.0367 - val_loss: 126.1443\n",
      "Epoch 104/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 113.1433 - val_loss: 102.1770\n",
      "Epoch 105/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 109.4762 - val_loss: 155.8317\n",
      "Epoch 106/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 117.8412 - val_loss: 99.0397\n",
      "Epoch 107/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 107.4627 - val_loss: 93.3736\n",
      "Epoch 108/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 111.3874 - val_loss: 103.5697\n",
      "Epoch 109/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 111.4443 - val_loss: 106.1879\n",
      "Epoch 110/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 111.3384 - val_loss: 114.0070\n",
      "Epoch 111/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 104.9988 - val_loss: 122.9552\n",
      "Epoch 112/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 98.1221 - val_loss: 100.9297\n",
      "Epoch 113/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 101.8730 - val_loss: 114.7570\n",
      "Epoch 114/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 113.6816 - val_loss: 134.1873\n",
      "Epoch 115/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 98.7974 - val_loss: 96.0485\n",
      "Epoch 116/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 102.7547 - val_loss: 107.6080\n",
      "Epoch 117/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 96.1228 - val_loss: 114.8957\n",
      "Epoch 118/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 100.6107 - val_loss: 96.2437\n",
      "Epoch 119/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 105.1324 - val_loss: 78.1765\n",
      "Epoch 120/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 108.3520 - val_loss: 95.0638\n",
      "Epoch 121/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 108.9069 - val_loss: 86.8176\n",
      "Epoch 122/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 93.4810 - val_loss: 120.3820\n",
      "Epoch 123/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 95.5199 - val_loss: 84.4340\n",
      "Epoch 124/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 112.2873 - val_loss: 102.7042\n",
      "Epoch 125/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 97.5372 - val_loss: 102.4368\n",
      "Epoch 126/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 104.3117 - val_loss: 73.3159\n",
      "Epoch 127/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 108.8547 - val_loss: 118.3523\n",
      "Epoch 128/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 103.3604 - val_loss: 113.0808\n",
      "Epoch 129/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 102.3706 - val_loss: 83.1233\n",
      "Epoch 130/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 98.0099 - val_loss: 93.0499\n",
      "Epoch 131/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 101.2957 - val_loss: 69.8052\n",
      "Epoch 132/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 127.5316 - val_loss: 79.7898\n",
      "Epoch 133/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 102.1475 - val_loss: 75.8519\n",
      "Epoch 134/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 96.7505 - val_loss: 82.0456\n",
      "Epoch 135/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 98.9594 - val_loss: 95.6900\n",
      "Epoch 136/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 111.8927 - val_loss: 92.1656\n",
      "Epoch 137/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 97.6613 - val_loss: 84.8058\n",
      "Epoch 138/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 107.8456 - val_loss: 87.1547\n",
      "Epoch 139/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 104.5588 - val_loss: 84.2383\n",
      "Epoch 140/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 96.3179 - val_loss: 85.0428\n",
      "Epoch 141/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 97.4037 - val_loss: 81.0637\n",
      "Epoch 142/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 96.2848 - val_loss: 51.1921\n",
      "Epoch 143/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 101.7441 - val_loss: 121.6473\n",
      "Epoch 144/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 111.3956 - val_loss: 87.0240\n",
      "Epoch 145/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 111.0920 - val_loss: 121.4081\n",
      "Epoch 146/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 106.1648 - val_loss: 127.8253\n",
      "Epoch 147/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 95.7632 - val_loss: 94.8992\n",
      "Epoch 148/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 104.0071 - val_loss: 86.4312\n",
      "Epoch 149/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 89.1808 - val_loss: 85.6488\n",
      "Epoch 150/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 105.1371 - val_loss: 47.0313\n",
      "Epoch 151/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 90.0217 - val_loss: 24.0997\n",
      "Epoch 152/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 99.9103 - val_loss: 114.2762\n",
      "Epoch 153/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 95.6969 - val_loss: 103.6174\n",
      "Epoch 154/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 113.5020 - val_loss: 97.7421\n",
      "Epoch 155/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 89.9803 - val_loss: 79.0099\n",
      "Epoch 156/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 99.8389 - val_loss: 67.7568\n",
      "Epoch 157/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 94.2287 - val_loss: 70.4149\n",
      "Epoch 158/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 88.4778 - val_loss: 57.1004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 95.1322 - val_loss: 83.3977\n",
      "Epoch 160/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 93.0090 - val_loss: 31.6857\n",
      "Epoch 161/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 85.8175 - val_loss: 50.6866\n",
      "Epoch 162/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 89.3637 - val_loss: 53.8538\n",
      "Epoch 163/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 86.9064 - val_loss: 32.7948\n",
      "Epoch 164/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 86.0838 - val_loss: 74.5695\n",
      "Epoch 165/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 91.5869 - val_loss: 54.8941\n",
      "Epoch 166/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 87.3092 - val_loss: 40.0682\n",
      "Epoch 167/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 96.3266 - val_loss: 44.7725\n",
      "Epoch 168/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 98.1973 - val_loss: 58.0401\n",
      "Epoch 169/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 89.2947 - val_loss: 24.5257\n",
      "Epoch 170/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 95.1600 - val_loss: 21.0658\n",
      "Epoch 171/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 99.4597 - val_loss: 23.5204\n",
      "Epoch 172/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 98.5657 - val_loss: 25.2463\n",
      "Epoch 173/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 91.0242 - val_loss: 18.0387\n",
      "Epoch 174/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 96.7524 - val_loss: 18.2091\n",
      "Epoch 175/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 91.8721 - val_loss: 28.1348\n",
      "Epoch 176/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 86.7269 - val_loss: 18.7158\n",
      "Epoch 177/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 107.9390 - val_loss: 40.5450\n",
      "Epoch 178/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 83.2273 - val_loss: 29.7732\n",
      "Epoch 179/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 91.8045 - val_loss: 27.0278\n",
      "Epoch 180/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 85.8866 - val_loss: 54.8235\n",
      "Epoch 181/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 88.0781 - val_loss: 50.4714\n",
      "Epoch 182/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 85.6044 - val_loss: 62.2888\n",
      "Epoch 183/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 96.3762 - val_loss: 30.2512\n",
      "Epoch 184/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 90.2613 - val_loss: 33.8568\n",
      "Epoch 185/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 95.7069 - val_loss: 59.3041\n",
      "Epoch 186/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 84.0711 - val_loss: 30.5164\n",
      "Epoch 187/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 91.5719 - val_loss: 130.5773\n",
      "Epoch 188/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 94.2562 - val_loss: 55.6842\n",
      "Epoch 189/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 86.7643 - val_loss: 64.1317\n",
      "Epoch 190/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 90.3902 - val_loss: 73.4624\n",
      "Epoch 191/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 85.6440 - val_loss: 53.6790\n",
      "Epoch 192/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 79.3548 - val_loss: 76.9927\n",
      "Epoch 193/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 90.0443 - val_loss: 53.6021\n",
      "Epoch 194/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 86.3558 - val_loss: 50.7593\n",
      "Epoch 195/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 84.5660 - val_loss: 44.2834\n",
      "Epoch 196/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 83.6761 - val_loss: 18.3547\n",
      "Epoch 197/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 90.4316 - val_loss: 23.1816\n",
      "Epoch 198/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 84.1141 - val_loss: 33.2972\n",
      "Epoch 199/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 82.7236 - val_loss: 20.8846\n",
      "Epoch 200/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 91.9081 - val_loss: 23.5365\n",
      "Epoch 201/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 82.6693 - val_loss: 18.9404\n",
      "Epoch 202/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 87.9968 - val_loss: 26.4286\n",
      "Epoch 203/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 90.0219 - val_loss: 19.6822\n",
      "Epoch 204/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 91.4627 - val_loss: 26.4654\n",
      "Epoch 205/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 88.1762 - val_loss: 19.6802\n",
      "Epoch 206/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 84.1364 - val_loss: 20.5079\n",
      "Epoch 207/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.5406 - val_loss: 19.4818\n",
      "Epoch 208/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 83.4986 - val_loss: 23.0291\n",
      "Epoch 209/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 88.3604 - val_loss: 19.1348\n",
      "Epoch 210/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 83.8488 - val_loss: 25.6144\n",
      "Epoch 211/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 84.3279 - val_loss: 40.3569\n",
      "Epoch 212/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 82.5011 - val_loss: 42.6623\n",
      "Epoch 213/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.6741 - val_loss: 55.5442\n",
      "Epoch 214/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 83.9380 - val_loss: 39.3011\n",
      "Epoch 215/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 87.0967 - val_loss: 52.1634\n",
      "Epoch 216/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 81.9306 - val_loss: 26.0212\n",
      "Epoch 217/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 79.8676 - val_loss: 47.4121\n",
      "Epoch 218/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 78.7322 - val_loss: 46.4948\n",
      "Epoch 219/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 80.8594 - val_loss: 40.3789\n",
      "Epoch 220/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 84.7138 - val_loss: 37.6854\n",
      "Epoch 221/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 95.4270 - val_loss: 62.4745\n",
      "Epoch 222/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 87.5092 - val_loss: 52.2506\n",
      "Epoch 223/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 83.6059 - val_loss: 57.6784\n",
      "Epoch 224/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 84.8810 - val_loss: 59.3232\n",
      "Epoch 225/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.9578 - val_loss: 48.7506\n",
      "Epoch 226/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.4729 - val_loss: 58.2918\n",
      "Epoch 227/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 79.4216 - val_loss: 42.5226\n",
      "Epoch 228/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 79.6049 - val_loss: 41.8816\n",
      "Epoch 229/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 84.0567 - val_loss: 43.4855\n",
      "Epoch 230/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.9055 - val_loss: 73.6468\n",
      "Epoch 231/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.2491 - val_loss: 56.2544\n",
      "Epoch 232/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 79.2115 - val_loss: 56.5570\n",
      "Epoch 233/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 85.4740 - val_loss: 38.9928\n",
      "Epoch 234/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 79.5399 - val_loss: 41.8644\n",
      "Epoch 235/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.0004 - val_loss: 58.3980\n",
      "Epoch 236/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 83.1380 - val_loss: 60.8570\n",
      "Epoch 237/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 103.3150 - val_loss: 76.8073\n",
      "Epoch 238/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 91.7665 - val_loss: 84.4586\n",
      "Epoch 239/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 92.9213 - val_loss: 70.7906\n",
      "Epoch 240/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 92.6265 - val_loss: 68.1355\n",
      "Epoch 241/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 82.6372 - val_loss: 36.8499\n",
      "Epoch 242/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 95.7820 - val_loss: 28.4480\n",
      "Epoch 243/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 82.9424 - val_loss: 47.0470\n",
      "Epoch 244/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.0483 - val_loss: 42.7124\n",
      "Epoch 245/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.4070 - val_loss: 35.2414\n",
      "Epoch 246/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 93.8263 - val_loss: 35.2223\n",
      "Epoch 247/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.4730 - val_loss: 34.6814\n",
      "Epoch 248/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 82.0902 - val_loss: 51.2035\n",
      "Epoch 249/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 87.6418 - val_loss: 33.1532\n",
      "Epoch 250/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.6747 - val_loss: 38.2769\n",
      "Epoch 251/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 89.0535 - val_loss: 35.5845\n",
      "Epoch 252/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 79.9184 - val_loss: 51.2375\n",
      "Epoch 253/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 87.4476 - val_loss: 38.7075\n",
      "Epoch 254/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 87.5209 - val_loss: 32.7287\n",
      "Epoch 255/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 90.4835 - val_loss: 56.7665\n",
      "Epoch 256/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 79.2039 - val_loss: 47.3733\n",
      "Epoch 257/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 79.4688 - val_loss: 39.8704\n",
      "Epoch 258/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 81.4149 - val_loss: 38.5262\n",
      "Epoch 259/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.2712 - val_loss: 39.8400\n",
      "Epoch 260/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 78.6037 - val_loss: 33.6677\n",
      "Epoch 261/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 84.8900 - val_loss: 45.1298\n",
      "Epoch 262/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 81.3230 - val_loss: 30.6069\n",
      "Epoch 263/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 78.3582 - val_loss: 57.3084\n",
      "Epoch 264/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 75.5096 - val_loss: 55.4601\n",
      "Epoch 265/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.9587 - val_loss: 50.6376\n",
      "Epoch 266/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.1581 - val_loss: 50.4542\n",
      "Epoch 267/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 82.5193 - val_loss: 35.2712\n",
      "Epoch 268/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 85.4868 - val_loss: 32.3701\n",
      "Epoch 269/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 85.3661 - val_loss: 42.0232\n",
      "Epoch 270/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.0835 - val_loss: 49.2105\n",
      "Epoch 271/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 75.8941 - val_loss: 50.8800\n",
      "Epoch 272/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 70.6205 - val_loss: 52.9215\n",
      "Epoch 273/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 74.5106 - val_loss: 44.6083\n",
      "Epoch 274/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 73.8204 - val_loss: 33.1621\n",
      "Epoch 275/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 84.5365 - val_loss: 37.0319\n",
      "Epoch 276/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 76.5498 - val_loss: 33.3719\n",
      "Epoch 277/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.8784 - val_loss: 46.8428\n",
      "Epoch 278/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 84.3942 - val_loss: 41.6618\n",
      "Epoch 279/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 84.4934 - val_loss: 46.3086\n",
      "Epoch 280/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.8428 - val_loss: 37.5388\n",
      "Epoch 281/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.3250 - val_loss: 34.9793\n",
      "Epoch 282/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.0011 - val_loss: 34.2478\n",
      "Epoch 283/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 78.0613 - val_loss: 30.7153\n",
      "Epoch 284/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 75.6583 - val_loss: 31.3688\n",
      "Epoch 285/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.4665 - val_loss: 39.3243\n",
      "Epoch 286/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 79.7552 - val_loss: 31.2776\n",
      "Epoch 287/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 78.6955 - val_loss: 39.7625\n",
      "Epoch 288/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 74.8954 - val_loss: 38.4770\n",
      "Epoch 289/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 75.2780 - val_loss: 43.2667\n",
      "Epoch 290/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 73.1411 - val_loss: 45.1156\n",
      "Epoch 291/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 71.6396 - val_loss: 35.2990\n",
      "Epoch 292/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 74.2674 - val_loss: 34.7449\n",
      "Epoch 293/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 73.2929 - val_loss: 48.3321\n",
      "Epoch 294/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 82.3761 - val_loss: 32.0484\n",
      "Epoch 295/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 83.5777 - val_loss: 58.9648\n",
      "Epoch 296/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 76.0737 - val_loss: 97.4605\n",
      "Epoch 297/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 73.9160 - val_loss: 45.6103\n",
      "Epoch 298/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 71.4749 - val_loss: 42.1067\n",
      "Epoch 299/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 75.0427 - val_loss: 39.6804\n",
      "Epoch 300/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.9939 - val_loss: 34.3974\n",
      "Epoch 301/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 73.2866 - val_loss: 34.1649\n",
      "Epoch 302/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 75.3631 - val_loss: 37.0088\n",
      "Epoch 303/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 79.3889 - val_loss: 43.9362\n",
      "Epoch 304/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 84.4596 - val_loss: 31.5025\n",
      "Epoch 305/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 76.3296 - val_loss: 32.8458\n",
      "Epoch 306/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 73.5732 - val_loss: 36.4524\n",
      "Epoch 307/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 76.5753 - val_loss: 30.2243\n",
      "Epoch 308/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 75.1657 - val_loss: 43.9314\n",
      "Epoch 309/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 77.6760 - val_loss: 35.3657\n",
      "Epoch 310/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 82.2247 - val_loss: 52.6500\n",
      "Epoch 311/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 83.6009 - val_loss: 36.9143\n",
      "Epoch 312/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 76.8910 - val_loss: 36.7193\n",
      "Epoch 313/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 81.1499 - val_loss: 46.2992\n",
      "Epoch 314/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 76.1277 - val_loss: 36.1001\n",
      "Epoch 315/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 82.6961 - val_loss: 34.4571\n",
      "Epoch 316/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 74.4277 - val_loss: 37.1349\n",
      "Epoch 317/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 76.4714 - val_loss: 63.3967\n",
      "Epoch 318/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 81.9177 - val_loss: 49.5727\n",
      "Epoch 319/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 91.4583 - val_loss: 48.6751\n",
      "Epoch 320/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 79.1143 - val_loss: 39.9775\n",
      "Epoch 321/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 73.4426 - val_loss: 38.4622\n",
      "Epoch 322/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.4401 - val_loss: 31.7815\n",
      "Epoch 323/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 70.6972 - val_loss: 30.5531\n",
      "Epoch 324/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 76.9745 - val_loss: 43.6891\n",
      "Epoch 325/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 84.7050 - val_loss: 48.1792\n",
      "Epoch 326/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 67.1024 - val_loss: 40.9104\n",
      "Epoch 327/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 72.7380 - val_loss: 30.0181\n",
      "Epoch 328/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 70.2027 - val_loss: 41.5755\n",
      "Epoch 329/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 70.0346 - val_loss: 36.3953\n",
      "Epoch 330/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 69.4501 - val_loss: 43.8185\n",
      "Epoch 331/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 70.8486 - val_loss: 43.2310\n",
      "Epoch 332/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 85.4133 - val_loss: 50.1326\n",
      "Epoch 333/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 83.1130 - val_loss: 58.1621\n",
      "Epoch 334/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 75.9758 - val_loss: 54.3139\n",
      "Epoch 335/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 69.4616 - val_loss: 38.3684\n",
      "Epoch 336/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 71.5126 - val_loss: 43.2593\n",
      "Epoch 337/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 68.0251 - val_loss: 38.7732\n",
      "Epoch 338/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.0206 - val_loss: 37.3759\n",
      "Epoch 339/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 66.7357 - val_loss: 32.9132\n",
      "Epoch 340/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 69.2389 - val_loss: 44.4094\n",
      "Epoch 341/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 71.2540 - val_loss: 29.0884\n",
      "Epoch 342/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 71.9123 - val_loss: 62.0189\n",
      "Epoch 343/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 88.3495 - val_loss: 51.3037\n",
      "Epoch 344/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 75.0880 - val_loss: 72.7765\n",
      "Epoch 345/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 65.6429 - val_loss: 35.3911\n",
      "Epoch 346/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 87.3704 - val_loss: 79.0008\n",
      "Epoch 347/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 69.1335 - val_loss: 41.7742\n",
      "Epoch 348/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 61.9580 - val_loss: 55.6191\n",
      "Epoch 349/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 71.6984 - val_loss: 53.7566\n",
      "Epoch 350/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 87.5961 - val_loss: 42.3805\n",
      "Epoch 351/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 73.9616 - val_loss: 48.5730\n",
      "Epoch 352/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 68.6045 - val_loss: 47.9263\n",
      "Epoch 353/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 83.7102 - val_loss: 46.1304\n",
      "Epoch 354/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 63.8769 - val_loss: 49.3431\n",
      "Epoch 355/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 74.0677 - val_loss: 48.7934\n",
      "Epoch 356/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.1002 - val_loss: 42.8512\n",
      "Epoch 357/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 78.4746 - val_loss: 37.7953\n",
      "Epoch 358/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 69.1383 - val_loss: 49.3358\n",
      "Epoch 359/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 76.1503 - val_loss: 47.3359\n",
      "Epoch 360/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 62.5896 - val_loss: 38.4770\n",
      "Epoch 361/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 64.8196 - val_loss: 36.3087\n",
      "Epoch 362/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 67.3109 - val_loss: 26.0178\n",
      "Epoch 363/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 78.3300 - val_loss: 33.4400\n",
      "Epoch 364/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 56.6778 - val_loss: 32.3552\n",
      "Epoch 365/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 64.4590 - val_loss: 32.9822\n",
      "Epoch 366/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.8155 - val_loss: 26.9228\n",
      "Epoch 367/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.2155 - val_loss: 34.8331\n",
      "Epoch 368/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 66.0524 - val_loss: 29.6454\n",
      "Epoch 369/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 76.7355 - val_loss: 28.7668\n",
      "Epoch 370/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 60.9038 - val_loss: 35.0511\n",
      "Epoch 371/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 67.3163 - val_loss: 42.6394\n",
      "Epoch 372/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 71.1734 - val_loss: 37.1985\n",
      "Epoch 373/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 81.4643 - val_loss: 33.8981\n",
      "Epoch 374/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 69.2283 - val_loss: 52.4835\n",
      "Epoch 375/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 65.3973 - val_loss: 38.6317\n",
      "Epoch 376/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 69.3869 - val_loss: 33.9563\n",
      "Epoch 377/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 61.7569 - val_loss: 28.5486\n",
      "Epoch 378/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 63.7757 - val_loss: 50.7656\n",
      "Epoch 379/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 69.5935 - val_loss: 29.6728\n",
      "Epoch 380/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 61.3313 - val_loss: 23.4180\n",
      "Epoch 381/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 84.4515 - val_loss: 53.7955\n",
      "Epoch 382/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 67.0618 - val_loss: 73.7125\n",
      "Epoch 383/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 69.0161 - val_loss: 31.6609\n",
      "Epoch 384/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 60.3096 - val_loss: 30.7665\n",
      "Epoch 385/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 63.3907 - val_loss: 28.4229\n",
      "Epoch 386/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 65.3733 - val_loss: 33.3119\n",
      "Epoch 387/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 76.8867 - val_loss: 37.1516\n",
      "Epoch 388/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 78.4394 - val_loss: 30.6172\n",
      "Epoch 389/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 69.9285 - val_loss: 37.7568\n",
      "Epoch 390/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 65.6911 - val_loss: 30.0945\n",
      "Epoch 391/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 66.7958 - val_loss: 30.5642\n",
      "Epoch 392/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 65.5073 - val_loss: 30.5445\n",
      "Epoch 393/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 63.1388 - val_loss: 35.1123\n",
      "Epoch 394/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 80.7646 - val_loss: 39.3882\n",
      "Epoch 395/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 71.0140 - val_loss: 34.4795\n",
      "Epoch 396/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 67.6072 - val_loss: 36.4042\n",
      "Epoch 397/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 63.8872 - val_loss: 36.0880\n",
      "Epoch 398/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 69.7193 - val_loss: 36.0716\n",
      "Epoch 399/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 59.4137 - val_loss: 36.4033\n",
      "Epoch 400/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 78.6384 - val_loss: 35.8884\n",
      "Epoch 401/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 67.4166 - val_loss: 38.2520\n",
      "Epoch 402/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 59.4387 - val_loss: 30.3519\n",
      "Epoch 403/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 57.4049 - val_loss: 33.5179\n",
      "Epoch 404/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 59.1225 - val_loss: 32.3980\n",
      "Epoch 405/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 58.0201 - val_loss: 30.7971\n",
      "Epoch 406/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 80.2746 - val_loss: 29.0760\n",
      "Epoch 407/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 72.2491 - val_loss: 38.3983\n",
      "Epoch 408/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 73.7955 - val_loss: 51.4848\n",
      "Epoch 409/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 66.8014 - val_loss: 40.5895\n",
      "Epoch 410/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 69.4735 - val_loss: 33.5029\n",
      "Epoch 411/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 66.1326 - val_loss: 35.2776\n",
      "Epoch 412/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 56.8749 - val_loss: 34.4692\n",
      "Epoch 413/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 59.0601 - val_loss: 32.6984\n",
      "Epoch 414/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 64.0408 - val_loss: 41.1408\n",
      "Epoch 415/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 57.8548 - val_loss: 36.9033\n",
      "Epoch 416/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 65.0530 - val_loss: 36.0917\n",
      "Epoch 417/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 75.9640 - val_loss: 29.4284\n",
      "Epoch 418/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 66.8901 - val_loss: 34.9074\n",
      "Epoch 419/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 64.8488 - val_loss: 30.8585\n",
      "Epoch 420/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 75.3778 - val_loss: 30.6532\n",
      "Epoch 421/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 57.6819 - val_loss: 32.5621\n",
      "Epoch 422/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 57.0934 - val_loss: 37.9847\n",
      "Epoch 423/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 60.9030 - val_loss: 36.9969\n",
      "Epoch 424/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 55.0671 - val_loss: 30.2151\n",
      "Epoch 425/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 59.1054 - val_loss: 35.1977\n",
      "Epoch 426/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 59.7974 - val_loss: 37.3211\n",
      "Epoch 427/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 56.2812 - val_loss: 35.2581\n",
      "Epoch 428/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 55.5317 - val_loss: 33.5687\n",
      "Epoch 429/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 66.8561 - val_loss: 37.0179\n",
      "Epoch 430/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 54.7388 - val_loss: 36.7518\n",
      "Epoch 431/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 74.4576 - val_loss: 31.4363\n",
      "Epoch 432/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 76.5527 - val_loss: 37.1497\n",
      "Epoch 433/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 55.1128 - val_loss: 55.2768\n",
      "Epoch 434/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 55.0547 - val_loss: 34.8336\n",
      "Epoch 435/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 60.5856 - val_loss: 42.9681\n",
      "Epoch 436/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 62.6859 - val_loss: 38.9321\n",
      "Epoch 437/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 68.0260 - val_loss: 29.8853\n",
      "Epoch 438/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 54.8453 - val_loss: 37.9326\n",
      "Epoch 439/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 68.1788 - val_loss: 41.4585\n",
      "Epoch 440/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 61.4664 - val_loss: 37.3017\n",
      "Epoch 441/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 57.8013 - val_loss: 51.5820\n",
      "Epoch 442/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 80.2124 - val_loss: 30.4213\n",
      "Epoch 443/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 58.1392 - val_loss: 31.9359\n",
      "Epoch 444/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 53.4111 - val_loss: 29.6132\n",
      "Epoch 445/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 57.0789 - val_loss: 29.5593\n",
      "Epoch 446/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 57.7408 - val_loss: 36.3618\n",
      "Epoch 447/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 57.6333 - val_loss: 32.3442\n",
      "Epoch 448/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 56.8775 - val_loss: 41.4186\n",
      "Epoch 449/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 61.9470 - val_loss: 33.5345\n",
      "Epoch 450/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 53.4827 - val_loss: 38.4066\n",
      "Epoch 451/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 56.7269 - val_loss: 35.4703\n",
      "Epoch 452/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 52.4793 - val_loss: 30.0102\n",
      "Epoch 453/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 62.7378 - val_loss: 30.9010\n",
      "Epoch 454/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 57.8383 - val_loss: 31.7597\n",
      "Epoch 455/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 58.7002 - val_loss: 28.0935\n",
      "Epoch 456/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 55.3674 - val_loss: 31.0819\n",
      "Epoch 457/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 61.8564 - val_loss: 29.4478\n",
      "Epoch 458/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 67.4964 - val_loss: 30.0136\n",
      "Epoch 459/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 58.6423 - val_loss: 33.4850\n",
      "Epoch 460/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 55.8771 - val_loss: 33.2873\n",
      "Epoch 461/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 52.5865 - val_loss: 33.0276\n",
      "Epoch 462/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 59.7353 - val_loss: 29.4252\n",
      "Epoch 463/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 57.5848 - val_loss: 28.8469\n",
      "Epoch 464/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 52.7794 - val_loss: 29.6547\n",
      "Epoch 465/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 52.2092 - val_loss: 34.0932\n",
      "Epoch 466/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 52.8656 - val_loss: 31.5832\n",
      "Epoch 467/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 53.2431 - val_loss: 27.9108\n",
      "Epoch 468/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 54.2066 - val_loss: 37.1259\n",
      "Epoch 469/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 58.1650 - val_loss: 28.5016\n",
      "Epoch 470/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 49.8576 - val_loss: 31.5583\n",
      "Epoch 471/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 57.9022 - val_loss: 29.6553\n",
      "Epoch 472/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 62.4543 - val_loss: 30.0601\n",
      "Epoch 473/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 56.4637 - val_loss: 29.7828\n",
      "Epoch 474/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 67.5707 - val_loss: 29.2278\n",
      "Epoch 475/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 60.5833 - val_loss: 28.0928\n",
      "Epoch 476/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 80.0615 - val_loss: 27.5242\n",
      "Epoch 477/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 54.5355 - val_loss: 31.4811\n",
      "Epoch 478/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 60.0115 - val_loss: 27.0447\n",
      "Epoch 479/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 77.6802 - val_loss: 30.3831\n",
      "Epoch 480/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 60.9609 - val_loss: 24.0315\n",
      "Epoch 481/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 63.7643 - val_loss: 32.2585\n",
      "Epoch 482/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 55.4570 - val_loss: 30.7712\n",
      "Epoch 483/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 55.5997 - val_loss: 27.6507\n",
      "Epoch 484/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 71.7362 - val_loss: 28.6133\n",
      "Epoch 485/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 99.0958 - val_loss: 28.8271\n",
      "Epoch 486/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 81.0997 - val_loss: 27.4392\n",
      "Epoch 487/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 81.8772 - val_loss: 33.5193\n",
      "Epoch 488/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 70.5194 - val_loss: 32.2676\n",
      "Epoch 489/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 70.5713 - val_loss: 30.4282\n",
      "Epoch 490/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 72.0213 - val_loss: 34.0003\n",
      "Epoch 491/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 68.9339 - val_loss: 29.6756\n",
      "Epoch 492/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 67.7995 - val_loss: 29.5593\n",
      "Epoch 493/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 72.5400 - val_loss: 30.2387\n",
      "Epoch 494/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 59.8991 - val_loss: 32.8765\n",
      "Epoch 495/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 63.0195 - val_loss: 26.7539\n",
      "Epoch 496/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 60.3277 - val_loss: 37.1029\n",
      "Epoch 497/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 58.1527 - val_loss: 27.5919\n",
      "Epoch 498/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 61.5203 - val_loss: 28.8767\n",
      "Epoch 499/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 60.7282 - val_loss: 28.4661\n",
      "Epoch 500/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 62.9896 - val_loss: 26.7917\n",
      "Epoch 501/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 57.1219 - val_loss: 29.2793\n",
      "Epoch 502/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 61.6593 - val_loss: 29.8611\n",
      "Epoch 503/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 56.8909 - val_loss: 28.0239\n",
      "Epoch 504/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 60.6259 - val_loss: 31.3721\n",
      "Epoch 505/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 64.6189 - val_loss: 27.9512\n",
      "Epoch 506/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 88.4186 - val_loss: 31.1463\n",
      "Epoch 507/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 54.3756 - val_loss: 36.6016\n",
      "Epoch 508/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 57.3403 - val_loss: 28.5509\n",
      "Epoch 509/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 53.7989 - val_loss: 36.6028\n",
      "Epoch 510/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 65.5959 - val_loss: 28.2729\n",
      "Epoch 511/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 91.3852 - val_loss: 44.9381\n",
      "Epoch 512/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 58.7535 - val_loss: 39.0620\n",
      "Epoch 513/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 55.5074 - val_loss: 33.9292\n",
      "Epoch 514/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 54.5398 - val_loss: 23.7789\n",
      "Epoch 515/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 58.3803 - val_loss: 36.7820\n",
      "Epoch 516/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 52.2312 - val_loss: 26.1707\n",
      "Epoch 517/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 54.5148 - val_loss: 29.9712\n",
      "Epoch 518/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 55.7509 - val_loss: 29.8044\n",
      "Epoch 519/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 50.8061 - val_loss: 31.8638\n",
      "Epoch 520/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 49.5467 - val_loss: 16.7560\n",
      "Epoch 521/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 54.4885 - val_loss: 24.5252\n",
      "Epoch 522/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 55.6230 - val_loss: 16.6845\n",
      "Epoch 523/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 58.6553 - val_loss: 24.3071\n",
      "Epoch 524/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 57.8110 - val_loss: 15.5285\n",
      "Epoch 525/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 45.0880 - val_loss: 28.4125\n",
      "Epoch 526/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 54.9170 - val_loss: 29.0297\n",
      "Epoch 527/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 56.0929 - val_loss: 16.5975\n",
      "Epoch 528/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 51.9658 - val_loss: 27.3713\n",
      "Epoch 529/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 49.5227 - val_loss: 26.1010\n",
      "Epoch 530/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 50.3982 - val_loss: 27.2154\n",
      "Epoch 531/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 55.8713 - val_loss: 20.8092\n",
      "Epoch 532/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 56.3623 - val_loss: 25.2311\n",
      "Epoch 533/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 51.9401 - val_loss: 25.4512\n",
      "Epoch 534/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 52.9137 - val_loss: 16.2483\n",
      "Epoch 535/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 62.3441 - val_loss: 25.7512\n",
      "Epoch 536/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 47.4124 - val_loss: 16.4449\n",
      "Epoch 537/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 44.8943 - val_loss: 22.0191\n",
      "Epoch 538/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 56.8435 - val_loss: 17.0449\n",
      "Epoch 539/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 40.2948 - val_loss: 25.5134\n",
      "Epoch 540/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 45.5203 - val_loss: 27.4260\n",
      "Epoch 541/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 46.1643 - val_loss: 18.3220\n",
      "Epoch 542/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 41.3034 - val_loss: 14.7604\n",
      "Epoch 543/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 49.7303 - val_loss: 14.6403\n",
      "Epoch 544/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 51.7498 - val_loss: 14.6530\n",
      "Epoch 545/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 42.9174 - val_loss: 25.6927\n",
      "Epoch 546/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 41.9926 - val_loss: 17.1654\n",
      "Epoch 547/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 49.9858 - val_loss: 15.0615\n",
      "Epoch 548/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 51.1496 - val_loss: 15.7629\n",
      "Epoch 549/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 51.6041 - val_loss: 15.6696\n",
      "Epoch 550/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 40.5589 - val_loss: 15.0960\n",
      "Epoch 551/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 50.7887 - val_loss: 15.9897\n",
      "Epoch 552/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 56.7262 - val_loss: 15.9437\n",
      "Epoch 553/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 74.3754 - val_loss: 25.5675\n",
      "Epoch 554/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 50.1080 - val_loss: 33.9802\n",
      "Epoch 555/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 41.7048 - val_loss: 35.0128\n",
      "Epoch 556/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 44.9954 - val_loss: 31.8663\n",
      "Epoch 557/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 43.5450 - val_loss: 33.3662\n",
      "Epoch 558/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 44.3836 - val_loss: 30.0205\n",
      "Epoch 559/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 40.2722 - val_loss: 25.8076\n",
      "Epoch 560/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 48.8030 - val_loss: 28.6398\n",
      "Epoch 561/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 55.5233 - val_loss: 49.1451\n",
      "Epoch 562/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 66.3482 - val_loss: 16.3162\n",
      "Epoch 563/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 42.6844 - val_loss: 35.2252\n",
      "Epoch 564/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 38.8922 - val_loss: 43.2450\n",
      "Epoch 565/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 36.8925 - val_loss: 38.4839\n",
      "Epoch 566/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 32.6314 - val_loss: 49.0723\n",
      "Epoch 567/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 33.4958 - val_loss: 33.9484\n",
      "Epoch 568/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 30.0492 - val_loss: 39.3459\n",
      "Epoch 569/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 34.1126 - val_loss: 37.7218\n",
      "Epoch 570/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 36.6163 - val_loss: 31.5297\n",
      "Epoch 571/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 60.7676 - val_loss: 36.7382\n",
      "Epoch 572/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 41.0018 - val_loss: 32.5702\n",
      "Epoch 573/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 32.7173 - val_loss: 33.1055\n",
      "Epoch 574/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 26.9465 - val_loss: 25.2114\n",
      "Epoch 575/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.0864 - val_loss: 17.3621\n",
      "Epoch 576/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 27.0606 - val_loss: 28.6731\n",
      "Epoch 577/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 32.2153 - val_loss: 34.9188\n",
      "Epoch 578/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 32.5401 - val_loss: 25.0796\n",
      "Epoch 579/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 33.3494 - val_loss: 39.2694\n",
      "Epoch 580/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 34.9989 - val_loss: 27.2651\n",
      "Epoch 581/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 33.2451 - val_loss: 27.0499\n",
      "Epoch 582/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 31.8114 - val_loss: 27.4879\n",
      "Epoch 583/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 32.7833 - val_loss: 25.3027\n",
      "Epoch 584/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 37.2739 - val_loss: 37.8389\n",
      "Epoch 585/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.8165 - val_loss: 33.5254\n",
      "Epoch 586/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 28.8962 - val_loss: 33.1970\n",
      "Epoch 587/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 35.4999 - val_loss: 25.9175\n",
      "Epoch 588/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.9423 - val_loss: 26.5637\n",
      "Epoch 589/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 28.3729 - val_loss: 27.7300\n",
      "Epoch 590/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 28.6378 - val_loss: 35.9140\n",
      "Epoch 591/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 26.1753 - val_loss: 34.8024\n",
      "Epoch 592/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 28.8484 - val_loss: 27.2588\n",
      "Epoch 593/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.4427 - val_loss: 34.4656\n",
      "Epoch 594/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.8148 - val_loss: 37.3935\n",
      "Epoch 595/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.4500 - val_loss: 26.5086\n",
      "Epoch 596/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 30.4243 - val_loss: 31.8793\n",
      "Epoch 597/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 33.9763 - val_loss: 27.3888\n",
      "Epoch 598/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.2275 - val_loss: 28.3099\n",
      "Epoch 599/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 24.8018 - val_loss: 28.0857\n",
      "Epoch 600/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 30.3886 - val_loss: 31.1258\n",
      "Epoch 601/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.0260 - val_loss: 26.9858\n",
      "Epoch 602/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 23.8324 - val_loss: 34.4623\n",
      "Epoch 603/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 32.3992 - val_loss: 28.0767\n",
      "Epoch 604/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 28.3687 - val_loss: 29.7525\n",
      "Epoch 605/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 31.8539 - val_loss: 36.8618\n",
      "Epoch 606/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 28.6585 - val_loss: 35.1823\n",
      "Epoch 607/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.7051 - val_loss: 34.0305\n",
      "Epoch 608/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 24.2703 - val_loss: 34.9321\n",
      "Epoch 609/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 26.0154 - val_loss: 33.7660\n",
      "Epoch 610/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.5512 - val_loss: 34.6107\n",
      "Epoch 611/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.9019 - val_loss: 26.5196\n",
      "Epoch 612/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 27.8356 - val_loss: 36.5413\n",
      "Epoch 613/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.1690 - val_loss: 26.6328\n",
      "Epoch 614/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.1766 - val_loss: 28.0824\n",
      "Epoch 615/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 32.9174 - val_loss: 34.3193\n",
      "Epoch 616/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.8560 - val_loss: 28.4625\n",
      "Epoch 617/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 24.8493 - val_loss: 27.6069\n",
      "Epoch 618/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.5386 - val_loss: 38.3012\n",
      "Epoch 619/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 27.7398 - val_loss: 28.1694\n",
      "Epoch 620/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.2242 - val_loss: 36.7528\n",
      "Epoch 621/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.0084 - val_loss: 28.3504\n",
      "Epoch 622/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 26.4913 - val_loss: 28.8075\n",
      "Epoch 623/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 27.7448 - val_loss: 28.7252\n",
      "Epoch 624/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.6572 - val_loss: 29.7271\n",
      "Epoch 625/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.6562 - val_loss: 29.2142\n",
      "Epoch 626/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 24.8289 - val_loss: 26.8931\n",
      "Epoch 627/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 25.7118 - val_loss: 17.5537\n",
      "Epoch 628/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.8859 - val_loss: 24.2721\n",
      "Epoch 629/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 27.4577 - val_loss: 14.5782\n",
      "Epoch 630/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.9966 - val_loss: 48.9673\n",
      "Epoch 631/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 38.5369 - val_loss: 36.6206\n",
      "Epoch 632/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 49.4876 - val_loss: 30.6142\n",
      "Epoch 633/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 33.1282 - val_loss: 18.9593\n",
      "Epoch 634/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 25.9960 - val_loss: 17.3056\n",
      "Epoch 635/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.9749 - val_loss: 17.8851\n",
      "Epoch 636/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 30.8171 - val_loss: 17.2806\n",
      "Epoch 637/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.1931 - val_loss: 16.2840\n",
      "Epoch 638/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 26.1694 - val_loss: 17.6726\n",
      "Epoch 639/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 20.1763 - val_loss: 28.3753\n",
      "Epoch 640/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.3300 - val_loss: 24.8325\n",
      "Epoch 641/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.6040 - val_loss: 18.4658\n",
      "Epoch 642/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 32.4088 - val_loss: 15.0704\n",
      "Epoch 643/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 32.9348 - val_loss: 29.0236\n",
      "Epoch 644/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.2378 - val_loss: 34.8452\n",
      "Epoch 645/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 26.2955 - val_loss: 27.5531\n",
      "Epoch 646/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 26.0592 - val_loss: 37.6317\n",
      "Epoch 647/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 23.0465 - val_loss: 38.3506\n",
      "Epoch 648/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.7521 - val_loss: 28.5109\n",
      "Epoch 649/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.7586 - val_loss: 19.2952\n",
      "Epoch 650/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 24.6096 - val_loss: 17.6296\n",
      "Epoch 651/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.0270 - val_loss: 18.0167\n",
      "Epoch 652/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.1024 - val_loss: 27.0785\n",
      "Epoch 653/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 28.0925 - val_loss: 26.8937\n",
      "Epoch 654/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 23.6495 - val_loss: 27.6453\n",
      "Epoch 655/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 24.1255 - val_loss: 15.0605\n",
      "Epoch 656/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.9536 - val_loss: 17.6656\n",
      "Epoch 657/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 26.7891 - val_loss: 18.1545\n",
      "Epoch 658/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.7817 - val_loss: 22.0254\n",
      "Epoch 659/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.8170 - val_loss: 30.6764\n",
      "Epoch 660/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 34.9775 - val_loss: 16.7286\n",
      "Epoch 661/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.8951 - val_loss: 34.9588\n",
      "Epoch 662/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.7493 - val_loss: 20.4369\n",
      "Epoch 663/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.1067 - val_loss: 16.4281\n",
      "Epoch 664/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 24.6937 - val_loss: 19.4485\n",
      "Epoch 665/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 29.6576 - val_loss: 14.5190\n",
      "Epoch 666/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.5392 - val_loss: 18.6354\n",
      "Epoch 667/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 24.1266 - val_loss: 15.4596\n",
      "Epoch 668/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 24.5772 - val_loss: 29.7337\n",
      "Epoch 669/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 24.3151 - val_loss: 28.3419\n",
      "Epoch 670/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 27.3243 - val_loss: 14.5644\n",
      "Epoch 671/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 30.8780 - val_loss: 20.2385\n",
      "Epoch 672/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 20.8610 - val_loss: 23.0973\n",
      "Epoch 673/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.5198 - val_loss: 16.3160\n",
      "Epoch 674/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.9570 - val_loss: 17.1667\n",
      "Epoch 675/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.1007 - val_loss: 16.9720\n",
      "Epoch 676/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 24.4003 - val_loss: 17.1302\n",
      "Epoch 677/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.2280 - val_loss: 16.9059\n",
      "Epoch 678/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.3921 - val_loss: 16.9566\n",
      "Epoch 679/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 20.9712 - val_loss: 16.9756\n",
      "Epoch 680/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 24.1143 - val_loss: 17.5314\n",
      "Epoch 681/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 24.9815 - val_loss: 17.6825\n",
      "Epoch 682/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 20.7250 - val_loss: 17.0458\n",
      "Epoch 683/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 20.2421 - val_loss: 17.6178\n",
      "Epoch 684/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.8622 - val_loss: 17.0355\n",
      "Epoch 685/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.8153 - val_loss: 15.1402\n",
      "Epoch 686/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.2050 - val_loss: 17.0108\n",
      "Epoch 687/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.3396 - val_loss: 20.4051\n",
      "Epoch 688/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.5017 - val_loss: 16.9202\n",
      "Epoch 689/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.2144 - val_loss: 15.7691\n",
      "Epoch 690/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.7988 - val_loss: 16.9583\n",
      "Epoch 691/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.0900 - val_loss: 15.1456\n",
      "Epoch 692/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6479 - val_loss: 14.9766\n",
      "Epoch 693/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.9404 - val_loss: 14.8912\n",
      "Epoch 694/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.1413 - val_loss: 15.7196\n",
      "Epoch 695/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.9328 - val_loss: 17.9055\n",
      "Epoch 696/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.4432 - val_loss: 15.1554\n",
      "Epoch 697/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.9120 - val_loss: 16.7551\n",
      "Epoch 698/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.9018 - val_loss: 15.2267\n",
      "Epoch 699/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.5395 - val_loss: 15.2013\n",
      "Epoch 700/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2846 - val_loss: 15.3984\n",
      "Epoch 701/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.4251 - val_loss: 15.1744\n",
      "Epoch 702/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.1702 - val_loss: 15.0967\n",
      "Epoch 703/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.6528 - val_loss: 14.8695\n",
      "Epoch 704/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.9662 - val_loss: 15.0795\n",
      "Epoch 705/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 20.0254 - val_loss: 16.2008\n",
      "Epoch 706/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.6874 - val_loss: 15.5692\n",
      "Epoch 707/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.4915 - val_loss: 16.1111\n",
      "Epoch 708/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 24.9394 - val_loss: 15.7344\n",
      "Epoch 709/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.3780 - val_loss: 15.0245\n",
      "Epoch 710/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.1313 - val_loss: 19.6052\n",
      "Epoch 711/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.0332 - val_loss: 15.1561\n",
      "Epoch 712/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 20.4851 - val_loss: 17.7178\n",
      "Epoch 713/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 30.0547 - val_loss: 17.4097\n",
      "Epoch 714/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 26.1363 - val_loss: 15.2375\n",
      "Epoch 715/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 25.8587 - val_loss: 16.3056\n",
      "Epoch 716/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.5007 - val_loss: 16.6973\n",
      "Epoch 717/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.2423 - val_loss: 15.4464\n",
      "Epoch 718/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.5117 - val_loss: 17.5301\n",
      "Epoch 719/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.0431 - val_loss: 17.4354\n",
      "Epoch 720/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 24.0988 - val_loss: 17.1601\n",
      "Epoch 721/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.1478 - val_loss: 15.6398\n",
      "Epoch 722/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.0662 - val_loss: 15.6199\n",
      "Epoch 723/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.1350 - val_loss: 15.3625\n",
      "Epoch 724/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.1014 - val_loss: 15.9891\n",
      "Epoch 725/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.7438 - val_loss: 16.0505\n",
      "Epoch 726/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.6117 - val_loss: 30.7326\n",
      "Epoch 727/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.1168 - val_loss: 29.5019\n",
      "Epoch 728/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.4646 - val_loss: 18.1786\n",
      "Epoch 729/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.4128 - val_loss: 18.1610\n",
      "Epoch 730/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.6732 - val_loss: 31.3091\n",
      "Epoch 731/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.6974 - val_loss: 15.0954\n",
      "Epoch 732/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.8294 - val_loss: 28.7560\n",
      "Epoch 733/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 26.8234 - val_loss: 17.0976\n",
      "Epoch 734/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.0973 - val_loss: 28.3590\n",
      "Epoch 735/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 23.7011 - val_loss: 14.2289\n",
      "Epoch 736/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 23.4136 - val_loss: 28.5371\n",
      "Epoch 737/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.7339 - val_loss: 14.6582\n",
      "Epoch 738/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.0661 - val_loss: 17.9121\n",
      "Epoch 739/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.1483 - val_loss: 17.7747\n",
      "Epoch 740/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.1045 - val_loss: 29.7578\n",
      "Epoch 741/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.9660 - val_loss: 17.8060\n",
      "Epoch 742/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.5791 - val_loss: 18.6181\n",
      "Epoch 743/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.0885 - val_loss: 14.7705\n",
      "Epoch 744/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.9217 - val_loss: 17.8530\n",
      "Epoch 745/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.7689 - val_loss: 14.8385\n",
      "Epoch 746/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.9821 - val_loss: 15.9286\n",
      "Epoch 747/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 22.4298 - val_loss: 28.8033\n",
      "Epoch 748/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 25.0164 - val_loss: 17.1186\n",
      "Epoch 749/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.6583 - val_loss: 28.1484\n",
      "Epoch 750/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.4243 - val_loss: 29.3002\n",
      "Epoch 751/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.7216 - val_loss: 18.9289\n",
      "Epoch 752/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 23.6842 - val_loss: 28.0549\n",
      "Epoch 753/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.6110 - val_loss: 40.3295\n",
      "Epoch 754/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 31.2969 - val_loss: 16.7863\n",
      "Epoch 755/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.5543 - val_loss: 30.7219\n",
      "Epoch 756/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.9600 - val_loss: 21.5675\n",
      "Epoch 757/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.4113 - val_loss: 25.6566\n",
      "Epoch 758/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.3569 - val_loss: 30.0226\n",
      "Epoch 759/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.2728 - val_loss: 20.0067\n",
      "Epoch 760/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 20.0430 - val_loss: 29.2324\n",
      "Epoch 761/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.1564 - val_loss: 29.3534\n",
      "Epoch 762/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.3726 - val_loss: 35.7331\n",
      "Epoch 763/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.4418 - val_loss: 28.7976\n",
      "Epoch 764/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.3562 - val_loss: 14.6320\n",
      "Epoch 765/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 18.3119 - val_loss: 27.2954\n",
      "Epoch 766/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.3045 - val_loss: 27.9273\n",
      "Epoch 767/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.4033 - val_loss: 28.0146\n",
      "Epoch 768/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.9886 - val_loss: 18.1370\n",
      "Epoch 769/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.5852 - val_loss: 28.0351\n",
      "Epoch 770/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.3232 - val_loss: 17.7083\n",
      "Epoch 771/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.5812 - val_loss: 33.1712\n",
      "Epoch 772/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.1948 - val_loss: 32.1589\n",
      "Epoch 773/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 21.8426 - val_loss: 31.4770\n",
      "Epoch 774/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.8723 - val_loss: 30.3192\n",
      "Epoch 775/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 19.7959 - val_loss: 28.5051\n",
      "Epoch 776/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.6639 - val_loss: 30.5759\n",
      "Epoch 777/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.9572 - val_loss: 32.6511\n",
      "Epoch 778/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 20.7080 - val_loss: 29.5098\n",
      "Epoch 779/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.3793 - val_loss: 32.1626\n",
      "Epoch 780/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.3488 - val_loss: 35.3253\n",
      "Epoch 781/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.0665 - val_loss: 32.4786\n",
      "Epoch 782/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.1192 - val_loss: 33.5082\n",
      "Epoch 783/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.8790 - val_loss: 31.0693\n",
      "Epoch 784/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.6565 - val_loss: 31.5924\n",
      "Epoch 785/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.5399 - val_loss: 32.5085\n",
      "Epoch 786/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.1605 - val_loss: 29.5539\n",
      "Epoch 787/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 21.5894 - val_loss: 35.4653\n",
      "Epoch 788/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.3849 - val_loss: 35.1051\n",
      "Epoch 789/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.2343 - val_loss: 34.1836\n",
      "Epoch 790/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.0105 - val_loss: 31.8349\n",
      "Epoch 791/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 19.6291 - val_loss: 36.9153\n",
      "Epoch 792/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3302 - val_loss: 35.3210\n",
      "Epoch 793/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.5762 - val_loss: 32.5501\n",
      "Epoch 794/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.8235 - val_loss: 33.2115\n",
      "Epoch 795/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.8476 - val_loss: 32.5604\n",
      "Epoch 796/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.7568 - val_loss: 34.0967\n",
      "Epoch 797/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.8127 - val_loss: 32.8515\n",
      "Epoch 798/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 17.1473 - val_loss: 34.1751\n",
      "Epoch 799/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 20.0034 - val_loss: 34.6744\n",
      "Epoch 800/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.7953 - val_loss: 33.8751\n",
      "Epoch 801/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.7820 - val_loss: 34.4078\n",
      "Epoch 802/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.0798 - val_loss: 34.4084\n",
      "Epoch 803/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.6617 - val_loss: 38.2852\n",
      "Epoch 804/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 19.8714 - val_loss: 38.2011\n",
      "Epoch 805/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 17.1321 - val_loss: 33.6115\n",
      "Epoch 806/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.0579 - val_loss: 37.8911\n",
      "Epoch 807/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.0824 - val_loss: 33.2775\n",
      "Epoch 808/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.6651 - val_loss: 35.5207\n",
      "Epoch 809/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 17.2791 - val_loss: 33.1069\n",
      "Epoch 810/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.6800 - val_loss: 33.9657\n",
      "Epoch 811/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.5329 - val_loss: 30.4385\n",
      "Epoch 812/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.6427 - val_loss: 31.2282\n",
      "Epoch 813/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.0546 - val_loss: 31.7454\n",
      "Epoch 814/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.1435 - val_loss: 33.4630\n",
      "Epoch 815/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.8651 - val_loss: 34.6991\n",
      "Epoch 816/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1399 - val_loss: 30.4866\n",
      "Epoch 817/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.9633 - val_loss: 32.6253\n",
      "Epoch 818/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.0390 - val_loss: 32.4915\n",
      "Epoch 819/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2490 - val_loss: 28.5660\n",
      "Epoch 820/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.6073 - val_loss: 32.2218\n",
      "Epoch 821/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.1838 - val_loss: 33.2839\n",
      "Epoch 822/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.2898 - val_loss: 35.7079\n",
      "Epoch 823/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.6203 - val_loss: 33.8462\n",
      "Epoch 824/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.6069 - val_loss: 36.8500\n",
      "Epoch 825/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.3074 - val_loss: 36.4819\n",
      "Epoch 826/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 18.0828 - val_loss: 35.5594\n",
      "Epoch 827/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1931 - val_loss: 33.0461\n",
      "Epoch 828/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 19.5190 - val_loss: 35.3721\n",
      "Epoch 829/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.9473 - val_loss: 34.1522\n",
      "Epoch 830/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.4480 - val_loss: 35.8908\n",
      "Epoch 831/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 14.1431 - val_loss: 32.2801\n",
      "Epoch 832/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.2959 - val_loss: 32.8850\n",
      "Epoch 833/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.3697 - val_loss: 34.4932\n",
      "Epoch 834/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 17.7493 - val_loss: 33.4062\n",
      "Epoch 835/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.1185 - val_loss: 30.0990\n",
      "Epoch 836/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.1479 - val_loss: 28.6371\n",
      "Epoch 837/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.3415 - val_loss: 32.5289\n",
      "Epoch 838/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.7925 - val_loss: 32.5551\n",
      "Epoch 839/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2259 - val_loss: 32.2507\n",
      "Epoch 840/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.1001 - val_loss: 33.8776\n",
      "Epoch 841/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0084 - val_loss: 33.7780\n",
      "Epoch 842/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.0660 - val_loss: 32.4642\n",
      "Epoch 843/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 20.6447 - val_loss: 30.6387\n",
      "Epoch 844/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 35.6821 - val_loss: 37.1267\n",
      "Epoch 845/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 26.5380 - val_loss: 35.2630\n",
      "Epoch 846/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.4314 - val_loss: 36.0402\n",
      "Epoch 847/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.6055 - val_loss: 31.9901\n",
      "Epoch 848/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.2955 - val_loss: 32.3220\n",
      "Epoch 849/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.2061 - val_loss: 39.1483\n",
      "Epoch 850/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.3226 - val_loss: 37.6259\n",
      "Epoch 851/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.7152 - val_loss: 44.0692\n",
      "Epoch 852/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.0754 - val_loss: 32.0105\n",
      "Epoch 853/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3973 - val_loss: 34.9711\n",
      "Epoch 854/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.8701 - val_loss: 38.0629\n",
      "Epoch 855/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.6922 - val_loss: 32.1439\n",
      "Epoch 856/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.3851 - val_loss: 32.9888\n",
      "Epoch 857/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0341 - val_loss: 32.0571\n",
      "Epoch 858/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.9615 - val_loss: 32.1150\n",
      "Epoch 859/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.7097 - val_loss: 33.2969\n",
      "Epoch 860/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.0585 - val_loss: 35.6506\n",
      "Epoch 861/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.7401 - val_loss: 33.6546\n",
      "Epoch 862/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.6196 - val_loss: 33.1021\n",
      "Epoch 863/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.3071 - val_loss: 31.4878\n",
      "Epoch 864/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.1565 - val_loss: 33.9167\n",
      "Epoch 865/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.1114 - val_loss: 32.8784\n",
      "Epoch 866/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.3143 - val_loss: 36.9301\n",
      "Epoch 867/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.0045 - val_loss: 33.0886\n",
      "Epoch 868/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.0954 - val_loss: 35.0484\n",
      "Epoch 869/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.7956 - val_loss: 35.4708\n",
      "Epoch 870/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 15.6680 - val_loss: 35.8496\n",
      "Epoch 871/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.8867 - val_loss: 31.4759\n",
      "Epoch 872/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5627 - val_loss: 37.8437\n",
      "Epoch 873/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.8215 - val_loss: 28.4804\n",
      "Epoch 874/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 20.6701 - val_loss: 32.4787\n",
      "Epoch 875/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.9258 - val_loss: 34.2843\n",
      "Epoch 876/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.6362 - val_loss: 38.7367\n",
      "Epoch 877/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.9249 - val_loss: 36.0752\n",
      "Epoch 878/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.1768 - val_loss: 33.6197\n",
      "Epoch 879/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.4477 - val_loss: 34.3155\n",
      "Epoch 880/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.6824 - val_loss: 34.5349\n",
      "Epoch 881/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.1821 - val_loss: 36.6461\n",
      "Epoch 882/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.0303 - val_loss: 39.0645\n",
      "Epoch 883/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.6089 - val_loss: 35.4326\n",
      "Epoch 884/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 13.7166 - val_loss: 38.4611\n",
      "Epoch 885/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.5916 - val_loss: 34.6410\n",
      "Epoch 886/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.2606 - val_loss: 33.2010\n",
      "Epoch 887/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.1395 - val_loss: 33.8648\n",
      "Epoch 888/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.2981 - val_loss: 35.1844\n",
      "Epoch 889/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.7797 - val_loss: 32.6268\n",
      "Epoch 890/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.6608 - val_loss: 29.7844\n",
      "Epoch 891/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.2811 - val_loss: 31.6179\n",
      "Epoch 892/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.5319 - val_loss: 33.1452\n",
      "Epoch 893/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.9393 - val_loss: 32.6262\n",
      "Epoch 894/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.1990 - val_loss: 35.4344\n",
      "Epoch 895/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.9086 - val_loss: 34.0393\n",
      "Epoch 896/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.3540 - val_loss: 33.2233\n",
      "Epoch 897/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.2114 - val_loss: 36.4931\n",
      "Epoch 898/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 11.8696 - val_loss: 36.1139\n",
      "Epoch 899/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.3048 - val_loss: 33.3593\n",
      "Epoch 900/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.9332 - val_loss: 33.8686\n",
      "Epoch 901/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 15.5146 - val_loss: 32.7386\n",
      "Epoch 902/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 15.1087 - val_loss: 33.3459\n",
      "Epoch 903/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 14.8876 - val_loss: 32.7767\n",
      "Epoch 904/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 13.3055 - val_loss: 33.3554\n",
      "Epoch 905/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.8591 - val_loss: 31.0815\n",
      "Epoch 906/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.0343 - val_loss: 33.5060\n",
      "Epoch 907/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.8724 - val_loss: 32.4530\n",
      "Epoch 908/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.5496 - val_loss: 31.0311\n",
      "Epoch 909/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.6829 - val_loss: 32.4987\n",
      "Epoch 910/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.8864 - val_loss: 28.9083\n",
      "Epoch 911/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.3098 - val_loss: 30.6067\n",
      "Epoch 912/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.9245 - val_loss: 31.2357\n",
      "Epoch 913/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.2371 - val_loss: 35.3121\n",
      "Epoch 914/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 19.3266 - val_loss: 31.3757\n",
      "Epoch 915/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 17.8616 - val_loss: 33.2241\n",
      "Epoch 916/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.4053 - val_loss: 31.5267\n",
      "Epoch 917/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.5281 - val_loss: 33.9983\n",
      "Epoch 918/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9071 - val_loss: 32.5280\n",
      "Epoch 919/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.7986 - val_loss: 37.6507\n",
      "Epoch 920/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2637 - val_loss: 32.2252\n",
      "Epoch 921/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.3044 - val_loss: 28.9317\n",
      "Epoch 922/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.3777 - val_loss: 33.3623\n",
      "Epoch 923/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5879 - val_loss: 31.8262\n",
      "Epoch 924/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.4442 - val_loss: 29.2777\n",
      "Epoch 925/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.1362 - val_loss: 33.7553\n",
      "Epoch 926/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.8608 - val_loss: 31.5656\n",
      "Epoch 927/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.8693 - val_loss: 33.6748\n",
      "Epoch 928/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.9983 - val_loss: 34.9509\n",
      "Epoch 929/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.9222 - val_loss: 31.0665\n",
      "Epoch 930/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.4422 - val_loss: 31.3642\n",
      "Epoch 931/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6555 - val_loss: 32.3233\n",
      "Epoch 932/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 29.6670 - val_loss: 31.8326\n",
      "Epoch 933/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.7561 - val_loss: 31.2914\n",
      "Epoch 934/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.6129 - val_loss: 29.2907\n",
      "Epoch 935/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 18.3405 - val_loss: 32.0203\n",
      "Epoch 936/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.5968 - val_loss: 31.3345\n",
      "Epoch 937/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.8619 - val_loss: 31.2744\n",
      "Epoch 938/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4510 - val_loss: 31.5720\n",
      "Epoch 939/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 14.9114 - val_loss: 33.1474\n",
      "Epoch 940/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 18.0787 - val_loss: 35.6366\n",
      "Epoch 941/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.2304 - val_loss: 31.6842\n",
      "Epoch 942/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2243 - val_loss: 29.2707\n",
      "Epoch 943/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.1136 - val_loss: 34.7312\n",
      "Epoch 944/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.9446 - val_loss: 32.9659\n",
      "Epoch 945/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.8970 - val_loss: 33.2988\n",
      "Epoch 946/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.6105 - val_loss: 31.1912\n",
      "Epoch 947/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.3993 - val_loss: 31.4497\n",
      "Epoch 948/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 15.7851 - val_loss: 31.6363\n",
      "Epoch 949/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 14.4722 - val_loss: 31.6126\n",
      "Epoch 950/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.4639 - val_loss: 31.0715\n",
      "Epoch 951/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.7706 - val_loss: 38.4126\n",
      "Epoch 952/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.7913 - val_loss: 33.7872\n",
      "Epoch 953/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.6837 - val_loss: 32.4377\n",
      "Epoch 954/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.4772 - val_loss: 31.9499\n",
      "Epoch 955/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.6037 - val_loss: 31.7342\n",
      "Epoch 956/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.3727 - val_loss: 32.3739\n",
      "Epoch 957/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.6996 - val_loss: 30.2065\n",
      "Epoch 958/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.7993 - val_loss: 34.7118\n",
      "Epoch 959/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.9883 - val_loss: 33.6087\n",
      "Epoch 960/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.3379 - val_loss: 28.9957\n",
      "Epoch 961/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.7058 - val_loss: 30.4642\n",
      "Epoch 962/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.0676 - val_loss: 33.9817\n",
      "Epoch 963/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.7011 - val_loss: 34.1916\n",
      "Epoch 964/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5284 - val_loss: 33.6556\n",
      "Epoch 965/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.3473 - val_loss: 30.8598\n",
      "Epoch 966/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.9234 - val_loss: 34.4867\n",
      "Epoch 967/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.1403 - val_loss: 33.0255\n",
      "Epoch 968/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.8999 - val_loss: 36.5649\n",
      "Epoch 969/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.5675 - val_loss: 34.6397\n",
      "Epoch 970/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.0476 - val_loss: 30.9980\n",
      "Epoch 971/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.2809 - val_loss: 33.4966\n",
      "Epoch 972/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.3330 - val_loss: 37.0832\n",
      "Epoch 973/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.0160 - val_loss: 33.7490\n",
      "Epoch 974/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.2671 - val_loss: 32.8930\n",
      "Epoch 975/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.0330 - val_loss: 38.5201\n",
      "Epoch 976/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.5598 - val_loss: 35.3064\n",
      "Epoch 977/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.8973 - val_loss: 34.0603\n",
      "Epoch 978/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.5381 - val_loss: 33.6068\n",
      "Epoch 979/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.5098 - val_loss: 33.2952\n",
      "Epoch 980/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.5191 - val_loss: 35.5045\n",
      "Epoch 981/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.5702 - val_loss: 32.6316\n",
      "Epoch 982/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.1551 - val_loss: 34.1285\n",
      "Epoch 983/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.6570 - val_loss: 30.5041\n",
      "Epoch 984/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.8378 - val_loss: 35.0513\n",
      "Epoch 985/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.5264 - val_loss: 32.2121\n",
      "Epoch 986/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.9020 - val_loss: 31.5501\n",
      "Epoch 987/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2650 - val_loss: 32.6096\n",
      "Epoch 988/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.9170 - val_loss: 31.9909\n",
      "Epoch 989/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.3729 - val_loss: 30.5828\n",
      "Epoch 990/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.0635 - val_loss: 34.5215\n",
      "Epoch 991/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.4970 - val_loss: 32.0388\n",
      "Epoch 992/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.3049 - val_loss: 34.9452\n",
      "Epoch 993/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.9858 - val_loss: 35.5003\n",
      "Epoch 994/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.9077 - val_loss: 35.2066\n",
      "Epoch 995/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.7549 - val_loss: 35.0518\n",
      "Epoch 996/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9467 - val_loss: 33.6777\n",
      "Epoch 997/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.6908 - val_loss: 32.1725\n",
      "Epoch 998/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.4625 - val_loss: 35.8749\n",
      "Epoch 999/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.4067 - val_loss: 33.8250\n",
      "Epoch 1000/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.9683 - val_loss: 33.7023\n",
      "Epoch 1001/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.5769 - val_loss: 35.1727\n",
      "Epoch 1002/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.6099 - val_loss: 33.0193\n",
      "Epoch 1003/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.1707 - val_loss: 32.9383\n",
      "Epoch 1004/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 13.1254 - val_loss: 37.3174\n",
      "Epoch 1005/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 13.1850 - val_loss: 34.8000\n",
      "Epoch 1006/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.5510 - val_loss: 37.2204\n",
      "Epoch 1007/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.3791 - val_loss: 35.5737\n",
      "Epoch 1008/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.8905 - val_loss: 33.8677\n",
      "Epoch 1009/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.2467 - val_loss: 33.3826\n",
      "Epoch 1010/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.9830 - val_loss: 32.3898\n",
      "Epoch 1011/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.5526 - val_loss: 33.2893\n",
      "Epoch 1012/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.3166 - val_loss: 34.3685\n",
      "Epoch 1013/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.4074 - val_loss: 32.4260\n",
      "Epoch 1014/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.4364 - val_loss: 32.5797\n",
      "Epoch 1015/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.9644 - val_loss: 32.7071\n",
      "Epoch 1016/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.3777 - val_loss: 29.1595\n",
      "Epoch 1017/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.6637 - val_loss: 29.9952\n",
      "Epoch 1018/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.1562 - val_loss: 31.5948\n",
      "Epoch 1019/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.1350 - val_loss: 30.4783\n",
      "Epoch 1020/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.3330 - val_loss: 31.1272\n",
      "Epoch 1021/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 21.3773 - val_loss: 29.9602\n",
      "Epoch 1022/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.6015 - val_loss: 30.1423\n",
      "Epoch 1023/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.0057 - val_loss: 31.9807\n",
      "Epoch 1024/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.9627 - val_loss: 31.9451\n",
      "Epoch 1025/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.4802 - val_loss: 29.2488\n",
      "Epoch 1026/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.0307 - val_loss: 31.5879\n",
      "Epoch 1027/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.0839 - val_loss: 31.2226\n",
      "Epoch 1028/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 12.3233 - val_loss: 33.4704\n",
      "Epoch 1029/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.4255 - val_loss: 31.8317\n",
      "Epoch 1030/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.8865 - val_loss: 32.5918\n",
      "Epoch 1031/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.9152 - val_loss: 32.0684\n",
      "Epoch 1032/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.1520 - val_loss: 32.4660\n",
      "Epoch 1033/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.2533 - val_loss: 32.7862\n",
      "Epoch 1034/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.9533 - val_loss: 33.7804\n",
      "Epoch 1035/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.6918 - val_loss: 34.1466\n",
      "Epoch 1036/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.1255 - val_loss: 33.4439\n",
      "Epoch 1037/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 17.4940 - val_loss: 33.4855\n",
      "Epoch 1038/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.2118 - val_loss: 34.3443\n",
      "Epoch 1039/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 12.0535 - val_loss: 34.2376\n",
      "Epoch 1040/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 13.0369 - val_loss: 34.2817\n",
      "Epoch 1041/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.1422 - val_loss: 33.3200\n",
      "Epoch 1042/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.0379 - val_loss: 33.1148\n",
      "Epoch 1043/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.3469 - val_loss: 31.3789\n",
      "Epoch 1044/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.2421 - val_loss: 31.4393\n",
      "Epoch 1045/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.2684 - val_loss: 34.1902\n",
      "Epoch 1046/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.2600 - val_loss: 32.3203\n",
      "Epoch 1047/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.7336 - val_loss: 31.4359\n",
      "Epoch 1048/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.8913 - val_loss: 31.5448\n",
      "Epoch 1049/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 14.0435 - val_loss: 32.9717\n",
      "Epoch 1050/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.0646 - val_loss: 35.5907\n",
      "Epoch 1051/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.5885 - val_loss: 33.9681\n",
      "Epoch 1052/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.5630 - val_loss: 31.7127\n",
      "Epoch 1053/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.6081 - val_loss: 33.7182\n",
      "Epoch 1054/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.4102 - val_loss: 32.7600\n",
      "Epoch 1055/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.1778 - val_loss: 33.5743\n",
      "Epoch 1056/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 12.8108 - val_loss: 31.9186\n",
      "Epoch 1057/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 11.6731 - val_loss: 33.7150\n",
      "Epoch 1058/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12.9078 - val_loss: 33.1700\n",
      "Epoch 1059/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 13.4656 - val_loss: 32.3317\n",
      "Epoch 1060/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 14.0183 - val_loss: 32.8195\n",
      "Epoch 1061/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 15.6885 - val_loss: 34.0645\n",
      "Epoch 1062/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 14.5444 - val_loss: 32.5751\n",
      "Epoch 1063/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.3474 - val_loss: 30.2741\n",
      "Epoch 1064/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.6334 - val_loss: 32.1532\n",
      "Epoch 1065/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.9996 - val_loss: 30.1272\n",
      "Epoch 1066/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.4492 - val_loss: 32.3835\n",
      "Epoch 1067/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.4368 - val_loss: 34.2250\n",
      "Epoch 1068/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 13.1043 - val_loss: 32.1092\n",
      "Epoch 1069/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 15.9263 - val_loss: 33.4867\n",
      "Epoch 1070/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.4037 - val_loss: 32.8728\n",
      "Epoch 1071/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.4811 - val_loss: 34.2472\n",
      "Epoch 1072/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.1063 - val_loss: 32.2969\n",
      "Epoch 1073/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.2503 - val_loss: 33.7888\n",
      "Epoch 1074/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.2625 - val_loss: 33.3023\n",
      "Epoch 1075/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.4031 - val_loss: 33.5567\n",
      "Epoch 1076/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.8225 - val_loss: 37.7191\n",
      "Epoch 1077/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.8836 - val_loss: 36.5227\n",
      "Epoch 1078/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.2830 - val_loss: 38.3263\n",
      "Epoch 1079/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.4570 - val_loss: 35.1984\n",
      "Epoch 1080/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.0383 - val_loss: 32.2664\n",
      "Epoch 1081/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.0678 - val_loss: 34.0976\n",
      "Epoch 1082/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.2759 - val_loss: 32.1734\n",
      "Epoch 1083/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.2801 - val_loss: 34.9913\n",
      "Epoch 1084/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 13.9396 - val_loss: 33.8949\n",
      "Epoch 1085/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.6865 - val_loss: 33.1929\n",
      "Epoch 1086/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.2984 - val_loss: 32.9009\n",
      "Epoch 1087/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.8656 - val_loss: 30.3964\n",
      "Epoch 1088/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.5802 - val_loss: 34.0491\n",
      "Epoch 1089/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.2132 - val_loss: 32.3151\n",
      "Epoch 1090/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.9281 - val_loss: 32.5693\n",
      "Epoch 1091/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.8863 - val_loss: 30.9577\n",
      "Epoch 1092/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.9466 - val_loss: 32.2813\n",
      "Epoch 1093/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 14.3472 - val_loss: 33.2831\n",
      "Epoch 1094/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.1763 - val_loss: 32.7397\n",
      "Epoch 1095/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.0442 - val_loss: 31.9378\n",
      "Epoch 1096/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.8800 - val_loss: 32.4225\n",
      "Epoch 1097/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.4641 - val_loss: 34.5807\n",
      "Epoch 1098/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6016 - val_loss: 32.9054\n",
      "Epoch 1099/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 32.8591 - val_loss: 34.0741\n",
      "Epoch 1100/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 24.7153 - val_loss: 35.5434\n",
      "Epoch 1101/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.8100 - val_loss: 31.9461\n",
      "Epoch 1102/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.0423 - val_loss: 33.9437\n",
      "Epoch 1103/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.9520 - val_loss: 32.8092\n",
      "Epoch 1104/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.4041 - val_loss: 30.6506\n",
      "Epoch 1105/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.8596 - val_loss: 32.4344\n",
      "Epoch 1106/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.1030 - val_loss: 32.8132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1107/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.1609 - val_loss: 31.0473\n",
      "Epoch 1108/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.6702 - val_loss: 31.7404\n",
      "Epoch 1109/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.5465 - val_loss: 31.5931\n",
      "Epoch 1110/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.5709 - val_loss: 34.2548\n",
      "Epoch 1111/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.6330 - val_loss: 31.6444\n",
      "Epoch 1112/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.7688 - val_loss: 30.3822\n",
      "Epoch 1113/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.1056 - val_loss: 32.5012\n",
      "Epoch 1114/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.7727 - val_loss: 33.2439\n",
      "Epoch 1115/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.3980 - val_loss: 30.5492\n",
      "Epoch 1116/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.8744 - val_loss: 34.2093\n",
      "Epoch 1117/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.1673 - val_loss: 32.8025\n",
      "Epoch 1118/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.4356 - val_loss: 31.8790\n",
      "Epoch 1119/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.5490 - val_loss: 33.4842\n",
      "Epoch 1120/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.2823 - val_loss: 35.4623\n",
      "Epoch 1121/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.1376 - val_loss: 35.3477\n",
      "Epoch 1122/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.8748 - val_loss: 33.2911\n",
      "Epoch 1123/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.9689 - val_loss: 33.8696\n",
      "Epoch 1124/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.8137 - val_loss: 32.6288\n",
      "Epoch 1125/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 19.4349 - val_loss: 34.1907\n",
      "Epoch 1126/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.4529 - val_loss: 33.8904\n",
      "Epoch 1127/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.6847 - val_loss: 34.7751\n",
      "Epoch 1128/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.7407 - val_loss: 32.6460\n",
      "Epoch 1129/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.7238 - val_loss: 34.0378\n",
      "Epoch 1130/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.0575 - val_loss: 33.6164\n",
      "Epoch 1131/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.5409 - val_loss: 31.6414\n",
      "Epoch 1132/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.2677 - val_loss: 32.8236\n",
      "Epoch 1133/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.5631 - val_loss: 33.3598\n",
      "Epoch 1134/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.6684 - val_loss: 29.2967\n",
      "Epoch 1135/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.9698 - val_loss: 31.5331\n",
      "Epoch 1136/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.5245 - val_loss: 31.4934\n",
      "Epoch 1137/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.6868 - val_loss: 31.1199\n",
      "Epoch 1138/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.6121 - val_loss: 33.2231\n",
      "Epoch 1139/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.3155 - val_loss: 32.8759\n",
      "Epoch 1140/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.6287 - val_loss: 34.8319\n",
      "Epoch 1141/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.9994 - val_loss: 31.2257\n",
      "Epoch 1142/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.9243 - val_loss: 30.5777\n",
      "Epoch 1143/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.8228 - val_loss: 33.4604\n",
      "Epoch 1144/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.1615 - val_loss: 33.9694\n",
      "Epoch 1145/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.2929 - val_loss: 33.4263\n",
      "Epoch 1146/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.8125 - val_loss: 33.8629\n",
      "Epoch 1147/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.4005 - val_loss: 32.8145\n",
      "Epoch 1148/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.7163 - val_loss: 32.1396\n",
      "Epoch 1149/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.7375 - val_loss: 33.6075\n",
      "Epoch 1150/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.8583 - val_loss: 33.6000\n",
      "Epoch 1151/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.3113 - val_loss: 31.2213\n",
      "Epoch 1152/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.1468 - val_loss: 32.3588\n",
      "Epoch 1153/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.1349 - val_loss: 33.0526\n",
      "Epoch 1154/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.5822 - val_loss: 33.4288\n",
      "Epoch 1155/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.6176 - val_loss: 33.2935\n",
      "Epoch 1156/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.5996 - val_loss: 34.5443\n",
      "Epoch 1157/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.3637 - val_loss: 32.4815\n",
      "Epoch 1158/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.3801 - val_loss: 32.3894\n",
      "Epoch 1159/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.4881 - val_loss: 33.2720\n",
      "Epoch 1160/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.2560 - val_loss: 34.3943\n",
      "Epoch 1161/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.8998 - val_loss: 33.9243\n",
      "Epoch 1162/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.9656 - val_loss: 32.4707\n",
      "Epoch 1163/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.2031 - val_loss: 31.3233\n",
      "Epoch 1164/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.1779 - val_loss: 31.6285\n",
      "Epoch 1165/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.3733 - val_loss: 32.7568\n",
      "Epoch 1166/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.5683 - val_loss: 32.2517\n",
      "Epoch 1167/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.0356 - val_loss: 34.1192\n",
      "Epoch 1168/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.9993 - val_loss: 31.9888\n",
      "Epoch 1169/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.3735 - val_loss: 30.9812\n",
      "Epoch 1170/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.8065 - val_loss: 31.2624\n",
      "Epoch 1171/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.2613 - val_loss: 32.1893\n",
      "Epoch 1172/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0055 - val_loss: 30.6502\n",
      "Epoch 1173/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.9133 - val_loss: 30.1057\n",
      "Epoch 1174/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.8954 - val_loss: 32.0533\n",
      "Epoch 1175/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.4326 - val_loss: 30.4361\n",
      "Epoch 1176/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.8704 - val_loss: 33.4680\n",
      "Epoch 1177/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.7837 - val_loss: 32.9151\n",
      "Epoch 1178/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.7883 - val_loss: 31.1324\n",
      "Epoch 1179/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.6312 - val_loss: 30.9938\n",
      "Epoch 1180/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.1393 - val_loss: 30.6125\n",
      "Epoch 1181/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.7210 - val_loss: 31.6418\n",
      "Epoch 1182/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.4600 - val_loss: 32.5232\n",
      "Epoch 1183/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.8520 - val_loss: 30.5234\n",
      "Epoch 1184/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.5493 - val_loss: 32.0476\n",
      "Epoch 1185/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.9963 - val_loss: 31.0746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1186/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.2031 - val_loss: 34.5891\n",
      "Epoch 1187/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.8460 - val_loss: 30.6228\n",
      "Epoch 1188/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.1509 - val_loss: 32.0985\n",
      "Epoch 1189/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.2020 - val_loss: 32.1999\n",
      "Epoch 1190/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.8605 - val_loss: 32.2866\n",
      "Epoch 1191/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.7294 - val_loss: 31.2376\n",
      "Epoch 1192/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.1081 - val_loss: 33.1247\n",
      "Epoch 1193/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.1944 - val_loss: 31.9296\n",
      "Epoch 1194/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.1400 - val_loss: 30.5891\n",
      "Epoch 1195/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.3138 - val_loss: 34.5379\n",
      "Epoch 1196/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 14.0245 - val_loss: 34.2293\n",
      "Epoch 1197/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.0805 - val_loss: 31.7921\n",
      "Epoch 1198/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.2437 - val_loss: 33.2586\n",
      "Epoch 1199/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.3414 - val_loss: 31.4047\n",
      "Epoch 1200/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1576 - val_loss: 31.1555\n",
      "Epoch 1201/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 11.7508 - val_loss: 31.1625\n",
      "Epoch 1202/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 12.3905 - val_loss: 31.6331\n",
      "Epoch 1203/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.4497 - val_loss: 29.8502\n",
      "Epoch 1204/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.9441 - val_loss: 32.0965\n",
      "Epoch 1205/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.4581 - val_loss: 31.3722\n",
      "Epoch 1206/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.9112 - val_loss: 31.3277\n",
      "Epoch 1207/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.8307 - val_loss: 32.8569\n",
      "Epoch 1208/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.1287 - val_loss: 32.9171\n",
      "Epoch 1209/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.0278 - val_loss: 32.9062\n",
      "Epoch 1210/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.3858 - val_loss: 32.7597\n",
      "Epoch 1211/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.6208 - val_loss: 31.1740\n",
      "Epoch 1212/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.3744 - val_loss: 31.7679\n",
      "Epoch 1213/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.7625 - val_loss: 30.9058\n",
      "Epoch 1214/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.7252 - val_loss: 33.3762\n",
      "Epoch 1215/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.1278 - val_loss: 33.9386\n",
      "Epoch 1216/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.2692 - val_loss: 32.0244\n",
      "Epoch 1217/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.0957 - val_loss: 33.8594\n",
      "Epoch 1218/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.3078 - val_loss: 32.7123\n",
      "Epoch 1219/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.8505 - val_loss: 31.2811\n",
      "Epoch 1220/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.8515 - val_loss: 32.2077\n",
      "Epoch 1221/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.3790 - val_loss: 31.3585\n",
      "Epoch 1222/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.8558 - val_loss: 32.2339\n",
      "Epoch 1223/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.6794 - val_loss: 31.2528\n",
      "Epoch 1224/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 11.1915 - val_loss: 30.5292\n",
      "Epoch 1225/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.4826 - val_loss: 31.5532\n",
      "Epoch 1226/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 9.8405 - val_loss: 31.2479\n",
      "Epoch 1227/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.3467 - val_loss: 30.9310\n",
      "Epoch 1228/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 13.5006 - val_loss: 32.2580\n",
      "Epoch 1229/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.0758 - val_loss: 30.7082\n",
      "Epoch 1230/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 10.6595 - val_loss: 32.6454\n",
      "Epoch 1231/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 8.5732 - val_loss: 31.4387\n",
      "Epoch 1232/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.1151 - val_loss: 31.3666\n",
      "Epoch 1233/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.2096 - val_loss: 31.4589\n",
      "Epoch 1234/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 10.6581 - val_loss: 32.6274\n",
      "Epoch 1235/10000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 12.9626Restoring model weights from the end of the best epoch: 735.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 10.9962 - val_loss: 30.2329\n",
      "Epoch 1235: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = lstm_model(reshaped_train, \n",
    "                                    reshaped_target, \n",
    "                                    want_verbose=1, \n",
    "                                    seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f0aad5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cb69c9b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>45.833691</td>\n",
       "      <td>45.881226</td>\n",
       "      <td>45.871128</td>\n",
       "      <td>45.886814</td>\n",
       "      <td>45.873013</td>\n",
       "      <td>45.909546</td>\n",
       "      <td>45.930824</td>\n",
       "      <td>46.013889</td>\n",
       "      <td>45.956223</td>\n",
       "      <td>45.974556</td>\n",
       "      <td>46.00737</td>\n",
       "      <td>46.14761</td>\n",
       "      <td>45.900936</td>\n",
       "      <td>46.225437</td>\n",
       "      <td>46.401173</td>\n",
       "      <td>46.192799</td>\n",
       "      <td>46.302208</td>\n",
       "      <td>46.535973</td>\n",
       "      <td>46.530994</td>\n",
       "      <td>47.240822</td>\n",
       "      <td>47.337921</td>\n",
       "      <td>49.472263</td>\n",
       "      <td>51.153061</td>\n",
       "      <td>51.199509</td>\n",
       "      <td>51.262581</td>\n",
       "      <td>51.139694</td>\n",
       "      <td>51.141106</td>\n",
       "      <td>47.461563</td>\n",
       "      <td>51.048008</td>\n",
       "      <td>48.689045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>53.235</td>\n",
       "      <td>59.29</td>\n",
       "      <td>54.875</td>\n",
       "      <td>57.52</td>\n",
       "      <td>49.573</td>\n",
       "      <td>40.698</td>\n",
       "      <td>47.195</td>\n",
       "      <td>43.527</td>\n",
       "      <td>45.488</td>\n",
       "      <td>44.96</td>\n",
       "      <td>36.721</td>\n",
       "      <td>54.463</td>\n",
       "      <td>51.462</td>\n",
       "      <td>58.854</td>\n",
       "      <td>53.94</td>\n",
       "      <td>51.514</td>\n",
       "      <td>42.635</td>\n",
       "      <td>40.371</td>\n",
       "      <td>48.99</td>\n",
       "      <td>44.726</td>\n",
       "      <td>44.491</td>\n",
       "      <td>43.901</td>\n",
       "      <td>55.019</td>\n",
       "      <td>50.942</td>\n",
       "      <td>63.992</td>\n",
       "      <td>64.127</td>\n",
       "      <td>60.822</td>\n",
       "      <td>65.182</td>\n",
       "      <td>51.282</td>\n",
       "      <td>43.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>7.40131</td>\n",
       "      <td>13.408775</td>\n",
       "      <td>9.003872</td>\n",
       "      <td>11.633186</td>\n",
       "      <td>3.699989</td>\n",
       "      <td>5.211544</td>\n",
       "      <td>1.264175</td>\n",
       "      <td>2.486889</td>\n",
       "      <td>0.468224</td>\n",
       "      <td>1.014557</td>\n",
       "      <td>9.286369</td>\n",
       "      <td>8.315392</td>\n",
       "      <td>5.561066</td>\n",
       "      <td>12.628563</td>\n",
       "      <td>7.538826</td>\n",
       "      <td>5.321201</td>\n",
       "      <td>3.66721</td>\n",
       "      <td>6.164974</td>\n",
       "      <td>2.459007</td>\n",
       "      <td>2.51482</td>\n",
       "      <td>2.84692</td>\n",
       "      <td>5.571262</td>\n",
       "      <td>3.86594</td>\n",
       "      <td>0.257507</td>\n",
       "      <td>12.72942</td>\n",
       "      <td>12.987305</td>\n",
       "      <td>9.680893</td>\n",
       "      <td>17.720436</td>\n",
       "      <td>0.233994</td>\n",
       "      <td>5.135044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1          2          3          4          5   \\\n",
       "Month         Month-1    Month-2    Month-3    Month-4    Month-5    Month-6   \n",
       "Prediction  45.833691  45.881226  45.871128  45.886814  45.873013  45.909546   \n",
       "Target         53.235      59.29     54.875      57.52     49.573     40.698   \n",
       "Error         7.40131  13.408775   9.003872  11.633186   3.699989   5.211544   \n",
       "\n",
       "                   6          7          8          9         10        11  \\\n",
       "Month         Month-7    Month-8    Month-9   Month-10  Month-11  Month-12   \n",
       "Prediction  45.930824  46.013889  45.956223  45.974556  46.00737  46.14761   \n",
       "Target         47.195     43.527     45.488      44.96    36.721    54.463   \n",
       "Error        1.264175   2.486889   0.468224   1.014557  9.286369  8.315392   \n",
       "\n",
       "                   12         13         14         15         16         17  \\\n",
       "Month        Month-13   Month-14   Month-15   Month-16   Month-17   Month-18   \n",
       "Prediction  45.900936  46.225437  46.401173  46.192799  46.302208  46.535973   \n",
       "Target         51.462     58.854      53.94     51.514     42.635     40.371   \n",
       "Error        5.561066  12.628563   7.538826   5.321201    3.66721   6.164974   \n",
       "\n",
       "                   18         19         20         21         22         23  \\\n",
       "Month        Month-19   Month-20   Month-21   Month-22   Month-23   Month-24   \n",
       "Prediction  46.530994  47.240822  47.337921  49.472263  51.153061  51.199509   \n",
       "Target          48.99     44.726     44.491     43.901     55.019     50.942   \n",
       "Error        2.459007    2.51482    2.84692   5.571262    3.86594   0.257507   \n",
       "\n",
       "                   24         25         26         27         28         29  \n",
       "Month        Month-25   Month-26   Month-27   Month-28   Month-29   Month-30  \n",
       "Prediction  51.262581  51.139694  51.141106  47.461563  51.048008  48.689045  \n",
       "Target         63.992     64.127     60.822     65.182     51.282     43.554  \n",
       "Error        12.72942  12.987305   9.680893  17.720436   0.233994   5.135044  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            reshaped_test, \n",
    "                                            reshaped_test_target, \n",
    "                                            start_index)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6b1c27bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.335955"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.119618155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c506c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0ca218d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m errors, mae, mape \u001b[38;5;241m=\u001b[39m year_mae_mape_calculator(trained_model, \n\u001b[1;32m      2\u001b[0m                                              test_input, \n\u001b[0;32m----> 3\u001b[0m                                              \u001b[43mtest_target\u001b[49m, \n\u001b[1;32m      4\u001b[0m                                              start_index)\n\u001b[1;32m      5\u001b[0m display(errors)\n\u001b[1;32m      6\u001b[0m display(mae)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_target' is not defined"
     ]
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             start_index)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b2bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
