{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d613198",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Mato Grosso - Consumo de Cimento (t)'\n",
    "start_index = 0\n",
    "split_index = 191 #Referente aos 230 anos de input \n",
    "window_size = 36\n",
    "train_split = split_index + 1 - 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc652c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Mato Grosso - Produção de Cimento (t)</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Mato Grosso - Desemprego</th>\n",
       "      <th>Mato Grosso - IDH</th>\n",
       "      <th>Mato Grosso - PIB - Estadual</th>\n",
       "      <th>Mato Grosso - PIB - Construção Civil</th>\n",
       "      <th>Mato Grosso - PIB - Per Capita</th>\n",
       "      <th>Mato Grosso - PIB - Preços de Mercado</th>\n",
       "      <th>Mato Grosso - value</th>\n",
       "      <th>Mato Grosso - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>50.917240</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>8.297178</td>\n",
       "      <td>0.745147</td>\n",
       "      <td>6.084564e+07</td>\n",
       "      <td>2.670588e+06</td>\n",
       "      <td>16.831332</td>\n",
       "      <td>5.118946e+07</td>\n",
       "      <td>0.331800</td>\n",
       "      <td>47.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>50.851586</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>8.291317</td>\n",
       "      <td>0.745308</td>\n",
       "      <td>6.092768e+07</td>\n",
       "      <td>2.672688e+06</td>\n",
       "      <td>16.835967</td>\n",
       "      <td>5.121614e+07</td>\n",
       "      <td>0.333615</td>\n",
       "      <td>45.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>50.970549</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>8.285457</td>\n",
       "      <td>0.745469</td>\n",
       "      <td>6.100973e+07</td>\n",
       "      <td>2.674788e+06</td>\n",
       "      <td>16.840602</td>\n",
       "      <td>5.124282e+07</td>\n",
       "      <td>0.334864</td>\n",
       "      <td>44.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>51.049978</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>8.279596</td>\n",
       "      <td>0.745630</td>\n",
       "      <td>6.109177e+07</td>\n",
       "      <td>2.676888e+06</td>\n",
       "      <td>16.845237</td>\n",
       "      <td>5.126950e+07</td>\n",
       "      <td>0.336048</td>\n",
       "      <td>45.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>51.567529</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>8.273735</td>\n",
       "      <td>0.745791</td>\n",
       "      <td>6.117381e+07</td>\n",
       "      <td>2.678988e+06</td>\n",
       "      <td>16.849872</td>\n",
       "      <td>5.129619e+07</td>\n",
       "      <td>0.336447</td>\n",
       "      <td>56.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>119.544326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600607</td>\n",
       "      <td>192.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>118.223448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598965</td>\n",
       "      <td>183.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>117.524152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.596866</td>\n",
       "      <td>180.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>116.430559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594246</td>\n",
       "      <td>161.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>116.846011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591053</td>\n",
       "      <td>161.683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Mato Grosso - Produção de Cimento (t)  \\\n",
       "0       2003-1                              50.917240   \n",
       "1       2003-2                              50.851586   \n",
       "2       2003-3                              50.970549   \n",
       "3       2003-4                              51.049978   \n",
       "4       2003-5                              51.567529   \n",
       "..         ...                                    ...   \n",
       "235     2022-8                             119.544326   \n",
       "236     2022-9                             118.223448   \n",
       "237    2022-10                             117.524152   \n",
       "238    2022-11                             116.430559   \n",
       "239    2022-12                             116.846011   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     Mato Grosso - Desemprego  Mato Grosso - IDH  \\\n",
       "0                    8.297178           0.745147   \n",
       "1                    8.291317           0.745308   \n",
       "2                    8.285457           0.745469   \n",
       "3                    8.279596           0.745630   \n",
       "4                    8.273735           0.745791   \n",
       "..                        ...                ...   \n",
       "235                       NaN                NaN   \n",
       "236                       NaN                NaN   \n",
       "237                       NaN                NaN   \n",
       "238                       NaN                NaN   \n",
       "239                       NaN                NaN   \n",
       "\n",
       "     Mato Grosso - PIB - Estadual  Mato Grosso - PIB - Construção Civil  \\\n",
       "0                    6.084564e+07                          2.670588e+06   \n",
       "1                    6.092768e+07                          2.672688e+06   \n",
       "2                    6.100973e+07                          2.674788e+06   \n",
       "3                    6.109177e+07                          2.676888e+06   \n",
       "4                    6.117381e+07                          2.678988e+06   \n",
       "..                            ...                                   ...   \n",
       "235                           NaN                                   NaN   \n",
       "236                           NaN                                   NaN   \n",
       "237                           NaN                                   NaN   \n",
       "238                           NaN                                   NaN   \n",
       "239                           NaN                                   NaN   \n",
       "\n",
       "     Mato Grosso - PIB - Per Capita  Mato Grosso - PIB - Preços de Mercado  \\\n",
       "0                         16.831332                           5.118946e+07   \n",
       "1                         16.835967                           5.121614e+07   \n",
       "2                         16.840602                           5.124282e+07   \n",
       "3                         16.845237                           5.126950e+07   \n",
       "4                         16.849872                           5.129619e+07   \n",
       "..                              ...                                    ...   \n",
       "235                             NaN                                    NaN   \n",
       "236                             NaN                                    NaN   \n",
       "237                             NaN                                    NaN   \n",
       "238                             NaN                                    NaN   \n",
       "239                             NaN                                    NaN   \n",
       "\n",
       "     Mato Grosso - value  Mato Grosso - Consumo de Cimento (t)  \n",
       "0               0.331800                                47.470  \n",
       "1               0.333615                                45.387  \n",
       "2               0.334864                                44.907  \n",
       "3               0.336048                                45.467  \n",
       "4               0.336447                                56.246  \n",
       "..                   ...                                   ...  \n",
       "235             0.600607                               192.533  \n",
       "236             0.598965                               183.895  \n",
       "237             0.596866                               180.525  \n",
       "238             0.594246                               161.683  \n",
       "239             0.591053                               161.683  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_MT.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mato Grosso - Produção de Cimento (t)</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Mato Grosso - Desemprego</th>\n",
       "      <th>Mato Grosso - IDH</th>\n",
       "      <th>Mato Grosso - PIB - Estadual</th>\n",
       "      <th>Mato Grosso - PIB - Construção Civil</th>\n",
       "      <th>Mato Grosso - PIB - Per Capita</th>\n",
       "      <th>Mato Grosso - PIB - Preços de Mercado</th>\n",
       "      <th>Mato Grosso - value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001009</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.746035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.921240</td>\n",
       "      <td>0.965719</td>\n",
       "      <td>0.580259</td>\n",
       "      <td>0.936603</td>\n",
       "      <td>0.007992</td>\n",
       "      <td>0.011007</td>\n",
       "      <td>0.968938</td>\n",
       "      <td>0.996341</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.004513</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.195974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.873107</td>\n",
       "      <td>0.927412</td>\n",
       "      <td>0.926926</td>\n",
       "      <td>0.906543</td>\n",
       "      <td>0.015984</td>\n",
       "      <td>0.022015</td>\n",
       "      <td>0.948438</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.023609</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.017385</td>\n",
       "      <td>0.009026</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>0.204977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.851659</td>\n",
       "      <td>0.885588</td>\n",
       "      <td>0.549924</td>\n",
       "      <td>0.858675</td>\n",
       "      <td>0.023976</td>\n",
       "      <td>0.033022</td>\n",
       "      <td>0.928794</td>\n",
       "      <td>0.989023</td>\n",
       "      <td>0.035414</td>\n",
       "      <td>0.015460</td>\n",
       "      <td>0.026077</td>\n",
       "      <td>0.013539</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>0.213516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011003</td>\n",
       "      <td>0.823277</td>\n",
       "      <td>0.838034</td>\n",
       "      <td>0.807277</td>\n",
       "      <td>0.824839</td>\n",
       "      <td>0.031968</td>\n",
       "      <td>0.044030</td>\n",
       "      <td>0.970421</td>\n",
       "      <td>0.985364</td>\n",
       "      <td>0.047219</td>\n",
       "      <td>0.020613</td>\n",
       "      <td>0.034770</td>\n",
       "      <td>0.018052</td>\n",
       "      <td>0.021384</td>\n",
       "      <td>0.216392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.692912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030808</td>\n",
       "      <td>0.063780</td>\n",
       "      <td>0.381401</td>\n",
       "      <td>0.987600</td>\n",
       "      <td>0.828698</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.232479</td>\n",
       "      <td>0.768057</td>\n",
       "      <td>0.988798</td>\n",
       "      <td>0.647567</td>\n",
       "      <td>0.992324</td>\n",
       "      <td>0.990966</td>\n",
       "      <td>0.843701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.693045</td>\n",
       "      <td>0.029504</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>0.048101</td>\n",
       "      <td>0.466609</td>\n",
       "      <td>0.990700</td>\n",
       "      <td>0.823090</td>\n",
       "      <td>0.037761</td>\n",
       "      <td>0.228761</td>\n",
       "      <td>0.756242</td>\n",
       "      <td>0.987198</td>\n",
       "      <td>0.649169</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.989675</td>\n",
       "      <td>0.850718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.701363</td>\n",
       "      <td>0.043125</td>\n",
       "      <td>0.023074</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.530936</td>\n",
       "      <td>0.993800</td>\n",
       "      <td>0.817482</td>\n",
       "      <td>0.087044</td>\n",
       "      <td>0.225042</td>\n",
       "      <td>0.744427</td>\n",
       "      <td>0.985598</td>\n",
       "      <td>0.650771</td>\n",
       "      <td>0.990131</td>\n",
       "      <td>0.988384</td>\n",
       "      <td>0.864656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.702586</td>\n",
       "      <td>0.059756</td>\n",
       "      <td>0.017547</td>\n",
       "      <td>0.035186</td>\n",
       "      <td>0.611274</td>\n",
       "      <td>0.996900</td>\n",
       "      <td>0.811875</td>\n",
       "      <td>0.118264</td>\n",
       "      <td>0.221324</td>\n",
       "      <td>0.732612</td>\n",
       "      <td>0.983998</td>\n",
       "      <td>0.652373</td>\n",
       "      <td>0.989035</td>\n",
       "      <td>0.987094</td>\n",
       "      <td>0.878935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.707263</td>\n",
       "      <td>0.130775</td>\n",
       "      <td>0.013180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806267</td>\n",
       "      <td>0.138179</td>\n",
       "      <td>0.217605</td>\n",
       "      <td>0.720797</td>\n",
       "      <td>0.982397</td>\n",
       "      <td>0.653975</td>\n",
       "      <td>0.987938</td>\n",
       "      <td>0.985803</td>\n",
       "      <td>0.896508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mato Grosso - Produção de Cimento (t)  \\\n",
       "0                                 0.001009   \n",
       "1                                 0.000000   \n",
       "2                                 0.001828   \n",
       "3                                 0.003049   \n",
       "4                                 0.011003   \n",
       "..                                     ...   \n",
       "187                               0.692912   \n",
       "188                               0.693045   \n",
       "189                               0.701363   \n",
       "190                               0.702586   \n",
       "191                               0.707263   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            1.000000   \n",
       "1                                            0.921240   \n",
       "2                                            0.873107   \n",
       "3                                            0.851659   \n",
       "4                                            0.823277   \n",
       "..                                                ...   \n",
       "187                                          0.000000   \n",
       "188                                          0.029504   \n",
       "189                                          0.043125   \n",
       "190                                          0.059756   \n",
       "191                                          0.130775   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         1.000000        0.746035  1.000000   0.000000   \n",
       "1                         0.965719        0.580259  0.936603   0.007992   \n",
       "2                         0.927412        0.926926  0.906543   0.015984   \n",
       "3                         0.885588        0.549924  0.858675   0.023976   \n",
       "4                         0.838034        0.807277  0.824839   0.031968   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                       0.030808        0.063780  0.381401   0.987600   \n",
       "188                       0.027720        0.048101  0.466609   0.990700   \n",
       "189                       0.023074        0.016800  0.530936   0.993800   \n",
       "190                       0.017547        0.035186  0.611274   0.996900   \n",
       "191                       0.013180        0.000000  0.679742   1.000000   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                  0.000000   1.000000   \n",
       "1                                  0.011007   0.968938   \n",
       "2                                  0.022015   0.948438   \n",
       "3                                  0.033022   0.928794   \n",
       "4                                  0.044030   0.970421   \n",
       "..                                      ...        ...   \n",
       "187                                0.828698   0.005731   \n",
       "188                                0.823090   0.037761   \n",
       "189                                0.817482   0.087044   \n",
       "190                                0.811875   0.118264   \n",
       "191                                0.806267   0.138179   \n",
       "\n",
       "     Mato Grosso - Desemprego  Mato Grosso - IDH  \\\n",
       "0                    1.000000           0.000000   \n",
       "1                    0.996341           0.011805   \n",
       "2                    0.992682           0.023609   \n",
       "3                    0.989023           0.035414   \n",
       "4                    0.985364           0.047219   \n",
       "..                        ...                ...   \n",
       "187                  0.232479           0.768057   \n",
       "188                  0.228761           0.756242   \n",
       "189                  0.225042           0.744427   \n",
       "190                  0.221324           0.732612   \n",
       "191                  0.217605           0.720797   \n",
       "\n",
       "     Mato Grosso - PIB - Estadual  Mato Grosso - PIB - Construção Civil  \\\n",
       "0                        0.000000                              0.000000   \n",
       "1                        0.005153                              0.008692   \n",
       "2                        0.010307                              0.017385   \n",
       "3                        0.015460                              0.026077   \n",
       "4                        0.020613                              0.034770   \n",
       "..                            ...                                   ...   \n",
       "187                      0.988798                              0.647567   \n",
       "188                      0.987198                              0.649169   \n",
       "189                      0.985598                              0.650771   \n",
       "190                      0.983998                              0.652373   \n",
       "191                      0.982397                              0.653975   \n",
       "\n",
       "     Mato Grosso - PIB - Per Capita  Mato Grosso - PIB - Preços de Mercado  \\\n",
       "0                          0.000000                               0.000000   \n",
       "1                          0.004513                               0.005346   \n",
       "2                          0.009026                               0.010692   \n",
       "3                          0.013539                               0.016038   \n",
       "4                          0.018052                               0.021384   \n",
       "..                              ...                                    ...   \n",
       "187                        0.992324                               0.990966   \n",
       "188                        0.991228                               0.989675   \n",
       "189                        0.990131                               0.988384   \n",
       "190                        0.989035                               0.987094   \n",
       "191                        0.987938                               0.985803   \n",
       "\n",
       "     Mato Grosso - value  \n",
       "0               0.182887  \n",
       "1               0.195974  \n",
       "2               0.204977  \n",
       "3               0.213516  \n",
       "4               0.216392  \n",
       "..                   ...  \n",
       "187             0.843701  \n",
       "188             0.850718  \n",
       "189             0.864656  \n",
       "190             0.878935  \n",
       "191             0.896508  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "# mean = np.mean(input_data, axis=0)\n",
    "# stddev =  np.std(input_data, axis=0)\n",
    "# input_data = ((input_data - mean) /stddev)\n",
    "scaler=MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(input_data)\n",
    "input_data = pd.DataFrame(scaled_data, columns=input_data.columns)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      51.972\n",
       "1      40.729\n",
       "2      54.446\n",
       "3      51.788\n",
       "4      58.702\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Mato Grosso - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mato Grosso - Produção de Cimento (t)</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Mato Grosso - Desemprego</th>\n",
       "      <th>Mato Grosso - IDH</th>\n",
       "      <th>Mato Grosso - PIB - Estadual</th>\n",
       "      <th>Mato Grosso - PIB - Construção Civil</th>\n",
       "      <th>Mato Grosso - PIB - Per Capita</th>\n",
       "      <th>Mato Grosso - PIB - Preços de Mercado</th>\n",
       "      <th>Mato Grosso - value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001009</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.746035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.921240</td>\n",
       "      <td>0.965719</td>\n",
       "      <td>0.580259</td>\n",
       "      <td>0.936603</td>\n",
       "      <td>0.007992</td>\n",
       "      <td>0.011007</td>\n",
       "      <td>0.968938</td>\n",
       "      <td>0.996341</td>\n",
       "      <td>0.011805</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.004513</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.195974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.873107</td>\n",
       "      <td>0.927412</td>\n",
       "      <td>0.926926</td>\n",
       "      <td>0.906543</td>\n",
       "      <td>0.015984</td>\n",
       "      <td>0.022015</td>\n",
       "      <td>0.948438</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.023609</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.017385</td>\n",
       "      <td>0.009026</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>0.204977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.851659</td>\n",
       "      <td>0.885588</td>\n",
       "      <td>0.549924</td>\n",
       "      <td>0.858675</td>\n",
       "      <td>0.023976</td>\n",
       "      <td>0.033022</td>\n",
       "      <td>0.928794</td>\n",
       "      <td>0.989023</td>\n",
       "      <td>0.035414</td>\n",
       "      <td>0.015460</td>\n",
       "      <td>0.026077</td>\n",
       "      <td>0.013539</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>0.213516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011003</td>\n",
       "      <td>0.823277</td>\n",
       "      <td>0.838034</td>\n",
       "      <td>0.807277</td>\n",
       "      <td>0.824839</td>\n",
       "      <td>0.031968</td>\n",
       "      <td>0.044030</td>\n",
       "      <td>0.970421</td>\n",
       "      <td>0.985364</td>\n",
       "      <td>0.047219</td>\n",
       "      <td>0.020613</td>\n",
       "      <td>0.034770</td>\n",
       "      <td>0.018052</td>\n",
       "      <td>0.021384</td>\n",
       "      <td>0.216392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.588452</td>\n",
       "      <td>0.379453</td>\n",
       "      <td>0.024030</td>\n",
       "      <td>0.338208</td>\n",
       "      <td>0.039971</td>\n",
       "      <td>0.890665</td>\n",
       "      <td>0.956993</td>\n",
       "      <td>0.182507</td>\n",
       "      <td>0.621493</td>\n",
       "      <td>0.994318</td>\n",
       "      <td>0.973043</td>\n",
       "      <td>0.688394</td>\n",
       "      <td>0.986108</td>\n",
       "      <td>0.975683</td>\n",
       "      <td>0.938508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.582813</td>\n",
       "      <td>0.332832</td>\n",
       "      <td>0.021531</td>\n",
       "      <td>0.371581</td>\n",
       "      <td>0.027548</td>\n",
       "      <td>0.893949</td>\n",
       "      <td>0.953662</td>\n",
       "      <td>0.168812</td>\n",
       "      <td>0.596535</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>0.974495</td>\n",
       "      <td>0.684427</td>\n",
       "      <td>0.985875</td>\n",
       "      <td>0.976460</td>\n",
       "      <td>0.931775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.576827</td>\n",
       "      <td>0.313954</td>\n",
       "      <td>0.019385</td>\n",
       "      <td>0.365349</td>\n",
       "      <td>0.037038</td>\n",
       "      <td>0.897232</td>\n",
       "      <td>0.950331</td>\n",
       "      <td>0.152959</td>\n",
       "      <td>0.571578</td>\n",
       "      <td>0.982954</td>\n",
       "      <td>0.975947</td>\n",
       "      <td>0.680460</td>\n",
       "      <td>0.985641</td>\n",
       "      <td>0.977238</td>\n",
       "      <td>0.924689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.568447</td>\n",
       "      <td>0.294856</td>\n",
       "      <td>0.017671</td>\n",
       "      <td>0.404993</td>\n",
       "      <td>0.070841</td>\n",
       "      <td>0.900516</td>\n",
       "      <td>0.947000</td>\n",
       "      <td>0.137613</td>\n",
       "      <td>0.546620</td>\n",
       "      <td>0.977272</td>\n",
       "      <td>0.977399</td>\n",
       "      <td>0.676493</td>\n",
       "      <td>0.985408</td>\n",
       "      <td>0.978015</td>\n",
       "      <td>0.918022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.577480</td>\n",
       "      <td>0.308016</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.471771</td>\n",
       "      <td>0.077013</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>0.943668</td>\n",
       "      <td>0.163171</td>\n",
       "      <td>0.521662</td>\n",
       "      <td>0.971590</td>\n",
       "      <td>0.978852</td>\n",
       "      <td>0.672526</td>\n",
       "      <td>0.985174</td>\n",
       "      <td>0.978793</td>\n",
       "      <td>0.911047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mato Grosso - Produção de Cimento (t)  \\\n",
       "0                                 0.001009   \n",
       "1                                 0.000000   \n",
       "2                                 0.001828   \n",
       "3                                 0.003049   \n",
       "4                                 0.011003   \n",
       "..                                     ...   \n",
       "157                               0.588452   \n",
       "158                               0.582813   \n",
       "159                               0.576827   \n",
       "160                               0.568447   \n",
       "161                               0.577480   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            1.000000   \n",
       "1                                            0.921240   \n",
       "2                                            0.873107   \n",
       "3                                            0.851659   \n",
       "4                                            0.823277   \n",
       "..                                                ...   \n",
       "157                                          0.379453   \n",
       "158                                          0.332832   \n",
       "159                                          0.313954   \n",
       "160                                          0.294856   \n",
       "161                                          0.308016   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         1.000000        0.746035  1.000000   0.000000   \n",
       "1                         0.965719        0.580259  0.936603   0.007992   \n",
       "2                         0.927412        0.926926  0.906543   0.015984   \n",
       "3                         0.885588        0.549924  0.858675   0.023976   \n",
       "4                         0.838034        0.807277  0.824839   0.031968   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                       0.024030        0.338208  0.039971   0.890665   \n",
       "158                       0.021531        0.371581  0.027548   0.893949   \n",
       "159                       0.019385        0.365349  0.037038   0.897232   \n",
       "160                       0.017671        0.404993  0.070841   0.900516   \n",
       "161                       0.015845        0.471771  0.077013   0.903800   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                  0.000000   1.000000   \n",
       "1                                  0.011007   0.968938   \n",
       "2                                  0.022015   0.948438   \n",
       "3                                  0.033022   0.928794   \n",
       "4                                  0.044030   0.970421   \n",
       "..                                      ...        ...   \n",
       "157                                0.956993   0.182507   \n",
       "158                                0.953662   0.168812   \n",
       "159                                0.950331   0.152959   \n",
       "160                                0.947000   0.137613   \n",
       "161                                0.943668   0.163171   \n",
       "\n",
       "     Mato Grosso - Desemprego  Mato Grosso - IDH  \\\n",
       "0                    1.000000           0.000000   \n",
       "1                    0.996341           0.011805   \n",
       "2                    0.992682           0.023609   \n",
       "3                    0.989023           0.035414   \n",
       "4                    0.985364           0.047219   \n",
       "..                        ...                ...   \n",
       "157                  0.621493           0.994318   \n",
       "158                  0.596535           0.988636   \n",
       "159                  0.571578           0.982954   \n",
       "160                  0.546620           0.977272   \n",
       "161                  0.521662           0.971590   \n",
       "\n",
       "     Mato Grosso - PIB - Estadual  Mato Grosso - PIB - Construção Civil  \\\n",
       "0                        0.000000                              0.000000   \n",
       "1                        0.005153                              0.008692   \n",
       "2                        0.010307                              0.017385   \n",
       "3                        0.015460                              0.026077   \n",
       "4                        0.020613                              0.034770   \n",
       "..                            ...                                   ...   \n",
       "157                      0.973043                              0.688394   \n",
       "158                      0.974495                              0.684427   \n",
       "159                      0.975947                              0.680460   \n",
       "160                      0.977399                              0.676493   \n",
       "161                      0.978852                              0.672526   \n",
       "\n",
       "     Mato Grosso - PIB - Per Capita  Mato Grosso - PIB - Preços de Mercado  \\\n",
       "0                          0.000000                               0.000000   \n",
       "1                          0.004513                               0.005346   \n",
       "2                          0.009026                               0.010692   \n",
       "3                          0.013539                               0.016038   \n",
       "4                          0.018052                               0.021384   \n",
       "..                              ...                                    ...   \n",
       "157                        0.986108                               0.975683   \n",
       "158                        0.985875                               0.976460   \n",
       "159                        0.985641                               0.977238   \n",
       "160                        0.985408                               0.978015   \n",
       "161                        0.985174                               0.978793   \n",
       "\n",
       "     Mato Grosso - value  \n",
       "0               0.182887  \n",
       "1               0.195974  \n",
       "2               0.204977  \n",
       "3               0.213516  \n",
       "4               0.216392  \n",
       "..                   ...  \n",
       "157             0.938508  \n",
       "158             0.931775  \n",
       "159             0.924689  \n",
       "160             0.918022  \n",
       "161             0.911047  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[start_index:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       51.972\n",
       "1       40.729\n",
       "2       54.446\n",
       "3       51.788\n",
       "4       58.702\n",
       "        ...   \n",
       "157     65.293\n",
       "158     90.338\n",
       "159     83.188\n",
       "160    107.230\n",
       "161    105.397\n",
       "Name: Mato Grosso - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[start_index:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21b9c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(t_input, t_target, window_size, start_from):\n",
    "    \n",
    "    X_batches = []\n",
    "    y_batches = []\n",
    "\n",
    "    train_input_values = t_input.values \n",
    "\n",
    "    for i in range(len(t_input) - window_size):\n",
    "        \n",
    "        X_window = train_input_values[i:i+window_size, :]\n",
    "        y_target = t_target[start_from+i+window_size]\n",
    "\n",
    "        X_batches.append(X_window)\n",
    "        y_batches.append(y_target)\n",
    "\n",
    "    return np.array(X_batches), np.array(y_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b281277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 36, 15)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_train, reshaped_target = create_batches(train_input, \n",
    "                                                 train_target, \n",
    "                                                 window_size, \n",
    "                                                 start_index)\n",
    "reshaped_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc5d50dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mato Grosso - Produção de Cimento (t)</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Mato Grosso - Desemprego</th>\n",
       "      <th>Mato Grosso - IDH</th>\n",
       "      <th>Mato Grosso - PIB - Estadual</th>\n",
       "      <th>Mato Grosso - PIB - Construção Civil</th>\n",
       "      <th>Mato Grosso - PIB - Per Capita</th>\n",
       "      <th>Mato Grosso - PIB - Preços de Mercado</th>\n",
       "      <th>Mato Grosso - value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612440</td>\n",
       "      <td>0.052718</td>\n",
       "      <td>0.094523</td>\n",
       "      <td>0.201912</td>\n",
       "      <td>0.780557</td>\n",
       "      <td>0.994213</td>\n",
       "      <td>0.372054</td>\n",
       "      <td>0.366310</td>\n",
       "      <td>0.798772</td>\n",
       "      <td>0.815216</td>\n",
       "      <td>0.971029</td>\n",
       "      <td>0.870123</td>\n",
       "      <td>0.843018</td>\n",
       "      <td>0.868231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.991476</td>\n",
       "      <td>0.626227</td>\n",
       "      <td>0.056653</td>\n",
       "      <td>0.200555</td>\n",
       "      <td>0.209545</td>\n",
       "      <td>0.784414</td>\n",
       "      <td>0.995177</td>\n",
       "      <td>0.375438</td>\n",
       "      <td>0.388500</td>\n",
       "      <td>0.797810</td>\n",
       "      <td>0.822368</td>\n",
       "      <td>0.966201</td>\n",
       "      <td>0.876689</td>\n",
       "      <td>0.849696</td>\n",
       "      <td>0.879874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.976090</td>\n",
       "      <td>0.645442</td>\n",
       "      <td>0.060771</td>\n",
       "      <td>0.214993</td>\n",
       "      <td>0.238038</td>\n",
       "      <td>0.788271</td>\n",
       "      <td>0.996142</td>\n",
       "      <td>0.372254</td>\n",
       "      <td>0.410690</td>\n",
       "      <td>0.796849</td>\n",
       "      <td>0.829519</td>\n",
       "      <td>0.961372</td>\n",
       "      <td>0.883254</td>\n",
       "      <td>0.856374</td>\n",
       "      <td>0.890140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.962811</td>\n",
       "      <td>0.673151</td>\n",
       "      <td>0.065105</td>\n",
       "      <td>0.053026</td>\n",
       "      <td>0.249843</td>\n",
       "      <td>0.792128</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.369458</td>\n",
       "      <td>0.432879</td>\n",
       "      <td>0.795888</td>\n",
       "      <td>0.836671</td>\n",
       "      <td>0.956544</td>\n",
       "      <td>0.889819</td>\n",
       "      <td>0.863052</td>\n",
       "      <td>0.900472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.069099</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.266770</td>\n",
       "      <td>0.795984</td>\n",
       "      <td>0.998071</td>\n",
       "      <td>0.371547</td>\n",
       "      <td>0.455069</td>\n",
       "      <td>0.794926</td>\n",
       "      <td>0.843822</td>\n",
       "      <td>0.951716</td>\n",
       "      <td>0.896384</td>\n",
       "      <td>0.869730</td>\n",
       "      <td>0.912345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.692912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030808</td>\n",
       "      <td>0.063780</td>\n",
       "      <td>0.381401</td>\n",
       "      <td>0.987600</td>\n",
       "      <td>0.828698</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.232479</td>\n",
       "      <td>0.768057</td>\n",
       "      <td>0.988798</td>\n",
       "      <td>0.647567</td>\n",
       "      <td>0.992324</td>\n",
       "      <td>0.990966</td>\n",
       "      <td>0.843701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.693045</td>\n",
       "      <td>0.029504</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>0.048101</td>\n",
       "      <td>0.466609</td>\n",
       "      <td>0.990700</td>\n",
       "      <td>0.823090</td>\n",
       "      <td>0.037761</td>\n",
       "      <td>0.228761</td>\n",
       "      <td>0.756242</td>\n",
       "      <td>0.987198</td>\n",
       "      <td>0.649169</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.989675</td>\n",
       "      <td>0.850718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.701363</td>\n",
       "      <td>0.043125</td>\n",
       "      <td>0.023074</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.530936</td>\n",
       "      <td>0.993800</td>\n",
       "      <td>0.817482</td>\n",
       "      <td>0.087044</td>\n",
       "      <td>0.225042</td>\n",
       "      <td>0.744427</td>\n",
       "      <td>0.985598</td>\n",
       "      <td>0.650771</td>\n",
       "      <td>0.990131</td>\n",
       "      <td>0.988384</td>\n",
       "      <td>0.864656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.702586</td>\n",
       "      <td>0.059756</td>\n",
       "      <td>0.017547</td>\n",
       "      <td>0.035186</td>\n",
       "      <td>0.611274</td>\n",
       "      <td>0.996900</td>\n",
       "      <td>0.811875</td>\n",
       "      <td>0.118264</td>\n",
       "      <td>0.221324</td>\n",
       "      <td>0.732612</td>\n",
       "      <td>0.983998</td>\n",
       "      <td>0.652373</td>\n",
       "      <td>0.989035</td>\n",
       "      <td>0.987094</td>\n",
       "      <td>0.878935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.707263</td>\n",
       "      <td>0.130775</td>\n",
       "      <td>0.013180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806267</td>\n",
       "      <td>0.138179</td>\n",
       "      <td>0.217605</td>\n",
       "      <td>0.720797</td>\n",
       "      <td>0.982397</td>\n",
       "      <td>0.653975</td>\n",
       "      <td>0.987938</td>\n",
       "      <td>0.985803</td>\n",
       "      <td>0.896508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mato Grosso - Produção de Cimento (t)  \\\n",
       "126                               1.000000   \n",
       "127                               0.991476   \n",
       "128                               0.976090   \n",
       "129                               0.962811   \n",
       "130                               0.946237   \n",
       "..                                     ...   \n",
       "187                               0.692912   \n",
       "188                               0.693045   \n",
       "189                               0.701363   \n",
       "190                               0.702586   \n",
       "191                               0.707263   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "126                                          0.612440   \n",
       "127                                          0.626227   \n",
       "128                                          0.645442   \n",
       "129                                          0.673151   \n",
       "130                                          0.699949   \n",
       "..                                                ...   \n",
       "187                                          0.000000   \n",
       "188                                          0.029504   \n",
       "189                                          0.043125   \n",
       "190                                          0.059756   \n",
       "191                                          0.130775   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "126                       0.052718        0.094523  0.201912   0.780557   \n",
       "127                       0.056653        0.200555  0.209545   0.784414   \n",
       "128                       0.060771        0.214993  0.238038   0.788271   \n",
       "129                       0.065105        0.053026  0.249843   0.792128   \n",
       "130                       0.069099        0.016760  0.266770   0.795984   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                       0.030808        0.063780  0.381401   0.987600   \n",
       "188                       0.027720        0.048101  0.466609   0.990700   \n",
       "189                       0.023074        0.016800  0.530936   0.993800   \n",
       "190                       0.017547        0.035186  0.611274   0.996900   \n",
       "191                       0.013180        0.000000  0.679742   1.000000   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "126                                0.994213   0.372054   \n",
       "127                                0.995177   0.375438   \n",
       "128                                0.996142   0.372254   \n",
       "129                                0.997106   0.369458   \n",
       "130                                0.998071   0.371547   \n",
       "..                                      ...        ...   \n",
       "187                                0.828698   0.005731   \n",
       "188                                0.823090   0.037761   \n",
       "189                                0.817482   0.087044   \n",
       "190                                0.811875   0.118264   \n",
       "191                                0.806267   0.138179   \n",
       "\n",
       "     Mato Grosso - Desemprego  Mato Grosso - IDH  \\\n",
       "126                  0.366310           0.798772   \n",
       "127                  0.388500           0.797810   \n",
       "128                  0.410690           0.796849   \n",
       "129                  0.432879           0.795888   \n",
       "130                  0.455069           0.794926   \n",
       "..                        ...                ...   \n",
       "187                  0.232479           0.768057   \n",
       "188                  0.228761           0.756242   \n",
       "189                  0.225042           0.744427   \n",
       "190                  0.221324           0.732612   \n",
       "191                  0.217605           0.720797   \n",
       "\n",
       "     Mato Grosso - PIB - Estadual  Mato Grosso - PIB - Construção Civil  \\\n",
       "126                      0.815216                              0.971029   \n",
       "127                      0.822368                              0.966201   \n",
       "128                      0.829519                              0.961372   \n",
       "129                      0.836671                              0.956544   \n",
       "130                      0.843822                              0.951716   \n",
       "..                            ...                                   ...   \n",
       "187                      0.988798                              0.647567   \n",
       "188                      0.987198                              0.649169   \n",
       "189                      0.985598                              0.650771   \n",
       "190                      0.983998                              0.652373   \n",
       "191                      0.982397                              0.653975   \n",
       "\n",
       "     Mato Grosso - PIB - Per Capita  Mato Grosso - PIB - Preços de Mercado  \\\n",
       "126                        0.870123                               0.843018   \n",
       "127                        0.876689                               0.849696   \n",
       "128                        0.883254                               0.856374   \n",
       "129                        0.889819                               0.863052   \n",
       "130                        0.896384                               0.869730   \n",
       "..                              ...                                    ...   \n",
       "187                        0.992324                               0.990966   \n",
       "188                        0.991228                               0.989675   \n",
       "189                        0.990131                               0.988384   \n",
       "190                        0.989035                               0.987094   \n",
       "191                        0.987938                               0.985803   \n",
       "\n",
       "     Mato Grosso - value  \n",
       "126             0.868231  \n",
       "127             0.879874  \n",
       "128             0.890140  \n",
       "129             0.900472  \n",
       "130             0.912345  \n",
       "..                   ...  \n",
       "187             0.843701  \n",
       "188             0.850718  \n",
       "189             0.864656  \n",
       "190             0.878935  \n",
       "191             0.896508  \n",
       "\n",
       "[66 rows x 15 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "test_input = input_data.iloc[train_split - window_size:split_index + 1]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82f07fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 36, 15)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_test, reshaped_test_target = create_batches(test_input, \n",
    "                                                     target_data, \n",
    "                                                     window_size, \n",
    "                                                     train_split - window_size)\n",
    "reshaped_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c5afeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(arr, div_factor, add_factor=0):\n",
    "    split_factor = len(arr) // div_factor\n",
    "    positions_to_drop_index = []\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = len(arr) - (i * div_factor + 1)\n",
    "        positions_to_drop_index.append(pos)\n",
    "        positions_to_drop.append(pos + add_factor)\n",
    "    \n",
    "    arr_droped = arr[positions_to_drop]\n",
    "    arr_result = np.delete(arr, positions_to_drop_index, axis=0)\n",
    "    \n",
    "    return arr_result, arr_droped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede Neural Recorrente com optmizador Estocástico\n",
    "def bidirectional_lstm_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    train, train_val = validation_splitter(train_input, 7)\n",
    "    target,target_val = validation_splitter(train_target, 7)\n",
    "#     display(train.shape)\n",
    "#     display(train_val.shape)\n",
    "#     display(target.shape)\n",
    "#     display(target_val.shape)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(36, activation='tanh', \n",
    "                                 return_sequences=False), \n",
    "                                 input_shape=(train_input.shape[1], \n",
    "                                              train_input.shape[2])),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "#         tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(180, activation='tanh')),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val,\n",
    "                                         target_val),\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_input, test_target):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(50)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = bidirectional_lstm_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1acb58be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1719479622, 3013794340, 4275837557, 383586916, 3371642246, 3573270711, 4282409986, 73237738, 1921382146, 141561786, 1911106934, 1303695431, 3499041090, 3264438077, 515574670, 1021877548, 3200841210, 3794557442, 533834484, 673842339, 4113175143, 2872753359, 2608002709, 2464198575, 2807599551, 1709097582, 3222455832, 1632090359, 2522314039, 2860252237, 3890213589, 3594358859, 426060538, 1279844865, 3227336353, 2810193439, 762627949, 1916038592, 3176425093, 115862435, 695583839, 2877020805, 779251982, 334760895, 1789613609, 1784751688, 3917190150, 786016214, 4173695063, 3019176347]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 77.32479095458984\n",
      "winner_seed: 1719479622\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 63.4732666015625\n",
      "winner_seed: 3013794340\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 92.3858871459961\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 57.80889892578125\n",
      "winner_seed: 383586916\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 76.75760650634766\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 79.09296417236328\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 76.42679595947266\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 91.16474914550781\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 77.2286376953125\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 39.15728759765625\n",
      "winner_seed: 141561786\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 79.9561767578125\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 83.74518585205078\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 82.88999938964844\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 54.53224563598633\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 77.8696060180664\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 78.13529205322266\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 132.48031616210938\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 63.84490203857422\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 52.44109344482422\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 89.41697692871094\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 69.47402954101562\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 63.29560089111328\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 77.41285705566406\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 125.13357543945312\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 66.614990234375\n",
      "\n",
      "\n",
      "Step: 25 ___________________________________________\n",
      "val_loss: 71.5369873046875\n",
      "\n",
      "\n",
      "Step: 26 ___________________________________________\n",
      "val_loss: 59.19163513183594\n",
      "\n",
      "\n",
      "Step: 27 ___________________________________________\n",
      "val_loss: 82.96897888183594\n",
      "\n",
      "\n",
      "Step: 28 ___________________________________________\n",
      "val_loss: 66.99447631835938\n",
      "\n",
      "\n",
      "Step: 29 ___________________________________________\n",
      "val_loss: 71.80480194091797\n",
      "\n",
      "\n",
      "Step: 30 ___________________________________________\n",
      "val_loss: 63.60366439819336\n",
      "\n",
      "\n",
      "Step: 31 ___________________________________________\n",
      "val_loss: 77.52265930175781\n",
      "\n",
      "\n",
      "Step: 32 ___________________________________________\n",
      "val_loss: 75.51779174804688\n",
      "\n",
      "\n",
      "Step: 33 ___________________________________________\n",
      "val_loss: 69.57601165771484\n",
      "\n",
      "\n",
      "Step: 34 ___________________________________________\n",
      "val_loss: 62.77538299560547\n",
      "\n",
      "\n",
      "Step: 35 ___________________________________________\n",
      "val_loss: 64.5751953125\n",
      "\n",
      "\n",
      "Step: 36 ___________________________________________\n",
      "val_loss: 61.81001281738281\n",
      "\n",
      "\n",
      "Step: 37 ___________________________________________\n",
      "val_loss: 88.61793518066406\n",
      "\n",
      "\n",
      "Step: 38 ___________________________________________\n",
      "val_loss: 68.64707946777344\n",
      "\n",
      "\n",
      "Step: 39 ___________________________________________\n",
      "val_loss: 76.08016967773438\n",
      "\n",
      "\n",
      "Step: 40 ___________________________________________\n",
      "val_loss: 62.85704040527344\n",
      "\n",
      "\n",
      "Step: 41 ___________________________________________\n",
      "val_loss: 143.3862762451172\n",
      "\n",
      "\n",
      "Step: 42 ___________________________________________\n",
      "val_loss: 90.30880737304688\n",
      "\n",
      "\n",
      "Step: 43 ___________________________________________\n",
      "val_loss: 111.3623275756836\n",
      "\n",
      "\n",
      "Step: 44 ___________________________________________\n",
      "val_loss: 84.18373107910156\n",
      "\n",
      "\n",
      "Step: 45 ___________________________________________\n",
      "val_loss: 53.92687225341797\n",
      "\n",
      "\n",
      "Step: 46 ___________________________________________\n",
      "val_loss: 67.03175354003906\n",
      "\n",
      "\n",
      "Step: 47 ___________________________________________\n",
      "val_loss: 70.5792465209961\n",
      "\n",
      "\n",
      "Step: 48 ___________________________________________\n",
      "val_loss: 69.47802734375\n",
      "\n",
      "\n",
      "Step: 49 ___________________________________________\n",
      "val_loss: 45.331172943115234\n",
      "\n",
      "\n",
      "final_seed: 141561786\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(reshaped_train, reshaped_target, reshaped_test, reshaped_test_target)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 [==============================] - 2s 282ms/step - loss: 7403.3623 - val_loss: 831.2336\n",
      "Epoch 2/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 673.8102 - val_loss: 455.3294\n",
      "Epoch 3/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 503.6784 - val_loss: 509.4312\n",
      "Epoch 4/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 517.4417 - val_loss: 450.5114\n",
      "Epoch 5/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 492.7687 - val_loss: 443.8699\n",
      "Epoch 6/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 490.9907 - val_loss: 438.0307\n",
      "Epoch 7/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 497.0232 - val_loss: 434.5442\n",
      "Epoch 8/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 478.3389 - val_loss: 434.0396\n",
      "Epoch 9/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 489.2970 - val_loss: 439.4046\n",
      "Epoch 10/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 497.7045 - val_loss: 413.4233\n",
      "Epoch 11/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 519.1580 - val_loss: 457.4932\n",
      "Epoch 12/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 486.6414 - val_loss: 407.8384\n",
      "Epoch 13/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 445.4091 - val_loss: 417.7874\n",
      "Epoch 14/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 494.7018 - val_loss: 398.6045\n",
      "Epoch 15/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 440.6786 - val_loss: 494.4599\n",
      "Epoch 16/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 465.0044 - val_loss: 375.5945\n",
      "Epoch 17/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 632.7988 - val_loss: 514.6454\n",
      "Epoch 18/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 532.9858 - val_loss: 407.1224\n",
      "Epoch 19/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 442.1303 - val_loss: 421.0690\n",
      "Epoch 20/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 488.5529 - val_loss: 391.4561\n",
      "Epoch 21/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 455.8283 - val_loss: 478.3115\n",
      "Epoch 22/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 414.6302 - val_loss: 384.4842\n",
      "Epoch 23/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 500.1055 - val_loss: 728.4091\n",
      "Epoch 24/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 525.4775 - val_loss: 430.2581\n",
      "Epoch 25/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 448.1439 - val_loss: 353.3028\n",
      "Epoch 26/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 399.2925 - val_loss: 346.1526\n",
      "Epoch 27/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 406.5822 - val_loss: 451.4913\n",
      "Epoch 28/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 396.0367 - val_loss: 337.8544\n",
      "Epoch 29/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 408.1101 - val_loss: 336.6797\n",
      "Epoch 30/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 436.8737 - val_loss: 349.2576\n",
      "Epoch 31/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 379.4730 - val_loss: 375.2986\n",
      "Epoch 32/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 388.5013 - val_loss: 388.7715\n",
      "Epoch 33/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 427.3868 - val_loss: 338.3537\n",
      "Epoch 34/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 396.4113 - val_loss: 416.5859\n",
      "Epoch 35/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 383.4801 - val_loss: 319.1083\n",
      "Epoch 36/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 360.0500 - val_loss: 308.2191\n",
      "Epoch 37/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 383.4813 - val_loss: 335.5305\n",
      "Epoch 38/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 355.9068 - val_loss: 417.8067\n",
      "Epoch 39/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 573.9895 - val_loss: 332.4457\n",
      "Epoch 40/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 355.9381 - val_loss: 306.5767\n",
      "Epoch 41/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 349.3783 - val_loss: 331.2652\n",
      "Epoch 42/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 351.6720 - val_loss: 287.0479\n",
      "Epoch 43/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 388.8351 - val_loss: 481.4027\n",
      "Epoch 44/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 400.9189 - val_loss: 281.0192\n",
      "Epoch 45/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 307.9109 - val_loss: 266.8897\n",
      "Epoch 46/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 303.1992 - val_loss: 261.7566\n",
      "Epoch 47/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 428.6830 - val_loss: 302.3236\n",
      "Epoch 48/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 300.8079 - val_loss: 254.7204\n",
      "Epoch 49/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 322.9637 - val_loss: 319.6986\n",
      "Epoch 50/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 279.7596 - val_loss: 390.9422\n",
      "Epoch 51/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 452.3156 - val_loss: 253.6771\n",
      "Epoch 52/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 269.0719 - val_loss: 303.3785\n",
      "Epoch 53/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 309.2768 - val_loss: 468.9858\n",
      "Epoch 54/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 516.9297 - val_loss: 244.5880\n",
      "Epoch 55/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 283.8473 - val_loss: 242.4472\n",
      "Epoch 56/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 263.7178 - val_loss: 287.2380\n",
      "Epoch 57/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 299.4905 - val_loss: 228.3275\n",
      "Epoch 58/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 249.6447 - val_loss: 236.9118\n",
      "Epoch 59/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 339.5533 - val_loss: 500.2661\n",
      "Epoch 60/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 386.1182 - val_loss: 261.8912\n",
      "Epoch 61/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 335.0417 - val_loss: 244.3948\n",
      "Epoch 62/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 317.4622 - val_loss: 239.1612\n",
      "Epoch 63/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 293.5933 - val_loss: 391.1503\n",
      "Epoch 64/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 301.5179 - val_loss: 218.6685\n",
      "Epoch 65/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 345.1113 - val_loss: 267.6479\n",
      "Epoch 66/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 289.7642 - val_loss: 219.8744\n",
      "Epoch 67/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 274.8425 - val_loss: 214.6347\n",
      "Epoch 68/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 263.0411 - val_loss: 252.8751\n",
      "Epoch 69/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 232.5114 - val_loss: 215.6752\n",
      "Epoch 70/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 214.1503 - val_loss: 251.8387\n",
      "Epoch 71/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 217.9978 - val_loss: 452.9124\n",
      "Epoch 72/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 268.9920 - val_loss: 201.8976\n",
      "Epoch 73/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 270.5010 - val_loss: 483.3829\n",
      "Epoch 74/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 323.1112 - val_loss: 260.3656\n",
      "Epoch 75/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 235.2408 - val_loss: 242.3098\n",
      "Epoch 76/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 215.9955 - val_loss: 254.0713\n",
      "Epoch 77/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 235.5117 - val_loss: 239.1479\n",
      "Epoch 78/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 274.9481 - val_loss: 245.8717\n",
      "Epoch 79/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 217.6658 - val_loss: 195.5232\n",
      "Epoch 80/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 208.3671 - val_loss: 204.1373\n",
      "Epoch 81/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 297.8167 - val_loss: 201.8707\n",
      "Epoch 82/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 224.3349 - val_loss: 226.4408\n",
      "Epoch 83/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 222.7792 - val_loss: 441.3784\n",
      "Epoch 84/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 500.1449 - val_loss: 233.5415\n",
      "Epoch 85/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 235.1996 - val_loss: 175.7592\n",
      "Epoch 86/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 224.5416 - val_loss: 225.7069\n",
      "Epoch 87/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 200.8817 - val_loss: 172.7939\n",
      "Epoch 88/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 201.2620 - val_loss: 247.6123\n",
      "Epoch 89/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 210.0905 - val_loss: 389.5764\n",
      "Epoch 90/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 311.0842 - val_loss: 174.0137\n",
      "Epoch 91/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 253.4329 - val_loss: 217.2889\n",
      "Epoch 92/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 227.8212 - val_loss: 190.8553\n",
      "Epoch 93/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 288.8891 - val_loss: 560.0105\n",
      "Epoch 94/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 378.9513 - val_loss: 221.7236\n",
      "Epoch 95/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 214.7612 - val_loss: 197.4237\n",
      "Epoch 96/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 201.9200 - val_loss: 231.0942\n",
      "Epoch 97/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 235.9904 - val_loss: 257.8856\n",
      "Epoch 98/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 215.3026 - val_loss: 217.8661\n",
      "Epoch 99/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 231.7186 - val_loss: 301.4011\n",
      "Epoch 100/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 287.4073 - val_loss: 173.8558\n",
      "Epoch 101/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 202.9161 - val_loss: 180.2060\n",
      "Epoch 102/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 185.3757 - val_loss: 260.4968\n",
      "Epoch 103/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 277.7325 - val_loss: 189.5770\n",
      "Epoch 104/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 200.6520 - val_loss: 293.7573\n",
      "Epoch 105/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 295.4615 - val_loss: 205.5195\n",
      "Epoch 106/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 283.6432 - val_loss: 298.4374\n",
      "Epoch 107/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 268.7687 - val_loss: 193.3067\n",
      "Epoch 108/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 230.7518 - val_loss: 871.7634\n",
      "Epoch 109/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 576.0970 - val_loss: 399.4718\n",
      "Epoch 110/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 381.1766 - val_loss: 236.8531\n",
      "Epoch 111/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 255.6897 - val_loss: 210.7354\n",
      "Epoch 112/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 221.0286 - val_loss: 246.5641\n",
      "Epoch 113/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 247.7891 - val_loss: 201.2191\n",
      "Epoch 114/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 235.3582 - val_loss: 199.4275\n",
      "Epoch 115/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 265.4760 - val_loss: 191.8749\n",
      "Epoch 116/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 213.6386 - val_loss: 218.2682\n",
      "Epoch 117/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 213.4483 - val_loss: 258.2949\n",
      "Epoch 118/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 187.8210 - val_loss: 265.4949\n",
      "Epoch 119/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 250.8436 - val_loss: 342.7879\n",
      "Epoch 120/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 280.1459 - val_loss: 175.2391\n",
      "Epoch 121/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 226.0776 - val_loss: 212.9615\n",
      "Epoch 122/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 219.4143 - val_loss: 219.5499\n",
      "Epoch 123/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 186.8759 - val_loss: 216.7502\n",
      "Epoch 124/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 239.7619 - val_loss: 354.0854\n",
      "Epoch 125/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 277.8575 - val_loss: 172.2398\n",
      "Epoch 126/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 190.5229 - val_loss: 352.5241\n",
      "Epoch 127/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 293.0364 - val_loss: 174.2220\n",
      "Epoch 128/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 208.8015 - val_loss: 166.1878\n",
      "Epoch 129/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 275.5722 - val_loss: 206.6305\n",
      "Epoch 130/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 193.6776 - val_loss: 203.9976\n",
      "Epoch 131/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 261.9862 - val_loss: 191.2525\n",
      "Epoch 132/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 225.2498 - val_loss: 163.2296\n",
      "Epoch 133/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 204.5524 - val_loss: 211.3332\n",
      "Epoch 134/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 230.3752 - val_loss: 165.0803\n",
      "Epoch 135/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 175.7349 - val_loss: 135.3653\n",
      "Epoch 136/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 189.2408 - val_loss: 206.1295\n",
      "Epoch 137/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 208.1426 - val_loss: 260.2972\n",
      "Epoch 138/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 202.5303 - val_loss: 161.5940\n",
      "Epoch 139/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 176.4744 - val_loss: 214.5391\n",
      "Epoch 140/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 199.6354 - val_loss: 176.3945\n",
      "Epoch 141/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 181.9755 - val_loss: 160.7900\n",
      "Epoch 142/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 177.5345 - val_loss: 205.4419\n",
      "Epoch 143/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 195.4387 - val_loss: 220.7881\n",
      "Epoch 144/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 205.7849 - val_loss: 251.0610\n",
      "Epoch 145/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 245.0909 - val_loss: 206.3570\n",
      "Epoch 146/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 201.6712 - val_loss: 217.4324\n",
      "Epoch 147/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 309.4519 - val_loss: 212.7399\n",
      "Epoch 148/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 218.3364 - val_loss: 160.2864\n",
      "Epoch 149/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 190.2061 - val_loss: 189.5926\n",
      "Epoch 150/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 183.9963 - val_loss: 220.9447\n",
      "Epoch 151/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 181.8574 - val_loss: 156.7151\n",
      "Epoch 152/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 202.4171 - val_loss: 267.7331\n",
      "Epoch 153/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 224.9543 - val_loss: 158.7946\n",
      "Epoch 154/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 185.4481 - val_loss: 149.3869\n",
      "Epoch 155/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 168.9264 - val_loss: 163.3576\n",
      "Epoch 156/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 225.9996 - val_loss: 150.5485\n",
      "Epoch 157/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 161.8298 - val_loss: 163.8888\n",
      "Epoch 158/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 248.6905 - val_loss: 150.4616\n",
      "Epoch 159/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 186.1685 - val_loss: 168.7246\n",
      "Epoch 160/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 190.6934 - val_loss: 156.0099\n",
      "Epoch 161/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 165.2077 - val_loss: 240.2443\n",
      "Epoch 162/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 211.2744 - val_loss: 153.2679\n",
      "Epoch 163/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 235.4141 - val_loss: 135.1862\n",
      "Epoch 164/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 173.2897 - val_loss: 151.5717\n",
      "Epoch 165/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 184.1141 - val_loss: 168.9399\n",
      "Epoch 166/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 181.4802 - val_loss: 231.5031\n",
      "Epoch 167/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 173.7560 - val_loss: 105.8397\n",
      "Epoch 168/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 185.0639 - val_loss: 146.2869\n",
      "Epoch 169/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 173.7172 - val_loss: 253.9513\n",
      "Epoch 170/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 200.8964 - val_loss: 181.2950\n",
      "Epoch 171/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 212.7202 - val_loss: 160.1942\n",
      "Epoch 172/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 188.9395 - val_loss: 222.3042\n",
      "Epoch 173/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 210.6271 - val_loss: 153.5859\n",
      "Epoch 174/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 183.9341 - val_loss: 179.9062\n",
      "Epoch 175/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 203.0984 - val_loss: 156.2492\n",
      "Epoch 176/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 155.1964 - val_loss: 195.4125\n",
      "Epoch 177/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 168.4652 - val_loss: 172.0376\n",
      "Epoch 178/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 173.6522 - val_loss: 141.4051\n",
      "Epoch 179/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 147.9433 - val_loss: 168.2562\n",
      "Epoch 180/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 162.5360 - val_loss: 168.2060\n",
      "Epoch 181/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 149.6185 - val_loss: 111.7367\n",
      "Epoch 182/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 175.0503 - val_loss: 179.9638\n",
      "Epoch 183/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 164.2632 - val_loss: 145.7450\n",
      "Epoch 184/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 252.9109 - val_loss: 139.8468\n",
      "Epoch 185/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 153.2330 - val_loss: 269.5712\n",
      "Epoch 186/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 270.7355 - val_loss: 203.6846\n",
      "Epoch 187/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 173.4778 - val_loss: 142.6416\n",
      "Epoch 188/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 176.1337 - val_loss: 349.0408\n",
      "Epoch 189/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 300.1411 - val_loss: 138.1953\n",
      "Epoch 190/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 157.6552 - val_loss: 106.3499\n",
      "Epoch 191/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 137.5544 - val_loss: 143.4568\n",
      "Epoch 192/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 150.1502 - val_loss: 172.5001\n",
      "Epoch 193/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 168.1281 - val_loss: 129.4652\n",
      "Epoch 194/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 190.6279 - val_loss: 149.1541\n",
      "Epoch 195/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 160.0714 - val_loss: 175.9675\n",
      "Epoch 196/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 189.5070 - val_loss: 173.5063\n",
      "Epoch 197/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 187.2351 - val_loss: 113.4054\n",
      "Epoch 198/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 146.8601 - val_loss: 523.9982\n",
      "Epoch 199/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 345.0690 - val_loss: 179.9034\n",
      "Epoch 200/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 195.1958 - val_loss: 187.1010\n",
      "Epoch 201/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 184.2074 - val_loss: 125.1610\n",
      "Epoch 202/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 163.1445 - val_loss: 108.3762\n",
      "Epoch 203/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 148.7976 - val_loss: 167.0707\n",
      "Epoch 204/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 159.5997 - val_loss: 126.1749\n",
      "Epoch 205/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 211.2466 - val_loss: 113.0965\n",
      "Epoch 206/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 200.8439 - val_loss: 187.5690\n",
      "Epoch 207/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 167.1055 - val_loss: 265.8731\n",
      "Epoch 208/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 175.7875 - val_loss: 138.8214\n",
      "Epoch 209/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 168.8085 - val_loss: 103.0150\n",
      "Epoch 210/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 181.7464 - val_loss: 115.9274\n",
      "Epoch 211/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 145.9539 - val_loss: 141.7592\n",
      "Epoch 212/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 217.0267 - val_loss: 203.1000\n",
      "Epoch 213/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 173.0248 - val_loss: 137.0004\n",
      "Epoch 214/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 160.0988 - val_loss: 133.7859\n",
      "Epoch 215/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 158.3828 - val_loss: 138.1737\n",
      "Epoch 216/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 145.6269 - val_loss: 126.7319\n",
      "Epoch 217/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 168.4396 - val_loss: 130.9003\n",
      "Epoch 218/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 155.7522 - val_loss: 360.0653\n",
      "Epoch 219/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 221.0412 - val_loss: 108.7884\n",
      "Epoch 220/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 123.1923 - val_loss: 135.9647\n",
      "Epoch 221/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 159.1977 - val_loss: 107.0747\n",
      "Epoch 222/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 233.8518 - val_loss: 136.9196\n",
      "Epoch 223/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 193.4252 - val_loss: 162.5459\n",
      "Epoch 224/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 184.1575 - val_loss: 155.7458\n",
      "Epoch 225/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 204.7533 - val_loss: 213.7478\n",
      "Epoch 226/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 201.8125 - val_loss: 169.1230\n",
      "Epoch 227/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 187.2414 - val_loss: 209.2665\n",
      "Epoch 228/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 244.4854 - val_loss: 164.9284\n",
      "Epoch 229/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 181.1305 - val_loss: 194.8015\n",
      "Epoch 230/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 185.5152 - val_loss: 305.9056\n",
      "Epoch 231/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 245.5744 - val_loss: 558.3380\n",
      "Epoch 232/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 357.0160 - val_loss: 186.9117\n",
      "Epoch 233/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 192.7145 - val_loss: 154.5498\n",
      "Epoch 234/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 183.3930 - val_loss: 140.9577\n",
      "Epoch 235/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 191.1994 - val_loss: 167.4679\n",
      "Epoch 236/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 173.1021 - val_loss: 153.3270\n",
      "Epoch 237/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 213.1343 - val_loss: 226.5556\n",
      "Epoch 238/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 200.1083 - val_loss: 195.7224\n",
      "Epoch 239/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 198.8308 - val_loss: 178.8180\n",
      "Epoch 240/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 186.6114 - val_loss: 237.4409\n",
      "Epoch 241/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 258.6844 - val_loss: 254.6875\n",
      "Epoch 242/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 172.6829 - val_loss: 128.7693\n",
      "Epoch 243/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 155.8519 - val_loss: 116.9770\n",
      "Epoch 244/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 195.9484 - val_loss: 188.5407\n",
      "Epoch 245/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 182.6196 - val_loss: 127.8034\n",
      "Epoch 246/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 178.5238 - val_loss: 109.6510\n",
      "Epoch 247/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 170.2123 - val_loss: 202.6633\n",
      "Epoch 248/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 215.9066 - val_loss: 231.3534\n",
      "Epoch 249/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 214.7654 - val_loss: 206.2554\n",
      "Epoch 250/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 187.1209 - val_loss: 136.3807\n",
      "Epoch 251/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 179.9073 - val_loss: 139.8753\n",
      "Epoch 252/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 213.6212 - val_loss: 221.2347\n",
      "Epoch 253/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 219.0152 - val_loss: 160.4681\n",
      "Epoch 254/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 185.5840 - val_loss: 153.5229\n",
      "Epoch 255/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 177.2735 - val_loss: 119.6547\n",
      "Epoch 256/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 167.9238 - val_loss: 137.5044\n",
      "Epoch 257/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 170.5725 - val_loss: 147.9489\n",
      "Epoch 258/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 152.8720 - val_loss: 122.9549\n",
      "Epoch 259/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 165.2975 - val_loss: 107.2359\n",
      "Epoch 260/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 147.9704 - val_loss: 243.2587\n",
      "Epoch 261/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 221.8716 - val_loss: 201.1478\n",
      "Epoch 262/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 244.2921 - val_loss: 145.3585\n",
      "Epoch 263/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 188.1141 - val_loss: 181.5196\n",
      "Epoch 264/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 194.6455 - val_loss: 177.1531\n",
      "Epoch 265/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 202.5639 - val_loss: 167.8189\n",
      "Epoch 266/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 234.9247 - val_loss: 318.7372\n",
      "Epoch 267/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 253.8585 - val_loss: 183.2573\n",
      "Epoch 268/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 225.6334 - val_loss: 122.6904\n",
      "Epoch 269/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 255.8558 - val_loss: 193.5986\n",
      "Epoch 270/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 190.0559 - val_loss: 116.8720\n",
      "Epoch 271/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 186.6957 - val_loss: 170.1646\n",
      "Epoch 272/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 223.6224 - val_loss: 316.9193\n",
      "Epoch 273/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 238.0317 - val_loss: 140.3097\n",
      "Epoch 274/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 178.2720 - val_loss: 158.4713\n",
      "Epoch 275/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 214.6022 - val_loss: 135.2216\n",
      "Epoch 276/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 180.0948 - val_loss: 141.8290\n",
      "Epoch 277/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 166.6611 - val_loss: 127.8041\n",
      "Epoch 278/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 183.4810 - val_loss: 228.7554\n",
      "Epoch 279/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 196.6367 - val_loss: 121.1438\n",
      "Epoch 280/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 164.2873 - val_loss: 130.4027\n",
      "Epoch 281/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 168.3241 - val_loss: 162.4323\n",
      "Epoch 282/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 172.8361 - val_loss: 120.4442\n",
      "Epoch 283/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 179.7240 - val_loss: 128.3782\n",
      "Epoch 284/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 158.2728 - val_loss: 152.3807\n",
      "Epoch 285/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 225.4044 - val_loss: 131.1331\n",
      "Epoch 286/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 175.5193 - val_loss: 144.0519\n",
      "Epoch 287/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 166.6728 - val_loss: 110.3998\n",
      "Epoch 288/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 175.8746 - val_loss: 267.3830\n",
      "Epoch 289/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 229.2738 - val_loss: 175.7217\n",
      "Epoch 290/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 181.6827 - val_loss: 141.8415\n",
      "Epoch 291/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 172.6929 - val_loss: 154.0673\n",
      "Epoch 292/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 167.2447 - val_loss: 170.7093\n",
      "Epoch 293/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 206.9267 - val_loss: 297.6556\n",
      "Epoch 294/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 201.5836 - val_loss: 140.4566\n",
      "Epoch 295/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 159.1544 - val_loss: 170.9343\n",
      "Epoch 296/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 170.9940 - val_loss: 120.2823\n",
      "Epoch 297/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 154.5635 - val_loss: 125.0775\n",
      "Epoch 298/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 174.0632 - val_loss: 138.8843\n",
      "Epoch 299/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 206.1652 - val_loss: 104.3700\n",
      "Epoch 300/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 258.1260 - val_loss: 199.3148\n",
      "Epoch 301/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 194.7280 - val_loss: 159.3159\n",
      "Epoch 302/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 183.7813 - val_loss: 242.1221\n",
      "Epoch 303/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 281.7428 - val_loss: 167.4414\n",
      "Epoch 304/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 190.0005 - val_loss: 529.4359\n",
      "Epoch 305/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 436.5684 - val_loss: 167.0386\n",
      "Epoch 306/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 195.5636 - val_loss: 147.6284\n",
      "Epoch 307/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 172.8223 - val_loss: 332.8435\n",
      "Epoch 308/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 222.5691 - val_loss: 184.2567\n",
      "Epoch 309/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 171.0173 - val_loss: 157.7316\n",
      "Epoch 310/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 155.9774 - val_loss: 178.5590\n",
      "Epoch 311/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 201.5866 - val_loss: 160.8704\n",
      "Epoch 312/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 201.1496 - val_loss: 313.5553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 241.8300 - val_loss: 178.3347\n",
      "Epoch 314/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 182.1706 - val_loss: 110.4995\n",
      "Epoch 315/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 211.8075 - val_loss: 179.0036\n",
      "Epoch 316/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 238.9887 - val_loss: 135.9407\n",
      "Epoch 317/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 162.3710 - val_loss: 222.1570\n",
      "Epoch 318/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 226.9680 - val_loss: 147.8624\n",
      "Epoch 319/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 157.2320 - val_loss: 134.0665\n",
      "Epoch 320/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 169.5975 - val_loss: 200.9012\n",
      "Epoch 321/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 175.4943 - val_loss: 123.1198\n",
      "Epoch 322/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 211.6669 - val_loss: 127.9221\n",
      "Epoch 323/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 157.4864 - val_loss: 132.6938\n",
      "Epoch 324/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 149.2774 - val_loss: 131.9202\n",
      "Epoch 325/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 157.9172 - val_loss: 121.6825\n",
      "Epoch 326/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 149.0287 - val_loss: 140.8996\n",
      "Epoch 327/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 196.8332 - val_loss: 122.5520\n",
      "Epoch 328/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 252.4396 - val_loss: 161.5805\n",
      "Epoch 329/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 197.8170 - val_loss: 154.3558\n",
      "Epoch 330/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 165.7501 - val_loss: 162.7664\n",
      "Epoch 331/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 174.9776 - val_loss: 143.6602\n",
      "Epoch 332/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 162.6340 - val_loss: 133.8643\n",
      "Epoch 333/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 164.4215 - val_loss: 142.0485\n",
      "Epoch 334/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 153.8353 - val_loss: 142.1259\n",
      "Epoch 335/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 177.0836 - val_loss: 119.3952\n",
      "Epoch 336/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 164.2374 - val_loss: 129.0719\n",
      "Epoch 337/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 170.0522 - val_loss: 105.4329\n",
      "Epoch 338/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 201.9950 - val_loss: 140.1921\n",
      "Epoch 339/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 159.8045 - val_loss: 121.8409\n",
      "Epoch 340/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 205.8933 - val_loss: 127.2984\n",
      "Epoch 341/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 151.1954 - val_loss: 105.0253\n",
      "Epoch 342/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 168.8786 - val_loss: 115.5638\n",
      "Epoch 343/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 152.3652 - val_loss: 134.8275\n",
      "Epoch 344/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 170.7775 - val_loss: 234.9369\n",
      "Epoch 345/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 217.9095 - val_loss: 192.5728\n",
      "Epoch 346/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 229.9492 - val_loss: 136.7174\n",
      "Epoch 347/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 155.0009 - val_loss: 209.4693\n",
      "Epoch 348/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 188.4127 - val_loss: 163.2041\n",
      "Epoch 349/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 171.0201 - val_loss: 402.4940\n",
      "Epoch 350/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 333.4754 - val_loss: 128.8674\n",
      "Epoch 351/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 168.8265 - val_loss: 114.3110\n",
      "Epoch 352/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 178.3843 - val_loss: 132.5210\n",
      "Epoch 353/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 173.3116 - val_loss: 264.0321\n",
      "Epoch 354/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 170.4774 - val_loss: 144.0123\n",
      "Epoch 355/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 146.8946 - val_loss: 236.3003\n",
      "Epoch 356/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 189.7371 - val_loss: 170.7442\n",
      "Epoch 357/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 184.7939 - val_loss: 155.3838\n",
      "Epoch 358/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 150.7247 - val_loss: 135.2322\n",
      "Epoch 359/10000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 277.1277 - val_loss: 195.0873\n",
      "Epoch 360/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 174.9053 - val_loss: 115.9414\n",
      "Epoch 361/10000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 211.6687 - val_loss: 106.9312\n",
      "Epoch 362/10000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 148.5857 - val_loss: 120.0759\n",
      "Epoch 363/10000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 158.8724 - val_loss: 113.9202\n",
      "Epoch 364/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 131.0866 - val_loss: 85.1944\n",
      "Epoch 365/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 265.7045 - val_loss: 409.3298\n",
      "Epoch 366/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 388.0793 - val_loss: 218.4936\n",
      "Epoch 367/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 215.3863 - val_loss: 170.4969\n",
      "Epoch 368/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 167.9870 - val_loss: 241.3325\n",
      "Epoch 369/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 200.7832 - val_loss: 192.1195\n",
      "Epoch 370/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 163.9763 - val_loss: 148.4789\n",
      "Epoch 371/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 287.9032 - val_loss: 177.1169\n",
      "Epoch 372/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 188.4657 - val_loss: 183.4916\n",
      "Epoch 373/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 182.4759 - val_loss: 147.9686\n",
      "Epoch 374/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 171.4444 - val_loss: 139.5005\n",
      "Epoch 375/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 155.1249 - val_loss: 137.3142\n",
      "Epoch 376/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 175.0873 - val_loss: 294.2091\n",
      "Epoch 377/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 289.7776 - val_loss: 153.2719\n",
      "Epoch 378/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 173.4148 - val_loss: 137.6660\n",
      "Epoch 379/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 158.7936 - val_loss: 116.2354\n",
      "Epoch 380/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 160.9068 - val_loss: 157.9549\n",
      "Epoch 381/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 155.6148 - val_loss: 161.7365\n",
      "Epoch 382/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 176.5519 - val_loss: 121.6930\n",
      "Epoch 383/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 170.2526 - val_loss: 223.4072\n",
      "Epoch 384/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 180.1051 - val_loss: 115.0721\n",
      "Epoch 385/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 143.3168 - val_loss: 108.7619\n",
      "Epoch 386/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 155.1724 - val_loss: 115.7448\n",
      "Epoch 387/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 173.3156 - val_loss: 140.4870\n",
      "Epoch 388/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 176.9234 - val_loss: 125.3080\n",
      "Epoch 389/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 140.2012 - val_loss: 79.9446\n",
      "Epoch 390/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 149.9343 - val_loss: 191.8053\n",
      "Epoch 391/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 199.0951 - val_loss: 126.6625\n",
      "Epoch 392/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 157.9215 - val_loss: 183.9583\n",
      "Epoch 393/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 195.5971 - val_loss: 123.0970\n",
      "Epoch 394/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 130.0111 - val_loss: 91.9465\n",
      "Epoch 395/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 215.4236 - val_loss: 137.0426\n",
      "Epoch 396/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 178.2335 - val_loss: 121.7159\n",
      "Epoch 397/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 149.8890 - val_loss: 127.5077\n",
      "Epoch 398/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 145.7549 - val_loss: 102.7137\n",
      "Epoch 399/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 162.8078 - val_loss: 151.4088\n",
      "Epoch 400/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 305.2504 - val_loss: 236.2988\n",
      "Epoch 401/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 242.0715 - val_loss: 180.3880\n",
      "Epoch 402/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 217.8152 - val_loss: 178.2535\n",
      "Epoch 403/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 240.4629 - val_loss: 190.6102\n",
      "Epoch 404/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 184.1640 - val_loss: 153.4238\n",
      "Epoch 405/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 166.8480 - val_loss: 189.5686\n",
      "Epoch 406/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 197.7654 - val_loss: 153.8810\n",
      "Epoch 407/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 168.4147 - val_loss: 132.2152\n",
      "Epoch 408/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 158.9025 - val_loss: 105.7041\n",
      "Epoch 409/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 133.6929 - val_loss: 163.1388\n",
      "Epoch 410/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 171.6863 - val_loss: 168.1032\n",
      "Epoch 411/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 159.5965 - val_loss: 197.5848\n",
      "Epoch 412/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 201.5274 - val_loss: 143.2561\n",
      "Epoch 413/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 186.9005 - val_loss: 156.5261\n",
      "Epoch 414/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 195.5677 - val_loss: 189.6290\n",
      "Epoch 415/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 223.5755 - val_loss: 333.1076\n",
      "Epoch 416/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 267.3070 - val_loss: 173.4528\n",
      "Epoch 417/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 176.9455 - val_loss: 188.6374\n",
      "Epoch 418/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 181.5201 - val_loss: 387.1670\n",
      "Epoch 419/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 415.3226 - val_loss: 163.3322\n",
      "Epoch 420/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 228.6174 - val_loss: 170.2135\n",
      "Epoch 421/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 170.7717 - val_loss: 148.8459\n",
      "Epoch 422/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 183.9350 - val_loss: 116.6826\n",
      "Epoch 423/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 157.3200 - val_loss: 174.3984\n",
      "Epoch 424/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 167.3419 - val_loss: 144.7741\n",
      "Epoch 425/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 153.7775 - val_loss: 203.8690\n",
      "Epoch 426/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 158.5627 - val_loss: 152.1205\n",
      "Epoch 427/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 151.3570 - val_loss: 206.0005\n",
      "Epoch 428/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 184.6995 - val_loss: 128.4455\n",
      "Epoch 429/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 217.8431 - val_loss: 256.2498\n",
      "Epoch 430/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 234.2091 - val_loss: 172.7180\n",
      "Epoch 431/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 172.3773 - val_loss: 162.9766\n",
      "Epoch 432/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 179.5826 - val_loss: 139.5071\n",
      "Epoch 433/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 158.2514 - val_loss: 126.5259\n",
      "Epoch 434/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 191.3975 - val_loss: 144.6212\n",
      "Epoch 435/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 187.8098 - val_loss: 127.2392\n",
      "Epoch 436/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 162.7225 - val_loss: 229.4801\n",
      "Epoch 437/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 190.7440 - val_loss: 153.1040\n",
      "Epoch 438/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 194.3510 - val_loss: 171.1222\n",
      "Epoch 439/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 192.4669 - val_loss: 135.7115\n",
      "Epoch 440/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 166.3331 - val_loss: 145.4524\n",
      "Epoch 441/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 171.8287 - val_loss: 124.9353\n",
      "Epoch 442/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 141.6800 - val_loss: 137.6887\n",
      "Epoch 443/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 170.0811 - val_loss: 281.7489\n",
      "Epoch 444/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 176.1499 - val_loss: 152.3748\n",
      "Epoch 445/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 160.3975 - val_loss: 158.6522\n",
      "Epoch 446/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 152.0639 - val_loss: 170.2054\n",
      "Epoch 447/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 185.1181 - val_loss: 144.7044\n",
      "Epoch 448/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 181.8278 - val_loss: 126.8978\n",
      "Epoch 449/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 145.0446 - val_loss: 134.4726\n",
      "Epoch 450/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 144.7339 - val_loss: 184.9500\n",
      "Epoch 451/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 287.6339 - val_loss: 153.1832\n",
      "Epoch 452/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 148.7240 - val_loss: 218.4970\n",
      "Epoch 453/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 237.3021 - val_loss: 168.7788\n",
      "Epoch 454/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 182.8118 - val_loss: 155.5274\n",
      "Epoch 455/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 151.6737 - val_loss: 166.8684\n",
      "Epoch 456/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 168.4937 - val_loss: 127.4610\n",
      "Epoch 457/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 267.6610 - val_loss: 186.1280\n",
      "Epoch 458/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 181.8295 - val_loss: 168.0509\n",
      "Epoch 459/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 225.8288 - val_loss: 319.6782\n",
      "Epoch 460/10000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 267.3617 - val_loss: 182.1479\n",
      "Epoch 461/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 206.5623 - val_loss: 284.5972\n",
      "Epoch 462/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 258.6827 - val_loss: 141.9230\n",
      "Epoch 463/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 171.5047 - val_loss: 141.7776\n",
      "Epoch 464/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 183.4901 - val_loss: 223.6526\n",
      "Epoch 465/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 272.6811 - val_loss: 245.8114\n",
      "Epoch 466/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 199.9799 - val_loss: 177.5659\n",
      "Epoch 467/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 156.8401 - val_loss: 176.8981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 158.5998 - val_loss: 201.5469\n",
      "Epoch 469/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 188.1764 - val_loss: 301.9666\n",
      "Epoch 470/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 222.1954 - val_loss: 148.6059\n",
      "Epoch 471/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 200.8916 - val_loss: 198.7243\n",
      "Epoch 472/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 161.1176 - val_loss: 165.8804\n",
      "Epoch 473/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 176.6523 - val_loss: 138.4124\n",
      "Epoch 474/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 167.6786 - val_loss: 145.4024\n",
      "Epoch 475/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 136.9652 - val_loss: 178.4556\n",
      "Epoch 476/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 208.9153 - val_loss: 162.3046\n",
      "Epoch 477/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 153.6305 - val_loss: 162.8023\n",
      "Epoch 478/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 164.9382 - val_loss: 146.7993\n",
      "Epoch 479/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 143.2430 - val_loss: 162.6268\n",
      "Epoch 480/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 159.3410 - val_loss: 175.0701\n",
      "Epoch 481/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 168.3320 - val_loss: 156.1456\n",
      "Epoch 482/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 143.3490 - val_loss: 215.4039\n",
      "Epoch 483/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 196.2603 - val_loss: 142.7701\n",
      "Epoch 484/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 160.6117 - val_loss: 353.3758\n",
      "Epoch 485/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 204.5349 - val_loss: 183.4765\n",
      "Epoch 486/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 165.5348 - val_loss: 186.8771\n",
      "Epoch 487/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 181.2583 - val_loss: 159.3409\n",
      "Epoch 488/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 174.1543 - val_loss: 152.6805\n",
      "Epoch 489/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 141.9820 - val_loss: 127.9266\n",
      "Epoch 490/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 185.6834 - val_loss: 170.4875\n",
      "Epoch 491/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 176.9311 - val_loss: 140.9765\n",
      "Epoch 492/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 159.5246 - val_loss: 154.2157\n",
      "Epoch 493/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 229.6761 - val_loss: 212.4180\n",
      "Epoch 494/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 225.6703 - val_loss: 150.8314\n",
      "Epoch 495/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 176.0590 - val_loss: 189.0450\n",
      "Epoch 496/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 173.1823 - val_loss: 193.2946\n",
      "Epoch 497/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 167.9456 - val_loss: 133.5571\n",
      "Epoch 498/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 144.6999 - val_loss: 186.7170\n",
      "Epoch 499/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 235.3596 - val_loss: 189.8383\n",
      "Epoch 500/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 217.0614 - val_loss: 158.9823\n",
      "Epoch 501/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 167.8712 - val_loss: 171.3482\n",
      "Epoch 502/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 172.2901 - val_loss: 141.6925\n",
      "Epoch 503/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 153.9603 - val_loss: 159.0733\n",
      "Epoch 504/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 134.6201 - val_loss: 174.2181\n",
      "Epoch 505/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 165.0646 - val_loss: 295.5389\n",
      "Epoch 506/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 174.0902 - val_loss: 129.7994\n",
      "Epoch 507/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 134.0392 - val_loss: 148.5327\n",
      "Epoch 508/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 132.7466 - val_loss: 128.3032\n",
      "Epoch 509/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 159.9990 - val_loss: 159.3802\n",
      "Epoch 510/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 175.0608 - val_loss: 211.2434\n",
      "Epoch 511/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 190.1688 - val_loss: 252.5380\n",
      "Epoch 512/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 264.6701 - val_loss: 154.9956\n",
      "Epoch 513/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 161.2622 - val_loss: 230.3682\n",
      "Epoch 514/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 149.7299 - val_loss: 167.2558\n",
      "Epoch 515/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 191.9926 - val_loss: 150.5906\n",
      "Epoch 516/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 162.8879 - val_loss: 162.6548\n",
      "Epoch 517/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 225.5184 - val_loss: 141.2630\n",
      "Epoch 518/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 155.6893 - val_loss: 220.5904\n",
      "Epoch 519/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 145.0099 - val_loss: 132.8736\n",
      "Epoch 520/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 150.5174 - val_loss: 176.1715\n",
      "Epoch 521/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 152.9239 - val_loss: 147.3245\n",
      "Epoch 522/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 129.7933 - val_loss: 170.1854\n",
      "Epoch 523/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 161.0833 - val_loss: 129.8859\n",
      "Epoch 524/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 121.2103 - val_loss: 260.8153\n",
      "Epoch 525/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 279.8258 - val_loss: 129.6982\n",
      "Epoch 526/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 147.7071 - val_loss: 248.3551\n",
      "Epoch 527/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 183.8059 - val_loss: 140.7883\n",
      "Epoch 528/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 198.6356 - val_loss: 164.6517\n",
      "Epoch 529/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 192.4989 - val_loss: 313.6497\n",
      "Epoch 530/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 225.5929 - val_loss: 151.1118\n",
      "Epoch 531/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 165.4828 - val_loss: 129.5629\n",
      "Epoch 532/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 144.4372 - val_loss: 136.6747\n",
      "Epoch 533/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 159.3681 - val_loss: 170.8282\n",
      "Epoch 534/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 173.9005 - val_loss: 192.0216\n",
      "Epoch 535/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 179.0342 - val_loss: 131.1115\n",
      "Epoch 536/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 148.5997 - val_loss: 139.8207\n",
      "Epoch 537/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 132.4535 - val_loss: 115.4218\n",
      "Epoch 538/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 142.1982 - val_loss: 107.3281\n",
      "Epoch 539/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 107.2063 - val_loss: 104.3904\n",
      "Epoch 540/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 168.9119 - val_loss: 316.8057\n",
      "Epoch 541/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 248.1165 - val_loss: 192.3815\n",
      "Epoch 542/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 193.5114 - val_loss: 206.1421\n",
      "Epoch 543/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 212.2262 - val_loss: 252.4989\n",
      "Epoch 544/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 170.0981 - val_loss: 213.3952\n",
      "Epoch 545/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 174.4870 - val_loss: 148.6152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 138.5028 - val_loss: 119.3570\n",
      "Epoch 547/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 142.0309 - val_loss: 128.0063\n",
      "Epoch 548/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 206.1654 - val_loss: 159.9747\n",
      "Epoch 549/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 163.8553 - val_loss: 125.6181\n",
      "Epoch 550/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 148.2386 - val_loss: 111.4776\n",
      "Epoch 551/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 178.4081 - val_loss: 147.6167\n",
      "Epoch 552/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 159.6456 - val_loss: 167.8409\n",
      "Epoch 553/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 145.4428 - val_loss: 151.1346\n",
      "Epoch 554/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 170.2217 - val_loss: 94.0330\n",
      "Epoch 555/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 199.2716 - val_loss: 122.6670\n",
      "Epoch 556/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 133.9956 - val_loss: 144.2595\n",
      "Epoch 557/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 138.9395 - val_loss: 131.9871\n",
      "Epoch 558/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 122.8139 - val_loss: 150.4290\n",
      "Epoch 559/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 131.9526 - val_loss: 144.3736\n",
      "Epoch 560/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 141.4741 - val_loss: 135.2385\n",
      "Epoch 561/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 128.5032 - val_loss: 100.2265\n",
      "Epoch 562/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 117.6528 - val_loss: 219.1651\n",
      "Epoch 563/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 161.2013 - val_loss: 293.3695\n",
      "Epoch 564/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 227.7875 - val_loss: 148.0907\n",
      "Epoch 565/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 174.7812 - val_loss: 158.0108\n",
      "Epoch 566/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 171.7982 - val_loss: 146.9187\n",
      "Epoch 567/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 168.2669 - val_loss: 270.2573\n",
      "Epoch 568/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 194.7197 - val_loss: 238.9989\n",
      "Epoch 569/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 202.2520 - val_loss: 205.4908\n",
      "Epoch 570/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 190.3015 - val_loss: 156.8682\n",
      "Epoch 571/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 144.8401 - val_loss: 137.9209\n",
      "Epoch 572/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 158.5391 - val_loss: 239.8581\n",
      "Epoch 573/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 238.6451 - val_loss: 163.2974\n",
      "Epoch 574/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 150.3388 - val_loss: 106.4840\n",
      "Epoch 575/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 123.3897 - val_loss: 137.5960\n",
      "Epoch 576/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 114.2182 - val_loss: 146.6257\n",
      "Epoch 577/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 155.7982 - val_loss: 138.9973\n",
      "Epoch 578/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 118.7557 - val_loss: 124.5766\n",
      "Epoch 579/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 120.8622 - val_loss: 180.2610\n",
      "Epoch 580/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 177.7818 - val_loss: 288.9836\n",
      "Epoch 581/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 226.3800 - val_loss: 191.8710\n",
      "Epoch 582/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 214.5891 - val_loss: 143.9430\n",
      "Epoch 583/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 140.2559 - val_loss: 145.7655\n",
      "Epoch 584/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 131.4787 - val_loss: 198.7378\n",
      "Epoch 585/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 108.0640 - val_loss: 194.6242\n",
      "Epoch 586/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 141.0159 - val_loss: 93.5663\n",
      "Epoch 587/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 126.9257 - val_loss: 196.8850\n",
      "Epoch 588/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 161.7509 - val_loss: 210.1481\n",
      "Epoch 589/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 250.9027 - val_loss: 198.9464\n",
      "Epoch 590/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 167.1562 - val_loss: 178.2270\n",
      "Epoch 591/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 160.6962 - val_loss: 143.5443\n",
      "Epoch 592/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 105.0826 - val_loss: 236.5325\n",
      "Epoch 593/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 313.2217 - val_loss: 108.5373\n",
      "Epoch 594/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 130.3407 - val_loss: 251.6660\n",
      "Epoch 595/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 376.7805 - val_loss: 333.3920\n",
      "Epoch 596/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 295.4265 - val_loss: 299.8089\n",
      "Epoch 597/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 244.9253 - val_loss: 195.5976\n",
      "Epoch 598/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 190.7996 - val_loss: 230.0994\n",
      "Epoch 599/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 217.6114 - val_loss: 237.8167\n",
      "Epoch 600/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 205.9722 - val_loss: 275.0122\n",
      "Epoch 601/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 242.3960 - val_loss: 223.6602\n",
      "Epoch 602/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 169.5148 - val_loss: 179.1873\n",
      "Epoch 603/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 160.2884 - val_loss: 196.8018\n",
      "Epoch 604/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 232.0321 - val_loss: 288.7946\n",
      "Epoch 605/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 227.5911 - val_loss: 278.2766\n",
      "Epoch 606/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 243.5215 - val_loss: 237.2777\n",
      "Epoch 607/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 245.9100 - val_loss: 223.8560\n",
      "Epoch 608/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 193.8540 - val_loss: 231.7062\n",
      "Epoch 609/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 213.9956 - val_loss: 203.5927\n",
      "Epoch 610/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 177.5356 - val_loss: 231.2611\n",
      "Epoch 611/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 214.9021 - val_loss: 220.7054\n",
      "Epoch 612/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 187.4845 - val_loss: 270.3238\n",
      "Epoch 613/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 275.5367 - val_loss: 131.5831\n",
      "Epoch 614/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 181.5463 - val_loss: 189.6572\n",
      "Epoch 615/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 238.8704 - val_loss: 189.5435\n",
      "Epoch 616/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 221.8779 - val_loss: 162.3940\n",
      "Epoch 617/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 150.7914 - val_loss: 176.4356\n",
      "Epoch 618/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 162.7710 - val_loss: 260.2430\n",
      "Epoch 619/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 200.9926 - val_loss: 185.2837\n",
      "Epoch 620/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 144.9665 - val_loss: 139.5802\n",
      "Epoch 621/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 150.5645 - val_loss: 197.3564\n",
      "Epoch 622/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 237.5394 - val_loss: 143.5654\n",
      "Epoch 623/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 135.8351 - val_loss: 224.5219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 624/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 126.9654 - val_loss: 182.2182\n",
      "Epoch 625/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 127.3357 - val_loss: 140.9307\n",
      "Epoch 626/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 122.8961 - val_loss: 256.7352\n",
      "Epoch 627/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 190.2558 - val_loss: 233.1458\n",
      "Epoch 628/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 227.8915 - val_loss: 480.9135\n",
      "Epoch 629/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 371.1112 - val_loss: 214.6647\n",
      "Epoch 630/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 230.0567 - val_loss: 189.9628\n",
      "Epoch 631/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 182.0632 - val_loss: 256.6334\n",
      "Epoch 632/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 311.5486 - val_loss: 201.5620\n",
      "Epoch 633/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 191.2147 - val_loss: 175.2138\n",
      "Epoch 634/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 200.1805 - val_loss: 185.8130\n",
      "Epoch 635/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 167.8091 - val_loss: 174.0662\n",
      "Epoch 636/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 155.3888 - val_loss: 193.7104\n",
      "Epoch 637/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 163.4295 - val_loss: 286.3398\n",
      "Epoch 638/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 177.7357 - val_loss: 184.7931\n",
      "Epoch 639/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 222.7417 - val_loss: 165.3110\n",
      "Epoch 640/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 182.0437 - val_loss: 179.1258\n",
      "Epoch 641/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 180.0417 - val_loss: 172.6940\n",
      "Epoch 642/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 162.2944 - val_loss: 124.6103\n",
      "Epoch 643/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 195.1973 - val_loss: 211.8944\n",
      "Epoch 644/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 216.0101 - val_loss: 128.7695\n",
      "Epoch 645/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 174.1829 - val_loss: 134.0620\n",
      "Epoch 646/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 174.2151 - val_loss: 140.8999\n",
      "Epoch 647/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 155.9185 - val_loss: 133.7297\n",
      "Epoch 648/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 188.0499 - val_loss: 369.0410\n",
      "Epoch 649/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 214.6417 - val_loss: 124.5814\n",
      "Epoch 650/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 150.9996 - val_loss: 129.4230\n",
      "Epoch 651/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 222.9385 - val_loss: 198.5477\n",
      "Epoch 652/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 213.7731 - val_loss: 185.5839\n",
      "Epoch 653/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 181.8548 - val_loss: 331.7303\n",
      "Epoch 654/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 223.9347 - val_loss: 191.8619\n",
      "Epoch 655/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 191.5916 - val_loss: 165.0317\n",
      "Epoch 656/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 197.4922 - val_loss: 153.9150\n",
      "Epoch 657/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 168.8179 - val_loss: 169.1232\n",
      "Epoch 658/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 172.8894 - val_loss: 127.2140\n",
      "Epoch 659/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 140.2921 - val_loss: 212.1322\n",
      "Epoch 660/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 158.8388 - val_loss: 139.5820\n",
      "Epoch 661/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 163.0841 - val_loss: 205.4042\n",
      "Epoch 662/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 162.0894 - val_loss: 140.8180\n",
      "Epoch 663/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 137.3046 - val_loss: 147.0802\n",
      "Epoch 664/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 155.2005 - val_loss: 150.3109\n",
      "Epoch 665/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 150.5587 - val_loss: 118.5145\n",
      "Epoch 666/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 175.4769 - val_loss: 298.1505\n",
      "Epoch 667/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 285.2773 - val_loss: 230.7251\n",
      "Epoch 668/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 197.0961 - val_loss: 153.3370\n",
      "Epoch 669/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 171.7653 - val_loss: 157.7849\n",
      "Epoch 670/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 157.1743 - val_loss: 172.6606\n",
      "Epoch 671/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 160.0951 - val_loss: 105.4691\n",
      "Epoch 672/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 160.5778 - val_loss: 111.7082\n",
      "Epoch 673/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 157.7906 - val_loss: 233.6391\n",
      "Epoch 674/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 191.0289 - val_loss: 133.8542\n",
      "Epoch 675/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 157.6737 - val_loss: 150.8960\n",
      "Epoch 676/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 162.8262 - val_loss: 194.3656\n",
      "Epoch 677/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 184.1192 - val_loss: 104.6086\n",
      "Epoch 678/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 157.4897 - val_loss: 136.2106\n",
      "Epoch 679/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 140.9663 - val_loss: 162.0481\n",
      "Epoch 680/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 158.9406 - val_loss: 107.4332\n",
      "Epoch 681/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 198.6671 - val_loss: 118.3834\n",
      "Epoch 682/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 164.5573 - val_loss: 145.6275\n",
      "Epoch 683/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 137.6680 - val_loss: 80.0841\n",
      "Epoch 684/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 118.9688 - val_loss: 106.1971\n",
      "Epoch 685/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 114.1751 - val_loss: 151.1886\n",
      "Epoch 686/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 185.0564 - val_loss: 139.0733\n",
      "Epoch 687/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 148.6426 - val_loss: 110.6495\n",
      "Epoch 688/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 162.8167 - val_loss: 221.9123\n",
      "Epoch 689/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 166.6155 - val_loss: 110.4268\n",
      "Epoch 690/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 150.8227 - val_loss: 76.1050\n",
      "Epoch 691/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 126.3698 - val_loss: 91.7148\n",
      "Epoch 692/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 124.1455 - val_loss: 120.8357\n",
      "Epoch 693/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 108.6034 - val_loss: 253.7744\n",
      "Epoch 694/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 238.6800 - val_loss: 85.8852\n",
      "Epoch 695/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 131.3694 - val_loss: 70.8808\n",
      "Epoch 696/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 109.4461 - val_loss: 84.7961\n",
      "Epoch 697/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 152.6395 - val_loss: 120.6884\n",
      "Epoch 698/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 182.3540 - val_loss: 141.3766\n",
      "Epoch 699/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 152.2651 - val_loss: 99.6471\n",
      "Epoch 700/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 118.5788 - val_loss: 104.4435\n",
      "Epoch 701/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 148.8344 - val_loss: 245.7304\n",
      "Epoch 702/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 160.2755 - val_loss: 72.8682\n",
      "Epoch 703/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 109.1040 - val_loss: 105.9529\n",
      "Epoch 704/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 114.7611 - val_loss: 111.3284\n",
      "Epoch 705/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 113.7458 - val_loss: 102.8601\n",
      "Epoch 706/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 125.5856 - val_loss: 39.1573\n",
      "Epoch 707/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 128.0131 - val_loss: 100.1601\n",
      "Epoch 708/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 141.7458 - val_loss: 77.7163\n",
      "Epoch 709/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 102.5110 - val_loss: 83.6188\n",
      "Epoch 710/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 105.9025 - val_loss: 122.7660\n",
      "Epoch 711/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 245.0349 - val_loss: 202.3255\n",
      "Epoch 712/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 234.4286 - val_loss: 195.7146\n",
      "Epoch 713/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 225.1033 - val_loss: 222.6364\n",
      "Epoch 714/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 215.2626 - val_loss: 141.0254\n",
      "Epoch 715/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 175.2306 - val_loss: 111.3799\n",
      "Epoch 716/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 173.2476 - val_loss: 153.4996\n",
      "Epoch 717/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 189.9917 - val_loss: 110.0852\n",
      "Epoch 718/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 182.2664 - val_loss: 685.1415\n",
      "Epoch 719/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 448.1257 - val_loss: 208.5954\n",
      "Epoch 720/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 233.4175 - val_loss: 236.8049\n",
      "Epoch 721/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 201.8409 - val_loss: 212.9359\n",
      "Epoch 722/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 167.1734 - val_loss: 160.0460\n",
      "Epoch 723/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 179.3233 - val_loss: 203.4311\n",
      "Epoch 724/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 198.7076 - val_loss: 146.7162\n",
      "Epoch 725/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 153.8441 - val_loss: 120.7248\n",
      "Epoch 726/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 226.6061 - val_loss: 203.4250\n",
      "Epoch 727/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 160.6774 - val_loss: 137.7565\n",
      "Epoch 728/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 154.2546 - val_loss: 163.0532\n",
      "Epoch 729/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 208.0470 - val_loss: 191.8382\n",
      "Epoch 730/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 158.5813 - val_loss: 135.5042\n",
      "Epoch 731/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 155.0320 - val_loss: 222.8368\n",
      "Epoch 732/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 191.2216 - val_loss: 184.8236\n",
      "Epoch 733/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 170.3568 - val_loss: 224.8039\n",
      "Epoch 734/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 202.8842 - val_loss: 204.2265\n",
      "Epoch 735/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 183.2226 - val_loss: 209.7058\n",
      "Epoch 736/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 155.0137 - val_loss: 203.5272\n",
      "Epoch 737/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 135.0766 - val_loss: 189.8605\n",
      "Epoch 738/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 126.1994 - val_loss: 165.2293\n",
      "Epoch 739/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 137.2165 - val_loss: 196.0186\n",
      "Epoch 740/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 135.5535 - val_loss: 234.3958\n",
      "Epoch 741/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 167.6720 - val_loss: 378.1723\n",
      "Epoch 742/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 265.0043 - val_loss: 191.8873\n",
      "Epoch 743/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 194.4090 - val_loss: 197.8766\n",
      "Epoch 744/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 214.8046 - val_loss: 165.9037\n",
      "Epoch 745/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 163.5075 - val_loss: 180.5617\n",
      "Epoch 746/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 189.8135 - val_loss: 157.5856\n",
      "Epoch 747/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 148.9320 - val_loss: 196.2183\n",
      "Epoch 748/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 136.7705 - val_loss: 217.2165\n",
      "Epoch 749/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 120.5569 - val_loss: 176.8033\n",
      "Epoch 750/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 167.4344 - val_loss: 170.9169\n",
      "Epoch 751/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 159.5242 - val_loss: 162.2360\n",
      "Epoch 752/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 181.8978 - val_loss: 194.1270\n",
      "Epoch 753/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 128.4592 - val_loss: 193.2278\n",
      "Epoch 754/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 114.7566 - val_loss: 231.0775\n",
      "Epoch 755/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 147.7117 - val_loss: 200.8264\n",
      "Epoch 756/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 105.7505 - val_loss: 218.8044\n",
      "Epoch 757/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 121.4472 - val_loss: 207.5223\n",
      "Epoch 758/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 168.4904 - val_loss: 134.2243\n",
      "Epoch 759/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 135.5895 - val_loss: 209.5672\n",
      "Epoch 760/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 132.3212 - val_loss: 217.5883\n",
      "Epoch 761/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 106.6174 - val_loss: 234.4547\n",
      "Epoch 762/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 104.8743 - val_loss: 197.7274\n",
      "Epoch 763/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 137.7509 - val_loss: 220.8854\n",
      "Epoch 764/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 121.3445 - val_loss: 269.5887\n",
      "Epoch 765/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 167.0338 - val_loss: 159.8910\n",
      "Epoch 766/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 130.4350 - val_loss: 171.9184\n",
      "Epoch 767/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 148.9296 - val_loss: 134.1682\n",
      "Epoch 768/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 164.2014 - val_loss: 197.0673\n",
      "Epoch 769/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 160.6779 - val_loss: 136.2881\n",
      "Epoch 770/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 130.2297 - val_loss: 131.7069\n",
      "Epoch 771/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 134.5742 - val_loss: 186.8611\n",
      "Epoch 772/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 112.7143 - val_loss: 262.0754\n",
      "Epoch 773/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 124.0511 - val_loss: 192.3829\n",
      "Epoch 774/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 121.5265 - val_loss: 202.4742\n",
      "Epoch 775/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 102.7700 - val_loss: 207.1477\n",
      "Epoch 776/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 109.0814 - val_loss: 221.7254\n",
      "Epoch 777/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 106.8269 - val_loss: 226.3933\n",
      "Epoch 778/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 205.4471 - val_loss: 146.1107\n",
      "Epoch 779/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 134.1365 - val_loss: 156.3936\n",
      "Epoch 780/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 105.4667 - val_loss: 218.6076\n",
      "Epoch 781/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 203.6192 - val_loss: 187.3440\n",
      "Epoch 782/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 152.5301 - val_loss: 114.3165\n",
      "Epoch 783/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 149.0766 - val_loss: 156.3351\n",
      "Epoch 784/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 156.0476 - val_loss: 150.7148\n",
      "Epoch 785/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 91.0481 - val_loss: 199.2267\n",
      "Epoch 786/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 150.1646 - val_loss: 155.1369\n",
      "Epoch 787/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 109.2461 - val_loss: 170.1185\n",
      "Epoch 788/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 91.1288 - val_loss: 151.0787\n",
      "Epoch 789/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 103.3760 - val_loss: 217.7228\n",
      "Epoch 790/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 105.0020 - val_loss: 240.4967\n",
      "Epoch 791/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 108.7069 - val_loss: 180.7048\n",
      "Epoch 792/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 100.2974 - val_loss: 184.8179\n",
      "Epoch 793/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 91.9160 - val_loss: 187.7583\n",
      "Epoch 794/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 98.0386 - val_loss: 192.1633\n",
      "Epoch 795/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 88.1360 - val_loss: 167.1743\n",
      "Epoch 796/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 100.1977 - val_loss: 158.9967\n",
      "Epoch 797/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 82.5157 - val_loss: 231.2738\n",
      "Epoch 798/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 86.0320 - val_loss: 240.6470\n",
      "Epoch 799/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 96.3699 - val_loss: 136.9142\n",
      "Epoch 800/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 111.4144 - val_loss: 171.3000\n",
      "Epoch 801/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 86.4358 - val_loss: 266.6303\n",
      "Epoch 802/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 107.7871 - val_loss: 172.5153\n",
      "Epoch 803/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 77.3806 - val_loss: 188.7312\n",
      "Epoch 804/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 84.1559 - val_loss: 191.0439\n",
      "Epoch 805/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 84.6021 - val_loss: 212.9274\n",
      "Epoch 806/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 74.4179 - val_loss: 255.5280\n",
      "Epoch 807/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 116.8008 - val_loss: 225.2332\n",
      "Epoch 808/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 107.9108 - val_loss: 283.9380\n",
      "Epoch 809/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 190.5004 - val_loss: 161.1962\n",
      "Epoch 810/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 116.7764 - val_loss: 200.7494\n",
      "Epoch 811/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 165.0350 - val_loss: 170.6807\n",
      "Epoch 812/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 170.6276 - val_loss: 161.9937\n",
      "Epoch 813/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 213.5817 - val_loss: 229.1234\n",
      "Epoch 814/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 218.0367 - val_loss: 157.8757\n",
      "Epoch 815/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 154.7922 - val_loss: 149.7438\n",
      "Epoch 816/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 136.1808 - val_loss: 203.7752\n",
      "Epoch 817/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 153.9925 - val_loss: 183.6751\n",
      "Epoch 818/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 132.8220 - val_loss: 169.9105\n",
      "Epoch 819/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 118.8224 - val_loss: 224.5320\n",
      "Epoch 820/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 155.2546 - val_loss: 168.2289\n",
      "Epoch 821/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 239.1849 - val_loss: 153.0414\n",
      "Epoch 822/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 175.4582 - val_loss: 235.0827\n",
      "Epoch 823/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 153.1483 - val_loss: 185.2843\n",
      "Epoch 824/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 124.4606 - val_loss: 137.5513\n",
      "Epoch 825/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 116.9396 - val_loss: 142.4340\n",
      "Epoch 826/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 116.1417 - val_loss: 164.7809\n",
      "Epoch 827/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 114.8304 - val_loss: 229.3500\n",
      "Epoch 828/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 122.6380 - val_loss: 212.7086\n",
      "Epoch 829/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 123.2415 - val_loss: 161.5351\n",
      "Epoch 830/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 117.9932 - val_loss: 189.0620\n",
      "Epoch 831/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 154.2700 - val_loss: 172.7275\n",
      "Epoch 832/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 170.1633 - val_loss: 118.4977\n",
      "Epoch 833/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 152.0337 - val_loss: 127.6157\n",
      "Epoch 834/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 110.1673 - val_loss: 405.3712\n",
      "Epoch 835/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 310.0260 - val_loss: 153.4489\n",
      "Epoch 836/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 154.3705 - val_loss: 143.0361\n",
      "Epoch 837/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 156.1498 - val_loss: 149.4901\n",
      "Epoch 838/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 125.4099 - val_loss: 104.8617\n",
      "Epoch 839/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 110.0208 - val_loss: 162.0960\n",
      "Epoch 840/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 109.2957 - val_loss: 143.0311\n",
      "Epoch 841/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 92.6517 - val_loss: 195.2966\n",
      "Epoch 842/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 91.7402 - val_loss: 178.6873\n",
      "Epoch 843/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 89.9062 - val_loss: 154.0997\n",
      "Epoch 844/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 84.1943 - val_loss: 100.3695\n",
      "Epoch 845/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 114.2532 - val_loss: 261.7985\n",
      "Epoch 846/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 255.7043 - val_loss: 180.5659\n",
      "Epoch 847/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 184.5701 - val_loss: 269.4275\n",
      "Epoch 848/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 213.5661 - val_loss: 150.7020\n",
      "Epoch 849/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 142.9716 - val_loss: 148.0006\n",
      "Epoch 850/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 132.4385 - val_loss: 177.1093\n",
      "Epoch 851/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 113.1806 - val_loss: 182.8090\n",
      "Epoch 852/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 114.5846 - val_loss: 162.0761\n",
      "Epoch 853/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 112.7850 - val_loss: 170.3711\n",
      "Epoch 854/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 160.7973 - val_loss: 183.5527\n",
      "Epoch 855/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 177.0342 - val_loss: 138.1596\n",
      "Epoch 856/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 170.8955 - val_loss: 193.1984\n",
      "Epoch 857/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 115.6544 - val_loss: 157.6500\n",
      "Epoch 858/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 125.2619 - val_loss: 198.1733\n",
      "Epoch 859/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 111.1029 - val_loss: 136.7952\n",
      "Epoch 860/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 103.9512 - val_loss: 213.8112\n",
      "Epoch 861/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 116.5233 - val_loss: 190.7352\n",
      "Epoch 862/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 107.6816 - val_loss: 165.4465\n",
      "Epoch 863/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 109.8935 - val_loss: 200.3537\n",
      "Epoch 864/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 105.5207 - val_loss: 194.8732\n",
      "Epoch 865/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 146.6635 - val_loss: 197.6932\n",
      "Epoch 866/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 178.8868 - val_loss: 162.4156\n",
      "Epoch 867/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 194.6923 - val_loss: 138.1659\n",
      "Epoch 868/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 151.1106 - val_loss: 202.5569\n",
      "Epoch 869/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 170.3556 - val_loss: 207.5080\n",
      "Epoch 870/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 168.2692 - val_loss: 143.1229\n",
      "Epoch 871/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 141.8646 - val_loss: 208.9233\n",
      "Epoch 872/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 212.8491 - val_loss: 211.7488\n",
      "Epoch 873/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 199.2970 - val_loss: 143.1319\n",
      "Epoch 874/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 175.2543 - val_loss: 172.1476\n",
      "Epoch 875/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 186.1758 - val_loss: 131.2264\n",
      "Epoch 876/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 170.2308 - val_loss: 229.1285\n",
      "Epoch 877/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 260.4663 - val_loss: 234.4061\n",
      "Epoch 878/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 171.1624 - val_loss: 121.7202\n",
      "Epoch 879/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 162.1035 - val_loss: 132.0447\n",
      "Epoch 880/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 146.4608 - val_loss: 168.5020\n",
      "Epoch 881/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 176.3188 - val_loss: 135.0737\n",
      "Epoch 882/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 145.9186 - val_loss: 139.6822\n",
      "Epoch 883/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 146.0283 - val_loss: 129.8251\n",
      "Epoch 884/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 119.4640 - val_loss: 115.1535\n",
      "Epoch 885/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 134.6618 - val_loss: 178.4744\n",
      "Epoch 886/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 107.2396 - val_loss: 154.0083\n",
      "Epoch 887/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 149.6162 - val_loss: 160.0633\n",
      "Epoch 888/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 99.8906 - val_loss: 159.5649\n",
      "Epoch 889/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 113.3435 - val_loss: 227.5848\n",
      "Epoch 890/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 107.9267 - val_loss: 165.1542\n",
      "Epoch 891/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 94.7346 - val_loss: 190.8428\n",
      "Epoch 892/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 102.9612 - val_loss: 157.5538\n",
      "Epoch 893/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 102.4022 - val_loss: 173.1581\n",
      "Epoch 894/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 115.0919 - val_loss: 135.9779\n",
      "Epoch 895/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 100.4677 - val_loss: 191.8076\n",
      "Epoch 896/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 97.3034 - val_loss: 160.4913\n",
      "Epoch 897/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 92.4597 - val_loss: 182.1244\n",
      "Epoch 898/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 99.8787 - val_loss: 142.6484\n",
      "Epoch 899/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 95.9554 - val_loss: 171.5493\n",
      "Epoch 900/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 98.1551 - val_loss: 179.3674\n",
      "Epoch 901/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 85.7327 - val_loss: 209.7824\n",
      "Epoch 902/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 105.5364 - val_loss: 160.5677\n",
      "Epoch 903/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 166.9051 - val_loss: 183.5217\n",
      "Epoch 904/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 100.2560 - val_loss: 202.8583\n",
      "Epoch 905/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 94.2039 - val_loss: 185.1761\n",
      "Epoch 906/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 92.1170 - val_loss: 172.1970\n",
      "Epoch 907/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 86.3281 - val_loss: 179.5930\n",
      "Epoch 908/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 85.5132 - val_loss: 184.8699\n",
      "Epoch 909/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 83.0591 - val_loss: 170.1362\n",
      "Epoch 910/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 88.2190 - val_loss: 206.7570\n",
      "Epoch 911/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 91.4890 - val_loss: 245.4159\n",
      "Epoch 912/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 94.1135 - val_loss: 193.6791\n",
      "Epoch 913/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 91.1635 - val_loss: 157.7136\n",
      "Epoch 914/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 102.6638 - val_loss: 211.3241\n",
      "Epoch 915/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 93.6348 - val_loss: 177.6897\n",
      "Epoch 916/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 81.7457 - val_loss: 163.1846\n",
      "Epoch 917/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 90.7914 - val_loss: 158.6881\n",
      "Epoch 918/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 82.5806 - val_loss: 201.5468\n",
      "Epoch 919/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 81.6783 - val_loss: 230.4790\n",
      "Epoch 920/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 81.3491 - val_loss: 225.8668\n",
      "Epoch 921/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 90.8814 - val_loss: 184.6889\n",
      "Epoch 922/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 145.5769 - val_loss: 160.2558\n",
      "Epoch 923/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 111.0964 - val_loss: 219.5647\n",
      "Epoch 924/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 108.2091 - val_loss: 316.0976\n",
      "Epoch 925/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 190.1892 - val_loss: 144.6009\n",
      "Epoch 926/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 129.2073 - val_loss: 176.5927\n",
      "Epoch 927/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 117.3583 - val_loss: 182.9958\n",
      "Epoch 928/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 168.7002 - val_loss: 179.4797\n",
      "Epoch 929/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 223.2857 - val_loss: 106.4600\n",
      "Epoch 930/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 192.1759 - val_loss: 157.0827\n",
      "Epoch 931/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 171.6194 - val_loss: 127.8931\n",
      "Epoch 932/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 167.1671 - val_loss: 120.4077\n",
      "Epoch 933/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 154.4262 - val_loss: 115.0108\n",
      "Epoch 934/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 192.4158 - val_loss: 176.0369\n",
      "Epoch 935/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 140.7259 - val_loss: 126.6731\n",
      "Epoch 936/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 154.2969 - val_loss: 102.3070\n",
      "Epoch 937/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 148.6443 - val_loss: 182.6958\n",
      "Epoch 938/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 122.7052 - val_loss: 107.8075\n",
      "Epoch 939/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 131.1513 - val_loss: 119.8459\n",
      "Epoch 940/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 92.9123 - val_loss: 136.0536\n",
      "Epoch 941/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 74.7991 - val_loss: 164.9902\n",
      "Epoch 942/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 76.8878 - val_loss: 153.8070\n",
      "Epoch 943/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 97.5419 - val_loss: 211.2732\n",
      "Epoch 944/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 107.3646 - val_loss: 159.0184\n",
      "Epoch 945/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 76.2382 - val_loss: 154.8667\n",
      "Epoch 946/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 70.8763 - val_loss: 140.0893\n",
      "Epoch 947/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 92.5564 - val_loss: 194.4063\n",
      "Epoch 948/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 76.2137 - val_loss: 154.9192\n",
      "Epoch 949/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 84.9194 - val_loss: 171.1071\n",
      "Epoch 950/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 76.2329 - val_loss: 178.8192\n",
      "Epoch 951/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 72.8064 - val_loss: 157.6131\n",
      "Epoch 952/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 71.0438 - val_loss: 170.7375\n",
      "Epoch 953/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 83.5885 - val_loss: 175.5534\n",
      "Epoch 954/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 87.6331 - val_loss: 151.6385\n",
      "Epoch 955/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 73.2414 - val_loss: 134.5287\n",
      "Epoch 956/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 57.7180 - val_loss: 157.0482\n",
      "Epoch 957/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 64.2380 - val_loss: 161.0605\n",
      "Epoch 958/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 72.9528 - val_loss: 149.3770\n",
      "Epoch 959/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 69.2240 - val_loss: 141.9626\n",
      "Epoch 960/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 55.2086 - val_loss: 163.9784\n",
      "Epoch 961/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 56.4712 - val_loss: 121.8691\n",
      "Epoch 962/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 61.5732 - val_loss: 258.1420\n",
      "Epoch 963/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 90.7154 - val_loss: 175.3600\n",
      "Epoch 964/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 60.0581 - val_loss: 175.2381\n",
      "Epoch 965/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 57.8507 - val_loss: 162.3220\n",
      "Epoch 966/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 57.0152 - val_loss: 141.9039\n",
      "Epoch 967/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 59.6214 - val_loss: 199.7482\n",
      "Epoch 968/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 78.7332 - val_loss: 131.2699\n",
      "Epoch 969/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 77.4241 - val_loss: 121.5581\n",
      "Epoch 970/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 67.7814 - val_loss: 170.9112\n",
      "Epoch 971/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 69.8732 - val_loss: 164.0273\n",
      "Epoch 972/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 73.4416 - val_loss: 179.5782\n",
      "Epoch 973/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 66.9950 - val_loss: 164.2205\n",
      "Epoch 974/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 61.1669 - val_loss: 125.6315\n",
      "Epoch 975/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 59.3285 - val_loss: 210.7319\n",
      "Epoch 976/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 74.7553 - val_loss: 152.3860\n",
      "Epoch 977/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 62.1506 - val_loss: 186.0112\n",
      "Epoch 978/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 74.5455 - val_loss: 111.2445\n",
      "Epoch 979/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 69.8859 - val_loss: 157.2685\n",
      "Epoch 980/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 53.3234 - val_loss: 168.1180\n",
      "Epoch 981/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 68.9871 - val_loss: 171.7911\n",
      "Epoch 982/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 59.9278 - val_loss: 144.0786\n",
      "Epoch 983/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 64.6090 - val_loss: 199.8092\n",
      "Epoch 984/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 66.5654 - val_loss: 170.7565\n",
      "Epoch 985/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 57.9757 - val_loss: 150.0059\n",
      "Epoch 986/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 65.0766 - val_loss: 163.2759\n",
      "Epoch 987/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 53.0814 - val_loss: 148.3840\n",
      "Epoch 988/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 51.0640 - val_loss: 159.0083\n",
      "Epoch 989/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 56.5605 - val_loss: 128.2175\n",
      "Epoch 990/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 51.0030 - val_loss: 166.2907\n",
      "Epoch 991/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 61.7157 - val_loss: 148.6750\n",
      "Epoch 992/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 51.7750 - val_loss: 128.4734\n",
      "Epoch 993/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 80.3668 - val_loss: 164.7870\n",
      "Epoch 994/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 59.6029 - val_loss: 172.3688\n",
      "Epoch 995/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 89.4229 - val_loss: 350.0937\n",
      "Epoch 996/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 160.0403 - val_loss: 203.9087\n",
      "Epoch 997/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 70.3678 - val_loss: 174.7999\n",
      "Epoch 998/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 85.5353 - val_loss: 177.0896\n",
      "Epoch 999/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 78.8291 - val_loss: 172.3059\n",
      "Epoch 1000/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 99.5862 - val_loss: 123.2969\n",
      "Epoch 1001/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 136.0007 - val_loss: 291.8598\n",
      "Epoch 1002/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 198.1251 - val_loss: 186.0040\n",
      "Epoch 1003/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 145.4895 - val_loss: 157.8033\n",
      "Epoch 1004/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 102.7385 - val_loss: 137.0244\n",
      "Epoch 1005/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 162.4948 - val_loss: 145.4099\n",
      "Epoch 1006/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 87.9791 - val_loss: 172.4748\n",
      "Epoch 1007/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 73.8985 - val_loss: 198.2362\n",
      "Epoch 1008/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 75.7624 - val_loss: 155.6326\n",
      "Epoch 1009/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 64.9648 - val_loss: 207.2980\n",
      "Epoch 1010/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 77.0943 - val_loss: 210.2109\n",
      "Epoch 1011/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 71.6722 - val_loss: 185.6099\n",
      "Epoch 1012/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 71.6331 - val_loss: 187.4899\n",
      "Epoch 1013/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 71.3615 - val_loss: 143.8183\n",
      "Epoch 1014/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 69.9022 - val_loss: 169.9059\n",
      "Epoch 1015/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 75.0203 - val_loss: 162.5035\n",
      "Epoch 1016/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 55.2065 - val_loss: 156.7627\n",
      "Epoch 1017/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 70.3150 - val_loss: 205.9842\n",
      "Epoch 1018/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 58.9771 - val_loss: 203.8793\n",
      "Epoch 1019/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 68.0256 - val_loss: 196.3310\n",
      "Epoch 1020/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 83.0410 - val_loss: 232.0625\n",
      "Epoch 1021/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 74.3907 - val_loss: 185.7251\n",
      "Epoch 1022/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 67.0615 - val_loss: 144.1176\n",
      "Epoch 1023/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 57.6390 - val_loss: 200.7000\n",
      "Epoch 1024/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 96.3248 - val_loss: 167.4510\n",
      "Epoch 1025/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 85.4666 - val_loss: 223.4830\n",
      "Epoch 1026/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 69.7183 - val_loss: 212.9792\n",
      "Epoch 1027/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 76.9700 - val_loss: 143.1836\n",
      "Epoch 1028/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 58.9330 - val_loss: 152.5992\n",
      "Epoch 1029/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 60.1311 - val_loss: 149.8385\n",
      "Epoch 1030/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 58.6288 - val_loss: 276.1712\n",
      "Epoch 1031/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 95.9033 - val_loss: 193.5945\n",
      "Epoch 1032/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 80.7795 - val_loss: 242.4359\n",
      "Epoch 1033/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 79.1950 - val_loss: 201.0559\n",
      "Epoch 1034/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 71.4666 - val_loss: 165.3737\n",
      "Epoch 1035/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 61.0467 - val_loss: 141.2579\n",
      "Epoch 1036/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 50.1604 - val_loss: 191.8812\n",
      "Epoch 1037/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 56.1404 - val_loss: 152.8513\n",
      "Epoch 1038/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 59.9684 - val_loss: 148.1564\n",
      "Epoch 1039/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 55.7212 - val_loss: 121.1237\n",
      "Epoch 1040/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 61.3244 - val_loss: 176.1124\n",
      "Epoch 1041/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 53.8235 - val_loss: 169.4629\n",
      "Epoch 1042/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 53.2657 - val_loss: 203.5757\n",
      "Epoch 1043/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 60.3236 - val_loss: 171.5427\n",
      "Epoch 1044/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 58.5359 - val_loss: 160.4349\n",
      "Epoch 1045/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 44.9401 - val_loss: 156.1534\n",
      "Epoch 1046/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 57.0071 - val_loss: 219.2445\n",
      "Epoch 1047/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 190.4781 - val_loss: 192.7824\n",
      "Epoch 1048/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 131.2883 - val_loss: 216.4656\n",
      "Epoch 1049/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 137.5599 - val_loss: 207.3640\n",
      "Epoch 1050/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 101.7119 - val_loss: 178.7628\n",
      "Epoch 1051/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 95.1767 - val_loss: 174.1866\n",
      "Epoch 1052/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 92.0599 - val_loss: 175.8740\n",
      "Epoch 1053/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 86.4772 - val_loss: 190.2053\n",
      "Epoch 1054/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 88.5774 - val_loss: 178.3822\n",
      "Epoch 1055/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 82.6011 - val_loss: 201.2884\n",
      "Epoch 1056/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 82.9427 - val_loss: 183.2613\n",
      "Epoch 1057/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 83.2792 - val_loss: 164.7374\n",
      "Epoch 1058/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 77.6708 - val_loss: 177.5221\n",
      "Epoch 1059/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 83.3778 - val_loss: 179.4104\n",
      "Epoch 1060/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 68.8384 - val_loss: 151.3676\n",
      "Epoch 1061/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 72.1830 - val_loss: 191.8236\n",
      "Epoch 1062/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 72.7738 - val_loss: 187.8049\n",
      "Epoch 1063/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 63.4584 - val_loss: 184.0422\n",
      "Epoch 1064/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 71.8094 - val_loss: 157.3629\n",
      "Epoch 1065/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 66.7868 - val_loss: 160.8325\n",
      "Epoch 1066/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 65.5802 - val_loss: 132.3465\n",
      "Epoch 1067/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 153.2507 - val_loss: 191.0763\n",
      "Epoch 1068/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 112.6898 - val_loss: 168.0481\n",
      "Epoch 1069/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 96.0431 - val_loss: 112.8513\n",
      "Epoch 1070/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 125.5287 - val_loss: 111.1387\n",
      "Epoch 1071/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 89.7998 - val_loss: 155.1509\n",
      "Epoch 1072/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 86.8393 - val_loss: 158.4454\n",
      "Epoch 1073/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 71.1835 - val_loss: 152.3440\n",
      "Epoch 1074/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 56.3563 - val_loss: 158.9348\n",
      "Epoch 1075/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 83.7458 - val_loss: 177.8139\n",
      "Epoch 1076/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 80.9092 - val_loss: 183.5990\n",
      "Epoch 1077/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 66.3267 - val_loss: 171.6043\n",
      "Epoch 1078/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 83.9796 - val_loss: 137.3742\n",
      "Epoch 1079/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 80.0211 - val_loss: 163.5764\n",
      "Epoch 1080/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 65.5273 - val_loss: 169.6476\n",
      "Epoch 1081/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 65.7887 - val_loss: 158.8960\n",
      "Epoch 1082/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 62.0640 - val_loss: 194.9951\n",
      "Epoch 1083/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 66.8047 - val_loss: 161.0421\n",
      "Epoch 1084/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 59.5883 - val_loss: 199.1315\n",
      "Epoch 1085/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 60.7158 - val_loss: 150.1577\n",
      "Epoch 1086/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 68.1431 - val_loss: 187.1366\n",
      "Epoch 1087/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 80.5270 - val_loss: 148.1420\n",
      "Epoch 1088/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 66.6629 - val_loss: 181.5361\n",
      "Epoch 1089/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 62.5904 - val_loss: 135.9971\n",
      "Epoch 1090/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 54.6068 - val_loss: 156.6795\n",
      "Epoch 1091/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 55.8905 - val_loss: 152.1584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1092/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 60.1993 - val_loss: 138.5204\n",
      "Epoch 1093/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 66.1103 - val_loss: 195.5092\n",
      "Epoch 1094/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 63.4689 - val_loss: 174.8297\n",
      "Epoch 1095/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 59.5184 - val_loss: 143.2348\n",
      "Epoch 1096/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 60.9240 - val_loss: 167.0104\n",
      "Epoch 1097/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 51.7065 - val_loss: 204.0026\n",
      "Epoch 1098/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 58.5131 - val_loss: 168.0707\n",
      "Epoch 1099/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 56.2961 - val_loss: 158.0217\n",
      "Epoch 1100/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 54.7650 - val_loss: 176.6197\n",
      "Epoch 1101/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 72.8830 - val_loss: 181.1185\n",
      "Epoch 1102/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 61.2256 - val_loss: 155.0381\n",
      "Epoch 1103/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 57.1630 - val_loss: 157.7702\n",
      "Epoch 1104/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 65.6712 - val_loss: 116.8643\n",
      "Epoch 1105/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 51.5178 - val_loss: 130.1183\n",
      "Epoch 1106/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 52.0737 - val_loss: 153.3405\n",
      "Epoch 1107/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 55.8613 - val_loss: 188.2764\n",
      "Epoch 1108/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 56.0343 - val_loss: 163.9323\n",
      "Epoch 1109/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 48.0023 - val_loss: 149.2587\n",
      "Epoch 1110/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 64.1944 - val_loss: 164.6238\n",
      "Epoch 1111/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 70.8231 - val_loss: 121.6980\n",
      "Epoch 1112/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 54.0470 - val_loss: 158.7010\n",
      "Epoch 1113/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 51.1188 - val_loss: 96.3972\n",
      "Epoch 1114/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 55.2089 - val_loss: 140.9789\n",
      "Epoch 1115/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 57.5441 - val_loss: 160.9804\n",
      "Epoch 1116/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 49.7510 - val_loss: 170.6190\n",
      "Epoch 1117/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 48.0700 - val_loss: 227.7767\n",
      "Epoch 1118/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 83.9141 - val_loss: 194.0618\n",
      "Epoch 1119/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 57.8859 - val_loss: 154.6176\n",
      "Epoch 1120/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 54.4544 - val_loss: 142.6193\n",
      "Epoch 1121/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 53.0392 - val_loss: 173.5788\n",
      "Epoch 1122/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 51.3651 - val_loss: 160.3376\n",
      "Epoch 1123/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 46.7147 - val_loss: 147.7171\n",
      "Epoch 1124/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 45.1426 - val_loss: 166.2752\n",
      "Epoch 1125/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 49.8515 - val_loss: 138.8544\n",
      "Epoch 1126/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 49.2487 - val_loss: 203.7764\n",
      "Epoch 1127/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 76.7087 - val_loss: 149.8338\n",
      "Epoch 1128/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 45.3399 - val_loss: 149.4898\n",
      "Epoch 1129/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 46.3855 - val_loss: 122.3102\n",
      "Epoch 1130/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 52.1458 - val_loss: 239.0749\n",
      "Epoch 1131/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 66.2801 - val_loss: 156.1788\n",
      "Epoch 1132/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 49.1853 - val_loss: 149.5540\n",
      "Epoch 1133/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 50.3085 - val_loss: 145.1821\n",
      "Epoch 1134/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 51.0334 - val_loss: 146.9394\n",
      "Epoch 1135/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 45.7267 - val_loss: 144.3233\n",
      "Epoch 1136/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 53.2801 - val_loss: 157.6697\n",
      "Epoch 1137/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 47.5260 - val_loss: 147.6641\n",
      "Epoch 1138/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 41.2718 - val_loss: 167.8684\n",
      "Epoch 1139/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 47.5974 - val_loss: 135.2851\n",
      "Epoch 1140/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 49.9265 - val_loss: 145.7123\n",
      "Epoch 1141/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 42.4843 - val_loss: 122.7229\n",
      "Epoch 1142/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 46.8244 - val_loss: 154.8069\n",
      "Epoch 1143/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 44.7946 - val_loss: 149.6631\n",
      "Epoch 1144/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 43.0038 - val_loss: 145.6612\n",
      "Epoch 1145/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 53.0799 - val_loss: 160.2334\n",
      "Epoch 1146/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 69.3401 - val_loss: 160.3859\n",
      "Epoch 1147/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 45.6362 - val_loss: 218.6683\n",
      "Epoch 1148/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 54.0535 - val_loss: 137.6491\n",
      "Epoch 1149/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 46.5274 - val_loss: 209.0097\n",
      "Epoch 1150/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 77.1928 - val_loss: 152.6471\n",
      "Epoch 1151/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 49.9367 - val_loss: 151.7054\n",
      "Epoch 1152/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 40.9286 - val_loss: 166.6882\n",
      "Epoch 1153/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 56.0047 - val_loss: 131.4883\n",
      "Epoch 1154/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 44.2884 - val_loss: 173.6897\n",
      "Epoch 1155/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 53.7360 - val_loss: 144.1932\n",
      "Epoch 1156/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 46.5494 - val_loss: 187.8264\n",
      "Epoch 1157/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 42.1202 - val_loss: 142.9586\n",
      "Epoch 1158/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 42.4775 - val_loss: 160.0652\n",
      "Epoch 1159/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 40.0155 - val_loss: 187.9030\n",
      "Epoch 1160/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 47.6323 - val_loss: 131.3728\n",
      "Epoch 1161/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 40.8612 - val_loss: 154.1065\n",
      "Epoch 1162/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 48.8050 - val_loss: 153.3992\n",
      "Epoch 1163/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 43.0014 - val_loss: 133.0241\n",
      "Epoch 1164/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 45.5617 - val_loss: 149.2796\n",
      "Epoch 1165/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 43.1346 - val_loss: 151.0145\n",
      "Epoch 1166/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 44.5427 - val_loss: 125.6582\n",
      "Epoch 1167/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 40.1874 - val_loss: 144.1035\n",
      "Epoch 1168/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 37.7028 - val_loss: 134.2418\n",
      "Epoch 1169/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 42.6192 - val_loss: 133.3079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1170/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 40.1794 - val_loss: 126.5138\n",
      "Epoch 1171/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 41.0775 - val_loss: 131.4466\n",
      "Epoch 1172/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 39.5839 - val_loss: 154.3902\n",
      "Epoch 1173/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 37.8386 - val_loss: 164.8466\n",
      "Epoch 1174/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 45.4634 - val_loss: 142.0032\n",
      "Epoch 1175/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 40.6462 - val_loss: 147.1178\n",
      "Epoch 1176/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 50.2895 - val_loss: 151.1917\n",
      "Epoch 1177/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 55.6360 - val_loss: 131.7371\n",
      "Epoch 1178/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 38.5347 - val_loss: 188.1579\n",
      "Epoch 1179/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 41.9206 - val_loss: 144.2498\n",
      "Epoch 1180/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 38.2788 - val_loss: 152.6680\n",
      "Epoch 1181/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 39.0776 - val_loss: 155.1913\n",
      "Epoch 1182/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 41.2086 - val_loss: 127.9840\n",
      "Epoch 1183/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 41.7229 - val_loss: 138.9559\n",
      "Epoch 1184/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 38.1934 - val_loss: 139.2792\n",
      "Epoch 1185/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 37.3415 - val_loss: 172.2634\n",
      "Epoch 1186/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 56.8511 - val_loss: 153.0399\n",
      "Epoch 1187/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 38.9256 - val_loss: 143.1546\n",
      "Epoch 1188/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 37.5214 - val_loss: 166.2771\n",
      "Epoch 1189/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 49.1502 - val_loss: 176.2516\n",
      "Epoch 1190/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 58.0957 - val_loss: 157.3591\n",
      "Epoch 1191/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 41.4997 - val_loss: 140.2751\n",
      "Epoch 1192/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 39.3757 - val_loss: 135.0899\n",
      "Epoch 1193/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 35.1029 - val_loss: 126.5395\n",
      "Epoch 1194/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 43.0516 - val_loss: 151.9138\n",
      "Epoch 1195/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 38.5590 - val_loss: 121.6510\n",
      "Epoch 1196/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 35.3420 - val_loss: 132.4470\n",
      "Epoch 1197/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 39.7439 - val_loss: 138.2285\n",
      "Epoch 1198/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 42.9486 - val_loss: 143.9700\n",
      "Epoch 1199/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 38.4204 - val_loss: 138.6342\n",
      "Epoch 1200/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 33.5691 - val_loss: 130.6646\n",
      "Epoch 1201/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 36.2099 - val_loss: 155.8353\n",
      "Epoch 1202/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 33.9449 - val_loss: 141.5915\n",
      "Epoch 1203/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 34.0950 - val_loss: 165.1549\n",
      "Epoch 1204/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 48.1579 - val_loss: 139.7616\n",
      "Epoch 1205/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 41.2199 - val_loss: 123.6151\n",
      "Epoch 1206/10000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 22.6940Restoring model weights from the end of the best epoch: 706.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 36.0283 - val_loss: 167.5305\n",
      "Epoch 1206: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = bidirectional_lstm_model(reshaped_train, \n",
    "                                                  reshaped_target, \n",
    "                                                  want_verbose=1, \n",
    "                                                  seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0aad5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb69c9b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>95.930099</td>\n",
       "      <td>89.598854</td>\n",
       "      <td>86.451584</td>\n",
       "      <td>85.180969</td>\n",
       "      <td>85.192024</td>\n",
       "      <td>86.980156</td>\n",
       "      <td>90.545868</td>\n",
       "      <td>96.675201</td>\n",
       "      <td>102.399986</td>\n",
       "      <td>106.788254</td>\n",
       "      <td>109.965096</td>\n",
       "      <td>112.668945</td>\n",
       "      <td>111.009773</td>\n",
       "      <td>112.008751</td>\n",
       "      <td>112.763977</td>\n",
       "      <td>111.072174</td>\n",
       "      <td>108.165421</td>\n",
       "      <td>103.484642</td>\n",
       "      <td>101.567963</td>\n",
       "      <td>101.04689</td>\n",
       "      <td>101.865425</td>\n",
       "      <td>104.182755</td>\n",
       "      <td>107.720703</td>\n",
       "      <td>111.541077</td>\n",
       "      <td>114.428558</td>\n",
       "      <td>115.746033</td>\n",
       "      <td>113.414581</td>\n",
       "      <td>108.340027</td>\n",
       "      <td>102.669899</td>\n",
       "      <td>97.002327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>120.055</td>\n",
       "      <td>125.769</td>\n",
       "      <td>112.904</td>\n",
       "      <td>123.201</td>\n",
       "      <td>112.725</td>\n",
       "      <td>90.828</td>\n",
       "      <td>96.36</td>\n",
       "      <td>86.444</td>\n",
       "      <td>94.285</td>\n",
       "      <td>98.986</td>\n",
       "      <td>88.072</td>\n",
       "      <td>141.01</td>\n",
       "      <td>122.652</td>\n",
       "      <td>142.145</td>\n",
       "      <td>121.124</td>\n",
       "      <td>130.503</td>\n",
       "      <td>104.115</td>\n",
       "      <td>90.69</td>\n",
       "      <td>102.685</td>\n",
       "      <td>96.144</td>\n",
       "      <td>102.197</td>\n",
       "      <td>106.712</td>\n",
       "      <td>124.057</td>\n",
       "      <td>124.625</td>\n",
       "      <td>133.116</td>\n",
       "      <td>144.31</td>\n",
       "      <td>140.357</td>\n",
       "      <td>152.769</td>\n",
       "      <td>124.038</td>\n",
       "      <td>95.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>24.124901</td>\n",
       "      <td>36.170143</td>\n",
       "      <td>26.452415</td>\n",
       "      <td>38.020027</td>\n",
       "      <td>27.532974</td>\n",
       "      <td>3.847847</td>\n",
       "      <td>5.814133</td>\n",
       "      <td>10.231201</td>\n",
       "      <td>8.114983</td>\n",
       "      <td>7.802254</td>\n",
       "      <td>21.893097</td>\n",
       "      <td>28.341049</td>\n",
       "      <td>11.642227</td>\n",
       "      <td>30.136253</td>\n",
       "      <td>8.360023</td>\n",
       "      <td>19.430832</td>\n",
       "      <td>4.050423</td>\n",
       "      <td>12.79464</td>\n",
       "      <td>1.117035</td>\n",
       "      <td>4.902893</td>\n",
       "      <td>0.331573</td>\n",
       "      <td>2.529243</td>\n",
       "      <td>16.336296</td>\n",
       "      <td>13.083923</td>\n",
       "      <td>18.687439</td>\n",
       "      <td>28.563965</td>\n",
       "      <td>26.942413</td>\n",
       "      <td>44.42897</td>\n",
       "      <td>21.368103</td>\n",
       "      <td>1.948326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1          2          3          4          5   \\\n",
       "Month         Month-1    Month-2    Month-3    Month-4    Month-5    Month-6   \n",
       "Prediction  95.930099  89.598854  86.451584  85.180969  85.192024  86.980156   \n",
       "Target        120.055    125.769    112.904    123.201    112.725     90.828   \n",
       "Error       24.124901  36.170143  26.452415  38.020027  27.532974   3.847847   \n",
       "\n",
       "                   6          7           8           9           10  \\\n",
       "Month         Month-7    Month-8     Month-9    Month-10    Month-11   \n",
       "Prediction  90.545868  96.675201  102.399986  106.788254  109.965096   \n",
       "Target          96.36     86.444      94.285      98.986      88.072   \n",
       "Error        5.814133  10.231201    8.114983    7.802254   21.893097   \n",
       "\n",
       "                    11          12          13          14          15  \\\n",
       "Month         Month-12    Month-13    Month-14    Month-15    Month-16   \n",
       "Prediction  112.668945  111.009773  112.008751  112.763977  111.072174   \n",
       "Target          141.01     122.652     142.145     121.124     130.503   \n",
       "Error        28.341049   11.642227   30.136253    8.360023   19.430832   \n",
       "\n",
       "                    16          17          18         19          20  \\\n",
       "Month         Month-17    Month-18    Month-19   Month-20    Month-21   \n",
       "Prediction  108.165421  103.484642  101.567963  101.04689  101.865425   \n",
       "Target         104.115       90.69     102.685     96.144     102.197   \n",
       "Error         4.050423    12.79464    1.117035   4.902893    0.331573   \n",
       "\n",
       "                    21          22          23          24          25  \\\n",
       "Month         Month-22    Month-23    Month-24    Month-25    Month-26   \n",
       "Prediction  104.182755  107.720703  111.541077  114.428558  115.746033   \n",
       "Target         106.712     124.057     124.625     133.116      144.31   \n",
       "Error         2.529243   16.336296   13.083923   18.687439   28.563965   \n",
       "\n",
       "                    26          27          28         29  \n",
       "Month         Month-27    Month-28    Month-29   Month-30  \n",
       "Prediction  113.414581  108.340027  102.669899  97.002327  \n",
       "Target         140.357     152.769     124.038     95.054  \n",
       "Error        26.942413    44.42897   21.368103   1.948326  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            reshaped_test, \n",
    "                                            reshaped_test_target, \n",
    "                                            start_index)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b1c27bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.83332"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.13851282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c506c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ca218d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[1148.377]] - Target[1290.639]| =  Error: [[142.26208]]; MAPE:[[0.11022608]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[1286.4294]] - Target[1367.6490000000001]| =  Error: [[81.219604]]; MAPE:[[0.05938629]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Ano-5: |Prediction[[651.60144]] - Target[789.644]| =  Error: [[138.04254]]; MAPE:[[0.17481618]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[142.26208]], dtype=float32),\n",
       " array([[81.219604]], dtype=float32),\n",
       " array([[138.04254]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "120.50808"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.11480951"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             reshaped_test, \n",
    "                                             reshaped_test_target, \n",
    "                                             start_index)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b2bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
