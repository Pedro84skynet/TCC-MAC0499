{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 13:04:38.319209: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 13:04:38.886119: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-10-20 13:04:39.552633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 13:04:39.576809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 13:04:39.577071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d613198",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Amapá - Consumo de Cimento (t)'\n",
    "start_index = 0\n",
    "split_index = 191 #Referente aos 230 anos de input \n",
    "window_size = 36\n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc652c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Amapá - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Amapá - PIB - Estadual</th>\n",
       "      <th>Amapá - PIB - Construção Civil</th>\n",
       "      <th>Amapá - PIB - Per Capita</th>\n",
       "      <th>Amapá - PIB - Preços de Mercado</th>\n",
       "      <th>Amapá - Desemprego</th>\n",
       "      <th>Amapá - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.711421</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>8.035813e+06</td>\n",
       "      <td>356591.003430</td>\n",
       "      <td>10.883143</td>\n",
       "      <td>7.033593e+06</td>\n",
       "      <td>8.514392</td>\n",
       "      <td>10.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.711553</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>8.046432e+06</td>\n",
       "      <td>356647.711004</td>\n",
       "      <td>10.885206</td>\n",
       "      <td>7.037356e+06</td>\n",
       "      <td>8.508753</td>\n",
       "      <td>6.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.711685</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>8.057052e+06</td>\n",
       "      <td>356704.418579</td>\n",
       "      <td>10.887268</td>\n",
       "      <td>7.041120e+06</td>\n",
       "      <td>8.503114</td>\n",
       "      <td>7.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.711817</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>8.067671e+06</td>\n",
       "      <td>356761.126153</td>\n",
       "      <td>10.889331</td>\n",
       "      <td>7.044883e+06</td>\n",
       "      <td>8.497475</td>\n",
       "      <td>7.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.711949</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>8.078290e+06</td>\n",
       "      <td>356817.833728</td>\n",
       "      <td>10.891394</td>\n",
       "      <td>7.048646e+06</td>\n",
       "      <td>8.491835</td>\n",
       "      <td>5.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Amapá - IDH   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0       2003-1     0.711421                                          0.724032   \n",
       "1       2003-2     0.711553                                          0.690297   \n",
       "2       2003-3     0.711685                                          0.669681   \n",
       "3       2003-4     0.711817                                          0.660494   \n",
       "4       2003-5     0.711949                                          0.648337   \n",
       "..         ...          ...                                               ...   \n",
       "235     2022-8          NaN                                               NaN   \n",
       "236     2022-9          NaN                                               NaN   \n",
       "237    2022-10          NaN                                               NaN   \n",
       "238    2022-11          NaN                                               NaN   \n",
       "239    2022-12          NaN                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     Amapá - PIB - Estadual  Amapá - PIB - Construção Civil  \\\n",
       "0              8.035813e+06                   356591.003430   \n",
       "1              8.046432e+06                   356647.711004   \n",
       "2              8.057052e+06                   356704.418579   \n",
       "3              8.067671e+06                   356761.126153   \n",
       "4              8.078290e+06                   356817.833728   \n",
       "..                      ...                             ...   \n",
       "235                     NaN                             NaN   \n",
       "236                     NaN                             NaN   \n",
       "237                     NaN                             NaN   \n",
       "238                     NaN                             NaN   \n",
       "239                     NaN                             NaN   \n",
       "\n",
       "     Amapá - PIB - Per Capita  Amapá - PIB - Preços de Mercado  \\\n",
       "0                   10.883143                     7.033593e+06   \n",
       "1                   10.885206                     7.037356e+06   \n",
       "2                   10.887268                     7.041120e+06   \n",
       "3                   10.889331                     7.044883e+06   \n",
       "4                   10.891394                     7.048646e+06   \n",
       "..                        ...                              ...   \n",
       "235                       NaN                              NaN   \n",
       "236                       NaN                              NaN   \n",
       "237                       NaN                              NaN   \n",
       "238                       NaN                              NaN   \n",
       "239                       NaN                              NaN   \n",
       "\n",
       "     Amapá - Desemprego  Amapá - Consumo de Cimento (t)  \n",
       "0              8.514392                          10.392  \n",
       "1              8.508753                           6.857  \n",
       "2              8.503114                           7.011  \n",
       "3              8.497475                           7.122  \n",
       "4              8.491835                           5.267  \n",
       "..                  ...                             ...  \n",
       "235                 NaN                          13.208  \n",
       "236                 NaN                          13.476  \n",
       "237                 NaN                          11.236  \n",
       "238                 NaN                          13.549  \n",
       "239                 NaN                          13.549  \n",
       "\n",
       "[240 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_AP.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amapá - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Amapá - PIB - Estadual</th>\n",
       "      <th>Amapá - PIB - Construção Civil</th>\n",
       "      <th>Amapá - PIB - Per Capita</th>\n",
       "      <th>Amapá - PIB - Preços de Mercado</th>\n",
       "      <th>Amapá - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.943242</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.716825</td>\n",
       "      <td>-0.487709</td>\n",
       "      <td>-0.246236</td>\n",
       "      <td>-1.984303</td>\n",
       "      <td>-0.890357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.870364</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.697794</td>\n",
       "      <td>-0.479493</td>\n",
       "      <td>-0.208006</td>\n",
       "      <td>-1.951397</td>\n",
       "      <td>-0.891922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.797485</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.678763</td>\n",
       "      <td>-0.471277</td>\n",
       "      <td>-0.169777</td>\n",
       "      <td>-1.918491</td>\n",
       "      <td>-0.893486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.724606</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.659732</td>\n",
       "      <td>-0.463061</td>\n",
       "      <td>-0.131548</td>\n",
       "      <td>-1.885585</td>\n",
       "      <td>-0.895051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.651728</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.640701</td>\n",
       "      <td>-0.454845</td>\n",
       "      <td>-0.093319</td>\n",
       "      <td>-1.852679</td>\n",
       "      <td>-0.896616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-0.638974</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.145925</td>\n",
       "      <td>-1.614044</td>\n",
       "      <td>-1.566534</td>\n",
       "      <td>1.010496</td>\n",
       "      <td>1.085785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-0.739823</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.135411</td>\n",
       "      <td>-1.605628</td>\n",
       "      <td>-1.579697</td>\n",
       "      <td>0.995294</td>\n",
       "      <td>1.078764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-0.840672</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.124897</td>\n",
       "      <td>-1.597213</td>\n",
       "      <td>-1.592859</td>\n",
       "      <td>0.980093</td>\n",
       "      <td>1.071742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-0.941521</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.114383</td>\n",
       "      <td>-1.588797</td>\n",
       "      <td>-1.606022</td>\n",
       "      <td>0.964891</td>\n",
       "      <td>1.064721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.042370</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.103869</td>\n",
       "      <td>-1.580382</td>\n",
       "      <td>-1.619185</td>\n",
       "      <td>0.949689</td>\n",
       "      <td>1.057699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Amapá - IDH   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0      -2.943242                                          2.723741   \n",
       "1      -2.870364                                          2.350880   \n",
       "2      -2.797485                                          2.123016   \n",
       "3      -2.724606                                          2.021477   \n",
       "4      -2.651728                                          1.887113   \n",
       "..           ...                                               ...   \n",
       "187    -0.638974                                         -2.010387   \n",
       "188    -0.739823                                         -1.870713   \n",
       "189    -0.840672                                         -1.806230   \n",
       "190    -0.941521                                         -1.727496   \n",
       "191    -1.042370                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Amapá - PIB - Estadual  Amapá - PIB - Construção Civil  \\\n",
       "0                 -1.716825                       -0.487709   \n",
       "1                 -1.697794                       -0.479493   \n",
       "2                 -1.678763                       -0.471277   \n",
       "3                 -1.659732                       -0.463061   \n",
       "4                 -1.640701                       -0.454845   \n",
       "..                      ...                             ...   \n",
       "187                1.145925                       -1.614044   \n",
       "188                1.135411                       -1.605628   \n",
       "189                1.124897                       -1.597213   \n",
       "190                1.114383                       -1.588797   \n",
       "191                1.103869                       -1.580382   \n",
       "\n",
       "     Amapá - PIB - Per Capita  Amapá - PIB - Preços de Mercado  \\\n",
       "0                   -0.246236                        -1.984303   \n",
       "1                   -0.208006                        -1.951397   \n",
       "2                   -0.169777                        -1.918491   \n",
       "3                   -0.131548                        -1.885585   \n",
       "4                   -0.093319                        -1.852679   \n",
       "..                        ...                              ...   \n",
       "187                 -1.566534                         1.010496   \n",
       "188                 -1.579697                         0.995294   \n",
       "189                 -1.592859                         0.980093   \n",
       "190                 -1.606022                         0.964891   \n",
       "191                 -1.619185                         0.949689   \n",
       "\n",
       "     Amapá - Desemprego  \n",
       "0             -0.890357  \n",
       "1             -0.891922  \n",
       "2             -0.893486  \n",
       "3             -0.895051  \n",
       "4             -0.896616  \n",
       "..                  ...  \n",
       "187            1.085785  \n",
       "188            1.078764  \n",
       "189            1.071742  \n",
       "190            1.064721  \n",
       "191            1.057699  \n",
       "\n",
       "[192 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      10.000\n",
       "1       6.136\n",
       "2       5.122\n",
       "3       3.926\n",
       "4       6.197\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Amapá - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amapá - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Amapá - PIB - Estadual</th>\n",
       "      <th>Amapá - PIB - Construção Civil</th>\n",
       "      <th>Amapá - PIB - Per Capita</th>\n",
       "      <th>Amapá - PIB - Preços de Mercado</th>\n",
       "      <th>Amapá - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.943242</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.716825</td>\n",
       "      <td>-0.487709</td>\n",
       "      <td>-0.246236</td>\n",
       "      <td>-1.984303</td>\n",
       "      <td>-0.890357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.870364</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.697794</td>\n",
       "      <td>-0.479493</td>\n",
       "      <td>-0.208006</td>\n",
       "      <td>-1.951397</td>\n",
       "      <td>-0.891922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.797485</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.678763</td>\n",
       "      <td>-0.471277</td>\n",
       "      <td>-0.169777</td>\n",
       "      <td>-1.918491</td>\n",
       "      <td>-0.893486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.724606</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.659732</td>\n",
       "      <td>-0.463061</td>\n",
       "      <td>-0.131548</td>\n",
       "      <td>-1.885585</td>\n",
       "      <td>-0.895051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.651728</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.640701</td>\n",
       "      <td>-0.454845</td>\n",
       "      <td>-0.093319</td>\n",
       "      <td>-1.852679</td>\n",
       "      <td>-0.896616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.388995</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>1.179199</td>\n",
       "      <td>-1.457028</td>\n",
       "      <td>-1.470096</td>\n",
       "      <td>1.047494</td>\n",
       "      <td>1.300799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.332036</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>1.184540</td>\n",
       "      <td>-1.486109</td>\n",
       "      <td>-1.464204</td>\n",
       "      <td>1.056372</td>\n",
       "      <td>1.292722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.275077</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>1.189880</td>\n",
       "      <td>-1.515190</td>\n",
       "      <td>-1.458311</td>\n",
       "      <td>1.065250</td>\n",
       "      <td>1.284645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.218118</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>1.195221</td>\n",
       "      <td>-1.544271</td>\n",
       "      <td>-1.452419</td>\n",
       "      <td>1.074128</td>\n",
       "      <td>1.276568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.161159</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>1.200562</td>\n",
       "      <td>-1.573353</td>\n",
       "      <td>-1.446526</td>\n",
       "      <td>1.083006</td>\n",
       "      <td>1.268492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Amapá - IDH   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0      -2.943242                                          2.723741   \n",
       "1      -2.870364                                          2.350880   \n",
       "2      -2.797485                                          2.123016   \n",
       "3      -2.724606                                          2.021477   \n",
       "4      -2.651728                                          1.887113   \n",
       "..           ...                                               ...   \n",
       "157     1.388995                                         -0.214006   \n",
       "158     1.332036                                         -0.434717   \n",
       "159     1.275077                                         -0.524091   \n",
       "160     1.218118                                         -0.614500   \n",
       "161     1.161159                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     Amapá - PIB - Estadual  Amapá - PIB - Construção Civil  \\\n",
       "0                 -1.716825                       -0.487709   \n",
       "1                 -1.697794                       -0.479493   \n",
       "2                 -1.678763                       -0.471277   \n",
       "3                 -1.659732                       -0.463061   \n",
       "4                 -1.640701                       -0.454845   \n",
       "..                      ...                             ...   \n",
       "157                1.179199                       -1.457028   \n",
       "158                1.184540                       -1.486109   \n",
       "159                1.189880                       -1.515190   \n",
       "160                1.195221                       -1.544271   \n",
       "161                1.200562                       -1.573353   \n",
       "\n",
       "     Amapá - PIB - Per Capita  Amapá - PIB - Preços de Mercado  \\\n",
       "0                   -0.246236                        -1.984303   \n",
       "1                   -0.208006                        -1.951397   \n",
       "2                   -0.169777                        -1.918491   \n",
       "3                   -0.131548                        -1.885585   \n",
       "4                   -0.093319                        -1.852679   \n",
       "..                        ...                              ...   \n",
       "157                 -1.470096                         1.047494   \n",
       "158                 -1.464204                         1.056372   \n",
       "159                 -1.458311                         1.065250   \n",
       "160                 -1.452419                         1.074128   \n",
       "161                 -1.446526                         1.083006   \n",
       "\n",
       "     Amapá - Desemprego  \n",
       "0             -0.890357  \n",
       "1             -0.891922  \n",
       "2             -0.893486  \n",
       "3             -0.895051  \n",
       "4             -0.896616  \n",
       "..                  ...  \n",
       "157            1.300799  \n",
       "158            1.292722  \n",
       "159            1.284645  \n",
       "160            1.276568  \n",
       "161            1.268492  \n",
       "\n",
       "[162 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[start_index:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      10.000\n",
       "1       6.136\n",
       "2       5.122\n",
       "3       3.926\n",
       "4       6.197\n",
       "        ...  \n",
       "157     8.322\n",
       "158    11.373\n",
       "159     9.651\n",
       "160    10.855\n",
       "161    13.970\n",
       "Name: Amapá - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[start_index:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21b9c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(t_input, t_target, window_size, start_from):\n",
    "    \n",
    "    X_batches = []\n",
    "    y_batches = []\n",
    "\n",
    "    train_input_values = t_input.values \n",
    "\n",
    "    for i in range(len(t_input) - window_size):\n",
    "        \n",
    "        X_window = train_input_values[i:i+window_size, :]\n",
    "        y_target = t_target[start_from+i+window_size]\n",
    "\n",
    "        X_batches.append(X_window)\n",
    "        y_batches.append(y_target)\n",
    "\n",
    "    return np.array(X_batches), np.array(y_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b281277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 36, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_train, reshaped_target = create_batches(train_input, \n",
    "                                                 train_target, \n",
    "                                                 window_size, \n",
    "                                                 start_index)\n",
    "reshaped_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc5d50dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amapá - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Amapá - PIB - Estadual</th>\n",
       "      <th>Amapá - PIB - Construção Civil</th>\n",
       "      <th>Amapá - PIB - Per Capita</th>\n",
       "      <th>Amapá - PIB - Preços de Mercado</th>\n",
       "      <th>Amapá - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.639896</td>\n",
       "      <td>0.888984</td>\n",
       "      <td>-0.460555</td>\n",
       "      <td>-1.131704</td>\n",
       "      <td>-0.368821</td>\n",
       "      <td>0.651397</td>\n",
       "      <td>0.944085</td>\n",
       "      <td>0.045243</td>\n",
       "      <td>0.813802</td>\n",
       "      <td>0.876851</td>\n",
       "      <td>-0.305631</td>\n",
       "      <td>0.923476</td>\n",
       "      <td>0.978734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.580720</td>\n",
       "      <td>0.954254</td>\n",
       "      <td>-0.440372</td>\n",
       "      <td>-0.613483</td>\n",
       "      <td>-0.328087</td>\n",
       "      <td>0.664707</td>\n",
       "      <td>0.947319</td>\n",
       "      <td>0.061828</td>\n",
       "      <td>0.829759</td>\n",
       "      <td>0.846024</td>\n",
       "      <td>-0.368234</td>\n",
       "      <td>0.925918</td>\n",
       "      <td>0.993895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.521544</td>\n",
       "      <td>1.045217</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.542919</td>\n",
       "      <td>-0.176031</td>\n",
       "      <td>0.678017</td>\n",
       "      <td>0.950553</td>\n",
       "      <td>0.046225</td>\n",
       "      <td>0.845716</td>\n",
       "      <td>0.815197</td>\n",
       "      <td>-0.430837</td>\n",
       "      <td>0.928361</td>\n",
       "      <td>1.009056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.462368</td>\n",
       "      <td>1.176395</td>\n",
       "      <td>-0.397019</td>\n",
       "      <td>-1.334517</td>\n",
       "      <td>-0.113037</td>\n",
       "      <td>0.691327</td>\n",
       "      <td>0.953786</td>\n",
       "      <td>0.032522</td>\n",
       "      <td>0.861673</td>\n",
       "      <td>0.784370</td>\n",
       "      <td>-0.493440</td>\n",
       "      <td>0.930803</td>\n",
       "      <td>1.024217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.403191</td>\n",
       "      <td>1.303259</td>\n",
       "      <td>-0.376532</td>\n",
       "      <td>-1.511762</td>\n",
       "      <td>-0.022703</td>\n",
       "      <td>0.704637</td>\n",
       "      <td>0.957020</td>\n",
       "      <td>0.042757</td>\n",
       "      <td>0.877629</td>\n",
       "      <td>0.753543</td>\n",
       "      <td>-0.556042</td>\n",
       "      <td>0.933246</td>\n",
       "      <td>1.039378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-0.638974</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.145925</td>\n",
       "      <td>-1.614044</td>\n",
       "      <td>-1.566534</td>\n",
       "      <td>1.010496</td>\n",
       "      <td>1.085785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-0.739823</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.135411</td>\n",
       "      <td>-1.605628</td>\n",
       "      <td>-1.579697</td>\n",
       "      <td>0.995294</td>\n",
       "      <td>1.078764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-0.840672</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.124897</td>\n",
       "      <td>-1.597213</td>\n",
       "      <td>-1.592859</td>\n",
       "      <td>0.980093</td>\n",
       "      <td>1.071742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-0.941521</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.114383</td>\n",
       "      <td>-1.588797</td>\n",
       "      <td>-1.606022</td>\n",
       "      <td>0.964891</td>\n",
       "      <td>1.064721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.042370</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.103869</td>\n",
       "      <td>-1.580382</td>\n",
       "      <td>-1.619185</td>\n",
       "      <td>0.949689</td>\n",
       "      <td>1.057699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Amapá - IDH   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "126     0.639896                                          0.888984   \n",
       "127     0.580720                                          0.954254   \n",
       "128     0.521544                                          1.045217   \n",
       "129     0.462368                                          1.176395   \n",
       "130     0.403191                                          1.303259   \n",
       "..           ...                                               ...   \n",
       "187    -0.638974                                         -2.010387   \n",
       "188    -0.739823                                         -1.870713   \n",
       "189    -0.840672                                         -1.806230   \n",
       "190    -0.941521                                         -1.727496   \n",
       "191    -1.042370                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "126                      -0.460555       -1.131704 -0.368821   0.651397   \n",
       "127                      -0.440372       -0.613483 -0.328087   0.664707   \n",
       "128                      -0.419247       -0.542919 -0.176031   0.678017   \n",
       "129                      -0.397019       -1.334517 -0.113037   0.691327   \n",
       "130                      -0.376532       -1.511762 -0.022703   0.704637   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "126                                0.944085   0.045243   \n",
       "127                                0.947319   0.061828   \n",
       "128                                0.950553   0.046225   \n",
       "129                                0.953786   0.032522   \n",
       "130                                0.957020   0.042757   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Amapá - PIB - Estadual  Amapá - PIB - Construção Civil  \\\n",
       "126                0.813802                        0.876851   \n",
       "127                0.829759                        0.846024   \n",
       "128                0.845716                        0.815197   \n",
       "129                0.861673                        0.784370   \n",
       "130                0.877629                        0.753543   \n",
       "..                      ...                             ...   \n",
       "187                1.145925                       -1.614044   \n",
       "188                1.135411                       -1.605628   \n",
       "189                1.124897                       -1.597213   \n",
       "190                1.114383                       -1.588797   \n",
       "191                1.103869                       -1.580382   \n",
       "\n",
       "     Amapá - PIB - Per Capita  Amapá - PIB - Preços de Mercado  \\\n",
       "126                 -0.305631                         0.923476   \n",
       "127                 -0.368234                         0.925918   \n",
       "128                 -0.430837                         0.928361   \n",
       "129                 -0.493440                         0.930803   \n",
       "130                 -0.556042                         0.933246   \n",
       "..                        ...                              ...   \n",
       "187                 -1.566534                         1.010496   \n",
       "188                 -1.579697                         0.995294   \n",
       "189                 -1.592859                         0.980093   \n",
       "190                 -1.606022                         0.964891   \n",
       "191                 -1.619185                         0.949689   \n",
       "\n",
       "     Amapá - Desemprego  \n",
       "126            0.978734  \n",
       "127            0.993895  \n",
       "128            1.009056  \n",
       "129            1.024217  \n",
       "130            1.039378  \n",
       "..                  ...  \n",
       "187            1.085785  \n",
       "188            1.078764  \n",
       "189            1.071742  \n",
       "190            1.064721  \n",
       "191            1.057699  \n",
       "\n",
       "[66 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "test_input = input_data.iloc[train_split-window_size:split_index + 1]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82f07fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.399, 11.268,  8.741, 12.358, 11.876, 11.713, 11.449,  7.805,\n",
       "        7.726,  8.516,  8.503, 10.175, 11.775,  9.724, 10.069, 13.93 ,\n",
       "       11.918, 11.757,  9.691,  7.378,  6.97 ,  7.612,  8.442,  8.835,\n",
       "       11.251, 11.342, 13.11 , 13.195, 10.053, 12.274])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_test, reshaped_test_target = create_batches(test_input, \n",
    "                                                     target_data, \n",
    "                                                     window_size, \n",
    "                                                     train_split - window_size)\n",
    "reshaped_test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c5afeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(arr, div_factor, add_factor=0):\n",
    "    split_factor = len(arr) // div_factor\n",
    "    positions_to_drop_index = []\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = len(arr) - (i * div_factor + 1)\n",
    "        positions_to_drop_index.append(pos)\n",
    "        positions_to_drop.append(pos + add_factor)\n",
    "    \n",
    "    arr_droped = arr[positions_to_drop]\n",
    "    arr_result = np.delete(arr, positions_to_drop_index, axis=0)\n",
    "    \n",
    "    return arr_result, arr_droped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede Neural Recorrente com optmizador Estocástico\n",
    "def lstm_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "#     train, train_val = validation_splitter(train_input, 7)\n",
    "#     target,target_val = validation_splitter(train_target, 7)\n",
    "#     display(train.shape)\n",
    "#     display(train_val.shape)\n",
    "#     display(target.shape)\n",
    "#     display(target_val.shape)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(72, activation='tanh', \n",
    "                             return_sequences=True, \n",
    "                             input_shape=(reshaped_train.shape[1],\n",
    "                                          reshaped_train.shape[2])),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.LSTM(36, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(36, activation='tanh'),\n",
    "        tf.keras.layers.Dense(18, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "                  loss='mean_squared_error')    \n",
    "    history = model.fit(train_input, \n",
    "                        train_target, \n",
    "                        epochs=10000,\n",
    "#                         validation_data=(train_val,\n",
    "#                                          target_val),\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_input, test_target):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(20)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = lstm_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1acb58be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1163406737, 960475672, 4216526090, 3019472274, 2975135380, 3983919895, 2220739625, 2789345229, 700955648, 4124268824, 996484512, 1676813750, 662915029, 3074102579, 2384568541, 855032732, 2992321060, 2436767679, 1535099939, 921828810]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 13:04:39.932395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 13:04:39.932603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 13:04:39.932747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 13:04:39.985091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 13:04:39.985261: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 13:04:39.985406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-20 13:04:39.985531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9382 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:08:00.0, compute capability: 8.6\n",
      "2023-10-20 13:04:41.988424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8904\n",
      "2023-10-20 13:04:42.045794: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-20 13:04:42.061475: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x32c39d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-20 13:04:42.061492: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-10-20 13:04:42.064610: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-20 13:04:42.155899: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 5.775665760040283\n",
      "winner_seed: 1163406737\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 5.720895767211914\n",
      "winner_seed: 960475672\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 5.622644901275635\n",
      "winner_seed: 4216526090\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 5.5852580070495605\n",
      "winner_seed: 3019472274\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 5.36119270324707\n",
      "winner_seed: 2975135380\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 14.806296348571777\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 5.801276683807373\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 6.961278438568115\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 8.389022827148438\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 9.070533752441406\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 6.893496513366699\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 5.392962455749512\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 15.778875350952148\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 13:16:38.700482: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 6.286588668823242\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 13:17:50.094022: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 5.526735782623291\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 5.005926132202148\n",
      "winner_seed: 855032732\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 14.902663230895996\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 6.7793073654174805\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 7.607578754425049\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 12.04067611694336\n",
      "\n",
      "\n",
      "final_seed: 855032732\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(reshaped_train, reshaped_target, reshaped_test, reshaped_test_target)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 [==============================] - 3s 131ms/step - loss: 239.6277 - val_loss: 104.0686\n",
      "Epoch 2/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 164.4232 - val_loss: 64.2777\n",
      "Epoch 3/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 132.4984 - val_loss: 53.9576\n",
      "Epoch 4/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 120.4036 - val_loss: 47.6530\n",
      "Epoch 5/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 111.7325 - val_loss: 42.2826\n",
      "Epoch 6/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 104.7266 - val_loss: 37.4515\n",
      "Epoch 7/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 97.8151 - val_loss: 33.1030\n",
      "Epoch 8/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 91.5791 - val_loss: 29.1488\n",
      "Epoch 9/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 85.6659 - val_loss: 25.5781\n",
      "Epoch 10/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 80.6167 - val_loss: 22.3283\n",
      "Epoch 11/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 75.5079 - val_loss: 19.4736\n",
      "Epoch 12/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 71.0309 - val_loss: 16.9203\n",
      "Epoch 13/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 67.0396 - val_loss: 14.6611\n",
      "Epoch 14/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 63.0076 - val_loss: 12.7366\n",
      "Epoch 15/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 59.6310 - val_loss: 11.0506\n",
      "Epoch 16/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 56.3555 - val_loss: 9.6182\n",
      "Epoch 17/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 53.6679 - val_loss: 8.3812\n",
      "Epoch 18/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 51.1752 - val_loss: 7.3547\n",
      "Epoch 19/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 48.6970 - val_loss: 6.5384\n",
      "Epoch 20/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 46.6259 - val_loss: 5.8795\n",
      "Epoch 21/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 44.7838 - val_loss: 5.3686\n",
      "Epoch 22/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 43.1649 - val_loss: 4.9887\n",
      "Epoch 23/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 41.5970 - val_loss: 4.7310\n",
      "Epoch 24/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 40.2384 - val_loss: 4.5737\n",
      "Epoch 25/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 39.2123 - val_loss: 4.5036\n",
      "Epoch 26/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 38.0406 - val_loss: 4.5144\n",
      "Epoch 27/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 37.2769 - val_loss: 4.5958\n",
      "Epoch 28/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 36.4432 - val_loss: 4.7271\n",
      "Epoch 29/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 35.7121 - val_loss: 4.8893\n",
      "Epoch 30/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 35.1297 - val_loss: 5.0801\n",
      "Epoch 31/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 34.6201 - val_loss: 5.3005\n",
      "Epoch 32/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 34.2172 - val_loss: 5.5592\n",
      "Epoch 33/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 33.8765 - val_loss: 5.8428\n",
      "Epoch 34/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 33.4858 - val_loss: 6.1212\n",
      "Epoch 35/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 33.2522 - val_loss: 6.4125\n",
      "Epoch 36/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 32.9684 - val_loss: 6.6834\n",
      "Epoch 37/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 32.7870 - val_loss: 6.9581\n",
      "Epoch 38/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 32.6192 - val_loss: 7.2172\n",
      "Epoch 39/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 32.4908 - val_loss: 7.4732\n",
      "Epoch 40/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 32.3575 - val_loss: 7.7213\n",
      "Epoch 41/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 32.2464 - val_loss: 7.9527\n",
      "Epoch 42/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 32.1574 - val_loss: 8.1779\n",
      "Epoch 43/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 32.0870 - val_loss: 8.4069\n",
      "Epoch 44/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 32.0418 - val_loss: 8.6699\n",
      "Epoch 45/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.9866 - val_loss: 8.9133\n",
      "Epoch 46/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.9179 - val_loss: 9.1221\n",
      "Epoch 47/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.8919 - val_loss: 9.3567\n",
      "Epoch 48/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.8533 - val_loss: 9.5481\n",
      "Epoch 49/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.8401 - val_loss: 9.7386\n",
      "Epoch 50/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.8303 - val_loss: 9.8887\n",
      "Epoch 51/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.8069 - val_loss: 9.9691\n",
      "Epoch 52/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.8049 - val_loss: 10.0779\n",
      "Epoch 53/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.8130 - val_loss: 10.2288\n",
      "Epoch 54/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7959 - val_loss: 10.3272\n",
      "Epoch 55/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.8081 - val_loss: 10.4243\n",
      "Epoch 56/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7880 - val_loss: 10.4235\n",
      "Epoch 57/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7881 - val_loss: 10.4108\n",
      "Epoch 58/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7855 - val_loss: 10.4516\n",
      "Epoch 59/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7832 - val_loss: 10.4709\n",
      "Epoch 60/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7902 - val_loss: 10.4767\n",
      "Epoch 61/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7873 - val_loss: 10.5656\n",
      "Epoch 62/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7814 - val_loss: 10.6106\n",
      "Epoch 63/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7805 - val_loss: 10.6485\n",
      "Epoch 64/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7783 - val_loss: 10.6471\n",
      "Epoch 65/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7857 - val_loss: 10.6671\n",
      "Epoch 66/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7802 - val_loss: 10.6374\n",
      "Epoch 67/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7805 - val_loss: 10.6217\n",
      "Epoch 68/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7819 - val_loss: 10.6069\n",
      "Epoch 69/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7812 - val_loss: 10.6124\n",
      "Epoch 70/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7825 - val_loss: 10.6238\n",
      "Epoch 71/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.7792 - val_loss: 10.6709\n",
      "Epoch 72/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7853 - val_loss: 10.7260\n",
      "Epoch 73/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7922 - val_loss: 10.8180\n",
      "Epoch 74/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7799 - val_loss: 10.8298\n",
      "Epoch 75/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.7826 - val_loss: 10.8097\n",
      "Epoch 76/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7818 - val_loss: 10.8000\n",
      "Epoch 77/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7886 - val_loss: 10.7451\n",
      "Epoch 78/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7847 - val_loss: 10.7870\n",
      "Epoch 79/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7827 - val_loss: 10.7939\n",
      "Epoch 80/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.7799 - val_loss: 10.8273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7869 - val_loss: 10.8715\n",
      "Epoch 82/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7802 - val_loss: 10.8434\n",
      "Epoch 83/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7855 - val_loss: 10.8620\n",
      "Epoch 84/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7767 - val_loss: 10.8283\n",
      "Epoch 85/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7785 - val_loss: 10.7568\n",
      "Epoch 86/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7905 - val_loss: 10.6883\n",
      "Epoch 87/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7794 - val_loss: 10.7294\n",
      "Epoch 88/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7796 - val_loss: 10.7366\n",
      "Epoch 89/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7838 - val_loss: 10.7324\n",
      "Epoch 90/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7788 - val_loss: 10.7186\n",
      "Epoch 91/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7788 - val_loss: 10.6623\n",
      "Epoch 92/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7848 - val_loss: 10.5709\n",
      "Epoch 93/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7889 - val_loss: 10.5166\n",
      "Epoch 94/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7821 - val_loss: 10.5285\n",
      "Epoch 95/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7886 - val_loss: 10.6191\n",
      "Epoch 96/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7795 - val_loss: 10.6501\n",
      "Epoch 97/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7796 - val_loss: 10.7158\n",
      "Epoch 98/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7794 - val_loss: 10.7486\n",
      "Epoch 99/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7791 - val_loss: 10.7877\n",
      "Epoch 100/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7801 - val_loss: 10.7905\n",
      "Epoch 101/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7864 - val_loss: 10.7394\n",
      "Epoch 102/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7817 - val_loss: 10.7160\n",
      "Epoch 103/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7836 - val_loss: 10.7950\n",
      "Epoch 104/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7795 - val_loss: 10.8303\n",
      "Epoch 105/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7803 - val_loss: 10.9032\n",
      "Epoch 106/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7821 - val_loss: 10.9194\n",
      "Epoch 107/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7786 - val_loss: 10.9304\n",
      "Epoch 108/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7826 - val_loss: 10.9700\n",
      "Epoch 109/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7892 - val_loss: 10.9196\n",
      "Epoch 110/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7815 - val_loss: 10.9596\n",
      "Epoch 111/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7821 - val_loss: 11.0076\n",
      "Epoch 112/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7885 - val_loss: 11.0515\n",
      "Epoch 113/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7872 - val_loss: 10.9726\n",
      "Epoch 114/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7826 - val_loss: 10.9272\n",
      "Epoch 115/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7833 - val_loss: 10.9614\n",
      "Epoch 116/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7805 - val_loss: 10.9165\n",
      "Epoch 117/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7918 - val_loss: 10.8573\n",
      "Epoch 118/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7862 - val_loss: 10.8385\n",
      "Epoch 119/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7800 - val_loss: 10.9276\n",
      "Epoch 120/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7902 - val_loss: 11.0389\n",
      "Epoch 121/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7865 - val_loss: 11.0565\n",
      "Epoch 122/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7809 - val_loss: 11.0211\n",
      "Epoch 123/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7827 - val_loss: 10.9844\n",
      "Epoch 124/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7953 - val_loss: 10.8802\n",
      "Epoch 125/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7807 - val_loss: 10.8994\n",
      "Epoch 126/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7812 - val_loss: 10.8947\n",
      "Epoch 127/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.8014 - val_loss: 10.7900\n",
      "Epoch 128/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7764 - val_loss: 10.8253\n",
      "Epoch 129/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7794 - val_loss: 10.8521\n",
      "Epoch 130/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7827 - val_loss: 10.9338\n",
      "Epoch 131/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7799 - val_loss: 11.0084\n",
      "Epoch 132/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7833 - val_loss: 11.0306\n",
      "Epoch 133/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.8058 - val_loss: 11.1958\n",
      "Epoch 134/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7893 - val_loss: 11.2944\n",
      "Epoch 135/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7968 - val_loss: 11.3325\n",
      "Epoch 136/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7888 - val_loss: 11.3063\n",
      "Epoch 137/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7876 - val_loss: 11.2547\n",
      "Epoch 138/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7841 - val_loss: 11.2094\n",
      "Epoch 139/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7839 - val_loss: 11.1138\n",
      "Epoch 140/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7829 - val_loss: 11.0443\n",
      "Epoch 141/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7825 - val_loss: 10.9179\n",
      "Epoch 142/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7810 - val_loss: 10.8486\n",
      "Epoch 143/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7861 - val_loss: 10.7753\n",
      "Epoch 144/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7800 - val_loss: 10.7605\n",
      "Epoch 145/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7786 - val_loss: 10.7196\n",
      "Epoch 146/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7781 - val_loss: 10.6978\n",
      "Epoch 147/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7805 - val_loss: 10.6762\n",
      "Epoch 148/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7835 - val_loss: 10.7133\n",
      "Epoch 149/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7814 - val_loss: 10.7088\n",
      "Epoch 150/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7787 - val_loss: 10.6680\n",
      "Epoch 151/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7827 - val_loss: 10.6128\n",
      "Epoch 152/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.7891 - val_loss: 10.6126\n",
      "Epoch 153/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.8061 - val_loss: 10.4859\n",
      "Epoch 154/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7888 - val_loss: 10.5721\n",
      "Epoch 155/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7891 - val_loss: 10.5526\n",
      "Epoch 156/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7769 - val_loss: 10.6360\n",
      "Epoch 157/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7835 - val_loss: 10.7786\n",
      "Epoch 158/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7809 - val_loss: 10.8955\n",
      "Epoch 159/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7776 - val_loss: 10.9657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7799 - val_loss: 11.0292\n",
      "Epoch 161/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7908 - val_loss: 10.9842\n",
      "Epoch 162/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7836 - val_loss: 10.9768\n",
      "Epoch 163/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7791 - val_loss: 11.0144\n",
      "Epoch 164/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7812 - val_loss: 11.0386\n",
      "Epoch 165/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7836 - val_loss: 11.0513\n",
      "Epoch 166/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7845 - val_loss: 11.0747\n",
      "Epoch 167/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7855 - val_loss: 11.0195\n",
      "Epoch 168/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7801 - val_loss: 10.9922\n",
      "Epoch 169/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7799 - val_loss: 10.9611\n",
      "Epoch 170/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7790 - val_loss: 10.9249\n",
      "Epoch 171/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7843 - val_loss: 10.8454\n",
      "Epoch 172/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7822 - val_loss: 10.7997\n",
      "Epoch 173/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7807 - val_loss: 10.7845\n",
      "Epoch 174/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7860 - val_loss: 10.7374\n",
      "Epoch 175/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7799 - val_loss: 10.8103\n",
      "Epoch 176/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7860 - val_loss: 10.8738\n",
      "Epoch 177/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7765 - val_loss: 10.8646\n",
      "Epoch 178/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7799 - val_loss: 10.8563\n",
      "Epoch 179/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7838 - val_loss: 10.8485\n",
      "Epoch 180/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7860 - val_loss: 10.8793\n",
      "Epoch 181/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7772 - val_loss: 10.8148\n",
      "Epoch 182/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7770 - val_loss: 10.7493\n",
      "Epoch 183/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7804 - val_loss: 10.6599\n",
      "Epoch 184/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7838 - val_loss: 10.5984\n",
      "Epoch 185/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7857 - val_loss: 10.5701\n",
      "Epoch 186/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.7800 - val_loss: 10.6142\n",
      "Epoch 187/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7766 - val_loss: 10.7162\n",
      "Epoch 188/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7836 - val_loss: 10.8049\n",
      "Epoch 189/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7877 - val_loss: 10.8754\n",
      "Epoch 190/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7819 - val_loss: 10.8446\n",
      "Epoch 191/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7800 - val_loss: 10.8399\n",
      "Epoch 192/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7814 - val_loss: 10.8341\n",
      "Epoch 193/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7772 - val_loss: 10.7815\n",
      "Epoch 194/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.7833 - val_loss: 10.7697\n",
      "Epoch 195/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7994 - val_loss: 10.6689\n",
      "Epoch 196/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.7816 - val_loss: 10.6952\n",
      "Epoch 197/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7801 - val_loss: 10.7071\n",
      "Epoch 198/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7808 - val_loss: 10.6871\n",
      "Epoch 199/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7794 - val_loss: 10.6529\n",
      "Epoch 200/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7824 - val_loss: 10.6359\n",
      "Epoch 201/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7786 - val_loss: 10.5796\n",
      "Epoch 202/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7802 - val_loss: 10.5481\n",
      "Epoch 203/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.7866 - val_loss: 10.4892\n",
      "Epoch 204/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.7835 - val_loss: 10.4848\n",
      "Epoch 205/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7843 - val_loss: 10.4836\n",
      "Epoch 206/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7871 - val_loss: 10.5819\n",
      "Epoch 207/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7839 - val_loss: 10.6248\n",
      "Epoch 208/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7947 - val_loss: 10.5386\n",
      "Epoch 209/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7860 - val_loss: 10.6049\n",
      "Epoch 210/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7826 - val_loss: 10.6530\n",
      "Epoch 211/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7805 - val_loss: 10.6821\n",
      "Epoch 212/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7945 - val_loss: 10.7552\n",
      "Epoch 213/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7794 - val_loss: 10.6685\n",
      "Epoch 214/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7834 - val_loss: 10.6243\n",
      "Epoch 215/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7823 - val_loss: 10.6612\n",
      "Epoch 216/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7797 - val_loss: 10.6787\n",
      "Epoch 217/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7805 - val_loss: 10.7057\n",
      "Epoch 218/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7821 - val_loss: 10.6994\n",
      "Epoch 219/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7800 - val_loss: 10.7413\n",
      "Epoch 220/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7782 - val_loss: 10.8153\n",
      "Epoch 221/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7902 - val_loss: 10.9167\n",
      "Epoch 222/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7823 - val_loss: 10.9225\n",
      "Epoch 223/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7859 - val_loss: 10.9246\n",
      "Epoch 224/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7773 - val_loss: 10.8405\n",
      "Epoch 225/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.8197 - val_loss: 10.6327\n",
      "Epoch 226/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7962 - val_loss: 10.7254\n",
      "Epoch 227/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7873 - val_loss: 10.7614\n",
      "Epoch 228/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7826 - val_loss: 10.8144\n",
      "Epoch 229/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7843 - val_loss: 10.7941\n",
      "Epoch 230/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7816 - val_loss: 10.7896\n",
      "Epoch 231/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7793 - val_loss: 10.8609\n",
      "Epoch 232/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7920 - val_loss: 10.9636\n",
      "Epoch 233/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7808 - val_loss: 10.9522\n",
      "Epoch 234/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7930 - val_loss: 10.8364\n",
      "Epoch 235/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7817 - val_loss: 10.8952\n",
      "Epoch 236/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.7812 - val_loss: 10.8570\n",
      "Epoch 237/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7804 - val_loss: 10.8806\n",
      "Epoch 238/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7790 - val_loss: 10.8558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7976 - val_loss: 10.7099\n",
      "Epoch 240/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.8048 - val_loss: 10.6287\n",
      "Epoch 241/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7767 - val_loss: 10.7476\n",
      "Epoch 242/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 31.7680 - val_loss: 10.9259\n",
      "Epoch 243/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7891 - val_loss: 11.1229\n",
      "Epoch 244/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7853 - val_loss: 11.2248\n",
      "Epoch 245/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7959 - val_loss: 11.3705\n",
      "Epoch 246/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7980 - val_loss: 11.3966\n",
      "Epoch 247/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7931 - val_loss: 11.3261\n",
      "Epoch 248/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7959 - val_loss: 11.2314\n",
      "Epoch 249/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.8025 - val_loss: 11.2902\n",
      "Epoch 250/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7849 - val_loss: 11.2057\n",
      "Epoch 251/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.8076 - val_loss: 11.0086\n",
      "Epoch 252/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7795 - val_loss: 10.9516\n",
      "Epoch 253/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7910 - val_loss: 10.7904\n",
      "Epoch 254/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7777 - val_loss: 10.7628\n",
      "Epoch 255/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.7790 - val_loss: 10.7205\n",
      "Epoch 256/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7829 - val_loss: 10.7428\n",
      "Epoch 257/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.7933 - val_loss: 10.6540\n",
      "Epoch 258/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.8031 - val_loss: 10.7583\n",
      "Epoch 259/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7829 - val_loss: 10.7106\n",
      "Epoch 260/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7812 - val_loss: 10.6741\n",
      "Epoch 261/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7831 - val_loss: 10.6209\n",
      "Epoch 262/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7850 - val_loss: 10.6166\n",
      "Epoch 263/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 31.7855 - val_loss: 10.6135\n",
      "Epoch 264/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7831 - val_loss: 10.4915\n",
      "Epoch 265/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7855 - val_loss: 10.4550\n",
      "Epoch 266/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7890 - val_loss: 10.4819\n",
      "Epoch 267/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7886 - val_loss: 10.5265\n",
      "Epoch 268/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7861 - val_loss: 10.5474\n",
      "Epoch 269/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7802 - val_loss: 10.6411\n",
      "Epoch 270/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7801 - val_loss: 10.6844\n",
      "Epoch 271/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7754 - val_loss: 10.8374\n",
      "Epoch 272/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7829 - val_loss: 10.9806\n",
      "Epoch 273/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7951 - val_loss: 11.1037\n",
      "Epoch 274/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7867 - val_loss: 11.0801\n",
      "Epoch 275/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7737 - val_loss: 10.8902\n",
      "Epoch 276/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7771 - val_loss: 10.6850\n",
      "Epoch 277/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7784 - val_loss: 10.5991\n",
      "Epoch 278/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7788 - val_loss: 10.5235\n",
      "Epoch 279/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7812 - val_loss: 10.4353\n",
      "Epoch 280/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7769 - val_loss: 10.2917\n",
      "Epoch 281/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.8149 - val_loss: 10.0797\n",
      "Epoch 282/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.8079 - val_loss: 10.0596\n",
      "Epoch 283/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.8038 - val_loss: 10.0911\n",
      "Epoch 284/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.8138 - val_loss: 10.0535\n",
      "Epoch 285/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7985 - val_loss: 10.2201\n",
      "Epoch 286/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.8072 - val_loss: 10.4674\n",
      "Epoch 287/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7860 - val_loss: 10.5995\n",
      "Epoch 288/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7979 - val_loss: 10.7596\n",
      "Epoch 289/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7812 - val_loss: 10.7352\n",
      "Epoch 290/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7858 - val_loss: 10.6823\n",
      "Epoch 291/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7859 - val_loss: 10.7900\n",
      "Epoch 292/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7917 - val_loss: 10.7843\n",
      "Epoch 293/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 31.7824 - val_loss: 10.9118\n",
      "Epoch 294/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7805 - val_loss: 10.9249\n",
      "Epoch 295/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7809 - val_loss: 10.9480\n",
      "Epoch 296/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7723 - val_loss: 11.0718\n",
      "Epoch 297/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7763 - val_loss: 11.2084\n",
      "Epoch 298/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.7677 - val_loss: 11.3531\n",
      "Epoch 299/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.8283 - val_loss: 11.6349\n",
      "Epoch 300/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 31.7783 - val_loss: 11.5762\n",
      "Epoch 301/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 31.5232 - val_loss: 10.0550\n",
      "Epoch 302/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 30.4881 - val_loss: 10.5828\n",
      "Epoch 303/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 29.4911 - val_loss: 11.2859\n",
      "Epoch 304/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 28.6971 - val_loss: 10.9378\n",
      "Epoch 305/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 27.7871 - val_loss: 12.1920\n",
      "Epoch 306/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 26.8191 - val_loss: 12.6992\n",
      "Epoch 307/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 26.3808 - val_loss: 13.2778\n",
      "Epoch 308/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 25.1549 - val_loss: 13.8803\n",
      "Epoch 309/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 21.2867 - val_loss: 14.2011\n",
      "Epoch 310/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 19.3546 - val_loss: 16.6561\n",
      "Epoch 311/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 21.7834 - val_loss: 18.5926\n",
      "Epoch 312/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 18.2169 - val_loss: 20.3274\n",
      "Epoch 313/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 17.1446 - val_loss: 22.2460\n",
      "Epoch 314/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 19.4462 - val_loss: 24.0536\n",
      "Epoch 315/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 16.4967 - val_loss: 25.8364\n",
      "Epoch 316/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 17.1011 - val_loss: 27.4522\n",
      "Epoch 317/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.4324 - val_loss: 28.8312\n",
      "Epoch 318/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 15.5364 - val_loss: 30.1282\n",
      "Epoch 319/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 15.4578 - val_loss: 31.1189\n",
      "Epoch 320/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 13.4867 - val_loss: 32.0622\n",
      "Epoch 321/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 13.8710 - val_loss: 33.5948\n",
      "Epoch 322/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12.6385 - val_loss: 35.2910\n",
      "Epoch 323/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 12.6393 - val_loss: 36.8659\n",
      "Epoch 324/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 11.8296 - val_loss: 38.5973\n",
      "Epoch 325/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12.3294 - val_loss: 40.0842\n",
      "Epoch 326/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.7054 - val_loss: 41.5078\n",
      "Epoch 327/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.7452 - val_loss: 42.8198\n",
      "Epoch 328/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.7288 - val_loss: 44.4416\n",
      "Epoch 329/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.2975 - val_loss: 45.9859\n",
      "Epoch 330/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.3461 - val_loss: 47.5640\n",
      "Epoch 331/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.2416 - val_loss: 48.7028\n",
      "Epoch 332/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.4789 - val_loss: 49.7613\n",
      "Epoch 333/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.2974 - val_loss: 50.4870\n",
      "Epoch 334/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.0865 - val_loss: 51.1012\n",
      "Epoch 335/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.6564 - val_loss: 51.6718\n",
      "Epoch 336/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.2490 - val_loss: 52.6939\n",
      "Epoch 337/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.4518 - val_loss: 53.5992\n",
      "Epoch 338/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.9487 - val_loss: 54.0948\n",
      "Epoch 339/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.7497 - val_loss: 54.1585\n",
      "Epoch 340/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.1605 - val_loss: 54.5020\n",
      "Epoch 341/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.7655 - val_loss: 55.2747\n",
      "Epoch 342/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.7170 - val_loss: 55.8665\n",
      "Epoch 343/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.8518 - val_loss: 55.9222\n",
      "Epoch 344/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.9522 - val_loss: 56.1529\n",
      "Epoch 345/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 11.0691 - val_loss: 56.3907\n",
      "Epoch 346/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.5489 - val_loss: 56.7006\n",
      "Epoch 347/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.9666 - val_loss: 57.1681\n",
      "Epoch 348/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.6592 - val_loss: 57.4781\n",
      "Epoch 349/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.5645 - val_loss: 57.7025\n",
      "Epoch 350/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.3474 - val_loss: 57.6729\n",
      "Epoch 351/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.4538 - val_loss: 57.8414\n",
      "Epoch 352/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.5868 - val_loss: 58.3704\n",
      "Epoch 353/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.2221 - val_loss: 58.8441\n",
      "Epoch 354/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.5035 - val_loss: 59.0920\n",
      "Epoch 355/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.2492 - val_loss: 59.2412\n",
      "Epoch 356/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.4078 - val_loss: 59.3575\n",
      "Epoch 357/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.3767 - val_loss: 59.3114\n",
      "Epoch 358/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.1618 - val_loss: 59.4478\n",
      "Epoch 359/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.7292 - val_loss: 59.5399\n",
      "Epoch 360/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 10.4390 - val_loss: 59.6941\n",
      "Epoch 361/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.2565 - val_loss: 59.9915\n",
      "Epoch 362/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 10.4896 - val_loss: 60.0750\n",
      "Epoch 363/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.3684 - val_loss: 59.7992\n",
      "Epoch 364/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.2743 - val_loss: 59.4120\n",
      "Epoch 365/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.0097 - val_loss: 59.3591\n",
      "Epoch 366/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.0808 - val_loss: 59.6111\n",
      "Epoch 367/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.0939 - val_loss: 59.9333\n",
      "Epoch 368/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.2185 - val_loss: 59.6645\n",
      "Epoch 369/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.0722 - val_loss: 59.6088\n",
      "Epoch 370/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.4856 - val_loss: 59.4374\n",
      "Epoch 371/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.2097 - val_loss: 59.5183\n",
      "Epoch 372/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.4768 - val_loss: 59.7259\n",
      "Epoch 373/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.2164 - val_loss: 59.9009\n",
      "Epoch 374/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 10.3335 - val_loss: 59.8453\n",
      "Epoch 375/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.6421 - val_loss: 59.6657\n",
      "Epoch 376/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.0749 - val_loss: 60.0468\n",
      "Epoch 377/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.5658 - val_loss: 60.4015\n",
      "Epoch 378/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.6436 - val_loss: 60.4790\n",
      "Epoch 379/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 11.0875 - val_loss: 60.8741\n",
      "Epoch 380/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.0442 - val_loss: 61.1426\n",
      "Epoch 381/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 10.0368 - val_loss: 61.5520\n",
      "Epoch 382/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.1704 - val_loss: 61.8236\n",
      "Epoch 383/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.0199 - val_loss: 62.0815\n",
      "Epoch 384/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1366 - val_loss: 62.0646\n",
      "Epoch 385/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9.9852 - val_loss: 61.9721\n",
      "Epoch 386/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.9485 - val_loss: 61.6343\n",
      "Epoch 387/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1302 - val_loss: 61.6031\n",
      "Epoch 388/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1149 - val_loss: 61.7398\n",
      "Epoch 389/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.9766 - val_loss: 61.7273\n",
      "Epoch 390/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.2508 - val_loss: 61.8377\n",
      "Epoch 391/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1220 - val_loss: 61.8484\n",
      "Epoch 392/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1424 - val_loss: 61.8638\n",
      "Epoch 393/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.4473 - val_loss: 61.6012\n",
      "Epoch 394/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.9625 - val_loss: 61.5406\n",
      "Epoch 395/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9.8983 - val_loss: 61.2911\n",
      "Epoch 396/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.2862 - val_loss: 61.1730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1938 - val_loss: 60.9457\n",
      "Epoch 398/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.1820 - val_loss: 60.9769\n",
      "Epoch 399/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.9848 - val_loss: 60.7123\n",
      "Epoch 400/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.0699 - val_loss: 60.7565\n",
      "Epoch 401/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.5169 - val_loss: 60.2485\n",
      "Epoch 402/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.3480 - val_loss: 59.7063\n",
      "Epoch 403/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.2575 - val_loss: 59.6062\n",
      "Epoch 404/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1366 - val_loss: 59.7820\n",
      "Epoch 405/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.3328 - val_loss: 60.2675\n",
      "Epoch 406/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.2627 - val_loss: 60.2700\n",
      "Epoch 407/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.5131 - val_loss: 60.4740\n",
      "Epoch 408/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.4465 - val_loss: 60.2246\n",
      "Epoch 409/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.5497 - val_loss: 60.2166\n",
      "Epoch 410/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.5150 - val_loss: 60.2009\n",
      "Epoch 411/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.3621 - val_loss: 60.4042\n",
      "Epoch 412/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 10.0531 - val_loss: 60.7842\n",
      "Epoch 413/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 10.1575 - val_loss: 61.0605\n",
      "Epoch 414/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1145 - val_loss: 61.1554\n",
      "Epoch 415/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.4475 - val_loss: 60.9556\n",
      "Epoch 416/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.2429 - val_loss: 60.5467\n",
      "Epoch 417/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1816 - val_loss: 60.1768\n",
      "Epoch 418/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1675 - val_loss: 61.0108\n",
      "Epoch 419/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.0693 - val_loss: 61.4841\n",
      "Epoch 420/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.0122 - val_loss: 61.7420\n",
      "Epoch 421/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1902 - val_loss: 61.9395\n",
      "Epoch 422/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.9549 - val_loss: 62.1161\n",
      "Epoch 423/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.0036 - val_loss: 62.3025\n",
      "Epoch 424/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.0366 - val_loss: 62.9334\n",
      "Epoch 425/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.2965 - val_loss: 63.4496\n",
      "Epoch 426/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1221 - val_loss: 63.7996\n",
      "Epoch 427/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 9.9064 - val_loss: 63.8242\n",
      "Epoch 428/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.8639 - val_loss: 64.0739\n",
      "Epoch 429/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.0069 - val_loss: 64.1030\n",
      "Epoch 430/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.5265 - val_loss: 64.2486\n",
      "Epoch 431/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.6692 - val_loss: 63.4179\n",
      "Epoch 432/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9.8734 - val_loss: 56.5424\n",
      "Epoch 433/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.3602 - val_loss: 44.4138\n",
      "Epoch 434/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.7450 - val_loss: 46.0823\n",
      "Epoch 435/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.9703 - val_loss: 40.3326\n",
      "Epoch 436/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9.9867 - val_loss: 35.6764\n",
      "Epoch 437/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.9288 - val_loss: 39.4306\n",
      "Epoch 438/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.3369 - val_loss: 41.9235\n",
      "Epoch 439/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.3007 - val_loss: 36.8446\n",
      "Epoch 440/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.4321 - val_loss: 36.7171\n",
      "Epoch 441/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.9458 - val_loss: 37.5466\n",
      "Epoch 442/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 101.3887 - val_loss: 33.2696\n",
      "Epoch 443/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 234.8417 - val_loss: 5.4435\n",
      "Epoch 444/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 21.2359 - val_loss: 8.4007\n",
      "Epoch 445/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 21.6617 - val_loss: 4.5984\n",
      "Epoch 446/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 20.5180 - val_loss: 4.5982\n",
      "Epoch 447/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 20.6765 - val_loss: 5.2139\n",
      "Epoch 448/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 21.3951 - val_loss: 6.6244\n",
      "Epoch 449/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 20.1500 - val_loss: 9.2961\n",
      "Epoch 450/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20.3096 - val_loss: 11.1206\n",
      "Epoch 451/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 19.0518 - val_loss: 11.7271\n",
      "Epoch 452/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 18.9732 - val_loss: 11.6596\n",
      "Epoch 453/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 17.4760 - val_loss: 11.3946\n",
      "Epoch 454/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 13.5809 - val_loss: 11.2014\n",
      "Epoch 455/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12.2978 - val_loss: 10.2956\n",
      "Epoch 456/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12.1148 - val_loss: 9.2696\n",
      "Epoch 457/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 13.6849 - val_loss: 8.2737\n",
      "Epoch 458/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12.9666 - val_loss: 7.7588\n",
      "Epoch 459/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 11.6145 - val_loss: 7.6841\n",
      "Epoch 460/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 13.5989 - val_loss: 7.3893\n",
      "Epoch 461/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.4312 - val_loss: 7.0375\n",
      "Epoch 462/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11.0274 - val_loss: 6.6010\n",
      "Epoch 463/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 11.5177 - val_loss: 7.0399\n",
      "Epoch 464/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.5687 - val_loss: 8.0540\n",
      "Epoch 465/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.6571 - val_loss: 8.3213\n",
      "Epoch 466/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9.7955 - val_loss: 8.5996\n",
      "Epoch 467/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.3270 - val_loss: 8.4733\n",
      "Epoch 468/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.2685 - val_loss: 8.6150\n",
      "Epoch 469/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1148 - val_loss: 9.2222\n",
      "Epoch 470/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.2184 - val_loss: 9.5407\n",
      "Epoch 471/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.0928 - val_loss: 9.6436\n",
      "Epoch 472/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.8787 - val_loss: 9.7091\n",
      "Epoch 473/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.2628 - val_loss: 9.7908\n",
      "Epoch 474/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.8462 - val_loss: 9.8529\n",
      "Epoch 475/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.4311 - val_loss: 9.9689\n",
      "Epoch 476/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 9.9785 - val_loss: 9.7971\n",
      "Epoch 477/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.0990 - val_loss: 9.1556\n",
      "Epoch 478/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.5467 - val_loss: 8.6375\n",
      "Epoch 479/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.3726 - val_loss: 8.4755\n",
      "Epoch 480/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9.6811 - val_loss: 8.3701\n",
      "Epoch 481/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.3324 - val_loss: 8.5218\n",
      "Epoch 482/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.2234 - val_loss: 8.7074\n",
      "Epoch 483/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.3351 - val_loss: 9.0634\n",
      "Epoch 484/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.0832 - val_loss: 9.4727\n",
      "Epoch 485/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.8934 - val_loss: 9.6294\n",
      "Epoch 486/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.1956 - val_loss: 9.8147\n",
      "Epoch 487/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.2508 - val_loss: 9.7130\n",
      "Epoch 488/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.4755 - val_loss: 9.7015\n",
      "Epoch 489/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.3982 - val_loss: 9.5447\n",
      "Epoch 490/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.6060 - val_loss: 9.4656\n",
      "Epoch 491/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.1780 - val_loss: 9.0740\n",
      "Epoch 492/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.7758 - val_loss: 8.9008\n",
      "Epoch 493/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9.2504 - val_loss: 9.1651\n",
      "Epoch 494/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9.6264 - val_loss: 9.6175\n",
      "Epoch 495/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9.1462 - val_loss: 9.7580\n",
      "Epoch 496/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 8.9956 - val_loss: 9.7636\n",
      "Epoch 497/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.8264 - val_loss: 9.8930\n",
      "Epoch 498/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9.2902 - val_loss: 10.0777\n",
      "Epoch 499/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.6849 - val_loss: 10.3879\n",
      "Epoch 500/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.2138 - val_loss: 10.7851\n",
      "Epoch 501/10000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.5739 - val_loss: 10.8984\n",
      "Epoch 502/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.0100 - val_loss: 10.7438\n",
      "Epoch 503/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.9217 - val_loss: 10.6428\n",
      "Epoch 504/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.0032 - val_loss: 10.6750\n",
      "Epoch 505/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.7273 - val_loss: 10.7373\n",
      "Epoch 506/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.9278 - val_loss: 10.9735\n",
      "Epoch 507/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.2612 - val_loss: 10.8712\n",
      "Epoch 508/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.7305 - val_loss: 10.7619\n",
      "Epoch 509/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.5938 - val_loss: 10.5907\n",
      "Epoch 510/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.1124 - val_loss: 10.4407\n",
      "Epoch 511/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.7617 - val_loss: 10.4189\n",
      "Epoch 512/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.5403 - val_loss: 10.5532\n",
      "Epoch 513/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.8245 - val_loss: 10.8726\n",
      "Epoch 514/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.6446 - val_loss: 11.1077\n",
      "Epoch 515/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.1775 - val_loss: 11.2768\n",
      "Epoch 516/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.6716 - val_loss: 11.2117\n",
      "Epoch 517/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.5075 - val_loss: 10.9723\n",
      "Epoch 518/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.5514 - val_loss: 10.8100\n",
      "Epoch 519/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9.3531 - val_loss: 10.7840\n",
      "Epoch 520/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.7504 - val_loss: 11.0720\n",
      "Epoch 521/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.7546 - val_loss: 11.3858\n",
      "Epoch 522/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.1651 - val_loss: 11.4759\n",
      "Epoch 523/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.9365 - val_loss: 11.4120\n",
      "Epoch 524/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10.1416 - val_loss: 11.2815\n",
      "Epoch 525/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.5275 - val_loss: 11.3155\n",
      "Epoch 526/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9.4764 - val_loss: 11.4843\n",
      "Epoch 527/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.9155 - val_loss: 11.6553\n",
      "Epoch 528/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.5907 - val_loss: 11.8934\n",
      "Epoch 529/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.0102 - val_loss: 11.7198\n",
      "Epoch 530/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.8770 - val_loss: 11.2481\n",
      "Epoch 531/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.4588 - val_loss: 10.7653\n",
      "Epoch 532/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.3833 - val_loss: 10.4155\n",
      "Epoch 533/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 9.0211 - val_loss: 10.6023\n",
      "Epoch 534/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.9276 - val_loss: 10.7494\n",
      "Epoch 535/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.7323 - val_loss: 11.1101\n",
      "Epoch 536/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.3277 - val_loss: 11.4489\n",
      "Epoch 537/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.4947 - val_loss: 11.7679\n",
      "Epoch 538/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.8566 - val_loss: 11.7610\n",
      "Epoch 539/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.2391 - val_loss: 11.8382\n",
      "Epoch 540/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.6466 - val_loss: 11.7939\n",
      "Epoch 541/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.9554 - val_loss: 11.7303\n",
      "Epoch 542/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.5514 - val_loss: 11.6391\n",
      "Epoch 543/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.9620 - val_loss: 11.6442\n",
      "Epoch 544/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.4725 - val_loss: 11.5573\n",
      "Epoch 545/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.6716 - val_loss: 11.7756\n",
      "Epoch 546/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.1419 - val_loss: 12.0620\n",
      "Epoch 547/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.9378 - val_loss: 12.3563\n",
      "Epoch 548/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.5936 - val_loss: 12.6592\n",
      "Epoch 549/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.8436 - val_loss: 12.9744\n",
      "Epoch 550/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.5043 - val_loss: 13.3275\n",
      "Epoch 551/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.1080 - val_loss: 13.4914\n",
      "Epoch 552/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.5314 - val_loss: 13.2778\n",
      "Epoch 553/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.1425 - val_loss: 12.5935\n",
      "Epoch 554/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.5550 - val_loss: 12.3546\n",
      "Epoch 555/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.2633 - val_loss: 12.5256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.7171 - val_loss: 13.0039\n",
      "Epoch 557/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.0986 - val_loss: 13.3018\n",
      "Epoch 558/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.9905 - val_loss: 13.5286\n",
      "Epoch 559/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.8809 - val_loss: 13.5413\n",
      "Epoch 560/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.9652 - val_loss: 13.5605\n",
      "Epoch 561/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 8.0053 - val_loss: 13.7414\n",
      "Epoch 562/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.1540 - val_loss: 13.9648\n",
      "Epoch 563/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8922 - val_loss: 14.2029\n",
      "Epoch 564/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.1774 - val_loss: 14.5469\n",
      "Epoch 565/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.2953 - val_loss: 14.6106\n",
      "Epoch 566/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.6498 - val_loss: 14.6135\n",
      "Epoch 567/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.0149 - val_loss: 14.3846\n",
      "Epoch 568/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.5594 - val_loss: 14.2310\n",
      "Epoch 569/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.7667 - val_loss: 14.1988\n",
      "Epoch 570/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.2188 - val_loss: 14.2573\n",
      "Epoch 571/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.6768 - val_loss: 14.3628\n",
      "Epoch 572/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.0979 - val_loss: 14.3856\n",
      "Epoch 573/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.5260 - val_loss: 14.5092\n",
      "Epoch 574/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8792 - val_loss: 14.5873\n",
      "Epoch 575/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.0590 - val_loss: 14.6853\n",
      "Epoch 576/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8416 - val_loss: 14.6049\n",
      "Epoch 577/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.3784 - val_loss: 14.5292\n",
      "Epoch 578/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.6956 - val_loss: 14.3630\n",
      "Epoch 579/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.6405 - val_loss: 14.3431\n",
      "Epoch 580/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.8362 - val_loss: 14.3904\n",
      "Epoch 581/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.6191 - val_loss: 14.3783\n",
      "Epoch 582/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8221 - val_loss: 14.5270\n",
      "Epoch 583/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 12.6184 - val_loss: 14.8872\n",
      "Epoch 584/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.9767 - val_loss: 15.0797\n",
      "Epoch 585/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.9200 - val_loss: 14.9873\n",
      "Epoch 586/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.8762 - val_loss: 14.8422\n",
      "Epoch 587/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.4829 - val_loss: 14.6080\n",
      "Epoch 588/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.3311 - val_loss: 14.4733\n",
      "Epoch 589/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.4068 - val_loss: 14.2650\n",
      "Epoch 590/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8939 - val_loss: 14.1244\n",
      "Epoch 591/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.0151 - val_loss: 14.0824\n",
      "Epoch 592/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.1584 - val_loss: 14.1761\n",
      "Epoch 593/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.5705 - val_loss: 14.3794\n",
      "Epoch 594/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.7729 - val_loss: 14.5202\n",
      "Epoch 595/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.5466 - val_loss: 14.4923\n",
      "Epoch 596/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.8294 - val_loss: 14.4260\n",
      "Epoch 597/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.2772 - val_loss: 14.1822\n",
      "Epoch 598/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.2975 - val_loss: 14.2376\n",
      "Epoch 599/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.7269 - val_loss: 14.2578\n",
      "Epoch 600/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.6561 - val_loss: 14.3545\n",
      "Epoch 601/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.6011 - val_loss: 14.4969\n",
      "Epoch 602/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.6492 - val_loss: 14.5269\n",
      "Epoch 603/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.6453 - val_loss: 14.6761\n",
      "Epoch 604/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.7163 - val_loss: 15.0279\n",
      "Epoch 605/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8120 - val_loss: 15.1917\n",
      "Epoch 606/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4399 - val_loss: 15.4047\n",
      "Epoch 607/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 8.2686 - val_loss: 15.5305\n",
      "Epoch 608/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 8.0621 - val_loss: 15.5655\n",
      "Epoch 609/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.1427 - val_loss: 15.5076\n",
      "Epoch 610/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.5575 - val_loss: 15.5157\n",
      "Epoch 611/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.7321 - val_loss: 15.5711\n",
      "Epoch 612/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8763 - val_loss: 15.4736\n",
      "Epoch 613/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8235 - val_loss: 15.4359\n",
      "Epoch 614/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.5168 - val_loss: 15.3962\n",
      "Epoch 615/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8586 - val_loss: 15.3607\n",
      "Epoch 616/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.7453 - val_loss: 15.2572\n",
      "Epoch 617/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8324 - val_loss: 15.3496\n",
      "Epoch 618/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.9198 - val_loss: 15.3333\n",
      "Epoch 619/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.1419 - val_loss: 15.5233\n",
      "Epoch 620/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.6050 - val_loss: 15.6073\n",
      "Epoch 621/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8285 - val_loss: 15.5166\n",
      "Epoch 622/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.7764 - val_loss: 15.1910\n",
      "Epoch 623/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4221 - val_loss: 15.0281\n",
      "Epoch 624/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.0690 - val_loss: 14.7585\n",
      "Epoch 625/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.5709 - val_loss: 14.7062\n",
      "Epoch 626/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.4090 - val_loss: 15.1852\n",
      "Epoch 627/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8974 - val_loss: 15.5754\n",
      "Epoch 628/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.5191 - val_loss: 15.5007\n",
      "Epoch 629/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.0508 - val_loss: 15.3231\n",
      "Epoch 630/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.7801 - val_loss: 15.1111\n",
      "Epoch 631/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.4917 - val_loss: 15.0825\n",
      "Epoch 632/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.6622 - val_loss: 14.9740\n",
      "Epoch 633/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.7536 - val_loss: 14.9677\n",
      "Epoch 634/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.9219 - val_loss: 15.1858\n",
      "Epoch 635/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 8.1635 - val_loss: 15.2739\n",
      "Epoch 636/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.4332 - val_loss: 15.3298\n",
      "Epoch 637/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4770 - val_loss: 15.3032\n",
      "Epoch 638/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4642 - val_loss: 15.1095\n",
      "Epoch 639/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.4084 - val_loss: 14.8960\n",
      "Epoch 640/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.4627 - val_loss: 14.9965\n",
      "Epoch 641/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3040 - val_loss: 15.3331\n",
      "Epoch 642/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1961 - val_loss: 15.7911\n",
      "Epoch 643/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2823 - val_loss: 16.2960\n",
      "Epoch 644/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.5598 - val_loss: 16.5219\n",
      "Epoch 645/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.6831 - val_loss: 16.5029\n",
      "Epoch 646/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.0948 - val_loss: 16.2986\n",
      "Epoch 647/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.4435 - val_loss: 16.1111\n",
      "Epoch 648/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.4894 - val_loss: 16.2119\n",
      "Epoch 649/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.7016 - val_loss: 16.4211\n",
      "Epoch 650/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4375 - val_loss: 16.3870\n",
      "Epoch 651/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.5693 - val_loss: 16.1939\n",
      "Epoch 652/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3859 - val_loss: 15.9030\n",
      "Epoch 653/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4273 - val_loss: 15.8915\n",
      "Epoch 654/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.4224 - val_loss: 15.8901\n",
      "Epoch 655/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.9881 - val_loss: 16.0279\n",
      "Epoch 656/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3627 - val_loss: 16.1659\n",
      "Epoch 657/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3570 - val_loss: 16.3980\n",
      "Epoch 658/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.4013 - val_loss: 16.1512\n",
      "Epoch 659/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2828 - val_loss: 15.8356\n",
      "Epoch 660/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.6860 - val_loss: 15.6009\n",
      "Epoch 661/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.8224 - val_loss: 15.7802\n",
      "Epoch 662/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2625 - val_loss: 15.9181\n",
      "Epoch 663/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.8008 - val_loss: 16.1173\n",
      "Epoch 664/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 8.0656 - val_loss: 16.2640\n",
      "Epoch 665/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1313 - val_loss: 16.3697\n",
      "Epoch 666/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.9852 - val_loss: 16.4313\n",
      "Epoch 667/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.3996 - val_loss: 16.4415\n",
      "Epoch 668/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.4525 - val_loss: 16.3164\n",
      "Epoch 669/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.5718 - val_loss: 16.1849\n",
      "Epoch 670/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3879 - val_loss: 16.2067\n",
      "Epoch 671/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.2614 - val_loss: 16.1311\n",
      "Epoch 672/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.7076 - val_loss: 16.0988\n",
      "Epoch 673/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.6790 - val_loss: 16.4129\n",
      "Epoch 674/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2605 - val_loss: 16.6125\n",
      "Epoch 675/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.6648 - val_loss: 16.5306\n",
      "Epoch 676/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.5313 - val_loss: 16.3002\n",
      "Epoch 677/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4672 - val_loss: 16.4134\n",
      "Epoch 678/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.3376 - val_loss: 16.4993\n",
      "Epoch 679/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2881 - val_loss: 16.7169\n",
      "Epoch 680/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0700 - val_loss: 16.9236\n",
      "Epoch 681/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4946 - val_loss: 17.0089\n",
      "Epoch 682/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.5666 - val_loss: 16.9014\n",
      "Epoch 683/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.5249 - val_loss: 16.7178\n",
      "Epoch 684/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.5128 - val_loss: 16.4349\n",
      "Epoch 685/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2938 - val_loss: 16.4175\n",
      "Epoch 686/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.5688 - val_loss: 16.6779\n",
      "Epoch 687/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3664 - val_loss: 16.8971\n",
      "Epoch 688/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.0503 - val_loss: 17.0349\n",
      "Epoch 689/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.0075 - val_loss: 17.1173\n",
      "Epoch 690/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.7057 - val_loss: 17.2404\n",
      "Epoch 691/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.6732 - val_loss: 17.3969\n",
      "Epoch 692/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9997 - val_loss: 17.4295\n",
      "Epoch 693/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.2774 - val_loss: 17.6023\n",
      "Epoch 694/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.2253 - val_loss: 17.8478\n",
      "Epoch 695/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9337 - val_loss: 18.0315\n",
      "Epoch 696/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4111 - val_loss: 18.1863\n",
      "Epoch 697/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.5895 - val_loss: 18.2085\n",
      "Epoch 698/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1888 - val_loss: 18.0910\n",
      "Epoch 699/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8702 - val_loss: 17.7800\n",
      "Epoch 700/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.3272 - val_loss: 17.5399\n",
      "Epoch 701/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9429 - val_loss: 17.5844\n",
      "Epoch 702/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3747 - val_loss: 17.7754\n",
      "Epoch 703/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.4992 - val_loss: 18.0373\n",
      "Epoch 704/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.9056 - val_loss: 18.0999\n",
      "Epoch 705/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1916 - val_loss: 18.3221\n",
      "Epoch 706/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1654 - val_loss: 18.3456\n",
      "Epoch 707/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4052 - val_loss: 18.2153\n",
      "Epoch 708/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2033 - val_loss: 18.1924\n",
      "Epoch 709/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8534 - val_loss: 18.3144\n",
      "Epoch 710/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.6757 - val_loss: 18.5708\n",
      "Epoch 711/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1626 - val_loss: 18.9209\n",
      "Epoch 712/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9600 - val_loss: 19.0973\n",
      "Epoch 713/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9121 - val_loss: 18.8641\n",
      "Epoch 714/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3399 - val_loss: 18.5369\n",
      "Epoch 715/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.8148 - val_loss: 18.2896\n",
      "Epoch 716/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9596 - val_loss: 18.3555\n",
      "Epoch 717/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6892 - val_loss: 18.8052\n",
      "Epoch 718/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9042 - val_loss: 19.0908\n",
      "Epoch 719/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8884 - val_loss: 19.1235\n",
      "Epoch 720/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2662 - val_loss: 18.7362\n",
      "Epoch 721/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.4256 - val_loss: 18.4171\n",
      "Epoch 722/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.7948 - val_loss: 18.3745\n",
      "Epoch 723/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.9853 - val_loss: 18.1935\n",
      "Epoch 724/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9939 - val_loss: 17.8844\n",
      "Epoch 725/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.1518 - val_loss: 18.0291\n",
      "Epoch 726/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3993 - val_loss: 18.3787\n",
      "Epoch 727/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.3535 - val_loss: 18.6259\n",
      "Epoch 728/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3152 - val_loss: 18.2798\n",
      "Epoch 729/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9966 - val_loss: 17.2767\n",
      "Epoch 730/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8478 - val_loss: 16.2212\n",
      "Epoch 731/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0203 - val_loss: 14.8340\n",
      "Epoch 732/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8631 - val_loss: 15.8690\n",
      "Epoch 733/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6884 - val_loss: 16.9436\n",
      "Epoch 734/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7341 - val_loss: 17.7663\n",
      "Epoch 735/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.0889 - val_loss: 18.0440\n",
      "Epoch 736/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.3535 - val_loss: 18.7281\n",
      "Epoch 737/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7820 - val_loss: 18.9075\n",
      "Epoch 738/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2067 - val_loss: 19.1384\n",
      "Epoch 739/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.3111 - val_loss: 19.0822\n",
      "Epoch 740/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.0881 - val_loss: 18.5447\n",
      "Epoch 741/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1784 - val_loss: 17.0151\n",
      "Epoch 742/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.6397 - val_loss: 15.9885\n",
      "Epoch 743/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9187 - val_loss: 15.0650\n",
      "Epoch 744/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1672 - val_loss: 16.0283\n",
      "Epoch 745/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3368 - val_loss: 16.8850\n",
      "Epoch 746/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.2552 - val_loss: 17.6778\n",
      "Epoch 747/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.0315 - val_loss: 18.1285\n",
      "Epoch 748/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.9539 - val_loss: 18.2203\n",
      "Epoch 749/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4335 - val_loss: 18.0516\n",
      "Epoch 750/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3522 - val_loss: 18.1742\n",
      "Epoch 751/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1269 - val_loss: 18.4410\n",
      "Epoch 752/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.9510 - val_loss: 18.5028\n",
      "Epoch 753/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.8122 - val_loss: 18.4765\n",
      "Epoch 754/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0165 - val_loss: 17.9587\n",
      "Epoch 755/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7443 - val_loss: 17.3035\n",
      "Epoch 756/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.4111 - val_loss: 16.9079\n",
      "Epoch 757/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.8511 - val_loss: 16.7768\n",
      "Epoch 758/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2736 - val_loss: 16.8074\n",
      "Epoch 759/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5898 - val_loss: 16.1751\n",
      "Epoch 760/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.6327 - val_loss: 16.2203\n",
      "Epoch 761/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6015 - val_loss: 16.8607\n",
      "Epoch 762/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8156 - val_loss: 17.0845\n",
      "Epoch 763/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.6179 - val_loss: 16.8455\n",
      "Epoch 764/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0349 - val_loss: 17.5095\n",
      "Epoch 765/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7778 - val_loss: 17.9466\n",
      "Epoch 766/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.8312 - val_loss: 18.1815\n",
      "Epoch 767/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5907 - val_loss: 18.1908\n",
      "Epoch 768/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.5321 - val_loss: 17.9796\n",
      "Epoch 769/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.0698 - val_loss: 18.1656\n",
      "Epoch 770/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7679 - val_loss: 18.4556\n",
      "Epoch 771/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9983 - val_loss: 17.9633\n",
      "Epoch 772/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.6400 - val_loss: 17.0657\n",
      "Epoch 773/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.6612 - val_loss: 16.6403\n",
      "Epoch 774/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8140 - val_loss: 16.3247\n",
      "Epoch 775/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.3008 - val_loss: 16.8502\n",
      "Epoch 776/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2401 - val_loss: 17.5565\n",
      "Epoch 777/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.7372 - val_loss: 18.0028\n",
      "Epoch 778/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.1810 - val_loss: 17.5609\n",
      "Epoch 779/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 7.4388 - val_loss: 17.7432\n",
      "Epoch 780/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.0955 - val_loss: 17.7832\n",
      "Epoch 781/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.9631 - val_loss: 17.4812\n",
      "Epoch 782/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2047 - val_loss: 17.3621\n",
      "Epoch 783/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.1519 - val_loss: 17.5286\n",
      "Epoch 784/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8070 - val_loss: 17.3900\n",
      "Epoch 785/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0093 - val_loss: 17.2358\n",
      "Epoch 786/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8894 - val_loss: 17.2078\n",
      "Epoch 787/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7005 - val_loss: 17.4192\n",
      "Epoch 788/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3874 - val_loss: 17.3922\n",
      "Epoch 789/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.0564 - val_loss: 17.2883\n",
      "Epoch 790/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.9408 - val_loss: 17.4594\n",
      "Epoch 791/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9134 - val_loss: 17.4721\n",
      "Epoch 792/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7985 - val_loss: 17.3267\n",
      "Epoch 793/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2964 - val_loss: 17.1677\n",
      "Epoch 794/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9126 - val_loss: 17.2887\n",
      "Epoch 795/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2416 - val_loss: 16.9853\n",
      "Epoch 796/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.9463 - val_loss: 16.7454\n",
      "Epoch 797/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0122 - val_loss: 16.3842\n",
      "Epoch 798/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8635 - val_loss: 16.1062\n",
      "Epoch 799/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8058 - val_loss: 15.8406\n",
      "Epoch 800/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2728 - val_loss: 15.8216\n",
      "Epoch 801/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9236 - val_loss: 15.9506\n",
      "Epoch 802/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8896 - val_loss: 15.3069\n",
      "Epoch 803/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.0290 - val_loss: 15.1543\n",
      "Epoch 804/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7202 - val_loss: 15.5669\n",
      "Epoch 805/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9633 - val_loss: 16.3634\n",
      "Epoch 806/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0457 - val_loss: 16.6098\n",
      "Epoch 807/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9090 - val_loss: 16.6101\n",
      "Epoch 808/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1414 - val_loss: 16.4549\n",
      "Epoch 809/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7752 - val_loss: 16.7282\n",
      "Epoch 810/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9171 - val_loss: 16.8074\n",
      "Epoch 811/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7582 - val_loss: 16.7754\n",
      "Epoch 812/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7593 - val_loss: 16.7842\n",
      "Epoch 813/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2205 - val_loss: 16.7828\n",
      "Epoch 814/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9057 - val_loss: 16.9686\n",
      "Epoch 815/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1462 - val_loss: 17.0102\n",
      "Epoch 816/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9631 - val_loss: 17.0895\n",
      "Epoch 817/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3071 - val_loss: 17.1264\n",
      "Epoch 818/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.4566 - val_loss: 16.9140\n",
      "Epoch 819/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9137 - val_loss: 16.0721\n",
      "Epoch 820/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.9217 - val_loss: 14.4909\n",
      "Epoch 821/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.9736 - val_loss: 13.8620\n",
      "Epoch 822/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0203 - val_loss: 13.9962\n",
      "Epoch 823/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5349 - val_loss: 14.3820\n",
      "Epoch 824/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.0662 - val_loss: 15.2397\n",
      "Epoch 825/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7525 - val_loss: 17.0499\n",
      "Epoch 826/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5430 - val_loss: 17.4644\n",
      "Epoch 827/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1251 - val_loss: 17.8436\n",
      "Epoch 828/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8185 - val_loss: 17.5546\n",
      "Epoch 829/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4209 - val_loss: 16.8385\n",
      "Epoch 830/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7663 - val_loss: 15.8152\n",
      "Epoch 831/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6817 - val_loss: 13.7947\n",
      "Epoch 832/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0259 - val_loss: 14.0846\n",
      "Epoch 833/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7022 - val_loss: 15.8786\n",
      "Epoch 834/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.0280 - val_loss: 17.2558\n",
      "Epoch 835/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9090 - val_loss: 17.7350\n",
      "Epoch 836/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.9150 - val_loss: 17.5257\n",
      "Epoch 837/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.0179 - val_loss: 17.2444\n",
      "Epoch 838/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2035 - val_loss: 16.1439\n",
      "Epoch 839/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.9966 - val_loss: 15.8685\n",
      "Epoch 840/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8735 - val_loss: 15.6627\n",
      "Epoch 841/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9932 - val_loss: 15.7452\n",
      "Epoch 842/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.5034 - val_loss: 16.4177\n",
      "Epoch 843/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9874 - val_loss: 16.3648\n",
      "Epoch 844/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8269 - val_loss: 16.1199\n",
      "Epoch 845/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4975 - val_loss: 16.1630\n",
      "Epoch 846/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.9095 - val_loss: 16.2069\n",
      "Epoch 847/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0466 - val_loss: 15.9458\n",
      "Epoch 848/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.8947 - val_loss: 15.4579\n",
      "Epoch 849/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.8638 - val_loss: 14.3014\n",
      "Epoch 850/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6529 - val_loss: 13.7774\n",
      "Epoch 851/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6924 - val_loss: 14.8967\n",
      "Epoch 852/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7874 - val_loss: 15.6011\n",
      "Epoch 853/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6853 - val_loss: 13.7488\n",
      "Epoch 854/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6519 - val_loss: 13.7468\n",
      "Epoch 855/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7260 - val_loss: 14.6947\n",
      "Epoch 856/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5103 - val_loss: 18.1799\n",
      "Epoch 857/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8363 - val_loss: 19.6299\n",
      "Epoch 858/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.8392 - val_loss: 18.9216\n",
      "Epoch 859/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9486 - val_loss: 17.8102\n",
      "Epoch 860/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6295 - val_loss: 17.5009\n",
      "Epoch 861/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6765 - val_loss: 17.4582\n",
      "Epoch 862/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7021 - val_loss: 17.9324\n",
      "Epoch 863/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6935 - val_loss: 18.0793\n",
      "Epoch 864/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7332 - val_loss: 18.0116\n",
      "Epoch 865/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7179 - val_loss: 17.4614\n",
      "Epoch 866/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7015 - val_loss: 16.0662\n",
      "Epoch 867/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7816 - val_loss: 14.5520\n",
      "Epoch 868/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7365 - val_loss: 13.4146\n",
      "Epoch 869/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0637 - val_loss: 12.3002\n",
      "Epoch 870/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8361 - val_loss: 14.3406\n",
      "Epoch 871/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5947 - val_loss: 17.1474\n",
      "Epoch 872/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 7.1939 - val_loss: 18.2019\n",
      "Epoch 873/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8698 - val_loss: 16.7682\n",
      "Epoch 874/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0213 - val_loss: 15.6641\n",
      "Epoch 875/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9189 - val_loss: 15.4186\n",
      "Epoch 876/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5255 - val_loss: 13.5285\n",
      "Epoch 877/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6318 - val_loss: 12.2740\n",
      "Epoch 878/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8432 - val_loss: 12.4334\n",
      "Epoch 879/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5471 - val_loss: 12.8779\n",
      "Epoch 880/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5717 - val_loss: 14.3404\n",
      "Epoch 881/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6183 - val_loss: 11.2779\n",
      "Epoch 882/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8296 - val_loss: 9.5308\n",
      "Epoch 883/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8387 - val_loss: 14.5911\n",
      "Epoch 884/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7407 - val_loss: 19.2608\n",
      "Epoch 885/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.1150 - val_loss: 18.5009\n",
      "Epoch 886/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3927 - val_loss: 15.1008\n",
      "Epoch 887/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4901 - val_loss: 10.4474\n",
      "Epoch 888/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6979 - val_loss: 7.3844\n",
      "Epoch 889/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.8382 - val_loss: 11.2345\n",
      "Epoch 890/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4971 - val_loss: 14.2061\n",
      "Epoch 891/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4852 - val_loss: 16.9607\n",
      "Epoch 892/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7785 - val_loss: 19.8674\n",
      "Epoch 893/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6761 - val_loss: 17.5776\n",
      "Epoch 894/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7768 - val_loss: 11.9184\n",
      "Epoch 895/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6527 - val_loss: 10.5971\n",
      "Epoch 896/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5614 - val_loss: 13.6387\n",
      "Epoch 897/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8505 - val_loss: 14.8262\n",
      "Epoch 898/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7859 - val_loss: 15.4776\n",
      "Epoch 899/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6379 - val_loss: 16.1363\n",
      "Epoch 900/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6258 - val_loss: 16.0695\n",
      "Epoch 901/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7796 - val_loss: 12.7544\n",
      "Epoch 902/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5368 - val_loss: 8.9529\n",
      "Epoch 903/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6339 - val_loss: 8.1922\n",
      "Epoch 904/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.8042 - val_loss: 9.7811\n",
      "Epoch 905/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7372 - val_loss: 13.9602\n",
      "Epoch 906/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7666 - val_loss: 12.6920\n",
      "Epoch 907/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6367 - val_loss: 12.4356\n",
      "Epoch 908/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6018 - val_loss: 12.3337\n",
      "Epoch 909/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5155 - val_loss: 11.9214\n",
      "Epoch 910/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6484 - val_loss: 11.8219\n",
      "Epoch 911/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6922 - val_loss: 11.6421\n",
      "Epoch 912/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7861 - val_loss: 10.0799\n",
      "Epoch 913/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5706 - val_loss: 11.5265\n",
      "Epoch 914/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5701 - val_loss: 14.4188\n",
      "Epoch 915/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7039 - val_loss: 15.7414\n",
      "Epoch 916/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6977 - val_loss: 15.7455\n",
      "Epoch 917/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3788 - val_loss: 13.1042\n",
      "Epoch 918/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7205 - val_loss: 9.2454\n",
      "Epoch 919/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2501 - val_loss: 7.9718\n",
      "Epoch 920/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5248 - val_loss: 7.9777\n",
      "Epoch 921/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6475 - val_loss: 8.4113\n",
      "Epoch 922/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6386 - val_loss: 11.2061\n",
      "Epoch 923/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7801 - val_loss: 13.4830\n",
      "Epoch 924/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4235 - val_loss: 15.5668\n",
      "Epoch 925/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7241 - val_loss: 15.7257\n",
      "Epoch 926/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4834 - val_loss: 14.7575\n",
      "Epoch 927/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6254 - val_loss: 14.1686\n",
      "Epoch 928/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5739 - val_loss: 14.0193\n",
      "Epoch 929/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2495 - val_loss: 12.7605\n",
      "Epoch 930/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7156 - val_loss: 11.9010\n",
      "Epoch 931/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7772 - val_loss: 11.4587\n",
      "Epoch 932/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4893 - val_loss: 9.4208\n",
      "Epoch 933/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4540 - val_loss: 7.3407\n",
      "Epoch 934/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4599 - val_loss: 6.3314\n",
      "Epoch 935/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4070 - val_loss: 6.6990\n",
      "Epoch 936/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7983 - val_loss: 9.5028\n",
      "Epoch 937/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4190 - val_loss: 14.2454\n",
      "Epoch 938/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5896 - val_loss: 16.0987\n",
      "Epoch 939/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2295 - val_loss: 15.2379\n",
      "Epoch 940/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5688 - val_loss: 12.8012\n",
      "Epoch 941/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6308 - val_loss: 11.4061\n",
      "Epoch 942/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5175 - val_loss: 10.8580\n",
      "Epoch 943/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3617 - val_loss: 13.0598\n",
      "Epoch 944/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5170 - val_loss: 12.4175\n",
      "Epoch 945/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4756 - val_loss: 10.8221\n",
      "Epoch 946/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8062 - val_loss: 10.3311\n",
      "Epoch 947/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.0624 - val_loss: 10.6646\n",
      "Epoch 948/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4504 - val_loss: 10.0525\n",
      "Epoch 949/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.5412 - val_loss: 8.6554\n",
      "Epoch 950/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9121 - val_loss: 8.2637\n",
      "Epoch 951/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6294 - val_loss: 9.4093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.8182 - val_loss: 11.9929\n",
      "Epoch 953/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4279 - val_loss: 14.2943\n",
      "Epoch 954/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3834 - val_loss: 13.3202\n",
      "Epoch 955/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7841 - val_loss: 12.2971\n",
      "Epoch 956/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4131 - val_loss: 10.7722\n",
      "Epoch 957/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.3763 - val_loss: 11.1178\n",
      "Epoch 958/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5727 - val_loss: 13.0652\n",
      "Epoch 959/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7620 - val_loss: 15.3571\n",
      "Epoch 960/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6530 - val_loss: 15.7876\n",
      "Epoch 961/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9848 - val_loss: 10.6014\n",
      "Epoch 962/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.7339 - val_loss: 7.1297\n",
      "Epoch 963/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5583 - val_loss: 7.0852\n",
      "Epoch 964/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8338 - val_loss: 12.7282\n",
      "Epoch 965/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6322 - val_loss: 15.0042\n",
      "Epoch 966/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7565 - val_loss: 11.0382\n",
      "Epoch 967/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4965 - val_loss: 9.0938\n",
      "Epoch 968/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.0496 - val_loss: 8.8250\n",
      "Epoch 969/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4120 - val_loss: 11.0079\n",
      "Epoch 970/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6655 - val_loss: 13.5239\n",
      "Epoch 971/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6850 - val_loss: 14.4884\n",
      "Epoch 972/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5511 - val_loss: 14.7788\n",
      "Epoch 973/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1365 - val_loss: 14.2167\n",
      "Epoch 974/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5496 - val_loss: 12.4638\n",
      "Epoch 975/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.1801 - val_loss: 10.6907\n",
      "Epoch 976/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2614 - val_loss: 9.5513\n",
      "Epoch 977/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5207 - val_loss: 8.7157\n",
      "Epoch 978/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.3398 - val_loss: 10.4328\n",
      "Epoch 979/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3219 - val_loss: 12.0496\n",
      "Epoch 980/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.9431 - val_loss: 12.9921\n",
      "Epoch 981/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5587 - val_loss: 11.9518\n",
      "Epoch 982/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3097 - val_loss: 12.1943\n",
      "Epoch 983/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2203 - val_loss: 13.2189\n",
      "Epoch 984/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4652 - val_loss: 12.9273\n",
      "Epoch 985/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1350 - val_loss: 12.7598\n",
      "Epoch 986/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1462 - val_loss: 11.0986\n",
      "Epoch 987/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.3285 - val_loss: 9.5987\n",
      "Epoch 988/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.6349 - val_loss: 8.6523\n",
      "Epoch 989/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8916 - val_loss: 7.4299\n",
      "Epoch 990/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.3002 - val_loss: 7.7997\n",
      "Epoch 991/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8493 - val_loss: 8.0758\n",
      "Epoch 992/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.3452 - val_loss: 8.7816\n",
      "Epoch 993/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0024 - val_loss: 9.7158\n",
      "Epoch 994/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1367 - val_loss: 8.6416\n",
      "Epoch 995/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7953 - val_loss: 8.4418\n",
      "Epoch 996/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.0427 - val_loss: 7.7878\n",
      "Epoch 997/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8250 - val_loss: 8.4213\n",
      "Epoch 998/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.8696 - val_loss: 9.7544\n",
      "Epoch 999/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5001 - val_loss: 9.4801\n",
      "Epoch 1000/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5477 - val_loss: 8.2554\n",
      "Epoch 1001/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5076 - val_loss: 8.8084\n",
      "Epoch 1002/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.6652 - val_loss: 13.7480\n",
      "Epoch 1003/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4220 - val_loss: 15.6246\n",
      "Epoch 1004/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4238 - val_loss: 13.3476\n",
      "Epoch 1005/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.5215 - val_loss: 11.8442\n",
      "Epoch 1006/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.3342 - val_loss: 9.9003\n",
      "Epoch 1007/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.1141 - val_loss: 9.3928\n",
      "Epoch 1008/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.8327 - val_loss: 9.5831\n",
      "Epoch 1009/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.1798 - val_loss: 8.6344\n",
      "Epoch 1010/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.6063 - val_loss: 6.4262\n",
      "Epoch 1011/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.0429 - val_loss: 5.0059\n",
      "Epoch 1012/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.0002 - val_loss: 5.1621\n",
      "Epoch 1013/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.1851 - val_loss: 6.2196\n",
      "Epoch 1014/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.1984 - val_loss: 9.3262\n",
      "Epoch 1015/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5267 - val_loss: 10.1234\n",
      "Epoch 1016/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.0240 - val_loss: 10.3334\n",
      "Epoch 1017/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5654 - val_loss: 9.5467\n",
      "Epoch 1018/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.3483 - val_loss: 8.4706\n",
      "Epoch 1019/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.4130 - val_loss: 9.3001\n",
      "Epoch 1020/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.2949 - val_loss: 10.8194\n",
      "Epoch 1021/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0946 - val_loss: 12.3702\n",
      "Epoch 1022/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.3469 - val_loss: 11.4560\n",
      "Epoch 1023/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.9500 - val_loss: 10.3051\n",
      "Epoch 1024/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3053 - val_loss: 8.8133\n",
      "Epoch 1025/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.9021 - val_loss: 8.6020\n",
      "Epoch 1026/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.8302 - val_loss: 7.6446\n",
      "Epoch 1027/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.6409 - val_loss: 7.1493\n",
      "Epoch 1028/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.8804 - val_loss: 7.5869\n",
      "Epoch 1029/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.2673 - val_loss: 10.7345\n",
      "Epoch 1030/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.2398 - val_loss: 9.0782\n",
      "Epoch 1031/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7059 - val_loss: 5.7995\n",
      "Epoch 1032/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5146 - val_loss: 12.3765\n",
      "Epoch 1033/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5885 - val_loss: 14.7796\n",
      "Epoch 1034/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.4569 - val_loss: 12.5607\n",
      "Epoch 1035/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0576 - val_loss: 10.2610\n",
      "Epoch 1036/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.1668 - val_loss: 9.7284\n",
      "Epoch 1037/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6934 - val_loss: 10.0253\n",
      "Epoch 1038/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0406 - val_loss: 10.0603\n",
      "Epoch 1039/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.1832 - val_loss: 10.0202\n",
      "Epoch 1040/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.1632 - val_loss: 9.9518\n",
      "Epoch 1041/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.3908 - val_loss: 8.4768\n",
      "Epoch 1042/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.7731 - val_loss: 6.5922\n",
      "Epoch 1043/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.6190 - val_loss: 8.1005\n",
      "Epoch 1044/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.8411 - val_loss: 11.4470\n",
      "Epoch 1045/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 9.3499 - val_loss: 14.3581\n",
      "Epoch 1046/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.7569 - val_loss: 13.6757\n",
      "Epoch 1047/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 8.5545 - val_loss: 9.5444\n",
      "Epoch 1048/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8228 - val_loss: 9.8765\n",
      "Epoch 1049/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.4885 - val_loss: 9.5526\n",
      "Epoch 1050/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.9794 - val_loss: 10.1645\n",
      "Epoch 1051/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 8.0385 - val_loss: 11.0897\n",
      "Epoch 1052/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.5755 - val_loss: 11.0967\n",
      "Epoch 1053/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.0046 - val_loss: 11.1883\n",
      "Epoch 1054/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.6298 - val_loss: 11.2252\n",
      "Epoch 1055/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4345 - val_loss: 12.4827\n",
      "Epoch 1056/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.2390 - val_loss: 12.4312\n",
      "Epoch 1057/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.5780 - val_loss: 10.2108\n",
      "Epoch 1058/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.0159 - val_loss: 8.2339\n",
      "Epoch 1059/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.1473 - val_loss: 8.2180\n",
      "Epoch 1060/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.5492 - val_loss: 10.8534\n",
      "Epoch 1061/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.7163 - val_loss: 11.0996\n",
      "Epoch 1062/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.2242 - val_loss: 9.4276\n",
      "Epoch 1063/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.1059 - val_loss: 8.1622\n",
      "Epoch 1064/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.4818 - val_loss: 7.5704\n",
      "Epoch 1065/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6744 - val_loss: 7.9262\n",
      "Epoch 1066/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.4936 - val_loss: 9.4922\n",
      "Epoch 1067/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.1635 - val_loss: 9.2298\n",
      "Epoch 1068/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.1810 - val_loss: 8.0271\n",
      "Epoch 1069/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.1237 - val_loss: 8.2656\n",
      "Epoch 1070/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.9870 - val_loss: 11.5350\n",
      "Epoch 1071/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.0782 - val_loss: 13.9907\n",
      "Epoch 1072/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4632 - val_loss: 11.0573\n",
      "Epoch 1073/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8658 - val_loss: 8.1073\n",
      "Epoch 1074/10000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 6.6861 - val_loss: 9.5260\n",
      "Epoch 1075/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.0147 - val_loss: 12.8997\n",
      "Epoch 1076/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.7673 - val_loss: 14.1070\n",
      "Epoch 1077/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.7127 - val_loss: 13.0724\n",
      "Epoch 1078/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.3925 - val_loss: 11.5610\n",
      "Epoch 1079/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6.3275 - val_loss: 10.8200\n",
      "Epoch 1080/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4489 - val_loss: 11.1651\n",
      "Epoch 1081/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3470 - val_loss: 11.6288\n",
      "Epoch 1082/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.2965 - val_loss: 12.3700\n",
      "Epoch 1083/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.3080 - val_loss: 11.3510\n",
      "Epoch 1084/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.1934 - val_loss: 9.1645\n",
      "Epoch 1085/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.2018 - val_loss: 7.0773\n",
      "Epoch 1086/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.2564 - val_loss: 7.1251\n",
      "Epoch 1087/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4981 - val_loss: 7.3100\n",
      "Epoch 1088/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.0386 - val_loss: 7.7790\n",
      "Epoch 1089/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5738 - val_loss: 7.2062\n",
      "Epoch 1090/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1548 - val_loss: 7.2883\n",
      "Epoch 1091/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5191 - val_loss: 7.2357\n",
      "Epoch 1092/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6495 - val_loss: 7.2313\n",
      "Epoch 1093/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4392 - val_loss: 7.8025\n",
      "Epoch 1094/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8233 - val_loss: 8.4345\n",
      "Epoch 1095/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0392 - val_loss: 7.7541\n",
      "Epoch 1096/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5955 - val_loss: 7.6946\n",
      "Epoch 1097/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.3136 - val_loss: 8.1156\n",
      "Epoch 1098/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3456 - val_loss: 7.9987\n",
      "Epoch 1099/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2213 - val_loss: 8.1003\n",
      "Epoch 1100/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2736 - val_loss: 7.6668\n",
      "Epoch 1101/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5316 - val_loss: 7.2613\n",
      "Epoch 1102/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5711 - val_loss: 7.5500\n",
      "Epoch 1103/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6461 - val_loss: 8.2042\n",
      "Epoch 1104/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2614 - val_loss: 8.3947\n",
      "Epoch 1105/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2212 - val_loss: 8.6643\n",
      "Epoch 1106/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0320 - val_loss: 9.0779\n",
      "Epoch 1107/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4616 - val_loss: 8.8791\n",
      "Epoch 1108/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8682 - val_loss: 8.1640\n",
      "Epoch 1109/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7737 - val_loss: 7.9352\n",
      "Epoch 1110/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 6.2358 - val_loss: 7.8164\n",
      "Epoch 1111/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.9371 - val_loss: 7.5506\n",
      "Epoch 1112/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7224 - val_loss: 8.3153\n",
      "Epoch 1113/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1639 - val_loss: 9.2788\n",
      "Epoch 1114/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.3235 - val_loss: 9.5888\n",
      "Epoch 1115/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7023 - val_loss: 9.0110\n",
      "Epoch 1116/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7092 - val_loss: 7.5512\n",
      "Epoch 1117/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6697 - val_loss: 7.0822\n",
      "Epoch 1118/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1390 - val_loss: 7.0312\n",
      "Epoch 1119/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6430 - val_loss: 7.1110\n",
      "Epoch 1120/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.9582 - val_loss: 7.0189\n",
      "Epoch 1121/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0517 - val_loss: 7.1020\n",
      "Epoch 1122/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.9258 - val_loss: 6.9483\n",
      "Epoch 1123/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0719 - val_loss: 6.7745\n",
      "Epoch 1124/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.3664 - val_loss: 6.8404\n",
      "Epoch 1125/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5129 - val_loss: 6.8490\n",
      "Epoch 1126/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.9709 - val_loss: 6.6836\n",
      "Epoch 1127/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3843 - val_loss: 6.6416\n",
      "Epoch 1128/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.2933 - val_loss: 6.5212\n",
      "Epoch 1129/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.8556 - val_loss: 6.6329\n",
      "Epoch 1130/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7687 - val_loss: 6.7488\n",
      "Epoch 1131/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1151 - val_loss: 7.0112\n",
      "Epoch 1132/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4204 - val_loss: 8.0130\n",
      "Epoch 1133/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4393 - val_loss: 9.2065\n",
      "Epoch 1134/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.9187 - val_loss: 9.9388\n",
      "Epoch 1135/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.3488 - val_loss: 9.9203\n",
      "Epoch 1136/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0404 - val_loss: 8.5027\n",
      "Epoch 1137/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5718 - val_loss: 7.8569\n",
      "Epoch 1138/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2948 - val_loss: 7.7017\n",
      "Epoch 1139/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8783 - val_loss: 7.5406\n",
      "Epoch 1140/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4582 - val_loss: 7.4075\n",
      "Epoch 1141/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.7496 - val_loss: 7.1368\n",
      "Epoch 1142/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3934 - val_loss: 7.2716\n",
      "Epoch 1143/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.7153 - val_loss: 7.4748\n",
      "Epoch 1144/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.7159 - val_loss: 7.8585\n",
      "Epoch 1145/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.8906 - val_loss: 8.1473\n",
      "Epoch 1146/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6856 - val_loss: 8.0235\n",
      "Epoch 1147/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0203 - val_loss: 7.6713\n",
      "Epoch 1148/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2503 - val_loss: 7.3578\n",
      "Epoch 1149/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.5842 - val_loss: 7.2889\n",
      "Epoch 1150/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8065 - val_loss: 7.3550\n",
      "Epoch 1151/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.3114 - val_loss: 7.5791\n",
      "Epoch 1152/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.6262 - val_loss: 8.1465\n",
      "Epoch 1153/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2569 - val_loss: 8.4109\n",
      "Epoch 1154/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9902 - val_loss: 8.6587\n",
      "Epoch 1155/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9779 - val_loss: 8.3808\n",
      "Epoch 1156/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7798 - val_loss: 7.8654\n",
      "Epoch 1157/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7412 - val_loss: 7.4294\n",
      "Epoch 1158/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1907 - val_loss: 6.9152\n",
      "Epoch 1159/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6683 - val_loss: 6.9888\n",
      "Epoch 1160/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1179 - val_loss: 7.4377\n",
      "Epoch 1161/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8837 - val_loss: 7.9791\n",
      "Epoch 1162/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8442 - val_loss: 8.1246\n",
      "Epoch 1163/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.7664 - val_loss: 7.9021\n",
      "Epoch 1164/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.8010 - val_loss: 7.5863\n",
      "Epoch 1165/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5233 - val_loss: 7.4855\n",
      "Epoch 1166/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1437 - val_loss: 7.8090\n",
      "Epoch 1167/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8905 - val_loss: 8.5014\n",
      "Epoch 1168/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3053 - val_loss: 8.4947\n",
      "Epoch 1169/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.7617 - val_loss: 8.2546\n",
      "Epoch 1170/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4154 - val_loss: 8.1121\n",
      "Epoch 1171/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0144 - val_loss: 7.8002\n",
      "Epoch 1172/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7987 - val_loss: 7.8610\n",
      "Epoch 1173/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.6181 - val_loss: 7.9780\n",
      "Epoch 1174/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7999 - val_loss: 7.5354\n",
      "Epoch 1175/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7779 - val_loss: 7.2092\n",
      "Epoch 1176/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9300 - val_loss: 7.0807\n",
      "Epoch 1177/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4118 - val_loss: 7.0198\n",
      "Epoch 1178/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.6965 - val_loss: 7.0140\n",
      "Epoch 1179/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.3243 - val_loss: 6.9802\n",
      "Epoch 1180/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7941 - val_loss: 7.2470\n",
      "Epoch 1181/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.3105 - val_loss: 7.6534\n",
      "Epoch 1182/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.1946 - val_loss: 8.1093\n",
      "Epoch 1183/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7936 - val_loss: 8.7606\n",
      "Epoch 1184/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.8963 - val_loss: 9.2003\n",
      "Epoch 1185/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.2399 - val_loss: 10.1368\n",
      "Epoch 1186/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1005 - val_loss: 9.8039\n",
      "Epoch 1187/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9705 - val_loss: 8.9378\n",
      "Epoch 1188/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.2910 - val_loss: 8.1077\n",
      "Epoch 1189/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4904 - val_loss: 7.6815\n",
      "Epoch 1190/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.6121 - val_loss: 7.1327\n",
      "Epoch 1191/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8970 - val_loss: 6.9972\n",
      "Epoch 1192/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.2529 - val_loss: 6.8232\n",
      "Epoch 1193/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.4340 - val_loss: 6.8342\n",
      "Epoch 1194/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.3235 - val_loss: 6.7437\n",
      "Epoch 1195/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.7509 - val_loss: 7.2413\n",
      "Epoch 1196/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7399 - val_loss: 8.0232\n",
      "Epoch 1197/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9387 - val_loss: 8.8760\n",
      "Epoch 1198/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.3918 - val_loss: 9.0544\n",
      "Epoch 1199/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8910 - val_loss: 8.7526\n",
      "Epoch 1200/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7263 - val_loss: 8.2136\n",
      "Epoch 1201/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0621 - val_loss: 7.2098\n",
      "Epoch 1202/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.3421 - val_loss: 6.7915\n",
      "Epoch 1203/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.4407 - val_loss: 6.9324\n",
      "Epoch 1204/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5822 - val_loss: 7.4427\n",
      "Epoch 1205/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5329 - val_loss: 7.7686\n",
      "Epoch 1206/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2078 - val_loss: 8.7083\n",
      "Epoch 1207/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0760 - val_loss: 7.6497\n",
      "Epoch 1208/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.3773 - val_loss: 6.6806\n",
      "Epoch 1209/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.7015 - val_loss: 6.5613\n",
      "Epoch 1210/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.7353 - val_loss: 6.8649\n",
      "Epoch 1211/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.5981 - val_loss: 6.9311\n",
      "Epoch 1212/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.2415 - val_loss: 6.9813\n",
      "Epoch 1213/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.4341 - val_loss: 7.3888\n",
      "Epoch 1214/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.3163 - val_loss: 7.8275\n",
      "Epoch 1215/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5136 - val_loss: 9.0969\n",
      "Epoch 1216/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.9768 - val_loss: 10.3067\n",
      "Epoch 1217/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5591 - val_loss: 9.8618\n",
      "Epoch 1218/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9094 - val_loss: 8.8229\n",
      "Epoch 1219/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.2564 - val_loss: 8.1536\n",
      "Epoch 1220/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7750 - val_loss: 7.8784\n",
      "Epoch 1221/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4330 - val_loss: 8.2416\n",
      "Epoch 1222/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5585 - val_loss: 10.6178\n",
      "Epoch 1223/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.9802 - val_loss: 11.2792\n",
      "Epoch 1224/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8611 - val_loss: 9.3362\n",
      "Epoch 1225/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.6108 - val_loss: 7.5959\n",
      "Epoch 1226/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.6487 - val_loss: 7.0943\n",
      "Epoch 1227/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.3564 - val_loss: 7.2676\n",
      "Epoch 1228/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.5752 - val_loss: 7.5054\n",
      "Epoch 1229/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.4924 - val_loss: 8.1112\n",
      "Epoch 1230/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5226 - val_loss: 8.5876\n",
      "Epoch 1231/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.3085 - val_loss: 8.4305\n",
      "Epoch 1232/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5768 - val_loss: 7.6709\n",
      "Epoch 1233/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.2203 - val_loss: 7.2119\n",
      "Epoch 1234/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.2498 - val_loss: 6.7587\n",
      "Epoch 1235/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5137 - val_loss: 6.9026\n",
      "Epoch 1236/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9181 - val_loss: 6.7819\n",
      "Epoch 1237/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.0157 - val_loss: 6.6504\n",
      "Epoch 1238/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.6521 - val_loss: 6.9434\n",
      "Epoch 1239/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.3237 - val_loss: 7.1039\n",
      "Epoch 1240/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5934 - val_loss: 7.2151\n",
      "Epoch 1241/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9131 - val_loss: 6.6009\n",
      "Epoch 1242/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.6075 - val_loss: 6.1084\n",
      "Epoch 1243/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.6729 - val_loss: 6.2178\n",
      "Epoch 1244/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7496 - val_loss: 7.1389\n",
      "Epoch 1245/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.1112 - val_loss: 8.4442\n",
      "Epoch 1246/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4440 - val_loss: 9.6800\n",
      "Epoch 1247/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.0544 - val_loss: 8.9826\n",
      "Epoch 1248/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.3716 - val_loss: 8.2198\n",
      "Epoch 1249/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7500 - val_loss: 7.5914\n",
      "Epoch 1250/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.2853 - val_loss: 7.2577\n",
      "Epoch 1251/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5386 - val_loss: 7.4218\n",
      "Epoch 1252/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.0853 - val_loss: 7.9746\n",
      "Epoch 1253/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4071 - val_loss: 8.2912\n",
      "Epoch 1254/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4411 - val_loss: 9.3585\n",
      "Epoch 1255/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.0790 - val_loss: 10.4780\n",
      "Epoch 1256/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.4668 - val_loss: 10.8301\n",
      "Epoch 1257/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4546 - val_loss: 10.7134\n",
      "Epoch 1258/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.4124 - val_loss: 9.9378\n",
      "Epoch 1259/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4674 - val_loss: 9.9156\n",
      "Epoch 1260/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0123 - val_loss: 8.4031\n",
      "Epoch 1261/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.1710 - val_loss: 8.0899\n",
      "Epoch 1262/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7962 - val_loss: 8.4146\n",
      "Epoch 1263/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.5341 - val_loss: 8.8243\n",
      "Epoch 1264/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.3684 - val_loss: 9.4708\n",
      "Epoch 1265/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.3015 - val_loss: 8.7159\n",
      "Epoch 1266/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5201 - val_loss: 7.7735\n",
      "Epoch 1267/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.3458 - val_loss: 7.9765\n",
      "Epoch 1268/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 5.6271 - val_loss: 10.3967\n",
      "Epoch 1269/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.1611 - val_loss: 11.2007\n",
      "Epoch 1270/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.5203 - val_loss: 10.7328\n",
      "Epoch 1271/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7174 - val_loss: 9.6608\n",
      "Epoch 1272/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.2773 - val_loss: 8.5001\n",
      "Epoch 1273/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2481 - val_loss: 9.2261\n",
      "Epoch 1274/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7995 - val_loss: 9.8202\n",
      "Epoch 1275/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7630 - val_loss: 10.6406\n",
      "Epoch 1276/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.2672 - val_loss: 11.3517\n",
      "Epoch 1277/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0281 - val_loss: 11.2569\n",
      "Epoch 1278/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5731 - val_loss: 9.6046\n",
      "Epoch 1279/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.1552 - val_loss: 8.3003\n",
      "Epoch 1280/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.2062 - val_loss: 7.9152\n",
      "Epoch 1281/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.6803 - val_loss: 8.4387\n",
      "Epoch 1282/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8482 - val_loss: 8.5045\n",
      "Epoch 1283/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8038 - val_loss: 7.4015\n",
      "Epoch 1284/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4663 - val_loss: 6.7870\n",
      "Epoch 1285/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.2207 - val_loss: 7.5455\n",
      "Epoch 1286/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.2072 - val_loss: 8.7806\n",
      "Epoch 1287/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.0246 - val_loss: 9.9938\n",
      "Epoch 1288/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4772 - val_loss: 9.1031\n",
      "Epoch 1289/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.3208 - val_loss: 7.7825\n",
      "Epoch 1290/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.0204 - val_loss: 8.0912\n",
      "Epoch 1291/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.5553 - val_loss: 9.1342\n",
      "Epoch 1292/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.1688 - val_loss: 10.2310\n",
      "Epoch 1293/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.6928 - val_loss: 9.6635\n",
      "Epoch 1294/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.7511 - val_loss: 9.3175\n",
      "Epoch 1295/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.4008 - val_loss: 7.4569\n",
      "Epoch 1296/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.3743 - val_loss: 6.8902\n",
      "Epoch 1297/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.0588 - val_loss: 7.2661\n",
      "Epoch 1298/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.4795 - val_loss: 8.3205\n",
      "Epoch 1299/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.1225 - val_loss: 9.2287\n",
      "Epoch 1300/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.1645 - val_loss: 9.3320\n",
      "Epoch 1301/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.3138 - val_loss: 9.4252\n",
      "Epoch 1302/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.7762 - val_loss: 8.9988\n",
      "Epoch 1303/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.0959 - val_loss: 7.8789\n",
      "Epoch 1304/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.1301 - val_loss: 7.8530\n",
      "Epoch 1305/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.2364 - val_loss: 8.2627\n",
      "Epoch 1306/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.0203 - val_loss: 9.2698\n",
      "Epoch 1307/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.6652 - val_loss: 10.5257\n",
      "Epoch 1308/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.0157 - val_loss: 9.6136\n",
      "Epoch 1309/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4882 - val_loss: 9.5543\n",
      "Epoch 1310/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.2462 - val_loss: 9.7896\n",
      "Epoch 1311/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.2610 - val_loss: 10.4452\n",
      "Epoch 1312/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.1796 - val_loss: 9.0853\n",
      "Epoch 1313/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.2016 - val_loss: 7.8705\n",
      "Epoch 1314/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.2932 - val_loss: 7.5308\n",
      "Epoch 1315/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4210 - val_loss: 8.5491\n",
      "Epoch 1316/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.3268 - val_loss: 9.9439\n",
      "Epoch 1317/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.5008 - val_loss: 10.2162\n",
      "Epoch 1318/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4770 - val_loss: 9.8660\n",
      "Epoch 1319/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.5302 - val_loss: 9.2080\n",
      "Epoch 1320/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.1417 - val_loss: 9.0501\n",
      "Epoch 1321/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.4049 - val_loss: 10.9848\n",
      "Epoch 1322/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.4782 - val_loss: 12.7549\n",
      "Epoch 1323/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.7112 - val_loss: 11.7347\n",
      "Epoch 1324/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.0722 - val_loss: 10.1885\n",
      "Epoch 1325/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.2905 - val_loss: 9.1572\n",
      "Epoch 1326/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.1364 - val_loss: 7.8097\n",
      "Epoch 1327/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.6040 - val_loss: 7.5031\n",
      "Epoch 1328/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.5234 - val_loss: 8.0847\n",
      "Epoch 1329/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.2996 - val_loss: 8.0561\n",
      "Epoch 1330/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.1157 - val_loss: 7.3724\n",
      "Epoch 1331/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.0224 - val_loss: 6.8825\n",
      "Epoch 1332/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9583 - val_loss: 6.8098\n",
      "Epoch 1333/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.0549 - val_loss: 7.1211\n",
      "Epoch 1334/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.1230 - val_loss: 7.2515\n",
      "Epoch 1335/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.7656 - val_loss: 6.8232\n",
      "Epoch 1336/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.2332 - val_loss: 5.7968\n",
      "Epoch 1337/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.4455 - val_loss: 5.2718\n",
      "Epoch 1338/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.8908 - val_loss: 5.2360\n",
      "Epoch 1339/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.0533 - val_loss: 5.7383\n",
      "Epoch 1340/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7785 - val_loss: 8.2826\n",
      "Epoch 1341/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2759 - val_loss: 7.7450\n",
      "Epoch 1342/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.4620 - val_loss: 5.5486\n",
      "Epoch 1343/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.9105 - val_loss: 6.0858\n",
      "Epoch 1344/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.5371 - val_loss: 7.9022\n",
      "Epoch 1345/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.5759 - val_loss: 9.2806\n",
      "Epoch 1346/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.1600 - val_loss: 9.6967\n",
      "Epoch 1347/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.9959 - val_loss: 8.4913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1348/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.6490 - val_loss: 7.5745\n",
      "Epoch 1349/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.8983 - val_loss: 6.4978\n",
      "Epoch 1350/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.5342 - val_loss: 5.9272\n",
      "Epoch 1351/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.7490 - val_loss: 6.1994\n",
      "Epoch 1352/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.4713 - val_loss: 7.0059\n",
      "Epoch 1353/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.2717 - val_loss: 7.2323\n",
      "Epoch 1354/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.4803 - val_loss: 7.2937\n",
      "Epoch 1355/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.1781 - val_loss: 7.7709\n",
      "Epoch 1356/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.8054 - val_loss: 8.0292\n",
      "Epoch 1357/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.4548 - val_loss: 7.7295\n",
      "Epoch 1358/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.5773 - val_loss: 7.6249\n",
      "Epoch 1359/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.6116 - val_loss: 7.7594\n",
      "Epoch 1360/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.8244 - val_loss: 7.4471\n",
      "Epoch 1361/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.3465 - val_loss: 6.9909\n",
      "Epoch 1362/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.6813 - val_loss: 6.6140\n",
      "Epoch 1363/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.2078 - val_loss: 6.4103\n",
      "Epoch 1364/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.8024 - val_loss: 5.9253\n",
      "Epoch 1365/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.3668 - val_loss: 5.6541\n",
      "Epoch 1366/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.2545 - val_loss: 5.6733\n",
      "Epoch 1367/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7828 - val_loss: 5.7984\n",
      "Epoch 1368/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.7807 - val_loss: 6.7733\n",
      "Epoch 1369/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.1301 - val_loss: 7.4190\n",
      "Epoch 1370/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.6996 - val_loss: 7.9178\n",
      "Epoch 1371/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5586 - val_loss: 7.0629\n",
      "Epoch 1372/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.0137 - val_loss: 6.8379\n",
      "Epoch 1373/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.7476 - val_loss: 6.1434\n",
      "Epoch 1374/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.3917 - val_loss: 6.0667\n",
      "Epoch 1375/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.2777 - val_loss: 6.6905\n",
      "Epoch 1376/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7503 - val_loss: 7.8690\n",
      "Epoch 1377/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1810 - val_loss: 7.3267\n",
      "Epoch 1378/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.7004 - val_loss: 6.9095\n",
      "Epoch 1379/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5121 - val_loss: 8.0530\n",
      "Epoch 1380/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.2067 - val_loss: 8.9123\n",
      "Epoch 1381/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.3239 - val_loss: 8.1649\n",
      "Epoch 1382/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4670 - val_loss: 7.6073\n",
      "Epoch 1383/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9165 - val_loss: 6.9899\n",
      "Epoch 1384/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8159 - val_loss: 7.2045\n",
      "Epoch 1385/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.2249 - val_loss: 9.2552\n",
      "Epoch 1386/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12.2755 - val_loss: 13.6814\n",
      "Epoch 1387/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.7849 - val_loss: 14.7722\n",
      "Epoch 1388/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.9535 - val_loss: 13.6397\n",
      "Epoch 1389/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.1100 - val_loss: 12.0885\n",
      "Epoch 1390/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.3318 - val_loss: 8.8998\n",
      "Epoch 1391/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.1673 - val_loss: 7.9265\n",
      "Epoch 1392/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.3057 - val_loss: 8.5821\n",
      "Epoch 1393/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.5726 - val_loss: 10.1735\n",
      "Epoch 1394/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.9673 - val_loss: 12.4203\n",
      "Epoch 1395/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.4861 - val_loss: 12.6162\n",
      "Epoch 1396/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.0623 - val_loss: 11.2968\n",
      "Epoch 1397/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2091 - val_loss: 10.8395\n",
      "Epoch 1398/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2621 - val_loss: 9.8162\n",
      "Epoch 1399/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 8.9059 - val_loss: 10.3336\n",
      "Epoch 1400/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.0209 - val_loss: 8.5155\n",
      "Epoch 1401/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.8842 - val_loss: 6.6791\n",
      "Epoch 1402/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6146 - val_loss: 6.2130\n",
      "Epoch 1403/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2351 - val_loss: 6.7518\n",
      "Epoch 1404/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6839 - val_loss: 8.5939\n",
      "Epoch 1405/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7231 - val_loss: 12.6382\n",
      "Epoch 1406/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.1117 - val_loss: 12.6428\n",
      "Epoch 1407/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.6083 - val_loss: 10.7560\n",
      "Epoch 1408/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.4884 - val_loss: 9.6048\n",
      "Epoch 1409/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4704 - val_loss: 9.1756\n",
      "Epoch 1410/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0946 - val_loss: 10.5390\n",
      "Epoch 1411/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4784 - val_loss: 10.9121\n",
      "Epoch 1412/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9128 - val_loss: 10.5225\n",
      "Epoch 1413/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.3303 - val_loss: 12.2062\n",
      "Epoch 1414/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.9704 - val_loss: 11.3222\n",
      "Epoch 1415/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0997 - val_loss: 8.6514\n",
      "Epoch 1416/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.6979 - val_loss: 7.2172\n",
      "Epoch 1417/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.7102 - val_loss: 7.0293\n",
      "Epoch 1418/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.2338 - val_loss: 7.5717\n",
      "Epoch 1419/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.7146 - val_loss: 7.9886\n",
      "Epoch 1420/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 7.7825 - val_loss: 9.4907\n",
      "Epoch 1421/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.8661 - val_loss: 10.2104\n",
      "Epoch 1422/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 8.2876 - val_loss: 8.8321\n",
      "Epoch 1423/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2501 - val_loss: 7.5812\n",
      "Epoch 1424/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.5275 - val_loss: 7.7653\n",
      "Epoch 1425/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8711 - val_loss: 9.1768\n",
      "Epoch 1426/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.9565 - val_loss: 9.5069\n",
      "Epoch 1427/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 6.8886 - val_loss: 9.4289\n",
      "Epoch 1428/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7208 - val_loss: 11.0201\n",
      "Epoch 1429/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.0195 - val_loss: 10.9632\n",
      "Epoch 1430/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7471 - val_loss: 11.2492\n",
      "Epoch 1431/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.7846 - val_loss: 8.5287\n",
      "Epoch 1432/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2014 - val_loss: 6.9776\n",
      "Epoch 1433/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.6990 - val_loss: 6.8851\n",
      "Epoch 1434/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2115 - val_loss: 7.2535\n",
      "Epoch 1435/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7857 - val_loss: 7.7795\n",
      "Epoch 1436/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8318 - val_loss: 8.7233\n",
      "Epoch 1437/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5341 - val_loss: 10.2622\n",
      "Epoch 1438/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7.2076 - val_loss: 14.6704\n",
      "Epoch 1439/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5962 - val_loss: 12.7612\n",
      "Epoch 1440/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6148 - val_loss: 8.5288\n",
      "Epoch 1441/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.2911 - val_loss: 7.2815\n",
      "Epoch 1442/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5596 - val_loss: 6.9179\n",
      "Epoch 1443/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.8436 - val_loss: 7.1427\n",
      "Epoch 1444/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.2026 - val_loss: 7.2933\n",
      "Epoch 1445/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0935 - val_loss: 7.7678\n",
      "Epoch 1446/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3877 - val_loss: 7.9638\n",
      "Epoch 1447/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5753 - val_loss: 7.5294\n",
      "Epoch 1448/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5190 - val_loss: 7.3524\n",
      "Epoch 1449/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1843 - val_loss: 8.3128\n",
      "Epoch 1450/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2173 - val_loss: 9.9943\n",
      "Epoch 1451/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3485 - val_loss: 9.9413\n",
      "Epoch 1452/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2755 - val_loss: 8.2677\n",
      "Epoch 1453/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0549 - val_loss: 7.8117\n",
      "Epoch 1454/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3484 - val_loss: 8.6010\n",
      "Epoch 1455/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3379 - val_loss: 10.3535\n",
      "Epoch 1456/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.2665 - val_loss: 10.9298\n",
      "Epoch 1457/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0149 - val_loss: 9.3820\n",
      "Epoch 1458/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.3528 - val_loss: 8.6333\n",
      "Epoch 1459/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5268 - val_loss: 8.0826\n",
      "Epoch 1460/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6865 - val_loss: 8.1149\n",
      "Epoch 1461/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.4389 - val_loss: 8.7416\n",
      "Epoch 1462/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4565 - val_loss: 8.9708\n",
      "Epoch 1463/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5629 - val_loss: 9.1342\n",
      "Epoch 1464/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.3808 - val_loss: 8.3924\n",
      "Epoch 1465/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9141 - val_loss: 7.8940\n",
      "Epoch 1466/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8806 - val_loss: 7.6930\n",
      "Epoch 1467/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.5448 - val_loss: 7.6148\n",
      "Epoch 1468/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.9137 - val_loss: 7.6566\n",
      "Epoch 1469/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.7413 - val_loss: 7.7594\n",
      "Epoch 1470/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2136 - val_loss: 7.7365\n",
      "Epoch 1471/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0195 - val_loss: 7.9050\n",
      "Epoch 1472/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0027 - val_loss: 8.0054\n",
      "Epoch 1473/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8591 - val_loss: 7.3733\n",
      "Epoch 1474/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.4280 - val_loss: 6.9577\n",
      "Epoch 1475/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9123 - val_loss: 6.9032\n",
      "Epoch 1476/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0987 - val_loss: 7.4033\n",
      "Epoch 1477/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.5747 - val_loss: 7.5655\n",
      "Epoch 1478/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0016 - val_loss: 8.4190\n",
      "Epoch 1479/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1870 - val_loss: 9.4513\n",
      "Epoch 1480/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.3357 - val_loss: 8.4779\n",
      "Epoch 1481/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.3809 - val_loss: 8.5832\n",
      "Epoch 1482/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.7179 - val_loss: 9.7725\n",
      "Epoch 1483/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9477 - val_loss: 10.8296\n",
      "Epoch 1484/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.8870 - val_loss: 9.6267\n",
      "Epoch 1485/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0661 - val_loss: 8.6275\n",
      "Epoch 1486/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0128 - val_loss: 8.7485\n",
      "Epoch 1487/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1370 - val_loss: 9.9456\n",
      "Epoch 1488/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.2063 - val_loss: 10.5987\n",
      "Epoch 1489/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9553 - val_loss: 9.8239\n",
      "Epoch 1490/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0772 - val_loss: 9.4405\n",
      "Epoch 1491/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.5192 - val_loss: 10.4343\n",
      "Epoch 1492/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9267 - val_loss: 11.2643\n",
      "Epoch 1493/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8315 - val_loss: 11.1363\n",
      "Epoch 1494/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9043 - val_loss: 10.3620\n",
      "Epoch 1495/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2173 - val_loss: 9.6494\n",
      "Epoch 1496/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.9229 - val_loss: 8.5672\n",
      "Epoch 1497/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.6674 - val_loss: 7.9139\n",
      "Epoch 1498/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0317 - val_loss: 8.2212\n",
      "Epoch 1499/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.9419 - val_loss: 9.6235\n",
      "Epoch 1500/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.9201 - val_loss: 10.0758\n",
      "Epoch 1501/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.8494 - val_loss: 9.1803\n",
      "Epoch 1502/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9094 - val_loss: 8.9571\n",
      "Epoch 1503/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.8735 - val_loss: 7.8673\n",
      "Epoch 1504/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.5199 - val_loss: 7.5410\n",
      "Epoch 1505/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.4705 - val_loss: 7.3860\n",
      "Epoch 1506/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 6.0178 - val_loss: 7.4283\n",
      "Epoch 1507/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0316 - val_loss: 7.5967\n",
      "Epoch 1508/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2842 - val_loss: 7.4721\n",
      "Epoch 1509/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.9441 - val_loss: 7.3340\n",
      "Epoch 1510/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.1049 - val_loss: 8.1562\n",
      "Epoch 1511/10000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 5.1906Restoring model weights from the end of the best epoch: 1011.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 5.8521 - val_loss: 9.5908\n",
      "Epoch 1511: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = lstm_model(reshaped_train, \n",
    "                                    reshaped_target, \n",
    "                                    want_verbose=1, \n",
    "                                    seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0aad5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb69c9b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>13.919381</td>\n",
       "      <td>13.990292</td>\n",
       "      <td>14.04735</td>\n",
       "      <td>14.09381</td>\n",
       "      <td>14.126345</td>\n",
       "      <td>14.146803</td>\n",
       "      <td>14.180419</td>\n",
       "      <td>14.265699</td>\n",
       "      <td>14.312064</td>\n",
       "      <td>14.341601</td>\n",
       "      <td>14.367002</td>\n",
       "      <td>14.400402</td>\n",
       "      <td>14.36585</td>\n",
       "      <td>14.369029</td>\n",
       "      <td>14.437085</td>\n",
       "      <td>14.431826</td>\n",
       "      <td>14.41492</td>\n",
       "      <td>14.354415</td>\n",
       "      <td>14.35275</td>\n",
       "      <td>14.413462</td>\n",
       "      <td>14.413156</td>\n",
       "      <td>14.375886</td>\n",
       "      <td>14.388503</td>\n",
       "      <td>14.356398</td>\n",
       "      <td>14.329171</td>\n",
       "      <td>14.334376</td>\n",
       "      <td>14.284247</td>\n",
       "      <td>14.326163</td>\n",
       "      <td>14.356879</td>\n",
       "      <td>14.575981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>12.399</td>\n",
       "      <td>11.268</td>\n",
       "      <td>8.741</td>\n",
       "      <td>12.358</td>\n",
       "      <td>11.876</td>\n",
       "      <td>11.713</td>\n",
       "      <td>11.449</td>\n",
       "      <td>7.805</td>\n",
       "      <td>7.726</td>\n",
       "      <td>8.516</td>\n",
       "      <td>8.503</td>\n",
       "      <td>10.175</td>\n",
       "      <td>11.775</td>\n",
       "      <td>9.724</td>\n",
       "      <td>10.069</td>\n",
       "      <td>13.93</td>\n",
       "      <td>11.918</td>\n",
       "      <td>11.757</td>\n",
       "      <td>9.691</td>\n",
       "      <td>7.378</td>\n",
       "      <td>6.97</td>\n",
       "      <td>7.612</td>\n",
       "      <td>8.442</td>\n",
       "      <td>8.835</td>\n",
       "      <td>11.251</td>\n",
       "      <td>11.342</td>\n",
       "      <td>13.11</td>\n",
       "      <td>13.195</td>\n",
       "      <td>10.053</td>\n",
       "      <td>12.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>1.520381</td>\n",
       "      <td>2.722292</td>\n",
       "      <td>5.30635</td>\n",
       "      <td>1.73581</td>\n",
       "      <td>2.250344</td>\n",
       "      <td>2.433803</td>\n",
       "      <td>2.731419</td>\n",
       "      <td>6.4607</td>\n",
       "      <td>6.586064</td>\n",
       "      <td>5.825602</td>\n",
       "      <td>5.864001</td>\n",
       "      <td>4.225402</td>\n",
       "      <td>2.590851</td>\n",
       "      <td>4.645029</td>\n",
       "      <td>4.368085</td>\n",
       "      <td>0.501825</td>\n",
       "      <td>2.49692</td>\n",
       "      <td>2.597415</td>\n",
       "      <td>4.66175</td>\n",
       "      <td>7.035462</td>\n",
       "      <td>7.443156</td>\n",
       "      <td>6.763886</td>\n",
       "      <td>5.946503</td>\n",
       "      <td>5.521398</td>\n",
       "      <td>3.078171</td>\n",
       "      <td>2.992376</td>\n",
       "      <td>1.174248</td>\n",
       "      <td>1.131164</td>\n",
       "      <td>4.303879</td>\n",
       "      <td>2.301981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1         2         3          4          5   \\\n",
       "Month         Month-1    Month-2   Month-3   Month-4    Month-5    Month-6   \n",
       "Prediction  13.919381  13.990292  14.04735  14.09381  14.126345  14.146803   \n",
       "Target         12.399     11.268     8.741    12.358     11.876     11.713   \n",
       "Error        1.520381   2.722292   5.30635   1.73581   2.250344   2.433803   \n",
       "\n",
       "                   6          7          8          9          10         11  \\\n",
       "Month         Month-7    Month-8    Month-9   Month-10   Month-11   Month-12   \n",
       "Prediction  14.180419  14.265699  14.312064  14.341601  14.367002  14.400402   \n",
       "Target         11.449      7.805      7.726      8.516      8.503     10.175   \n",
       "Error        2.731419     6.4607   6.586064   5.825602   5.864001   4.225402   \n",
       "\n",
       "                  12         13         14         15        16         17  \\\n",
       "Month       Month-13   Month-14   Month-15   Month-16  Month-17   Month-18   \n",
       "Prediction  14.36585  14.369029  14.437085  14.431826  14.41492  14.354415   \n",
       "Target        11.775      9.724     10.069      13.93    11.918     11.757   \n",
       "Error       2.590851   4.645029   4.368085   0.501825   2.49692   2.597415   \n",
       "\n",
       "                  18         19         20         21         22         23  \\\n",
       "Month       Month-19   Month-20   Month-21   Month-22   Month-23   Month-24   \n",
       "Prediction  14.35275  14.413462  14.413156  14.375886  14.388503  14.356398   \n",
       "Target         9.691      7.378       6.97      7.612      8.442      8.835   \n",
       "Error        4.66175   7.035462   7.443156   6.763886   5.946503   5.521398   \n",
       "\n",
       "                   24         25         26         27         28         29  \n",
       "Month        Month-25   Month-26   Month-27   Month-28   Month-29   Month-30  \n",
       "Prediction  14.329171  14.334376  14.284247  14.326163  14.356879  14.575981  \n",
       "Target         11.251     11.342      13.11     13.195     10.053     12.274  \n",
       "Error        3.078171   2.992376   1.174248   1.131164   4.303879   2.301981  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            reshaped_test, \n",
    "                                            reshaped_test_target, \n",
    "                                            start_index)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b1c27bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9072087"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.42878637"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c506c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ca218d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[170.19118]] - Target[122.52900000000001]| =  Error: [[47.662178]]; MAPE:[[0.38898692]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[172.67328]] - Target[118.101]| =  Error: [[54.57228]]; MAPE:[[0.46208146]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Ano-5: |Prediction[[86.20682]] - Target[71.22500000000001]| =  Error: [[14.981819]]; MAPE:[[0.21034496]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[47.662178]], dtype=float32),\n",
       " array([[54.57228]], dtype=float32),\n",
       " array([[14.981819]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "39.072094"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.35380444"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             reshaped_test, \n",
    "                                             reshaped_test_target, \n",
    "                                             start_index)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b2bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
