{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d613198",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Bahia - Consumo de Cimento (t)'\n",
    "start_index = 0\n",
    "split_index = 191 #Referente aos 230 anos de input \n",
    "window_size = 36\n",
    "train_split = split_index + 1 - 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc652c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Precipitation (mm/day)</th>\n",
       "      <th>...</th>\n",
       "      <th>Air Relative Humidity (%)</th>\n",
       "      <th>Wind Gust (m/s)</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>Bahia - Desemprego</th>\n",
       "      <th>Bahia - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.299858</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.611498</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>1.604227</td>\n",
       "      <td>...</td>\n",
       "      <td>75.411587</td>\n",
       "      <td>2.004234</td>\n",
       "      <td>0.669899</td>\n",
       "      <td>39.798880</td>\n",
       "      <td>1.317344e+08</td>\n",
       "      <td>8.384593e+06</td>\n",
       "      <td>8.566149</td>\n",
       "      <td>1.216359e+08</td>\n",
       "      <td>8.348779</td>\n",
       "      <td>151.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.301903</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.450389</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>2.224533</td>\n",
       "      <td>...</td>\n",
       "      <td>76.966756</td>\n",
       "      <td>1.726139</td>\n",
       "      <td>0.670210</td>\n",
       "      <td>39.480034</td>\n",
       "      <td>1.318964e+08</td>\n",
       "      <td>8.391946e+06</td>\n",
       "      <td>8.569210</td>\n",
       "      <td>1.216914e+08</td>\n",
       "      <td>8.342979</td>\n",
       "      <td>138.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.303709</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.870184</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>2.312330</td>\n",
       "      <td>...</td>\n",
       "      <td>78.493126</td>\n",
       "      <td>1.462602</td>\n",
       "      <td>0.670521</td>\n",
       "      <td>39.400256</td>\n",
       "      <td>1.320584e+08</td>\n",
       "      <td>8.399299e+06</td>\n",
       "      <td>8.572270</td>\n",
       "      <td>1.217469e+08</td>\n",
       "      <td>8.337179</td>\n",
       "      <td>135.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.305311</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.355287</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>2.332765</td>\n",
       "      <td>...</td>\n",
       "      <td>78.801800</td>\n",
       "      <td>1.217048</td>\n",
       "      <td>0.670831</td>\n",
       "      <td>39.417185</td>\n",
       "      <td>1.322204e+08</td>\n",
       "      <td>8.406652e+06</td>\n",
       "      <td>8.575331</td>\n",
       "      <td>1.218023e+08</td>\n",
       "      <td>8.331379</td>\n",
       "      <td>126.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.306860</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.585538</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>2.225842</td>\n",
       "      <td>...</td>\n",
       "      <td>79.547467</td>\n",
       "      <td>1.031926</td>\n",
       "      <td>0.671142</td>\n",
       "      <td>39.479943</td>\n",
       "      <td>1.323824e+08</td>\n",
       "      <td>8.414005e+06</td>\n",
       "      <td>8.578392</td>\n",
       "      <td>1.218578e+08</td>\n",
       "      <td>8.325579</td>\n",
       "      <td>137.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2002-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.608320</td>\n",
       "      <td>...</td>\n",
       "      <td>78.229336</td>\n",
       "      <td>1.977754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2002-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.453784</td>\n",
       "      <td>...</td>\n",
       "      <td>76.934612</td>\n",
       "      <td>2.093929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2002-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.071670</td>\n",
       "      <td>...</td>\n",
       "      <td>75.331548</td>\n",
       "      <td>2.191347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>2002-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.149319</td>\n",
       "      <td>...</td>\n",
       "      <td>74.405966</td>\n",
       "      <td>2.307342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2002-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.302823</td>\n",
       "      <td>...</td>\n",
       "      <td>74.400960</td>\n",
       "      <td>2.234476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Bahia - value  \\\n",
       "0       2003-1       0.299858   \n",
       "1       2003-2       0.301903   \n",
       "2       2003-3       0.303709   \n",
       "3       2003-4       0.305311   \n",
       "4       2003-5       0.306860   \n",
       "..         ...            ...   \n",
       "259     2002-8            NaN   \n",
       "260     2002-9            NaN   \n",
       "261    2002-10            NaN   \n",
       "262    2002-11            NaN   \n",
       "263    2002-12            NaN   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "259                                               NaN   \n",
       "260                                               NaN   \n",
       "261                                               NaN   \n",
       "262                                               NaN   \n",
       "263                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.611498  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.450389  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.870184  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.355287  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.585538  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "259                            NaN             NaN       NaN           NaN   \n",
       "260                            NaN             NaN       NaN           NaN   \n",
       "261                            NaN             NaN       NaN           NaN   \n",
       "262                            NaN             NaN       NaN           NaN   \n",
       "263                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "259                                     NaN        NaN   \n",
       "260                                     NaN        NaN   \n",
       "261                                     NaN        NaN   \n",
       "262                                     NaN        NaN   \n",
       "263                                     NaN        NaN   \n",
       "\n",
       "     Precipitation (mm/day)  ...  Air Relative Humidity (%)  Wind Gust (m/s)  \\\n",
       "0                  1.604227  ...                  75.411587         2.004234   \n",
       "1                  2.224533  ...                  76.966756         1.726139   \n",
       "2                  2.312330  ...                  78.493126         1.462602   \n",
       "3                  2.332765  ...                  78.801800         1.217048   \n",
       "4                  2.225842  ...                  79.547467         1.031926   \n",
       "..                      ...  ...                        ...              ...   \n",
       "259                1.608320  ...                  78.229336         1.977754   \n",
       "260                1.453784  ...                  76.934612         2.093929   \n",
       "261                1.071670  ...                  75.331548         2.191347   \n",
       "262                1.149319  ...                  74.405966         2.307342   \n",
       "263                1.302823  ...                  74.400960         2.234476   \n",
       "\n",
       "     Bahia - IDH  Bahia - Produção de Cimento (t)  Bahia - PIB - Estadual  \\\n",
       "0       0.669899                        39.798880            1.317344e+08   \n",
       "1       0.670210                        39.480034            1.318964e+08   \n",
       "2       0.670521                        39.400256            1.320584e+08   \n",
       "3       0.670831                        39.417185            1.322204e+08   \n",
       "4       0.671142                        39.479943            1.323824e+08   \n",
       "..           ...                              ...                     ...   \n",
       "259          NaN                              NaN                     NaN   \n",
       "260          NaN                              NaN                     NaN   \n",
       "261          NaN                              NaN                     NaN   \n",
       "262          NaN                              NaN                     NaN   \n",
       "263          NaN                              NaN                     NaN   \n",
       "\n",
       "     Bahia - PIB - Construção Civil  Bahia - PIB - Per Capita  \\\n",
       "0                      8.384593e+06                  8.566149   \n",
       "1                      8.391946e+06                  8.569210   \n",
       "2                      8.399299e+06                  8.572270   \n",
       "3                      8.406652e+06                  8.575331   \n",
       "4                      8.414005e+06                  8.578392   \n",
       "..                              ...                       ...   \n",
       "259                             NaN                       NaN   \n",
       "260                             NaN                       NaN   \n",
       "261                             NaN                       NaN   \n",
       "262                             NaN                       NaN   \n",
       "263                             NaN                       NaN   \n",
       "\n",
       "     Bahia - PIB - Preços de Mercado  Bahia - Desemprego  \\\n",
       "0                       1.216359e+08            8.348779   \n",
       "1                       1.216914e+08            8.342979   \n",
       "2                       1.217469e+08            8.337179   \n",
       "3                       1.218023e+08            8.331379   \n",
       "4                       1.218578e+08            8.325579   \n",
       "..                               ...                 ...   \n",
       "259                              NaN                 NaN   \n",
       "260                              NaN                 NaN   \n",
       "261                              NaN                 NaN   \n",
       "262                              NaN                 NaN   \n",
       "263                              NaN                 NaN   \n",
       "\n",
       "     Bahia - Consumo de Cimento (t)  \n",
       "0                           151.297  \n",
       "1                           138.707  \n",
       "2                           135.009  \n",
       "3                           126.554  \n",
       "4                           137.331  \n",
       "..                              ...  \n",
       "259                             NaN  \n",
       "260                             NaN  \n",
       "261                             NaN  \n",
       "262                             NaN  \n",
       "263                             NaN  \n",
       "\n",
       "[264 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_BA.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Precipitation (mm/day)</th>\n",
       "      <th>Atmospheric Pressure(mB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Dew Point Temperature (°C)</th>\n",
       "      <th>Air Relative Humidity (%)</th>\n",
       "      <th>Wind Gust (m/s)</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>Bahia - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.440329</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.132459</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-0.038360</td>\n",
       "      <td>-0.693716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029035</td>\n",
       "      <td>-0.182257</td>\n",
       "      <td>1.402525</td>\n",
       "      <td>-2.143224</td>\n",
       "      <td>-1.723080</td>\n",
       "      <td>-1.703176</td>\n",
       "      <td>-0.816345</td>\n",
       "      <td>-2.235724</td>\n",
       "      <td>-2.158201</td>\n",
       "      <td>-0.884052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.404914</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.592202</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>1.221742</td>\n",
       "      <td>-0.603174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060353</td>\n",
       "      <td>0.138191</td>\n",
       "      <td>0.499197</td>\n",
       "      <td>-2.108465</td>\n",
       "      <td>-1.735985</td>\n",
       "      <td>-1.684201</td>\n",
       "      <td>-0.772933</td>\n",
       "      <td>-2.194204</td>\n",
       "      <td>-2.117854</td>\n",
       "      <td>-0.885724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.373637</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.999926</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>1.400094</td>\n",
       "      <td>-0.351990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033064</td>\n",
       "      <td>0.452705</td>\n",
       "      <td>-0.356839</td>\n",
       "      <td>-2.073707</td>\n",
       "      <td>-1.739214</td>\n",
       "      <td>-1.665225</td>\n",
       "      <td>-0.729522</td>\n",
       "      <td>-2.152684</td>\n",
       "      <td>-2.077508</td>\n",
       "      <td>-0.887395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.345888</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.273293</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>1.441606</td>\n",
       "      <td>0.189583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109968</td>\n",
       "      <td>0.516308</td>\n",
       "      <td>-1.154465</td>\n",
       "      <td>-2.038948</td>\n",
       "      <td>-1.738529</td>\n",
       "      <td>-1.646249</td>\n",
       "      <td>-0.686111</td>\n",
       "      <td>-2.111164</td>\n",
       "      <td>-2.037161</td>\n",
       "      <td>-0.889067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.319065</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.045407</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>1.224400</td>\n",
       "      <td>0.717316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250986</td>\n",
       "      <td>0.669955</td>\n",
       "      <td>-1.755788</td>\n",
       "      <td>-2.004190</td>\n",
       "      <td>-1.735989</td>\n",
       "      <td>-1.627274</td>\n",
       "      <td>-0.642700</td>\n",
       "      <td>-2.069645</td>\n",
       "      <td>-1.996814</td>\n",
       "      <td>-0.890739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.796141</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.311366</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-0.479209</td>\n",
       "      <td>0.697302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.498914</td>\n",
       "      <td>-0.113596</td>\n",
       "      <td>-0.437518</td>\n",
       "      <td>1.261516</td>\n",
       "      <td>0.511535</td>\n",
       "      <td>1.096947</td>\n",
       "      <td>-1.668064</td>\n",
       "      <td>0.877256</td>\n",
       "      <td>0.724962</td>\n",
       "      <td>1.200853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.811284</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.417143</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>0.014731</td>\n",
       "      <td>0.264175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.419733</td>\n",
       "      <td>-0.176406</td>\n",
       "      <td>-0.385163</td>\n",
       "      <td>1.253736</td>\n",
       "      <td>0.513264</td>\n",
       "      <td>1.085441</td>\n",
       "      <td>-1.663847</td>\n",
       "      <td>0.851021</td>\n",
       "      <td>0.704849</td>\n",
       "      <td>1.200487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.833479</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.597784</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>0.024464</td>\n",
       "      <td>0.049785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321149</td>\n",
       "      <td>-0.283086</td>\n",
       "      <td>-0.415774</td>\n",
       "      <td>1.245956</td>\n",
       "      <td>0.526782</td>\n",
       "      <td>1.073935</td>\n",
       "      <td>-1.659631</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.684737</td>\n",
       "      <td>1.200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.853109</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.400787</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-0.195334</td>\n",
       "      <td>-0.223773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205138</td>\n",
       "      <td>-0.406765</td>\n",
       "      <td>-0.475393</td>\n",
       "      <td>1.238176</td>\n",
       "      <td>0.525379</td>\n",
       "      <td>1.062429</td>\n",
       "      <td>-1.655414</td>\n",
       "      <td>0.798552</td>\n",
       "      <td>0.664624</td>\n",
       "      <td>1.199756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.880066</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.604775</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>0.690450</td>\n",
       "      <td>-0.409591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086784</td>\n",
       "      <td>-0.408326</td>\n",
       "      <td>-0.589886</td>\n",
       "      <td>1.230396</td>\n",
       "      <td>0.525808</td>\n",
       "      <td>1.050923</td>\n",
       "      <td>-1.651197</td>\n",
       "      <td>0.772317</td>\n",
       "      <td>0.644511</td>\n",
       "      <td>1.199390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bahia - value   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0        -1.440329                                          2.723741   \n",
       "1        -1.404914                                          2.350880   \n",
       "2        -1.373637                                          2.123016   \n",
       "3        -1.345888                                          2.021477   \n",
       "4        -1.319065                                          1.887113   \n",
       "..             ...                                               ...   \n",
       "187       1.796141                                         -2.010387   \n",
       "188       1.811284                                         -1.870713   \n",
       "189       1.833479                                         -1.806230   \n",
       "190       1.853109                                         -1.727496   \n",
       "191       1.880066                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.132459  3.890153  -2.042341   \n",
       "1                         4.222509        1.592202  3.551840  -2.014760   \n",
       "2                         4.026019        2.999926  3.391423  -1.987179   \n",
       "3                         3.811492        1.273293  3.135979  -1.959598   \n",
       "4                         3.567576        2.045407  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.311366  0.589021   1.365911   \n",
       "188                      -0.588777       -1.417143  1.043728   1.376610   \n",
       "189                      -0.612606       -1.597784  1.387010   1.387308   \n",
       "190                      -0.640956       -1.400787  1.815728   1.398006   \n",
       "191                      -0.663358       -1.604775  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Precipitation (mm/day)  Atmospheric Pressure(mB)  ...  \\\n",
       "0                 -0.038360                 -0.693716  ...   \n",
       "1                  1.221742                 -0.603174  ...   \n",
       "2                  1.400094                 -0.351990  ...   \n",
       "3                  1.441606                  0.189583  ...   \n",
       "4                  1.224400                  0.717316  ...   \n",
       "..                      ...                       ...  ...   \n",
       "187               -0.479209                  0.697302  ...   \n",
       "188                0.014731                  0.264175  ...   \n",
       "189                0.024464                  0.049785  ...   \n",
       "190               -0.195334                 -0.223773  ...   \n",
       "191                0.690450                 -0.409591  ...   \n",
       "\n",
       "     Dew Point Temperature (°C)  Air Relative Humidity (%)  Wind Gust (m/s)  \\\n",
       "0                      0.029035                  -0.182257         1.402525   \n",
       "1                      0.060353                   0.138191         0.499197   \n",
       "2                      0.033064                   0.452705        -0.356839   \n",
       "3                     -0.109968                   0.516308        -1.154465   \n",
       "4                     -0.250986                   0.669955        -1.755788   \n",
       "..                          ...                        ...              ...   \n",
       "187                   -0.498914                  -0.113596        -0.437518   \n",
       "188                   -0.419733                  -0.176406        -0.385163   \n",
       "189                   -0.321149                  -0.283086        -0.415774   \n",
       "190                   -0.205138                  -0.406765        -0.475393   \n",
       "191                   -0.086784                  -0.408326        -0.589886   \n",
       "\n",
       "     Bahia - IDH  Bahia - Produção de Cimento (t)  Bahia - PIB - Estadual  \\\n",
       "0      -2.143224                        -1.723080               -1.703176   \n",
       "1      -2.108465                        -1.735985               -1.684201   \n",
       "2      -2.073707                        -1.739214               -1.665225   \n",
       "3      -2.038948                        -1.738529               -1.646249   \n",
       "4      -2.004190                        -1.735989               -1.627274   \n",
       "..           ...                              ...                     ...   \n",
       "187     1.261516                         0.511535                1.096947   \n",
       "188     1.253736                         0.513264                1.085441   \n",
       "189     1.245956                         0.526782                1.073935   \n",
       "190     1.238176                         0.525379                1.062429   \n",
       "191     1.230396                         0.525808                1.050923   \n",
       "\n",
       "     Bahia - PIB - Construção Civil  Bahia - PIB - Per Capita  \\\n",
       "0                         -0.816345                 -2.235724   \n",
       "1                         -0.772933                 -2.194204   \n",
       "2                         -0.729522                 -2.152684   \n",
       "3                         -0.686111                 -2.111164   \n",
       "4                         -0.642700                 -2.069645   \n",
       "..                              ...                       ...   \n",
       "187                       -1.668064                  0.877256   \n",
       "188                       -1.663847                  0.851021   \n",
       "189                       -1.659631                  0.824786   \n",
       "190                       -1.655414                  0.798552   \n",
       "191                       -1.651197                  0.772317   \n",
       "\n",
       "     Bahia - PIB - Preços de Mercado  Bahia - Desemprego  \n",
       "0                          -2.158201           -0.884052  \n",
       "1                          -2.117854           -0.885724  \n",
       "2                          -2.077508           -0.887395  \n",
       "3                          -2.037161           -0.889067  \n",
       "4                          -1.996814           -0.890739  \n",
       "..                               ...                 ...  \n",
       "187                         0.724962            1.200853  \n",
       "188                         0.704849            1.200487  \n",
       "189                         0.684737            1.200122  \n",
       "190                         0.664624            1.199756  \n",
       "191                         0.644511            1.199390  \n",
       "\n",
       "[192 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      129.857\n",
       "1      126.813\n",
       "2      152.225\n",
       "3      136.288\n",
       "4      148.117\n",
       "        ...   \n",
       "259        NaN\n",
       "260        NaN\n",
       "261        NaN\n",
       "262        NaN\n",
       "263        NaN\n",
       "Name: Bahia - Consumo de Cimento (t), Length: 264, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Precipitation (mm/day)</th>\n",
       "      <th>Atmospheric Pressure(mB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Dew Point Temperature (°C)</th>\n",
       "      <th>Air Relative Humidity (%)</th>\n",
       "      <th>Wind Gust (m/s)</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>Bahia - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.440329</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.132459</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-0.038360</td>\n",
       "      <td>-0.693716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029035</td>\n",
       "      <td>-0.182257</td>\n",
       "      <td>1.402525</td>\n",
       "      <td>-2.143224</td>\n",
       "      <td>-1.723080</td>\n",
       "      <td>-1.703176</td>\n",
       "      <td>-0.816345</td>\n",
       "      <td>-2.235724</td>\n",
       "      <td>-2.158201</td>\n",
       "      <td>-0.884052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.404914</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.592202</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>1.221742</td>\n",
       "      <td>-0.603174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060353</td>\n",
       "      <td>0.138191</td>\n",
       "      <td>0.499197</td>\n",
       "      <td>-2.108465</td>\n",
       "      <td>-1.735985</td>\n",
       "      <td>-1.684201</td>\n",
       "      <td>-0.772933</td>\n",
       "      <td>-2.194204</td>\n",
       "      <td>-2.117854</td>\n",
       "      <td>-0.885724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.373637</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.999926</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>1.400094</td>\n",
       "      <td>-0.351990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033064</td>\n",
       "      <td>0.452705</td>\n",
       "      <td>-0.356839</td>\n",
       "      <td>-2.073707</td>\n",
       "      <td>-1.739214</td>\n",
       "      <td>-1.665225</td>\n",
       "      <td>-0.729522</td>\n",
       "      <td>-2.152684</td>\n",
       "      <td>-2.077508</td>\n",
       "      <td>-0.887395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.345888</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.273293</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>1.441606</td>\n",
       "      <td>0.189583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109968</td>\n",
       "      <td>0.516308</td>\n",
       "      <td>-1.154465</td>\n",
       "      <td>-2.038948</td>\n",
       "      <td>-1.738529</td>\n",
       "      <td>-1.646249</td>\n",
       "      <td>-0.686111</td>\n",
       "      <td>-2.111164</td>\n",
       "      <td>-2.037161</td>\n",
       "      <td>-0.889067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.319065</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.045407</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>1.224400</td>\n",
       "      <td>0.717316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250986</td>\n",
       "      <td>0.669955</td>\n",
       "      <td>-1.755788</td>\n",
       "      <td>-2.004190</td>\n",
       "      <td>-1.735989</td>\n",
       "      <td>-1.627274</td>\n",
       "      <td>-0.642700</td>\n",
       "      <td>-2.069645</td>\n",
       "      <td>-1.996814</td>\n",
       "      <td>-0.890739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.097864</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.043807</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>-0.463180</td>\n",
       "      <td>-0.124526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089711</td>\n",
       "      <td>-0.552869</td>\n",
       "      <td>-0.500043</td>\n",
       "      <td>1.430739</td>\n",
       "      <td>0.617097</td>\n",
       "      <td>1.205171</td>\n",
       "      <td>-1.332406</td>\n",
       "      <td>1.004714</td>\n",
       "      <td>1.051323</td>\n",
       "      <td>1.273469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.120412</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.210856</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>-0.366119</td>\n",
       "      <td>0.218896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138090</td>\n",
       "      <td>-0.420868</td>\n",
       "      <td>-0.369291</td>\n",
       "      <td>1.428086</td>\n",
       "      <td>0.590103</td>\n",
       "      <td>1.206522</td>\n",
       "      <td>-1.357999</td>\n",
       "      <td>1.007770</td>\n",
       "      <td>1.045502</td>\n",
       "      <td>1.268173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.139591</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.107070</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>-0.415933</td>\n",
       "      <td>0.632077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258235</td>\n",
       "      <td>-0.273422</td>\n",
       "      <td>-0.389089</td>\n",
       "      <td>1.425433</td>\n",
       "      <td>0.561454</td>\n",
       "      <td>1.207873</td>\n",
       "      <td>-1.383592</td>\n",
       "      <td>1.010826</td>\n",
       "      <td>1.039682</td>\n",
       "      <td>1.262877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.156903</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.392942</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>-0.184106</td>\n",
       "      <td>1.099938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393645</td>\n",
       "      <td>-0.149855</td>\n",
       "      <td>-0.325560</td>\n",
       "      <td>1.422780</td>\n",
       "      <td>0.523492</td>\n",
       "      <td>1.209225</td>\n",
       "      <td>-1.409185</td>\n",
       "      <td>1.013881</td>\n",
       "      <td>1.033862</td>\n",
       "      <td>1.257581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.173599</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.714458</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>-0.603064</td>\n",
       "      <td>1.357710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503283</td>\n",
       "      <td>-0.213338</td>\n",
       "      <td>-0.290637</td>\n",
       "      <td>1.420127</td>\n",
       "      <td>0.512378</td>\n",
       "      <td>1.210576</td>\n",
       "      <td>-1.434778</td>\n",
       "      <td>1.016937</td>\n",
       "      <td>1.028042</td>\n",
       "      <td>1.252286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bahia - value   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0        -1.440329                                          2.723741   \n",
       "1        -1.404914                                          2.350880   \n",
       "2        -1.373637                                          2.123016   \n",
       "3        -1.345888                                          2.021477   \n",
       "4        -1.319065                                          1.887113   \n",
       "..             ...                                               ...   \n",
       "157       1.097864                                         -0.214006   \n",
       "158       1.120412                                         -0.434717   \n",
       "159       1.139591                                         -0.524091   \n",
       "160       1.156903                                         -0.614500   \n",
       "161       1.173599                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.132459  3.890153  -2.042341   \n",
       "1                         4.222509        1.592202  3.551840  -2.014760   \n",
       "2                         4.026019        2.999926  3.391423  -1.987179   \n",
       "3                         3.811492        1.273293  3.135979  -1.959598   \n",
       "4                         3.567576        2.045407  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.043807 -1.233012   1.031384   \n",
       "158                      -0.620523        0.210856 -1.299304   1.042716   \n",
       "159                      -0.631530        0.107070 -1.248662   1.054049   \n",
       "160                      -0.640320        0.392942 -1.068274   1.065381   \n",
       "161                      -0.649685        0.714458 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     Precipitation (mm/day)  Atmospheric Pressure(mB)  ...  \\\n",
       "0                 -0.038360                 -0.693716  ...   \n",
       "1                  1.221742                 -0.603174  ...   \n",
       "2                  1.400094                 -0.351990  ...   \n",
       "3                  1.441606                  0.189583  ...   \n",
       "4                  1.224400                  0.717316  ...   \n",
       "..                      ...                       ...  ...   \n",
       "157               -0.463180                 -0.124526  ...   \n",
       "158               -0.366119                  0.218896  ...   \n",
       "159               -0.415933                  0.632077  ...   \n",
       "160               -0.184106                  1.099938  ...   \n",
       "161               -0.603064                  1.357710  ...   \n",
       "\n",
       "     Dew Point Temperature (°C)  Air Relative Humidity (%)  Wind Gust (m/s)  \\\n",
       "0                      0.029035                  -0.182257         1.402525   \n",
       "1                      0.060353                   0.138191         0.499197   \n",
       "2                      0.033064                   0.452705        -0.356839   \n",
       "3                     -0.109968                   0.516308        -1.154465   \n",
       "4                     -0.250986                   0.669955        -1.755788   \n",
       "..                          ...                        ...              ...   \n",
       "157                   -0.089711                  -0.552869        -0.500043   \n",
       "158                   -0.138090                  -0.420868        -0.369291   \n",
       "159                   -0.258235                  -0.273422        -0.389089   \n",
       "160                   -0.393645                  -0.149855        -0.325560   \n",
       "161                   -0.503283                  -0.213338        -0.290637   \n",
       "\n",
       "     Bahia - IDH  Bahia - Produção de Cimento (t)  Bahia - PIB - Estadual  \\\n",
       "0      -2.143224                        -1.723080               -1.703176   \n",
       "1      -2.108465                        -1.735985               -1.684201   \n",
       "2      -2.073707                        -1.739214               -1.665225   \n",
       "3      -2.038948                        -1.738529               -1.646249   \n",
       "4      -2.004190                        -1.735989               -1.627274   \n",
       "..           ...                              ...                     ...   \n",
       "157     1.430739                         0.617097                1.205171   \n",
       "158     1.428086                         0.590103                1.206522   \n",
       "159     1.425433                         0.561454                1.207873   \n",
       "160     1.422780                         0.523492                1.209225   \n",
       "161     1.420127                         0.512378                1.210576   \n",
       "\n",
       "     Bahia - PIB - Construção Civil  Bahia - PIB - Per Capita  \\\n",
       "0                         -0.816345                 -2.235724   \n",
       "1                         -0.772933                 -2.194204   \n",
       "2                         -0.729522                 -2.152684   \n",
       "3                         -0.686111                 -2.111164   \n",
       "4                         -0.642700                 -2.069645   \n",
       "..                              ...                       ...   \n",
       "157                       -1.332406                  1.004714   \n",
       "158                       -1.357999                  1.007770   \n",
       "159                       -1.383592                  1.010826   \n",
       "160                       -1.409185                  1.013881   \n",
       "161                       -1.434778                  1.016937   \n",
       "\n",
       "     Bahia - PIB - Preços de Mercado  Bahia - Desemprego  \n",
       "0                          -2.158201           -0.884052  \n",
       "1                          -2.117854           -0.885724  \n",
       "2                          -2.077508           -0.887395  \n",
       "3                          -2.037161           -0.889067  \n",
       "4                          -1.996814           -0.890739  \n",
       "..                               ...                 ...  \n",
       "157                         1.051323            1.273469  \n",
       "158                         1.045502            1.268173  \n",
       "159                         1.039682            1.262877  \n",
       "160                         1.033862            1.257581  \n",
       "161                         1.028042            1.252286  \n",
       "\n",
       "[162 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[start_index:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      129.857\n",
       "1      126.813\n",
       "2      152.225\n",
       "3      136.288\n",
       "4      148.117\n",
       "        ...   \n",
       "157    213.266\n",
       "158    285.938\n",
       "159    219.576\n",
       "160    267.203\n",
       "161    240.714\n",
       "Name: Bahia - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[start_index:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21b9c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(t_input, t_target, window_size, start_from):\n",
    "    \n",
    "    X_batches = []\n",
    "    y_batches = []\n",
    "\n",
    "    train_input_values = t_input.values \n",
    "\n",
    "    for i in range(len(t_input) - window_size):\n",
    "        \n",
    "        X_window = train_input_values[i:i+window_size, :]\n",
    "        y_target = t_target[start_from+i+window_size]\n",
    "\n",
    "        X_batches.append(X_window)\n",
    "        y_batches.append(y_target)\n",
    "\n",
    "    return np.array(X_batches), np.array(y_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b281277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 36, 22)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_train, reshaped_target = create_batches(train_input, \n",
    "                                                 train_target, \n",
    "                                                 window_size, \n",
    "                                                 start_index)\n",
    "reshaped_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc5d50dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Precipitation (mm/day)</th>\n",
       "      <th>Atmospheric Pressure(mB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Dew Point Temperature (°C)</th>\n",
       "      <th>Air Relative Humidity (%)</th>\n",
       "      <th>Wind Gust (m/s)</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>Bahia - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.558660</td>\n",
       "      <td>0.888984</td>\n",
       "      <td>-0.460555</td>\n",
       "      <td>-1.048761</td>\n",
       "      <td>-0.368821</td>\n",
       "      <td>0.651397</td>\n",
       "      <td>0.944085</td>\n",
       "      <td>0.045243</td>\n",
       "      <td>0.398433</td>\n",
       "      <td>0.532679</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.301039</td>\n",
       "      <td>0.974067</td>\n",
       "      <td>-0.100403</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>1.205505</td>\n",
       "      <td>0.833268</td>\n",
       "      <td>0.194482</td>\n",
       "      <td>0.840990</td>\n",
       "      <td>1.014636</td>\n",
       "      <td>0.957509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.586295</td>\n",
       "      <td>0.954254</td>\n",
       "      <td>-0.440372</td>\n",
       "      <td>-0.649312</td>\n",
       "      <td>-0.328087</td>\n",
       "      <td>0.664707</td>\n",
       "      <td>0.947319</td>\n",
       "      <td>0.061828</td>\n",
       "      <td>0.881864</td>\n",
       "      <td>0.430146</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305019</td>\n",
       "      <td>0.883592</td>\n",
       "      <td>0.125796</td>\n",
       "      <td>0.471044</td>\n",
       "      <td>1.203037</td>\n",
       "      <td>0.852943</td>\n",
       "      <td>0.147537</td>\n",
       "      <td>0.856945</td>\n",
       "      <td>1.027926</td>\n",
       "      <td>0.975019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.614441</td>\n",
       "      <td>1.045217</td>\n",
       "      <td>-0.419247</td>\n",
       "      <td>-0.535369</td>\n",
       "      <td>-0.176031</td>\n",
       "      <td>0.678017</td>\n",
       "      <td>0.950553</td>\n",
       "      <td>0.046225</td>\n",
       "      <td>1.489586</td>\n",
       "      <td>0.052429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212853</td>\n",
       "      <td>0.871901</td>\n",
       "      <td>0.231163</td>\n",
       "      <td>0.480874</td>\n",
       "      <td>1.178322</td>\n",
       "      <td>0.872618</td>\n",
       "      <td>0.100591</td>\n",
       "      <td>0.872900</td>\n",
       "      <td>1.041216</td>\n",
       "      <td>0.992528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.639726</td>\n",
       "      <td>1.176395</td>\n",
       "      <td>-0.397019</td>\n",
       "      <td>-1.288807</td>\n",
       "      <td>-0.113037</td>\n",
       "      <td>0.691327</td>\n",
       "      <td>0.953786</td>\n",
       "      <td>0.032522</td>\n",
       "      <td>1.573881</td>\n",
       "      <td>-0.261929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.129927</td>\n",
       "      <td>0.796449</td>\n",
       "      <td>0.231164</td>\n",
       "      <td>0.490704</td>\n",
       "      <td>1.155459</td>\n",
       "      <td>0.892293</td>\n",
       "      <td>0.053646</td>\n",
       "      <td>0.888855</td>\n",
       "      <td>1.054506</td>\n",
       "      <td>1.010038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.666428</td>\n",
       "      <td>1.303259</td>\n",
       "      <td>-0.376532</td>\n",
       "      <td>-1.507550</td>\n",
       "      <td>-0.022703</td>\n",
       "      <td>0.704637</td>\n",
       "      <td>0.957020</td>\n",
       "      <td>0.042757</td>\n",
       "      <td>1.385770</td>\n",
       "      <td>-0.590265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036978</td>\n",
       "      <td>0.790608</td>\n",
       "      <td>0.097551</td>\n",
       "      <td>0.500533</td>\n",
       "      <td>1.124580</td>\n",
       "      <td>0.911968</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.904809</td>\n",
       "      <td>1.067796</td>\n",
       "      <td>1.027547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.796141</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.311366</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-0.479209</td>\n",
       "      <td>0.697302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.498914</td>\n",
       "      <td>-0.113596</td>\n",
       "      <td>-0.437518</td>\n",
       "      <td>1.261516</td>\n",
       "      <td>0.511535</td>\n",
       "      <td>1.096947</td>\n",
       "      <td>-1.668064</td>\n",
       "      <td>0.877256</td>\n",
       "      <td>0.724962</td>\n",
       "      <td>1.200853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.811284</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.417143</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>0.014731</td>\n",
       "      <td>0.264175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.419733</td>\n",
       "      <td>-0.176406</td>\n",
       "      <td>-0.385163</td>\n",
       "      <td>1.253736</td>\n",
       "      <td>0.513264</td>\n",
       "      <td>1.085441</td>\n",
       "      <td>-1.663847</td>\n",
       "      <td>0.851021</td>\n",
       "      <td>0.704849</td>\n",
       "      <td>1.200487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.833479</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.597784</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>0.024464</td>\n",
       "      <td>0.049785</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321149</td>\n",
       "      <td>-0.283086</td>\n",
       "      <td>-0.415774</td>\n",
       "      <td>1.245956</td>\n",
       "      <td>0.526782</td>\n",
       "      <td>1.073935</td>\n",
       "      <td>-1.659631</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.684737</td>\n",
       "      <td>1.200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.853109</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.400787</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-0.195334</td>\n",
       "      <td>-0.223773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205138</td>\n",
       "      <td>-0.406765</td>\n",
       "      <td>-0.475393</td>\n",
       "      <td>1.238176</td>\n",
       "      <td>0.525379</td>\n",
       "      <td>1.062429</td>\n",
       "      <td>-1.655414</td>\n",
       "      <td>0.798552</td>\n",
       "      <td>0.664624</td>\n",
       "      <td>1.199756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.880066</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.604775</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>0.690450</td>\n",
       "      <td>-0.409591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086784</td>\n",
       "      <td>-0.408326</td>\n",
       "      <td>-0.589886</td>\n",
       "      <td>1.230396</td>\n",
       "      <td>0.525808</td>\n",
       "      <td>1.050923</td>\n",
       "      <td>-1.651197</td>\n",
       "      <td>0.772317</td>\n",
       "      <td>0.644511</td>\n",
       "      <td>1.199390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bahia - value   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "126       0.558660                                          0.888984   \n",
       "127       0.586295                                          0.954254   \n",
       "128       0.614441                                          1.045217   \n",
       "129       0.639726                                          1.176395   \n",
       "130       0.666428                                          1.303259   \n",
       "..             ...                                               ...   \n",
       "187       1.796141                                         -2.010387   \n",
       "188       1.811284                                         -1.870713   \n",
       "189       1.833479                                         -1.806230   \n",
       "190       1.853109                                         -1.727496   \n",
       "191       1.880066                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "126                      -0.460555       -1.048761 -0.368821   0.651397   \n",
       "127                      -0.440372       -0.649312 -0.328087   0.664707   \n",
       "128                      -0.419247       -0.535369 -0.176031   0.678017   \n",
       "129                      -0.397019       -1.288807 -0.113037   0.691327   \n",
       "130                      -0.376532       -1.507550 -0.022703   0.704637   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.311366  0.589021   1.365911   \n",
       "188                      -0.588777       -1.417143  1.043728   1.376610   \n",
       "189                      -0.612606       -1.597784  1.387010   1.387308   \n",
       "190                      -0.640956       -1.400787  1.815728   1.398006   \n",
       "191                      -0.663358       -1.604775  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "126                                0.944085   0.045243   \n",
       "127                                0.947319   0.061828   \n",
       "128                                0.950553   0.046225   \n",
       "129                                0.953786   0.032522   \n",
       "130                                0.957020   0.042757   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Precipitation (mm/day)  Atmospheric Pressure(mB)  ...  \\\n",
       "126                0.398433                  0.532679  ...   \n",
       "127                0.881864                  0.430146  ...   \n",
       "128                1.489586                  0.052429  ...   \n",
       "129                1.573881                 -0.261929  ...   \n",
       "130                1.385770                 -0.590265  ...   \n",
       "..                      ...                       ...  ...   \n",
       "187               -0.479209                  0.697302  ...   \n",
       "188                0.014731                  0.264175  ...   \n",
       "189                0.024464                  0.049785  ...   \n",
       "190               -0.195334                 -0.223773  ...   \n",
       "191                0.690450                 -0.409591  ...   \n",
       "\n",
       "     Dew Point Temperature (°C)  Air Relative Humidity (%)  Wind Gust (m/s)  \\\n",
       "126                   -0.301039                   0.974067        -0.100403   \n",
       "127                   -0.305019                   0.883592         0.125796   \n",
       "128                   -0.212853                   0.871901         0.231163   \n",
       "129                   -0.129927                   0.796449         0.231164   \n",
       "130                   -0.036978                   0.790608         0.097551   \n",
       "..                          ...                        ...              ...   \n",
       "187                   -0.498914                  -0.113596        -0.437518   \n",
       "188                   -0.419733                  -0.176406        -0.385163   \n",
       "189                   -0.321149                  -0.283086        -0.415774   \n",
       "190                   -0.205138                  -0.406765        -0.475393   \n",
       "191                   -0.086784                  -0.408326        -0.589886   \n",
       "\n",
       "     Bahia - IDH  Bahia - Produção de Cimento (t)  Bahia - PIB - Estadual  \\\n",
       "126     0.461215                         1.205505                0.833268   \n",
       "127     0.471044                         1.203037                0.852943   \n",
       "128     0.480874                         1.178322                0.872618   \n",
       "129     0.490704                         1.155459                0.892293   \n",
       "130     0.500533                         1.124580                0.911968   \n",
       "..           ...                              ...                     ...   \n",
       "187     1.261516                         0.511535                1.096947   \n",
       "188     1.253736                         0.513264                1.085441   \n",
       "189     1.245956                         0.526782                1.073935   \n",
       "190     1.238176                         0.525379                1.062429   \n",
       "191     1.230396                         0.525808                1.050923   \n",
       "\n",
       "     Bahia - PIB - Construção Civil  Bahia - PIB - Per Capita  \\\n",
       "126                        0.194482                  0.840990   \n",
       "127                        0.147537                  0.856945   \n",
       "128                        0.100591                  0.872900   \n",
       "129                        0.053646                  0.888855   \n",
       "130                        0.006700                  0.904809   \n",
       "..                              ...                       ...   \n",
       "187                       -1.668064                  0.877256   \n",
       "188                       -1.663847                  0.851021   \n",
       "189                       -1.659631                  0.824786   \n",
       "190                       -1.655414                  0.798552   \n",
       "191                       -1.651197                  0.772317   \n",
       "\n",
       "     Bahia - PIB - Preços de Mercado  Bahia - Desemprego  \n",
       "126                         1.014636            0.957509  \n",
       "127                         1.027926            0.975019  \n",
       "128                         1.041216            0.992528  \n",
       "129                         1.054506            1.010038  \n",
       "130                         1.067796            1.027547  \n",
       "..                               ...                 ...  \n",
       "187                         0.724962            1.200853  \n",
       "188                         0.704849            1.200487  \n",
       "189                         0.684737            1.200122  \n",
       "190                         0.664624            1.199756  \n",
       "191                         0.644511            1.199390  \n",
       "\n",
       "[66 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "test_input = input_data.iloc[train_split - window_size:split_index + 1]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82f07fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 36, 22)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_test, reshaped_test_target = create_batches(test_input, \n",
    "                                                     target_data, \n",
    "                                                     window_size, \n",
    "                                                     train_split - window_size)\n",
    "reshaped_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c5afeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(arr, div_factor, add_factor=0):\n",
    "    split_factor = len(arr) // div_factor\n",
    "    positions_to_drop_index = []\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = len(arr) - (i * div_factor + 1)\n",
    "        positions_to_drop_index.append(pos)\n",
    "        positions_to_drop.append(pos + add_factor)\n",
    "    \n",
    "    arr_droped = arr[positions_to_drop]\n",
    "    arr_result = np.delete(arr, positions_to_drop_index, axis=0)\n",
    "    \n",
    "    return arr_result, arr_droped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede Neural Recorrente com optmizador Estocástico\n",
    "def lstm_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    train, train_val = validation_splitter(train_input, 7)\n",
    "    target,target_val = validation_splitter(train_target, 7)\n",
    "#     display(train.shape)\n",
    "#     display(train_val.shape)\n",
    "#     display(target.shape)\n",
    "#     display(target_val.shape)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(36, activation='tanh', \n",
    "                             return_sequences=True, \n",
    "                             input_shape=(reshaped_train.shape[1],\n",
    "                                          reshaped_train.shape[2])),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.LSTM(180,activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val,\n",
    "                                         target_val),\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_input, test_target):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(50)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = lstm_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1acb58be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1204955363, 4288140589, 945062301, 1578163188, 674910152, 3928923232, 4023788313, 2178889877, 2797376664, 2469496785, 1623094374, 139938307, 4197823081, 316891619, 505937130, 4198836269, 3122020789, 3420567170, 1474563229, 3714789750, 2418111916, 4170547530, 945979248, 2394054202, 326598428, 2600141495, 3696591145, 1566232679, 2536234443, 3335621420, 3550578555, 1410184816, 3896969222, 1627487441, 2914332535, 551149131, 3554704798, 4192696033, 2391300185, 3816837603, 1505854832, 130677964, 156634971, 1611721355, 3441167327, 1580430504, 12116113, 903321005, 1202636046, 355629169]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 553.7412109375\n",
      "winner_seed: 1204955363\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 613.1414184570312\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 570.1702270507812\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 1181.860107421875\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 529.5692138671875\n",
      "winner_seed: 674910152\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 603.9993286132812\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 564.1668701171875\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 566.1148071289062\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 588.7467651367188\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 11:45:04.327227: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 589.1661987304688\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 512.1698608398438\n",
      "winner_seed: 1623094374\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 878.75244140625\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 622.929443359375\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 783.0830078125\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 637.3547973632812\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 579.6981811523438\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 11:49:51.725653: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 549.134521484375\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 607.1585083007812\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 903.810546875\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 639.9957275390625\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 507.9351806640625\n",
      "winner_seed: 2418111916\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 568.7835693359375\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 544.49462890625\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 561.6903686523438\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 621.6878051757812\n",
      "\n",
      "\n",
      "Step: 25 ___________________________________________\n",
      "val_loss: 537.5923461914062\n",
      "\n",
      "\n",
      "Step: 26 ___________________________________________\n",
      "val_loss: 668.2783203125\n",
      "\n",
      "\n",
      "Step: 27 ___________________________________________\n",
      "val_loss: 672.629638671875\n",
      "\n",
      "\n",
      "Step: 28 ___________________________________________\n",
      "val_loss: 396.7104187011719\n",
      "winner_seed: 2536234443\n",
      "\n",
      "\n",
      "Step: 29 ___________________________________________\n",
      "val_loss: 553.5266723632812\n",
      "\n",
      "\n",
      "Step: 30 ___________________________________________\n",
      "val_loss: 645.429931640625\n",
      "\n",
      "\n",
      "Step: 31 ___________________________________________\n",
      "val_loss: 573.8820190429688\n",
      "\n",
      "\n",
      "Step: 32 ___________________________________________\n",
      "val_loss: 658.099365234375\n",
      "\n",
      "\n",
      "Step: 33 ___________________________________________\n",
      "val_loss: 533.8823852539062\n",
      "\n",
      "\n",
      "Step: 34 ___________________________________________\n",
      "val_loss: 605.4137573242188\n",
      "\n",
      "\n",
      "Step: 35 ___________________________________________\n",
      "val_loss: 588.1891479492188\n",
      "\n",
      "\n",
      "Step: 36 ___________________________________________\n",
      "val_loss: 618.343017578125\n",
      "\n",
      "\n",
      "Step: 37 ___________________________________________\n",
      "val_loss: 524.9758911132812\n",
      "\n",
      "\n",
      "Step: 38 ___________________________________________\n",
      "val_loss: 548.01513671875\n",
      "\n",
      "\n",
      "Step: 39 ___________________________________________\n",
      "val_loss: 637.083740234375\n",
      "\n",
      "\n",
      "Step: 40 ___________________________________________\n",
      "val_loss: 605.9974975585938\n",
      "\n",
      "\n",
      "Step: 41 ___________________________________________\n",
      "val_loss: 534.4713134765625\n",
      "\n",
      "\n",
      "Step: 42 ___________________________________________\n",
      "val_loss: 676.0947265625\n",
      "\n",
      "\n",
      "Step: 43 ___________________________________________\n",
      "val_loss: 544.0449829101562\n",
      "\n",
      "\n",
      "Step: 44 ___________________________________________\n",
      "val_loss: 592.2483520507812\n",
      "\n",
      "\n",
      "Step: 45 ___________________________________________\n",
      "val_loss: 424.3180847167969\n",
      "\n",
      "\n",
      "Step: 46 ___________________________________________\n",
      "val_loss: 587.3533325195312\n",
      "\n",
      "\n",
      "Step: 47 ___________________________________________\n",
      "val_loss: 585.6809692382812\n",
      "\n",
      "\n",
      "Step: 48 ___________________________________________\n",
      "val_loss: 447.7502746582031\n",
      "\n",
      "\n",
      "Step: 49 ___________________________________________\n",
      "val_loss: 470.046875\n",
      "\n",
      "\n",
      "final_seed: 2536234443\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(reshaped_train, reshaped_target, reshaped_test, reshaped_test_target)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 [==============================] - 2s 120ms/step - loss: 57661.2539 - val_loss: 3894.6025\n",
      "Epoch 2/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2974.9497 - val_loss: 2896.0864\n",
      "Epoch 3/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2919.0327 - val_loss: 4516.9863\n",
      "Epoch 4/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4062.4526 - val_loss: 4475.5781\n",
      "Epoch 5/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3164.9417 - val_loss: 3650.8035\n",
      "Epoch 6/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3796.5295 - val_loss: 2975.1572\n",
      "Epoch 7/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3192.3621 - val_loss: 2777.5771\n",
      "Epoch 8/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2795.3298 - val_loss: 2661.8411\n",
      "Epoch 9/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3203.4111 - val_loss: 2825.4104\n",
      "Epoch 10/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2637.3018 - val_loss: 2919.7524\n",
      "Epoch 11/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2370.6028 - val_loss: 3722.2861\n",
      "Epoch 12/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2427.8188 - val_loss: 1844.1167\n",
      "Epoch 13/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1604.6648 - val_loss: 1587.2192\n",
      "Epoch 14/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1477.7460 - val_loss: 2952.4670\n",
      "Epoch 15/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4134.5342 - val_loss: 1987.7888\n",
      "Epoch 16/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1768.3959 - val_loss: 1778.2463\n",
      "Epoch 17/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1756.0085 - val_loss: 1692.2019\n",
      "Epoch 18/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1278.8618 - val_loss: 1289.4618\n",
      "Epoch 19/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1003.8031 - val_loss: 1215.3320\n",
      "Epoch 20/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1120.9822 - val_loss: 2064.6748\n",
      "Epoch 21/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1468.8345 - val_loss: 1037.5519\n",
      "Epoch 22/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1176.4777 - val_loss: 1519.4344\n",
      "Epoch 23/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1040.3170 - val_loss: 1316.5425\n",
      "Epoch 24/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 931.2540 - val_loss: 1339.0162\n",
      "Epoch 25/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1634.2280 - val_loss: 737.7855\n",
      "Epoch 26/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1000.0743 - val_loss: 1021.3602\n",
      "Epoch 27/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 888.2986 - val_loss: 756.5469\n",
      "Epoch 28/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 538.1638 - val_loss: 668.0618\n",
      "Epoch 29/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 694.4900 - val_loss: 663.0499\n",
      "Epoch 30/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 575.2333 - val_loss: 1345.9141\n",
      "Epoch 31/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 767.1017 - val_loss: 544.8983\n",
      "Epoch 32/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 817.7637 - val_loss: 886.4907\n",
      "Epoch 33/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 671.6508 - val_loss: 687.0976\n",
      "Epoch 34/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 527.9489 - val_loss: 1178.5554\n",
      "Epoch 35/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1533.6252 - val_loss: 575.2018\n",
      "Epoch 36/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 698.4550 - val_loss: 519.1051\n",
      "Epoch 37/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 509.9830 - val_loss: 555.4299\n",
      "Epoch 38/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 571.9044 - val_loss: 1452.8484\n",
      "Epoch 39/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 933.2131 - val_loss: 673.9841\n",
      "Epoch 40/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 490.3390 - val_loss: 545.0108\n",
      "Epoch 41/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 505.8254 - val_loss: 551.3314\n",
      "Epoch 42/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 502.9787 - val_loss: 824.4246\n",
      "Epoch 43/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1014.3351 - val_loss: 689.5100\n",
      "Epoch 44/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 837.0140 - val_loss: 818.9933\n",
      "Epoch 45/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 554.9460 - val_loss: 791.3289\n",
      "Epoch 46/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 466.9397 - val_loss: 640.7117\n",
      "Epoch 47/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 403.0182 - val_loss: 684.7631\n",
      "Epoch 48/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 432.4042 - val_loss: 681.6073\n",
      "Epoch 49/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2019.5759 - val_loss: 1660.7606\n",
      "Epoch 50/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 732.9039 - val_loss: 599.0466\n",
      "Epoch 51/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 585.9789 - val_loss: 766.5711\n",
      "Epoch 52/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 430.7378 - val_loss: 708.9071\n",
      "Epoch 53/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 410.2595 - val_loss: 738.1630\n",
      "Epoch 54/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 356.9188 - val_loss: 776.6548\n",
      "Epoch 55/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 430.8080 - val_loss: 769.9910\n",
      "Epoch 56/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 478.8400 - val_loss: 736.9915\n",
      "Epoch 57/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 373.5330 - val_loss: 621.3880\n",
      "Epoch 58/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 396.6149 - val_loss: 692.9216\n",
      "Epoch 59/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 370.4818 - val_loss: 642.1949\n",
      "Epoch 60/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 336.5285 - val_loss: 924.6173\n",
      "Epoch 61/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 775.3828 - val_loss: 1002.4382\n",
      "Epoch 62/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 400.7529 - val_loss: 671.2805\n",
      "Epoch 63/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 433.3381 - val_loss: 670.3268\n",
      "Epoch 64/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 323.3933 - val_loss: 627.9477\n",
      "Epoch 65/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 396.4179 - val_loss: 602.4465\n",
      "Epoch 66/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 308.6508 - val_loss: 621.7288\n",
      "Epoch 67/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 354.1935 - val_loss: 643.7383\n",
      "Epoch 68/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 296.8348 - val_loss: 754.0535\n",
      "Epoch 69/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 509.5559 - val_loss: 649.6676\n",
      "Epoch 70/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 313.2614 - val_loss: 743.1662\n",
      "Epoch 71/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 343.9205 - val_loss: 618.0900\n",
      "Epoch 72/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 317.6628 - val_loss: 641.5109\n",
      "Epoch 73/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 270.3124 - val_loss: 628.1819\n",
      "Epoch 74/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 280.6423 - val_loss: 727.6714\n",
      "Epoch 75/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 341.2205 - val_loss: 637.6682\n",
      "Epoch 76/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 313.5803 - val_loss: 1042.8292\n",
      "Epoch 77/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1030.5284 - val_loss: 680.1170\n",
      "Epoch 78/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 328.9410 - val_loss: 703.7424\n",
      "Epoch 79/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 301.8081 - val_loss: 592.1796\n",
      "Epoch 80/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 299.7668 - val_loss: 653.8931\n",
      "Epoch 81/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 273.0102 - val_loss: 634.6710\n",
      "Epoch 82/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 268.2903 - val_loss: 611.0404\n",
      "Epoch 83/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 288.1713 - val_loss: 592.8536\n",
      "Epoch 84/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 280.8788 - val_loss: 646.5765\n",
      "Epoch 85/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 237.6575 - val_loss: 630.5984\n",
      "Epoch 86/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 255.4982 - val_loss: 1033.6656\n",
      "Epoch 87/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 416.2823 - val_loss: 968.5189\n",
      "Epoch 88/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 402.3506 - val_loss: 658.1161\n",
      "Epoch 89/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 307.1173 - val_loss: 715.3715\n",
      "Epoch 90/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 297.0154 - val_loss: 672.6287\n",
      "Epoch 91/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 237.8755 - val_loss: 644.3953\n",
      "Epoch 92/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 230.7933 - val_loss: 612.5840\n",
      "Epoch 93/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 261.6235 - val_loss: 611.9596\n",
      "Epoch 94/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 238.0270 - val_loss: 630.5491\n",
      "Epoch 95/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 252.3383 - val_loss: 622.0811\n",
      "Epoch 96/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 249.0378 - val_loss: 678.1308\n",
      "Epoch 97/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 306.9720 - val_loss: 641.4216\n",
      "Epoch 98/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 238.6450 - val_loss: 662.6655\n",
      "Epoch 99/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 229.1573 - val_loss: 693.1400\n",
      "Epoch 100/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 309.0709 - val_loss: 604.0745\n",
      "Epoch 101/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 258.9500 - val_loss: 591.4211\n",
      "Epoch 102/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 321.3371 - val_loss: 608.8540\n",
      "Epoch 103/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 299.0537 - val_loss: 640.0918\n",
      "Epoch 104/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 249.7336 - val_loss: 632.8630\n",
      "Epoch 105/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 220.7762 - val_loss: 641.2987\n",
      "Epoch 106/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 232.0984 - val_loss: 751.4150\n",
      "Epoch 107/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 307.6756 - val_loss: 603.3052\n",
      "Epoch 108/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 251.6958 - val_loss: 719.4234\n",
      "Epoch 109/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 224.7529 - val_loss: 603.5722\n",
      "Epoch 110/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 242.1221 - val_loss: 577.1565\n",
      "Epoch 111/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 224.7006 - val_loss: 671.5108\n",
      "Epoch 112/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 245.1762 - val_loss: 677.9186\n",
      "Epoch 113/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 224.9133 - val_loss: 670.7187\n",
      "Epoch 114/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 240.1051 - val_loss: 686.8557\n",
      "Epoch 115/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 229.3580 - val_loss: 680.8989\n",
      "Epoch 116/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 221.2271 - val_loss: 706.8134\n",
      "Epoch 117/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 227.4727 - val_loss: 727.0361\n",
      "Epoch 118/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 193.4467 - val_loss: 685.1115\n",
      "Epoch 119/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 242.2176 - val_loss: 737.6025\n",
      "Epoch 120/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 253.3643 - val_loss: 786.8454\n",
      "Epoch 121/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 232.6689 - val_loss: 678.8333\n",
      "Epoch 122/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 191.6642 - val_loss: 725.8040\n",
      "Epoch 123/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 230.5711 - val_loss: 704.0043\n",
      "Epoch 124/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 188.8432 - val_loss: 697.4059\n",
      "Epoch 125/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 198.3673 - val_loss: 695.1945\n",
      "Epoch 126/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 204.2003 - val_loss: 677.3137\n",
      "Epoch 127/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 218.4114 - val_loss: 705.1388\n",
      "Epoch 128/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 224.1418 - val_loss: 716.9707\n",
      "Epoch 129/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 218.5338 - val_loss: 690.2313\n",
      "Epoch 130/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 227.0983 - val_loss: 744.8077\n",
      "Epoch 131/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 277.4048 - val_loss: 667.2446\n",
      "Epoch 132/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 177.5774 - val_loss: 753.5268\n",
      "Epoch 133/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 192.7605 - val_loss: 706.7556\n",
      "Epoch 134/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 229.6357 - val_loss: 636.1942\n",
      "Epoch 135/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 207.5364 - val_loss: 650.8644\n",
      "Epoch 136/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 222.5054 - val_loss: 660.2582\n",
      "Epoch 137/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 254.6078 - val_loss: 670.0525\n",
      "Epoch 138/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 234.2103 - val_loss: 638.2699\n",
      "Epoch 139/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 212.2155 - val_loss: 694.6453\n",
      "Epoch 140/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 217.6637 - val_loss: 687.7505\n",
      "Epoch 141/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 218.5126 - val_loss: 720.7056\n",
      "Epoch 142/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 196.3731 - val_loss: 768.9705\n",
      "Epoch 143/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 202.3897 - val_loss: 646.5305\n",
      "Epoch 144/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 200.1857 - val_loss: 674.8985\n",
      "Epoch 145/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 243.2100 - val_loss: 619.1049\n",
      "Epoch 146/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 269.7851 - val_loss: 729.1633\n",
      "Epoch 147/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 219.9068 - val_loss: 672.2530\n",
      "Epoch 148/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 235.1188 - val_loss: 725.8691\n",
      "Epoch 149/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 185.4063 - val_loss: 675.4531\n",
      "Epoch 150/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 249.5771 - val_loss: 642.3170\n",
      "Epoch 151/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 183.0719 - val_loss: 629.2642\n",
      "Epoch 152/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 184.2068 - val_loss: 661.0799\n",
      "Epoch 153/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 175.8993 - val_loss: 598.0828\n",
      "Epoch 154/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 176.0860 - val_loss: 673.1124\n",
      "Epoch 155/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 214.7852 - val_loss: 639.7597\n",
      "Epoch 156/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 209.4821 - val_loss: 670.7412\n",
      "Epoch 157/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 201.2251 - val_loss: 657.3181\n",
      "Epoch 158/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 216.0056 - val_loss: 748.8733\n",
      "Epoch 159/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 200.8542 - val_loss: 730.6512\n",
      "Epoch 160/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 202.2718 - val_loss: 753.0575\n",
      "Epoch 161/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 243.6872 - val_loss: 766.3827\n",
      "Epoch 162/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 235.8396 - val_loss: 702.1755\n",
      "Epoch 163/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 209.4466 - val_loss: 613.5001\n",
      "Epoch 164/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 211.8786 - val_loss: 797.1661\n",
      "Epoch 165/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 244.8933 - val_loss: 649.6470\n",
      "Epoch 166/10000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 172.9231 - val_loss: 661.1822\n",
      "Epoch 167/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 201.4542 - val_loss: 723.2141\n",
      "Epoch 168/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 197.4895 - val_loss: 668.1332\n",
      "Epoch 169/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 207.6711 - val_loss: 652.2241\n",
      "Epoch 170/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 189.3395 - val_loss: 640.3254\n",
      "Epoch 171/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 210.3090 - val_loss: 642.7439\n",
      "Epoch 172/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 177.3611 - val_loss: 632.8171\n",
      "Epoch 173/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 184.8695 - val_loss: 648.4946\n",
      "Epoch 174/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 173.6171 - val_loss: 726.0856\n",
      "Epoch 175/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 222.1695 - val_loss: 652.1072\n",
      "Epoch 176/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 242.0066 - val_loss: 678.9366\n",
      "Epoch 177/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 214.0600 - val_loss: 627.3631\n",
      "Epoch 178/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 191.3787 - val_loss: 665.3002\n",
      "Epoch 179/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 222.4428 - val_loss: 614.0461\n",
      "Epoch 180/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 194.3512 - val_loss: 644.1799\n",
      "Epoch 181/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 173.9192 - val_loss: 633.9211\n",
      "Epoch 182/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 191.9222 - val_loss: 637.2734\n",
      "Epoch 183/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 195.7321 - val_loss: 643.5609\n",
      "Epoch 184/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 188.4182 - val_loss: 664.4493\n",
      "Epoch 185/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 198.6918 - val_loss: 689.4123\n",
      "Epoch 186/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 197.1964 - val_loss: 735.0580\n",
      "Epoch 187/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 193.7039 - val_loss: 697.4238\n",
      "Epoch 188/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 197.0519 - val_loss: 664.7420\n",
      "Epoch 189/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 202.3971 - val_loss: 660.2076\n",
      "Epoch 190/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 215.8975 - val_loss: 683.5738\n",
      "Epoch 191/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 199.2263 - val_loss: 681.0475\n",
      "Epoch 192/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 215.2193 - val_loss: 723.9587\n",
      "Epoch 193/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 287.2801 - val_loss: 770.0352\n",
      "Epoch 194/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 186.4973 - val_loss: 675.3123\n",
      "Epoch 195/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 199.1494 - val_loss: 663.7534\n",
      "Epoch 196/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 182.2138 - val_loss: 675.6033\n",
      "Epoch 197/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 235.1983 - val_loss: 705.2234\n",
      "Epoch 198/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 166.5053 - val_loss: 654.2466\n",
      "Epoch 199/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 164.2939 - val_loss: 699.6124\n",
      "Epoch 200/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 186.9428 - val_loss: 653.1761\n",
      "Epoch 201/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 184.8479 - val_loss: 697.3107\n",
      "Epoch 202/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 174.7330 - val_loss: 665.3217\n",
      "Epoch 203/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 187.0868 - val_loss: 642.3935\n",
      "Epoch 204/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 201.6053 - val_loss: 640.1275\n",
      "Epoch 205/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 181.6204 - val_loss: 637.0481\n",
      "Epoch 206/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 184.9684 - val_loss: 625.4098\n",
      "Epoch 207/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 175.1593 - val_loss: 755.2030\n",
      "Epoch 208/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 174.3823 - val_loss: 685.1602\n",
      "Epoch 209/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 184.5878 - val_loss: 662.9540\n",
      "Epoch 210/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 177.4179 - val_loss: 686.7101\n",
      "Epoch 211/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 184.2527 - val_loss: 674.3386\n",
      "Epoch 212/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 194.4689 - val_loss: 643.3870\n",
      "Epoch 213/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 203.6563 - val_loss: 708.4329\n",
      "Epoch 214/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 207.0576 - val_loss: 666.4572\n",
      "Epoch 215/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 206.0587 - val_loss: 683.0507\n",
      "Epoch 216/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 194.2503 - val_loss: 625.6022\n",
      "Epoch 217/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 180.6393 - val_loss: 623.0823\n",
      "Epoch 218/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 181.8897 - val_loss: 611.4443\n",
      "Epoch 219/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 237.0915 - val_loss: 647.0953\n",
      "Epoch 220/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 192.8169 - val_loss: 711.5310\n",
      "Epoch 221/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 301.3385 - val_loss: 670.4199\n",
      "Epoch 222/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 206.1441 - val_loss: 688.6796\n",
      "Epoch 223/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 201.0311 - val_loss: 738.3752\n",
      "Epoch 224/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 200.0541 - val_loss: 685.3337\n",
      "Epoch 225/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 191.6567 - val_loss: 632.7968\n",
      "Epoch 226/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 196.3450 - val_loss: 609.3569\n",
      "Epoch 227/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 211.8033 - val_loss: 657.1155\n",
      "Epoch 228/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 205.9756 - val_loss: 589.7740\n",
      "Epoch 229/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 215.2927 - val_loss: 627.5989\n",
      "Epoch 230/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 268.8233 - val_loss: 677.5969\n",
      "Epoch 231/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 235.7305 - val_loss: 614.6765\n",
      "Epoch 232/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 222.4802 - val_loss: 612.8777\n",
      "Epoch 233/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 216.3228 - val_loss: 603.0468\n",
      "Epoch 234/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 198.7170 - val_loss: 599.7838\n",
      "Epoch 235/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 198.8653 - val_loss: 722.8079\n",
      "Epoch 236/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 275.1929 - val_loss: 625.3996\n",
      "Epoch 237/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 214.3308 - val_loss: 611.9238\n",
      "Epoch 238/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 182.1263 - val_loss: 615.1033\n",
      "Epoch 239/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 225.9146 - val_loss: 555.5974\n",
      "Epoch 240/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 189.3769 - val_loss: 554.1085\n",
      "Epoch 241/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 187.8790 - val_loss: 770.8277\n",
      "Epoch 242/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 277.8770 - val_loss: 626.7552\n",
      "Epoch 243/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 210.8576 - val_loss: 583.4798\n",
      "Epoch 244/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 175.4595 - val_loss: 591.6438\n",
      "Epoch 245/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 203.3768 - val_loss: 593.1586\n",
      "Epoch 246/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 186.0870 - val_loss: 728.5811\n",
      "Epoch 247/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 215.8931 - val_loss: 561.6465\n",
      "Epoch 248/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 185.8917 - val_loss: 578.6210\n",
      "Epoch 249/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 189.0215 - val_loss: 605.1622\n",
      "Epoch 250/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 185.7667 - val_loss: 621.7785\n",
      "Epoch 251/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 178.3270 - val_loss: 603.5551\n",
      "Epoch 252/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 202.2479 - val_loss: 653.1344\n",
      "Epoch 253/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 173.6257 - val_loss: 625.3044\n",
      "Epoch 254/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 169.6181 - val_loss: 623.5200\n",
      "Epoch 255/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 170.2515 - val_loss: 661.0007\n",
      "Epoch 256/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 175.6135 - val_loss: 620.4378\n",
      "Epoch 257/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 183.4424 - val_loss: 633.6456\n",
      "Epoch 258/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 158.7931 - val_loss: 642.7705\n",
      "Epoch 259/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 158.9866 - val_loss: 634.4460\n",
      "Epoch 260/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 171.2809 - val_loss: 702.1628\n",
      "Epoch 261/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 191.5832 - val_loss: 628.2297\n",
      "Epoch 262/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 209.8011 - val_loss: 624.3933\n",
      "Epoch 263/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 180.1288 - val_loss: 723.4232\n",
      "Epoch 264/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 169.2563 - val_loss: 724.1814\n",
      "Epoch 265/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 185.4216 - val_loss: 703.9233\n",
      "Epoch 266/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 158.2010 - val_loss: 632.8379\n",
      "Epoch 267/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 156.1867 - val_loss: 661.1714\n",
      "Epoch 268/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 166.8435 - val_loss: 680.3939\n",
      "Epoch 269/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 173.3655 - val_loss: 698.0332\n",
      "Epoch 270/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 207.2950 - val_loss: 670.7288\n",
      "Epoch 271/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 166.9364 - val_loss: 698.6402\n",
      "Epoch 272/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 170.0073 - val_loss: 801.8317\n",
      "Epoch 273/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 232.2650 - val_loss: 709.2603\n",
      "Epoch 274/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 192.9668 - val_loss: 654.5330\n",
      "Epoch 275/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 164.8862 - val_loss: 813.4778\n",
      "Epoch 276/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 165.9129 - val_loss: 771.5906\n",
      "Epoch 277/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 196.0466 - val_loss: 681.2033\n",
      "Epoch 278/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 215.3394 - val_loss: 711.2809\n",
      "Epoch 279/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 203.4672 - val_loss: 672.3169\n",
      "Epoch 280/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 179.1447 - val_loss: 660.6619\n",
      "Epoch 281/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 163.9051 - val_loss: 711.5514\n",
      "Epoch 282/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 170.9410 - val_loss: 654.2714\n",
      "Epoch 283/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 168.9069 - val_loss: 649.5087\n",
      "Epoch 284/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 158.4414 - val_loss: 701.2715\n",
      "Epoch 285/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 200.9033 - val_loss: 655.8997\n",
      "Epoch 286/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 154.7211 - val_loss: 667.3217\n",
      "Epoch 287/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 179.4501 - val_loss: 653.7487\n",
      "Epoch 288/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 161.4499 - val_loss: 646.0180\n",
      "Epoch 289/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 174.9319 - val_loss: 682.8381\n",
      "Epoch 290/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 193.0572 - val_loss: 691.4255\n",
      "Epoch 291/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 149.4182 - val_loss: 664.1402\n",
      "Epoch 292/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 181.9665 - val_loss: 641.0339\n",
      "Epoch 293/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 154.7423 - val_loss: 641.5372\n",
      "Epoch 294/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 170.9073 - val_loss: 638.2117\n",
      "Epoch 295/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 170.8016 - val_loss: 632.8710\n",
      "Epoch 296/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 168.1542 - val_loss: 622.4136\n",
      "Epoch 297/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 159.9034 - val_loss: 653.6049\n",
      "Epoch 298/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 187.0595 - val_loss: 620.7249\n",
      "Epoch 299/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 165.7693 - val_loss: 680.1082\n",
      "Epoch 300/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 180.4149 - val_loss: 695.1770\n",
      "Epoch 301/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 164.8232 - val_loss: 683.0198\n",
      "Epoch 302/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 186.1041 - val_loss: 658.6928\n",
      "Epoch 303/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 179.3177 - val_loss: 658.9175\n",
      "Epoch 304/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 167.5297 - val_loss: 657.1705\n",
      "Epoch 305/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 186.2150 - val_loss: 672.1276\n",
      "Epoch 306/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 164.3365 - val_loss: 661.0323\n",
      "Epoch 307/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 168.5852 - val_loss: 639.6566\n",
      "Epoch 308/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 179.2441 - val_loss: 657.8171\n",
      "Epoch 309/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 162.1352 - val_loss: 688.9948\n",
      "Epoch 310/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 155.4392 - val_loss: 681.6227\n",
      "Epoch 311/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 177.8956 - val_loss: 662.1125\n",
      "Epoch 312/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 168.6901 - val_loss: 638.1435\n",
      "Epoch 313/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 152.4355 - val_loss: 646.7757\n",
      "Epoch 314/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 171.9503 - val_loss: 630.0779\n",
      "Epoch 315/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 168.4564 - val_loss: 647.4995\n",
      "Epoch 316/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 156.6684 - val_loss: 675.1277\n",
      "Epoch 317/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 162.0480 - val_loss: 684.4794\n",
      "Epoch 318/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 155.3527 - val_loss: 721.5233\n",
      "Epoch 319/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 200.1848 - val_loss: 744.3530\n",
      "Epoch 320/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 184.4107 - val_loss: 646.5833\n",
      "Epoch 321/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 163.2046 - val_loss: 716.2075\n",
      "Epoch 322/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 181.5757 - val_loss: 718.2825\n",
      "Epoch 323/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 204.6168 - val_loss: 643.6351\n",
      "Epoch 324/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 179.1565 - val_loss: 754.1573\n",
      "Epoch 325/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 207.4142 - val_loss: 633.9361\n",
      "Epoch 326/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 158.7875 - val_loss: 662.6935\n",
      "Epoch 327/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 229.1656 - val_loss: 701.6520\n",
      "Epoch 328/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 205.7031 - val_loss: 631.4805\n",
      "Epoch 329/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 184.3610 - val_loss: 659.1976\n",
      "Epoch 330/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 152.9070 - val_loss: 652.6105\n",
      "Epoch 331/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 162.6401 - val_loss: 656.9876\n",
      "Epoch 332/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 165.9129 - val_loss: 665.3793\n",
      "Epoch 333/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 173.3455 - val_loss: 720.3661\n",
      "Epoch 334/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 195.8614 - val_loss: 774.8386\n",
      "Epoch 335/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 156.0282 - val_loss: 687.7012\n",
      "Epoch 336/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 160.3120 - val_loss: 690.5040\n",
      "Epoch 337/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 150.4835 - val_loss: 740.0633\n",
      "Epoch 338/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 197.1391 - val_loss: 746.6971\n",
      "Epoch 339/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 164.9974 - val_loss: 747.8752\n",
      "Epoch 340/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 172.9193 - val_loss: 712.1539\n",
      "Epoch 341/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 165.4079 - val_loss: 727.4424\n",
      "Epoch 342/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 165.3286 - val_loss: 723.0930\n",
      "Epoch 343/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 180.3519 - val_loss: 655.2059\n",
      "Epoch 344/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 161.7386 - val_loss: 618.8402\n",
      "Epoch 345/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 162.1344 - val_loss: 640.1834\n",
      "Epoch 346/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 151.0743 - val_loss: 629.0980\n",
      "Epoch 347/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 150.8492 - val_loss: 753.1857\n",
      "Epoch 348/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 151.6459 - val_loss: 744.8831\n",
      "Epoch 349/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 158.2323 - val_loss: 845.9627\n",
      "Epoch 350/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 252.7610 - val_loss: 651.1418\n",
      "Epoch 351/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 161.8369 - val_loss: 704.7263\n",
      "Epoch 352/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 155.4906 - val_loss: 672.6497\n",
      "Epoch 353/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 208.6295 - val_loss: 702.9348\n",
      "Epoch 354/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 156.3983 - val_loss: 745.5370\n",
      "Epoch 355/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 160.9826 - val_loss: 766.5982\n",
      "Epoch 356/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 146.3792 - val_loss: 754.9108\n",
      "Epoch 357/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 182.2540 - val_loss: 717.1843\n",
      "Epoch 358/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 152.7786 - val_loss: 793.1034\n",
      "Epoch 359/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 163.5039 - val_loss: 725.3985\n",
      "Epoch 360/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 147.5100 - val_loss: 733.6074\n",
      "Epoch 361/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 163.2413 - val_loss: 705.6421\n",
      "Epoch 362/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 155.7303 - val_loss: 654.6273\n",
      "Epoch 363/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 139.8815 - val_loss: 645.5276\n",
      "Epoch 364/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 169.6331 - val_loss: 735.5939\n",
      "Epoch 365/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 168.4877 - val_loss: 708.9682\n",
      "Epoch 366/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 144.4051 - val_loss: 628.0580\n",
      "Epoch 367/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 155.2970 - val_loss: 639.7676\n",
      "Epoch 368/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 156.3778 - val_loss: 645.5389\n",
      "Epoch 369/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 193.7654 - val_loss: 673.6343\n",
      "Epoch 370/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 162.4687 - val_loss: 712.0745\n",
      "Epoch 371/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 151.5545 - val_loss: 651.5714\n",
      "Epoch 372/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 144.5918 - val_loss: 651.4052\n",
      "Epoch 373/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 160.4762 - val_loss: 680.3635\n",
      "Epoch 374/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 180.3672 - val_loss: 676.7935\n",
      "Epoch 375/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 159.9154 - val_loss: 688.8591\n",
      "Epoch 376/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 171.6672 - val_loss: 685.9133\n",
      "Epoch 377/10000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 173.5065 - val_loss: 709.3859\n",
      "Epoch 378/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 168.3856 - val_loss: 665.1553\n",
      "Epoch 379/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 179.7940 - val_loss: 601.1523\n",
      "Epoch 380/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 152.8328 - val_loss: 611.6287\n",
      "Epoch 381/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 153.4701 - val_loss: 633.1492\n",
      "Epoch 382/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 154.3325 - val_loss: 643.8708\n",
      "Epoch 383/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 156.5518 - val_loss: 630.0657\n",
      "Epoch 384/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 147.9576 - val_loss: 655.9227\n",
      "Epoch 385/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 164.3910 - val_loss: 632.5188\n",
      "Epoch 386/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 151.1345 - val_loss: 638.3644\n",
      "Epoch 387/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 165.3465 - val_loss: 635.7878\n",
      "Epoch 388/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 136.2801 - val_loss: 649.5067\n",
      "Epoch 389/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 153.3580 - val_loss: 646.0396\n",
      "Epoch 390/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 153.2503 - val_loss: 669.1717\n",
      "Epoch 391/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 173.0515 - val_loss: 637.1436\n",
      "Epoch 392/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 140.7482 - val_loss: 638.3413\n",
      "Epoch 393/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 146.8154 - val_loss: 639.7324\n",
      "Epoch 394/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 142.5987 - val_loss: 634.6975\n",
      "Epoch 395/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 161.2638 - val_loss: 632.2659\n",
      "Epoch 396/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 142.4686 - val_loss: 661.9236\n",
      "Epoch 397/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 162.6251 - val_loss: 650.4164\n",
      "Epoch 398/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 152.6436 - val_loss: 612.6343\n",
      "Epoch 399/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 149.6050 - val_loss: 635.5477\n",
      "Epoch 400/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 163.1962 - val_loss: 622.6842\n",
      "Epoch 401/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 149.9096 - val_loss: 650.8293\n",
      "Epoch 402/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 181.2343 - val_loss: 629.7159\n",
      "Epoch 403/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 147.7366 - val_loss: 636.5692\n",
      "Epoch 404/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 157.2003 - val_loss: 639.5125\n",
      "Epoch 405/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 148.3198 - val_loss: 667.0278\n",
      "Epoch 406/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 160.9445 - val_loss: 630.5293\n",
      "Epoch 407/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 158.0629 - val_loss: 670.9307\n",
      "Epoch 408/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 207.5583 - val_loss: 751.2729\n",
      "Epoch 409/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 139.8667 - val_loss: 774.7164\n",
      "Epoch 410/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 138.5447 - val_loss: 710.8015\n",
      "Epoch 411/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 150.6380 - val_loss: 704.9832\n",
      "Epoch 412/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 167.0254 - val_loss: 701.1722\n",
      "Epoch 413/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 155.6278 - val_loss: 696.2003\n",
      "Epoch 414/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 147.1429 - val_loss: 698.8823\n",
      "Epoch 415/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 146.7727 - val_loss: 714.4890\n",
      "Epoch 416/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 146.8317 - val_loss: 707.5919\n",
      "Epoch 417/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 159.7727 - val_loss: 737.8904\n",
      "Epoch 418/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 165.1422 - val_loss: 725.8735\n",
      "Epoch 419/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 188.4432 - val_loss: 781.4924\n",
      "Epoch 420/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 144.5909 - val_loss: 822.4490\n",
      "Epoch 421/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 155.5091 - val_loss: 755.9014\n",
      "Epoch 422/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 164.7858 - val_loss: 731.4173\n",
      "Epoch 423/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 143.2455 - val_loss: 786.0959\n",
      "Epoch 424/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 143.1334 - val_loss: 761.5203\n",
      "Epoch 425/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 130.6565 - val_loss: 750.0248\n",
      "Epoch 426/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 163.6317 - val_loss: 633.8475\n",
      "Epoch 427/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 153.5867 - val_loss: 609.1607\n",
      "Epoch 428/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 149.5053 - val_loss: 624.3580\n",
      "Epoch 429/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 142.4751 - val_loss: 653.0110\n",
      "Epoch 430/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 146.5203 - val_loss: 649.8275\n",
      "Epoch 431/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 152.5157 - val_loss: 724.6660\n",
      "Epoch 432/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 153.4294 - val_loss: 664.2135\n",
      "Epoch 433/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 165.2674 - val_loss: 694.5720\n",
      "Epoch 434/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 136.0027 - val_loss: 678.5328\n",
      "Epoch 435/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 126.5772 - val_loss: 702.6113\n",
      "Epoch 436/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 136.1896 - val_loss: 701.5256\n",
      "Epoch 437/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 136.6643 - val_loss: 748.1195\n",
      "Epoch 438/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 210.1442 - val_loss: 878.0314\n",
      "Epoch 439/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 218.8338 - val_loss: 675.3526\n",
      "Epoch 440/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 157.5215 - val_loss: 683.5564\n",
      "Epoch 441/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 137.9504 - val_loss: 696.0712\n",
      "Epoch 442/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 157.9827 - val_loss: 612.1030\n",
      "Epoch 443/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 208.2169 - val_loss: 673.3533\n",
      "Epoch 444/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 173.7376 - val_loss: 721.2963\n",
      "Epoch 445/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 161.6753 - val_loss: 704.0896\n",
      "Epoch 446/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 148.7955 - val_loss: 732.7505\n",
      "Epoch 447/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 163.8350 - val_loss: 752.5068\n",
      "Epoch 448/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 151.7597 - val_loss: 715.3961\n",
      "Epoch 449/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 143.2036 - val_loss: 765.3889\n",
      "Epoch 450/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 155.5182 - val_loss: 762.0760\n",
      "Epoch 451/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 155.5837 - val_loss: 754.2641\n",
      "Epoch 452/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 148.1614 - val_loss: 764.2128\n",
      "Epoch 453/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 148.9636 - val_loss: 749.2146\n",
      "Epoch 454/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 141.7593 - val_loss: 735.9709\n",
      "Epoch 455/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 144.3240 - val_loss: 755.7799\n",
      "Epoch 456/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 142.7108 - val_loss: 753.6279\n",
      "Epoch 457/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 126.6872 - val_loss: 736.6401\n",
      "Epoch 458/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 144.1259 - val_loss: 790.2791\n",
      "Epoch 459/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 146.5290 - val_loss: 773.7626\n",
      "Epoch 460/10000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 141.9791 - val_loss: 752.6528\n",
      "Epoch 461/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 150.7344 - val_loss: 758.1318\n",
      "Epoch 462/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 168.6250 - val_loss: 723.2004\n",
      "Epoch 463/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 136.8923 - val_loss: 662.2503\n",
      "Epoch 464/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 152.7168 - val_loss: 701.6566\n",
      "Epoch 465/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 136.3048 - val_loss: 678.9641\n",
      "Epoch 466/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 140.9545 - val_loss: 714.3945\n",
      "Epoch 467/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 127.5643 - val_loss: 777.0963\n",
      "Epoch 468/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 152.8419 - val_loss: 634.9381\n",
      "Epoch 469/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 143.1823 - val_loss: 686.6435\n",
      "Epoch 470/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 148.9102 - val_loss: 672.7642\n",
      "Epoch 471/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 142.2864 - val_loss: 664.9274\n",
      "Epoch 472/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 158.7086 - val_loss: 646.0969\n",
      "Epoch 473/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 156.5972 - val_loss: 632.2234\n",
      "Epoch 474/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 130.3577 - val_loss: 687.2136\n",
      "Epoch 475/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 155.8608 - val_loss: 713.9521\n",
      "Epoch 476/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 157.2811 - val_loss: 714.6496\n",
      "Epoch 477/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 138.6557 - val_loss: 770.9282\n",
      "Epoch 478/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 152.0300 - val_loss: 761.7817\n",
      "Epoch 479/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 157.5286 - val_loss: 736.3165\n",
      "Epoch 480/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 141.2973 - val_loss: 696.5053\n",
      "Epoch 481/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 138.5400 - val_loss: 641.8548\n",
      "Epoch 482/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 149.2328 - val_loss: 660.6902\n",
      "Epoch 483/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 149.0439 - val_loss: 658.7434\n",
      "Epoch 484/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 153.5403 - val_loss: 738.8264\n",
      "Epoch 485/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 168.8930 - val_loss: 743.7690\n",
      "Epoch 486/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 143.9604 - val_loss: 778.2275\n",
      "Epoch 487/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 143.2223 - val_loss: 785.8788\n",
      "Epoch 488/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 145.3165 - val_loss: 765.7424\n",
      "Epoch 489/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 141.7491 - val_loss: 776.1826\n",
      "Epoch 490/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 145.0909 - val_loss: 768.0850\n",
      "Epoch 491/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 144.8443 - val_loss: 765.6577\n",
      "Epoch 492/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 142.2561 - val_loss: 746.4966\n",
      "Epoch 493/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 162.4719 - val_loss: 767.0632\n",
      "Epoch 494/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 143.3769 - val_loss: 739.2988\n",
      "Epoch 495/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 142.2066 - val_loss: 744.6696\n",
      "Epoch 496/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 134.6465 - val_loss: 811.5886\n",
      "Epoch 497/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 154.3880 - val_loss: 641.0764\n",
      "Epoch 498/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 142.6358 - val_loss: 644.9413\n",
      "Epoch 499/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 143.3870 - val_loss: 686.4645\n",
      "Epoch 500/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 119.2409 - val_loss: 712.7947\n",
      "Epoch 501/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 140.2643 - val_loss: 713.0008\n",
      "Epoch 502/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 178.5719 - val_loss: 821.0155\n",
      "Epoch 503/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 132.5385 - val_loss: 766.9250\n",
      "Epoch 504/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 142.0934 - val_loss: 771.8625\n",
      "Epoch 505/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 142.0832 - val_loss: 733.9111\n",
      "Epoch 506/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 133.6043 - val_loss: 747.1757\n",
      "Epoch 507/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 148.9095 - val_loss: 667.2001\n",
      "Epoch 508/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 141.2074 - val_loss: 696.8615\n",
      "Epoch 509/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 135.1743 - val_loss: 733.0655\n",
      "Epoch 510/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 154.9612 - val_loss: 820.9401\n",
      "Epoch 511/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 160.8876 - val_loss: 626.0643\n",
      "Epoch 512/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 143.7120 - val_loss: 603.3094\n",
      "Epoch 513/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 129.4144 - val_loss: 608.6587\n",
      "Epoch 514/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 148.5768 - val_loss: 646.7014\n",
      "Epoch 515/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 166.8931 - val_loss: 628.7047\n",
      "Epoch 516/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 144.5389 - val_loss: 673.9283\n",
      "Epoch 517/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 158.0357 - val_loss: 639.5493\n",
      "Epoch 518/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 119.6717 - val_loss: 641.4333\n",
      "Epoch 519/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 136.8366 - val_loss: 642.4931\n",
      "Epoch 520/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 124.8809 - val_loss: 654.1777\n",
      "Epoch 521/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 130.1215 - val_loss: 649.4296\n",
      "Epoch 522/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 137.4978 - val_loss: 648.9514\n",
      "Epoch 523/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 144.3601 - val_loss: 709.3489\n",
      "Epoch 524/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 117.5479 - val_loss: 697.0955\n",
      "Epoch 525/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 183.4189 - val_loss: 708.3577\n",
      "Epoch 526/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 152.9588 - val_loss: 660.2875\n",
      "Epoch 527/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 142.3546 - val_loss: 641.9866\n",
      "Epoch 528/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 138.5663 - val_loss: 660.2121\n",
      "Epoch 529/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 163.1560 - val_loss: 873.5118\n",
      "Epoch 530/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 171.5206 - val_loss: 689.1775\n",
      "Epoch 531/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 175.7202 - val_loss: 3119.2161\n",
      "Epoch 532/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 9578.3955 - val_loss: 578.0553\n",
      "Epoch 533/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 689.1205 - val_loss: 1281.6411\n",
      "Epoch 534/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1094.2430 - val_loss: 2235.9065\n",
      "Epoch 535/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 871.8223 - val_loss: 791.7471\n",
      "Epoch 536/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 384.8144 - val_loss: 1052.3763\n",
      "Epoch 537/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 501.4041 - val_loss: 696.3182\n",
      "Epoch 538/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 250.8031 - val_loss: 655.0244\n",
      "Epoch 539/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 262.0126 - val_loss: 637.1086\n",
      "Epoch 540/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 366.1104 - val_loss: 629.5795\n",
      "Epoch 541/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 241.7307 - val_loss: 647.1475\n",
      "Epoch 542/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 245.7116 - val_loss: 615.9833\n",
      "Epoch 543/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 186.9712 - val_loss: 668.1947\n",
      "Epoch 544/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 232.3172 - val_loss: 659.7741\n",
      "Epoch 545/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 188.2534 - val_loss: 642.2750\n",
      "Epoch 546/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 181.3242 - val_loss: 672.6530\n",
      "Epoch 547/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 229.4565 - val_loss: 691.8179\n",
      "Epoch 548/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 202.3249 - val_loss: 701.2198\n",
      "Epoch 549/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 220.5416 - val_loss: 686.5415\n",
      "Epoch 550/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 176.4087 - val_loss: 719.6987\n",
      "Epoch 551/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 184.0515 - val_loss: 805.5130\n",
      "Epoch 552/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 197.9236 - val_loss: 675.3937\n",
      "Epoch 553/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 205.1568 - val_loss: 650.3921\n",
      "Epoch 554/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 191.4853 - val_loss: 682.5624\n",
      "Epoch 555/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 191.3005 - val_loss: 640.3947\n",
      "Epoch 556/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 219.1596 - val_loss: 633.3469\n",
      "Epoch 557/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 201.7570 - val_loss: 682.9847\n",
      "Epoch 558/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 171.6308 - val_loss: 611.2614\n",
      "Epoch 559/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 167.9221 - val_loss: 639.6823\n",
      "Epoch 560/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 167.7927 - val_loss: 648.0793\n",
      "Epoch 561/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 169.5252 - val_loss: 673.6618\n",
      "Epoch 562/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 225.3322 - val_loss: 649.4133\n",
      "Epoch 563/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 182.1152 - val_loss: 721.3958\n",
      "Epoch 564/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 189.0593 - val_loss: 556.5764\n",
      "Epoch 565/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 211.4704 - val_loss: 857.4301\n",
      "Epoch 566/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 214.1963 - val_loss: 562.4880\n",
      "Epoch 567/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 181.3163 - val_loss: 559.8237\n",
      "Epoch 568/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 187.7755 - val_loss: 563.5757\n",
      "Epoch 569/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 167.5222 - val_loss: 564.3928\n",
      "Epoch 570/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 162.4857 - val_loss: 587.8025\n",
      "Epoch 571/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 196.2260 - val_loss: 645.8203\n",
      "Epoch 572/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 234.4879 - val_loss: 699.3857\n",
      "Epoch 573/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 228.9127 - val_loss: 656.3051\n",
      "Epoch 574/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 180.2713 - val_loss: 626.7997\n",
      "Epoch 575/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 165.1717 - val_loss: 611.9755\n",
      "Epoch 576/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 156.0870 - val_loss: 607.9747\n",
      "Epoch 577/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 199.4131 - val_loss: 652.3857\n",
      "Epoch 578/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 190.4410 - val_loss: 621.4093\n",
      "Epoch 579/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 185.0416 - val_loss: 638.5303\n",
      "Epoch 580/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 229.1181 - val_loss: 671.7090\n",
      "Epoch 581/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 197.5861 - val_loss: 672.3387\n",
      "Epoch 582/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 162.9180 - val_loss: 653.7935\n",
      "Epoch 583/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 140.7892 - val_loss: 642.7090\n",
      "Epoch 584/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 170.4429 - val_loss: 396.7104\n",
      "Epoch 585/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 187.1324 - val_loss: 669.5731\n",
      "Epoch 586/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 154.2884 - val_loss: 696.3518\n",
      "Epoch 587/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 161.6102 - val_loss: 670.1547\n",
      "Epoch 588/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 193.0023 - val_loss: 645.4416\n",
      "Epoch 589/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 161.6647 - val_loss: 640.0091\n",
      "Epoch 590/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 163.1245 - val_loss: 596.2974\n",
      "Epoch 591/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 162.3117 - val_loss: 751.2128\n",
      "Epoch 592/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 192.5815 - val_loss: 693.6678\n",
      "Epoch 593/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 164.7667 - val_loss: 720.2280\n",
      "Epoch 594/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 143.5481 - val_loss: 715.2829\n",
      "Epoch 595/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 162.7006 - val_loss: 667.1115\n",
      "Epoch 596/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 128.8613 - val_loss: 679.6671\n",
      "Epoch 597/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 138.1554 - val_loss: 652.8162\n",
      "Epoch 598/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 157.5506 - val_loss: 679.9116\n",
      "Epoch 599/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 162.5634 - val_loss: 690.0604\n",
      "Epoch 600/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 144.1551 - val_loss: 671.0302\n",
      "Epoch 601/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 132.9315 - val_loss: 688.3848\n",
      "Epoch 602/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 170.0824 - val_loss: 629.3743\n",
      "Epoch 603/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 155.6971 - val_loss: 650.7969\n",
      "Epoch 604/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 164.3733 - val_loss: 705.7267\n",
      "Epoch 605/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 150.1443 - val_loss: 619.2417\n",
      "Epoch 606/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 145.4442 - val_loss: 686.3422\n",
      "Epoch 607/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 168.7185 - val_loss: 716.5846\n",
      "Epoch 608/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 166.2918 - val_loss: 706.4644\n",
      "Epoch 609/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 154.0062 - val_loss: 684.4290\n",
      "Epoch 610/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 144.4813 - val_loss: 670.5156\n",
      "Epoch 611/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 147.0578 - val_loss: 624.4121\n",
      "Epoch 612/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 186.9881 - val_loss: 659.8547\n",
      "Epoch 613/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 143.7418 - val_loss: 727.2201\n",
      "Epoch 614/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 134.5226 - val_loss: 687.1742\n",
      "Epoch 615/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 135.5967 - val_loss: 711.6430\n",
      "Epoch 616/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 145.3724 - val_loss: 692.2003\n",
      "Epoch 617/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 197.5001 - val_loss: 671.5326\n",
      "Epoch 618/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 185.8410 - val_loss: 669.7650\n",
      "Epoch 619/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 163.5319 - val_loss: 645.0115\n",
      "Epoch 620/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 138.5573 - val_loss: 691.8702\n",
      "Epoch 621/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 150.4929 - val_loss: 675.2521\n",
      "Epoch 622/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 154.2507 - val_loss: 674.9733\n",
      "Epoch 623/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 141.5176 - val_loss: 704.1567\n",
      "Epoch 624/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 184.3000 - val_loss: 654.9041\n",
      "Epoch 625/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 182.1921 - val_loss: 721.4138\n",
      "Epoch 626/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 185.2972 - val_loss: 703.3167\n",
      "Epoch 627/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 137.6923 - val_loss: 668.2960\n",
      "Epoch 628/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 150.4060 - val_loss: 660.2871\n",
      "Epoch 629/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 186.8607 - val_loss: 674.4529\n",
      "Epoch 630/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 202.0603 - val_loss: 677.9673\n",
      "Epoch 631/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 161.8996 - val_loss: 665.4318\n",
      "Epoch 632/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 169.5218 - val_loss: 678.3642\n",
      "Epoch 633/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 173.2416 - val_loss: 689.9440\n",
      "Epoch 634/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 141.2549 - val_loss: 726.7839\n",
      "Epoch 635/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 162.2726 - val_loss: 695.6448\n",
      "Epoch 636/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 136.4775 - val_loss: 737.2304\n",
      "Epoch 637/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 172.0234 - val_loss: 775.3892\n",
      "Epoch 638/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 131.7975 - val_loss: 710.2639\n",
      "Epoch 639/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 135.5582 - val_loss: 735.2226\n",
      "Epoch 640/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 152.8552 - val_loss: 625.9506\n",
      "Epoch 641/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 163.3720 - val_loss: 638.1144\n",
      "Epoch 642/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 169.9073 - val_loss: 659.3553\n",
      "Epoch 643/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 187.6986 - val_loss: 693.7912\n",
      "Epoch 644/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 177.0925 - val_loss: 684.9618\n",
      "Epoch 645/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 151.9392 - val_loss: 693.4121\n",
      "Epoch 646/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 149.3977 - val_loss: 696.3665\n",
      "Epoch 647/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 152.2286 - val_loss: 706.3492\n",
      "Epoch 648/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 150.6010 - val_loss: 761.1873\n",
      "Epoch 649/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 151.4305 - val_loss: 661.6923\n",
      "Epoch 650/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 131.9331 - val_loss: 662.3529\n",
      "Epoch 651/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 147.4182 - val_loss: 677.2271\n",
      "Epoch 652/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 147.9817 - val_loss: 734.0975\n",
      "Epoch 653/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 165.9279 - val_loss: 655.3930\n",
      "Epoch 654/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 144.5699 - val_loss: 758.1500\n",
      "Epoch 655/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 149.1940 - val_loss: 642.3636\n",
      "Epoch 656/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 152.4122 - val_loss: 650.6001\n",
      "Epoch 657/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 172.9306 - val_loss: 655.2258\n",
      "Epoch 658/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 165.6270 - val_loss: 635.6729\n",
      "Epoch 659/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 142.2516 - val_loss: 645.7880\n",
      "Epoch 660/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 148.1927 - val_loss: 639.3894\n",
      "Epoch 661/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 172.0117 - val_loss: 614.6047\n",
      "Epoch 662/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 127.2109 - val_loss: 622.7642\n",
      "Epoch 663/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 130.4579 - val_loss: 649.2678\n",
      "Epoch 664/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 141.2315 - val_loss: 659.8305\n",
      "Epoch 665/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 162.3244 - val_loss: 628.5628\n",
      "Epoch 666/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 135.0781 - val_loss: 613.0407\n",
      "Epoch 667/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 138.7095 - val_loss: 627.3218\n",
      "Epoch 668/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 133.4195 - val_loss: 657.1533\n",
      "Epoch 669/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 139.7839 - val_loss: 636.8279\n",
      "Epoch 670/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 118.6578 - val_loss: 628.0692\n",
      "Epoch 671/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 154.0644 - val_loss: 629.8542\n",
      "Epoch 672/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 148.4419 - val_loss: 664.7413\n",
      "Epoch 673/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 164.6516 - val_loss: 650.4792\n",
      "Epoch 674/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 161.6336 - val_loss: 626.6346\n",
      "Epoch 675/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 162.4821 - val_loss: 647.0139\n",
      "Epoch 676/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 144.9100 - val_loss: 620.8706\n",
      "Epoch 677/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 141.6343 - val_loss: 627.1959\n",
      "Epoch 678/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 158.6864 - val_loss: 621.8164\n",
      "Epoch 679/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 125.2362 - val_loss: 630.1089\n",
      "Epoch 680/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 155.8485 - val_loss: 638.1378\n",
      "Epoch 681/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 132.7918 - val_loss: 644.7872\n",
      "Epoch 682/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 143.5417 - val_loss: 614.8309\n",
      "Epoch 683/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 141.8201 - val_loss: 614.5468\n",
      "Epoch 684/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 136.9278 - val_loss: 634.3523\n",
      "Epoch 685/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 135.0605 - val_loss: 625.9365\n",
      "Epoch 686/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 130.8485 - val_loss: 638.0160\n",
      "Epoch 687/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 142.3920 - val_loss: 629.4911\n",
      "Epoch 688/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 136.9246 - val_loss: 624.4773\n",
      "Epoch 689/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 111.9463 - val_loss: 634.6999\n",
      "Epoch 690/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 146.9854 - val_loss: 642.7834\n",
      "Epoch 691/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 137.7327 - val_loss: 647.4559\n",
      "Epoch 692/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 164.3340 - val_loss: 632.5640\n",
      "Epoch 693/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 144.7600 - val_loss: 665.3925\n",
      "Epoch 694/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 178.5584 - val_loss: 643.6803\n",
      "Epoch 695/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 141.1020 - val_loss: 643.8982\n",
      "Epoch 696/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 141.8442 - val_loss: 652.9329\n",
      "Epoch 697/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 153.0059 - val_loss: 648.8600\n",
      "Epoch 698/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 128.4144 - val_loss: 669.3072\n",
      "Epoch 699/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 140.9007 - val_loss: 641.2646\n",
      "Epoch 700/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 145.4916 - val_loss: 662.2446\n",
      "Epoch 701/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 144.0194 - val_loss: 660.0640\n",
      "Epoch 702/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 144.3890 - val_loss: 650.9328\n",
      "Epoch 703/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 144.1642 - val_loss: 651.4097\n",
      "Epoch 704/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 126.2038 - val_loss: 638.8566\n",
      "Epoch 705/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 141.0289 - val_loss: 657.6703\n",
      "Epoch 706/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 138.2188 - val_loss: 657.3304\n",
      "Epoch 707/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 132.0399 - val_loss: 637.5023\n",
      "Epoch 708/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 123.0981 - val_loss: 633.0089\n",
      "Epoch 709/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 143.2138 - val_loss: 604.6609\n",
      "Epoch 710/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 148.3430 - val_loss: 630.4631\n",
      "Epoch 711/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 135.3048 - val_loss: 653.8640\n",
      "Epoch 712/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 133.2718 - val_loss: 662.5344\n",
      "Epoch 713/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 153.7601 - val_loss: 605.1490\n",
      "Epoch 714/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 133.5822 - val_loss: 643.9396\n",
      "Epoch 715/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 124.7884 - val_loss: 627.0867\n",
      "Epoch 716/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 123.9786 - val_loss: 625.9186\n",
      "Epoch 717/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 134.5591 - val_loss: 656.6052\n",
      "Epoch 718/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 157.0770 - val_loss: 639.6420\n",
      "Epoch 719/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 132.1476 - val_loss: 667.4451\n",
      "Epoch 720/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 132.8084 - val_loss: 645.8915\n",
      "Epoch 721/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 149.6260 - val_loss: 627.0878\n",
      "Epoch 722/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 126.6577 - val_loss: 631.8905\n",
      "Epoch 723/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 135.5944 - val_loss: 641.4678\n",
      "Epoch 724/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 136.1770 - val_loss: 616.7463\n",
      "Epoch 725/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 129.6801 - val_loss: 626.2488\n",
      "Epoch 726/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 120.8575 - val_loss: 677.1064\n",
      "Epoch 727/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 154.8230 - val_loss: 646.2410\n",
      "Epoch 728/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 136.5450 - val_loss: 642.9158\n",
      "Epoch 729/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 128.3993 - val_loss: 659.2421\n",
      "Epoch 730/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 113.4014 - val_loss: 656.6414\n",
      "Epoch 731/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 120.5528 - val_loss: 657.9476\n",
      "Epoch 732/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 121.1741 - val_loss: 676.2520\n",
      "Epoch 733/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 136.4914 - val_loss: 624.1981\n",
      "Epoch 734/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 118.1089 - val_loss: 651.0890\n",
      "Epoch 735/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 144.8275 - val_loss: 650.6541\n",
      "Epoch 736/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 111.4335 - val_loss: 647.4233\n",
      "Epoch 737/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 122.5220 - val_loss: 689.2091\n",
      "Epoch 738/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 123.8754 - val_loss: 556.7921\n",
      "Epoch 739/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 156.4576 - val_loss: 582.7889\n",
      "Epoch 740/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 143.0636 - val_loss: 721.7967\n",
      "Epoch 741/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 159.8155 - val_loss: 621.1440\n",
      "Epoch 742/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 118.5074 - val_loss: 612.7400\n",
      "Epoch 743/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 151.3078 - val_loss: 699.9465\n",
      "Epoch 744/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 120.5211 - val_loss: 717.6104\n",
      "Epoch 745/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 126.9592 - val_loss: 689.9244\n",
      "Epoch 746/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 133.0517 - val_loss: 674.6971\n",
      "Epoch 747/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 154.5223 - val_loss: 681.4964\n",
      "Epoch 748/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 148.9420 - val_loss: 669.2654\n",
      "Epoch 749/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 142.4970 - val_loss: 661.1074\n",
      "Epoch 750/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 142.3626 - val_loss: 698.5983\n",
      "Epoch 751/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 107.7086 - val_loss: 677.2362\n",
      "Epoch 752/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 117.2493 - val_loss: 687.4824\n",
      "Epoch 753/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 136.8648 - val_loss: 636.6631\n",
      "Epoch 754/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 113.9802 - val_loss: 620.2159\n",
      "Epoch 755/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 113.7355 - val_loss: 684.2627\n",
      "Epoch 756/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 126.0089 - val_loss: 665.7194\n",
      "Epoch 757/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 115.1276 - val_loss: 666.7981\n",
      "Epoch 758/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 137.4810 - val_loss: 649.8049\n",
      "Epoch 759/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 137.6405 - val_loss: 648.4213\n",
      "Epoch 760/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 130.9134 - val_loss: 686.0187\n",
      "Epoch 761/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 145.5874 - val_loss: 678.2108\n",
      "Epoch 762/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 133.2510 - val_loss: 663.5927\n",
      "Epoch 763/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 136.3443 - val_loss: 649.4031\n",
      "Epoch 764/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 117.7331 - val_loss: 668.2561\n",
      "Epoch 765/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 141.9661 - val_loss: 664.8915\n",
      "Epoch 766/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 136.7036 - val_loss: 667.2248\n",
      "Epoch 767/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 134.9744 - val_loss: 663.8458\n",
      "Epoch 768/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 133.3996 - val_loss: 656.8349\n",
      "Epoch 769/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 125.6705 - val_loss: 671.8974\n",
      "Epoch 770/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 143.0205 - val_loss: 664.7441\n",
      "Epoch 771/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 124.9100 - val_loss: 659.5002\n",
      "Epoch 772/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 110.5276 - val_loss: 690.3003\n",
      "Epoch 773/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 108.9885 - val_loss: 667.9261\n",
      "Epoch 774/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 163.6107 - val_loss: 654.2170\n",
      "Epoch 775/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 155.2506 - val_loss: 651.3510\n",
      "Epoch 776/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 122.1701 - val_loss: 651.5846\n",
      "Epoch 777/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 146.4843 - val_loss: 689.1733\n",
      "Epoch 778/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 116.5097 - val_loss: 664.5082\n",
      "Epoch 779/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 114.6571 - val_loss: 662.8682\n",
      "Epoch 780/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 118.0554 - val_loss: 633.5166\n",
      "Epoch 781/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 121.4172 - val_loss: 619.8112\n",
      "Epoch 782/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 131.7162 - val_loss: 643.1036\n",
      "Epoch 783/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 117.2925 - val_loss: 621.4640\n",
      "Epoch 784/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 122.5686 - val_loss: 627.9708\n",
      "Epoch 785/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 122.0464 - val_loss: 626.3443\n",
      "Epoch 786/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 123.7443 - val_loss: 655.4788\n",
      "Epoch 787/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 127.8237 - val_loss: 659.0422\n",
      "Epoch 788/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 102.0398 - val_loss: 666.6765\n",
      "Epoch 789/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 96.0031 - val_loss: 661.9924\n",
      "Epoch 790/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 122.4795 - val_loss: 655.7178\n",
      "Epoch 791/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 143.1411 - val_loss: 659.1675\n",
      "Epoch 792/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 124.6623 - val_loss: 672.9232\n",
      "Epoch 793/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 139.5709 - val_loss: 673.7820\n",
      "Epoch 794/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 123.8703 - val_loss: 687.8288\n",
      "Epoch 795/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 115.5282 - val_loss: 655.2831\n",
      "Epoch 796/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 111.8456 - val_loss: 655.5868\n",
      "Epoch 797/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 109.2354 - val_loss: 679.8199\n",
      "Epoch 798/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 117.2194 - val_loss: 681.3284\n",
      "Epoch 799/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 115.8732 - val_loss: 653.1409\n",
      "Epoch 800/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 124.8841 - val_loss: 620.4138\n",
      "Epoch 801/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 117.9213 - val_loss: 676.5059\n",
      "Epoch 802/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 117.5210 - val_loss: 689.1838\n",
      "Epoch 803/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 102.4073 - val_loss: 671.8058\n",
      "Epoch 804/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 93.8138 - val_loss: 686.4813\n",
      "Epoch 805/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 111.9854 - val_loss: 677.4113\n",
      "Epoch 806/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 129.4703 - val_loss: 661.0457\n",
      "Epoch 807/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 121.1921 - val_loss: 690.8988\n",
      "Epoch 808/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 112.3460 - val_loss: 683.0096\n",
      "Epoch 809/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 125.3156 - val_loss: 688.0721\n",
      "Epoch 810/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 126.4377 - val_loss: 664.8693\n",
      "Epoch 811/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 117.2610 - val_loss: 681.3146\n",
      "Epoch 812/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 123.7862 - val_loss: 670.5727\n",
      "Epoch 813/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 125.9309 - val_loss: 678.4690\n",
      "Epoch 814/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 110.8203 - val_loss: 663.7048\n",
      "Epoch 815/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 124.1343 - val_loss: 709.7536\n",
      "Epoch 816/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 116.3075 - val_loss: 646.0393\n",
      "Epoch 817/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 106.7179 - val_loss: 681.9470\n",
      "Epoch 818/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 128.3387 - val_loss: 676.2874\n",
      "Epoch 819/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 112.6787 - val_loss: 654.4930\n",
      "Epoch 820/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 114.6798 - val_loss: 678.9031\n",
      "Epoch 821/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 117.7280 - val_loss: 717.4669\n",
      "Epoch 822/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 113.4328 - val_loss: 698.4169\n",
      "Epoch 823/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 120.4090 - val_loss: 677.2150\n",
      "Epoch 824/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 129.0109 - val_loss: 634.2943\n",
      "Epoch 825/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 111.4473 - val_loss: 631.7375\n",
      "Epoch 826/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 120.5364 - val_loss: 655.5192\n",
      "Epoch 827/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 133.8713 - val_loss: 627.3314\n",
      "Epoch 828/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 141.8670 - val_loss: 661.9550\n",
      "Epoch 829/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 105.9200 - val_loss: 670.5923\n",
      "Epoch 830/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 121.9826 - val_loss: 693.7849\n",
      "Epoch 831/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 121.6041 - val_loss: 731.2717\n",
      "Epoch 832/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 127.8282 - val_loss: 822.5569\n",
      "Epoch 833/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 115.5922 - val_loss: 675.7899\n",
      "Epoch 834/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 137.6691 - val_loss: 734.3581\n",
      "Epoch 835/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 143.3531 - val_loss: 683.9481\n",
      "Epoch 836/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 106.4564 - val_loss: 711.4592\n",
      "Epoch 837/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 135.2285 - val_loss: 702.7512\n",
      "Epoch 838/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 138.8193 - val_loss: 706.4165\n",
      "Epoch 839/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 106.5490 - val_loss: 666.5577\n",
      "Epoch 840/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 114.1217 - val_loss: 660.6214\n",
      "Epoch 841/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 113.2930 - val_loss: 669.5284\n",
      "Epoch 842/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 124.5217 - val_loss: 640.2258\n",
      "Epoch 843/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 131.6220 - val_loss: 648.5056\n",
      "Epoch 844/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 124.0690 - val_loss: 653.7007\n",
      "Epoch 845/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 107.2596 - val_loss: 693.6406\n",
      "Epoch 846/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 91.7906 - val_loss: 689.4842\n",
      "Epoch 847/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 108.1155 - val_loss: 669.1440\n",
      "Epoch 848/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 116.3985 - val_loss: 627.8659\n",
      "Epoch 849/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 127.2877 - val_loss: 669.7250\n",
      "Epoch 850/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 120.0099 - val_loss: 700.2278\n",
      "Epoch 851/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 125.1767 - val_loss: 710.7169\n",
      "Epoch 852/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 100.3157 - val_loss: 696.2103\n",
      "Epoch 853/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 125.8556 - val_loss: 699.8322\n",
      "Epoch 854/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 116.9710 - val_loss: 685.5668\n",
      "Epoch 855/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 145.5002 - val_loss: 673.6547\n",
      "Epoch 856/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 124.0732 - val_loss: 711.1097\n",
      "Epoch 857/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 139.1721 - val_loss: 666.9536\n",
      "Epoch 858/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 118.5919 - val_loss: 680.4861\n",
      "Epoch 859/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 112.2622 - val_loss: 646.1044\n",
      "Epoch 860/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 108.3509 - val_loss: 621.8406\n",
      "Epoch 861/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 108.0032 - val_loss: 644.7117\n",
      "Epoch 862/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 117.7642 - val_loss: 656.8613\n",
      "Epoch 863/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 110.1668 - val_loss: 665.4268\n",
      "Epoch 864/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 110.8547 - val_loss: 672.9517\n",
      "Epoch 865/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 127.1068 - val_loss: 691.2503\n",
      "Epoch 866/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 107.7531 - val_loss: 690.9036\n",
      "Epoch 867/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 116.4182 - val_loss: 645.8370\n",
      "Epoch 868/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 119.1771 - val_loss: 656.0311\n",
      "Epoch 869/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 115.8366 - val_loss: 680.6252\n",
      "Epoch 870/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 114.4967 - val_loss: 666.8209\n",
      "Epoch 871/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 137.6476 - val_loss: 689.1762\n",
      "Epoch 872/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 102.6596 - val_loss: 806.6168\n",
      "Epoch 873/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 115.4256 - val_loss: 722.3929\n",
      "Epoch 874/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 115.5799 - val_loss: 875.3474\n",
      "Epoch 875/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 139.2772 - val_loss: 734.8117\n",
      "Epoch 876/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 108.9238 - val_loss: 688.9006\n",
      "Epoch 877/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 109.5166 - val_loss: 678.3601\n",
      "Epoch 878/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 97.1603 - val_loss: 701.4631\n",
      "Epoch 879/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 126.2490 - val_loss: 675.4256\n",
      "Epoch 880/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 110.0418 - val_loss: 706.4297\n",
      "Epoch 881/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 112.1533 - val_loss: 671.1454\n",
      "Epoch 882/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 90.8972 - val_loss: 699.9948\n",
      "Epoch 883/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 111.0025 - val_loss: 733.0193\n",
      "Epoch 884/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 90.3500 - val_loss: 685.3279\n",
      "Epoch 885/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 122.4509 - val_loss: 676.7316\n",
      "Epoch 886/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 112.4997 - val_loss: 674.2838\n",
      "Epoch 887/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 92.7636 - val_loss: 720.8173\n",
      "Epoch 888/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 102.9129 - val_loss: 673.2598\n",
      "Epoch 889/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 89.5813 - val_loss: 686.7539\n",
      "Epoch 890/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 98.9328 - val_loss: 662.0016\n",
      "Epoch 891/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 128.9745 - val_loss: 700.5207\n",
      "Epoch 892/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 117.2766 - val_loss: 664.4501\n",
      "Epoch 893/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 100.7354 - val_loss: 673.0732\n",
      "Epoch 894/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 141.7365 - val_loss: 674.2562\n",
      "Epoch 895/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 89.5939 - val_loss: 649.8773\n",
      "Epoch 896/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 111.5222 - val_loss: 658.8586\n",
      "Epoch 897/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 87.6666 - val_loss: 633.5908\n",
      "Epoch 898/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 108.5472 - val_loss: 681.6712\n",
      "Epoch 899/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 105.2324 - val_loss: 683.0805\n",
      "Epoch 900/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 92.3848 - val_loss: 734.0203\n",
      "Epoch 901/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 107.2871 - val_loss: 799.0308\n",
      "Epoch 902/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 133.1227 - val_loss: 724.0724\n",
      "Epoch 903/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 100.6914 - val_loss: 738.8430\n",
      "Epoch 904/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 103.6499 - val_loss: 717.4788\n",
      "Epoch 905/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 110.9918 - val_loss: 764.2959\n",
      "Epoch 906/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 91.0360 - val_loss: 752.4484\n",
      "Epoch 907/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 104.1724 - val_loss: 732.6640\n",
      "Epoch 908/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 125.4586 - val_loss: 700.7422\n",
      "Epoch 909/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 89.7272 - val_loss: 744.0829\n",
      "Epoch 910/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 106.4364 - val_loss: 752.8088\n",
      "Epoch 911/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 91.4829 - val_loss: 742.2000\n",
      "Epoch 912/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 111.2704 - val_loss: 732.1991\n",
      "Epoch 913/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 103.4683 - val_loss: 728.9592\n",
      "Epoch 914/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 88.7081 - val_loss: 780.4879\n",
      "Epoch 915/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 105.4194 - val_loss: 798.1115\n",
      "Epoch 916/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 102.5314 - val_loss: 748.2975\n",
      "Epoch 917/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 104.9729 - val_loss: 716.3923\n",
      "Epoch 918/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 113.6260 - val_loss: 825.8725\n",
      "Epoch 919/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 119.8381 - val_loss: 723.0165\n",
      "Epoch 920/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 115.7840 - val_loss: 726.0976\n",
      "Epoch 921/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 103.6226 - val_loss: 699.8763\n",
      "Epoch 922/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 101.2759 - val_loss: 726.5390\n",
      "Epoch 923/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 90.6997 - val_loss: 740.8401\n",
      "Epoch 924/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 87.2046 - val_loss: 620.1412\n",
      "Epoch 925/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 89.9114 - val_loss: 728.7313\n",
      "Epoch 926/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 100.9656 - val_loss: 692.5994\n",
      "Epoch 927/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 98.0062 - val_loss: 698.6209\n",
      "Epoch 928/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 87.9872 - val_loss: 680.9542\n",
      "Epoch 929/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 115.3391 - val_loss: 689.3710\n",
      "Epoch 930/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 104.6694 - val_loss: 687.0225\n",
      "Epoch 931/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 109.9089 - val_loss: 689.6311\n",
      "Epoch 932/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 110.4585 - val_loss: 698.7850\n",
      "Epoch 933/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 103.4998 - val_loss: 665.5487\n",
      "Epoch 934/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 109.0266 - val_loss: 716.8176\n",
      "Epoch 935/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 106.0873 - val_loss: 710.6672\n",
      "Epoch 936/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 99.6568 - val_loss: 653.4333\n",
      "Epoch 937/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 133.5010 - val_loss: 703.6375\n",
      "Epoch 938/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 120.3942 - val_loss: 668.5050\n",
      "Epoch 939/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 93.3519 - val_loss: 672.1790\n",
      "Epoch 940/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 133.1101 - val_loss: 691.6614\n",
      "Epoch 941/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 138.1287 - val_loss: 676.2448\n",
      "Epoch 942/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 118.8256 - val_loss: 658.4163\n",
      "Epoch 943/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 109.2425 - val_loss: 698.6790\n",
      "Epoch 944/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 99.9976 - val_loss: 735.9850\n",
      "Epoch 945/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 114.4501 - val_loss: 740.0880\n",
      "Epoch 946/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 94.4363 - val_loss: 726.8160\n",
      "Epoch 947/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 83.1541 - val_loss: 839.6655\n",
      "Epoch 948/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 139.9517 - val_loss: 766.3937\n",
      "Epoch 949/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 122.6793 - val_loss: 712.8139\n",
      "Epoch 950/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 108.7377 - val_loss: 699.9683\n",
      "Epoch 951/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 112.4160 - val_loss: 722.5939\n",
      "Epoch 952/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 100.1956 - val_loss: 685.9644\n",
      "Epoch 953/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 106.7308 - val_loss: 720.1161\n",
      "Epoch 954/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 111.7057 - val_loss: 744.2654\n",
      "Epoch 955/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 108.6155 - val_loss: 686.6370\n",
      "Epoch 956/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 92.1787 - val_loss: 748.9177\n",
      "Epoch 957/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 112.7380 - val_loss: 719.2686\n",
      "Epoch 958/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 108.2379 - val_loss: 735.0316\n",
      "Epoch 959/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 92.6552 - val_loss: 752.5356\n",
      "Epoch 960/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 107.2565 - val_loss: 723.1381\n",
      "Epoch 961/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 119.4042 - val_loss: 808.4777\n",
      "Epoch 962/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 92.9036 - val_loss: 746.4785\n",
      "Epoch 963/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 96.0828 - val_loss: 759.1285\n",
      "Epoch 964/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 100.4477 - val_loss: 735.8328\n",
      "Epoch 965/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 98.7533 - val_loss: 725.1239\n",
      "Epoch 966/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 85.5508 - val_loss: 771.6081\n",
      "Epoch 967/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 88.7552 - val_loss: 787.4543\n",
      "Epoch 968/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 124.2347 - val_loss: 706.8964\n",
      "Epoch 969/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 86.3680 - val_loss: 718.2935\n",
      "Epoch 970/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 106.4448 - val_loss: 708.6774\n",
      "Epoch 971/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 117.1022 - val_loss: 701.1962\n",
      "Epoch 972/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 99.1730 - val_loss: 722.1310\n",
      "Epoch 973/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 76.0967 - val_loss: 741.8710\n",
      "Epoch 974/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 99.6222 - val_loss: 724.2999\n",
      "Epoch 975/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 95.5908 - val_loss: 734.2142\n",
      "Epoch 976/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 116.5073 - val_loss: 758.5750\n",
      "Epoch 977/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 99.4048 - val_loss: 746.6258\n",
      "Epoch 978/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 112.8029 - val_loss: 752.9659\n",
      "Epoch 979/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 102.6660 - val_loss: 752.7413\n",
      "Epoch 980/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 105.1880 - val_loss: 734.0804\n",
      "Epoch 981/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 100.5738 - val_loss: 713.9761\n",
      "Epoch 982/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 105.0823 - val_loss: 729.2372\n",
      "Epoch 983/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 100.3721 - val_loss: 682.2845\n",
      "Epoch 984/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 99.6121 - val_loss: 718.7931\n",
      "Epoch 985/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 108.3929 - val_loss: 697.9145\n",
      "Epoch 986/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 97.0233 - val_loss: 702.5272\n",
      "Epoch 987/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 102.2978 - val_loss: 749.2655\n",
      "Epoch 988/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 116.7185 - val_loss: 765.0535\n",
      "Epoch 989/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 93.2343 - val_loss: 733.7605\n",
      "Epoch 990/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 101.9855 - val_loss: 754.6257\n",
      "Epoch 991/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 127.4441 - val_loss: 759.5935\n",
      "Epoch 992/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 78.0314 - val_loss: 746.8467\n",
      "Epoch 993/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 78.0546 - val_loss: 740.2656\n",
      "Epoch 994/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 101.5388 - val_loss: 720.8572\n",
      "Epoch 995/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 102.8910 - val_loss: 715.0732\n",
      "Epoch 996/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 102.4203 - val_loss: 711.4974\n",
      "Epoch 997/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 86.5369 - val_loss: 725.3039\n",
      "Epoch 998/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 82.5881 - val_loss: 760.7949\n",
      "Epoch 999/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 85.9405 - val_loss: 717.3097\n",
      "Epoch 1000/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 160.0696 - val_loss: 759.5006\n",
      "Epoch 1001/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 99.7849 - val_loss: 749.6660\n",
      "Epoch 1002/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 114.4917 - val_loss: 838.5618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1003/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 107.2689 - val_loss: 745.6584\n",
      "Epoch 1004/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 98.5698 - val_loss: 787.7244\n",
      "Epoch 1005/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 104.5764 - val_loss: 726.3801\n",
      "Epoch 1006/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 117.2129 - val_loss: 748.4990\n",
      "Epoch 1007/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 98.4683 - val_loss: 733.4036\n",
      "Epoch 1008/10000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 134.1000 - val_loss: 776.1608\n",
      "Epoch 1009/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 95.5503 - val_loss: 767.2470\n",
      "Epoch 1010/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 108.7551 - val_loss: 758.0757\n",
      "Epoch 1011/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 78.6812 - val_loss: 765.0439\n",
      "Epoch 1012/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 121.2232 - val_loss: 903.0401\n",
      "Epoch 1013/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 163.8498 - val_loss: 782.3733\n",
      "Epoch 1014/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 114.1423 - val_loss: 704.7610\n",
      "Epoch 1015/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 119.6294 - val_loss: 698.0820\n",
      "Epoch 1016/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 103.1416 - val_loss: 717.6486\n",
      "Epoch 1017/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 110.3398 - val_loss: 728.2834\n",
      "Epoch 1018/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 121.6634 - val_loss: 775.1545\n",
      "Epoch 1019/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 124.0108 - val_loss: 708.2660\n",
      "Epoch 1020/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 85.1578 - val_loss: 746.4070\n",
      "Epoch 1021/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 95.9807 - val_loss: 671.2073\n",
      "Epoch 1022/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 93.8880 - val_loss: 665.1464\n",
      "Epoch 1023/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 110.9861 - val_loss: 716.0916\n",
      "Epoch 1024/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 83.1294 - val_loss: 714.0064\n",
      "Epoch 1025/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 98.0204 - val_loss: 861.4998\n",
      "Epoch 1026/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 107.3921 - val_loss: 776.0006\n",
      "Epoch 1027/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 89.4401 - val_loss: 783.9890\n",
      "Epoch 1028/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 103.2202 - val_loss: 754.8560\n",
      "Epoch 1029/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 81.2669 - val_loss: 747.5120\n",
      "Epoch 1030/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 82.7966 - val_loss: 719.7510\n",
      "Epoch 1031/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 102.0776 - val_loss: 709.3039\n",
      "Epoch 1032/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 89.2883 - val_loss: 718.0584\n",
      "Epoch 1033/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 98.6137 - val_loss: 788.4446\n",
      "Epoch 1034/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 88.6890 - val_loss: 760.6912\n",
      "Epoch 1035/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 83.6778 - val_loss: 761.4315\n",
      "Epoch 1036/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 107.1867 - val_loss: 722.6921\n",
      "Epoch 1037/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 85.4951 - val_loss: 763.5674\n",
      "Epoch 1038/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 101.7512 - val_loss: 764.0822\n",
      "Epoch 1039/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 81.5350 - val_loss: 717.8586\n",
      "Epoch 1040/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 81.8668 - val_loss: 756.1558\n",
      "Epoch 1041/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 74.7082 - val_loss: 780.9398\n",
      "Epoch 1042/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 79.8228 - val_loss: 746.6702\n",
      "Epoch 1043/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 77.1444 - val_loss: 757.0380\n",
      "Epoch 1044/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 77.1691 - val_loss: 816.7503\n",
      "Epoch 1045/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 88.6561 - val_loss: 769.5584\n",
      "Epoch 1046/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 100.3483 - val_loss: 734.0166\n",
      "Epoch 1047/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 141.8195 - val_loss: 728.7790\n",
      "Epoch 1048/10000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 61.4663 - val_loss: 758.7943\n",
      "Epoch 1049/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 70.8840 - val_loss: 793.8665\n",
      "Epoch 1050/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 101.9525 - val_loss: 758.0078\n",
      "Epoch 1051/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 82.6975 - val_loss: 787.2019\n",
      "Epoch 1052/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 74.1088 - val_loss: 838.2068\n",
      "Epoch 1053/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 79.4475 - val_loss: 760.5520\n",
      "Epoch 1054/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 78.4906 - val_loss: 777.6429\n",
      "Epoch 1055/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 99.1680 - val_loss: 743.2397\n",
      "Epoch 1056/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 81.3542 - val_loss: 831.1494\n",
      "Epoch 1057/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 112.3025 - val_loss: 788.8016\n",
      "Epoch 1058/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 83.3745 - val_loss: 781.4218\n",
      "Epoch 1059/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 83.7971 - val_loss: 775.9259\n",
      "Epoch 1060/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 95.1298 - val_loss: 773.5427\n",
      "Epoch 1061/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 91.7065 - val_loss: 747.7922\n",
      "Epoch 1062/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 82.8011 - val_loss: 754.3810\n",
      "Epoch 1063/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 87.0788 - val_loss: 786.2430\n",
      "Epoch 1064/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 82.4073 - val_loss: 802.6436\n",
      "Epoch 1065/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 88.1517 - val_loss: 744.4543\n",
      "Epoch 1066/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 74.2308 - val_loss: 781.1409\n",
      "Epoch 1067/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 82.6239 - val_loss: 768.3455\n",
      "Epoch 1068/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 83.5888 - val_loss: 785.9662\n",
      "Epoch 1069/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 95.6381 - val_loss: 763.6873\n",
      "Epoch 1070/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 98.8103 - val_loss: 799.1057\n",
      "Epoch 1071/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 72.9633 - val_loss: 783.9117\n",
      "Epoch 1072/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 87.7811 - val_loss: 797.3086\n",
      "Epoch 1073/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 102.1806 - val_loss: 763.0031\n",
      "Epoch 1074/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 98.5076 - val_loss: 837.0991\n",
      "Epoch 1075/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 92.2951 - val_loss: 772.4043\n",
      "Epoch 1076/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 79.3602 - val_loss: 782.9443\n",
      "Epoch 1077/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 73.7913 - val_loss: 810.7096\n",
      "Epoch 1078/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 88.2750 - val_loss: 774.2162\n",
      "Epoch 1079/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 69.4946 - val_loss: 778.9211\n",
      "Epoch 1080/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 94.3851 - val_loss: 823.7172\n",
      "Epoch 1081/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 91.3278 - val_loss: 804.6003\n",
      "Epoch 1082/10000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 91.5503 - val_loss: 778.2991\n",
      "Epoch 1083/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 104.5805 - val_loss: 700.6866\n",
      "Epoch 1084/10000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 49.5555Restoring model weights from the end of the best epoch: 584.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 67.2025 - val_loss: 777.7902\n",
      "Epoch 1084: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = lstm_model(reshaped_train, \n",
    "                                    reshaped_target, \n",
    "                                    want_verbose=1, \n",
    "                                    seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0aad5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb69c9b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>269.392365</td>\n",
       "      <td>268.480896</td>\n",
       "      <td>266.625122</td>\n",
       "      <td>266.005981</td>\n",
       "      <td>263.088898</td>\n",
       "      <td>256.995148</td>\n",
       "      <td>244.792038</td>\n",
       "      <td>245.031662</td>\n",
       "      <td>253.702759</td>\n",
       "      <td>258.802612</td>\n",
       "      <td>263.399261</td>\n",
       "      <td>266.450043</td>\n",
       "      <td>267.620056</td>\n",
       "      <td>264.992401</td>\n",
       "      <td>262.941376</td>\n",
       "      <td>256.804626</td>\n",
       "      <td>250.55426</td>\n",
       "      <td>243.252045</td>\n",
       "      <td>242.999542</td>\n",
       "      <td>243.297684</td>\n",
       "      <td>244.29599</td>\n",
       "      <td>250.122833</td>\n",
       "      <td>248.844467</td>\n",
       "      <td>248.875122</td>\n",
       "      <td>249.001831</td>\n",
       "      <td>249.501114</td>\n",
       "      <td>247.965118</td>\n",
       "      <td>244.582306</td>\n",
       "      <td>243.515015</td>\n",
       "      <td>243.249268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>250.101</td>\n",
       "      <td>277.528</td>\n",
       "      <td>270.092</td>\n",
       "      <td>278.146</td>\n",
       "      <td>257.458</td>\n",
       "      <td>231.748</td>\n",
       "      <td>268.336</td>\n",
       "      <td>223.453</td>\n",
       "      <td>241.464</td>\n",
       "      <td>238.901</td>\n",
       "      <td>191.989</td>\n",
       "      <td>272.452</td>\n",
       "      <td>261.009</td>\n",
       "      <td>292.688</td>\n",
       "      <td>258.881</td>\n",
       "      <td>276.879</td>\n",
       "      <td>255.774</td>\n",
       "      <td>208.326</td>\n",
       "      <td>291.428</td>\n",
       "      <td>249.43</td>\n",
       "      <td>241.612</td>\n",
       "      <td>252.303</td>\n",
       "      <td>281.912</td>\n",
       "      <td>200.213</td>\n",
       "      <td>270.511</td>\n",
       "      <td>281.466</td>\n",
       "      <td>285.535</td>\n",
       "      <td>328.259</td>\n",
       "      <td>298.078</td>\n",
       "      <td>264.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>19.291367</td>\n",
       "      <td>9.047119</td>\n",
       "      <td>3.466888</td>\n",
       "      <td>12.140015</td>\n",
       "      <td>5.63089</td>\n",
       "      <td>25.247147</td>\n",
       "      <td>23.543961</td>\n",
       "      <td>21.578659</td>\n",
       "      <td>12.238754</td>\n",
       "      <td>19.901611</td>\n",
       "      <td>71.410263</td>\n",
       "      <td>6.001953</td>\n",
       "      <td>6.611053</td>\n",
       "      <td>27.695587</td>\n",
       "      <td>4.060364</td>\n",
       "      <td>20.074371</td>\n",
       "      <td>5.219742</td>\n",
       "      <td>34.926041</td>\n",
       "      <td>48.428467</td>\n",
       "      <td>6.132309</td>\n",
       "      <td>2.68399</td>\n",
       "      <td>2.180161</td>\n",
       "      <td>33.06752</td>\n",
       "      <td>48.662125</td>\n",
       "      <td>21.509155</td>\n",
       "      <td>31.96489</td>\n",
       "      <td>37.569885</td>\n",
       "      <td>83.676697</td>\n",
       "      <td>54.562988</td>\n",
       "      <td>21.588745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1           2           3           4   \\\n",
       "Month          Month-1     Month-2     Month-3     Month-4     Month-5   \n",
       "Prediction  269.392365  268.480896  266.625122  266.005981  263.088898   \n",
       "Target         250.101     277.528     270.092     278.146     257.458   \n",
       "Error        19.291367    9.047119    3.466888   12.140015     5.63089   \n",
       "\n",
       "                    5           6           7           8           9   \\\n",
       "Month          Month-6     Month-7     Month-8     Month-9    Month-10   \n",
       "Prediction  256.995148  244.792038  245.031662  253.702759  258.802612   \n",
       "Target         231.748     268.336     223.453     241.464     238.901   \n",
       "Error        25.247147   23.543961   21.578659   12.238754   19.901611   \n",
       "\n",
       "                    10          11          12          13          14  \\\n",
       "Month         Month-11    Month-12    Month-13    Month-14    Month-15   \n",
       "Prediction  263.399261  266.450043  267.620056  264.992401  262.941376   \n",
       "Target         191.989     272.452     261.009     292.688     258.881   \n",
       "Error        71.410263    6.001953    6.611053   27.695587    4.060364   \n",
       "\n",
       "                    15         16          17          18          19  \\\n",
       "Month         Month-16   Month-17    Month-18    Month-19    Month-20   \n",
       "Prediction  256.804626  250.55426  243.252045  242.999542  243.297684   \n",
       "Target         276.879    255.774     208.326     291.428      249.43   \n",
       "Error        20.074371   5.219742   34.926041   48.428467    6.132309   \n",
       "\n",
       "                   20          21          22          23          24  \\\n",
       "Month        Month-21    Month-22    Month-23    Month-24    Month-25   \n",
       "Prediction  244.29599  250.122833  248.844467  248.875122  249.001831   \n",
       "Target        241.612     252.303     281.912     200.213     270.511   \n",
       "Error         2.68399    2.180161    33.06752   48.662125   21.509155   \n",
       "\n",
       "                    25          26          27          28          29  \n",
       "Month         Month-26    Month-27    Month-28    Month-29    Month-30  \n",
       "Prediction  249.501114  247.965118  244.582306  243.515015  243.249268  \n",
       "Target         281.466     285.535     328.259     298.078     264.838  \n",
       "Error         31.96489   37.569885   83.676697   54.562988   21.588745  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            reshaped_test, \n",
    "                                            reshaped_test_target, \n",
    "                                            start_index)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b1c27bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.003757"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.09401667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c506c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ca218d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m errors, mae, mape \u001b[38;5;241m=\u001b[39m year_mae_mape_calculator(trained_model, \n\u001b[1;32m      2\u001b[0m                                              test_input, \n\u001b[0;32m----> 3\u001b[0m                                              \u001b[43mtest_target\u001b[49m, \n\u001b[1;32m      4\u001b[0m                                              start_index)\n\u001b[1;32m      5\u001b[0m display(errors)\n\u001b[1;32m      6\u001b[0m display(mae)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_target' is not defined"
     ]
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             start_index)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b2bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
