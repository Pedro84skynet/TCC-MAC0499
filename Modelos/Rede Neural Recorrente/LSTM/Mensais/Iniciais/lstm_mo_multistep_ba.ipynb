{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d613198",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Bahia - Consumo de Cimento (t)'\n",
    "start_index = 0\n",
    "split_index = 203 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 - 12*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc652c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Fluxo Mensal (Milhões de reais)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>Bahia - Desemprego</th>\n",
       "      <th>Bahia - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.299858</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>-5331.049150</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>0.669899</td>\n",
       "      <td>39.798880</td>\n",
       "      <td>1.317344e+08</td>\n",
       "      <td>8.384593e+06</td>\n",
       "      <td>8.566149</td>\n",
       "      <td>1.216359e+08</td>\n",
       "      <td>8.348779</td>\n",
       "      <td>151.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.301903</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>-5318.079644</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>0.670210</td>\n",
       "      <td>39.480034</td>\n",
       "      <td>1.318964e+08</td>\n",
       "      <td>8.391946e+06</td>\n",
       "      <td>8.569210</td>\n",
       "      <td>1.216914e+08</td>\n",
       "      <td>8.342979</td>\n",
       "      <td>138.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.303709</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>-5436.417870</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>0.670521</td>\n",
       "      <td>39.400256</td>\n",
       "      <td>1.320584e+08</td>\n",
       "      <td>8.399299e+06</td>\n",
       "      <td>8.572270</td>\n",
       "      <td>1.217469e+08</td>\n",
       "      <td>8.337179</td>\n",
       "      <td>135.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.305311</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>-5707.015274</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>0.670831</td>\n",
       "      <td>39.417185</td>\n",
       "      <td>1.322204e+08</td>\n",
       "      <td>8.406652e+06</td>\n",
       "      <td>8.575331</td>\n",
       "      <td>1.218023e+08</td>\n",
       "      <td>8.331379</td>\n",
       "      <td>126.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.306860</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>-5599.317941</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>0.671142</td>\n",
       "      <td>39.479943</td>\n",
       "      <td>1.323824e+08</td>\n",
       "      <td>8.414005e+06</td>\n",
       "      <td>8.578392</td>\n",
       "      <td>1.218578e+08</td>\n",
       "      <td>8.325579</td>\n",
       "      <td>137.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>0.597113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.069163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>0.596178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.752943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>0.594662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.537361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>0.592436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.971241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>0.589305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.857141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Bahia - value  \\\n",
       "0       2003-1       0.299858   \n",
       "1       2003-2       0.301903   \n",
       "2       2003-3       0.303709   \n",
       "3       2003-4       0.305311   \n",
       "4       2003-5       0.306860   \n",
       "..         ...            ...   \n",
       "235     2022-8       0.597113   \n",
       "236     2022-9       0.596178   \n",
       "237    2022-10       0.594662   \n",
       "238    2022-11       0.592436   \n",
       "239    2022-12       0.589305   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "      NFSP - Fluxo Mensal (Milhões de reais)  NFSP - Porcentagem do PIB (%)  \\\n",
       "0                               -5331.049150                      11.520143   \n",
       "1                               -5318.079644                      11.189862   \n",
       "2                               -5436.417870                      10.820792   \n",
       "3                               -5707.015274                      10.417840   \n",
       "4                               -5599.317941                       9.959690   \n",
       "..                                       ...                            ...   \n",
       "235                                      NaN                            NaN   \n",
       "236                                      NaN                            NaN   \n",
       "237                                      NaN                            NaN   \n",
       "238                                      NaN                            NaN   \n",
       "239                                      NaN                            NaN   \n",
       "\n",
       "     Taxa Selic (%)    IGP-DI     População  \\\n",
       "0          1.639718  1.036534  1.772069e+08   \n",
       "1          1.378899  0.993449  1.773884e+08   \n",
       "2          1.924317  0.973020  1.775699e+08   \n",
       "3          1.331174  0.940489  1.777514e+08   \n",
       "4          1.736072  0.917493  1.779329e+08   \n",
       "..              ...       ...           ...   \n",
       "235             NaN       NaN           NaN   \n",
       "236             NaN       NaN           NaN   \n",
       "237             NaN       NaN           NaN   \n",
       "238             NaN       NaN           NaN   \n",
       "239             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Bahia - IDH  \\\n",
       "0                              7.330309e+06   0.969649     0.669899   \n",
       "1                              7.335910e+06   0.950783     0.670210   \n",
       "2                              7.341511e+06   0.938332     0.670521   \n",
       "3                              7.347112e+06   0.926401     0.670831   \n",
       "4                              7.352713e+06   0.951683     0.671142   \n",
       "..                                      ...        ...          ...   \n",
       "235                                     NaN        NaN          NaN   \n",
       "236                                     NaN        NaN          NaN   \n",
       "237                                     NaN        NaN          NaN   \n",
       "238                                     NaN        NaN          NaN   \n",
       "239                                     NaN        NaN          NaN   \n",
       "\n",
       "     Bahia - Produção de Cimento (t)  Bahia - PIB - Estadual  \\\n",
       "0                          39.798880            1.317344e+08   \n",
       "1                          39.480034            1.318964e+08   \n",
       "2                          39.400256            1.320584e+08   \n",
       "3                          39.417185            1.322204e+08   \n",
       "4                          39.479943            1.323824e+08   \n",
       "..                               ...                     ...   \n",
       "235                       106.069163                     NaN   \n",
       "236                       105.752943                     NaN   \n",
       "237                       105.537361                     NaN   \n",
       "238                       104.971241                     NaN   \n",
       "239                       104.857141                     NaN   \n",
       "\n",
       "     Bahia - PIB - Construção Civil  Bahia - PIB - Per Capita  \\\n",
       "0                      8.384593e+06                  8.566149   \n",
       "1                      8.391946e+06                  8.569210   \n",
       "2                      8.399299e+06                  8.572270   \n",
       "3                      8.406652e+06                  8.575331   \n",
       "4                      8.414005e+06                  8.578392   \n",
       "..                              ...                       ...   \n",
       "235                             NaN                       NaN   \n",
       "236                             NaN                       NaN   \n",
       "237                             NaN                       NaN   \n",
       "238                             NaN                       NaN   \n",
       "239                             NaN                       NaN   \n",
       "\n",
       "     Bahia - PIB - Preços de Mercado  Bahia - Desemprego  \\\n",
       "0                       1.216359e+08            8.348779   \n",
       "1                       1.216914e+08            8.342979   \n",
       "2                       1.217469e+08            8.337179   \n",
       "3                       1.218023e+08            8.331379   \n",
       "4                       1.218578e+08            8.325579   \n",
       "..                               ...                 ...   \n",
       "235                              NaN                 NaN   \n",
       "236                              NaN                 NaN   \n",
       "237                              NaN                 NaN   \n",
       "238                              NaN                 NaN   \n",
       "239                              NaN                 NaN   \n",
       "\n",
       "     Bahia - Consumo de Cimento (t)  \n",
       "0                           151.297  \n",
       "1                           138.707  \n",
       "2                           135.009  \n",
       "3                           126.554  \n",
       "4                           137.331  \n",
       "..                              ...  \n",
       "235                         366.305  \n",
       "236                         346.042  \n",
       "237                         347.901  \n",
       "238                         310.845  \n",
       "239                         310.845  \n",
       "\n",
       "[240 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_BA.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Fluxo Mensal (Milhões de reais)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>Bahia - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.436732</td>\n",
       "      <td>2.782450</td>\n",
       "      <td>0.097384</td>\n",
       "      <td>4.506880</td>\n",
       "      <td>2.067266</td>\n",
       "      <td>2.574314</td>\n",
       "      <td>-2.064648</td>\n",
       "      <td>-2.469876</td>\n",
       "      <td>3.184489</td>\n",
       "      <td>-2.195846</td>\n",
       "      <td>-1.793459</td>\n",
       "      <td>-1.766933</td>\n",
       "      <td>-0.695996</td>\n",
       "      <td>-2.315693</td>\n",
       "      <td>-2.238131</td>\n",
       "      <td>-0.944845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.404185</td>\n",
       "      <td>2.407943</td>\n",
       "      <td>0.100462</td>\n",
       "      <td>4.328460</td>\n",
       "      <td>1.285816</td>\n",
       "      <td>2.334870</td>\n",
       "      <td>-2.037913</td>\n",
       "      <td>-2.431875</td>\n",
       "      <td>3.029073</td>\n",
       "      <td>-2.161313</td>\n",
       "      <td>-1.806616</td>\n",
       "      <td>-1.747868</td>\n",
       "      <td>-0.654222</td>\n",
       "      <td>-2.273375</td>\n",
       "      <td>-2.196868</td>\n",
       "      <td>-0.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.375442</td>\n",
       "      <td>2.179073</td>\n",
       "      <td>0.072380</td>\n",
       "      <td>4.129086</td>\n",
       "      <td>2.919965</td>\n",
       "      <td>2.221334</td>\n",
       "      <td>-2.011179</td>\n",
       "      <td>-2.393874</td>\n",
       "      <td>2.926505</td>\n",
       "      <td>-2.126781</td>\n",
       "      <td>-1.809908</td>\n",
       "      <td>-1.728803</td>\n",
       "      <td>-0.612447</td>\n",
       "      <td>-2.231056</td>\n",
       "      <td>-2.155605</td>\n",
       "      <td>-0.948156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.349941</td>\n",
       "      <td>2.077086</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>3.911409</td>\n",
       "      <td>1.142823</td>\n",
       "      <td>2.040542</td>\n",
       "      <td>-1.984445</td>\n",
       "      <td>-2.355872</td>\n",
       "      <td>2.828220</td>\n",
       "      <td>-2.092248</td>\n",
       "      <td>-1.809210</td>\n",
       "      <td>-1.709739</td>\n",
       "      <td>-0.570673</td>\n",
       "      <td>-2.188738</td>\n",
       "      <td>-2.114342</td>\n",
       "      <td>-0.949811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.325290</td>\n",
       "      <td>1.942128</td>\n",
       "      <td>0.033724</td>\n",
       "      <td>3.663912</td>\n",
       "      <td>2.355956</td>\n",
       "      <td>1.912744</td>\n",
       "      <td>-1.957710</td>\n",
       "      <td>-2.317871</td>\n",
       "      <td>3.036493</td>\n",
       "      <td>-2.057715</td>\n",
       "      <td>-1.806620</td>\n",
       "      <td>-1.690674</td>\n",
       "      <td>-0.528898</td>\n",
       "      <td>-2.146420</td>\n",
       "      <td>-2.073079</td>\n",
       "      <td>-0.951467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.851312</td>\n",
       "      <td>-0.689886</td>\n",
       "      <td>2.909383</td>\n",
       "      <td>-0.724085</td>\n",
       "      <td>-1.189161</td>\n",
       "      <td>3.148408</td>\n",
       "      <td>1.378950</td>\n",
       "      <td>0.117681</td>\n",
       "      <td>0.370628</td>\n",
       "      <td>1.041952</td>\n",
       "      <td>0.619029</td>\n",
       "      <td>0.865987</td>\n",
       "      <td>-1.416165</td>\n",
       "      <td>0.555618</td>\n",
       "      <td>0.463875</td>\n",
       "      <td>1.107985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.873607</td>\n",
       "      <td>-0.441954</td>\n",
       "      <td>2.913017</td>\n",
       "      <td>-0.736434</td>\n",
       "      <td>-1.296499</td>\n",
       "      <td>3.219670</td>\n",
       "      <td>1.391539</td>\n",
       "      <td>0.092456</td>\n",
       "      <td>0.427775</td>\n",
       "      <td>1.026783</td>\n",
       "      <td>0.635352</td>\n",
       "      <td>0.848481</td>\n",
       "      <td>-1.404857</td>\n",
       "      <td>0.531641</td>\n",
       "      <td>0.443334</td>\n",
       "      <td>1.106555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.901718</td>\n",
       "      <td>-0.132782</td>\n",
       "      <td>2.818435</td>\n",
       "      <td>-0.738433</td>\n",
       "      <td>-1.444029</td>\n",
       "      <td>3.421082</td>\n",
       "      <td>1.404128</td>\n",
       "      <td>0.067231</td>\n",
       "      <td>0.538287</td>\n",
       "      <td>1.011615</td>\n",
       "      <td>0.652040</td>\n",
       "      <td>0.830975</td>\n",
       "      <td>-1.393550</td>\n",
       "      <td>0.507664</td>\n",
       "      <td>0.422793</td>\n",
       "      <td>1.105126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.928136</td>\n",
       "      <td>0.084061</td>\n",
       "      <td>2.905726</td>\n",
       "      <td>-0.738236</td>\n",
       "      <td>-1.444143</td>\n",
       "      <td>3.373840</td>\n",
       "      <td>1.416717</td>\n",
       "      <td>0.042006</td>\n",
       "      <td>0.666156</td>\n",
       "      <td>0.996447</td>\n",
       "      <td>0.638794</td>\n",
       "      <td>0.813469</td>\n",
       "      <td>-1.382243</td>\n",
       "      <td>0.483687</td>\n",
       "      <td>0.402252</td>\n",
       "      <td>1.103697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1.972896</td>\n",
       "      <td>0.162956</td>\n",
       "      <td>2.954768</td>\n",
       "      <td>-0.746642</td>\n",
       "      <td>-1.717057</td>\n",
       "      <td>3.497364</td>\n",
       "      <td>1.429307</td>\n",
       "      <td>0.016781</td>\n",
       "      <td>0.767681</td>\n",
       "      <td>0.981278</td>\n",
       "      <td>0.637852</td>\n",
       "      <td>0.795963</td>\n",
       "      <td>-1.370936</td>\n",
       "      <td>0.459711</td>\n",
       "      <td>0.381711</td>\n",
       "      <td>1.102267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bahia - value   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0        -1.436732                                          2.782450   \n",
       "1        -1.404185                                          2.407943   \n",
       "2        -1.375442                                          2.179073   \n",
       "3        -1.349941                                          2.077086   \n",
       "4        -1.325290                                          1.942128   \n",
       "..             ...                                               ...   \n",
       "199       1.851312                                         -0.689886   \n",
       "200       1.873607                                         -0.441954   \n",
       "201       1.901718                                         -0.132782   \n",
       "202       1.928136                                          0.084061   \n",
       "203       1.972896                                          0.162956   \n",
       "\n",
       "      NFSP - Fluxo Mensal (Milhões de reais)  NFSP - Porcentagem do PIB (%)  \\\n",
       "0                                   0.097384                       4.506880   \n",
       "1                                   0.100462                       4.328460   \n",
       "2                                   0.072380                       4.129086   \n",
       "3                                   0.008167                       3.911409   \n",
       "4                                   0.033724                       3.663912   \n",
       "..                                       ...                            ...   \n",
       "199                                 2.909383                      -0.724085   \n",
       "200                                 2.913017                      -0.736434   \n",
       "201                                 2.818435                      -0.738433   \n",
       "202                                 2.905726                      -0.738236   \n",
       "203                                 2.954768                      -0.746642   \n",
       "\n",
       "     Taxa Selic (%)    IGP-DI  População  \\\n",
       "0          2.067266  2.574314  -2.064648   \n",
       "1          1.285816  2.334870  -2.037913   \n",
       "2          2.919965  2.221334  -2.011179   \n",
       "3          1.142823  2.040542  -1.984445   \n",
       "4          2.355956  1.912744  -1.957710   \n",
       "..              ...       ...        ...   \n",
       "199       -1.189161  3.148408   1.378950   \n",
       "200       -1.296499  3.219670   1.391539   \n",
       "201       -1.444029  3.421082   1.404128   \n",
       "202       -1.444143  3.373840   1.416717   \n",
       "203       -1.717057  3.497364   1.429307   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Bahia - IDH  \\\n",
       "0                                 -2.469876   3.184489    -2.195846   \n",
       "1                                 -2.431875   3.029073    -2.161313   \n",
       "2                                 -2.393874   2.926505    -2.126781   \n",
       "3                                 -2.355872   2.828220    -2.092248   \n",
       "4                                 -2.317871   3.036493    -2.057715   \n",
       "..                                      ...        ...          ...   \n",
       "199                                0.117681   0.370628     1.041952   \n",
       "200                                0.092456   0.427775     1.026783   \n",
       "201                                0.067231   0.538287     1.011615   \n",
       "202                                0.042006   0.666156     0.996447   \n",
       "203                                0.016781   0.767681     0.981278   \n",
       "\n",
       "     Bahia - Produção de Cimento (t)  Bahia - PIB - Estadual  \\\n",
       "0                          -1.793459               -1.766933   \n",
       "1                          -1.806616               -1.747868   \n",
       "2                          -1.809908               -1.728803   \n",
       "3                          -1.809210               -1.709739   \n",
       "4                          -1.806620               -1.690674   \n",
       "..                               ...                     ...   \n",
       "199                         0.619029                0.865987   \n",
       "200                         0.635352                0.848481   \n",
       "201                         0.652040                0.830975   \n",
       "202                         0.638794                0.813469   \n",
       "203                         0.637852                0.795963   \n",
       "\n",
       "     Bahia - PIB - Construção Civil  Bahia - PIB - Per Capita  \\\n",
       "0                         -0.695996                 -2.315693   \n",
       "1                         -0.654222                 -2.273375   \n",
       "2                         -0.612447                 -2.231056   \n",
       "3                         -0.570673                 -2.188738   \n",
       "4                         -0.528898                 -2.146420   \n",
       "..                              ...                       ...   \n",
       "199                       -1.416165                  0.555618   \n",
       "200                       -1.404857                  0.531641   \n",
       "201                       -1.393550                  0.507664   \n",
       "202                       -1.382243                  0.483687   \n",
       "203                       -1.370936                  0.459711   \n",
       "\n",
       "     Bahia - PIB - Preços de Mercado  Bahia - Desemprego  \n",
       "0                          -2.238131           -0.944845  \n",
       "1                          -2.196868           -0.946500  \n",
       "2                          -2.155605           -0.948156  \n",
       "3                          -2.114342           -0.949811  \n",
       "4                          -2.073079           -0.951467  \n",
       "..                               ...                 ...  \n",
       "199                         0.463875            1.107985  \n",
       "200                         0.443334            1.106555  \n",
       "201                         0.422793            1.105126  \n",
       "202                         0.402252            1.103697  \n",
       "203                         0.381711            1.102267  \n",
       "\n",
       "[204 rows x 16 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "# input_data = data.iloc[:split_index + 1,:]\n",
    "input_data = (input_data - np.mean(input_data, axis=0)) / np.std(input_data, axis=0)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      138.707\n",
       "1      135.009\n",
       "2      126.554\n",
       "3      137.331\n",
       "4      118.680\n",
       "        ...   \n",
       "235    346.042\n",
       "236    347.901\n",
       "237    310.845\n",
       "238    310.845\n",
       "239        NaN\n",
       "Name: Bahia - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-1)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Fluxo Mensal (Milhões de reais)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>Bahia - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.436732</td>\n",
       "      <td>2.782450</td>\n",
       "      <td>0.097384</td>\n",
       "      <td>4.506880</td>\n",
       "      <td>2.067266</td>\n",
       "      <td>2.574314</td>\n",
       "      <td>-2.064648</td>\n",
       "      <td>-2.469876</td>\n",
       "      <td>3.184489</td>\n",
       "      <td>-2.195846</td>\n",
       "      <td>-1.793459</td>\n",
       "      <td>-1.766933</td>\n",
       "      <td>-0.695996</td>\n",
       "      <td>-2.315693</td>\n",
       "      <td>-2.238131</td>\n",
       "      <td>-0.944845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.404185</td>\n",
       "      <td>2.407943</td>\n",
       "      <td>0.100462</td>\n",
       "      <td>4.328460</td>\n",
       "      <td>1.285816</td>\n",
       "      <td>2.334870</td>\n",
       "      <td>-2.037913</td>\n",
       "      <td>-2.431875</td>\n",
       "      <td>3.029073</td>\n",
       "      <td>-2.161313</td>\n",
       "      <td>-1.806616</td>\n",
       "      <td>-1.747868</td>\n",
       "      <td>-0.654222</td>\n",
       "      <td>-2.273375</td>\n",
       "      <td>-2.196868</td>\n",
       "      <td>-0.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.375442</td>\n",
       "      <td>2.179073</td>\n",
       "      <td>0.072380</td>\n",
       "      <td>4.129086</td>\n",
       "      <td>2.919965</td>\n",
       "      <td>2.221334</td>\n",
       "      <td>-2.011179</td>\n",
       "      <td>-2.393874</td>\n",
       "      <td>2.926505</td>\n",
       "      <td>-2.126781</td>\n",
       "      <td>-1.809908</td>\n",
       "      <td>-1.728803</td>\n",
       "      <td>-0.612447</td>\n",
       "      <td>-2.231056</td>\n",
       "      <td>-2.155605</td>\n",
       "      <td>-0.948156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.349941</td>\n",
       "      <td>2.077086</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>3.911409</td>\n",
       "      <td>1.142823</td>\n",
       "      <td>2.040542</td>\n",
       "      <td>-1.984445</td>\n",
       "      <td>-2.355872</td>\n",
       "      <td>2.828220</td>\n",
       "      <td>-2.092248</td>\n",
       "      <td>-1.809210</td>\n",
       "      <td>-1.709739</td>\n",
       "      <td>-0.570673</td>\n",
       "      <td>-2.188738</td>\n",
       "      <td>-2.114342</td>\n",
       "      <td>-0.949811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.325290</td>\n",
       "      <td>1.942128</td>\n",
       "      <td>0.033724</td>\n",
       "      <td>3.663912</td>\n",
       "      <td>2.355956</td>\n",
       "      <td>1.912744</td>\n",
       "      <td>-1.957710</td>\n",
       "      <td>-2.317871</td>\n",
       "      <td>3.036493</td>\n",
       "      <td>-2.057715</td>\n",
       "      <td>-1.806620</td>\n",
       "      <td>-1.690674</td>\n",
       "      <td>-0.528898</td>\n",
       "      <td>-2.146420</td>\n",
       "      <td>-2.073079</td>\n",
       "      <td>-0.951467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.005306</td>\n",
       "      <td>-0.742853</td>\n",
       "      <td>0.615006</td>\n",
       "      <td>-0.619453</td>\n",
       "      <td>0.617009</td>\n",
       "      <td>-0.970725</td>\n",
       "      <td>0.980624</td>\n",
       "      <td>0.764972</td>\n",
       "      <td>-1.322806</td>\n",
       "      <td>1.339087</td>\n",
       "      <td>0.469766</td>\n",
       "      <td>1.163205</td>\n",
       "      <td>-1.340370</td>\n",
       "      <td>1.005749</td>\n",
       "      <td>1.008566</td>\n",
       "      <td>1.160245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.029532</td>\n",
       "      <td>-0.787367</td>\n",
       "      <td>0.546355</td>\n",
       "      <td>-0.611176</td>\n",
       "      <td>0.459632</td>\n",
       "      <td>-0.841670</td>\n",
       "      <td>0.991608</td>\n",
       "      <td>0.753473</td>\n",
       "      <td>-1.355523</td>\n",
       "      <td>1.336451</td>\n",
       "      <td>0.457435</td>\n",
       "      <td>1.164562</td>\n",
       "      <td>-1.364998</td>\n",
       "      <td>1.008863</td>\n",
       "      <td>1.002613</td>\n",
       "      <td>1.155001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.057198</td>\n",
       "      <td>-0.757940</td>\n",
       "      <td>0.421319</td>\n",
       "      <td>-0.599627</td>\n",
       "      <td>0.493659</td>\n",
       "      <td>-0.838453</td>\n",
       "      <td>1.002592</td>\n",
       "      <td>0.741973</td>\n",
       "      <td>-1.376175</td>\n",
       "      <td>1.333816</td>\n",
       "      <td>0.454716</td>\n",
       "      <td>1.165920</td>\n",
       "      <td>-1.389626</td>\n",
       "      <td>1.011977</td>\n",
       "      <td>0.996661</td>\n",
       "      <td>1.149757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.082730</td>\n",
       "      <td>-0.917469</td>\n",
       "      <td>0.661467</td>\n",
       "      <td>-0.589237</td>\n",
       "      <td>0.617024</td>\n",
       "      <td>-1.006001</td>\n",
       "      <td>1.013577</td>\n",
       "      <td>0.730473</td>\n",
       "      <td>-1.414146</td>\n",
       "      <td>1.331180</td>\n",
       "      <td>0.446427</td>\n",
       "      <td>1.167277</td>\n",
       "      <td>-1.414254</td>\n",
       "      <td>1.015092</td>\n",
       "      <td>0.990708</td>\n",
       "      <td>1.144512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.112662</td>\n",
       "      <td>-0.980136</td>\n",
       "      <td>0.679126</td>\n",
       "      <td>-0.584931</td>\n",
       "      <td>0.302239</td>\n",
       "      <td>-1.088872</td>\n",
       "      <td>1.024561</td>\n",
       "      <td>0.718973</td>\n",
       "      <td>-1.444336</td>\n",
       "      <td>1.328544</td>\n",
       "      <td>0.406571</td>\n",
       "      <td>1.168635</td>\n",
       "      <td>-1.438882</td>\n",
       "      <td>1.018206</td>\n",
       "      <td>0.984756</td>\n",
       "      <td>1.139268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bahia - value   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0        -1.436732                                          2.782450   \n",
       "1        -1.404185                                          2.407943   \n",
       "2        -1.375442                                          2.179073   \n",
       "3        -1.349941                                          2.077086   \n",
       "4        -1.325290                                          1.942128   \n",
       "..             ...                                               ...   \n",
       "163       1.005306                                         -0.742853   \n",
       "164       1.029532                                         -0.787367   \n",
       "165       1.057198                                         -0.757940   \n",
       "166       1.082730                                         -0.917469   \n",
       "167       1.112662                                         -0.980136   \n",
       "\n",
       "      NFSP - Fluxo Mensal (Milhões de reais)  NFSP - Porcentagem do PIB (%)  \\\n",
       "0                                   0.097384                       4.506880   \n",
       "1                                   0.100462                       4.328460   \n",
       "2                                   0.072380                       4.129086   \n",
       "3                                   0.008167                       3.911409   \n",
       "4                                   0.033724                       3.663912   \n",
       "..                                       ...                            ...   \n",
       "163                                 0.615006                      -0.619453   \n",
       "164                                 0.546355                      -0.611176   \n",
       "165                                 0.421319                      -0.599627   \n",
       "166                                 0.661467                      -0.589237   \n",
       "167                                 0.679126                      -0.584931   \n",
       "\n",
       "     Taxa Selic (%)    IGP-DI  População  \\\n",
       "0          2.067266  2.574314  -2.064648   \n",
       "1          1.285816  2.334870  -2.037913   \n",
       "2          2.919965  2.221334  -2.011179   \n",
       "3          1.142823  2.040542  -1.984445   \n",
       "4          2.355956  1.912744  -1.957710   \n",
       "..              ...       ...        ...   \n",
       "163        0.617009 -0.970725   0.980624   \n",
       "164        0.459632 -0.841670   0.991608   \n",
       "165        0.493659 -0.838453   1.002592   \n",
       "166        0.617024 -1.006001   1.013577   \n",
       "167        0.302239 -1.088872   1.024561   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Bahia - IDH  \\\n",
       "0                                 -2.469876   3.184489    -2.195846   \n",
       "1                                 -2.431875   3.029073    -2.161313   \n",
       "2                                 -2.393874   2.926505    -2.126781   \n",
       "3                                 -2.355872   2.828220    -2.092248   \n",
       "4                                 -2.317871   3.036493    -2.057715   \n",
       "..                                      ...        ...          ...   \n",
       "163                                0.764972  -1.322806     1.339087   \n",
       "164                                0.753473  -1.355523     1.336451   \n",
       "165                                0.741973  -1.376175     1.333816   \n",
       "166                                0.730473  -1.414146     1.331180   \n",
       "167                                0.718973  -1.444336     1.328544   \n",
       "\n",
       "     Bahia - Produção de Cimento (t)  Bahia - PIB - Estadual  \\\n",
       "0                          -1.793459               -1.766933   \n",
       "1                          -1.806616               -1.747868   \n",
       "2                          -1.809908               -1.728803   \n",
       "3                          -1.809210               -1.709739   \n",
       "4                          -1.806620               -1.690674   \n",
       "..                               ...                     ...   \n",
       "163                         0.469766                1.163205   \n",
       "164                         0.457435                1.164562   \n",
       "165                         0.454716                1.165920   \n",
       "166                         0.446427                1.167277   \n",
       "167                         0.406571                1.168635   \n",
       "\n",
       "     Bahia - PIB - Construção Civil  Bahia - PIB - Per Capita  \\\n",
       "0                         -0.695996                 -2.315693   \n",
       "1                         -0.654222                 -2.273375   \n",
       "2                         -0.612447                 -2.231056   \n",
       "3                         -0.570673                 -2.188738   \n",
       "4                         -0.528898                 -2.146420   \n",
       "..                              ...                       ...   \n",
       "163                       -1.340370                  1.005749   \n",
       "164                       -1.364998                  1.008863   \n",
       "165                       -1.389626                  1.011977   \n",
       "166                       -1.414254                  1.015092   \n",
       "167                       -1.438882                  1.018206   \n",
       "\n",
       "     Bahia - PIB - Preços de Mercado  Bahia - Desemprego  \n",
       "0                          -2.238131           -0.944845  \n",
       "1                          -2.196868           -0.946500  \n",
       "2                          -2.155605           -0.948156  \n",
       "3                          -2.114342           -0.949811  \n",
       "4                          -2.073079           -0.951467  \n",
       "..                               ...                 ...  \n",
       "163                         1.008566            1.160245  \n",
       "164                         1.002613            1.155001  \n",
       "165                         0.996661            1.149757  \n",
       "166                         0.990708            1.144512  \n",
       "167                         0.984756            1.139268  \n",
       "\n",
       "[168 rows x 16 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[start_index:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      138.707\n",
       "1      135.009\n",
       "2      126.554\n",
       "3      137.331\n",
       "4      118.680\n",
       "        ...   \n",
       "163    280.074\n",
       "164    277.938\n",
       "165    275.802\n",
       "166    273.666\n",
       "167    271.530\n",
       "Name: Bahia - Consumo de Cimento (t), Length: 168, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[start_index:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21b9c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(t_input, t_target, window_size, start_from):\n",
    "    \n",
    "    X_batches = []\n",
    "    y_batches = []\n",
    "\n",
    "    train_input_values = t_input.values \n",
    "\n",
    "    for i in range(len(t_input) - window_size):\n",
    "        \n",
    "        X_window = train_input_values[i:i+window_size, :]\n",
    "        y_target = t_target[start_from+i+window_size]\n",
    "\n",
    "        X_batches.append(X_window)\n",
    "        y_batches.append(y_target)\n",
    "\n",
    "    return np.array(X_batches), np.array(y_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b281277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 36, 16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_train, reshaped_target = create_batches(train_input, train_target, 36, start_index)\n",
    "reshaped_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc5d50dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Fluxo Mensal (Milhões de reais)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>Bahia - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.543796</td>\n",
       "      <td>1.590448</td>\n",
       "      <td>0.225519</td>\n",
       "      <td>-0.298056</td>\n",
       "      <td>-0.311347</td>\n",
       "      <td>-0.077688</td>\n",
       "      <td>0.623805</td>\n",
       "      <td>0.982447</td>\n",
       "      <td>0.041401</td>\n",
       "      <td>0.450270</td>\n",
       "      <td>1.069363</td>\n",
       "      <td>0.900016</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.917759</td>\n",
       "      <td>1.088312</td>\n",
       "      <td>0.982858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.564912</td>\n",
       "      <td>1.702213</td>\n",
       "      <td>0.413533</td>\n",
       "      <td>-0.281023</td>\n",
       "      <td>-0.313831</td>\n",
       "      <td>-0.030826</td>\n",
       "      <td>0.635788</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>-0.019620</td>\n",
       "      <td>0.450043</td>\n",
       "      <td>1.054155</td>\n",
       "      <td>0.914134</td>\n",
       "      <td>-0.050121</td>\n",
       "      <td>0.925696</td>\n",
       "      <td>1.092431</td>\n",
       "      <td>0.995759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.584512</td>\n",
       "      <td>1.677438</td>\n",
       "      <td>0.431751</td>\n",
       "      <td>-0.265304</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>-0.076111</td>\n",
       "      <td>0.647771</td>\n",
       "      <td>0.975750</td>\n",
       "      <td>0.029284</td>\n",
       "      <td>0.449817</td>\n",
       "      <td>1.039972</td>\n",
       "      <td>0.928253</td>\n",
       "      <td>-0.105908</td>\n",
       "      <td>0.933634</td>\n",
       "      <td>1.096551</td>\n",
       "      <td>1.008660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.603507</td>\n",
       "      <td>1.638599</td>\n",
       "      <td>0.414613</td>\n",
       "      <td>-0.251648</td>\n",
       "      <td>-0.486922</td>\n",
       "      <td>-0.205002</td>\n",
       "      <td>0.659754</td>\n",
       "      <td>0.972402</td>\n",
       "      <td>0.072516</td>\n",
       "      <td>0.449591</td>\n",
       "      <td>1.025069</td>\n",
       "      <td>0.942371</td>\n",
       "      <td>-0.161695</td>\n",
       "      <td>0.941571</td>\n",
       "      <td>1.100670</td>\n",
       "      <td>1.021561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.624844</td>\n",
       "      <td>1.691843</td>\n",
       "      <td>0.566348</td>\n",
       "      <td>-0.231997</td>\n",
       "      <td>-0.559925</td>\n",
       "      <td>-0.132229</td>\n",
       "      <td>0.671737</td>\n",
       "      <td>0.969054</td>\n",
       "      <td>-0.064532</td>\n",
       "      <td>0.449365</td>\n",
       "      <td>1.009687</td>\n",
       "      <td>0.956489</td>\n",
       "      <td>-0.217482</td>\n",
       "      <td>0.949509</td>\n",
       "      <td>1.104789</td>\n",
       "      <td>1.034462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.851312</td>\n",
       "      <td>-0.689886</td>\n",
       "      <td>2.909383</td>\n",
       "      <td>-0.724085</td>\n",
       "      <td>-1.189161</td>\n",
       "      <td>3.148408</td>\n",
       "      <td>1.378950</td>\n",
       "      <td>0.117681</td>\n",
       "      <td>0.370628</td>\n",
       "      <td>1.041952</td>\n",
       "      <td>0.619029</td>\n",
       "      <td>0.865987</td>\n",
       "      <td>-1.416165</td>\n",
       "      <td>0.555618</td>\n",
       "      <td>0.463875</td>\n",
       "      <td>1.107985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.873607</td>\n",
       "      <td>-0.441954</td>\n",
       "      <td>2.913017</td>\n",
       "      <td>-0.736434</td>\n",
       "      <td>-1.296499</td>\n",
       "      <td>3.219670</td>\n",
       "      <td>1.391539</td>\n",
       "      <td>0.092456</td>\n",
       "      <td>0.427775</td>\n",
       "      <td>1.026783</td>\n",
       "      <td>0.635352</td>\n",
       "      <td>0.848481</td>\n",
       "      <td>-1.404857</td>\n",
       "      <td>0.531641</td>\n",
       "      <td>0.443334</td>\n",
       "      <td>1.106555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.901718</td>\n",
       "      <td>-0.132782</td>\n",
       "      <td>2.818435</td>\n",
       "      <td>-0.738433</td>\n",
       "      <td>-1.444029</td>\n",
       "      <td>3.421082</td>\n",
       "      <td>1.404128</td>\n",
       "      <td>0.067231</td>\n",
       "      <td>0.538287</td>\n",
       "      <td>1.011615</td>\n",
       "      <td>0.652040</td>\n",
       "      <td>0.830975</td>\n",
       "      <td>-1.393550</td>\n",
       "      <td>0.507664</td>\n",
       "      <td>0.422793</td>\n",
       "      <td>1.105126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.928136</td>\n",
       "      <td>0.084061</td>\n",
       "      <td>2.905726</td>\n",
       "      <td>-0.738236</td>\n",
       "      <td>-1.444143</td>\n",
       "      <td>3.373840</td>\n",
       "      <td>1.416717</td>\n",
       "      <td>0.042006</td>\n",
       "      <td>0.666156</td>\n",
       "      <td>0.996447</td>\n",
       "      <td>0.638794</td>\n",
       "      <td>0.813469</td>\n",
       "      <td>-1.382243</td>\n",
       "      <td>0.483687</td>\n",
       "      <td>0.402252</td>\n",
       "      <td>1.103697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1.972896</td>\n",
       "      <td>0.162956</td>\n",
       "      <td>2.954768</td>\n",
       "      <td>-0.746642</td>\n",
       "      <td>-1.717057</td>\n",
       "      <td>3.497364</td>\n",
       "      <td>1.429307</td>\n",
       "      <td>0.016781</td>\n",
       "      <td>0.767681</td>\n",
       "      <td>0.981278</td>\n",
       "      <td>0.637852</td>\n",
       "      <td>0.795963</td>\n",
       "      <td>-1.370936</td>\n",
       "      <td>0.459711</td>\n",
       "      <td>0.381711</td>\n",
       "      <td>1.102267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bahia - value   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "132       0.543796                                          1.590448   \n",
       "133       0.564912                                          1.702213   \n",
       "134       0.584512                                          1.677438   \n",
       "135       0.603507                                          1.638599   \n",
       "136       0.624844                                          1.691843   \n",
       "..             ...                                               ...   \n",
       "199       1.851312                                         -0.689886   \n",
       "200       1.873607                                         -0.441954   \n",
       "201       1.901718                                         -0.132782   \n",
       "202       1.928136                                          0.084061   \n",
       "203       1.972896                                          0.162956   \n",
       "\n",
       "      NFSP - Fluxo Mensal (Milhões de reais)  NFSP - Porcentagem do PIB (%)  \\\n",
       "132                                 0.225519                      -0.298056   \n",
       "133                                 0.413533                      -0.281023   \n",
       "134                                 0.431751                      -0.265304   \n",
       "135                                 0.414613                      -0.251648   \n",
       "136                                 0.566348                      -0.231997   \n",
       "..                                       ...                            ...   \n",
       "199                                 2.909383                      -0.724085   \n",
       "200                                 2.913017                      -0.736434   \n",
       "201                                 2.818435                      -0.738433   \n",
       "202                                 2.905726                      -0.738236   \n",
       "203                                 2.954768                      -0.746642   \n",
       "\n",
       "     Taxa Selic (%)    IGP-DI  População  \\\n",
       "132       -0.311347 -0.077688   0.623805   \n",
       "133       -0.313831 -0.030826   0.635788   \n",
       "134        0.006739 -0.076111   0.647771   \n",
       "135       -0.486922 -0.205002   0.659754   \n",
       "136       -0.559925 -0.132229   0.671737   \n",
       "..              ...       ...        ...   \n",
       "199       -1.189161  3.148408   1.378950   \n",
       "200       -1.296499  3.219670   1.391539   \n",
       "201       -1.444029  3.421082   1.404128   \n",
       "202       -1.444143  3.373840   1.416717   \n",
       "203       -1.717057  3.497364   1.429307   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Bahia - IDH  \\\n",
       "132                                0.982447   0.041401     0.450270   \n",
       "133                                0.979099  -0.019620     0.450043   \n",
       "134                                0.975750   0.029284     0.449817   \n",
       "135                                0.972402   0.072516     0.449591   \n",
       "136                                0.969054  -0.064532     0.449365   \n",
       "..                                      ...        ...          ...   \n",
       "199                                0.117681   0.370628     1.041952   \n",
       "200                                0.092456   0.427775     1.026783   \n",
       "201                                0.067231   0.538287     1.011615   \n",
       "202                                0.042006   0.666156     0.996447   \n",
       "203                                0.016781   0.767681     0.981278   \n",
       "\n",
       "     Bahia - Produção de Cimento (t)  Bahia - PIB - Estadual  \\\n",
       "132                         1.069363                0.900016   \n",
       "133                         1.054155                0.914134   \n",
       "134                         1.039972                0.928253   \n",
       "135                         1.025069                0.942371   \n",
       "136                         1.009687                0.956489   \n",
       "..                               ...                     ...   \n",
       "199                         0.619029                0.865987   \n",
       "200                         0.635352                0.848481   \n",
       "201                         0.652040                0.830975   \n",
       "202                         0.638794                0.813469   \n",
       "203                         0.637852                0.795963   \n",
       "\n",
       "     Bahia - PIB - Construção Civil  Bahia - PIB - Per Capita  \\\n",
       "132                        0.005667                  0.917759   \n",
       "133                       -0.050121                  0.925696   \n",
       "134                       -0.105908                  0.933634   \n",
       "135                       -0.161695                  0.941571   \n",
       "136                       -0.217482                  0.949509   \n",
       "..                              ...                       ...   \n",
       "199                       -1.416165                  0.555618   \n",
       "200                       -1.404857                  0.531641   \n",
       "201                       -1.393550                  0.507664   \n",
       "202                       -1.382243                  0.483687   \n",
       "203                       -1.370936                  0.459711   \n",
       "\n",
       "     Bahia - PIB - Preços de Mercado  Bahia - Desemprego  \n",
       "132                         1.088312            0.982858  \n",
       "133                         1.092431            0.995759  \n",
       "134                         1.096551            1.008660  \n",
       "135                         1.100670            1.021561  \n",
       "136                         1.104789            1.034462  \n",
       "..                               ...                 ...  \n",
       "199                         0.463875            1.107985  \n",
       "200                         0.443334            1.106555  \n",
       "201                         0.422793            1.105126  \n",
       "202                         0.402252            1.103697  \n",
       "203                         0.381711            1.102267  \n",
       "\n",
       "[72 rows x 16 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "test_input = input_data.iloc[train_split-36:split_index + 1]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82f07fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 36, 16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_test, reshaped_test_target = create_batches(test_input, target_data, 36, 132)\n",
    "reshaped_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c5afeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(arr, div_factor, add_factor=0):\n",
    "    split_factor = len(arr) // div_factor\n",
    "    positions_to_drop_index = []\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = len(arr) - (i * 6 + 1)\n",
    "        positions_to_drop_index.append(pos)\n",
    "        positions_to_drop.append(pos + add_factor)\n",
    "    \n",
    "    arr_droped = arr[positions_to_drop]\n",
    "    arr_result = np.delete(arr, positions_to_drop_index, axis=0)\n",
    "    \n",
    "    return arr_result, arr_droped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede Neural Recorrente com optmizador Estocástico\n",
    "def lstm_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    train, train_val = validation_splitter(train_input, 6)\n",
    "    target,target_val = validation_splitter(train_target, 6)\n",
    "#     display(train.shape)\n",
    "#     display(train_val.shape)\n",
    "#     display(target.shape)\n",
    "#     display(target_val.shape)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(36, activation='tanh', \n",
    "                             return_sequences=True, \n",
    "                             input_shape=(reshaped_train.shape[1],\n",
    "                                          reshaped_train.shape[2])),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.LSTM(180, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val,\n",
    "                                         target_val),\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_input, test_target):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = lstm_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1acb58be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[607932482, 3618141235, 4202845226, 3864565908, 842708788, 2521680910, 1487098388, 1305453216, 1664261261, 1702725033, 802031259, 2259736423, 929213541, 657784457, 3433843519, 967964318, 3146527401, 493776341, 1844216892, 876680700, 3963062856, 2051108872, 2450534288, 1050358393, 859958532]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 154.43568420410156\n",
      "winner_seed: 607932482\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 156.52947998046875\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 282.73675537109375\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 116.61396789550781\n",
      "winner_seed: 3864565908\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 126.7946548461914\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 151.833740234375\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 160.74114990234375\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 249.00546264648438\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 129.03150939941406\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 114.33562469482422\n",
      "winner_seed: 1702725033\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 144.08209228515625\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 176.94342041015625\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 132.6521453857422\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 480.5156555175781\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 115.14021301269531\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 138.15037536621094\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 1617.6343994140625\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 113.09342956542969\n",
      "winner_seed: 493776341\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 125.12731170654297\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 130.81607055664062\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 98.99700164794922\n",
      "winner_seed: 3963062856\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 154.19117736816406\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 136.5626220703125\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 97.70635223388672\n",
      "winner_seed: 1050358393\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 101.2892837524414\n",
      "\n",
      "\n",
      "final_seed: 1050358393\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(reshaped_train, reshaped_target, reshaped_test, reshaped_test_target)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 [==============================] - 2s 111ms/step - loss: 60113.1562 - val_loss: 2966.0806\n",
      "Epoch 2/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3716.4397 - val_loss: 3253.5015\n",
      "Epoch 3/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3885.6323 - val_loss: 3016.9617\n",
      "Epoch 4/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3615.0134 - val_loss: 2971.2927\n",
      "Epoch 5/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3605.6680 - val_loss: 3241.0127\n",
      "Epoch 6/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3711.6287 - val_loss: 3284.9827\n",
      "Epoch 7/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3723.6125 - val_loss: 2881.4597\n",
      "Epoch 8/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3189.0046 - val_loss: 3256.2751\n",
      "Epoch 9/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3782.6667 - val_loss: 2947.6584\n",
      "Epoch 10/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3504.6580 - val_loss: 6310.8901\n",
      "Epoch 11/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4066.1301 - val_loss: 2968.5337\n",
      "Epoch 12/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2796.1567 - val_loss: 1760.2344\n",
      "Epoch 13/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2132.1414 - val_loss: 2590.6409\n",
      "Epoch 14/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2054.6003 - val_loss: 1200.7913\n",
      "Epoch 15/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1536.6781 - val_loss: 1111.4515\n",
      "Epoch 16/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1225.1597 - val_loss: 1361.6306\n",
      "Epoch 17/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1572.7003 - val_loss: 1744.7695\n",
      "Epoch 18/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1478.7966 - val_loss: 1364.1788\n",
      "Epoch 19/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1131.6202 - val_loss: 769.5389\n",
      "Epoch 20/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 875.9517 - val_loss: 798.1415\n",
      "Epoch 21/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1291.7089 - val_loss: 640.1124\n",
      "Epoch 22/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 884.3972 - val_loss: 673.4012\n",
      "Epoch 23/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 840.1668 - val_loss: 629.7776\n",
      "Epoch 24/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 787.1598 - val_loss: 723.3633\n",
      "Epoch 25/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1575.9706 - val_loss: 1625.1399\n",
      "Epoch 26/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1467.5847 - val_loss: 805.9664\n",
      "Epoch 27/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1133.5082 - val_loss: 746.9205\n",
      "Epoch 28/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 761.3896 - val_loss: 720.4713\n",
      "Epoch 29/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 807.1252 - val_loss: 603.7668\n",
      "Epoch 30/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 717.3264 - val_loss: 1646.7189\n",
      "Epoch 31/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1159.3545 - val_loss: 971.7701\n",
      "Epoch 32/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 771.6718 - val_loss: 638.3332\n",
      "Epoch 33/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 799.2371 - val_loss: 642.4881\n",
      "Epoch 34/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 729.6875 - val_loss: 652.6180\n",
      "Epoch 35/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 746.5869 - val_loss: 1514.0206\n",
      "Epoch 36/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4055.4302 - val_loss: 1712.0624\n",
      "Epoch 37/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1793.5983 - val_loss: 1421.0941\n",
      "Epoch 38/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1044.3887 - val_loss: 1324.3829\n",
      "Epoch 39/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 888.7114 - val_loss: 844.9238\n",
      "Epoch 40/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 903.3658 - val_loss: 610.6352\n",
      "Epoch 41/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 739.1757 - val_loss: 593.6509\n",
      "Epoch 42/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 822.4449 - val_loss: 587.7684\n",
      "Epoch 43/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 688.8810 - val_loss: 575.4062\n",
      "Epoch 44/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 706.5487 - val_loss: 541.5208\n",
      "Epoch 45/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 674.4549 - val_loss: 1048.2948\n",
      "Epoch 46/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 738.3080 - val_loss: 672.1327\n",
      "Epoch 47/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 752.0619 - val_loss: 651.3954\n",
      "Epoch 48/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 669.9152 - val_loss: 681.9832\n",
      "Epoch 49/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 709.7943 - val_loss: 966.8160\n",
      "Epoch 50/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 701.4037 - val_loss: 497.3075\n",
      "Epoch 51/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 631.2819 - val_loss: 800.8222\n",
      "Epoch 52/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 863.9769 - val_loss: 422.7120\n",
      "Epoch 53/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 557.0162 - val_loss: 562.3071\n",
      "Epoch 54/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 648.8986 - val_loss: 477.8808\n",
      "Epoch 55/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 488.3634 - val_loss: 343.2216\n",
      "Epoch 56/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1033.2769 - val_loss: 702.8841\n",
      "Epoch 57/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 620.9354 - val_loss: 606.6967\n",
      "Epoch 58/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 970.0116 - val_loss: 622.2555\n",
      "Epoch 59/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 606.7338 - val_loss: 553.2182\n",
      "Epoch 60/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 615.0418 - val_loss: 412.3529\n",
      "Epoch 61/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 720.4578 - val_loss: 386.7091\n",
      "Epoch 62/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 576.0206 - val_loss: 413.1668\n",
      "Epoch 63/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 498.3958 - val_loss: 461.1616\n",
      "Epoch 64/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 689.7653 - val_loss: 864.7479\n",
      "Epoch 65/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 776.2309 - val_loss: 672.6387\n",
      "Epoch 66/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 578.6363 - val_loss: 524.4822\n",
      "Epoch 67/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 513.3467 - val_loss: 485.8341\n",
      "Epoch 68/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 622.0309 - val_loss: 326.1140\n",
      "Epoch 69/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 565.5741 - val_loss: 346.2742\n",
      "Epoch 70/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 424.2155 - val_loss: 573.2484\n",
      "Epoch 71/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 473.6613 - val_loss: 467.9298\n",
      "Epoch 72/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 546.4916 - val_loss: 477.2410\n",
      "Epoch 73/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1465.1935 - val_loss: 352.0260\n",
      "Epoch 74/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 571.0684 - val_loss: 327.1537\n",
      "Epoch 75/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 855.9144 - val_loss: 552.5183\n",
      "Epoch 76/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 677.6519 - val_loss: 351.7836\n",
      "Epoch 77/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 604.4996 - val_loss: 447.6325\n",
      "Epoch 78/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 751.5312 - val_loss: 239.8998\n",
      "Epoch 79/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 406.3309 - val_loss: 270.8820\n",
      "Epoch 80/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 489.9063 - val_loss: 218.2407\n",
      "Epoch 81/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 579.5417 - val_loss: 438.9644\n",
      "Epoch 82/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 837.2184 - val_loss: 342.4742\n",
      "Epoch 83/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 462.1609 - val_loss: 311.8296\n",
      "Epoch 84/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 424.1825 - val_loss: 214.1479\n",
      "Epoch 85/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 384.8317 - val_loss: 260.0876\n",
      "Epoch 86/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 448.7028 - val_loss: 248.8876\n",
      "Epoch 87/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 383.9268 - val_loss: 310.4935\n",
      "Epoch 88/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 438.5531 - val_loss: 204.1221\n",
      "Epoch 89/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 451.6107 - val_loss: 382.0739\n",
      "Epoch 90/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 388.6951 - val_loss: 486.2245\n",
      "Epoch 91/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 417.4310 - val_loss: 583.3914\n",
      "Epoch 92/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 678.8846 - val_loss: 367.8790\n",
      "Epoch 93/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 364.6995 - val_loss: 350.0027\n",
      "Epoch 94/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 550.0962 - val_loss: 208.1512\n",
      "Epoch 95/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 401.8668 - val_loss: 260.1647\n",
      "Epoch 96/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 488.1844 - val_loss: 331.2100\n",
      "Epoch 97/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 471.2348 - val_loss: 505.4695\n",
      "Epoch 98/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 431.2389 - val_loss: 679.7917\n",
      "Epoch 99/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 455.3355 - val_loss: 340.1792\n",
      "Epoch 100/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 450.3939 - val_loss: 294.5739\n",
      "Epoch 101/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 472.6048 - val_loss: 321.7151\n",
      "Epoch 102/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 446.5175 - val_loss: 407.1591\n",
      "Epoch 103/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 582.8402 - val_loss: 237.6355\n",
      "Epoch 104/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 436.3183 - val_loss: 245.7184\n",
      "Epoch 105/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 624.1469 - val_loss: 424.7806\n",
      "Epoch 106/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 427.5368 - val_loss: 265.3580\n",
      "Epoch 107/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 418.3748 - val_loss: 209.6499\n",
      "Epoch 108/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 362.0194 - val_loss: 180.5974\n",
      "Epoch 109/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 497.9010 - val_loss: 350.2722\n",
      "Epoch 110/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 402.4329 - val_loss: 255.5505\n",
      "Epoch 111/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 383.9769 - val_loss: 174.9988\n",
      "Epoch 112/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 366.9258 - val_loss: 230.0213\n",
      "Epoch 113/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 406.8245 - val_loss: 178.1380\n",
      "Epoch 114/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 880.8696 - val_loss: 262.5162\n",
      "Epoch 115/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 361.8515 - val_loss: 477.5080\n",
      "Epoch 116/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 430.7390 - val_loss: 210.2336\n",
      "Epoch 117/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 421.4819 - val_loss: 170.8891\n",
      "Epoch 118/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 391.1066 - val_loss: 265.4277\n",
      "Epoch 119/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 411.2276 - val_loss: 408.1398\n",
      "Epoch 120/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 383.0054 - val_loss: 274.7397\n",
      "Epoch 121/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 455.6357 - val_loss: 260.8668\n",
      "Epoch 122/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 378.0401 - val_loss: 475.4686\n",
      "Epoch 123/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 427.4929 - val_loss: 178.8634\n",
      "Epoch 124/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 313.1260 - val_loss: 187.3103\n",
      "Epoch 125/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 366.4493 - val_loss: 202.3090\n",
      "Epoch 126/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 389.2281 - val_loss: 178.3101\n",
      "Epoch 127/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 434.4859 - val_loss: 212.7914\n",
      "Epoch 128/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 464.7624 - val_loss: 337.0676\n",
      "Epoch 129/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 426.2129 - val_loss: 252.0753\n",
      "Epoch 130/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 385.6519 - val_loss: 159.2309\n",
      "Epoch 131/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 379.3121 - val_loss: 371.5173\n",
      "Epoch 132/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 478.4650 - val_loss: 1080.4335\n",
      "Epoch 133/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 856.9111 - val_loss: 405.5546\n",
      "Epoch 134/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 415.9805 - val_loss: 275.7146\n",
      "Epoch 135/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 427.2288 - val_loss: 306.4318\n",
      "Epoch 136/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 382.9794 - val_loss: 299.2410\n",
      "Epoch 137/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 387.5645 - val_loss: 208.3405\n",
      "Epoch 138/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 373.1577 - val_loss: 324.5395\n",
      "Epoch 139/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 364.9138 - val_loss: 241.3492\n",
      "Epoch 140/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 434.8429 - val_loss: 264.3860\n",
      "Epoch 141/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 667.0411 - val_loss: 188.3812\n",
      "Epoch 142/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 369.4409 - val_loss: 160.3318\n",
      "Epoch 143/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 402.1321 - val_loss: 164.3685\n",
      "Epoch 144/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 370.2507 - val_loss: 722.9468\n",
      "Epoch 145/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 405.4113 - val_loss: 397.5695\n",
      "Epoch 146/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 378.7892 - val_loss: 369.3048\n",
      "Epoch 147/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 332.4870 - val_loss: 171.6564\n",
      "Epoch 148/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 323.1339 - val_loss: 317.8939\n",
      "Epoch 149/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 375.8205 - val_loss: 172.6998\n",
      "Epoch 150/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 330.7587 - val_loss: 236.2522\n",
      "Epoch 151/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 378.8014 - val_loss: 236.3465\n",
      "Epoch 152/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 383.9813 - val_loss: 258.8440\n",
      "Epoch 153/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 345.5631 - val_loss: 173.6239\n",
      "Epoch 154/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 318.6934 - val_loss: 226.1141\n",
      "Epoch 155/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 356.0238 - val_loss: 451.6607\n",
      "Epoch 156/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 474.9850 - val_loss: 395.4716\n",
      "Epoch 157/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 388.6042 - val_loss: 393.3872\n",
      "Epoch 158/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 505.2452 - val_loss: 338.5903\n",
      "Epoch 159/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 381.3467 - val_loss: 429.8561\n",
      "Epoch 160/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 424.9409 - val_loss: 289.8496\n",
      "Epoch 161/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 351.1176 - val_loss: 244.9048\n",
      "Epoch 162/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 374.9512 - val_loss: 310.4054\n",
      "Epoch 163/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 348.5233 - val_loss: 734.1678\n",
      "Epoch 164/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 796.9301 - val_loss: 237.7150\n",
      "Epoch 165/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 539.0856 - val_loss: 206.1410\n",
      "Epoch 166/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 418.4402 - val_loss: 190.8216\n",
      "Epoch 167/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 367.9704 - val_loss: 167.2906\n",
      "Epoch 168/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 325.6450 - val_loss: 238.4499\n",
      "Epoch 169/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 310.4984 - val_loss: 218.5241\n",
      "Epoch 170/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 311.3789 - val_loss: 250.9037\n",
      "Epoch 171/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 353.0821 - val_loss: 626.7239\n",
      "Epoch 172/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 359.9311 - val_loss: 174.5959\n",
      "Epoch 173/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 363.9750 - val_loss: 268.0701\n",
      "Epoch 174/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 371.1458 - val_loss: 420.0117\n",
      "Epoch 175/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 407.0085 - val_loss: 198.1045\n",
      "Epoch 176/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 360.6201 - val_loss: 273.4634\n",
      "Epoch 177/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 338.7617 - val_loss: 478.8943\n",
      "Epoch 178/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 355.3320 - val_loss: 445.5555\n",
      "Epoch 179/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 424.5886 - val_loss: 133.7604\n",
      "Epoch 180/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 530.7039 - val_loss: 255.8502\n",
      "Epoch 181/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 397.6935 - val_loss: 275.4270\n",
      "Epoch 182/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 374.6797 - val_loss: 179.3904\n",
      "Epoch 183/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 351.4467 - val_loss: 185.9835\n",
      "Epoch 184/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 327.1947 - val_loss: 243.4939\n",
      "Epoch 185/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 322.2091 - val_loss: 218.0164\n",
      "Epoch 186/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 327.4887 - val_loss: 192.6677\n",
      "Epoch 187/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 326.3413 - val_loss: 149.6348\n",
      "Epoch 188/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 337.3626 - val_loss: 193.2249\n",
      "Epoch 189/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 348.2891 - val_loss: 226.6949\n",
      "Epoch 190/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 316.6835 - val_loss: 188.1588\n",
      "Epoch 191/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 478.7904 - val_loss: 490.7208\n",
      "Epoch 192/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 357.4409 - val_loss: 488.9486\n",
      "Epoch 193/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 529.4571 - val_loss: 285.4583\n",
      "Epoch 194/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 388.5409 - val_loss: 195.3809\n",
      "Epoch 195/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 356.8099 - val_loss: 373.8648\n",
      "Epoch 196/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 359.8707 - val_loss: 521.4685\n",
      "Epoch 197/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 500.3029 - val_loss: 205.9582\n",
      "Epoch 198/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 302.6958 - val_loss: 148.7321\n",
      "Epoch 199/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 328.4686 - val_loss: 239.4585\n",
      "Epoch 200/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 405.7665 - val_loss: 270.2962\n",
      "Epoch 201/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 411.2441 - val_loss: 264.7738\n",
      "Epoch 202/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 391.7535 - val_loss: 234.7442\n",
      "Epoch 203/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 305.8632 - val_loss: 206.5918\n",
      "Epoch 204/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 288.1822 - val_loss: 294.9103\n",
      "Epoch 205/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 308.9499 - val_loss: 259.6517\n",
      "Epoch 206/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 303.4873 - val_loss: 194.7644\n",
      "Epoch 207/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 311.6873 - val_loss: 167.1589\n",
      "Epoch 208/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 330.5514 - val_loss: 589.5753\n",
      "Epoch 209/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 433.2045 - val_loss: 264.5658\n",
      "Epoch 210/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 326.9831 - val_loss: 366.8568\n",
      "Epoch 211/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 495.7146 - val_loss: 348.1086\n",
      "Epoch 212/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 315.7665 - val_loss: 186.0685\n",
      "Epoch 213/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 300.5174 - val_loss: 165.7593\n",
      "Epoch 214/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 305.9152 - val_loss: 296.0485\n",
      "Epoch 215/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 318.6163 - val_loss: 156.3740\n",
      "Epoch 216/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 321.6103 - val_loss: 164.3521\n",
      "Epoch 217/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 317.7133 - val_loss: 202.1429\n",
      "Epoch 218/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 333.9408 - val_loss: 201.2397\n",
      "Epoch 219/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 367.9301 - val_loss: 272.3045\n",
      "Epoch 220/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 338.0964 - val_loss: 138.2977\n",
      "Epoch 221/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 332.0500 - val_loss: 316.3444\n",
      "Epoch 222/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 601.4553 - val_loss: 215.7885\n",
      "Epoch 223/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 351.0044 - val_loss: 296.9593\n",
      "Epoch 224/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 348.7645 - val_loss: 159.3055\n",
      "Epoch 225/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 317.6802 - val_loss: 254.5467\n",
      "Epoch 226/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 359.7690 - val_loss: 974.4391\n",
      "Epoch 227/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 514.9279 - val_loss: 433.2498\n",
      "Epoch 228/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 362.7613 - val_loss: 415.1852\n",
      "Epoch 229/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 354.1556 - val_loss: 180.1829\n",
      "Epoch 230/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 320.8499 - val_loss: 269.2061\n",
      "Epoch 231/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 359.3379 - val_loss: 128.3118\n",
      "Epoch 232/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 380.8494 - val_loss: 218.1639\n",
      "Epoch 233/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 309.2263 - val_loss: 225.4713\n",
      "Epoch 234/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 300.7548 - val_loss: 209.6252\n",
      "Epoch 235/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 313.5000 - val_loss: 233.4648\n",
      "Epoch 236/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 351.4978 - val_loss: 363.9926\n",
      "Epoch 237/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 339.1375 - val_loss: 165.2144\n",
      "Epoch 238/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 294.6255 - val_loss: 493.2733\n",
      "Epoch 239/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 394.4835 - val_loss: 243.7320\n",
      "Epoch 240/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 298.6923 - val_loss: 205.9140\n",
      "Epoch 241/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 357.9200 - val_loss: 153.5442\n",
      "Epoch 242/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 315.6550 - val_loss: 264.1104\n",
      "Epoch 243/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 346.8401 - val_loss: 206.2180\n",
      "Epoch 244/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 281.3374 - val_loss: 130.3531\n",
      "Epoch 245/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 314.1224 - val_loss: 247.3305\n",
      "Epoch 246/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 368.4148 - val_loss: 331.2970\n",
      "Epoch 247/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 350.1183 - val_loss: 230.1956\n",
      "Epoch 248/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 392.9092 - val_loss: 303.4182\n",
      "Epoch 249/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 624.3088 - val_loss: 160.3239\n",
      "Epoch 250/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 353.7742 - val_loss: 195.9752\n",
      "Epoch 251/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 299.7077 - val_loss: 287.5768\n",
      "Epoch 252/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 328.8043 - val_loss: 150.5099\n",
      "Epoch 253/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 286.2677 - val_loss: 289.2712\n",
      "Epoch 254/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 290.9370 - val_loss: 169.5718\n",
      "Epoch 255/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 294.5349 - val_loss: 195.8134\n",
      "Epoch 256/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 312.1163 - val_loss: 189.5835\n",
      "Epoch 257/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 307.2404 - val_loss: 862.7910\n",
      "Epoch 258/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 674.1748 - val_loss: 600.9225\n",
      "Epoch 259/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 513.3326 - val_loss: 276.4088\n",
      "Epoch 260/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 360.8195 - val_loss: 200.3810\n",
      "Epoch 261/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 376.8005 - val_loss: 306.0537\n",
      "Epoch 262/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 381.6367 - val_loss: 261.7837\n",
      "Epoch 263/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 350.6421 - val_loss: 150.0105\n",
      "Epoch 264/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 394.8358 - val_loss: 159.1885\n",
      "Epoch 265/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 419.4409 - val_loss: 112.6355\n",
      "Epoch 266/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 330.5261 - val_loss: 169.6544\n",
      "Epoch 267/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 339.9847 - val_loss: 237.6504\n",
      "Epoch 268/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 372.0332 - val_loss: 367.9428\n",
      "Epoch 269/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 330.9700 - val_loss: 491.9876\n",
      "Epoch 270/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 600.6353 - val_loss: 232.1999\n",
      "Epoch 271/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 316.8337 - val_loss: 200.0802\n",
      "Epoch 272/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 333.5351 - val_loss: 347.9066\n",
      "Epoch 273/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 333.5256 - val_loss: 397.7647\n",
      "Epoch 274/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 315.4619 - val_loss: 167.9193\n",
      "Epoch 275/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 366.0002 - val_loss: 237.0450\n",
      "Epoch 276/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 361.6470 - val_loss: 183.1149\n",
      "Epoch 277/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 296.4799 - val_loss: 260.7641\n",
      "Epoch 278/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 525.4811 - val_loss: 472.8321\n",
      "Epoch 279/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 408.4843 - val_loss: 185.8890\n",
      "Epoch 280/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 284.6029 - val_loss: 374.9199\n",
      "Epoch 281/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 279.6001 - val_loss: 173.5984\n",
      "Epoch 282/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 321.2946 - val_loss: 152.3092\n",
      "Epoch 283/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 404.0110 - val_loss: 334.6400\n",
      "Epoch 284/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 332.3673 - val_loss: 221.2802\n",
      "Epoch 285/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 355.0894 - val_loss: 167.7986\n",
      "Epoch 286/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 321.7161 - val_loss: 277.2675\n",
      "Epoch 287/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 340.2884 - val_loss: 146.4365\n",
      "Epoch 288/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 359.8837 - val_loss: 517.3457\n",
      "Epoch 289/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 316.9198 - val_loss: 148.5148\n",
      "Epoch 290/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 318.7938 - val_loss: 113.7846\n",
      "Epoch 291/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 325.6753 - val_loss: 273.1252\n",
      "Epoch 292/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 315.7238 - val_loss: 172.5837\n",
      "Epoch 293/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 289.5721 - val_loss: 184.2202\n",
      "Epoch 294/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 321.5178 - val_loss: 544.6186\n",
      "Epoch 295/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 368.9609 - val_loss: 187.4696\n",
      "Epoch 296/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 275.2419 - val_loss: 168.8766\n",
      "Epoch 297/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 314.6982 - val_loss: 360.8264\n",
      "Epoch 298/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 349.4525 - val_loss: 241.8341\n",
      "Epoch 299/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 313.8845 - val_loss: 207.1625\n",
      "Epoch 300/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 262.6047 - val_loss: 347.4160\n",
      "Epoch 301/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 299.2144 - val_loss: 267.5690\n",
      "Epoch 302/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 306.4417 - val_loss: 197.9524\n",
      "Epoch 303/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 422.4473 - val_loss: 234.3164\n",
      "Epoch 304/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 455.1213 - val_loss: 202.6766\n",
      "Epoch 305/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 304.9264 - val_loss: 143.3094\n",
      "Epoch 306/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 317.3624 - val_loss: 214.1462\n",
      "Epoch 307/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 288.8683 - val_loss: 194.5525\n",
      "Epoch 308/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 300.9349 - val_loss: 152.9258\n",
      "Epoch 309/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 476.8482 - val_loss: 242.0083\n",
      "Epoch 310/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 377.4178 - val_loss: 213.1284\n",
      "Epoch 311/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 388.7810 - val_loss: 271.9716\n",
      "Epoch 312/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 318.6855 - val_loss: 223.7798\n",
      "Epoch 313/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 309.2505 - val_loss: 204.7279\n",
      "Epoch 314/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 323.8674 - val_loss: 218.1364\n",
      "Epoch 315/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 330.1360 - val_loss: 285.3857\n",
      "Epoch 316/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 300.5735 - val_loss: 190.3841\n",
      "Epoch 317/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 301.2668 - val_loss: 192.0186\n",
      "Epoch 318/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 310.5426 - val_loss: 374.3806\n",
      "Epoch 319/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 381.0960 - val_loss: 316.8260\n",
      "Epoch 320/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 303.1793 - val_loss: 320.5744\n",
      "Epoch 321/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 424.5437 - val_loss: 305.9799\n",
      "Epoch 322/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 321.6875 - val_loss: 332.9256\n",
      "Epoch 323/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 316.7882 - val_loss: 238.4374\n",
      "Epoch 324/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 343.7260 - val_loss: 235.1786\n",
      "Epoch 325/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 385.0885 - val_loss: 403.5521\n",
      "Epoch 326/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 348.3533 - val_loss: 296.4799\n",
      "Epoch 327/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 324.7928 - val_loss: 322.8481\n",
      "Epoch 328/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 293.6876 - val_loss: 168.0089\n",
      "Epoch 329/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 334.7480 - val_loss: 276.6467\n",
      "Epoch 330/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 297.2351 - val_loss: 153.0498\n",
      "Epoch 331/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 279.2717 - val_loss: 243.7699\n",
      "Epoch 332/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 294.4579 - val_loss: 281.1079\n",
      "Epoch 333/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 305.9635 - val_loss: 223.2156\n",
      "Epoch 334/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 275.5136 - val_loss: 377.5591\n",
      "Epoch 335/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 363.7537 - val_loss: 317.7207\n",
      "Epoch 336/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 364.4987 - val_loss: 183.2784\n",
      "Epoch 337/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 336.3064 - val_loss: 251.8709\n",
      "Epoch 338/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 290.9225 - val_loss: 183.5491\n",
      "Epoch 339/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 321.9796 - val_loss: 207.6087\n",
      "Epoch 340/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 263.1496 - val_loss: 215.0330\n",
      "Epoch 341/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 263.3350 - val_loss: 178.5943\n",
      "Epoch 342/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 274.8689 - val_loss: 317.6626\n",
      "Epoch 343/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 361.0182 - val_loss: 202.6105\n",
      "Epoch 344/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 298.0626 - val_loss: 157.2439\n",
      "Epoch 345/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 281.0044 - val_loss: 300.4355\n",
      "Epoch 346/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 294.7898 - val_loss: 245.0361\n",
      "Epoch 347/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 288.4484 - val_loss: 153.8804\n",
      "Epoch 348/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 264.9510 - val_loss: 219.4015\n",
      "Epoch 349/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 275.8485 - val_loss: 187.6117\n",
      "Epoch 350/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 299.3900 - val_loss: 223.4764\n",
      "Epoch 351/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 302.2790 - val_loss: 189.5500\n",
      "Epoch 352/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 293.7158 - val_loss: 315.0722\n",
      "Epoch 353/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 355.4843 - val_loss: 297.1972\n",
      "Epoch 354/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 326.8349 - val_loss: 182.9721\n",
      "Epoch 355/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 290.7000 - val_loss: 155.3768\n",
      "Epoch 356/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 277.1157 - val_loss: 168.6871\n",
      "Epoch 357/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 253.1540 - val_loss: 152.9585\n",
      "Epoch 358/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 350.2169 - val_loss: 188.5140\n",
      "Epoch 359/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 322.6176 - val_loss: 113.2271\n",
      "Epoch 360/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 309.9833 - val_loss: 245.8872\n",
      "Epoch 361/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 305.6615 - val_loss: 153.2818\n",
      "Epoch 362/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 347.7834 - val_loss: 163.6657\n",
      "Epoch 363/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 249.1779 - val_loss: 235.5453\n",
      "Epoch 364/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 273.1010 - val_loss: 170.6080\n",
      "Epoch 365/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 258.1551 - val_loss: 265.1250\n",
      "Epoch 366/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 272.3257 - val_loss: 443.6094\n",
      "Epoch 367/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 310.7747 - val_loss: 297.3940\n",
      "Epoch 368/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 284.1412 - val_loss: 199.0639\n",
      "Epoch 369/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 295.5573 - val_loss: 216.5796\n",
      "Epoch 370/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 290.6944 - val_loss: 156.3284\n",
      "Epoch 371/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 256.5348 - val_loss: 188.4914\n",
      "Epoch 372/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 255.5213 - val_loss: 161.8794\n",
      "Epoch 373/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 325.3193 - val_loss: 148.7090\n",
      "Epoch 374/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 298.9756 - val_loss: 163.0486\n",
      "Epoch 375/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 259.6042 - val_loss: 199.0916\n",
      "Epoch 376/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 244.9420 - val_loss: 181.3009\n",
      "Epoch 377/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 276.3846 - val_loss: 153.5565\n",
      "Epoch 378/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 262.9569 - val_loss: 139.0020\n",
      "Epoch 379/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 228.0824 - val_loss: 205.6588\n",
      "Epoch 380/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 249.1260 - val_loss: 164.3102\n",
      "Epoch 381/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 296.0894 - val_loss: 198.0897\n",
      "Epoch 382/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 297.9881 - val_loss: 153.8149\n",
      "Epoch 383/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 276.4625 - val_loss: 114.9358\n",
      "Epoch 384/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 387.5296 - val_loss: 204.1505\n",
      "Epoch 385/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 291.5511 - val_loss: 163.0983\n",
      "Epoch 386/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 376.8307 - val_loss: 148.4891\n",
      "Epoch 387/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 236.0813 - val_loss: 192.8824\n",
      "Epoch 388/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 237.6301 - val_loss: 182.6567\n",
      "Epoch 389/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 249.7282 - val_loss: 127.4026\n",
      "Epoch 390/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 267.8690 - val_loss: 218.8550\n",
      "Epoch 391/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 249.9367 - val_loss: 174.4627\n",
      "Epoch 392/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 258.6600 - val_loss: 164.1984\n",
      "Epoch 393/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 251.3245 - val_loss: 196.4285\n",
      "Epoch 394/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 305.6487 - val_loss: 378.9547\n",
      "Epoch 395/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 292.6508 - val_loss: 153.0338\n",
      "Epoch 396/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 394.7203 - val_loss: 176.9729\n",
      "Epoch 397/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 315.5618 - val_loss: 215.9593\n",
      "Epoch 398/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 308.7744 - val_loss: 256.2818\n",
      "Epoch 399/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 275.3925 - val_loss: 148.4896\n",
      "Epoch 400/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 296.0569 - val_loss: 178.4520\n",
      "Epoch 401/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 271.5382 - val_loss: 187.6328\n",
      "Epoch 402/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 261.6977 - val_loss: 188.5743\n",
      "Epoch 403/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 263.4781 - val_loss: 204.7269\n",
      "Epoch 404/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 277.6785 - val_loss: 306.9313\n",
      "Epoch 405/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 300.7982 - val_loss: 173.9944\n",
      "Epoch 406/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 259.9812 - val_loss: 506.7425\n",
      "Epoch 407/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 281.7473 - val_loss: 479.7005\n",
      "Epoch 408/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 283.9741 - val_loss: 153.8968\n",
      "Epoch 409/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 283.9803 - val_loss: 256.2859\n",
      "Epoch 410/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 268.3444 - val_loss: 444.2090\n",
      "Epoch 411/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 357.7151 - val_loss: 220.0806\n",
      "Epoch 412/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 492.5296 - val_loss: 597.8589\n",
      "Epoch 413/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 439.1539 - val_loss: 309.7395\n",
      "Epoch 414/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 275.7261 - val_loss: 227.3059\n",
      "Epoch 415/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 289.1338 - val_loss: 198.1928\n",
      "Epoch 416/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 281.2300 - val_loss: 186.0057\n",
      "Epoch 417/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 237.4200 - val_loss: 259.2868\n",
      "Epoch 418/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 293.0720 - val_loss: 161.3554\n",
      "Epoch 419/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 282.3026 - val_loss: 184.2875\n",
      "Epoch 420/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 253.9557 - val_loss: 233.4362\n",
      "Epoch 421/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 245.9814 - val_loss: 184.3323\n",
      "Epoch 422/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 295.5173 - val_loss: 182.6573\n",
      "Epoch 423/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 264.9355 - val_loss: 178.0893\n",
      "Epoch 424/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 265.3296 - val_loss: 208.3473\n",
      "Epoch 425/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 242.5302 - val_loss: 146.0566\n",
      "Epoch 426/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 243.9079 - val_loss: 316.7846\n",
      "Epoch 427/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 315.2902 - val_loss: 279.1958\n",
      "Epoch 428/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 287.3648 - val_loss: 154.4039\n",
      "Epoch 429/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 227.6845 - val_loss: 168.4991\n",
      "Epoch 430/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 246.8824 - val_loss: 459.9385\n",
      "Epoch 431/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 270.9002 - val_loss: 233.7108\n",
      "Epoch 432/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 231.3219 - val_loss: 190.0200\n",
      "Epoch 433/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 232.4107 - val_loss: 150.7329\n",
      "Epoch 434/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 276.5195 - val_loss: 288.3091\n",
      "Epoch 435/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 251.0616 - val_loss: 179.0941\n",
      "Epoch 436/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 335.6686 - val_loss: 452.2140\n",
      "Epoch 437/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 404.9283 - val_loss: 157.5618\n",
      "Epoch 438/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 237.2238 - val_loss: 266.8840\n",
      "Epoch 439/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 252.4981 - val_loss: 133.4424\n",
      "Epoch 440/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 252.1184 - val_loss: 127.8510\n",
      "Epoch 441/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 268.5933 - val_loss: 201.4404\n",
      "Epoch 442/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 221.6188 - val_loss: 125.9016\n",
      "Epoch 443/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 273.3806 - val_loss: 188.9595\n",
      "Epoch 444/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 270.9739 - val_loss: 564.3295\n",
      "Epoch 445/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 334.3682 - val_loss: 299.7032\n",
      "Epoch 446/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 236.7536 - val_loss: 123.2997\n",
      "Epoch 447/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 249.7484 - val_loss: 165.8697\n",
      "Epoch 448/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 235.3449 - val_loss: 201.8537\n",
      "Epoch 449/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 216.9712 - val_loss: 202.5478\n",
      "Epoch 450/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 246.5650 - val_loss: 270.7119\n",
      "Epoch 451/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 242.0202 - val_loss: 162.1720\n",
      "Epoch 452/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 250.5883 - val_loss: 195.7541\n",
      "Epoch 453/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 338.1738 - val_loss: 194.0993\n",
      "Epoch 454/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 271.9647 - val_loss: 282.9972\n",
      "Epoch 455/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 272.7661 - val_loss: 226.5099\n",
      "Epoch 456/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 283.3167 - val_loss: 145.2300\n",
      "Epoch 457/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 262.5375 - val_loss: 240.4040\n",
      "Epoch 458/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 245.9547 - val_loss: 350.0953\n",
      "Epoch 459/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 270.8836 - val_loss: 149.3235\n",
      "Epoch 460/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 249.3453 - val_loss: 192.8679\n",
      "Epoch 461/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 237.5607 - val_loss: 223.4450\n",
      "Epoch 462/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 230.2256 - val_loss: 192.8167\n",
      "Epoch 463/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 267.8808 - val_loss: 166.7048\n",
      "Epoch 464/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 234.7614 - val_loss: 298.4646\n",
      "Epoch 465/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 267.5506 - val_loss: 256.5627\n",
      "Epoch 466/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 249.3978 - val_loss: 126.5093\n",
      "Epoch 467/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 224.9743 - val_loss: 195.6045\n",
      "Epoch 468/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 248.3131 - val_loss: 176.7785\n",
      "Epoch 469/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 238.4406 - val_loss: 408.6785\n",
      "Epoch 470/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 280.8248 - val_loss: 149.4087\n",
      "Epoch 471/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 229.8129 - val_loss: 215.4922\n",
      "Epoch 472/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 231.2098 - val_loss: 287.6287\n",
      "Epoch 473/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 216.8955 - val_loss: 159.6060\n",
      "Epoch 474/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 228.0306 - val_loss: 224.7842\n",
      "Epoch 475/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 234.3430 - val_loss: 251.1862\n",
      "Epoch 476/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 241.6001 - val_loss: 149.2828\n",
      "Epoch 477/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 242.7474 - val_loss: 258.3646\n",
      "Epoch 478/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 276.9716 - val_loss: 388.8239\n",
      "Epoch 479/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 254.5707 - val_loss: 221.5100\n",
      "Epoch 480/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 244.4750 - val_loss: 287.5759\n",
      "Epoch 481/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 232.8286 - val_loss: 239.9374\n",
      "Epoch 482/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 225.5186 - val_loss: 187.0637\n",
      "Epoch 483/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 250.3153 - val_loss: 361.9807\n",
      "Epoch 484/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 251.8628 - val_loss: 154.6717\n",
      "Epoch 485/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 245.9332 - val_loss: 252.6179\n",
      "Epoch 486/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 338.3017 - val_loss: 456.7601\n",
      "Epoch 487/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 263.3012 - val_loss: 158.1889\n",
      "Epoch 488/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 249.3282 - val_loss: 174.3583\n",
      "Epoch 489/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 242.4411 - val_loss: 278.9214\n",
      "Epoch 490/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 251.6499 - val_loss: 302.9502\n",
      "Epoch 491/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 244.6407 - val_loss: 122.4017\n",
      "Epoch 492/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 234.7966 - val_loss: 203.8528\n",
      "Epoch 493/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 323.6058 - val_loss: 170.8539\n",
      "Epoch 494/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 262.3438 - val_loss: 288.7952\n",
      "Epoch 495/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 229.9474 - val_loss: 218.6564\n",
      "Epoch 496/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 212.9969 - val_loss: 132.2721\n",
      "Epoch 497/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 256.2471 - val_loss: 142.0282\n",
      "Epoch 498/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 322.4345 - val_loss: 190.8546\n",
      "Epoch 499/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 327.0341 - val_loss: 267.3562\n",
      "Epoch 500/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 259.4114 - val_loss: 193.7406\n",
      "Epoch 501/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 255.4853 - val_loss: 185.5143\n",
      "Epoch 502/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 232.4916 - val_loss: 307.2466\n",
      "Epoch 503/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 245.7745 - val_loss: 221.5771\n",
      "Epoch 504/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 256.0215 - val_loss: 245.3087\n",
      "Epoch 505/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 261.3083 - val_loss: 163.1942\n",
      "Epoch 506/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 263.0375 - val_loss: 187.4430\n",
      "Epoch 507/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 230.2137 - val_loss: 231.8961\n",
      "Epoch 508/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 224.8671 - val_loss: 97.7064\n",
      "Epoch 509/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 236.5512 - val_loss: 139.1475\n",
      "Epoch 510/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 239.8130 - val_loss: 303.9604\n",
      "Epoch 511/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 239.0339 - val_loss: 377.5769\n",
      "Epoch 512/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 275.5814 - val_loss: 125.3995\n",
      "Epoch 513/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 247.7631 - val_loss: 123.5191\n",
      "Epoch 514/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 346.8021 - val_loss: 215.5016\n",
      "Epoch 515/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 298.5052 - val_loss: 381.6387\n",
      "Epoch 516/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 286.7891 - val_loss: 337.4505\n",
      "Epoch 517/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 280.5532 - val_loss: 162.9702\n",
      "Epoch 518/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 270.8195 - val_loss: 147.8072\n",
      "Epoch 519/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 216.3737 - val_loss: 167.7066\n",
      "Epoch 520/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 284.4159 - val_loss: 227.5428\n",
      "Epoch 521/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 293.3871 - val_loss: 146.8560\n",
      "Epoch 522/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 258.7284 - val_loss: 121.0019\n",
      "Epoch 523/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 221.6446 - val_loss: 130.1535\n",
      "Epoch 524/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 243.2048 - val_loss: 155.1421\n",
      "Epoch 525/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 230.2777 - val_loss: 164.9746\n",
      "Epoch 526/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 235.2375 - val_loss: 105.4289\n",
      "Epoch 527/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 252.4526 - val_loss: 146.8874\n",
      "Epoch 528/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 223.7189 - val_loss: 161.0538\n",
      "Epoch 529/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 240.0474 - val_loss: 174.3731\n",
      "Epoch 530/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 227.2023 - val_loss: 195.4832\n",
      "Epoch 531/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 240.5021 - val_loss: 426.9947\n",
      "Epoch 532/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 289.8949 - val_loss: 313.9732\n",
      "Epoch 533/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 254.4748 - val_loss: 262.9627\n",
      "Epoch 534/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 224.4718 - val_loss: 248.2590\n",
      "Epoch 535/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 236.3458 - val_loss: 189.2014\n",
      "Epoch 536/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 239.8870 - val_loss: 216.0771\n",
      "Epoch 537/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 237.6873 - val_loss: 235.7793\n",
      "Epoch 538/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 239.2249 - val_loss: 221.0039\n",
      "Epoch 539/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 219.0755 - val_loss: 204.4165\n",
      "Epoch 540/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 219.4396 - val_loss: 156.6022\n",
      "Epoch 541/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 250.7866 - val_loss: 134.9644\n",
      "Epoch 542/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 229.7080 - val_loss: 340.2852\n",
      "Epoch 543/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 245.6286 - val_loss: 166.5484\n",
      "Epoch 544/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 216.3078 - val_loss: 171.2159\n",
      "Epoch 545/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 247.5806 - val_loss: 297.2227\n",
      "Epoch 546/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 246.8268 - val_loss: 174.4972\n",
      "Epoch 547/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 214.8809 - val_loss: 229.0477\n",
      "Epoch 548/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 235.2847 - val_loss: 150.4352\n",
      "Epoch 549/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 264.4902 - val_loss: 234.8637\n",
      "Epoch 550/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 212.3080 - val_loss: 186.8926\n",
      "Epoch 551/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 221.6145 - val_loss: 172.2485\n",
      "Epoch 552/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 285.1472 - val_loss: 159.2280\n",
      "Epoch 553/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 268.3689 - val_loss: 457.6154\n",
      "Epoch 554/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 406.6753 - val_loss: 314.4363\n",
      "Epoch 555/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 337.9627 - val_loss: 248.2006\n",
      "Epoch 556/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 245.0097 - val_loss: 236.7407\n",
      "Epoch 557/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 262.1570 - val_loss: 227.9290\n",
      "Epoch 558/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 303.0408 - val_loss: 300.1452\n",
      "Epoch 559/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 295.9697 - val_loss: 371.0134\n",
      "Epoch 560/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 350.4086 - val_loss: 181.7117\n",
      "Epoch 561/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 304.7070 - val_loss: 230.8994\n",
      "Epoch 562/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 296.5033 - val_loss: 242.8208\n",
      "Epoch 563/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 271.7080 - val_loss: 309.7592\n",
      "Epoch 564/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 258.3754 - val_loss: 245.9720\n",
      "Epoch 565/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 278.8572 - val_loss: 191.3519\n",
      "Epoch 566/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 255.2152 - val_loss: 255.9609\n",
      "Epoch 567/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 247.1171 - val_loss: 308.3397\n",
      "Epoch 568/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 243.9644 - val_loss: 357.6514\n",
      "Epoch 569/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 282.0591 - val_loss: 206.7647\n",
      "Epoch 570/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 263.9260 - val_loss: 214.4823\n",
      "Epoch 571/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 270.3203 - val_loss: 248.7597\n",
      "Epoch 572/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 219.1351 - val_loss: 203.0918\n",
      "Epoch 573/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 233.1326 - val_loss: 197.1097\n",
      "Epoch 574/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 231.7705 - val_loss: 214.9260\n",
      "Epoch 575/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 217.7904 - val_loss: 348.7261\n",
      "Epoch 576/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 310.2150 - val_loss: 275.6078\n",
      "Epoch 577/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 222.2369 - val_loss: 183.5326\n",
      "Epoch 578/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 230.0474 - val_loss: 242.9288\n",
      "Epoch 579/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 236.7429 - val_loss: 255.6312\n",
      "Epoch 580/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 216.3987 - val_loss: 322.9880\n",
      "Epoch 581/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 240.7632 - val_loss: 263.9282\n",
      "Epoch 582/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 221.4183 - val_loss: 327.5944\n",
      "Epoch 583/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 252.8658 - val_loss: 338.1414\n",
      "Epoch 584/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 244.3025 - val_loss: 250.9122\n",
      "Epoch 585/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 234.9062 - val_loss: 271.1718\n",
      "Epoch 586/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 212.6802 - val_loss: 280.5970\n",
      "Epoch 587/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 235.8738 - val_loss: 343.4025\n",
      "Epoch 588/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 241.0467 - val_loss: 210.3545\n",
      "Epoch 589/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 230.8354 - val_loss: 310.7162\n",
      "Epoch 590/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 285.6963 - val_loss: 371.4546\n",
      "Epoch 591/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 220.2900 - val_loss: 222.4804\n",
      "Epoch 592/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 238.8624 - val_loss: 193.8819\n",
      "Epoch 593/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 230.2029 - val_loss: 292.5748\n",
      "Epoch 594/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 254.4898 - val_loss: 250.0271\n",
      "Epoch 595/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 233.2413 - val_loss: 195.9455\n",
      "Epoch 596/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 250.2743 - val_loss: 349.3477\n",
      "Epoch 597/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 264.6204 - val_loss: 175.2125\n",
      "Epoch 598/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 241.3748 - val_loss: 288.4557\n",
      "Epoch 599/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 235.0075 - val_loss: 257.6752\n",
      "Epoch 600/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 234.4118 - val_loss: 213.2995\n",
      "Epoch 601/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 207.1135 - val_loss: 320.6469\n",
      "Epoch 602/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 247.8918 - val_loss: 235.7834\n",
      "Epoch 603/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 227.1825 - val_loss: 188.5788\n",
      "Epoch 604/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 208.1315 - val_loss: 199.1330\n",
      "Epoch 605/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 254.1107 - val_loss: 259.7535\n",
      "Epoch 606/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 228.6424 - val_loss: 369.5282\n",
      "Epoch 607/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 277.4552 - val_loss: 515.6559\n",
      "Epoch 608/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 218.7120 - val_loss: 287.5300\n",
      "Epoch 609/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 246.9891 - val_loss: 320.5773\n",
      "Epoch 610/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 258.5997 - val_loss: 214.7464\n",
      "Epoch 611/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 232.4789 - val_loss: 252.2713\n",
      "Epoch 612/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 241.5851 - val_loss: 278.5671\n",
      "Epoch 613/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 206.2813 - val_loss: 534.4026\n",
      "Epoch 614/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 296.0063 - val_loss: 205.1736\n",
      "Epoch 615/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 247.7415 - val_loss: 273.1262\n",
      "Epoch 616/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 220.8642 - val_loss: 280.8027\n",
      "Epoch 617/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 303.5738 - val_loss: 222.6072\n",
      "Epoch 618/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 230.9782 - val_loss: 247.4476\n",
      "Epoch 619/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 231.6765 - val_loss: 197.1441\n",
      "Epoch 620/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 338.2172 - val_loss: 233.1396\n",
      "Epoch 621/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 264.6864 - val_loss: 255.4862\n",
      "Epoch 622/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 229.6620 - val_loss: 208.6458\n",
      "Epoch 623/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 269.4152 - val_loss: 297.5717\n",
      "Epoch 624/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 241.1786 - val_loss: 220.6677\n",
      "Epoch 625/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 206.0060 - val_loss: 211.2536\n",
      "Epoch 626/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 191.5249 - val_loss: 398.9577\n",
      "Epoch 627/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 277.4824 - val_loss: 230.1526\n",
      "Epoch 628/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 240.1407 - val_loss: 237.5918\n",
      "Epoch 629/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 266.5890 - val_loss: 212.9523\n",
      "Epoch 630/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 246.2653 - val_loss: 522.5471\n",
      "Epoch 631/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 246.6526 - val_loss: 209.7099\n",
      "Epoch 632/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 210.6120 - val_loss: 200.1654\n",
      "Epoch 633/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 203.7906 - val_loss: 238.7152\n",
      "Epoch 634/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 248.6230 - val_loss: 295.3934\n",
      "Epoch 635/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 416.8017 - val_loss: 685.4500\n",
      "Epoch 636/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 316.6342 - val_loss: 274.7111\n",
      "Epoch 637/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 231.6352 - val_loss: 349.5880\n",
      "Epoch 638/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 245.5542 - val_loss: 280.0909\n",
      "Epoch 639/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 205.8128 - val_loss: 209.4256\n",
      "Epoch 640/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 220.6433 - val_loss: 391.4252\n",
      "Epoch 641/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 229.9182 - val_loss: 288.1333\n",
      "Epoch 642/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 207.7248 - val_loss: 228.8550\n",
      "Epoch 643/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 246.1646 - val_loss: 251.8666\n",
      "Epoch 644/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 225.8917 - val_loss: 410.9444\n",
      "Epoch 645/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 219.8409 - val_loss: 257.1543\n",
      "Epoch 646/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 267.7387 - val_loss: 205.9485\n",
      "Epoch 647/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 239.2532 - val_loss: 351.8092\n",
      "Epoch 648/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 216.0286 - val_loss: 387.2939\n",
      "Epoch 649/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 225.6591 - val_loss: 239.5208\n",
      "Epoch 650/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 237.3058 - val_loss: 249.5981\n",
      "Epoch 651/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 219.1560 - val_loss: 183.1167\n",
      "Epoch 652/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 249.4168 - val_loss: 174.2497\n",
      "Epoch 653/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 236.0052 - val_loss: 184.5749\n",
      "Epoch 654/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 225.2149 - val_loss: 234.6979\n",
      "Epoch 655/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 218.4004 - val_loss: 239.2271\n",
      "Epoch 656/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 219.7090 - val_loss: 186.3596\n",
      "Epoch 657/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 242.3907 - val_loss: 528.1796\n",
      "Epoch 658/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 409.6815 - val_loss: 308.2694\n",
      "Epoch 659/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 296.0363 - val_loss: 261.4566\n",
      "Epoch 660/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 279.3252 - val_loss: 224.8289\n",
      "Epoch 661/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 225.4157 - val_loss: 258.7024\n",
      "Epoch 662/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 250.0120 - val_loss: 312.0696\n",
      "Epoch 663/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 226.3533 - val_loss: 348.6579\n",
      "Epoch 664/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 275.3452 - val_loss: 326.0735\n",
      "Epoch 665/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 256.2703 - val_loss: 260.4720\n",
      "Epoch 666/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 247.0395 - val_loss: 323.1288\n",
      "Epoch 667/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 215.4296 - val_loss: 266.8932\n",
      "Epoch 668/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 201.0531 - val_loss: 375.5336\n",
      "Epoch 669/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 258.9698 - val_loss: 221.5542\n",
      "Epoch 670/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 209.5175 - val_loss: 231.9244\n",
      "Epoch 671/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 213.4649 - val_loss: 304.4124\n",
      "Epoch 672/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 282.3710 - val_loss: 302.0471\n",
      "Epoch 673/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 206.1436 - val_loss: 215.3976\n",
      "Epoch 674/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 243.3103 - val_loss: 212.3783\n",
      "Epoch 675/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 197.0133 - val_loss: 252.3684\n",
      "Epoch 676/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 224.4169 - val_loss: 246.5863\n",
      "Epoch 677/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 242.9320 - val_loss: 250.7834\n",
      "Epoch 678/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 237.2719 - val_loss: 349.7715\n",
      "Epoch 679/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 210.0264 - val_loss: 464.3988\n",
      "Epoch 680/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 207.5198 - val_loss: 423.2681\n",
      "Epoch 681/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 221.6821 - val_loss: 298.3349\n",
      "Epoch 682/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 210.7777 - val_loss: 307.2238\n",
      "Epoch 683/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 279.4328 - val_loss: 429.1541\n",
      "Epoch 684/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 227.6524 - val_loss: 471.1233\n",
      "Epoch 685/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 220.3192 - val_loss: 240.2676\n",
      "Epoch 686/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 206.3508 - val_loss: 228.8202\n",
      "Epoch 687/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 280.4187 - val_loss: 219.7999\n",
      "Epoch 688/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 267.7748 - val_loss: 363.0518\n",
      "Epoch 689/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 216.9305 - val_loss: 260.4417\n",
      "Epoch 690/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 201.8671 - val_loss: 206.9242\n",
      "Epoch 691/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 240.5654 - val_loss: 585.1748\n",
      "Epoch 692/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 251.1563 - val_loss: 218.1997\n",
      "Epoch 693/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 211.9185 - val_loss: 215.7879\n",
      "Epoch 694/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 199.6361 - val_loss: 259.5269\n",
      "Epoch 695/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 188.1253 - val_loss: 274.8665\n",
      "Epoch 696/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 219.5090 - val_loss: 257.8123\n",
      "Epoch 697/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 204.7093 - val_loss: 334.7019\n",
      "Epoch 698/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 237.7529 - val_loss: 293.2965\n",
      "Epoch 699/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 185.6499 - val_loss: 198.3454\n",
      "Epoch 700/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 219.7101 - val_loss: 462.1594\n",
      "Epoch 701/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 236.2422 - val_loss: 228.2042\n",
      "Epoch 702/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 203.3683 - val_loss: 241.5719\n",
      "Epoch 703/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 240.9536 - val_loss: 587.1226\n",
      "Epoch 704/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 281.2982 - val_loss: 275.4710\n",
      "Epoch 705/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 239.8183 - val_loss: 460.7037\n",
      "Epoch 706/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 246.9227 - val_loss: 320.1969\n",
      "Epoch 707/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 209.5126 - val_loss: 212.0276\n",
      "Epoch 708/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 164.5740 - val_loss: 237.2668\n",
      "Epoch 709/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 182.7396 - val_loss: 283.9581\n",
      "Epoch 710/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 245.8817 - val_loss: 225.1895\n",
      "Epoch 711/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 166.3255 - val_loss: 242.1762\n",
      "Epoch 712/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 197.5701 - val_loss: 314.3669\n",
      "Epoch 713/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 202.0549 - val_loss: 221.2402\n",
      "Epoch 714/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 206.4002 - val_loss: 259.9295\n",
      "Epoch 715/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 214.2829 - val_loss: 256.6779\n",
      "Epoch 716/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 232.5004 - val_loss: 512.2594\n",
      "Epoch 717/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 287.5254 - val_loss: 257.0175\n",
      "Epoch 718/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 201.4243 - val_loss: 286.3760\n",
      "Epoch 719/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 212.7464 - val_loss: 262.3483\n",
      "Epoch 720/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 229.9142 - val_loss: 215.7158\n",
      "Epoch 721/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 234.6583 - val_loss: 263.3050\n",
      "Epoch 722/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 201.2427 - val_loss: 341.0108\n",
      "Epoch 723/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 215.6019 - val_loss: 242.0423\n",
      "Epoch 724/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 191.2609 - val_loss: 416.2312\n",
      "Epoch 725/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 237.2490 - val_loss: 233.7963\n",
      "Epoch 726/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 213.8135 - val_loss: 238.4571\n",
      "Epoch 727/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 195.1395 - val_loss: 268.4386\n",
      "Epoch 728/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 173.7228 - val_loss: 292.6644\n",
      "Epoch 729/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 175.1857 - val_loss: 210.4127\n",
      "Epoch 730/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 162.9058 - val_loss: 261.2260\n",
      "Epoch 731/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 176.5264 - val_loss: 220.4030\n",
      "Epoch 732/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 192.1196 - val_loss: 269.3017\n",
      "Epoch 733/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 202.1788 - val_loss: 303.5297\n",
      "Epoch 734/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 192.7380 - val_loss: 229.1339\n",
      "Epoch 735/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 176.0615 - val_loss: 212.5897\n",
      "Epoch 736/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 181.5197 - val_loss: 224.0439\n",
      "Epoch 737/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 224.4455 - val_loss: 228.4656\n",
      "Epoch 738/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 200.4963 - val_loss: 277.2542\n",
      "Epoch 739/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 195.2083 - val_loss: 197.5424\n",
      "Epoch 740/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 224.4189 - val_loss: 286.8723\n",
      "Epoch 741/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 183.9137 - val_loss: 255.4354\n",
      "Epoch 742/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 256.9498 - val_loss: 306.7941\n",
      "Epoch 743/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 226.4006 - val_loss: 260.6579\n",
      "Epoch 744/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 251.4394 - val_loss: 229.9996\n",
      "Epoch 745/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 232.6956 - val_loss: 687.7652\n",
      "Epoch 746/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 275.4904 - val_loss: 299.5853\n",
      "Epoch 747/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 223.6794 - val_loss: 219.2657\n",
      "Epoch 748/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 298.0061 - val_loss: 280.4580\n",
      "Epoch 749/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 202.4937 - val_loss: 434.0838\n",
      "Epoch 750/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 261.1545 - val_loss: 358.8567\n",
      "Epoch 751/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 203.7531 - val_loss: 215.7999\n",
      "Epoch 752/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 206.5629 - val_loss: 282.9499\n",
      "Epoch 753/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 190.3610 - val_loss: 222.6044\n",
      "Epoch 754/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 231.6875 - val_loss: 335.0156\n",
      "Epoch 755/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 210.2585 - val_loss: 201.0541\n",
      "Epoch 756/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 214.2833 - val_loss: 245.3147\n",
      "Epoch 757/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 175.6660 - val_loss: 187.8258\n",
      "Epoch 758/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 211.3133 - val_loss: 248.2987\n",
      "Epoch 759/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 184.3137 - val_loss: 341.8007\n",
      "Epoch 760/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 179.0825 - val_loss: 246.6814\n",
      "Epoch 761/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 168.7354 - val_loss: 225.4978\n",
      "Epoch 762/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 157.8068 - val_loss: 223.5110\n",
      "Epoch 763/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 222.3213 - val_loss: 234.4157\n",
      "Epoch 764/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 206.4352 - val_loss: 217.0561\n",
      "Epoch 765/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 214.7617 - val_loss: 237.2556\n",
      "Epoch 766/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 173.9592 - val_loss: 191.7051\n",
      "Epoch 767/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 235.2523 - val_loss: 243.4947\n",
      "Epoch 768/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 241.0131 - val_loss: 401.3988\n",
      "Epoch 769/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 204.4424 - val_loss: 284.1169\n",
      "Epoch 770/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 198.5164 - val_loss: 218.9437\n",
      "Epoch 771/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 167.0929 - val_loss: 175.7590\n",
      "Epoch 772/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 212.8518 - val_loss: 189.1282\n",
      "Epoch 773/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 214.1604 - val_loss: 228.7438\n",
      "Epoch 774/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 225.1803 - val_loss: 263.3005\n",
      "Epoch 775/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 158.1740 - val_loss: 282.2935\n",
      "Epoch 776/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 228.7324 - val_loss: 239.7176\n",
      "Epoch 777/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 186.7301 - val_loss: 237.3504\n",
      "Epoch 778/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 230.8526 - val_loss: 222.6623\n",
      "Epoch 779/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 244.5070 - val_loss: 209.2963\n",
      "Epoch 780/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 220.5433 - val_loss: 312.2268\n",
      "Epoch 781/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 197.7488 - val_loss: 257.5193\n",
      "Epoch 782/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 169.9305 - val_loss: 247.6212\n",
      "Epoch 783/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 171.1891 - val_loss: 385.5285\n",
      "Epoch 784/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 219.4272 - val_loss: 258.2711\n",
      "Epoch 785/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 227.3425 - val_loss: 371.8365\n",
      "Epoch 786/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 212.9883 - val_loss: 268.4769\n",
      "Epoch 787/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 158.3545 - val_loss: 234.0482\n",
      "Epoch 788/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 218.8815 - val_loss: 222.4868\n",
      "Epoch 789/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 174.6586 - val_loss: 313.5175\n",
      "Epoch 790/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 144.0775 - val_loss: 278.2286\n",
      "Epoch 791/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 201.6202 - val_loss: 311.7487\n",
      "Epoch 792/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 202.2022 - val_loss: 275.7717\n",
      "Epoch 793/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 154.8817 - val_loss: 288.2545\n",
      "Epoch 794/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 206.4954 - val_loss: 268.1649\n",
      "Epoch 795/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 192.9700 - val_loss: 461.0292\n",
      "Epoch 796/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 154.9936 - val_loss: 265.1780\n",
      "Epoch 797/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 199.4542 - val_loss: 261.9105\n",
      "Epoch 798/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 198.4433 - val_loss: 241.8925\n",
      "Epoch 799/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 246.5544 - val_loss: 335.2824\n",
      "Epoch 800/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 373.0575 - val_loss: 216.9084\n",
      "Epoch 801/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 198.4743 - val_loss: 278.2589\n",
      "Epoch 802/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 241.7230 - val_loss: 355.7110\n",
      "Epoch 803/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 189.3536 - val_loss: 230.7280\n",
      "Epoch 804/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 197.3978 - val_loss: 269.0915\n",
      "Epoch 805/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 225.3983 - val_loss: 237.9474\n",
      "Epoch 806/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 236.6594 - val_loss: 235.1375\n",
      "Epoch 807/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 194.9809 - val_loss: 242.5111\n",
      "Epoch 808/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 176.8539 - val_loss: 248.5825\n",
      "Epoch 809/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 198.8328 - val_loss: 352.6870\n",
      "Epoch 810/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 181.9126 - val_loss: 266.1480\n",
      "Epoch 811/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 167.7982 - val_loss: 377.6652\n",
      "Epoch 812/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 253.2630 - val_loss: 837.8933\n",
      "Epoch 813/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 338.9032 - val_loss: 268.0883\n",
      "Epoch 814/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 202.0546 - val_loss: 317.1647\n",
      "Epoch 815/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 181.6768 - val_loss: 255.8117\n",
      "Epoch 816/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 173.8498 - val_loss: 250.8735\n",
      "Epoch 817/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 139.8124 - val_loss: 232.3797\n",
      "Epoch 818/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 192.6350 - val_loss: 203.0817\n",
      "Epoch 819/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 158.3055 - val_loss: 260.6470\n",
      "Epoch 820/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 181.7389 - val_loss: 247.9233\n",
      "Epoch 821/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 222.0282 - val_loss: 379.6660\n",
      "Epoch 822/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 175.6677 - val_loss: 566.5183\n",
      "Epoch 823/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 193.4747 - val_loss: 263.4430\n",
      "Epoch 824/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 203.3799 - val_loss: 214.2401\n",
      "Epoch 825/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 199.6013 - val_loss: 252.6466\n",
      "Epoch 826/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 202.9292 - val_loss: 292.7320\n",
      "Epoch 827/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 158.2877 - val_loss: 421.1215\n",
      "Epoch 828/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 253.5465 - val_loss: 261.8823\n",
      "Epoch 829/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 192.4753 - val_loss: 209.6914\n",
      "Epoch 830/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 192.3232 - val_loss: 360.3017\n",
      "Epoch 831/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 180.5749 - val_loss: 267.7797\n",
      "Epoch 832/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 182.6985 - val_loss: 312.3928\n",
      "Epoch 833/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 176.2310 - val_loss: 353.9413\n",
      "Epoch 834/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 175.2714 - val_loss: 483.3959\n",
      "Epoch 835/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 218.9825 - val_loss: 263.1364\n",
      "Epoch 836/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 242.0575 - val_loss: 236.7754\n",
      "Epoch 837/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 253.7450 - val_loss: 244.3322\n",
      "Epoch 838/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 243.8580 - val_loss: 314.3873\n",
      "Epoch 839/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 214.2518 - val_loss: 210.1019\n",
      "Epoch 840/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 177.7441 - val_loss: 374.6414\n",
      "Epoch 841/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 209.4719 - val_loss: 282.0766\n",
      "Epoch 842/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 182.5501 - val_loss: 248.4781\n",
      "Epoch 843/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 200.0676 - val_loss: 234.7995\n",
      "Epoch 844/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 195.7607 - val_loss: 409.4144\n",
      "Epoch 845/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 208.1972 - val_loss: 325.5572\n",
      "Epoch 846/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 165.6047 - val_loss: 324.1656\n",
      "Epoch 847/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 159.9050 - val_loss: 217.0094\n",
      "Epoch 848/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 182.6525 - val_loss: 195.3729\n",
      "Epoch 849/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 168.3886 - val_loss: 267.4566\n",
      "Epoch 850/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 182.7661 - val_loss: 363.3820\n",
      "Epoch 851/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 258.2137 - val_loss: 281.2268\n",
      "Epoch 852/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 206.9352 - val_loss: 308.4436\n",
      "Epoch 853/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 149.1371 - val_loss: 441.9702\n",
      "Epoch 854/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 199.4142 - val_loss: 679.9107\n",
      "Epoch 855/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 252.3410 - val_loss: 288.3088\n",
      "Epoch 856/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 184.1896 - val_loss: 267.4177\n",
      "Epoch 857/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 179.1831 - val_loss: 415.5946\n",
      "Epoch 858/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 189.2840 - val_loss: 228.5144\n",
      "Epoch 859/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 166.8867 - val_loss: 220.2644\n",
      "Epoch 860/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 171.9777 - val_loss: 250.9328\n",
      "Epoch 861/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 179.9562 - val_loss: 386.2065\n",
      "Epoch 862/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 150.0118 - val_loss: 240.2781\n",
      "Epoch 863/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 190.1009 - val_loss: 430.4507\n",
      "Epoch 864/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 203.3076 - val_loss: 218.0514\n",
      "Epoch 865/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 145.0450 - val_loss: 211.1822\n",
      "Epoch 866/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 161.2778 - val_loss: 653.5125\n",
      "Epoch 867/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 284.3383 - val_loss: 496.5760\n",
      "Epoch 868/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 223.1805 - val_loss: 239.0493\n",
      "Epoch 869/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 166.6007 - val_loss: 256.3796\n",
      "Epoch 870/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 161.0402 - val_loss: 349.9510\n",
      "Epoch 871/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 151.6113 - val_loss: 291.1520\n",
      "Epoch 872/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 161.2318 - val_loss: 260.1340\n",
      "Epoch 873/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 174.8353 - val_loss: 304.2191\n",
      "Epoch 874/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 183.3952 - val_loss: 491.8505\n",
      "Epoch 875/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 217.9170 - val_loss: 489.1006\n",
      "Epoch 876/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 171.7850 - val_loss: 245.1408\n",
      "Epoch 877/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 171.1354 - val_loss: 375.0512\n",
      "Epoch 878/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 233.1012 - val_loss: 206.4850\n",
      "Epoch 879/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 172.2010 - val_loss: 466.3579\n",
      "Epoch 880/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 187.6159 - val_loss: 224.2146\n",
      "Epoch 881/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 179.5939 - val_loss: 203.2177\n",
      "Epoch 882/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 174.2828 - val_loss: 285.8488\n",
      "Epoch 883/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 138.4473 - val_loss: 273.6229\n",
      "Epoch 884/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 162.1997 - val_loss: 300.8698\n",
      "Epoch 885/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 137.9160 - val_loss: 435.3579\n",
      "Epoch 886/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 176.4583 - val_loss: 388.9626\n",
      "Epoch 887/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 174.9696 - val_loss: 411.4751\n",
      "Epoch 888/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 153.0994 - val_loss: 437.7137\n",
      "Epoch 889/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 156.0426 - val_loss: 325.9178\n",
      "Epoch 890/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 194.0150 - val_loss: 371.7625\n",
      "Epoch 891/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 192.5456 - val_loss: 335.8618\n",
      "Epoch 892/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 141.0795 - val_loss: 256.5061\n",
      "Epoch 893/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 157.4895 - val_loss: 459.1290\n",
      "Epoch 894/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 176.7659 - val_loss: 199.6181\n",
      "Epoch 895/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 255.0419 - val_loss: 233.0997\n",
      "Epoch 896/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 156.3096 - val_loss: 334.3007\n",
      "Epoch 897/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 151.7253 - val_loss: 653.1056\n",
      "Epoch 898/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 263.8100 - val_loss: 422.0278\n",
      "Epoch 899/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 227.8022 - val_loss: 253.6547\n",
      "Epoch 900/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 220.4548 - val_loss: 352.5511\n",
      "Epoch 901/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 126.2581 - val_loss: 674.5599\n",
      "Epoch 902/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 215.2211 - val_loss: 243.4006\n",
      "Epoch 903/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 172.3188 - val_loss: 244.6464\n",
      "Epoch 904/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 144.4206 - val_loss: 191.9264\n",
      "Epoch 905/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 246.6696 - val_loss: 262.2939\n",
      "Epoch 906/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 171.1889 - val_loss: 479.1361\n",
      "Epoch 907/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 324.4797 - val_loss: 271.8930\n",
      "Epoch 908/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 198.3505 - val_loss: 187.5546\n",
      "Epoch 909/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 159.0963 - val_loss: 209.7156\n",
      "Epoch 910/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 146.4897 - val_loss: 300.8444\n",
      "Epoch 911/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 138.5832 - val_loss: 348.1310\n",
      "Epoch 912/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 225.7013 - val_loss: 250.2025\n",
      "Epoch 913/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 185.9747 - val_loss: 384.3017\n",
      "Epoch 914/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 138.2187 - val_loss: 214.5206\n",
      "Epoch 915/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 175.2614 - val_loss: 346.2482\n",
      "Epoch 916/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 250.7126 - val_loss: 353.1809\n",
      "Epoch 917/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 153.8309 - val_loss: 393.3785\n",
      "Epoch 918/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 159.8642 - val_loss: 477.5428\n",
      "Epoch 919/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 169.4561 - val_loss: 227.2800\n",
      "Epoch 920/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 162.8750 - val_loss: 643.1601\n",
      "Epoch 921/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 194.2745 - val_loss: 388.2015\n",
      "Epoch 922/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 188.8172 - val_loss: 159.0910\n",
      "Epoch 923/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 143.1701 - val_loss: 320.1429\n",
      "Epoch 924/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 127.9403 - val_loss: 414.4122\n",
      "Epoch 925/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 133.7549 - val_loss: 201.2951\n",
      "Epoch 926/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 313.9595 - val_loss: 296.0635\n",
      "Epoch 927/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 335.4784 - val_loss: 407.7800\n",
      "Epoch 928/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 248.0407 - val_loss: 230.2695\n",
      "Epoch 929/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 322.6880 - val_loss: 199.4924\n",
      "Epoch 930/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 460.9274 - val_loss: 333.3614\n",
      "Epoch 931/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 350.6174 - val_loss: 225.1596\n",
      "Epoch 932/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 301.4894 - val_loss: 256.0740\n",
      "Epoch 933/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 200.1845 - val_loss: 191.7609\n",
      "Epoch 934/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 237.5004 - val_loss: 170.3013\n",
      "Epoch 935/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 202.9813 - val_loss: 218.2771\n",
      "Epoch 936/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 216.7887 - val_loss: 165.7253\n",
      "Epoch 937/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 226.8716 - val_loss: 196.1912\n",
      "Epoch 938/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 292.5818 - val_loss: 223.0046\n",
      "Epoch 939/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 245.8499 - val_loss: 244.9824\n",
      "Epoch 940/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 242.0949 - val_loss: 183.9732\n",
      "Epoch 941/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 202.3073 - val_loss: 177.3823\n",
      "Epoch 942/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 219.6068 - val_loss: 294.6806\n",
      "Epoch 943/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 317.2283 - val_loss: 395.3107\n",
      "Epoch 944/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 264.3779 - val_loss: 285.1066\n",
      "Epoch 945/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 241.6789 - val_loss: 194.5084\n",
      "Epoch 946/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 321.4643 - val_loss: 240.3022\n",
      "Epoch 947/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 253.9148 - val_loss: 269.5870\n",
      "Epoch 948/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 248.6003 - val_loss: 202.8655\n",
      "Epoch 949/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 215.6269 - val_loss: 233.3926\n",
      "Epoch 950/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 285.2457 - val_loss: 233.3983\n",
      "Epoch 951/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 293.6310 - val_loss: 216.5362\n",
      "Epoch 952/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 233.8665 - val_loss: 191.6979\n",
      "Epoch 953/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 190.4203 - val_loss: 170.4339\n",
      "Epoch 954/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 239.7910 - val_loss: 222.8096\n",
      "Epoch 955/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 220.1357 - val_loss: 294.8556\n",
      "Epoch 956/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 195.2248 - val_loss: 280.1310\n",
      "Epoch 957/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 214.2951 - val_loss: 283.6724\n",
      "Epoch 958/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 208.9785 - val_loss: 314.4499\n",
      "Epoch 959/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 203.1732 - val_loss: 216.0224\n",
      "Epoch 960/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 236.9458 - val_loss: 509.0081\n",
      "Epoch 961/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 300.1192 - val_loss: 237.0469\n",
      "Epoch 962/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 230.9183 - val_loss: 217.1622\n",
      "Epoch 963/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 235.8754 - val_loss: 200.1124\n",
      "Epoch 964/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 234.6151 - val_loss: 182.9978\n",
      "Epoch 965/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 226.0451 - val_loss: 238.1520\n",
      "Epoch 966/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 213.3850 - val_loss: 241.4915\n",
      "Epoch 967/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 193.0156 - val_loss: 259.9497\n",
      "Epoch 968/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 226.0719 - val_loss: 271.1910\n",
      "Epoch 969/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 229.1049 - val_loss: 348.7951\n",
      "Epoch 970/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 215.0689 - val_loss: 289.6230\n",
      "Epoch 971/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 189.4057 - val_loss: 347.2024\n",
      "Epoch 972/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 197.2639 - val_loss: 273.5025\n",
      "Epoch 973/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 204.3536 - val_loss: 367.3120\n",
      "Epoch 974/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 258.1153 - val_loss: 467.2487\n",
      "Epoch 975/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 254.6628 - val_loss: 329.6529\n",
      "Epoch 976/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 252.3826 - val_loss: 251.5913\n",
      "Epoch 977/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 188.6582 - val_loss: 280.4961\n",
      "Epoch 978/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 199.4544 - val_loss: 272.7171\n",
      "Epoch 979/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 213.1313 - val_loss: 246.6864\n",
      "Epoch 980/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 240.9072 - val_loss: 288.9757\n",
      "Epoch 981/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 208.6181 - val_loss: 234.7889\n",
      "Epoch 982/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 314.6227 - val_loss: 326.1255\n",
      "Epoch 983/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 294.6870 - val_loss: 358.7664\n",
      "Epoch 984/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 237.8366 - val_loss: 304.4004\n",
      "Epoch 985/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 279.4489 - val_loss: 308.9315\n",
      "Epoch 986/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 241.3916 - val_loss: 304.3754\n",
      "Epoch 987/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 221.9691 - val_loss: 504.3140\n",
      "Epoch 988/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 358.9437 - val_loss: 318.8485\n",
      "Epoch 989/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 206.6870 - val_loss: 305.3187\n",
      "Epoch 990/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 272.5195 - val_loss: 258.1066\n",
      "Epoch 991/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 222.7068 - val_loss: 260.2046\n",
      "Epoch 992/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 270.7611 - val_loss: 337.0325\n",
      "Epoch 993/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 206.4438 - val_loss: 326.4261\n",
      "Epoch 994/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 225.6445 - val_loss: 563.6761\n",
      "Epoch 995/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 227.8126 - val_loss: 324.2461\n",
      "Epoch 996/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 222.8199 - val_loss: 299.5439\n",
      "Epoch 997/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 253.4166 - val_loss: 286.9038\n",
      "Epoch 998/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 209.7644 - val_loss: 287.9526\n",
      "Epoch 999/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 253.0070 - val_loss: 245.9133\n",
      "Epoch 1000/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 191.8021 - val_loss: 275.5123\n",
      "Epoch 1001/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 223.6668 - val_loss: 294.1071\n",
      "Epoch 1002/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 187.0773 - val_loss: 399.9849\n",
      "Epoch 1003/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 244.2511 - val_loss: 261.4465\n",
      "Epoch 1004/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 266.4532 - val_loss: 288.0467\n",
      "Epoch 1005/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 196.4739 - val_loss: 209.7679\n",
      "Epoch 1006/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 213.7645 - val_loss: 244.5385\n",
      "Epoch 1007/10000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 212.2246 - val_loss: 301.7627\n",
      "Epoch 1008/10000\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 189.3818Restoring model weights from the end of the best epoch: 508.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 208.0085 - val_loss: 267.3057\n",
      "Epoch 1008: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = lstm_model(reshaped_train, \n",
    "                                    reshaped_target, \n",
    "                                    want_verbose=1, \n",
    "                                    seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0aad5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        input_test = test_input[i:i+1]\n",
    "        prediction = model.predict(input_test)\n",
    "        error = np.abs(prediction - test_target[start_target + i])\n",
    "        errors.append(error)\n",
    "        error_percent.append(error / test_target[start_target + i])\n",
    "        print(f\"Month-{i + 1} - Error: {error}\")\n",
    "    \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb69c9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 305ms/step\n",
      "Month-1 - Error: [[71.347885]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-2 - Error: [[0.9328613]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-3 - Error: [[65.41725]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-4 - Error: [[17.391327]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-5 - Error: [[43.829147]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-6 - Error: [[34.60875]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-7 - Error: [[6.4669495]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-8 - Error: [[14.292908]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Month-9 - Error: [[6.5070496]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-10 - Error: [[26.91095]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-11 - Error: [[52.228867]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-12 - Error: [[15.144104]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-13 - Error: [[60.53531]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-14 - Error: [[42.552475]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-15 - Error: [[44.375458]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-16 - Error: [[89.24101]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Month-17 - Error: [[6.5548706]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-18 - Error: [[15.817047]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-19 - Error: [[19.491852]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-20 - Error: [[14.816162]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-21 - Error: [[4.7763367]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-22 - Error: [[16.256393]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-23 - Error: [[61.840775]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-24 - Error: [[22.395355]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-25 - Error: [[19.242065]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-26 - Error: [[26.06009]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-27 - Error: [[15.302719]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-28 - Error: [[12.495758]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-29 - Error: [[72.39531]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-30 - Error: [[8.378357]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Month-31 - Error: [[1.0352478]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-32 - Error: [[3.7378235]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-33 - Error: [[44.69998]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-34 - Error: [[13.022491]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Month-35 - Error: [[21.428375]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Month-36 - Error: [[13.19873]]\n"
     ]
    }
   ],
   "source": [
    "errors, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                        reshaped_test, \n",
    "                                        reshaped_test_target, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b1c27bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.909111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.118665524"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c506c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        input_test = test_input[i:i+1]\n",
    "        prediction = model.predict(input_test)\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ca218d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[3413.3184]] - Target[3060.1059999999998]| =  Error: [[353.2124]]; MAPE:[[0.11542489]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[3318.57]] - Target[3013.2439999999997]| =  Error: [[305.32617]]; MAPE:[[0.10132807]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-11: |Prediction[[3329.085]] - Target[3254.4680000000003]| =  Error: [[74.61694]]; MAPE:[[0.02292754]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[353.2124]], dtype=float32),\n",
       " array([[305.32617]], dtype=float32),\n",
       " array([[74.61694]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "244.38518"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0798935"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             reshaped_test, \n",
    "                                             reshaped_test_target, 0)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b2bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
