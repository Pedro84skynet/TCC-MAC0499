{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Bahia - Consumo de Cimento (t)'\n",
    "start_index = 0\n",
    "split_index = 203 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 - 12*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc652c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>Bahia - IDH Educacao</th>\n",
       "      <th>Bahia - IDH Longevidade</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - IDH Renda</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>...</th>\n",
       "      <th>Títulos – CRI (R$)</th>\n",
       "      <th>Títulos – LCI (R$)</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Bahia - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.299858</td>\n",
       "      <td>0.598394</td>\n",
       "      <td>0.766362</td>\n",
       "      <td>0.669899</td>\n",
       "      <td>39.798880</td>\n",
       "      <td>0.638715</td>\n",
       "      <td>1.317344e+08</td>\n",
       "      <td>8.384593e+06</td>\n",
       "      <td>8.566149</td>\n",
       "      <td>...</td>\n",
       "      <td>1.921789e+10</td>\n",
       "      <td>8.202881e+10</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>151.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.301903</td>\n",
       "      <td>0.598795</td>\n",
       "      <td>0.766745</td>\n",
       "      <td>0.670210</td>\n",
       "      <td>39.480034</td>\n",
       "      <td>0.638948</td>\n",
       "      <td>1.318964e+08</td>\n",
       "      <td>8.391946e+06</td>\n",
       "      <td>8.569210</td>\n",
       "      <td>...</td>\n",
       "      <td>1.921789e+10</td>\n",
       "      <td>8.222716e+10</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>138.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.303709</td>\n",
       "      <td>0.599196</td>\n",
       "      <td>0.767127</td>\n",
       "      <td>0.670521</td>\n",
       "      <td>39.400256</td>\n",
       "      <td>0.639181</td>\n",
       "      <td>1.320584e+08</td>\n",
       "      <td>8.399299e+06</td>\n",
       "      <td>8.572270</td>\n",
       "      <td>...</td>\n",
       "      <td>1.921789e+10</td>\n",
       "      <td>8.234287e+10</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>135.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.305311</td>\n",
       "      <td>0.599597</td>\n",
       "      <td>0.767509</td>\n",
       "      <td>0.670831</td>\n",
       "      <td>39.417185</td>\n",
       "      <td>0.639414</td>\n",
       "      <td>1.322204e+08</td>\n",
       "      <td>8.406652e+06</td>\n",
       "      <td>8.575331</td>\n",
       "      <td>...</td>\n",
       "      <td>1.921789e+10</td>\n",
       "      <td>8.235526e+10</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>126.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.306860</td>\n",
       "      <td>0.599998</td>\n",
       "      <td>0.767892</td>\n",
       "      <td>0.671142</td>\n",
       "      <td>39.479943</td>\n",
       "      <td>0.639647</td>\n",
       "      <td>1.323824e+08</td>\n",
       "      <td>8.414005e+06</td>\n",
       "      <td>8.578392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.921843e+10</td>\n",
       "      <td>8.245980e+10</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>137.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>0.596178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.752943</td>\n",
       "      <td>0.659315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>0.594662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.537361</td>\n",
       "      <td>0.659395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>0.592436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.971241</td>\n",
       "      <td>0.659476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>0.589305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.857141</td>\n",
       "      <td>0.659557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2023-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.659638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Bahia - value  Bahia - IDH Educacao  Bahia - IDH Longevidade  \\\n",
       "0       2003-1       0.299858              0.598394                 0.766362   \n",
       "1       2003-2       0.301903              0.598795                 0.766745   \n",
       "2       2003-3       0.303709              0.599196                 0.767127   \n",
       "3       2003-4       0.305311              0.599597                 0.767509   \n",
       "4       2003-5       0.306860              0.599998                 0.767892   \n",
       "..         ...            ...                   ...                      ...   \n",
       "236     2022-9       0.596178                   NaN                      NaN   \n",
       "237    2022-10       0.594662                   NaN                      NaN   \n",
       "238    2022-11       0.592436                   NaN                      NaN   \n",
       "239    2022-12       0.589305                   NaN                      NaN   \n",
       "240     2023-1            NaN                   NaN                      NaN   \n",
       "\n",
       "     Bahia - IDH  Bahia - Produção de Cimento (t)  Bahia - IDH Renda  \\\n",
       "0       0.669899                        39.798880           0.638715   \n",
       "1       0.670210                        39.480034           0.638948   \n",
       "2       0.670521                        39.400256           0.639181   \n",
       "3       0.670831                        39.417185           0.639414   \n",
       "4       0.671142                        39.479943           0.639647   \n",
       "..           ...                              ...                ...   \n",
       "236          NaN                       105.752943           0.659315   \n",
       "237          NaN                       105.537361           0.659395   \n",
       "238          NaN                       104.971241           0.659476   \n",
       "239          NaN                       104.857141           0.659557   \n",
       "240          NaN                              NaN           0.659638   \n",
       "\n",
       "     Bahia - PIB - Estadual  Bahia - PIB - Construção Civil  \\\n",
       "0              1.317344e+08                    8.384593e+06   \n",
       "1              1.318964e+08                    8.391946e+06   \n",
       "2              1.320584e+08                    8.399299e+06   \n",
       "3              1.322204e+08                    8.406652e+06   \n",
       "4              1.323824e+08                    8.414005e+06   \n",
       "..                      ...                             ...   \n",
       "236                     NaN                             NaN   \n",
       "237                     NaN                             NaN   \n",
       "238                     NaN                             NaN   \n",
       "239                     NaN                             NaN   \n",
       "240                     NaN                             NaN   \n",
       "\n",
       "     Bahia - PIB - Per Capita  ...   Títulos – CRI (R$)   Títulos – LCI (R$)  \\\n",
       "0                    8.566149  ...         1.921789e+10         8.202881e+10   \n",
       "1                    8.569210  ...         1.921789e+10         8.222716e+10   \n",
       "2                    8.572270  ...         1.921789e+10         8.234287e+10   \n",
       "3                    8.575331  ...         1.921789e+10         8.235526e+10   \n",
       "4                    8.578392  ...         1.921843e+10         8.245980e+10   \n",
       "..                        ...  ...                  ...                  ...   \n",
       "236                       NaN  ...                  NaN                  NaN   \n",
       "237                       NaN  ...                  NaN                  NaN   \n",
       "238                       NaN  ...                  NaN                  NaN   \n",
       "239                       NaN  ...                  NaN                  NaN   \n",
       "240                       NaN  ...                  NaN                  NaN   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "240                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "240                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "240                                     NaN        NaN   \n",
       "\n",
       "     Bahia - Consumo de Cimento (t)  \n",
       "0                           151.297  \n",
       "1                           138.707  \n",
       "2                           135.009  \n",
       "3                           126.554  \n",
       "4                           137.331  \n",
       "..                              ...  \n",
       "236                         346.042  \n",
       "237                         347.901  \n",
       "238                         310.845  \n",
       "239                         310.845  \n",
       "240                             NaN  \n",
       "\n",
       "[241 rows x 65 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_BA.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>Bahia - IDH Educacao</th>\n",
       "      <th>Bahia - IDH Longevidade</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - IDH Renda</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>...</th>\n",
       "      <th>Títulos – LIG (R$)</th>\n",
       "      <th>Títulos – CRI (R$)</th>\n",
       "      <th>Títulos – LCI (R$)</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.436732</td>\n",
       "      <td>-1.890989</td>\n",
       "      <td>-2.630882</td>\n",
       "      <td>-2.195846</td>\n",
       "      <td>-1.793459</td>\n",
       "      <td>-2.210000</td>\n",
       "      <td>-1.766933</td>\n",
       "      <td>-0.695996</td>\n",
       "      <td>-2.315693</td>\n",
       "      <td>-2.238131</td>\n",
       "      <td>...</td>\n",
       "      <td>1.155957</td>\n",
       "      <td>-1.063593</td>\n",
       "      <td>-0.822933</td>\n",
       "      <td>2.782450</td>\n",
       "      <td>4.506880</td>\n",
       "      <td>2.067266</td>\n",
       "      <td>2.574314</td>\n",
       "      <td>-2.064648</td>\n",
       "      <td>-2.469876</td>\n",
       "      <td>3.184489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.404185</td>\n",
       "      <td>-1.868832</td>\n",
       "      <td>-2.578239</td>\n",
       "      <td>-2.161313</td>\n",
       "      <td>-1.806616</td>\n",
       "      <td>-2.177528</td>\n",
       "      <td>-1.747868</td>\n",
       "      <td>-0.654222</td>\n",
       "      <td>-2.273375</td>\n",
       "      <td>-2.196868</td>\n",
       "      <td>...</td>\n",
       "      <td>1.155957</td>\n",
       "      <td>-1.063593</td>\n",
       "      <td>-0.818174</td>\n",
       "      <td>2.407943</td>\n",
       "      <td>4.328460</td>\n",
       "      <td>1.285816</td>\n",
       "      <td>2.334870</td>\n",
       "      <td>-2.037913</td>\n",
       "      <td>-2.431875</td>\n",
       "      <td>3.029073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.375442</td>\n",
       "      <td>-1.846676</td>\n",
       "      <td>-2.525597</td>\n",
       "      <td>-2.126781</td>\n",
       "      <td>-1.809908</td>\n",
       "      <td>-2.145055</td>\n",
       "      <td>-1.728803</td>\n",
       "      <td>-0.612447</td>\n",
       "      <td>-2.231056</td>\n",
       "      <td>-2.155605</td>\n",
       "      <td>...</td>\n",
       "      <td>1.155957</td>\n",
       "      <td>-1.063593</td>\n",
       "      <td>-0.815398</td>\n",
       "      <td>2.179073</td>\n",
       "      <td>4.129086</td>\n",
       "      <td>2.919965</td>\n",
       "      <td>2.221334</td>\n",
       "      <td>-2.011179</td>\n",
       "      <td>-2.393874</td>\n",
       "      <td>2.926505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.349941</td>\n",
       "      <td>-1.824519</td>\n",
       "      <td>-2.472955</td>\n",
       "      <td>-2.092248</td>\n",
       "      <td>-1.809210</td>\n",
       "      <td>-2.112583</td>\n",
       "      <td>-1.709739</td>\n",
       "      <td>-0.570673</td>\n",
       "      <td>-2.188738</td>\n",
       "      <td>-2.114342</td>\n",
       "      <td>...</td>\n",
       "      <td>1.155957</td>\n",
       "      <td>-1.063593</td>\n",
       "      <td>-0.815101</td>\n",
       "      <td>2.077086</td>\n",
       "      <td>3.911409</td>\n",
       "      <td>1.142823</td>\n",
       "      <td>2.040542</td>\n",
       "      <td>-1.984445</td>\n",
       "      <td>-2.355872</td>\n",
       "      <td>2.828220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.325290</td>\n",
       "      <td>-1.802362</td>\n",
       "      <td>-2.420313</td>\n",
       "      <td>-2.057715</td>\n",
       "      <td>-1.806620</td>\n",
       "      <td>-2.080111</td>\n",
       "      <td>-1.690674</td>\n",
       "      <td>-0.528898</td>\n",
       "      <td>-2.146420</td>\n",
       "      <td>-2.073079</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151943</td>\n",
       "      <td>-1.063566</td>\n",
       "      <td>-0.812592</td>\n",
       "      <td>1.942128</td>\n",
       "      <td>3.663912</td>\n",
       "      <td>2.355956</td>\n",
       "      <td>1.912744</td>\n",
       "      <td>-1.957710</td>\n",
       "      <td>-2.317871</td>\n",
       "      <td>3.036493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.851312</td>\n",
       "      <td>1.208211</td>\n",
       "      <td>0.651753</td>\n",
       "      <td>1.041952</td>\n",
       "      <td>0.619029</td>\n",
       "      <td>0.966650</td>\n",
       "      <td>0.865987</td>\n",
       "      <td>-1.416165</td>\n",
       "      <td>0.555618</td>\n",
       "      <td>0.463875</td>\n",
       "      <td>...</td>\n",
       "      <td>3.115817</td>\n",
       "      <td>1.690001</td>\n",
       "      <td>0.667867</td>\n",
       "      <td>-0.689886</td>\n",
       "      <td>-0.724085</td>\n",
       "      <td>-1.189161</td>\n",
       "      <td>3.148408</td>\n",
       "      <td>1.378950</td>\n",
       "      <td>0.117681</td>\n",
       "      <td>0.370628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.873607</td>\n",
       "      <td>1.201241</td>\n",
       "      <td>0.624227</td>\n",
       "      <td>1.026783</td>\n",
       "      <td>0.635352</td>\n",
       "      <td>0.964148</td>\n",
       "      <td>0.848481</td>\n",
       "      <td>-1.404857</td>\n",
       "      <td>0.531641</td>\n",
       "      <td>0.443334</td>\n",
       "      <td>...</td>\n",
       "      <td>3.295619</td>\n",
       "      <td>1.717926</td>\n",
       "      <td>0.640959</td>\n",
       "      <td>-0.441954</td>\n",
       "      <td>-0.736434</td>\n",
       "      <td>-1.296499</td>\n",
       "      <td>3.219670</td>\n",
       "      <td>1.391539</td>\n",
       "      <td>0.092456</td>\n",
       "      <td>0.427775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.901718</td>\n",
       "      <td>1.194270</td>\n",
       "      <td>0.596702</td>\n",
       "      <td>1.011615</td>\n",
       "      <td>0.652040</td>\n",
       "      <td>0.961646</td>\n",
       "      <td>0.830975</td>\n",
       "      <td>-1.393550</td>\n",
       "      <td>0.507664</td>\n",
       "      <td>0.422793</td>\n",
       "      <td>...</td>\n",
       "      <td>3.486686</td>\n",
       "      <td>1.748758</td>\n",
       "      <td>0.615514</td>\n",
       "      <td>-0.132782</td>\n",
       "      <td>-0.738433</td>\n",
       "      <td>-1.444029</td>\n",
       "      <td>3.421082</td>\n",
       "      <td>1.404128</td>\n",
       "      <td>0.067231</td>\n",
       "      <td>0.538287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.928136</td>\n",
       "      <td>1.187300</td>\n",
       "      <td>0.569176</td>\n",
       "      <td>0.996447</td>\n",
       "      <td>0.638794</td>\n",
       "      <td>0.959144</td>\n",
       "      <td>0.813469</td>\n",
       "      <td>-1.382243</td>\n",
       "      <td>0.483687</td>\n",
       "      <td>0.402252</td>\n",
       "      <td>...</td>\n",
       "      <td>3.692016</td>\n",
       "      <td>1.780444</td>\n",
       "      <td>0.593546</td>\n",
       "      <td>0.084061</td>\n",
       "      <td>-0.738236</td>\n",
       "      <td>-1.444143</td>\n",
       "      <td>3.373840</td>\n",
       "      <td>1.416717</td>\n",
       "      <td>0.042006</td>\n",
       "      <td>0.666156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1.972896</td>\n",
       "      <td>1.180330</td>\n",
       "      <td>0.541650</td>\n",
       "      <td>0.981278</td>\n",
       "      <td>0.637852</td>\n",
       "      <td>0.956643</td>\n",
       "      <td>0.795963</td>\n",
       "      <td>-1.370936</td>\n",
       "      <td>0.459711</td>\n",
       "      <td>0.381711</td>\n",
       "      <td>...</td>\n",
       "      <td>3.909808</td>\n",
       "      <td>1.818976</td>\n",
       "      <td>0.577468</td>\n",
       "      <td>0.162956</td>\n",
       "      <td>-0.746642</td>\n",
       "      <td>-1.717057</td>\n",
       "      <td>3.497364</td>\n",
       "      <td>1.429307</td>\n",
       "      <td>0.016781</td>\n",
       "      <td>0.767681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bahia - value  Bahia - IDH Educacao  Bahia - IDH Longevidade  \\\n",
       "0        -1.436732             -1.890989                -2.630882   \n",
       "1        -1.404185             -1.868832                -2.578239   \n",
       "2        -1.375442             -1.846676                -2.525597   \n",
       "3        -1.349941             -1.824519                -2.472955   \n",
       "4        -1.325290             -1.802362                -2.420313   \n",
       "..             ...                   ...                      ...   \n",
       "199       1.851312              1.208211                 0.651753   \n",
       "200       1.873607              1.201241                 0.624227   \n",
       "201       1.901718              1.194270                 0.596702   \n",
       "202       1.928136              1.187300                 0.569176   \n",
       "203       1.972896              1.180330                 0.541650   \n",
       "\n",
       "     Bahia - IDH  Bahia - Produção de Cimento (t)  Bahia - IDH Renda  \\\n",
       "0      -2.195846                        -1.793459          -2.210000   \n",
       "1      -2.161313                        -1.806616          -2.177528   \n",
       "2      -2.126781                        -1.809908          -2.145055   \n",
       "3      -2.092248                        -1.809210          -2.112583   \n",
       "4      -2.057715                        -1.806620          -2.080111   \n",
       "..           ...                              ...                ...   \n",
       "199     1.041952                         0.619029           0.966650   \n",
       "200     1.026783                         0.635352           0.964148   \n",
       "201     1.011615                         0.652040           0.961646   \n",
       "202     0.996447                         0.638794           0.959144   \n",
       "203     0.981278                         0.637852           0.956643   \n",
       "\n",
       "     Bahia - PIB - Estadual  Bahia - PIB - Construção Civil  \\\n",
       "0                 -1.766933                       -0.695996   \n",
       "1                 -1.747868                       -0.654222   \n",
       "2                 -1.728803                       -0.612447   \n",
       "3                 -1.709739                       -0.570673   \n",
       "4                 -1.690674                       -0.528898   \n",
       "..                      ...                             ...   \n",
       "199                0.865987                       -1.416165   \n",
       "200                0.848481                       -1.404857   \n",
       "201                0.830975                       -1.393550   \n",
       "202                0.813469                       -1.382243   \n",
       "203                0.795963                       -1.370936   \n",
       "\n",
       "     Bahia - PIB - Per Capita  Bahia - PIB - Preços de Mercado  ...  \\\n",
       "0                   -2.315693                        -2.238131  ...   \n",
       "1                   -2.273375                        -2.196868  ...   \n",
       "2                   -2.231056                        -2.155605  ...   \n",
       "3                   -2.188738                        -2.114342  ...   \n",
       "4                   -2.146420                        -2.073079  ...   \n",
       "..                        ...                              ...  ...   \n",
       "199                  0.555618                         0.463875  ...   \n",
       "200                  0.531641                         0.443334  ...   \n",
       "201                  0.507664                         0.422793  ...   \n",
       "202                  0.483687                         0.402252  ...   \n",
       "203                  0.459711                         0.381711  ...   \n",
       "\n",
       "      Títulos – LIG (R$)   Títulos – CRI (R$)   Títulos – LCI (R$)  \\\n",
       "0               1.155957            -1.063593            -0.822933   \n",
       "1               1.155957            -1.063593            -0.818174   \n",
       "2               1.155957            -1.063593            -0.815398   \n",
       "3               1.155957            -1.063593            -0.815101   \n",
       "4               1.151943            -1.063566            -0.812592   \n",
       "..                   ...                  ...                  ...   \n",
       "199             3.115817             1.690001             0.667867   \n",
       "200             3.295619             1.717926             0.640959   \n",
       "201             3.486686             1.748758             0.615514   \n",
       "202             3.692016             1.780444             0.593546   \n",
       "203             3.909808             1.818976             0.577468   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.782450   \n",
       "1                                            2.407943   \n",
       "2                                            2.179073   \n",
       "3                                            2.077086   \n",
       "4                                            1.942128   \n",
       "..                                                ...   \n",
       "199                                         -0.689886   \n",
       "200                                         -0.441954   \n",
       "201                                         -0.132782   \n",
       "202                                          0.084061   \n",
       "203                                          0.162956   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.506880        2.067266  2.574314  -2.064648   \n",
       "1                         4.328460        1.285816  2.334870  -2.037913   \n",
       "2                         4.129086        2.919965  2.221334  -2.011179   \n",
       "3                         3.911409        1.142823  2.040542  -1.984445   \n",
       "4                         3.663912        2.355956  1.912744  -1.957710   \n",
       "..                             ...             ...       ...        ...   \n",
       "199                      -0.724085       -1.189161  3.148408   1.378950   \n",
       "200                      -0.736434       -1.296499  3.219670   1.391539   \n",
       "201                      -0.738433       -1.444029  3.421082   1.404128   \n",
       "202                      -0.738236       -1.444143  3.373840   1.416717   \n",
       "203                      -0.746642       -1.717057  3.497364   1.429307   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \n",
       "0                                 -2.469876   3.184489  \n",
       "1                                 -2.431875   3.029073  \n",
       "2                                 -2.393874   2.926505  \n",
       "3                                 -2.355872   2.828220  \n",
       "4                                 -2.317871   3.036493  \n",
       "..                                      ...        ...  \n",
       "199                                0.117681   0.370628  \n",
       "200                                0.092456   0.427775  \n",
       "201                                0.067231   0.538287  \n",
       "202                                0.042006   0.666156  \n",
       "203                                0.016781   0.767681  \n",
       "\n",
       "[204 rows x 63 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "# input_data = data.iloc[:split_index + 1,:]\n",
    "input_data = (input_data - np.mean(input_data, axis=0)) / np.std(input_data, axis=0)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      138.707\n",
       "1      135.009\n",
       "2      126.554\n",
       "3      137.331\n",
       "4      118.680\n",
       "        ...   \n",
       "236    347.901\n",
       "237    310.845\n",
       "238    310.845\n",
       "239        NaN\n",
       "240        NaN\n",
       "Name: Bahia - Consumo de Cimento (t), Length: 241, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-1)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>Bahia - IDH Educacao</th>\n",
       "      <th>Bahia - IDH Longevidade</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - IDH Renda</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>...</th>\n",
       "      <th>Títulos – LIG (R$)</th>\n",
       "      <th>Títulos – CRI (R$)</th>\n",
       "      <th>Títulos – LCI (R$)</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.436732</td>\n",
       "      <td>-1.890989</td>\n",
       "      <td>-2.630882</td>\n",
       "      <td>-2.195846</td>\n",
       "      <td>-1.793459</td>\n",
       "      <td>-2.210000</td>\n",
       "      <td>-1.766933</td>\n",
       "      <td>-0.695996</td>\n",
       "      <td>-2.315693</td>\n",
       "      <td>-2.238131</td>\n",
       "      <td>...</td>\n",
       "      <td>1.155957</td>\n",
       "      <td>-1.063593</td>\n",
       "      <td>-0.822933</td>\n",
       "      <td>2.782450</td>\n",
       "      <td>4.506880</td>\n",
       "      <td>2.067266</td>\n",
       "      <td>2.574314</td>\n",
       "      <td>-2.064648</td>\n",
       "      <td>-2.469876</td>\n",
       "      <td>3.184489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.404185</td>\n",
       "      <td>-1.868832</td>\n",
       "      <td>-2.578239</td>\n",
       "      <td>-2.161313</td>\n",
       "      <td>-1.806616</td>\n",
       "      <td>-2.177528</td>\n",
       "      <td>-1.747868</td>\n",
       "      <td>-0.654222</td>\n",
       "      <td>-2.273375</td>\n",
       "      <td>-2.196868</td>\n",
       "      <td>...</td>\n",
       "      <td>1.155957</td>\n",
       "      <td>-1.063593</td>\n",
       "      <td>-0.818174</td>\n",
       "      <td>2.407943</td>\n",
       "      <td>4.328460</td>\n",
       "      <td>1.285816</td>\n",
       "      <td>2.334870</td>\n",
       "      <td>-2.037913</td>\n",
       "      <td>-2.431875</td>\n",
       "      <td>3.029073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.375442</td>\n",
       "      <td>-1.846676</td>\n",
       "      <td>-2.525597</td>\n",
       "      <td>-2.126781</td>\n",
       "      <td>-1.809908</td>\n",
       "      <td>-2.145055</td>\n",
       "      <td>-1.728803</td>\n",
       "      <td>-0.612447</td>\n",
       "      <td>-2.231056</td>\n",
       "      <td>-2.155605</td>\n",
       "      <td>...</td>\n",
       "      <td>1.155957</td>\n",
       "      <td>-1.063593</td>\n",
       "      <td>-0.815398</td>\n",
       "      <td>2.179073</td>\n",
       "      <td>4.129086</td>\n",
       "      <td>2.919965</td>\n",
       "      <td>2.221334</td>\n",
       "      <td>-2.011179</td>\n",
       "      <td>-2.393874</td>\n",
       "      <td>2.926505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.349941</td>\n",
       "      <td>-1.824519</td>\n",
       "      <td>-2.472955</td>\n",
       "      <td>-2.092248</td>\n",
       "      <td>-1.809210</td>\n",
       "      <td>-2.112583</td>\n",
       "      <td>-1.709739</td>\n",
       "      <td>-0.570673</td>\n",
       "      <td>-2.188738</td>\n",
       "      <td>-2.114342</td>\n",
       "      <td>...</td>\n",
       "      <td>1.155957</td>\n",
       "      <td>-1.063593</td>\n",
       "      <td>-0.815101</td>\n",
       "      <td>2.077086</td>\n",
       "      <td>3.911409</td>\n",
       "      <td>1.142823</td>\n",
       "      <td>2.040542</td>\n",
       "      <td>-1.984445</td>\n",
       "      <td>-2.355872</td>\n",
       "      <td>2.828220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.325290</td>\n",
       "      <td>-1.802362</td>\n",
       "      <td>-2.420313</td>\n",
       "      <td>-2.057715</td>\n",
       "      <td>-1.806620</td>\n",
       "      <td>-2.080111</td>\n",
       "      <td>-1.690674</td>\n",
       "      <td>-0.528898</td>\n",
       "      <td>-2.146420</td>\n",
       "      <td>-2.073079</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151943</td>\n",
       "      <td>-1.063566</td>\n",
       "      <td>-0.812592</td>\n",
       "      <td>1.942128</td>\n",
       "      <td>3.663912</td>\n",
       "      <td>2.355956</td>\n",
       "      <td>1.912744</td>\n",
       "      <td>-1.957710</td>\n",
       "      <td>-2.317871</td>\n",
       "      <td>3.036493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.005306</td>\n",
       "      <td>1.275616</td>\n",
       "      <td>1.370224</td>\n",
       "      <td>1.339087</td>\n",
       "      <td>0.469766</td>\n",
       "      <td>1.171052</td>\n",
       "      <td>1.163205</td>\n",
       "      <td>-1.340370</td>\n",
       "      <td>1.005749</td>\n",
       "      <td>1.008566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660781</td>\n",
       "      <td>1.272681</td>\n",
       "      <td>1.521503</td>\n",
       "      <td>-0.742853</td>\n",
       "      <td>-0.619453</td>\n",
       "      <td>0.617009</td>\n",
       "      <td>-0.970725</td>\n",
       "      <td>0.980624</td>\n",
       "      <td>0.764972</td>\n",
       "      <td>-1.322806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.029532</td>\n",
       "      <td>1.275493</td>\n",
       "      <td>1.358762</td>\n",
       "      <td>1.336451</td>\n",
       "      <td>0.457435</td>\n",
       "      <td>1.163001</td>\n",
       "      <td>1.164562</td>\n",
       "      <td>-1.364998</td>\n",
       "      <td>1.008863</td>\n",
       "      <td>1.002613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660781</td>\n",
       "      <td>1.288866</td>\n",
       "      <td>1.512161</td>\n",
       "      <td>-0.787367</td>\n",
       "      <td>-0.611176</td>\n",
       "      <td>0.459632</td>\n",
       "      <td>-0.841670</td>\n",
       "      <td>0.991608</td>\n",
       "      <td>0.753473</td>\n",
       "      <td>-1.355523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.057198</td>\n",
       "      <td>1.275369</td>\n",
       "      <td>1.347300</td>\n",
       "      <td>1.333816</td>\n",
       "      <td>0.454716</td>\n",
       "      <td>1.154950</td>\n",
       "      <td>1.165920</td>\n",
       "      <td>-1.389626</td>\n",
       "      <td>1.011977</td>\n",
       "      <td>0.996661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660781</td>\n",
       "      <td>1.304998</td>\n",
       "      <td>1.500026</td>\n",
       "      <td>-0.757940</td>\n",
       "      <td>-0.599627</td>\n",
       "      <td>0.493659</td>\n",
       "      <td>-0.838453</td>\n",
       "      <td>1.002592</td>\n",
       "      <td>0.741973</td>\n",
       "      <td>-1.376175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.082730</td>\n",
       "      <td>1.275246</td>\n",
       "      <td>1.335837</td>\n",
       "      <td>1.331180</td>\n",
       "      <td>0.446427</td>\n",
       "      <td>1.146900</td>\n",
       "      <td>1.167277</td>\n",
       "      <td>-1.414254</td>\n",
       "      <td>1.015092</td>\n",
       "      <td>0.990708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660781</td>\n",
       "      <td>1.332157</td>\n",
       "      <td>1.486995</td>\n",
       "      <td>-0.917469</td>\n",
       "      <td>-0.589237</td>\n",
       "      <td>0.617024</td>\n",
       "      <td>-1.006001</td>\n",
       "      <td>1.013577</td>\n",
       "      <td>0.730473</td>\n",
       "      <td>-1.414146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.112662</td>\n",
       "      <td>1.275122</td>\n",
       "      <td>1.324375</td>\n",
       "      <td>1.328544</td>\n",
       "      <td>0.406571</td>\n",
       "      <td>1.138849</td>\n",
       "      <td>1.168635</td>\n",
       "      <td>-1.438882</td>\n",
       "      <td>1.018206</td>\n",
       "      <td>0.984756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660781</td>\n",
       "      <td>1.354987</td>\n",
       "      <td>1.473884</td>\n",
       "      <td>-0.980136</td>\n",
       "      <td>-0.584931</td>\n",
       "      <td>0.302239</td>\n",
       "      <td>-1.088872</td>\n",
       "      <td>1.024561</td>\n",
       "      <td>0.718973</td>\n",
       "      <td>-1.444336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bahia - value  Bahia - IDH Educacao  Bahia - IDH Longevidade  \\\n",
       "0        -1.436732             -1.890989                -2.630882   \n",
       "1        -1.404185             -1.868832                -2.578239   \n",
       "2        -1.375442             -1.846676                -2.525597   \n",
       "3        -1.349941             -1.824519                -2.472955   \n",
       "4        -1.325290             -1.802362                -2.420313   \n",
       "..             ...                   ...                      ...   \n",
       "163       1.005306              1.275616                 1.370224   \n",
       "164       1.029532              1.275493                 1.358762   \n",
       "165       1.057198              1.275369                 1.347300   \n",
       "166       1.082730              1.275246                 1.335837   \n",
       "167       1.112662              1.275122                 1.324375   \n",
       "\n",
       "     Bahia - IDH  Bahia - Produção de Cimento (t)  Bahia - IDH Renda  \\\n",
       "0      -2.195846                        -1.793459          -2.210000   \n",
       "1      -2.161313                        -1.806616          -2.177528   \n",
       "2      -2.126781                        -1.809908          -2.145055   \n",
       "3      -2.092248                        -1.809210          -2.112583   \n",
       "4      -2.057715                        -1.806620          -2.080111   \n",
       "..           ...                              ...                ...   \n",
       "163     1.339087                         0.469766           1.171052   \n",
       "164     1.336451                         0.457435           1.163001   \n",
       "165     1.333816                         0.454716           1.154950   \n",
       "166     1.331180                         0.446427           1.146900   \n",
       "167     1.328544                         0.406571           1.138849   \n",
       "\n",
       "     Bahia - PIB - Estadual  Bahia - PIB - Construção Civil  \\\n",
       "0                 -1.766933                       -0.695996   \n",
       "1                 -1.747868                       -0.654222   \n",
       "2                 -1.728803                       -0.612447   \n",
       "3                 -1.709739                       -0.570673   \n",
       "4                 -1.690674                       -0.528898   \n",
       "..                      ...                             ...   \n",
       "163                1.163205                       -1.340370   \n",
       "164                1.164562                       -1.364998   \n",
       "165                1.165920                       -1.389626   \n",
       "166                1.167277                       -1.414254   \n",
       "167                1.168635                       -1.438882   \n",
       "\n",
       "     Bahia - PIB - Per Capita  Bahia - PIB - Preços de Mercado  ...  \\\n",
       "0                   -2.315693                        -2.238131  ...   \n",
       "1                   -2.273375                        -2.196868  ...   \n",
       "2                   -2.231056                        -2.155605  ...   \n",
       "3                   -2.188738                        -2.114342  ...   \n",
       "4                   -2.146420                        -2.073079  ...   \n",
       "..                        ...                              ...  ...   \n",
       "163                  1.005749                         1.008566  ...   \n",
       "164                  1.008863                         1.002613  ...   \n",
       "165                  1.011977                         0.996661  ...   \n",
       "166                  1.015092                         0.990708  ...   \n",
       "167                  1.018206                         0.984756  ...   \n",
       "\n",
       "      Títulos – LIG (R$)   Títulos – CRI (R$)   Títulos – LCI (R$)  \\\n",
       "0               1.155957            -1.063593            -0.822933   \n",
       "1               1.155957            -1.063593            -0.818174   \n",
       "2               1.155957            -1.063593            -0.815398   \n",
       "3               1.155957            -1.063593            -0.815101   \n",
       "4               1.151943            -1.063566            -0.812592   \n",
       "..                   ...                  ...                  ...   \n",
       "163            -0.660781             1.272681             1.521503   \n",
       "164            -0.660781             1.288866             1.512161   \n",
       "165            -0.660781             1.304998             1.500026   \n",
       "166            -0.660781             1.332157             1.486995   \n",
       "167            -0.660781             1.354987             1.473884   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.782450   \n",
       "1                                            2.407943   \n",
       "2                                            2.179073   \n",
       "3                                            2.077086   \n",
       "4                                            1.942128   \n",
       "..                                                ...   \n",
       "163                                         -0.742853   \n",
       "164                                         -0.787367   \n",
       "165                                         -0.757940   \n",
       "166                                         -0.917469   \n",
       "167                                         -0.980136   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.506880        2.067266  2.574314  -2.064648   \n",
       "1                         4.328460        1.285816  2.334870  -2.037913   \n",
       "2                         4.129086        2.919965  2.221334  -2.011179   \n",
       "3                         3.911409        1.142823  2.040542  -1.984445   \n",
       "4                         3.663912        2.355956  1.912744  -1.957710   \n",
       "..                             ...             ...       ...        ...   \n",
       "163                      -0.619453        0.617009 -0.970725   0.980624   \n",
       "164                      -0.611176        0.459632 -0.841670   0.991608   \n",
       "165                      -0.599627        0.493659 -0.838453   1.002592   \n",
       "166                      -0.589237        0.617024 -1.006001   1.013577   \n",
       "167                      -0.584931        0.302239 -1.088872   1.024561   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \n",
       "0                                 -2.469876   3.184489  \n",
       "1                                 -2.431875   3.029073  \n",
       "2                                 -2.393874   2.926505  \n",
       "3                                 -2.355872   2.828220  \n",
       "4                                 -2.317871   3.036493  \n",
       "..                                      ...        ...  \n",
       "163                                0.764972  -1.322806  \n",
       "164                                0.753473  -1.355523  \n",
       "165                                0.741973  -1.376175  \n",
       "166                                0.730473  -1.414146  \n",
       "167                                0.718973  -1.444336  \n",
       "\n",
       "[168 rows x 63 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[start_index:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      138.707\n",
       "1      135.009\n",
       "2      126.554\n",
       "3      137.331\n",
       "4      118.680\n",
       "        ...   \n",
       "163    280.074\n",
       "164    277.938\n",
       "165    275.802\n",
       "166    273.666\n",
       "167    271.530\n",
       "Name: Bahia - Consumo de Cimento (t), Length: 168, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[start_index:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>Bahia - IDH Educacao</th>\n",
       "      <th>Bahia - IDH Longevidade</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - IDH Renda</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>...</th>\n",
       "      <th>Títulos – LIG (R$)</th>\n",
       "      <th>Títulos – CRI (R$)</th>\n",
       "      <th>Títulos – LCI (R$)</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.142199</td>\n",
       "      <td>1.274999</td>\n",
       "      <td>1.312912</td>\n",
       "      <td>1.325909</td>\n",
       "      <td>0.407445</td>\n",
       "      <td>1.130798</td>\n",
       "      <td>1.169992</td>\n",
       "      <td>-1.463511</td>\n",
       "      <td>1.021321</td>\n",
       "      <td>0.978804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660781</td>\n",
       "      <td>1.364625</td>\n",
       "      <td>1.460212</td>\n",
       "      <td>-1.032458</td>\n",
       "      <td>-0.585256</td>\n",
       "      <td>-0.505289</td>\n",
       "      <td>-1.202612</td>\n",
       "      <td>1.035545</td>\n",
       "      <td>0.707473</td>\n",
       "      <td>-1.446117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.169669</td>\n",
       "      <td>1.275283</td>\n",
       "      <td>1.296236</td>\n",
       "      <td>1.318823</td>\n",
       "      <td>0.400025</td>\n",
       "      <td>1.131519</td>\n",
       "      <td>1.166430</td>\n",
       "      <td>-1.470219</td>\n",
       "      <td>1.023238</td>\n",
       "      <td>0.968444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660781</td>\n",
       "      <td>1.371257</td>\n",
       "      <td>1.445627</td>\n",
       "      <td>-1.077854</td>\n",
       "      <td>-0.581056</td>\n",
       "      <td>-0.373612</td>\n",
       "      <td>-1.139987</td>\n",
       "      <td>1.046449</td>\n",
       "      <td>0.692399</td>\n",
       "      <td>-1.526274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.197459</td>\n",
       "      <td>1.275567</td>\n",
       "      <td>1.279560</td>\n",
       "      <td>1.311738</td>\n",
       "      <td>0.398398</td>\n",
       "      <td>1.132241</td>\n",
       "      <td>1.162868</td>\n",
       "      <td>-1.476927</td>\n",
       "      <td>1.025155</td>\n",
       "      <td>0.958085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660781</td>\n",
       "      <td>1.375328</td>\n",
       "      <td>1.430008</td>\n",
       "      <td>-1.036724</td>\n",
       "      <td>-0.574769</td>\n",
       "      <td>-0.291560</td>\n",
       "      <td>-1.053534</td>\n",
       "      <td>1.057352</td>\n",
       "      <td>0.677324</td>\n",
       "      <td>-1.610341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.231686</td>\n",
       "      <td>1.275851</td>\n",
       "      <td>1.262884</td>\n",
       "      <td>1.304652</td>\n",
       "      <td>0.379182</td>\n",
       "      <td>1.132962</td>\n",
       "      <td>1.159306</td>\n",
       "      <td>-1.483635</td>\n",
       "      <td>1.027072</td>\n",
       "      <td>0.947726</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660781</td>\n",
       "      <td>1.381257</td>\n",
       "      <td>1.413730</td>\n",
       "      <td>-1.013400</td>\n",
       "      <td>-0.567021</td>\n",
       "      <td>-0.450118</td>\n",
       "      <td>-0.932974</td>\n",
       "      <td>1.068256</td>\n",
       "      <td>0.662249</td>\n",
       "      <td>-1.601301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.268038</td>\n",
       "      <td>1.276135</td>\n",
       "      <td>1.246208</td>\n",
       "      <td>1.297567</td>\n",
       "      <td>0.384352</td>\n",
       "      <td>1.133683</td>\n",
       "      <td>1.155744</td>\n",
       "      <td>-1.490343</td>\n",
       "      <td>1.028989</td>\n",
       "      <td>0.937367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660781</td>\n",
       "      <td>1.364882</td>\n",
       "      <td>1.396980</td>\n",
       "      <td>-1.059228</td>\n",
       "      <td>-0.557842</td>\n",
       "      <td>-0.909054</td>\n",
       "      <td>-0.763756</td>\n",
       "      <td>1.079159</td>\n",
       "      <td>0.647175</td>\n",
       "      <td>-1.618284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.299588</td>\n",
       "      <td>1.276419</td>\n",
       "      <td>1.229531</td>\n",
       "      <td>1.290482</td>\n",
       "      <td>0.367059</td>\n",
       "      <td>1.134404</td>\n",
       "      <td>1.152182</td>\n",
       "      <td>-1.497051</td>\n",
       "      <td>1.030906</td>\n",
       "      <td>0.927007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.582593</td>\n",
       "      <td>1.369812</td>\n",
       "      <td>1.379116</td>\n",
       "      <td>-1.170032</td>\n",
       "      <td>-0.548012</td>\n",
       "      <td>0.387442</td>\n",
       "      <td>-0.644652</td>\n",
       "      <td>1.090063</td>\n",
       "      <td>0.632100</td>\n",
       "      <td>-1.602348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.338328</td>\n",
       "      <td>1.276703</td>\n",
       "      <td>1.212855</td>\n",
       "      <td>1.283396</td>\n",
       "      <td>0.363065</td>\n",
       "      <td>1.135125</td>\n",
       "      <td>1.148620</td>\n",
       "      <td>-1.503759</td>\n",
       "      <td>1.032823</td>\n",
       "      <td>0.916648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474908</td>\n",
       "      <td>1.376543</td>\n",
       "      <td>1.360141</td>\n",
       "      <td>-1.115621</td>\n",
       "      <td>-0.537244</td>\n",
       "      <td>-0.937589</td>\n",
       "      <td>-0.541601</td>\n",
       "      <td>1.100966</td>\n",
       "      <td>0.617026</td>\n",
       "      <td>-1.686659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.376421</td>\n",
       "      <td>1.276987</td>\n",
       "      <td>1.196179</td>\n",
       "      <td>1.276311</td>\n",
       "      <td>0.360415</td>\n",
       "      <td>1.135846</td>\n",
       "      <td>1.145058</td>\n",
       "      <td>-1.510467</td>\n",
       "      <td>1.034740</td>\n",
       "      <td>0.906289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364364</td>\n",
       "      <td>1.384496</td>\n",
       "      <td>1.341361</td>\n",
       "      <td>-1.182159</td>\n",
       "      <td>-0.524149</td>\n",
       "      <td>-1.212466</td>\n",
       "      <td>-0.565747</td>\n",
       "      <td>1.111870</td>\n",
       "      <td>0.601951</td>\n",
       "      <td>-1.688184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.409717</td>\n",
       "      <td>1.277271</td>\n",
       "      <td>1.179503</td>\n",
       "      <td>1.269226</td>\n",
       "      <td>0.359113</td>\n",
       "      <td>1.136567</td>\n",
       "      <td>1.141496</td>\n",
       "      <td>-1.517175</td>\n",
       "      <td>1.036658</td>\n",
       "      <td>0.895930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250935</td>\n",
       "      <td>1.391358</td>\n",
       "      <td>1.323058</td>\n",
       "      <td>-1.270623</td>\n",
       "      <td>-0.519647</td>\n",
       "      <td>-0.499856</td>\n",
       "      <td>-0.536256</td>\n",
       "      <td>1.122773</td>\n",
       "      <td>0.586877</td>\n",
       "      <td>-1.692173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.441251</td>\n",
       "      <td>1.277555</td>\n",
       "      <td>1.162827</td>\n",
       "      <td>1.262140</td>\n",
       "      <td>0.367682</td>\n",
       "      <td>1.137288</td>\n",
       "      <td>1.137934</td>\n",
       "      <td>-1.523883</td>\n",
       "      <td>1.038575</td>\n",
       "      <td>0.885571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134596</td>\n",
       "      <td>1.399740</td>\n",
       "      <td>1.303196</td>\n",
       "      <td>-1.321931</td>\n",
       "      <td>-0.510389</td>\n",
       "      <td>-0.120028</td>\n",
       "      <td>-0.544036</td>\n",
       "      <td>1.133677</td>\n",
       "      <td>0.571802</td>\n",
       "      <td>-1.690760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.453870</td>\n",
       "      <td>1.277839</td>\n",
       "      <td>1.146151</td>\n",
       "      <td>1.255055</td>\n",
       "      <td>0.362771</td>\n",
       "      <td>1.138009</td>\n",
       "      <td>1.134372</td>\n",
       "      <td>-1.530591</td>\n",
       "      <td>1.040492</td>\n",
       "      <td>0.875211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015321</td>\n",
       "      <td>1.407683</td>\n",
       "      <td>1.274576</td>\n",
       "      <td>-1.339532</td>\n",
       "      <td>-0.493794</td>\n",
       "      <td>0.302226</td>\n",
       "      <td>-0.455816</td>\n",
       "      <td>1.144580</td>\n",
       "      <td>0.556728</td>\n",
       "      <td>-1.754852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.466416</td>\n",
       "      <td>1.278123</td>\n",
       "      <td>1.129475</td>\n",
       "      <td>1.247969</td>\n",
       "      <td>0.368449</td>\n",
       "      <td>1.138731</td>\n",
       "      <td>1.130810</td>\n",
       "      <td>-1.537299</td>\n",
       "      <td>1.042409</td>\n",
       "      <td>0.864852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106916</td>\n",
       "      <td>1.418271</td>\n",
       "      <td>1.244691</td>\n",
       "      <td>-1.177993</td>\n",
       "      <td>-0.482543</td>\n",
       "      <td>-1.133998</td>\n",
       "      <td>-0.341841</td>\n",
       "      <td>1.155483</td>\n",
       "      <td>0.541653</td>\n",
       "      <td>-1.791166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.480970</td>\n",
       "      <td>1.278407</td>\n",
       "      <td>1.112798</td>\n",
       "      <td>1.240884</td>\n",
       "      <td>0.387991</td>\n",
       "      <td>1.139452</td>\n",
       "      <td>1.127248</td>\n",
       "      <td>-1.544007</td>\n",
       "      <td>1.044326</td>\n",
       "      <td>0.854493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232140</td>\n",
       "      <td>1.427612</td>\n",
       "      <td>1.217066</td>\n",
       "      <td>-1.259339</td>\n",
       "      <td>-0.476661</td>\n",
       "      <td>-1.443985</td>\n",
       "      <td>-0.404575</td>\n",
       "      <td>1.166387</td>\n",
       "      <td>0.526579</td>\n",
       "      <td>-1.758016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.495507</td>\n",
       "      <td>1.276623</td>\n",
       "      <td>1.090435</td>\n",
       "      <td>1.233154</td>\n",
       "      <td>0.400455</td>\n",
       "      <td>1.126511</td>\n",
       "      <td>1.115688</td>\n",
       "      <td>-1.539950</td>\n",
       "      <td>1.017587</td>\n",
       "      <td>0.833924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360378</td>\n",
       "      <td>1.438650</td>\n",
       "      <td>1.188080</td>\n",
       "      <td>-1.295690</td>\n",
       "      <td>-0.477030</td>\n",
       "      <td>-1.094983</td>\n",
       "      <td>-0.459546</td>\n",
       "      <td>1.176757</td>\n",
       "      <td>0.507219</td>\n",
       "      <td>-1.773309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.503196</td>\n",
       "      <td>1.274839</td>\n",
       "      <td>1.068071</td>\n",
       "      <td>1.225425</td>\n",
       "      <td>0.405571</td>\n",
       "      <td>1.113570</td>\n",
       "      <td>1.104128</td>\n",
       "      <td>-1.535892</td>\n",
       "      <td>0.990848</td>\n",
       "      <td>0.813354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491656</td>\n",
       "      <td>1.449658</td>\n",
       "      <td>1.159956</td>\n",
       "      <td>-1.375339</td>\n",
       "      <td>-0.480370</td>\n",
       "      <td>-1.222235</td>\n",
       "      <td>-0.278469</td>\n",
       "      <td>1.187127</td>\n",
       "      <td>0.487859</td>\n",
       "      <td>-1.769159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.512115</td>\n",
       "      <td>1.273056</td>\n",
       "      <td>1.045707</td>\n",
       "      <td>1.217695</td>\n",
       "      <td>0.398503</td>\n",
       "      <td>1.100629</td>\n",
       "      <td>1.092568</td>\n",
       "      <td>-1.531834</td>\n",
       "      <td>0.964108</td>\n",
       "      <td>0.792785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625998</td>\n",
       "      <td>1.459466</td>\n",
       "      <td>1.133018</td>\n",
       "      <td>-1.486072</td>\n",
       "      <td>-0.485497</td>\n",
       "      <td>-1.257837</td>\n",
       "      <td>-0.319575</td>\n",
       "      <td>1.197496</td>\n",
       "      <td>0.468498</td>\n",
       "      <td>-1.788744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.525662</td>\n",
       "      <td>1.271272</td>\n",
       "      <td>1.023343</td>\n",
       "      <td>1.209966</td>\n",
       "      <td>0.408478</td>\n",
       "      <td>1.087688</td>\n",
       "      <td>1.081008</td>\n",
       "      <td>-1.527776</td>\n",
       "      <td>0.937369</td>\n",
       "      <td>0.772216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763432</td>\n",
       "      <td>1.468722</td>\n",
       "      <td>1.107017</td>\n",
       "      <td>-1.642545</td>\n",
       "      <td>-0.493698</td>\n",
       "      <td>-1.292177</td>\n",
       "      <td>-0.288531</td>\n",
       "      <td>1.207866</td>\n",
       "      <td>0.449138</td>\n",
       "      <td>-1.818878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.523051</td>\n",
       "      <td>1.269488</td>\n",
       "      <td>1.000979</td>\n",
       "      <td>1.202236</td>\n",
       "      <td>0.451828</td>\n",
       "      <td>1.074747</td>\n",
       "      <td>1.069448</td>\n",
       "      <td>-1.523719</td>\n",
       "      <td>0.910630</td>\n",
       "      <td>0.751646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903982</td>\n",
       "      <td>1.478529</td>\n",
       "      <td>1.079248</td>\n",
       "      <td>-1.696141</td>\n",
       "      <td>-0.503979</td>\n",
       "      <td>-1.370259</td>\n",
       "      <td>-0.279873</td>\n",
       "      <td>1.218236</td>\n",
       "      <td>0.429778</td>\n",
       "      <td>-1.814437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.525659</td>\n",
       "      <td>1.267705</td>\n",
       "      <td>0.978615</td>\n",
       "      <td>1.194507</td>\n",
       "      <td>0.469481</td>\n",
       "      <td>1.061807</td>\n",
       "      <td>1.057888</td>\n",
       "      <td>-1.519661</td>\n",
       "      <td>0.883891</td>\n",
       "      <td>0.731077</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047675</td>\n",
       "      <td>1.491355</td>\n",
       "      <td>1.050977</td>\n",
       "      <td>-1.924292</td>\n",
       "      <td>-0.519678</td>\n",
       "      <td>-1.295050</td>\n",
       "      <td>-0.169438</td>\n",
       "      <td>1.228606</td>\n",
       "      <td>0.410418</td>\n",
       "      <td>-1.797383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.537596</td>\n",
       "      <td>1.265921</td>\n",
       "      <td>0.956252</td>\n",
       "      <td>1.186777</td>\n",
       "      <td>0.484754</td>\n",
       "      <td>1.048866</td>\n",
       "      <td>1.046328</td>\n",
       "      <td>-1.515603</td>\n",
       "      <td>0.857152</td>\n",
       "      <td>0.710508</td>\n",
       "      <td>...</td>\n",
       "      <td>1.194536</td>\n",
       "      <td>1.500917</td>\n",
       "      <td>1.021780</td>\n",
       "      <td>-1.972576</td>\n",
       "      <td>-0.537386</td>\n",
       "      <td>-1.148806</td>\n",
       "      <td>0.237913</td>\n",
       "      <td>1.238976</td>\n",
       "      <td>0.391058</td>\n",
       "      <td>-1.790206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.551512</td>\n",
       "      <td>1.264137</td>\n",
       "      <td>0.933888</td>\n",
       "      <td>1.179048</td>\n",
       "      <td>0.486517</td>\n",
       "      <td>1.035925</td>\n",
       "      <td>1.034768</td>\n",
       "      <td>-1.511546</td>\n",
       "      <td>0.830413</td>\n",
       "      <td>0.689938</td>\n",
       "      <td>...</td>\n",
       "      <td>1.344592</td>\n",
       "      <td>1.511590</td>\n",
       "      <td>0.992393</td>\n",
       "      <td>-1.832285</td>\n",
       "      <td>-0.553461</td>\n",
       "      <td>-1.222716</td>\n",
       "      <td>0.559735</td>\n",
       "      <td>1.249345</td>\n",
       "      <td>0.371698</td>\n",
       "      <td>-1.629944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.571909</td>\n",
       "      <td>1.262353</td>\n",
       "      <td>0.911524</td>\n",
       "      <td>1.171318</td>\n",
       "      <td>0.500299</td>\n",
       "      <td>1.022984</td>\n",
       "      <td>1.023208</td>\n",
       "      <td>-1.507488</td>\n",
       "      <td>0.803674</td>\n",
       "      <td>0.669369</td>\n",
       "      <td>...</td>\n",
       "      <td>1.497867</td>\n",
       "      <td>1.523467</td>\n",
       "      <td>0.962962</td>\n",
       "      <td>-1.767518</td>\n",
       "      <td>-0.577640</td>\n",
       "      <td>-1.370262</td>\n",
       "      <td>0.802696</td>\n",
       "      <td>1.259715</td>\n",
       "      <td>0.352338</td>\n",
       "      <td>-1.383366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.589949</td>\n",
       "      <td>1.260570</td>\n",
       "      <td>0.889160</td>\n",
       "      <td>1.163589</td>\n",
       "      <td>0.498868</td>\n",
       "      <td>1.010043</td>\n",
       "      <td>1.011648</td>\n",
       "      <td>-1.503430</td>\n",
       "      <td>0.776935</td>\n",
       "      <td>0.648800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.648317</td>\n",
       "      <td>1.535737</td>\n",
       "      <td>0.934598</td>\n",
       "      <td>-1.688436</td>\n",
       "      <td>-0.606406</td>\n",
       "      <td>-1.283594</td>\n",
       "      <td>1.106124</td>\n",
       "      <td>1.270085</td>\n",
       "      <td>0.332977</td>\n",
       "      <td>-1.227161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.614723</td>\n",
       "      <td>1.258786</td>\n",
       "      <td>0.866796</td>\n",
       "      <td>1.155859</td>\n",
       "      <td>0.499306</td>\n",
       "      <td>0.997102</td>\n",
       "      <td>1.000088</td>\n",
       "      <td>-1.499373</td>\n",
       "      <td>0.750195</td>\n",
       "      <td>0.628230</td>\n",
       "      <td>...</td>\n",
       "      <td>1.820968</td>\n",
       "      <td>1.536902</td>\n",
       "      <td>0.905139</td>\n",
       "      <td>-1.350739</td>\n",
       "      <td>-0.629137</td>\n",
       "      <td>-1.449457</td>\n",
       "      <td>1.364723</td>\n",
       "      <td>1.280455</td>\n",
       "      <td>0.313617</td>\n",
       "      <td>-1.127517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1.641795</td>\n",
       "      <td>1.257002</td>\n",
       "      <td>0.844432</td>\n",
       "      <td>1.148130</td>\n",
       "      <td>0.540294</td>\n",
       "      <td>0.984161</td>\n",
       "      <td>0.988529</td>\n",
       "      <td>-1.495315</td>\n",
       "      <td>0.723456</td>\n",
       "      <td>0.607661</td>\n",
       "      <td>...</td>\n",
       "      <td>1.981659</td>\n",
       "      <td>1.541747</td>\n",
       "      <td>0.876058</td>\n",
       "      <td>-1.335646</td>\n",
       "      <td>-0.644481</td>\n",
       "      <td>-1.429372</td>\n",
       "      <td>1.795882</td>\n",
       "      <td>1.290825</td>\n",
       "      <td>0.294257</td>\n",
       "      <td>-0.993281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.672065</td>\n",
       "      <td>1.250032</td>\n",
       "      <td>0.816907</td>\n",
       "      <td>1.132961</td>\n",
       "      <td>0.528474</td>\n",
       "      <td>0.981660</td>\n",
       "      <td>0.971023</td>\n",
       "      <td>-1.484008</td>\n",
       "      <td>0.699479</td>\n",
       "      <td>0.587120</td>\n",
       "      <td>...</td>\n",
       "      <td>2.138581</td>\n",
       "      <td>1.552099</td>\n",
       "      <td>0.846482</td>\n",
       "      <td>-1.219493</td>\n",
       "      <td>-0.656384</td>\n",
       "      <td>-1.694292</td>\n",
       "      <td>2.156500</td>\n",
       "      <td>1.303414</td>\n",
       "      <td>0.269032</td>\n",
       "      <td>-0.748672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.708758</td>\n",
       "      <td>1.243062</td>\n",
       "      <td>0.789381</td>\n",
       "      <td>1.117793</td>\n",
       "      <td>0.538242</td>\n",
       "      <td>0.979158</td>\n",
       "      <td>0.953517</td>\n",
       "      <td>-1.472700</td>\n",
       "      <td>0.675503</td>\n",
       "      <td>0.566579</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302069</td>\n",
       "      <td>1.567324</td>\n",
       "      <td>0.816905</td>\n",
       "      <td>-1.109104</td>\n",
       "      <td>-0.667513</td>\n",
       "      <td>-1.370264</td>\n",
       "      <td>2.328120</td>\n",
       "      <td>1.316003</td>\n",
       "      <td>0.243807</td>\n",
       "      <td>-0.529379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.749791</td>\n",
       "      <td>1.236092</td>\n",
       "      <td>0.761855</td>\n",
       "      <td>1.102625</td>\n",
       "      <td>0.541863</td>\n",
       "      <td>0.976656</td>\n",
       "      <td>0.936011</td>\n",
       "      <td>-1.461393</td>\n",
       "      <td>0.651526</td>\n",
       "      <td>0.546038</td>\n",
       "      <td>...</td>\n",
       "      <td>2.465039</td>\n",
       "      <td>1.583824</td>\n",
       "      <td>0.787236</td>\n",
       "      <td>-1.210267</td>\n",
       "      <td>-0.680761</td>\n",
       "      <td>-1.222734</td>\n",
       "      <td>2.527565</td>\n",
       "      <td>1.328592</td>\n",
       "      <td>0.218582</td>\n",
       "      <td>-0.408128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.776281</td>\n",
       "      <td>1.229122</td>\n",
       "      <td>0.734330</td>\n",
       "      <td>1.087457</td>\n",
       "      <td>0.559874</td>\n",
       "      <td>0.974155</td>\n",
       "      <td>0.918505</td>\n",
       "      <td>-1.450086</td>\n",
       "      <td>0.627549</td>\n",
       "      <td>0.525497</td>\n",
       "      <td>...</td>\n",
       "      <td>2.625860</td>\n",
       "      <td>1.604785</td>\n",
       "      <td>0.756963</td>\n",
       "      <td>-1.155379</td>\n",
       "      <td>-0.691791</td>\n",
       "      <td>-1.469841</td>\n",
       "      <td>2.881734</td>\n",
       "      <td>1.341182</td>\n",
       "      <td>0.193357</td>\n",
       "      <td>-0.074438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.802829</td>\n",
       "      <td>1.222151</td>\n",
       "      <td>0.706804</td>\n",
       "      <td>1.072288</td>\n",
       "      <td>0.568669</td>\n",
       "      <td>0.971653</td>\n",
       "      <td>0.900999</td>\n",
       "      <td>-1.438779</td>\n",
       "      <td>0.603572</td>\n",
       "      <td>0.504957</td>\n",
       "      <td>...</td>\n",
       "      <td>2.784669</td>\n",
       "      <td>1.639208</td>\n",
       "      <td>0.725941</td>\n",
       "      <td>-1.066718</td>\n",
       "      <td>-0.703014</td>\n",
       "      <td>-1.326682</td>\n",
       "      <td>2.923240</td>\n",
       "      <td>1.353771</td>\n",
       "      <td>0.168132</td>\n",
       "      <td>0.315163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.829211</td>\n",
       "      <td>1.215181</td>\n",
       "      <td>0.679278</td>\n",
       "      <td>1.057120</td>\n",
       "      <td>0.597643</td>\n",
       "      <td>0.969151</td>\n",
       "      <td>0.883493</td>\n",
       "      <td>-1.427472</td>\n",
       "      <td>0.579595</td>\n",
       "      <td>0.484416</td>\n",
       "      <td>...</td>\n",
       "      <td>2.941966</td>\n",
       "      <td>1.663960</td>\n",
       "      <td>0.695836</td>\n",
       "      <td>-0.849380</td>\n",
       "      <td>-0.712461</td>\n",
       "      <td>-1.222733</td>\n",
       "      <td>3.089057</td>\n",
       "      <td>1.366360</td>\n",
       "      <td>0.142906</td>\n",
       "      <td>0.349253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.851312</td>\n",
       "      <td>1.208211</td>\n",
       "      <td>0.651753</td>\n",
       "      <td>1.041952</td>\n",
       "      <td>0.619029</td>\n",
       "      <td>0.966650</td>\n",
       "      <td>0.865987</td>\n",
       "      <td>-1.416165</td>\n",
       "      <td>0.555618</td>\n",
       "      <td>0.463875</td>\n",
       "      <td>...</td>\n",
       "      <td>3.115817</td>\n",
       "      <td>1.690001</td>\n",
       "      <td>0.667867</td>\n",
       "      <td>-0.689886</td>\n",
       "      <td>-0.724085</td>\n",
       "      <td>-1.189161</td>\n",
       "      <td>3.148408</td>\n",
       "      <td>1.378950</td>\n",
       "      <td>0.117681</td>\n",
       "      <td>0.370628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.873607</td>\n",
       "      <td>1.201241</td>\n",
       "      <td>0.624227</td>\n",
       "      <td>1.026783</td>\n",
       "      <td>0.635352</td>\n",
       "      <td>0.964148</td>\n",
       "      <td>0.848481</td>\n",
       "      <td>-1.404857</td>\n",
       "      <td>0.531641</td>\n",
       "      <td>0.443334</td>\n",
       "      <td>...</td>\n",
       "      <td>3.295619</td>\n",
       "      <td>1.717926</td>\n",
       "      <td>0.640959</td>\n",
       "      <td>-0.441954</td>\n",
       "      <td>-0.736434</td>\n",
       "      <td>-1.296499</td>\n",
       "      <td>3.219670</td>\n",
       "      <td>1.391539</td>\n",
       "      <td>0.092456</td>\n",
       "      <td>0.427775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.901718</td>\n",
       "      <td>1.194270</td>\n",
       "      <td>0.596702</td>\n",
       "      <td>1.011615</td>\n",
       "      <td>0.652040</td>\n",
       "      <td>0.961646</td>\n",
       "      <td>0.830975</td>\n",
       "      <td>-1.393550</td>\n",
       "      <td>0.507664</td>\n",
       "      <td>0.422793</td>\n",
       "      <td>...</td>\n",
       "      <td>3.486686</td>\n",
       "      <td>1.748758</td>\n",
       "      <td>0.615514</td>\n",
       "      <td>-0.132782</td>\n",
       "      <td>-0.738433</td>\n",
       "      <td>-1.444029</td>\n",
       "      <td>3.421082</td>\n",
       "      <td>1.404128</td>\n",
       "      <td>0.067231</td>\n",
       "      <td>0.538287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.928136</td>\n",
       "      <td>1.187300</td>\n",
       "      <td>0.569176</td>\n",
       "      <td>0.996447</td>\n",
       "      <td>0.638794</td>\n",
       "      <td>0.959144</td>\n",
       "      <td>0.813469</td>\n",
       "      <td>-1.382243</td>\n",
       "      <td>0.483687</td>\n",
       "      <td>0.402252</td>\n",
       "      <td>...</td>\n",
       "      <td>3.692016</td>\n",
       "      <td>1.780444</td>\n",
       "      <td>0.593546</td>\n",
       "      <td>0.084061</td>\n",
       "      <td>-0.738236</td>\n",
       "      <td>-1.444143</td>\n",
       "      <td>3.373840</td>\n",
       "      <td>1.416717</td>\n",
       "      <td>0.042006</td>\n",
       "      <td>0.666156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1.972896</td>\n",
       "      <td>1.180330</td>\n",
       "      <td>0.541650</td>\n",
       "      <td>0.981278</td>\n",
       "      <td>0.637852</td>\n",
       "      <td>0.956643</td>\n",
       "      <td>0.795963</td>\n",
       "      <td>-1.370936</td>\n",
       "      <td>0.459711</td>\n",
       "      <td>0.381711</td>\n",
       "      <td>...</td>\n",
       "      <td>3.909808</td>\n",
       "      <td>1.818976</td>\n",
       "      <td>0.577468</td>\n",
       "      <td>0.162956</td>\n",
       "      <td>-0.746642</td>\n",
       "      <td>-1.717057</td>\n",
       "      <td>3.497364</td>\n",
       "      <td>1.429307</td>\n",
       "      <td>0.016781</td>\n",
       "      <td>0.767681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bahia - value  Bahia - IDH Educacao  Bahia - IDH Longevidade  \\\n",
       "168       1.142199              1.274999                 1.312912   \n",
       "169       1.169669              1.275283                 1.296236   \n",
       "170       1.197459              1.275567                 1.279560   \n",
       "171       1.231686              1.275851                 1.262884   \n",
       "172       1.268038              1.276135                 1.246208   \n",
       "173       1.299588              1.276419                 1.229531   \n",
       "174       1.338328              1.276703                 1.212855   \n",
       "175       1.376421              1.276987                 1.196179   \n",
       "176       1.409717              1.277271                 1.179503   \n",
       "177       1.441251              1.277555                 1.162827   \n",
       "178       1.453870              1.277839                 1.146151   \n",
       "179       1.466416              1.278123                 1.129475   \n",
       "180       1.480970              1.278407                 1.112798   \n",
       "181       1.495507              1.276623                 1.090435   \n",
       "182       1.503196              1.274839                 1.068071   \n",
       "183       1.512115              1.273056                 1.045707   \n",
       "184       1.525662              1.271272                 1.023343   \n",
       "185       1.523051              1.269488                 1.000979   \n",
       "186       1.525659              1.267705                 0.978615   \n",
       "187       1.537596              1.265921                 0.956252   \n",
       "188       1.551512              1.264137                 0.933888   \n",
       "189       1.571909              1.262353                 0.911524   \n",
       "190       1.589949              1.260570                 0.889160   \n",
       "191       1.614723              1.258786                 0.866796   \n",
       "192       1.641795              1.257002                 0.844432   \n",
       "193       1.672065              1.250032                 0.816907   \n",
       "194       1.708758              1.243062                 0.789381   \n",
       "195       1.749791              1.236092                 0.761855   \n",
       "196       1.776281              1.229122                 0.734330   \n",
       "197       1.802829              1.222151                 0.706804   \n",
       "198       1.829211              1.215181                 0.679278   \n",
       "199       1.851312              1.208211                 0.651753   \n",
       "200       1.873607              1.201241                 0.624227   \n",
       "201       1.901718              1.194270                 0.596702   \n",
       "202       1.928136              1.187300                 0.569176   \n",
       "203       1.972896              1.180330                 0.541650   \n",
       "\n",
       "     Bahia - IDH  Bahia - Produção de Cimento (t)  Bahia - IDH Renda  \\\n",
       "168     1.325909                         0.407445           1.130798   \n",
       "169     1.318823                         0.400025           1.131519   \n",
       "170     1.311738                         0.398398           1.132241   \n",
       "171     1.304652                         0.379182           1.132962   \n",
       "172     1.297567                         0.384352           1.133683   \n",
       "173     1.290482                         0.367059           1.134404   \n",
       "174     1.283396                         0.363065           1.135125   \n",
       "175     1.276311                         0.360415           1.135846   \n",
       "176     1.269226                         0.359113           1.136567   \n",
       "177     1.262140                         0.367682           1.137288   \n",
       "178     1.255055                         0.362771           1.138009   \n",
       "179     1.247969                         0.368449           1.138731   \n",
       "180     1.240884                         0.387991           1.139452   \n",
       "181     1.233154                         0.400455           1.126511   \n",
       "182     1.225425                         0.405571           1.113570   \n",
       "183     1.217695                         0.398503           1.100629   \n",
       "184     1.209966                         0.408478           1.087688   \n",
       "185     1.202236                         0.451828           1.074747   \n",
       "186     1.194507                         0.469481           1.061807   \n",
       "187     1.186777                         0.484754           1.048866   \n",
       "188     1.179048                         0.486517           1.035925   \n",
       "189     1.171318                         0.500299           1.022984   \n",
       "190     1.163589                         0.498868           1.010043   \n",
       "191     1.155859                         0.499306           0.997102   \n",
       "192     1.148130                         0.540294           0.984161   \n",
       "193     1.132961                         0.528474           0.981660   \n",
       "194     1.117793                         0.538242           0.979158   \n",
       "195     1.102625                         0.541863           0.976656   \n",
       "196     1.087457                         0.559874           0.974155   \n",
       "197     1.072288                         0.568669           0.971653   \n",
       "198     1.057120                         0.597643           0.969151   \n",
       "199     1.041952                         0.619029           0.966650   \n",
       "200     1.026783                         0.635352           0.964148   \n",
       "201     1.011615                         0.652040           0.961646   \n",
       "202     0.996447                         0.638794           0.959144   \n",
       "203     0.981278                         0.637852           0.956643   \n",
       "\n",
       "     Bahia - PIB - Estadual  Bahia - PIB - Construção Civil  \\\n",
       "168                1.169992                       -1.463511   \n",
       "169                1.166430                       -1.470219   \n",
       "170                1.162868                       -1.476927   \n",
       "171                1.159306                       -1.483635   \n",
       "172                1.155744                       -1.490343   \n",
       "173                1.152182                       -1.497051   \n",
       "174                1.148620                       -1.503759   \n",
       "175                1.145058                       -1.510467   \n",
       "176                1.141496                       -1.517175   \n",
       "177                1.137934                       -1.523883   \n",
       "178                1.134372                       -1.530591   \n",
       "179                1.130810                       -1.537299   \n",
       "180                1.127248                       -1.544007   \n",
       "181                1.115688                       -1.539950   \n",
       "182                1.104128                       -1.535892   \n",
       "183                1.092568                       -1.531834   \n",
       "184                1.081008                       -1.527776   \n",
       "185                1.069448                       -1.523719   \n",
       "186                1.057888                       -1.519661   \n",
       "187                1.046328                       -1.515603   \n",
       "188                1.034768                       -1.511546   \n",
       "189                1.023208                       -1.507488   \n",
       "190                1.011648                       -1.503430   \n",
       "191                1.000088                       -1.499373   \n",
       "192                0.988529                       -1.495315   \n",
       "193                0.971023                       -1.484008   \n",
       "194                0.953517                       -1.472700   \n",
       "195                0.936011                       -1.461393   \n",
       "196                0.918505                       -1.450086   \n",
       "197                0.900999                       -1.438779   \n",
       "198                0.883493                       -1.427472   \n",
       "199                0.865987                       -1.416165   \n",
       "200                0.848481                       -1.404857   \n",
       "201                0.830975                       -1.393550   \n",
       "202                0.813469                       -1.382243   \n",
       "203                0.795963                       -1.370936   \n",
       "\n",
       "     Bahia - PIB - Per Capita  Bahia - PIB - Preços de Mercado  ...  \\\n",
       "168                  1.021321                         0.978804  ...   \n",
       "169                  1.023238                         0.968444  ...   \n",
       "170                  1.025155                         0.958085  ...   \n",
       "171                  1.027072                         0.947726  ...   \n",
       "172                  1.028989                         0.937367  ...   \n",
       "173                  1.030906                         0.927007  ...   \n",
       "174                  1.032823                         0.916648  ...   \n",
       "175                  1.034740                         0.906289  ...   \n",
       "176                  1.036658                         0.895930  ...   \n",
       "177                  1.038575                         0.885571  ...   \n",
       "178                  1.040492                         0.875211  ...   \n",
       "179                  1.042409                         0.864852  ...   \n",
       "180                  1.044326                         0.854493  ...   \n",
       "181                  1.017587                         0.833924  ...   \n",
       "182                  0.990848                         0.813354  ...   \n",
       "183                  0.964108                         0.792785  ...   \n",
       "184                  0.937369                         0.772216  ...   \n",
       "185                  0.910630                         0.751646  ...   \n",
       "186                  0.883891                         0.731077  ...   \n",
       "187                  0.857152                         0.710508  ...   \n",
       "188                  0.830413                         0.689938  ...   \n",
       "189                  0.803674                         0.669369  ...   \n",
       "190                  0.776935                         0.648800  ...   \n",
       "191                  0.750195                         0.628230  ...   \n",
       "192                  0.723456                         0.607661  ...   \n",
       "193                  0.699479                         0.587120  ...   \n",
       "194                  0.675503                         0.566579  ...   \n",
       "195                  0.651526                         0.546038  ...   \n",
       "196                  0.627549                         0.525497  ...   \n",
       "197                  0.603572                         0.504957  ...   \n",
       "198                  0.579595                         0.484416  ...   \n",
       "199                  0.555618                         0.463875  ...   \n",
       "200                  0.531641                         0.443334  ...   \n",
       "201                  0.507664                         0.422793  ...   \n",
       "202                  0.483687                         0.402252  ...   \n",
       "203                  0.459711                         0.381711  ...   \n",
       "\n",
       "      Títulos – LIG (R$)   Títulos – CRI (R$)   Títulos – LCI (R$)  \\\n",
       "168            -0.660781             1.364625             1.460212   \n",
       "169            -0.660781             1.371257             1.445627   \n",
       "170            -0.660781             1.375328             1.430008   \n",
       "171            -0.660781             1.381257             1.413730   \n",
       "172            -0.660781             1.364882             1.396980   \n",
       "173            -0.582593             1.369812             1.379116   \n",
       "174            -0.474908             1.376543             1.360141   \n",
       "175            -0.364364             1.384496             1.341361   \n",
       "176            -0.250935             1.391358             1.323058   \n",
       "177            -0.134596             1.399740             1.303196   \n",
       "178            -0.015321             1.407683             1.274576   \n",
       "179             0.106916             1.418271             1.244691   \n",
       "180             0.232140             1.427612             1.217066   \n",
       "181             0.360378             1.438650             1.188080   \n",
       "182             0.491656             1.449658             1.159956   \n",
       "183             0.625998             1.459466             1.133018   \n",
       "184             0.763432             1.468722             1.107017   \n",
       "185             0.903982             1.478529             1.079248   \n",
       "186             1.047675             1.491355             1.050977   \n",
       "187             1.194536             1.500917             1.021780   \n",
       "188             1.344592             1.511590             0.992393   \n",
       "189             1.497867             1.523467             0.962962   \n",
       "190             1.648317             1.535737             0.934598   \n",
       "191             1.820968             1.536902             0.905139   \n",
       "192             1.981659             1.541747             0.876058   \n",
       "193             2.138581             1.552099             0.846482   \n",
       "194             2.302069             1.567324             0.816905   \n",
       "195             2.465039             1.583824             0.787236   \n",
       "196             2.625860             1.604785             0.756963   \n",
       "197             2.784669             1.639208             0.725941   \n",
       "198             2.941966             1.663960             0.695836   \n",
       "199             3.115817             1.690001             0.667867   \n",
       "200             3.295619             1.717926             0.640959   \n",
       "201             3.486686             1.748758             0.615514   \n",
       "202             3.692016             1.780444             0.593546   \n",
       "203             3.909808             1.818976             0.577468   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "168                                         -1.032458   \n",
       "169                                         -1.077854   \n",
       "170                                         -1.036724   \n",
       "171                                         -1.013400   \n",
       "172                                         -1.059228   \n",
       "173                                         -1.170032   \n",
       "174                                         -1.115621   \n",
       "175                                         -1.182159   \n",
       "176                                         -1.270623   \n",
       "177                                         -1.321931   \n",
       "178                                         -1.339532   \n",
       "179                                         -1.177993   \n",
       "180                                         -1.259339   \n",
       "181                                         -1.295690   \n",
       "182                                         -1.375339   \n",
       "183                                         -1.486072   \n",
       "184                                         -1.642545   \n",
       "185                                         -1.696141   \n",
       "186                                         -1.924292   \n",
       "187                                         -1.972576   \n",
       "188                                         -1.832285   \n",
       "189                                         -1.767518   \n",
       "190                                         -1.688436   \n",
       "191                                         -1.350739   \n",
       "192                                         -1.335646   \n",
       "193                                         -1.219493   \n",
       "194                                         -1.109104   \n",
       "195                                         -1.210267   \n",
       "196                                         -1.155379   \n",
       "197                                         -1.066718   \n",
       "198                                         -0.849380   \n",
       "199                                         -0.689886   \n",
       "200                                         -0.441954   \n",
       "201                                         -0.132782   \n",
       "202                                          0.084061   \n",
       "203                                          0.162956   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "168                      -0.585256       -0.505289 -1.202612   1.035545   \n",
       "169                      -0.581056       -0.373612 -1.139987   1.046449   \n",
       "170                      -0.574769       -0.291560 -1.053534   1.057352   \n",
       "171                      -0.567021       -0.450118 -0.932974   1.068256   \n",
       "172                      -0.557842       -0.909054 -0.763756   1.079159   \n",
       "173                      -0.548012        0.387442 -0.644652   1.090063   \n",
       "174                      -0.537244       -0.937589 -0.541601   1.100966   \n",
       "175                      -0.524149       -1.212466 -0.565747   1.111870   \n",
       "176                      -0.519647       -0.499856 -0.536256   1.122773   \n",
       "177                      -0.510389       -0.120028 -0.544036   1.133677   \n",
       "178                      -0.493794        0.302226 -0.455816   1.144580   \n",
       "179                      -0.482543       -1.133998 -0.341841   1.155483   \n",
       "180                      -0.476661       -1.443985 -0.404575   1.166387   \n",
       "181                      -0.477030       -1.094983 -0.459546   1.176757   \n",
       "182                      -0.480370       -1.222235 -0.278469   1.187127   \n",
       "183                      -0.485497       -1.257837 -0.319575   1.197496   \n",
       "184                      -0.493698       -1.292177 -0.288531   1.207866   \n",
       "185                      -0.503979       -1.370259 -0.279873   1.218236   \n",
       "186                      -0.519678       -1.295050 -0.169438   1.228606   \n",
       "187                      -0.537386       -1.148806  0.237913   1.238976   \n",
       "188                      -0.553461       -1.222716  0.559735   1.249345   \n",
       "189                      -0.577640       -1.370262  0.802696   1.259715   \n",
       "190                      -0.606406       -1.283594  1.106124   1.270085   \n",
       "191                      -0.629137       -1.449457  1.364723   1.280455   \n",
       "192                      -0.644481       -1.429372  1.795882   1.290825   \n",
       "193                      -0.656384       -1.694292  2.156500   1.303414   \n",
       "194                      -0.667513       -1.370264  2.328120   1.316003   \n",
       "195                      -0.680761       -1.222734  2.527565   1.328592   \n",
       "196                      -0.691791       -1.469841  2.881734   1.341182   \n",
       "197                      -0.703014       -1.326682  2.923240   1.353771   \n",
       "198                      -0.712461       -1.222733  3.089057   1.366360   \n",
       "199                      -0.724085       -1.189161  3.148408   1.378950   \n",
       "200                      -0.736434       -1.296499  3.219670   1.391539   \n",
       "201                      -0.738433       -1.444029  3.421082   1.404128   \n",
       "202                      -0.738236       -1.444143  3.373840   1.416717   \n",
       "203                      -0.746642       -1.717057  3.497364   1.429307   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \n",
       "168                                0.707473  -1.446117  \n",
       "169                                0.692399  -1.526274  \n",
       "170                                0.677324  -1.610341  \n",
       "171                                0.662249  -1.601301  \n",
       "172                                0.647175  -1.618284  \n",
       "173                                0.632100  -1.602348  \n",
       "174                                0.617026  -1.686659  \n",
       "175                                0.601951  -1.688184  \n",
       "176                                0.586877  -1.692173  \n",
       "177                                0.571802  -1.690760  \n",
       "178                                0.556728  -1.754852  \n",
       "179                                0.541653  -1.791166  \n",
       "180                                0.526579  -1.758016  \n",
       "181                                0.507219  -1.773309  \n",
       "182                                0.487859  -1.769159  \n",
       "183                                0.468498  -1.788744  \n",
       "184                                0.449138  -1.818878  \n",
       "185                                0.429778  -1.814437  \n",
       "186                                0.410418  -1.797383  \n",
       "187                                0.391058  -1.790206  \n",
       "188                                0.371698  -1.629944  \n",
       "189                                0.352338  -1.383366  \n",
       "190                                0.332977  -1.227161  \n",
       "191                                0.313617  -1.127517  \n",
       "192                                0.294257  -0.993281  \n",
       "193                                0.269032  -0.748672  \n",
       "194                                0.243807  -0.529379  \n",
       "195                                0.218582  -0.408128  \n",
       "196                                0.193357  -0.074438  \n",
       "197                                0.168132   0.315163  \n",
       "198                                0.142906   0.349253  \n",
       "199                                0.117681   0.370628  \n",
       "200                                0.092456   0.427775  \n",
       "201                                0.067231   0.538287  \n",
       "202                                0.042006   0.666156  \n",
       "203                                0.016781   0.767681  \n",
       "\n",
       "[36 rows x 63 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168    213.266\n",
       "169    285.938\n",
       "170    219.576\n",
       "171    267.203\n",
       "172    240.714\n",
       "173    250.101\n",
       "174    277.528\n",
       "175    270.092\n",
       "176    278.146\n",
       "177    257.458\n",
       "178    231.748\n",
       "179    268.336\n",
       "180    223.453\n",
       "181    241.464\n",
       "182    238.901\n",
       "183    191.989\n",
       "184    272.452\n",
       "185    261.009\n",
       "186    292.688\n",
       "187    258.881\n",
       "188    276.879\n",
       "189    255.774\n",
       "190    208.326\n",
       "191    291.428\n",
       "192    249.430\n",
       "193    241.612\n",
       "194    252.303\n",
       "195    281.912\n",
       "196    200.213\n",
       "197    270.511\n",
       "198    281.466\n",
       "199    285.535\n",
       "200    328.259\n",
       "201    298.078\n",
       "202    264.838\n",
       "203    300.311\n",
       "Name: Bahia - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor, add_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop_index = []\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*6 + 1)\n",
    "        positions_to_drop_index.append(pos + add_factor)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop_index), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    train, train_val = validation_splitter(train_input, 6, 0)\n",
    "    target,target_val = validation_splitter(train_target, 6, 0)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val, target_val),\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2360793833, 2046932901, 1032176266, 2073564254, 1190890854, 3468556023, 2027863536, 3516736498, 457782744, 825139877, 1677325863, 1069152882, 336240673, 3668977071, 4254347119, 1972142621, 301492780, 917021409, 1574993953, 3468524231, 3282773125, 3794823208, 685376338, 601039690, 3553825260]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 138.3181915283203\n",
      "winner_seed: 2360793833\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 109.01384735107422\n",
      "winner_seed: 2046932901\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 99.66685485839844\n",
      "winner_seed: 1032176266\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 136.27853393554688\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 111.09034729003906\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 148.58641052246094\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 161.1203155517578\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 107.26963806152344\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 114.39008331298828\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 105.63102722167969\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 106.070556640625\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 156.58810424804688\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 139.3738555908203\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 112.28141021728516\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 128.8583526611328\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 87.19660949707031\n",
      "winner_seed: 1972142621\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 93.3083724975586\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 107.24681091308594\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 123.67152404785156\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 128.50535583496094\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 110.40577697753906\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 100.99129486083984\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 119.97408294677734\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 97.08011627197266\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 92.15110778808594\n",
      "\n",
      "\n",
      "final_seed: 1972142621\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 65943.7266 - val_loss: 36080.3359\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 43171.9297 - val_loss: 43277.8477\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 33185.9375 - val_loss: 21928.1738\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 33788.0938 - val_loss: 33705.9844\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19036.9805 - val_loss: 17109.9434\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16023.2461 - val_loss: 29281.2188\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19703.3125 - val_loss: 19299.2500\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17663.8477 - val_loss: 15617.1104\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15620.6963 - val_loss: 17807.7910\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18068.6348 - val_loss: 18786.5781\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14359.6650 - val_loss: 9634.4395\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5948.4551 - val_loss: 2566.1526\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4656.1997 - val_loss: 12551.5029\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11549.3545 - val_loss: 12189.2314\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10017.6094 - val_loss: 18493.6602\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18991.0742 - val_loss: 11728.4863\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12078.4727 - val_loss: 9337.4912\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9647.6494 - val_loss: 7825.6128\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6526.2642 - val_loss: 5315.8438\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4944.5386 - val_loss: 6340.3999\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5209.3457 - val_loss: 5335.1616\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3044.2124 - val_loss: 3886.3906\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3477.3774 - val_loss: 2710.7742\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7886.4355 - val_loss: 9392.5225\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10368.7285 - val_loss: 15158.1807\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7588.5151 - val_loss: 5879.6562\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5350.5249 - val_loss: 4764.7695\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5530.8071 - val_loss: 4359.2759\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4019.9570 - val_loss: 4437.7197\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4608.5151 - val_loss: 3133.2830\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2505.6665 - val_loss: 2285.8713\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2134.7068 - val_loss: 2870.8862\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2561.7900 - val_loss: 3328.7661\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2407.6965 - val_loss: 1905.6913\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1706.9668 - val_loss: 1866.8616\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1805.9338 - val_loss: 1741.1010\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1899.6884 - val_loss: 1642.6208\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 886.1420 - val_loss: 639.7982\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1010.3978 - val_loss: 438.0749\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 830.3538 - val_loss: 383.9265\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 690.4410 - val_loss: 514.6382\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 723.1654 - val_loss: 384.6065\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 537.1616 - val_loss: 307.5561\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 501.3961 - val_loss: 254.2186\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 544.1642 - val_loss: 328.7666\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1024.3066 - val_loss: 1447.7322\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1119.7051 - val_loss: 1296.7765\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 988.5715 - val_loss: 663.3063\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 788.0248 - val_loss: 419.1272\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 834.4655 - val_loss: 280.1764\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 603.5847 - val_loss: 683.7812\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 650.7966 - val_loss: 521.5565\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 688.8641 - val_loss: 664.5165\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 851.4421 - val_loss: 556.6395\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 640.3363 - val_loss: 387.0756\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 643.2527 - val_loss: 610.5770\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 551.5561 - val_loss: 220.1515\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 583.2767 - val_loss: 764.2222\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 614.2896 - val_loss: 1131.9541\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 580.8448 - val_loss: 523.3636\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 783.7634 - val_loss: 531.2770\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 686.1315 - val_loss: 421.7935\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 878.3134 - val_loss: 1147.9000\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1100.1854 - val_loss: 534.1532\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 609.1880 - val_loss: 497.2230\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 524.4498 - val_loss: 252.9238\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 463.0639 - val_loss: 346.7113\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 506.6124 - val_loss: 275.5607\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 495.8199 - val_loss: 592.5343\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 492.7094 - val_loss: 240.4282\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 385.9752 - val_loss: 519.6423\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 592.7084 - val_loss: 337.3282\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 493.7459 - val_loss: 292.7043\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 880.9817 - val_loss: 555.7435\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1005.3583 - val_loss: 469.4418\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 751.2338 - val_loss: 516.6827\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2061.6348 - val_loss: 2644.8755\n",
      "Epoch 78/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 3499.4702 - val_loss: 3764.0959\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3053.2522 - val_loss: 2717.9878\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3871.6870 - val_loss: 3128.6211\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2314.2947 - val_loss: 690.5169\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1069.3535 - val_loss: 1000.7843\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1152.8718 - val_loss: 829.4814\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1090.1013 - val_loss: 1072.6023\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1119.8466 - val_loss: 987.7377\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1133.7267 - val_loss: 598.5381\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 779.3120 - val_loss: 421.7924\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 549.8560 - val_loss: 462.8123\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 583.7674 - val_loss: 1142.2225\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 996.0183 - val_loss: 673.8265\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 833.8072 - val_loss: 477.8833\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 590.2898 - val_loss: 416.5470\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 486.5316 - val_loss: 1248.8058\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 652.2146 - val_loss: 261.7246\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 505.5116 - val_loss: 316.0854\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 484.1600 - val_loss: 307.2693\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 535.2905 - val_loss: 295.4667\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 506.8382 - val_loss: 763.5319\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 571.2251 - val_loss: 411.6165\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 568.6803 - val_loss: 490.8470\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 692.2396 - val_loss: 302.0784\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 675.0266 - val_loss: 660.2911\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1030.7555 - val_loss: 424.7430\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 611.1821 - val_loss: 333.7989\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 535.7731 - val_loss: 350.3008\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 535.7958 - val_loss: 601.6849\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 629.2321 - val_loss: 297.0630\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 644.8554 - val_loss: 339.3056\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 631.0906 - val_loss: 521.9922\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 692.2742 - val_loss: 491.4467\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 763.9899 - val_loss: 621.2194\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 587.7529 - val_loss: 331.3985\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 539.8406 - val_loss: 322.4808\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 481.4529 - val_loss: 555.1301\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 586.7260 - val_loss: 1118.9603\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 796.5921 - val_loss: 797.8923\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 689.2799 - val_loss: 348.6071\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 571.4073 - val_loss: 420.4991\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 604.4633 - val_loss: 795.7316\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1014.9073 - val_loss: 592.6885\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 772.2096 - val_loss: 299.6452\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 455.2110 - val_loss: 287.2001\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 428.2452 - val_loss: 504.4970\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 383.3163 - val_loss: 586.1443\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 486.2764 - val_loss: 525.1569\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 505.0161 - val_loss: 460.1449\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 525.2900 - val_loss: 1303.0164\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 765.4418 - val_loss: 572.7093\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 612.2811 - val_loss: 589.1900\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 613.8531 - val_loss: 593.4940\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 808.2600 - val_loss: 452.5616\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 685.6174 - val_loss: 375.8354\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 691.0492 - val_loss: 441.1239\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 967.2761 - val_loss: 570.7684\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 904.6868 - val_loss: 436.9744\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 458.6359 - val_loss: 327.1197\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 418.4731 - val_loss: 627.8529\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 967.6437 - val_loss: 2452.0920\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1381.1223 - val_loss: 1170.9332\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 884.4372 - val_loss: 859.0624\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1962.8433 - val_loss: 933.3030\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1071.0087 - val_loss: 544.5416\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 882.1324 - val_loss: 539.7550\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 734.5693 - val_loss: 486.3881\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 523.4324 - val_loss: 340.4441\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 615.6061 - val_loss: 330.0252\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 430.7556 - val_loss: 385.9022\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 741.6441 - val_loss: 591.2529\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 943.2823 - val_loss: 585.8727\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 470.2109 - val_loss: 700.5656\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 619.9993 - val_loss: 481.2983\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 574.0620 - val_loss: 452.8972\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 764.5381 - val_loss: 845.2554\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 709.0935 - val_loss: 270.4515\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 590.5723 - val_loss: 345.0936\n",
      "Epoch 156/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 520.0095 - val_loss: 428.7917\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 453.6446 - val_loss: 383.8856\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 519.1922 - val_loss: 750.9761\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 580.3488 - val_loss: 605.1085\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 691.3607 - val_loss: 372.3113\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 752.1157 - val_loss: 374.3541\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 837.3021 - val_loss: 852.0215\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 959.9126 - val_loss: 1550.7050\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1400.6869 - val_loss: 463.7523\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 744.8889 - val_loss: 365.1504\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 625.0573 - val_loss: 470.6707\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 779.6501 - val_loss: 372.8430\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 650.6701 - val_loss: 1016.3159\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1028.6495 - val_loss: 468.2443\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 586.6774 - val_loss: 299.5430\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 707.6809 - val_loss: 357.0648\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 718.9338 - val_loss: 464.3958\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 436.7335 - val_loss: 525.2543\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 612.7588 - val_loss: 792.7900\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 675.2440 - val_loss: 1272.5011\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 731.6755 - val_loss: 408.5729\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 664.1011 - val_loss: 923.1600\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1746.4005 - val_loss: 1655.5460\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1937.3732 - val_loss: 1602.5023\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1680.5164 - val_loss: 1476.9674\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1245.7747 - val_loss: 1394.2716\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1284.5311 - val_loss: 478.0011\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 975.3143 - val_loss: 917.2616\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1265.7563 - val_loss: 1030.1848\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1207.9860 - val_loss: 812.7076\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 851.4559 - val_loss: 377.8629\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 622.2484 - val_loss: 641.9450\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 588.6085 - val_loss: 364.6117\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1579.7426 - val_loss: 2014.4401\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2424.2964 - val_loss: 1106.1255\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1155.5944 - val_loss: 1406.3615\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 935.8893 - val_loss: 494.3179\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 767.1060 - val_loss: 330.0287\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 764.8494 - val_loss: 274.8839\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 879.8168 - val_loss: 731.8964\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 867.6578 - val_loss: 557.2520\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 681.8781 - val_loss: 637.5755\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 796.3167 - val_loss: 674.8275\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1202.4257 - val_loss: 1850.9285\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2044.2312 - val_loss: 2239.8599\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2314.7410 - val_loss: 2629.9500\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2605.2366 - val_loss: 1014.5776\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1029.8225 - val_loss: 773.3904\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1101.8730 - val_loss: 1873.5070\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1116.5784 - val_loss: 890.3692\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 871.8950 - val_loss: 1141.0405\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1104.2692 - val_loss: 1058.9393\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1083.1263 - val_loss: 755.6695\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 944.2917 - val_loss: 880.5067\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1352.0797 - val_loss: 1233.1692\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1671.1080 - val_loss: 1141.1541\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1306.8693 - val_loss: 1205.2682\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1003.7135 - val_loss: 1234.0079\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 668.7889 - val_loss: 402.9319\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 852.4667 - val_loss: 411.3175\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 663.1630 - val_loss: 712.9337\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 696.8824 - val_loss: 406.8965\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 524.1599 - val_loss: 538.2858\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 830.5091 - val_loss: 603.8667\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 675.5619 - val_loss: 471.2207\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 750.5450 - val_loss: 292.1943\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1013.3750 - val_loss: 2116.2361\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1731.5853 - val_loss: 1420.8185\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1146.0487 - val_loss: 556.3908\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 853.1490 - val_loss: 449.9964\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 919.7159 - val_loss: 943.6881\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1153.7417 - val_loss: 385.1685\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 948.7924 - val_loss: 494.0366\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1725.4801 - val_loss: 1026.7567\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 962.4355 - val_loss: 746.8327\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1001.7778 - val_loss: 1329.0422\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1384.4823 - val_loss: 1037.3759\n",
      "Epoch 233/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 1415.4316 - val_loss: 770.2206\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 911.8644 - val_loss: 846.2910\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1165.7079 - val_loss: 590.3621\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1595.9313 - val_loss: 1319.4020\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1780.0681 - val_loss: 1598.2277\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1948.8357 - val_loss: 1901.1270\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1385.1270 - val_loss: 1339.3210\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1078.4402 - val_loss: 1351.7987\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1181.6608 - val_loss: 1687.8859\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1329.1737 - val_loss: 963.5825\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1402.6130 - val_loss: 948.6514\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1040.4563 - val_loss: 578.2098\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1000.0865 - val_loss: 735.3122\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 832.0131 - val_loss: 589.8521\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 685.6115 - val_loss: 815.4437\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1339.2694 - val_loss: 1025.5570\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1248.5819 - val_loss: 1409.9271\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1643.7559 - val_loss: 1450.2307\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1263.8257 - val_loss: 1693.7528\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1835.9100 - val_loss: 1403.1188\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1286.4351 - val_loss: 1291.7317\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1374.5424 - val_loss: 1181.0380\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1224.0358 - val_loss: 732.2471\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 851.7683 - val_loss: 819.8596\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 889.8774 - val_loss: 1123.7107\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1210.9572 - val_loss: 586.2567\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 896.1531 - val_loss: 596.0622\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 975.6631 - val_loss: 570.8058\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1077.3506 - val_loss: 781.1367\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 900.3697 - val_loss: 555.4946\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 838.7178 - val_loss: 515.1750\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 735.9387 - val_loss: 531.3156\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 635.2871 - val_loss: 509.2472\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 978.4371 - val_loss: 629.8711\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 874.0851 - val_loss: 715.5956\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 686.2392 - val_loss: 463.3545\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 640.8021 - val_loss: 423.1101\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 776.6182 - val_loss: 381.5883\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 563.2311 - val_loss: 432.4996\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 466.2321 - val_loss: 437.2166\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 637.8959 - val_loss: 416.2502\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 521.3392 - val_loss: 405.3961\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 456.0326 - val_loss: 434.4010\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 489.9722 - val_loss: 322.9333\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 726.6261 - val_loss: 355.2090\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 644.3728 - val_loss: 551.7835\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 610.9535 - val_loss: 414.3320\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 963.2051 - val_loss: 601.3952\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 751.4410 - val_loss: 344.4110\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 537.6143 - val_loss: 350.3760\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 693.0244 - val_loss: 762.8773\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 813.0370 - val_loss: 878.5788\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 957.7764 - val_loss: 702.5656\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 746.8585 - val_loss: 382.7987\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 603.8950 - val_loss: 1048.2673\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 802.2589 - val_loss: 762.4604\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 834.9271 - val_loss: 606.2100\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 784.9789 - val_loss: 414.0308\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 723.6553 - val_loss: 606.9067\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 572.5593 - val_loss: 342.9179\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 524.8226 - val_loss: 295.3125\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 515.9846 - val_loss: 224.2084\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 456.6570 - val_loss: 233.1858\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 566.3170 - val_loss: 509.2894\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 902.5400 - val_loss: 667.0207\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 747.0297 - val_loss: 1000.5360\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 759.9501 - val_loss: 601.1142\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 529.6370 - val_loss: 577.9131\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 575.5773 - val_loss: 542.0522\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 604.5464 - val_loss: 461.9405\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 484.7210 - val_loss: 531.7495\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 618.0023 - val_loss: 452.5223\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 664.8911 - val_loss: 498.4969\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 571.3620 - val_loss: 384.5973\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 608.3539 - val_loss: 406.2405\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 581.4418 - val_loss: 264.6746\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 611.9462 - val_loss: 520.6070\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 789.8896 - val_loss: 411.7323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 667.2840 - val_loss: 332.1201\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 421.4134 - val_loss: 518.7028\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 612.9999 - val_loss: 512.5034\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 477.1662 - val_loss: 434.6696\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 552.2656 - val_loss: 218.2593\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 541.9565 - val_loss: 265.6550\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 448.2069 - val_loss: 203.2052\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 558.6938 - val_loss: 311.1777\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 552.2139 - val_loss: 475.4461\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 507.4442 - val_loss: 293.4387\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 515.9763 - val_loss: 374.5306\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 508.7907 - val_loss: 419.4503\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 514.5590 - val_loss: 1132.0453\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 594.7849 - val_loss: 1023.9530\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 625.1972 - val_loss: 485.8584\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 442.7866 - val_loss: 557.6394\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 435.3541 - val_loss: 585.0602\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 389.1319 - val_loss: 1084.9220\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 617.5539 - val_loss: 559.3531\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 581.3339 - val_loss: 611.2621\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 581.8167 - val_loss: 300.7315\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 546.2481 - val_loss: 343.5566\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 525.0048 - val_loss: 505.6120\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 663.4123 - val_loss: 356.0367\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 501.4007 - val_loss: 297.0207\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 478.4065 - val_loss: 359.8337\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 559.9921 - val_loss: 432.8841\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 455.5143 - val_loss: 430.6000\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 476.0155 - val_loss: 414.7890\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 783.7874 - val_loss: 497.1288\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 537.4586 - val_loss: 463.3723\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 569.9161 - val_loss: 792.9515\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 628.9030 - val_loss: 352.4036\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 432.7886 - val_loss: 427.6480\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 425.3039 - val_loss: 429.9896\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 457.2559 - val_loss: 506.7517\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 505.3186 - val_loss: 585.7986\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 652.2109 - val_loss: 578.0016\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 507.7599 - val_loss: 744.1913\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 774.4728 - val_loss: 529.7690\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 511.8797 - val_loss: 396.4530\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 486.6750 - val_loss: 378.3261\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 495.3228 - val_loss: 576.9225\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 646.5535 - val_loss: 577.3423\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 502.2220 - val_loss: 489.6967\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 480.4006 - val_loss: 556.2997\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 522.1800 - val_loss: 468.3421\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 515.7723 - val_loss: 610.6148\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 516.4379 - val_loss: 474.2342\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 463.4632 - val_loss: 520.7302\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 718.3845 - val_loss: 284.4341\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 689.4562 - val_loss: 298.4240\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 506.5989 - val_loss: 555.9734\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 620.8311 - val_loss: 261.1838\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 462.0370 - val_loss: 203.9371\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 435.7004 - val_loss: 314.7639\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 574.1628 - val_loss: 381.8814\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 552.4033 - val_loss: 355.5627\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 463.3231 - val_loss: 277.8483\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 470.3724 - val_loss: 412.4090\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 436.5225 - val_loss: 397.7173\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 500.8293 - val_loss: 324.8017\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 435.8480 - val_loss: 404.5810\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 411.2076 - val_loss: 772.0916\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 513.2705 - val_loss: 663.3475\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 601.6376 - val_loss: 529.6906\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 561.2054 - val_loss: 444.6864\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 431.7142 - val_loss: 523.1772\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 479.1107 - val_loss: 494.1125\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 462.6001 - val_loss: 362.5902\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 342.7119 - val_loss: 407.5586\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 495.1668 - val_loss: 491.7188\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 463.3437 - val_loss: 627.6968\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 483.6304 - val_loss: 757.2362\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 494.0486 - val_loss: 602.0450\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.5052 - val_loss: 561.0417\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 529.0249 - val_loss: 623.2804\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 584.7204 - val_loss: 974.1137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 698.8704 - val_loss: 729.0824\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 564.0093 - val_loss: 558.5201\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 586.1455 - val_loss: 375.1819\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 485.8002 - val_loss: 292.9634\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 398.2148 - val_loss: 281.8556\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 501.3618 - val_loss: 316.2039\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 425.9836 - val_loss: 548.3947\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 505.7529 - val_loss: 322.7847\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 484.0585 - val_loss: 263.2483\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 377.3929 - val_loss: 417.8921\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 386.9521 - val_loss: 405.4683\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 393.2209 - val_loss: 384.0505\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 410.8401 - val_loss: 262.0496\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 475.6876 - val_loss: 559.3346\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 554.0920 - val_loss: 375.3052\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 406.9924 - val_loss: 368.9134\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 456.2637 - val_loss: 312.5271\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.8999 - val_loss: 359.8007\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 455.1938 - val_loss: 206.6859\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 435.2288 - val_loss: 454.7249\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 557.6578 - val_loss: 337.5449\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 451.9392 - val_loss: 301.8170\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.1570 - val_loss: 387.2278\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 412.2977 - val_loss: 578.9663\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 456.8636 - val_loss: 224.1012\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 381.4979 - val_loss: 228.4114\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 423.5964 - val_loss: 366.0816\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 381.6955 - val_loss: 268.2945\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 415.7127 - val_loss: 233.9538\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 385.0215 - val_loss: 301.5899\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 423.2524 - val_loss: 361.4084\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 372.7869 - val_loss: 330.8900\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 377.9811 - val_loss: 586.4941\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.5934 - val_loss: 458.9291\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 435.3499 - val_loss: 530.4208\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 439.0490 - val_loss: 394.1306\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 497.4893 - val_loss: 322.1599\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 394.4017 - val_loss: 396.8961\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 448.2944 - val_loss: 410.6422\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 404.8450 - val_loss: 324.1702\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 371.3494 - val_loss: 396.7198\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 600.9724 - val_loss: 436.2525\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 545.0594 - val_loss: 506.7261\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 521.6955 - val_loss: 586.4276\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 425.1894 - val_loss: 334.8255\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 433.3519 - val_loss: 434.1108\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 458.7576 - val_loss: 307.0300\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 413.8777 - val_loss: 219.1381\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 564.0235 - val_loss: 284.4965\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 464.9603 - val_loss: 347.3886\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 460.5946 - val_loss: 453.8188\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 549.9587 - val_loss: 294.9424\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 412.6724 - val_loss: 254.1182\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 475.5259 - val_loss: 274.6857\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 457.4777 - val_loss: 239.5486\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 531.9208 - val_loss: 250.0315\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 490.4248 - val_loss: 256.1693\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 400.5936 - val_loss: 229.9312\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 561.5945 - val_loss: 296.2347\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 383.9530 - val_loss: 342.3488\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 413.1122 - val_loss: 378.1382\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 442.4174 - val_loss: 238.4090\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 461.1297 - val_loss: 394.6158\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 545.5459 - val_loss: 400.1241\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 327.4049 - val_loss: 292.2849\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 411.5039 - val_loss: 315.9268\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 392.6770 - val_loss: 281.1259\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 419.0262 - val_loss: 371.7256\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 442.0149 - val_loss: 296.5119\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 482.4758 - val_loss: 319.0545\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 440.2440 - val_loss: 345.2357\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 529.9714 - val_loss: 282.5185\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 475.0703 - val_loss: 235.2955\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 652.7534 - val_loss: 466.9922\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 727.9066 - val_loss: 580.9227\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 703.5339 - val_loss: 272.6111\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 561.2724 - val_loss: 297.2768\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 499.2983 - val_loss: 328.1486\n",
      "Epoch 467/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 548.8125 - val_loss: 361.0284\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 462.7079 - val_loss: 283.8754\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 423.3360 - val_loss: 332.6209\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 488.5190 - val_loss: 337.2600\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 485.5188 - val_loss: 695.1653\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 541.8702 - val_loss: 412.9785\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 468.8626 - val_loss: 320.5335\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 420.4366 - val_loss: 319.6258\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 560.0657 - val_loss: 964.6486\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 702.8844 - val_loss: 575.2309\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 473.7613 - val_loss: 806.4932\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 506.5165 - val_loss: 669.6306\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 423.2079 - val_loss: 734.9652\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 495.3581 - val_loss: 536.8649\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 464.3615 - val_loss: 641.4655\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 510.1239 - val_loss: 572.7532\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 375.2195 - val_loss: 694.8246\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.1620 - val_loss: 740.0751\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 365.7729 - val_loss: 659.4623\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 471.9028 - val_loss: 423.0052\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 376.4151 - val_loss: 440.1170\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.3925 - val_loss: 416.3836\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 466.7841 - val_loss: 538.8073\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 368.6101 - val_loss: 311.3151\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 377.3667 - val_loss: 540.4583\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 384.0359 - val_loss: 547.2361\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 349.0336 - val_loss: 588.7705\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 368.3387 - val_loss: 570.6953\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 371.6101 - val_loss: 597.6163\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.0471 - val_loss: 471.7156\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 380.2718 - val_loss: 513.8932\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 489.8306 - val_loss: 394.0165\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 387.8348 - val_loss: 414.9859\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 412.4104 - val_loss: 400.9970\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 313.9989 - val_loss: 586.9659\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 430.2145 - val_loss: 437.4236\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 351.7864 - val_loss: 357.6831\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 416.0340 - val_loss: 435.0318\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.1128 - val_loss: 390.9856\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 421.2568 - val_loss: 360.6104\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 383.7239 - val_loss: 273.2378\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 436.1871 - val_loss: 220.9104\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 320.5975 - val_loss: 201.7166\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 337.5509 - val_loss: 382.4697\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 428.9767 - val_loss: 200.5780\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 413.5334 - val_loss: 242.0779\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 389.7036 - val_loss: 251.6664\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 385.4649 - val_loss: 242.2799\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 385.3649 - val_loss: 216.0550\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 389.8881 - val_loss: 118.6489\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.8615 - val_loss: 311.5470\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 426.3128 - val_loss: 232.5476\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 361.2310 - val_loss: 214.3208\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.2958 - val_loss: 257.5915\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 416.1603 - val_loss: 174.4694\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.8592 - val_loss: 251.2024\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 388.8574 - val_loss: 240.7531\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 357.4368 - val_loss: 415.4383\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 343.2928 - val_loss: 426.5793\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 328.1105 - val_loss: 486.4380\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 401.0360 - val_loss: 286.8673\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 458.3890 - val_loss: 307.7063\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 474.4559 - val_loss: 215.9888\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 401.1155 - val_loss: 298.5170\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 361.9799 - val_loss: 178.0271\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.8444 - val_loss: 243.5172\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 371.8701 - val_loss: 211.0316\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 434.9113 - val_loss: 277.9415\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 441.4364 - val_loss: 213.3394\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 410.6673 - val_loss: 166.0689\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 416.4055 - val_loss: 350.4275\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 484.5951 - val_loss: 338.5783\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 489.6006 - val_loss: 247.7121\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 406.2829 - val_loss: 290.6499\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 307.6034 - val_loss: 665.0812\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 471.7633 - val_loss: 236.9798\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356.3170 - val_loss: 431.1076\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 460.2726 - val_loss: 267.7990\n",
      "Epoch 545/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 384.7484 - val_loss: 341.9980\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 437.0211 - val_loss: 284.5810\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 359.7571 - val_loss: 328.5701\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 416.1988 - val_loss: 241.9306\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 395.6559 - val_loss: 225.1440\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356.8755 - val_loss: 293.7916\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 428.5538 - val_loss: 199.1506\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 390.1247 - val_loss: 295.1935\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 443.8901 - val_loss: 203.6482\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 365.3110 - val_loss: 253.5676\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 372.3780 - val_loss: 361.6999\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 450.9158 - val_loss: 359.1332\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 474.5787 - val_loss: 539.9843\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 389.4478 - val_loss: 460.1521\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 395.6538 - val_loss: 461.1707\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 359.4841 - val_loss: 419.3716\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.1133 - val_loss: 359.9029\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 361.0823 - val_loss: 291.5147\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 350.7608 - val_loss: 370.1502\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 437.2343 - val_loss: 307.7920\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356.0171 - val_loss: 310.8682\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 383.0676 - val_loss: 331.1634\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.4054 - val_loss: 224.6631\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 398.1780 - val_loss: 255.2141\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 393.3317 - val_loss: 250.9642\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.8836 - val_loss: 287.0880\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 370.2562 - val_loss: 267.1417\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.0461 - val_loss: 328.3207\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 363.3622 - val_loss: 510.3609\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 383.2541 - val_loss: 382.3644\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.5386 - val_loss: 387.6432\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 341.1588 - val_loss: 330.1165\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 342.1410 - val_loss: 259.6866\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 444.2624 - val_loss: 254.0557\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 383.9187 - val_loss: 403.8474\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.0405 - val_loss: 409.1830\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 392.3289 - val_loss: 481.2826\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 378.4697 - val_loss: 510.1641\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.5195 - val_loss: 362.4976\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 302.4393 - val_loss: 337.1094\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 380.8029 - val_loss: 437.3770\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 405.0534 - val_loss: 260.2184\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 400.7647 - val_loss: 528.2518\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 418.8134 - val_loss: 258.9154\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 295.9502 - val_loss: 591.0563\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 417.6224 - val_loss: 346.5557\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 369.7786 - val_loss: 353.0265\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 326.3594 - val_loss: 269.0340\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356.2513 - val_loss: 273.0378\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 354.0419 - val_loss: 234.7279\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.9842 - val_loss: 214.1731\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.8991 - val_loss: 236.7701\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 407.4198 - val_loss: 242.5878\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 327.1101 - val_loss: 262.7866\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 374.3315 - val_loss: 257.3140\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 383.4559 - val_loss: 215.5904\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 329.6059 - val_loss: 300.2858\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.3398 - val_loss: 298.6087\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.5176 - val_loss: 359.2231\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.2255 - val_loss: 293.5322\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.3070 - val_loss: 307.1104\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 361.7330 - val_loss: 346.0073\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 377.7999 - val_loss: 357.7039\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 484.0865 - val_loss: 384.7514\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 434.3681 - val_loss: 378.7537\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 385.2038 - val_loss: 302.5754\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338.3672 - val_loss: 209.6445\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 394.3727 - val_loss: 336.8429\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 454.2390 - val_loss: 435.1137\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 421.2691 - val_loss: 285.5435\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 327.9529 - val_loss: 277.7560\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 319.1440 - val_loss: 207.7732\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301.0949 - val_loss: 215.4911\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.5922 - val_loss: 225.0053\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304.6189 - val_loss: 226.7194\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 347.5140 - val_loss: 202.3202\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 386.0714 - val_loss: 171.1915\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338.8076 - val_loss: 191.3250\n",
      "Epoch 623/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 292.4041 - val_loss: 188.3543\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 303.6725 - val_loss: 342.5097\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 354.7083 - val_loss: 421.0311\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 354.9307 - val_loss: 342.5806\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 359.5127 - val_loss: 607.2928\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.1611 - val_loss: 403.5127\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 365.1166 - val_loss: 366.9831\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 391.0660 - val_loss: 294.4099\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 302.8532 - val_loss: 403.0783\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.9196 - val_loss: 460.8563\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.4212 - val_loss: 373.2151\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.9824 - val_loss: 296.4774\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 295.6272 - val_loss: 233.4680\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.5080 - val_loss: 310.8979\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.5401 - val_loss: 224.1364\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 419.3201 - val_loss: 375.9722\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 310.6837 - val_loss: 372.0722\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 293.2784 - val_loss: 348.3701\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 328.4081 - val_loss: 351.9361\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.8876 - val_loss: 388.0423\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 308.7003 - val_loss: 397.7310\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 317.9946 - val_loss: 412.3772\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 343.4858 - val_loss: 314.5310\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 350.0474 - val_loss: 249.3643\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.0420 - val_loss: 325.6523\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 291.8019 - val_loss: 258.9197\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 427.3650 - val_loss: 202.2206\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 406.5144 - val_loss: 176.8468\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 418.2941 - val_loss: 139.7994\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.6895 - val_loss: 229.5329\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 342.8875 - val_loss: 133.3795\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 348.4590 - val_loss: 174.4599\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.3524 - val_loss: 190.5935\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 345.1522 - val_loss: 265.0792\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 386.1647 - val_loss: 354.7754\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 407.4140 - val_loss: 324.0098\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 409.7701 - val_loss: 388.6692\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 395.5598 - val_loss: 343.2200\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 384.4151 - val_loss: 209.2593\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 329.2225 - val_loss: 174.6327\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.2336 - val_loss: 212.8584\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 284.2471 - val_loss: 330.0434\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 342.0636 - val_loss: 316.4719\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.9333 - val_loss: 419.5015\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 328.4564 - val_loss: 363.7383\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 379.0450 - val_loss: 377.9129\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 379.6705 - val_loss: 351.9048\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 345.1486 - val_loss: 277.5832\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.7822 - val_loss: 284.6922\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314.0652 - val_loss: 356.5730\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 363.7470 - val_loss: 362.7921\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 360.3087 - val_loss: 560.0092\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 405.1873 - val_loss: 322.2888\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.8737 - val_loss: 475.1795\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.9706 - val_loss: 644.4360\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 459.3950 - val_loss: 347.4153\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 334.2303 - val_loss: 295.2905\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 416.5623 - val_loss: 213.5752\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 385.8462 - val_loss: 304.8847\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 436.9109 - val_loss: 197.9020\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.3492 - val_loss: 199.0838\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 381.6038 - val_loss: 114.3899\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 326.4261 - val_loss: 208.3162\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 322.4432 - val_loss: 118.5488\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.6193 - val_loss: 140.3030\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304.8659 - val_loss: 119.3123\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 295.6909 - val_loss: 124.0382\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333.9992 - val_loss: 127.4132\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 343.5239 - val_loss: 197.8043\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338.6281 - val_loss: 285.7967\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.1847 - val_loss: 261.6040\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 341.6323 - val_loss: 209.2814\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 373.1738 - val_loss: 288.4354\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.2999 - val_loss: 216.4568\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 376.4043 - val_loss: 314.1496\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 398.4673 - val_loss: 318.9561\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 384.0349 - val_loss: 318.2548\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 419.5579 - val_loss: 415.9211\n",
      "Epoch 701/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 583.9296 - val_loss: 213.6086\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 449.7419 - val_loss: 310.6554\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 380.3684 - val_loss: 171.8802\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 366.8268 - val_loss: 232.9196\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 398.5755 - val_loss: 228.5192\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 369.0072 - val_loss: 243.4791\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.8961 - val_loss: 219.3040\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301.6083 - val_loss: 189.1159\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.1655 - val_loss: 207.8378\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 408.6575 - val_loss: 281.1571\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 393.6270 - val_loss: 535.8851\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 466.0493 - val_loss: 197.4768\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 365.9809 - val_loss: 308.1796\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 382.2851 - val_loss: 283.8886\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 348.9316 - val_loss: 271.1872\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.2284 - val_loss: 254.3402\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 328.7949 - val_loss: 268.4019\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 402.2836 - val_loss: 263.0630\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 410.4955 - val_loss: 245.5348\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 352.6276 - val_loss: 341.5789\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 349.8669 - val_loss: 320.2882\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 328.1827 - val_loss: 323.4318\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304.1578 - val_loss: 337.9239\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 303.6271 - val_loss: 338.1059\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.2611 - val_loss: 323.5578\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 375.1310 - val_loss: 383.9360\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 357.9219 - val_loss: 464.0724\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 443.5178 - val_loss: 482.6611\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 432.8066 - val_loss: 599.8163\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 530.6416 - val_loss: 600.6407\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 460.8836 - val_loss: 448.0952\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 402.7055 - val_loss: 455.7249\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 370.7350 - val_loss: 444.4973\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 342.0020 - val_loss: 377.5605\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.1584 - val_loss: 386.1279\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 349.3465 - val_loss: 385.7398\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 328.7358 - val_loss: 393.9223\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 371.4912 - val_loss: 395.4246\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 319.5057 - val_loss: 334.3682\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 331.7104 - val_loss: 293.9998\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.4380 - val_loss: 264.8885\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.9037 - val_loss: 298.9577\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 364.9426 - val_loss: 210.6847\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 347.8264 - val_loss: 236.9621\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 300.1583 - val_loss: 210.9160\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.6265 - val_loss: 426.1689\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 380.8716 - val_loss: 510.9233\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 609.3672 - val_loss: 456.4245\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 447.2214 - val_loss: 484.8134\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 406.5591 - val_loss: 309.6898\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 465.4166 - val_loss: 207.3703\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 442.0834 - val_loss: 141.5831\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 334.4932 - val_loss: 154.0547\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 337.0177 - val_loss: 282.7086\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 387.2712 - val_loss: 370.1557\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.7894 - val_loss: 343.5418\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 379.6190 - val_loss: 398.1909\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 372.7425 - val_loss: 295.9348\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 393.0738 - val_loss: 327.3205\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.3779 - val_loss: 249.8381\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 380.7678 - val_loss: 214.3409\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 394.2516 - val_loss: 366.2382\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 389.2306 - val_loss: 231.0033\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.8561 - val_loss: 290.6622\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 370.8734 - val_loss: 360.0690\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 365.2472 - val_loss: 446.4646\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 331.3214 - val_loss: 275.2341\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 319.0507 - val_loss: 179.9429\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 294.5758 - val_loss: 140.6991\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.8963 - val_loss: 243.2022\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 344.9791 - val_loss: 282.3977\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 302.9906 - val_loss: 395.1563\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.5277 - val_loss: 333.6060\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 285.5481 - val_loss: 325.0151\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 331.7383 - val_loss: 291.2622\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 267.5853 - val_loss: 349.7661\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 312.0253 - val_loss: 231.2255\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.1190 - val_loss: 278.9884\n",
      "Epoch 779/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 302.8394 - val_loss: 293.6341\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356.3989 - val_loss: 293.4261\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 329.8267 - val_loss: 258.9134\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 329.4019 - val_loss: 404.9954\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.6330 - val_loss: 219.9675\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.9473 - val_loss: 303.4802\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.2336 - val_loss: 295.4391\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 401.0112 - val_loss: 207.5412\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 394.3824 - val_loss: 340.1319\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 406.4097 - val_loss: 686.8510\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 402.4331 - val_loss: 328.7748\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 369.8269 - val_loss: 252.5035\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 344.3865 - val_loss: 253.9337\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.6669 - val_loss: 143.5829\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 308.2410 - val_loss: 238.9959\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 309.3250 - val_loss: 272.1790\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 307.2097 - val_loss: 466.6678\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 492.3773 - val_loss: 208.9901\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 402.4163 - val_loss: 325.1696\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 485.7536 - val_loss: 206.6404\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 483.3791 - val_loss: 166.0857\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 396.0111 - val_loss: 261.6582\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 398.6557 - val_loss: 192.0684\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.0079 - val_loss: 192.7657\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 364.4694 - val_loss: 296.3967\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 415.2200 - val_loss: 144.7253\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 307.3324 - val_loss: 285.3680\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 299.5139 - val_loss: 158.9342\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.3042 - val_loss: 427.1998\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 520.1204 - val_loss: 379.0666\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 384.5016 - val_loss: 313.8409\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 295.7414 - val_loss: 187.8824\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 360.7758 - val_loss: 289.7410\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 460.8436 - val_loss: 166.7312\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.4822 - val_loss: 335.8988\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 374.9325 - val_loss: 182.2240\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 372.1093 - val_loss: 199.4527\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 374.5405 - val_loss: 236.0107\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 291.9524 - val_loss: 286.8569\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 295.4271 - val_loss: 332.5751\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 295.2389 - val_loss: 212.6559\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.3405 - val_loss: 196.8697\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 293.2023 - val_loss: 212.4078\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 377.0099 - val_loss: 194.4687\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 322.8640 - val_loss: 216.2182\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 337.7925 - val_loss: 228.2510\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.8264 - val_loss: 336.0952\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 306.0424 - val_loss: 343.4690\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 298.5711 - val_loss: 239.1104\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 265.8459 - val_loss: 248.5774\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 385.2278 - val_loss: 262.4047\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333.5513 - val_loss: 314.1067\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 305.9870 - val_loss: 248.9017\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 348.6192 - val_loss: 250.2458\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 299.0413 - val_loss: 215.2512\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 285.1561 - val_loss: 243.6210\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 366.7549 - val_loss: 238.6709\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333.3626 - val_loss: 335.9316\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 312.7502 - val_loss: 302.8720\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 307.3332 - val_loss: 269.4481\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 277.4048 - val_loss: 263.8058\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 272.2353 - val_loss: 351.3034\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 317.3820 - val_loss: 303.0338\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 276.1225 - val_loss: 266.8375\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333.3762 - val_loss: 294.4478\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 331.9937 - val_loss: 372.6140\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338.3095 - val_loss: 271.9909\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304.3079 - val_loss: 414.6848\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.6693 - val_loss: 354.9037\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.3109 - val_loss: 421.5972\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.0275 - val_loss: 264.2582\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 290.1943 - val_loss: 421.1809\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.3302 - val_loss: 272.5195\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 269.8788 - val_loss: 223.9182\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 272.4990 - val_loss: 397.7458\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 322.2544 - val_loss: 280.3419\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 285.2282 - val_loss: 296.7595\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 263.8633 - val_loss: 246.1327\n",
      "Epoch 857/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 317.2401 - val_loss: 221.9169\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 283.5759 - val_loss: 216.2529\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 271.5493 - val_loss: 263.3000\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 286.8986 - val_loss: 165.0117\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 253.8835 - val_loss: 151.6299\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 278.0964 - val_loss: 223.4073\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 322.4089 - val_loss: 128.9971\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 269.0179 - val_loss: 181.9186\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 346.1176 - val_loss: 151.6302\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 345.6732 - val_loss: 215.2421\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.5077 - val_loss: 248.8754\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 447.9686 - val_loss: 182.6560\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304.2392 - val_loss: 343.6425\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.5339 - val_loss: 381.2896\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304.6353 - val_loss: 206.0433\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 329.6270 - val_loss: 451.9729\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 351.3110 - val_loss: 374.4624\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 337.6275 - val_loss: 361.3492\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 346.0153 - val_loss: 345.1973\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 298.1796 - val_loss: 309.2974\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 295.8603 - val_loss: 397.6143\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 361.4653 - val_loss: 359.8104\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 299.5058 - val_loss: 445.3185\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.2476 - val_loss: 333.0208\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.4942 - val_loss: 284.8796\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 378.3061 - val_loss: 375.1096\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 378.3932 - val_loss: 340.1503\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.9720 - val_loss: 281.9911\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.3599 - val_loss: 306.1446\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 389.2669 - val_loss: 404.9915\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.5479 - val_loss: 404.4332\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 379.4865 - val_loss: 543.0719\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 449.6669 - val_loss: 472.1180\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.6745 - val_loss: 458.7876\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.9481 - val_loss: 393.5122\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 380.2543 - val_loss: 423.2595\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 298.5843 - val_loss: 423.6809\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 400.6772 - val_loss: 481.8471\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 513.5548 - val_loss: 412.4816\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 369.4276 - val_loss: 411.0288\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 311.5842 - val_loss: 325.0647\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.1167 - val_loss: 446.3985\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 375.3940 - val_loss: 426.6484\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.3032 - val_loss: 414.5372\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 305.2844 - val_loss: 380.5152\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 366.9515 - val_loss: 229.3624\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 341.4724 - val_loss: 136.9348\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 284.8561 - val_loss: 160.4293\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 295.2098 - val_loss: 160.4180\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301.8046 - val_loss: 296.8165\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 297.3506 - val_loss: 282.8821\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.8742 - val_loss: 335.1632\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.9487 - val_loss: 322.3936\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 274.4078 - val_loss: 408.4810\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 337.7294 - val_loss: 295.5838\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292.6550 - val_loss: 227.8102\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 308.7464 - val_loss: 192.1129\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 301.1897 - val_loss: 231.8392\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 326.9245 - val_loss: 246.2520\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.6505 - val_loss: 315.2782\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 287.5327 - val_loss: 257.2595\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.7735 - val_loss: 368.1101\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292.7901 - val_loss: 388.4224\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 373.4643 - val_loss: 392.4116\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 365.5711 - val_loss: 492.6190\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 365.3451 - val_loss: 331.0333\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 378.0438 - val_loss: 271.7577\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 289.2723 - val_loss: 321.6882\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 275.4760 - val_loss: 207.9546\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 297.7054 - val_loss: 246.1177\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 278.1077 - val_loss: 304.1674\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.7006 - val_loss: 441.0950\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 405.7553 - val_loss: 368.6935\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 310.9792 - val_loss: 291.9633\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.0266 - val_loss: 327.4778\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 341.1786 - val_loss: 289.8462\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 372.8864 - val_loss: 317.9113\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.7083 - val_loss: 335.2724\n",
      "Epoch 935/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 331.8282 - val_loss: 342.1216\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 357.8877 - val_loss: 167.9949\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 351.7625 - val_loss: 264.3254\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 282.4100 - val_loss: 249.8156\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 291.8109 - val_loss: 236.6759\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 273.2783 - val_loss: 277.6096\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 344.4906 - val_loss: 145.4573\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.0110 - val_loss: 171.8960\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314.4784 - val_loss: 152.9204\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 279.1619 - val_loss: 125.5415\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.6193 - val_loss: 208.4582\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.2771 - val_loss: 129.8131\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 312.0158 - val_loss: 121.9907\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 364.9876 - val_loss: 167.5560\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 293.5665 - val_loss: 144.4563\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 290.9969 - val_loss: 185.3447\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301.4937 - val_loss: 146.6959\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.2671 - val_loss: 155.7962\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.8647 - val_loss: 368.2003\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 368.8339 - val_loss: 206.7132\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 394.6908 - val_loss: 184.8300\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 381.8858 - val_loss: 381.9105\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.8764 - val_loss: 189.4375\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.8292 - val_loss: 209.1784\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.7012 - val_loss: 135.9807\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 360.5085 - val_loss: 289.6663\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 391.8970 - val_loss: 189.2742\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292.8264 - val_loss: 125.3269\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 327.4046 - val_loss: 95.7056\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 378.7386 - val_loss: 177.2931\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 346.5029 - val_loss: 124.0130\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 406.2239 - val_loss: 207.1654\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 334.9076 - val_loss: 176.3273\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.1520 - val_loss: 154.4791\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.1816 - val_loss: 198.9996\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.2436 - val_loss: 130.3884\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 322.4293 - val_loss: 418.1348\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 420.2645 - val_loss: 195.0757\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 312.7576 - val_loss: 188.5726\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 354.1730 - val_loss: 347.6407\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.1241 - val_loss: 170.8399\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.2127 - val_loss: 298.2011\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.9431 - val_loss: 225.3589\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 384.1702 - val_loss: 159.9065\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.6064 - val_loss: 174.1754\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 361.3584 - val_loss: 327.3284\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333.3726 - val_loss: 213.3529\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 450.1220 - val_loss: 206.5562\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 392.4140 - val_loss: 286.9959\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 350.1902 - val_loss: 159.5416\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356.5941 - val_loss: 218.8101\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.9128 - val_loss: 175.8185\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.5972 - val_loss: 241.1967\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 434.8641 - val_loss: 230.0164\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 341.3655 - val_loss: 167.0916\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 378.2900 - val_loss: 255.5796\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 345.8901 - val_loss: 273.4560\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 327.7354 - val_loss: 283.7722\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.2336 - val_loss: 239.7598\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 281.5776 - val_loss: 469.6696\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 385.6420 - val_loss: 422.2248\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 303.2171 - val_loss: 195.8365\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 344.2978 - val_loss: 296.4143\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 368.5263 - val_loss: 314.1872\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 440.3978 - val_loss: 223.9979\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 347.5933 - val_loss: 201.0501\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 348.9308 - val_loss: 231.7213\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 346.2284 - val_loss: 174.3272\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 345.9192 - val_loss: 212.6946\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.8770 - val_loss: 133.8898\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 294.5305 - val_loss: 178.0864\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 293.1645 - val_loss: 293.6125\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.6555 - val_loss: 157.9017\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.3112 - val_loss: 188.7943\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.4474 - val_loss: 183.9740\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 390.6719 - val_loss: 201.7730\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.0436 - val_loss: 313.0704\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 370.1812 - val_loss: 329.7044\n",
      "Epoch 1013/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 328.7723 - val_loss: 339.2423\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 347.4806 - val_loss: 320.0573\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.0098 - val_loss: 247.1990\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 295.2058 - val_loss: 391.6407\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 341.5876 - val_loss: 249.1745\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 276.3006 - val_loss: 244.0081\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.8230 - val_loss: 236.7403\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.7202 - val_loss: 329.4836\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 365.0620 - val_loss: 245.3299\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 305.9218 - val_loss: 237.5923\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 489.0984 - val_loss: 168.6681\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 400.6667 - val_loss: 164.5453\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333.3146 - val_loss: 201.9830\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.4872 - val_loss: 278.8685\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333.8135 - val_loss: 273.0761\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 433.7924 - val_loss: 354.3252\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 384.3625 - val_loss: 272.7090\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 360.4289 - val_loss: 217.6039\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 347.9807 - val_loss: 226.5919\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 443.7189 - val_loss: 252.1607\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 389.9820 - val_loss: 284.0112\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 398.4076 - val_loss: 263.0879\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 363.5116 - val_loss: 246.0635\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 310.7359 - val_loss: 634.6925\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 550.4248 - val_loss: 464.0896\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 415.6072 - val_loss: 435.4050\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 426.1590 - val_loss: 444.2369\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 350.3556 - val_loss: 476.5809\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 371.1706 - val_loss: 418.4483\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356.7642 - val_loss: 423.7284\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 383.0832 - val_loss: 216.9512\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.1212 - val_loss: 261.4844\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 329.2015 - val_loss: 249.4900\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 271.8526 - val_loss: 233.8631\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 329.9139 - val_loss: 198.9445\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.3936 - val_loss: 545.9196\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 447.0125 - val_loss: 252.9501\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 452.8468 - val_loss: 228.1794\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 382.9248 - val_loss: 193.7131\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 352.4517 - val_loss: 289.9681\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.2505 - val_loss: 360.9501\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292.6162 - val_loss: 334.4406\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 306.3454 - val_loss: 425.7087\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 327.5576 - val_loss: 568.5165\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 366.2247 - val_loss: 365.1607\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314.6287 - val_loss: 338.6324\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.6269 - val_loss: 434.9660\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 418.9674 - val_loss: 421.1385\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333.0382 - val_loss: 252.1617\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.6534 - val_loss: 392.8730\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 425.8340 - val_loss: 306.4019\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 276.0929 - val_loss: 164.2194\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 279.4134 - val_loss: 174.0522\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 309.2105 - val_loss: 113.6627\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.1966 - val_loss: 251.1977\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292.1418 - val_loss: 283.4618\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 357.2004 - val_loss: 262.9761\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 287.7575 - val_loss: 218.8778\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 319.7716 - val_loss: 176.0013\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 296.0541 - val_loss: 149.0265\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 291.2808 - val_loss: 171.9488\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 306.9410 - val_loss: 155.2064\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.5024 - val_loss: 293.8064\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.0823 - val_loss: 348.6956\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.9111 - val_loss: 205.4454\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 296.0698 - val_loss: 220.6584\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292.1307 - val_loss: 182.2617\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 317.0851 - val_loss: 249.9239\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 289.9859 - val_loss: 266.7801\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 326.9478 - val_loss: 214.9191\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.7039 - val_loss: 232.4784\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 298.3227 - val_loss: 281.9460\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 307.5753 - val_loss: 270.8830\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 342.8683 - val_loss: 187.1770\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 352.2478 - val_loss: 241.1285\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.1003 - val_loss: 174.5673\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 287.4792 - val_loss: 263.4343\n",
      "Epoch 1090/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 336.3281 - val_loss: 291.1675\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 351.9290 - val_loss: 205.8365\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.7638 - val_loss: 233.4756\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.3225 - val_loss: 156.5230\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.6602 - val_loss: 194.4990\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 341.9770 - val_loss: 218.0578\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.8086 - val_loss: 155.6807\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 345.5468 - val_loss: 220.9666\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 300.6912 - val_loss: 221.5331\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 386.7338 - val_loss: 156.6567\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 349.9848 - val_loss: 240.5572\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 391.7444 - val_loss: 162.9718\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 343.0298 - val_loss: 158.1080\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 290.3293 - val_loss: 236.7638\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.1337 - val_loss: 251.9830\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 312.6257 - val_loss: 239.9874\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 297.6093 - val_loss: 225.4035\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 303.5013 - val_loss: 308.3621\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 283.8670 - val_loss: 393.6855\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.6180 - val_loss: 453.6660\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 271.8592 - val_loss: 394.3372\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.5493 - val_loss: 571.6620\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.6732 - val_loss: 470.5888\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 289.0233 - val_loss: 378.3146\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 317.4524 - val_loss: 316.2776\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.9238 - val_loss: 272.8577\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 305.9297 - val_loss: 240.1516\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.2024 - val_loss: 257.5624\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314.2765 - val_loss: 165.0188\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 350.7088 - val_loss: 275.3870\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.9747 - val_loss: 429.7576\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 311.0343 - val_loss: 245.2817\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304.8398 - val_loss: 239.2428\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338.7055 - val_loss: 208.9101\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 247.4960 - val_loss: 179.0538\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.6080 - val_loss: 211.5780\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301.1211 - val_loss: 250.9026\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 360.0439 - val_loss: 195.4311\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 289.6671 - val_loss: 175.5520\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 290.7809 - val_loss: 194.8894\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 281.5732 - val_loss: 269.4802\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 389.6897 - val_loss: 227.6482\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.8055 - val_loss: 233.0680\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.1692 - val_loss: 310.8995\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 328.2346 - val_loss: 262.4032\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 372.4368 - val_loss: 198.2830\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.2311 - val_loss: 190.9035\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 363.6072 - val_loss: 168.2205\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 380.9800 - val_loss: 188.5441\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 297.3195 - val_loss: 184.4862\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 277.4450 - val_loss: 210.0881\n",
      "Epoch 1141/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.0558 - val_loss: 213.9044\n",
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 265.8164 - val_loss: 208.3494\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 372.4143 - val_loss: 151.5163\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 302.6391 - val_loss: 182.1588\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 303.9382 - val_loss: 197.8961\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 326.4705 - val_loss: 175.6260\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 284.1515 - val_loss: 237.8873\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.2905 - val_loss: 215.8647\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 296.0156 - val_loss: 280.3537\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 357.4505 - val_loss: 232.0525\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 319.1018 - val_loss: 212.1723\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 380.4364 - val_loss: 275.1643\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 348.4885 - val_loss: 195.0288\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 325.8275 - val_loss: 132.1290\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 305.1816 - val_loss: 127.9523\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 319.1631 - val_loss: 261.2976\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 307.0338 - val_loss: 295.0521\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 491.1426 - val_loss: 366.2119\n",
      "Epoch 1159/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 458.6174 - val_loss: 163.7965\n",
      "Epoch 1160/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.6525 - val_loss: 157.6253\n",
      "Epoch 1161/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.2593 - val_loss: 148.4448\n",
      "Epoch 1162/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 288.0151 - val_loss: 192.0398\n",
      "Epoch 1163/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 311.5203 - val_loss: 200.2230\n",
      "Epoch 1164/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 297.0117 - val_loss: 124.3070\n",
      "Epoch 1165/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.7343 - val_loss: 194.1300\n",
      "Epoch 1166/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 393.4107 - val_loss: 179.5900\n",
      "Epoch 1167/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 356.0285 - val_loss: 146.3602\n",
      "Epoch 1168/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 311.3696 - val_loss: 156.3544\n",
      "Epoch 1169/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.8207 - val_loss: 110.3871\n",
      "Epoch 1170/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.9278 - val_loss: 144.5525\n",
      "Epoch 1171/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 254.3268 - val_loss: 157.4430\n",
      "Epoch 1172/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 294.7932 - val_loss: 160.2456\n",
      "Epoch 1173/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 296.9257 - val_loss: 167.6476\n",
      "Epoch 1174/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 236.5159 - val_loss: 250.6839\n",
      "Epoch 1175/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 273.2741 - val_loss: 241.9255\n",
      "Epoch 1176/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 298.0460 - val_loss: 203.0494\n",
      "Epoch 1177/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 289.7143 - val_loss: 240.5734\n",
      "Epoch 1178/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.5761 - val_loss: 148.3628\n",
      "Epoch 1179/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.2779 - val_loss: 132.2040\n",
      "Epoch 1180/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 271.8238 - val_loss: 143.7489\n",
      "Epoch 1181/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 262.9607 - val_loss: 144.5475\n",
      "Epoch 1182/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301.9512 - val_loss: 383.0406\n",
      "Epoch 1183/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 411.7448 - val_loss: 126.2623\n",
      "Epoch 1184/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 309.8360 - val_loss: 112.8338\n",
      "Epoch 1185/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.4126 - val_loss: 204.6426\n",
      "Epoch 1186/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 391.6106 - val_loss: 151.7957\n",
      "Epoch 1187/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 297.7593 - val_loss: 126.0608\n",
      "Epoch 1188/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 322.9604 - val_loss: 87.1966\n",
      "Epoch 1189/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 298.8177 - val_loss: 118.2963\n",
      "Epoch 1190/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.3781 - val_loss: 125.2615\n",
      "Epoch 1191/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 310.5910 - val_loss: 101.7586\n",
      "Epoch 1192/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 359.2836 - val_loss: 117.5711\n",
      "Epoch 1193/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 384.4932 - val_loss: 94.1695\n",
      "Epoch 1194/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 390.8684 - val_loss: 117.6036\n",
      "Epoch 1195/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 380.7017 - val_loss: 117.7183\n",
      "Epoch 1196/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 343.5597 - val_loss: 142.6193\n",
      "Epoch 1197/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314.4547 - val_loss: 140.7558\n",
      "Epoch 1198/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 284.6296 - val_loss: 139.8862\n",
      "Epoch 1199/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292.6333 - val_loss: 148.6305\n",
      "Epoch 1200/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 286.0279 - val_loss: 218.9007\n",
      "Epoch 1201/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 300.2609 - val_loss: 340.0992\n",
      "Epoch 1202/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 280.0867 - val_loss: 395.1380\n",
      "Epoch 1203/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.8479 - val_loss: 352.3448\n",
      "Epoch 1204/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.2280 - val_loss: 366.7724\n",
      "Epoch 1205/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 267.0761 - val_loss: 359.2062\n",
      "Epoch 1206/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 309.6528 - val_loss: 357.2192\n",
      "Epoch 1207/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 274.8305 - val_loss: 430.0000\n",
      "Epoch 1208/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 329.2860 - val_loss: 420.0436\n",
      "Epoch 1209/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333.9557 - val_loss: 359.2224\n",
      "Epoch 1210/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 279.8464 - val_loss: 357.7036\n",
      "Epoch 1211/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 303.5415 - val_loss: 181.4372\n",
      "Epoch 1212/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 245.7649 - val_loss: 202.9010\n",
      "Epoch 1213/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.4602 - val_loss: 259.5021\n",
      "Epoch 1214/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 257.5097 - val_loss: 250.7589\n",
      "Epoch 1215/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.3293 - val_loss: 170.5382\n",
      "Epoch 1216/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 306.7050 - val_loss: 135.6967\n",
      "Epoch 1217/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.6780 - val_loss: 188.9521\n",
      "Epoch 1218/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 286.0267 - val_loss: 274.5596\n",
      "Epoch 1219/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 308.0565 - val_loss: 380.0001\n",
      "Epoch 1220/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 342.8392 - val_loss: 282.0525\n",
      "Epoch 1221/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 297.5725 - val_loss: 266.6793\n",
      "Epoch 1222/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 355.5968 - val_loss: 313.4969\n",
      "Epoch 1223/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292.3014 - val_loss: 302.3887\n",
      "Epoch 1224/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 275.6220 - val_loss: 286.4106\n",
      "Epoch 1225/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314.1336 - val_loss: 277.8118\n",
      "Epoch 1226/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.7447 - val_loss: 306.6961\n",
      "Epoch 1227/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 269.3773 - val_loss: 317.2651\n",
      "Epoch 1228/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 305.6880 - val_loss: 282.2365\n",
      "Epoch 1229/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.2561 - val_loss: 287.8211\n",
      "Epoch 1230/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 325.9675 - val_loss: 302.9791\n",
      "Epoch 1231/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 306.8433 - val_loss: 302.5118\n",
      "Epoch 1232/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 334.8463 - val_loss: 456.3708\n",
      "Epoch 1233/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 349.9196 - val_loss: 227.1282\n",
      "Epoch 1234/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 289.2222 - val_loss: 303.7909\n",
      "Epoch 1235/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.4761 - val_loss: 304.1348\n",
      "Epoch 1236/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 417.3632 - val_loss: 209.1204\n",
      "Epoch 1237/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 310.9844 - val_loss: 183.1983\n",
      "Epoch 1238/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338.4709 - val_loss: 168.5243\n",
      "Epoch 1239/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 329.7129 - val_loss: 321.1326\n",
      "Epoch 1240/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 474.9988 - val_loss: 411.7581\n",
      "Epoch 1241/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 418.5696 - val_loss: 174.5106\n",
      "Epoch 1242/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 343.2059 - val_loss: 171.9803\n",
      "Epoch 1243/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 317.4290 - val_loss: 124.4287\n",
      "Epoch 1244/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 295.7803 - val_loss: 179.6044\n",
      "Epoch 1245/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 298.7958 - val_loss: 145.9642\n",
      "Epoch 1246/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 281.6142 - val_loss: 228.9252\n",
      "Epoch 1247/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.5739 - val_loss: 240.1242\n",
      "Epoch 1248/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 308.7990 - val_loss: 260.5636\n",
      "Epoch 1249/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 306.1732 - val_loss: 238.2764\n",
      "Epoch 1250/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 282.6333 - val_loss: 274.1550\n",
      "Epoch 1251/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 283.4701 - val_loss: 326.2153\n",
      "Epoch 1252/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 312.9210 - val_loss: 359.0157\n",
      "Epoch 1253/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 334.3966 - val_loss: 389.4341\n",
      "Epoch 1254/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 303.7093 - val_loss: 463.5599\n",
      "Epoch 1255/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 289.0018 - val_loss: 420.4368\n",
      "Epoch 1256/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 309.2262 - val_loss: 363.8022\n",
      "Epoch 1257/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 272.6146 - val_loss: 365.8754\n",
      "Epoch 1258/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.4110 - val_loss: 278.7176\n",
      "Epoch 1259/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.6757 - val_loss: 510.0163\n",
      "Epoch 1260/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 379.4614 - val_loss: 187.5238\n",
      "Epoch 1261/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 282.9377 - val_loss: 170.0772\n",
      "Epoch 1262/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 361.8597 - val_loss: 202.5423\n",
      "Epoch 1263/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.7011 - val_loss: 212.5460\n",
      "Epoch 1264/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 299.7773 - val_loss: 185.7230\n",
      "Epoch 1265/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.9598 - val_loss: 150.5209\n",
      "Epoch 1266/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 361.6985 - val_loss: 236.3890\n",
      "Epoch 1267/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 359.3388 - val_loss: 281.1992\n",
      "Epoch 1268/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 312.0175 - val_loss: 457.4539\n",
      "Epoch 1269/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 364.5645 - val_loss: 359.2397\n",
      "Epoch 1270/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 366.4097 - val_loss: 290.8122\n",
      "Epoch 1271/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338.2415 - val_loss: 263.4691\n",
      "Epoch 1272/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356.3989 - val_loss: 386.2322\n",
      "Epoch 1273/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 366.3477 - val_loss: 374.6094\n",
      "Epoch 1274/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 357.4308 - val_loss: 463.7242\n",
      "Epoch 1275/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 436.4567 - val_loss: 220.5637\n",
      "Epoch 1276/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 327.5820 - val_loss: 190.4355\n",
      "Epoch 1277/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.7567 - val_loss: 220.5533\n",
      "Epoch 1278/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 289.7562 - val_loss: 228.7869\n",
      "Epoch 1279/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.1062 - val_loss: 213.8308\n",
      "Epoch 1280/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 342.2166 - val_loss: 189.1113\n",
      "Epoch 1281/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 365.1181 - val_loss: 211.7498\n",
      "Epoch 1282/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 317.4838 - val_loss: 207.0935\n",
      "Epoch 1283/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 294.3227 - val_loss: 234.6123\n",
      "Epoch 1284/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 296.1721 - val_loss: 227.8681\n",
      "Epoch 1285/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 299.8319 - val_loss: 200.5879\n",
      "Epoch 1286/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 368.0474 - val_loss: 508.9638\n",
      "Epoch 1287/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 399.2416 - val_loss: 303.9373\n",
      "Epoch 1288/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 368.4745 - val_loss: 293.1384\n",
      "Epoch 1289/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.9853 - val_loss: 209.0429\n",
      "Epoch 1290/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304.8727 - val_loss: 377.9059\n",
      "Epoch 1291/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.4630 - val_loss: 231.4989\n",
      "Epoch 1292/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 373.8544 - val_loss: 217.8396\n",
      "Epoch 1293/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 288.8255 - val_loss: 265.4942\n",
      "Epoch 1294/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 297.8412 - val_loss: 215.8008\n",
      "Epoch 1295/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 306.1162 - val_loss: 204.8224\n",
      "Epoch 1296/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 286.5706 - val_loss: 194.6352\n",
      "Epoch 1297/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314.9355 - val_loss: 181.2520\n",
      "Epoch 1298/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.8564 - val_loss: 251.7139\n",
      "Epoch 1299/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.5065 - val_loss: 254.0035\n",
      "Epoch 1300/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 290.1793 - val_loss: 277.3747\n",
      "Epoch 1301/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 284.3279 - val_loss: 321.0681\n",
      "Epoch 1302/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 311.0553 - val_loss: 290.2347\n",
      "Epoch 1303/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.0438 - val_loss: 300.1035\n",
      "Epoch 1304/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 352.5943 - val_loss: 326.4854\n",
      "Epoch 1305/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.1632 - val_loss: 392.0400\n",
      "Epoch 1306/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 272.0957 - val_loss: 314.0375\n",
      "Epoch 1307/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 322.7865 - val_loss: 304.2556\n",
      "Epoch 1308/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 293.0527 - val_loss: 270.4514\n",
      "Epoch 1309/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 455.2312 - val_loss: 381.8001\n",
      "Epoch 1310/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 355.7502 - val_loss: 311.7338\n",
      "Epoch 1311/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.6546 - val_loss: 290.8373\n",
      "Epoch 1312/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304.6453 - val_loss: 287.8633\n",
      "Epoch 1313/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 309.1598 - val_loss: 327.0096\n",
      "Epoch 1314/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 297.8547 - val_loss: 328.5607\n",
      "Epoch 1315/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 331.4083 - val_loss: 294.7337\n",
      "Epoch 1316/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 344.0212 - val_loss: 326.1701\n",
      "Epoch 1317/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 285.5138 - val_loss: 612.1265\n",
      "Epoch 1318/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 265.9215 - val_loss: 489.1898\n",
      "Epoch 1319/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 328.0118 - val_loss: 425.3484\n",
      "Epoch 1320/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.7520 - val_loss: 320.7093\n",
      "Epoch 1321/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 341.9852 - val_loss: 541.6426\n",
      "Epoch 1322/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 364.0670 - val_loss: 573.8846\n",
      "Epoch 1323/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 389.2299 - val_loss: 445.1077\n",
      "Epoch 1324/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 344.3211 - val_loss: 369.8857\n",
      "Epoch 1325/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 361.8509 - val_loss: 388.5826\n",
      "Epoch 1326/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 317.0695 - val_loss: 393.4939\n",
      "Epoch 1327/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 347.3255 - val_loss: 356.3837\n",
      "Epoch 1328/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356.4507 - val_loss: 337.0711\n",
      "Epoch 1329/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 331.2165 - val_loss: 435.9428\n",
      "Epoch 1330/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 357.6784 - val_loss: 284.3907\n",
      "Epoch 1331/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 401.4380 - val_loss: 370.6422\n",
      "Epoch 1332/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.3987 - val_loss: 317.5917\n",
      "Epoch 1333/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.4902 - val_loss: 331.3679\n",
      "Epoch 1334/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.9917 - val_loss: 398.5926\n",
      "Epoch 1335/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 354.1248 - val_loss: 362.4307\n",
      "Epoch 1336/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.8973 - val_loss: 446.3004\n",
      "Epoch 1337/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 348.3594 - val_loss: 416.0883\n",
      "Epoch 1338/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 391.0706 - val_loss: 381.9907\n",
      "Epoch 1339/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 383.8388 - val_loss: 395.6509\n",
      "Epoch 1340/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 350.6422 - val_loss: 406.8777\n",
      "Epoch 1341/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 344.7935 - val_loss: 283.1139\n",
      "Epoch 1342/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 308.1159 - val_loss: 268.5609\n",
      "Epoch 1343/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.6946 - val_loss: 196.5783\n",
      "Epoch 1344/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 274.4247 - val_loss: 191.0389\n",
      "Epoch 1345/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 303.3698 - val_loss: 192.8623\n",
      "Epoch 1346/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 307.9810 - val_loss: 210.4655\n",
      "Epoch 1347/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.5887 - val_loss: 245.9500\n",
      "Epoch 1348/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.3485 - val_loss: 308.0670\n",
      "Epoch 1349/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 343.9116 - val_loss: 305.8336\n",
      "Epoch 1350/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 298.7807 - val_loss: 300.8239\n",
      "Epoch 1351/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 342.5080 - val_loss: 286.1881\n",
      "Epoch 1352/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 378.2668 - val_loss: 344.3477\n",
      "Epoch 1353/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.7786 - val_loss: 260.5318\n",
      "Epoch 1354/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 300.1185 - val_loss: 263.4186\n",
      "Epoch 1355/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 348.0341 - val_loss: 384.2835\n",
      "Epoch 1356/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 380.7851 - val_loss: 366.7493\n",
      "Epoch 1357/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 342.6697 - val_loss: 287.4380\n",
      "Epoch 1358/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 294.2288 - val_loss: 368.3745\n",
      "Epoch 1359/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 352.0244 - val_loss: 312.4650\n",
      "Epoch 1360/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333.1467 - val_loss: 304.2796\n",
      "Epoch 1361/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.8366 - val_loss: 422.2339\n",
      "Epoch 1362/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338.1294 - val_loss: 277.2487\n",
      "Epoch 1363/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301.7016 - val_loss: 284.0352\n",
      "Epoch 1364/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.9188 - val_loss: 265.1227\n",
      "Epoch 1365/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 286.6935 - val_loss: 365.9619\n",
      "Epoch 1366/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 290.7594 - val_loss: 259.4748\n",
      "Epoch 1367/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 349.9200 - val_loss: 255.5909\n",
      "Epoch 1368/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 273.3805 - val_loss: 305.4912\n",
      "Epoch 1369/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.5319 - val_loss: 312.7638\n",
      "Epoch 1370/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 272.2761 - val_loss: 309.7342\n",
      "Epoch 1371/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 294.6044 - val_loss: 383.9787\n",
      "Epoch 1372/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 282.0931 - val_loss: 346.8906\n",
      "Epoch 1373/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 276.0842 - val_loss: 335.3516\n",
      "Epoch 1374/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 285.9544 - val_loss: 244.9922\n",
      "Epoch 1375/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 290.2977 - val_loss: 216.5317\n",
      "Epoch 1376/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 309.3785 - val_loss: 251.2633\n",
      "Epoch 1377/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 271.5344 - val_loss: 255.3005\n",
      "Epoch 1378/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 279.2407 - val_loss: 251.3274\n",
      "Epoch 1379/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 279.1146 - val_loss: 353.0659\n",
      "Epoch 1380/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.5019 - val_loss: 304.7767\n",
      "Epoch 1381/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.6899 - val_loss: 262.0904\n",
      "Epoch 1382/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 295.7408 - val_loss: 340.8977\n",
      "Epoch 1383/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 302.6693 - val_loss: 267.8951\n",
      "Epoch 1384/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 267.8578 - val_loss: 337.3962\n",
      "Epoch 1385/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 280.5045 - val_loss: 274.6526\n",
      "Epoch 1386/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 285.2278 - val_loss: 289.7351\n",
      "Epoch 1387/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 259.4974 - val_loss: 279.4603\n",
      "Epoch 1388/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 302.8924 - val_loss: 315.7170\n",
      "Epoch 1389/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314.3154 - val_loss: 344.3165\n",
      "Epoch 1390/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 277.1874 - val_loss: 279.6569\n",
      "Epoch 1391/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 287.6779 - val_loss: 351.4787\n",
      "Epoch 1392/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 368.2372 - val_loss: 243.7879\n",
      "Epoch 1393/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 293.1156 - val_loss: 254.1405\n",
      "Epoch 1394/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.9170 - val_loss: 234.8345\n",
      "Epoch 1395/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 334.8122 - val_loss: 198.8494\n",
      "Epoch 1396/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 344.3396 - val_loss: 273.6385\n",
      "Epoch 1397/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.1855 - val_loss: 183.9274\n",
      "Epoch 1398/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 314.2141 - val_loss: 208.3299\n",
      "Epoch 1399/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 334.0910 - val_loss: 199.2609\n",
      "Epoch 1400/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 344.4301 - val_loss: 282.6612\n",
      "Epoch 1401/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.8521 - val_loss: 234.3660\n",
      "Epoch 1402/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 366.1415 - val_loss: 151.0260\n",
      "Epoch 1403/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 317.2142 - val_loss: 169.5778\n",
      "Epoch 1404/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.5229 - val_loss: 174.5671\n",
      "Epoch 1405/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 291.7531 - val_loss: 179.1744\n",
      "Epoch 1406/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338.4087 - val_loss: 169.5276\n",
      "Epoch 1407/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 277.1433 - val_loss: 191.5962\n",
      "Epoch 1408/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 251.6245 - val_loss: 271.9339\n",
      "Epoch 1409/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 288.7113 - val_loss: 221.4791\n",
      "Epoch 1410/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 248.4095 - val_loss: 258.7949\n",
      "Epoch 1411/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 274.3379 - val_loss: 253.7093\n",
      "Epoch 1412/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 334.9031 - val_loss: 278.1821\n",
      "Epoch 1413/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 283.3640 - val_loss: 270.1131\n",
      "Epoch 1414/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.9171 - val_loss: 168.1307\n",
      "Epoch 1415/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 290.4245 - val_loss: 169.2316\n",
      "Epoch 1416/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 307.8780 - val_loss: 231.8013\n",
      "Epoch 1417/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 294.0153 - val_loss: 249.9046\n",
      "Epoch 1418/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 248.5800 - val_loss: 278.7115\n",
      "Epoch 1419/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 303.7324 - val_loss: 181.4247\n",
      "Epoch 1420/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 288.3660 - val_loss: 187.4524\n",
      "Epoch 1421/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 278.5029 - val_loss: 223.0520\n",
      "Epoch 1422/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.9009 - val_loss: 190.9313\n",
      "Epoch 1423/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 329.3862 - val_loss: 266.8698\n",
      "Epoch 1424/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 378.2185 - val_loss: 545.9979\n",
      "Epoch 1425/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 483.8337 - val_loss: 291.3904\n",
      "Epoch 1426/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 441.7565 - val_loss: 349.9241\n",
      "Epoch 1427/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 355.7964 - val_loss: 375.8611\n",
      "Epoch 1428/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 410.3698 - val_loss: 391.6795\n",
      "Epoch 1429/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.8517 - val_loss: 411.8130\n",
      "Epoch 1430/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 376.0804 - val_loss: 382.3227\n",
      "Epoch 1431/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 420.7958 - val_loss: 309.4614\n",
      "Epoch 1432/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.1369 - val_loss: 256.7195\n",
      "Epoch 1433/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 360.6488 - val_loss: 273.7735\n",
      "Epoch 1434/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.8260 - val_loss: 312.9967\n",
      "Epoch 1435/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 363.0828 - val_loss: 313.4094\n",
      "Epoch 1436/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301.7483 - val_loss: 327.9219\n",
      "Epoch 1437/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.3013 - val_loss: 346.8510\n",
      "Epoch 1438/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314.3933 - val_loss: 372.3204\n",
      "Epoch 1439/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 300.6320 - val_loss: 239.7676\n",
      "Epoch 1440/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 393.8649 - val_loss: 297.9624\n",
      "Epoch 1441/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 302.3482 - val_loss: 230.9520\n",
      "Epoch 1442/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338.7668 - val_loss: 226.3200\n",
      "Epoch 1443/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 306.4650 - val_loss: 241.6320\n",
      "Epoch 1444/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 368.8023 - val_loss: 209.3553\n",
      "Epoch 1445/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 325.1987 - val_loss: 206.4944\n",
      "Epoch 1446/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 278.4248 - val_loss: 224.0170\n",
      "Epoch 1447/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356.6405 - val_loss: 240.0734\n",
      "Epoch 1448/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.0386 - val_loss: 302.2720\n",
      "Epoch 1449/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 384.3715 - val_loss: 237.2551\n",
      "Epoch 1450/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.8221 - val_loss: 260.7823\n",
      "Epoch 1451/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 369.9277 - val_loss: 181.6688\n",
      "Epoch 1452/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 317.9151 - val_loss: 254.2862\n",
      "Epoch 1453/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.9616 - val_loss: 237.2926\n",
      "Epoch 1454/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 307.7737 - val_loss: 233.4211\n",
      "Epoch 1455/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 319.1988 - val_loss: 233.6326\n",
      "Epoch 1456/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.7612 - val_loss: 249.1682\n",
      "Epoch 1457/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 392.0349 - val_loss: 193.6544\n",
      "Epoch 1458/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 341.8218 - val_loss: 200.8458\n",
      "Epoch 1459/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.2731 - val_loss: 238.0862\n",
      "Epoch 1460/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292.5542 - val_loss: 336.4757\n",
      "Epoch 1461/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 279.9277 - val_loss: 334.2400\n",
      "Epoch 1462/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314.4239 - val_loss: 343.3427\n",
      "Epoch 1463/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 286.9269 - val_loss: 414.8442\n",
      "Epoch 1464/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 366.3761 - val_loss: 444.5231\n",
      "Epoch 1465/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 342.9051 - val_loss: 438.2593\n",
      "Epoch 1466/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 329.8976 - val_loss: 504.3772\n",
      "Epoch 1467/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 378.0787 - val_loss: 459.8366\n",
      "Epoch 1468/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 327.0901 - val_loss: 388.5811\n",
      "Epoch 1469/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 302.9768 - val_loss: 439.7291\n",
      "Epoch 1470/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 306.9573 - val_loss: 473.8134\n",
      "Epoch 1471/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.1324 - val_loss: 431.2828\n",
      "Epoch 1472/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.9583 - val_loss: 325.3557\n",
      "Epoch 1473/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 327.3879 - val_loss: 322.3015\n",
      "Epoch 1474/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.1017 - val_loss: 280.2638\n",
      "Epoch 1475/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 327.8579 - val_loss: 214.3385\n",
      "Epoch 1476/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 275.2063 - val_loss: 204.1894\n",
      "Epoch 1477/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.2593 - val_loss: 435.3123\n",
      "Epoch 1478/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 504.9590 - val_loss: 188.6311\n",
      "Epoch 1479/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 392.9966 - val_loss: 309.2244\n",
      "Epoch 1480/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 397.0123 - val_loss: 213.1206\n",
      "Epoch 1481/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 348.3903 - val_loss: 254.5066\n",
      "Epoch 1482/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 346.3015 - val_loss: 334.4500\n",
      "Epoch 1483/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 355.3903 - val_loss: 272.0212\n",
      "Epoch 1484/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 368.5888 - val_loss: 210.4627\n",
      "Epoch 1485/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 456.1907 - val_loss: 259.6404\n",
      "Epoch 1486/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 369.6051 - val_loss: 228.7822\n",
      "Epoch 1487/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 309.8046 - val_loss: 236.8235\n",
      "Epoch 1488/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 297.2642 - val_loss: 272.0809\n",
      "Epoch 1489/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314.1327 - val_loss: 258.2617\n",
      "Epoch 1490/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.3786 - val_loss: 457.3993\n",
      "Epoch 1491/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 360.2940 - val_loss: 251.7637\n",
      "Epoch 1492/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 295.6626 - val_loss: 233.9067\n",
      "Epoch 1493/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 357.2380 - val_loss: 223.1138\n",
      "Epoch 1494/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 326.1713 - val_loss: 339.1856\n",
      "Epoch 1495/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 341.4799 - val_loss: 317.3886\n",
      "Epoch 1496/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 363.8165 - val_loss: 286.5184\n",
      "Epoch 1497/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 373.6361 - val_loss: 429.9761\n",
      "Epoch 1498/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 355.5890 - val_loss: 358.3071\n",
      "Epoch 1499/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 328.8250 - val_loss: 270.6841\n",
      "Epoch 1500/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 318.5549 - val_loss: 285.8920\n",
      "Epoch 1501/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 288.7099 - val_loss: 449.6831\n",
      "Epoch 1502/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 385.3036 - val_loss: 350.5259\n",
      "Epoch 1503/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 303.8151 - val_loss: 349.4337\n",
      "Epoch 1504/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 328.9609 - val_loss: 409.6550\n",
      "Epoch 1505/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 331.0874 - val_loss: 584.6719\n",
      "Epoch 1506/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 385.9054 - val_loss: 689.1159\n",
      "Epoch 1507/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 509.3643 - val_loss: 400.7662\n",
      "Epoch 1508/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 364.4248 - val_loss: 415.8404\n",
      "Epoch 1509/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356.8215 - val_loss: 374.9789\n",
      "Epoch 1510/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.6530 - val_loss: 388.3593\n",
      "Epoch 1511/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.4551 - val_loss: 485.1043\n",
      "Epoch 1512/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 421.6788 - val_loss: 386.4401\n",
      "Epoch 1513/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 286.6742 - val_loss: 423.5103\n",
      "Epoch 1514/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 326.9863 - val_loss: 427.3885\n",
      "Epoch 1515/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 260.8677 - val_loss: 413.5932\n",
      "Epoch 1516/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.3934 - val_loss: 414.5251\n",
      "Epoch 1517/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 297.0403 - val_loss: 307.0060\n",
      "Epoch 1518/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 305.6580 - val_loss: 321.2854\n",
      "Epoch 1519/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 267.9556 - val_loss: 324.5852\n",
      "Epoch 1520/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 299.0279 - val_loss: 282.0530\n",
      "Epoch 1521/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 269.8825 - val_loss: 255.2005\n",
      "Epoch 1522/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 249.8599 - val_loss: 338.9947\n",
      "Epoch 1523/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 310.1339 - val_loss: 304.8211\n",
      "Epoch 1524/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 326.6667 - val_loss: 407.5239\n",
      "Epoch 1525/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 308.5991 - val_loss: 397.6979\n",
      "Epoch 1526/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 283.3457 - val_loss: 392.8461\n",
      "Epoch 1527/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 282.0337 - val_loss: 406.3648\n",
      "Epoch 1528/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 289.2129 - val_loss: 359.3781\n",
      "Epoch 1529/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 288.4381 - val_loss: 289.8693\n",
      "Epoch 1530/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 337.3512 - val_loss: 308.4160\n",
      "Epoch 1531/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 311.0726 - val_loss: 495.6237\n",
      "Epoch 1532/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.2531 - val_loss: 439.0273\n",
      "Epoch 1533/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 296.6830 - val_loss: 326.4085\n",
      "Epoch 1534/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 278.0259 - val_loss: 401.3996\n",
      "Epoch 1535/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.2088 - val_loss: 347.7527\n",
      "Epoch 1536/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 319.5266 - val_loss: 306.0370\n",
      "Epoch 1537/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 282.2586 - val_loss: 246.3935\n",
      "Epoch 1538/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.9128 - val_loss: 213.2003\n",
      "Epoch 1539/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 269.4139 - val_loss: 224.1333\n",
      "Epoch 1540/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 281.9833 - val_loss: 217.5457\n",
      "Epoch 1541/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 281.7663 - val_loss: 291.7178\n",
      "Epoch 1542/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 311.6886 - val_loss: 286.8636\n",
      "Epoch 1543/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.3351 - val_loss: 367.5257\n",
      "Epoch 1544/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 322.4298 - val_loss: 335.8539\n",
      "Epoch 1545/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 286.7715 - val_loss: 380.0161\n",
      "Epoch 1546/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 267.7376 - val_loss: 272.4382\n",
      "Epoch 1547/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304.4190 - val_loss: 236.9559\n",
      "Epoch 1548/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304.9560 - val_loss: 299.3930\n",
      "Epoch 1549/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292.4792 - val_loss: 283.2941\n",
      "Epoch 1550/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 257.7131 - val_loss: 292.6838\n",
      "Epoch 1551/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 302.4195 - val_loss: 388.7617\n",
      "Epoch 1552/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 304.3364 - val_loss: 337.2284\n",
      "Epoch 1553/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 283.7733 - val_loss: 245.2729\n",
      "Epoch 1554/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 257.7415 - val_loss: 379.0097\n",
      "Epoch 1555/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 267.1216 - val_loss: 281.9626\n",
      "Epoch 1556/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 284.2518 - val_loss: 290.5987\n",
      "Epoch 1557/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 342.8638 - val_loss: 343.5930\n",
      "Epoch 1558/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 296.2300 - val_loss: 411.3531\n",
      "Epoch 1559/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 286.8618 - val_loss: 384.2901\n",
      "Epoch 1560/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 308.8291 - val_loss: 331.7415\n",
      "Epoch 1561/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.7702 - val_loss: 263.6415\n",
      "Epoch 1562/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 305.8196 - val_loss: 343.2689\n",
      "Epoch 1563/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.9498 - val_loss: 297.6948\n",
      "Epoch 1564/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 434.3603 - val_loss: 331.5489\n",
      "Epoch 1565/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 430.3558 - val_loss: 255.2372\n",
      "Epoch 1566/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.1266 - val_loss: 259.1886\n",
      "Epoch 1567/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 393.5269 - val_loss: 227.2743\n",
      "Epoch 1568/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 447.5172 - val_loss: 258.9519\n",
      "Epoch 1569/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 325.8556 - val_loss: 180.3651\n",
      "Epoch 1570/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 280.3857 - val_loss: 255.9803\n",
      "Epoch 1571/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.8686 - val_loss: 247.7170\n",
      "Epoch 1572/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 392.0898 - val_loss: 320.1836\n",
      "Epoch 1573/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 374.2193 - val_loss: 251.9983\n",
      "Epoch 1574/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.4709 - val_loss: 239.5569\n",
      "Epoch 1575/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.1122 - val_loss: 701.9594\n",
      "Epoch 1576/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.0607 - val_loss: 416.1528\n",
      "Epoch 1577/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 265.3555 - val_loss: 414.1719\n",
      "Epoch 1578/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 368.6682 - val_loss: 502.2192\n",
      "Epoch 1579/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 272.5295 - val_loss: 418.8870\n",
      "Epoch 1580/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292.7783 - val_loss: 425.0889\n",
      "Epoch 1581/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 232.8974 - val_loss: 579.0609\n",
      "Epoch 1582/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 291.3988 - val_loss: 419.5808\n",
      "Epoch 1583/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 263.7768 - val_loss: 386.8377\n",
      "Epoch 1584/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 284.3660 - val_loss: 357.4584\n",
      "Epoch 1585/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 259.8574 - val_loss: 301.1472\n",
      "Epoch 1586/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 283.0673 - val_loss: 327.5278\n",
      "Epoch 1587/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314.6008 - val_loss: 334.0491\n",
      "Epoch 1588/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 284.1934 - val_loss: 354.4449\n",
      "Epoch 1589/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 283.8613 - val_loss: 317.6203\n",
      "Epoch 1590/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 308.0739 - val_loss: 324.1877\n",
      "Epoch 1591/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 359.9531 - val_loss: 434.2541\n",
      "Epoch 1592/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 392.8498 - val_loss: 335.2956\n",
      "Epoch 1593/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.4366 - val_loss: 281.0045\n",
      "Epoch 1594/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.7469 - val_loss: 312.8433\n",
      "Epoch 1595/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.5428 - val_loss: 512.4044\n",
      "Epoch 1596/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 345.9651 - val_loss: 529.3126\n",
      "Epoch 1597/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 359.5873 - val_loss: 517.0408\n",
      "Epoch 1598/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.3981 - val_loss: 474.2901\n",
      "Epoch 1599/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333.7467 - val_loss: 654.5264\n",
      "Epoch 1600/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.7772 - val_loss: 506.9166\n",
      "Epoch 1601/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 276.3526 - val_loss: 493.1968\n",
      "Epoch 1602/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 376.5809 - val_loss: 346.6479\n",
      "Epoch 1603/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 357.5692 - val_loss: 385.9789\n",
      "Epoch 1604/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 404.6857 - val_loss: 420.0229\n",
      "Epoch 1605/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.5632 - val_loss: 343.6164\n",
      "Epoch 1606/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 299.1101 - val_loss: 385.3450\n",
      "Epoch 1607/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 309.3130 - val_loss: 600.3912\n",
      "Epoch 1608/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 406.0239 - val_loss: 324.0691\n",
      "Epoch 1609/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 355.6861 - val_loss: 306.7357\n",
      "Epoch 1610/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 351.4154 - val_loss: 359.5047\n",
      "Epoch 1611/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.6973 - val_loss: 343.1184\n",
      "Epoch 1612/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 365.0486 - val_loss: 489.7986\n",
      "Epoch 1613/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 351.9269 - val_loss: 388.7905\n",
      "Epoch 1614/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356.9774 - val_loss: 278.4107\n",
      "Epoch 1615/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 361.4005 - val_loss: 274.4957\n",
      "Epoch 1616/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 348.4053 - val_loss: 243.6600\n",
      "Epoch 1617/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 327.7461 - val_loss: 307.8517\n",
      "Epoch 1618/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 380.6147 - val_loss: 193.9842\n",
      "Epoch 1619/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.6211 - val_loss: 225.2534\n",
      "Epoch 1620/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 352.2391 - val_loss: 243.5702\n",
      "Epoch 1621/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 345.2821 - val_loss: 221.4688\n",
      "Epoch 1622/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.6817 - val_loss: 292.2867\n",
      "Epoch 1623/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 403.6124 - val_loss: 337.1132\n",
      "Epoch 1624/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 364.6878 - val_loss: 211.1449\n",
      "Epoch 1625/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 347.4397 - val_loss: 318.0771\n",
      "Epoch 1626/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 393.2983 - val_loss: 261.6454\n",
      "Epoch 1627/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 296.8530 - val_loss: 214.8062\n",
      "Epoch 1628/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 310.4722 - val_loss: 206.1763\n",
      "Epoch 1629/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 341.5768 - val_loss: 204.8458\n",
      "Epoch 1630/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 323.6663 - val_loss: 218.2839\n",
      "Epoch 1631/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301.7525 - val_loss: 204.6677\n",
      "Epoch 1632/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 300.1492 - val_loss: 205.6833\n",
      "Epoch 1633/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.8982 - val_loss: 251.5802\n",
      "Epoch 1634/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.7129 - val_loss: 229.7201\n",
      "Epoch 1635/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 343.0766 - val_loss: 335.0283\n",
      "Epoch 1636/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 334.0487 - val_loss: 305.4274\n",
      "Epoch 1637/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 304.0446 - val_loss: 297.0242\n",
      "Epoch 1638/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 325.6250 - val_loss: 285.6246\n",
      "Epoch 1639/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 378.7444 - val_loss: 278.3732\n",
      "Epoch 1640/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.2147 - val_loss: 311.3649\n",
      "Epoch 1641/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 338.4569 - val_loss: 284.6597\n",
      "Epoch 1642/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.3144 - val_loss: 271.7625\n",
      "Epoch 1643/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 358.2420 - val_loss: 244.1532\n",
      "Epoch 1644/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 359.2180 - val_loss: 246.1208\n",
      "Epoch 1645/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 365.0524 - val_loss: 245.7644\n",
      "Epoch 1646/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 374.4102 - val_loss: 224.8530\n",
      "Epoch 1647/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 382.1856 - val_loss: 244.8089\n",
      "Epoch 1648/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.4417 - val_loss: 232.8565\n",
      "Epoch 1649/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301.8517 - val_loss: 253.0023\n",
      "Epoch 1650/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 312.4167 - val_loss: 183.4520\n",
      "Epoch 1651/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.9812 - val_loss: 245.4004\n",
      "Epoch 1652/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 340.2476 - val_loss: 255.7926\n",
      "Epoch 1653/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 418.0061 - val_loss: 258.3253\n",
      "Epoch 1654/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.0251 - val_loss: 263.8287\n",
      "Epoch 1655/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 344.0151 - val_loss: 479.1522\n",
      "Epoch 1656/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 352.3374 - val_loss: 292.6876\n",
      "Epoch 1657/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 324.2793 - val_loss: 287.9563\n",
      "Epoch 1658/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 374.2643 - val_loss: 286.8605\n",
      "Epoch 1659/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 421.9911 - val_loss: 292.2272\n",
      "Epoch 1660/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 377.4117 - val_loss: 498.7052\n",
      "Epoch 1661/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 401.2357 - val_loss: 425.3072\n",
      "Epoch 1662/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 393.9425 - val_loss: 366.6838\n",
      "Epoch 1663/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 346.3813 - val_loss: 319.8988\n",
      "Epoch 1664/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.7626 - val_loss: 317.5885\n",
      "Epoch 1665/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 299.3490 - val_loss: 233.2831\n",
      "Epoch 1666/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 327.3838 - val_loss: 316.3410\n",
      "Epoch 1667/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 332.4082 - val_loss: 150.6973\n",
      "Epoch 1668/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.0882 - val_loss: 160.3439\n",
      "Epoch 1669/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 326.3383 - val_loss: 181.7323\n",
      "Epoch 1670/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 341.1427 - val_loss: 211.3569\n",
      "Epoch 1671/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 352.3573 - val_loss: 262.4261\n",
      "Epoch 1672/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 421.3030 - val_loss: 168.1301\n",
      "Epoch 1673/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 346.7911 - val_loss: 374.7997\n",
      "Epoch 1674/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.3686 - val_loss: 198.3177\n",
      "Epoch 1675/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.4497 - val_loss: 176.0686\n",
      "Epoch 1676/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 310.6867 - val_loss: 222.6413\n",
      "Epoch 1677/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.9904 - val_loss: 344.6913\n",
      "Epoch 1678/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 300.5464 - val_loss: 272.7796\n",
      "Epoch 1679/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.6878 - val_loss: 246.1860\n",
      "Epoch 1680/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 372.8214 - val_loss: 300.7304\n",
      "Epoch 1681/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.8351 - val_loss: 247.1255\n",
      "Epoch 1682/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 325.5734 - val_loss: 247.4183\n",
      "Epoch 1683/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 317.4861 - val_loss: 230.7937\n",
      "Epoch 1684/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 310.5621 - val_loss: 210.6234\n",
      "Epoch 1685/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.3761 - val_loss: 237.2202\n",
      "Epoch 1686/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.8236 - val_loss: 224.7413\n",
      "Epoch 1687/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 313.5233 - val_loss: 397.8929\n",
      "Epoch 1688/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 419.0923Restoring model weights from the end of the best epoch: 1188.\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 291.0118 - val_loss: 275.3842\n",
      "Epoch 1688: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, train_target, want_verbose=1, seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        error = np.abs(prediction - test_target[start_target + i])\n",
    "        errors.append(error)\n",
    "        error_percent.append(error / test_target[start_target + i])\n",
    "        print(f\"Month-{i + 1} - Error: {error}\")\n",
    "    \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09914e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "Month-1 - Error: [[50.986954]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-2 - Error: [[21.685028]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-3 - Error: [[44.676865]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-4 - Error: [[20.723831]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-5 - Error: [[5.780075]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-6 - Error: [[6.096634]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-7 - Error: [[33.52365]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-8 - Error: [[26.302444]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-9 - Error: [[42.06888]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-10 - Error: [[27.614594]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-11 - Error: [[8.818176]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-12 - Error: [[44.85518]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-13 - Error: [[0.45040894]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-14 - Error: [[18.534225]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-15 - Error: [[15.971268]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-16 - Error: [[30.939377]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-17 - Error: [[49.632843]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-18 - Error: [[54.86371]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-19 - Error: [[86.69263]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-20 - Error: [[52.8898]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-21 - Error: [[70.88939]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-22 - Error: [[49.784424]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-23 - Error: [[2.3363495]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-24 - Error: [[85.43883]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-25 - Error: [[43.440887]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-26 - Error: [[35.62291]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-27 - Error: [[46.313904]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-28 - Error: [[75.9229]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-29 - Error: [[5.7760925]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-30 - Error: [[64.5219]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-31 - Error: [[75.47691]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-32 - Error: [[79.54591]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-33 - Error: [[122.26991]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-34 - Error: [[92.08891]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Month-35 - Error: [[58.848923]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Month-36 - Error: [[94.321915]]\n"
     ]
    }
   ],
   "source": [
    "errors, mae, mape = mae_mape_calculator(trained_model, test_input, test_target, 168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.71407"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.16908966"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[2929.8616]] - Target[3060.1059999999998]| =  Error: [[130.24438]]; MAPE:[[0.04256205]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[2556.6997]] - Target[3013.2439999999997]| =  Error: [[456.5442]]; MAPE:[[0.15151252]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-11: |Prediction[[2471.8691]] - Target[3254.4680000000003]| =  Error: [[782.5989]]; MAPE:[[0.24046907]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[130.24438]], dtype=float32),\n",
       " array([[456.5442]], dtype=float32),\n",
       " array([[782.5989]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "456.4625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.14484788"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, test_input, test_target, 168)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
