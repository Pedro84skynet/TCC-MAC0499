{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Paraíba - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Paraíba - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Paraíba - Produção de Cimento (t)</th>\n",
       "      <th>Paraíba - value</th>\n",
       "      <th>Paraíba - IDH</th>\n",
       "      <th>Paraíba - PIB - Estadual</th>\n",
       "      <th>Paraíba - PIB - Construção Civil</th>\n",
       "      <th>Paraíba - PIB - Per Capita</th>\n",
       "      <th>Paraíba - PIB - Preços de Mercado</th>\n",
       "      <th>Paraíba - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>8.315958</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>118.926160</td>\n",
       "      <td>0.182304</td>\n",
       "      <td>0.656510</td>\n",
       "      <td>3.017292e+07</td>\n",
       "      <td>1.631334e+06</td>\n",
       "      <td>7.291169</td>\n",
       "      <td>2.736342e+07</td>\n",
       "      <td>38.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>8.309895</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>117.724891</td>\n",
       "      <td>0.185909</td>\n",
       "      <td>0.656949</td>\n",
       "      <td>3.021010e+07</td>\n",
       "      <td>1.632950e+06</td>\n",
       "      <td>7.293438</td>\n",
       "      <td>2.737516e+07</td>\n",
       "      <td>31.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>8.303831</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>118.501965</td>\n",
       "      <td>0.189593</td>\n",
       "      <td>0.657388</td>\n",
       "      <td>3.024728e+07</td>\n",
       "      <td>1.634566e+06</td>\n",
       "      <td>7.295708</td>\n",
       "      <td>2.738689e+07</td>\n",
       "      <td>28.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>8.297767</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>119.390679</td>\n",
       "      <td>0.193353</td>\n",
       "      <td>0.657827</td>\n",
       "      <td>3.028445e+07</td>\n",
       "      <td>1.636182e+06</td>\n",
       "      <td>7.297978</td>\n",
       "      <td>2.739862e+07</td>\n",
       "      <td>28.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>8.291704</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>121.517541</td>\n",
       "      <td>0.197186</td>\n",
       "      <td>0.658266</td>\n",
       "      <td>3.032163e+07</td>\n",
       "      <td>1.637798e+06</td>\n",
       "      <td>7.300247</td>\n",
       "      <td>2.741035e+07</td>\n",
       "      <td>31.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>294.165653</td>\n",
       "      <td>0.679715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>293.457511</td>\n",
       "      <td>0.678961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>292.809622</td>\n",
       "      <td>0.677475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290.980478</td>\n",
       "      <td>0.676277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>289.805678</td>\n",
       "      <td>0.675003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Paraíba - Desemprego  \\\n",
       "0       2003-1              8.315958   \n",
       "1       2003-2              8.309895   \n",
       "2       2003-3              8.303831   \n",
       "3       2003-4              8.297767   \n",
       "4       2003-5              8.291704   \n",
       "..         ...                   ...   \n",
       "235     2022-8                   NaN   \n",
       "236     2022-9                   NaN   \n",
       "237    2022-10                   NaN   \n",
       "238    2022-11                   NaN   \n",
       "239    2022-12                   NaN   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     Paraíba - Produção de Cimento (t)  Paraíba - value  Paraíba - IDH  \\\n",
       "0                           118.926160         0.182304       0.656510   \n",
       "1                           117.724891         0.185909       0.656949   \n",
       "2                           118.501965         0.189593       0.657388   \n",
       "3                           119.390679         0.193353       0.657827   \n",
       "4                           121.517541         0.197186       0.658266   \n",
       "..                                 ...              ...            ...   \n",
       "235                         294.165653         0.679715            NaN   \n",
       "236                         293.457511         0.678961            NaN   \n",
       "237                         292.809622         0.677475            NaN   \n",
       "238                         290.980478         0.676277            NaN   \n",
       "239                         289.805678         0.675003            NaN   \n",
       "\n",
       "     Paraíba - PIB - Estadual  Paraíba - PIB - Construção Civil  \\\n",
       "0                3.017292e+07                      1.631334e+06   \n",
       "1                3.021010e+07                      1.632950e+06   \n",
       "2                3.024728e+07                      1.634566e+06   \n",
       "3                3.028445e+07                      1.636182e+06   \n",
       "4                3.032163e+07                      1.637798e+06   \n",
       "..                        ...                               ...   \n",
       "235                       NaN                               NaN   \n",
       "236                       NaN                               NaN   \n",
       "237                       NaN                               NaN   \n",
       "238                       NaN                               NaN   \n",
       "239                       NaN                               NaN   \n",
       "\n",
       "     Paraíba - PIB - Per Capita  Paraíba - PIB - Preços de Mercado  \\\n",
       "0                      7.291169                       2.736342e+07   \n",
       "1                      7.293438                       2.737516e+07   \n",
       "2                      7.295708                       2.738689e+07   \n",
       "3                      7.297978                       2.739862e+07   \n",
       "4                      7.300247                       2.741035e+07   \n",
       "..                          ...                                ...   \n",
       "235                         NaN                                NaN   \n",
       "236                         NaN                                NaN   \n",
       "237                         NaN                                NaN   \n",
       "238                         NaN                                NaN   \n",
       "239                         NaN                                NaN   \n",
       "\n",
       "     Paraíba - Consumo de Cimento (t)  \n",
       "0                              38.426  \n",
       "1                              31.672  \n",
       "2                              28.775  \n",
       "3                              28.571  \n",
       "4                              31.613  \n",
       "..                                ...  \n",
       "235                            95.860  \n",
       "236                            90.790  \n",
       "237                            94.588  \n",
       "238                            89.777  \n",
       "239                            89.777  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_PB.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paraíba - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Paraíba - Produção de Cimento (t)</th>\n",
       "      <th>Paraíba - value</th>\n",
       "      <th>Paraíba - IDH</th>\n",
       "      <th>Paraíba - PIB - Estadual</th>\n",
       "      <th>Paraíba - PIB - Construção Civil</th>\n",
       "      <th>Paraíba - PIB - Per Capita</th>\n",
       "      <th>Paraíba - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.800943</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-2.092830</td>\n",
       "      <td>-2.424081</td>\n",
       "      <td>-2.168844</td>\n",
       "      <td>-1.710694</td>\n",
       "      <td>-2.484291</td>\n",
       "      <td>-2.270808</td>\n",
       "      <td>-2.124240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.805366</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-2.140285</td>\n",
       "      <td>-2.392248</td>\n",
       "      <td>-2.133132</td>\n",
       "      <td>-1.692339</td>\n",
       "      <td>-2.436666</td>\n",
       "      <td>-2.234559</td>\n",
       "      <td>-2.091568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.809789</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-2.109587</td>\n",
       "      <td>-2.359718</td>\n",
       "      <td>-2.097421</td>\n",
       "      <td>-1.673984</td>\n",
       "      <td>-2.389041</td>\n",
       "      <td>-2.198310</td>\n",
       "      <td>-2.058896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.814212</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-2.074479</td>\n",
       "      <td>-2.326517</td>\n",
       "      <td>-2.061709</td>\n",
       "      <td>-1.655629</td>\n",
       "      <td>-2.341417</td>\n",
       "      <td>-2.162061</td>\n",
       "      <td>-2.026224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.818635</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.990458</td>\n",
       "      <td>-2.292670</td>\n",
       "      <td>-2.025998</td>\n",
       "      <td>-1.637274</td>\n",
       "      <td>-2.293792</td>\n",
       "      <td>-2.125812</td>\n",
       "      <td>-1.993552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.272641</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.885384</td>\n",
       "      <td>0.924040</td>\n",
       "      <td>1.235988</td>\n",
       "      <td>1.087341</td>\n",
       "      <td>-0.170948</td>\n",
       "      <td>0.675345</td>\n",
       "      <td>0.728937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.277530</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.959697</td>\n",
       "      <td>0.934231</td>\n",
       "      <td>1.228601</td>\n",
       "      <td>1.077496</td>\n",
       "      <td>-0.163231</td>\n",
       "      <td>0.658514</td>\n",
       "      <td>0.715410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.282419</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>2.094602</td>\n",
       "      <td>0.957607</td>\n",
       "      <td>1.221214</td>\n",
       "      <td>1.067651</td>\n",
       "      <td>-0.155514</td>\n",
       "      <td>0.641683</td>\n",
       "      <td>0.701882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.287308</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>2.203705</td>\n",
       "      <td>0.987746</td>\n",
       "      <td>1.213827</td>\n",
       "      <td>1.057806</td>\n",
       "      <td>-0.147797</td>\n",
       "      <td>0.624852</td>\n",
       "      <td>0.688355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.292197</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>2.288246</td>\n",
       "      <td>1.015598</td>\n",
       "      <td>1.206439</td>\n",
       "      <td>1.047961</td>\n",
       "      <td>-0.140080</td>\n",
       "      <td>0.608021</td>\n",
       "      <td>0.674827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Paraíba - Desemprego   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0               -0.800943                                          2.723741   \n",
       "1               -0.805366                                          2.350880   \n",
       "2               -0.809789                                          2.123016   \n",
       "3               -0.814212                                          2.021477   \n",
       "4               -0.818635                                          1.887113   \n",
       "..                    ...                                               ...   \n",
       "187              1.272641                                         -2.010387   \n",
       "188              1.277530                                         -1.870713   \n",
       "189              1.282419                                         -1.806230   \n",
       "190              1.287308                                         -1.727496   \n",
       "191              1.292197                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Paraíba - Produção de Cimento (t)  Paraíba - value  Paraíba - IDH  \\\n",
       "0                            -2.092830        -2.424081      -2.168844   \n",
       "1                            -2.140285        -2.392248      -2.133132   \n",
       "2                            -2.109587        -2.359718      -2.097421   \n",
       "3                            -2.074479        -2.326517      -2.061709   \n",
       "4                            -1.990458        -2.292670      -2.025998   \n",
       "..                                 ...              ...            ...   \n",
       "187                           1.885384         0.924040       1.235988   \n",
       "188                           1.959697         0.934231       1.228601   \n",
       "189                           2.094602         0.957607       1.221214   \n",
       "190                           2.203705         0.987746       1.213827   \n",
       "191                           2.288246         1.015598       1.206439   \n",
       "\n",
       "     Paraíba - PIB - Estadual  Paraíba - PIB - Construção Civil  \\\n",
       "0                   -1.710694                         -2.484291   \n",
       "1                   -1.692339                         -2.436666   \n",
       "2                   -1.673984                         -2.389041   \n",
       "3                   -1.655629                         -2.341417   \n",
       "4                   -1.637274                         -2.293792   \n",
       "..                        ...                               ...   \n",
       "187                  1.087341                         -0.170948   \n",
       "188                  1.077496                         -0.163231   \n",
       "189                  1.067651                         -0.155514   \n",
       "190                  1.057806                         -0.147797   \n",
       "191                  1.047961                         -0.140080   \n",
       "\n",
       "     Paraíba - PIB - Per Capita  Paraíba - PIB - Preços de Mercado  \n",
       "0                     -2.270808                          -2.124240  \n",
       "1                     -2.234559                          -2.091568  \n",
       "2                     -2.198310                          -2.058896  \n",
       "3                     -2.162061                          -2.026224  \n",
       "4                     -2.125812                          -1.993552  \n",
       "..                          ...                                ...  \n",
       "187                    0.675345                           0.728937  \n",
       "188                    0.658514                           0.715410  \n",
       "189                    0.641683                           0.701882  \n",
       "190                    0.624852                           0.688355  \n",
       "191                    0.608021                           0.674827  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      31.891\n",
       "1      26.089\n",
       "2      32.066\n",
       "3      26.351\n",
       "4      27.348\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Paraíba - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paraíba - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Paraíba - Produção de Cimento (t)</th>\n",
       "      <th>Paraíba - value</th>\n",
       "      <th>Paraíba - IDH</th>\n",
       "      <th>Paraíba - PIB - Estadual</th>\n",
       "      <th>Paraíba - PIB - Construção Civil</th>\n",
       "      <th>Paraíba - PIB - Per Capita</th>\n",
       "      <th>Paraíba - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.800943</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-2.092830</td>\n",
       "      <td>-2.424081</td>\n",
       "      <td>-2.168844</td>\n",
       "      <td>-1.710694</td>\n",
       "      <td>-2.484291</td>\n",
       "      <td>-2.270808</td>\n",
       "      <td>-2.124240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.805366</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-2.140285</td>\n",
       "      <td>-2.392248</td>\n",
       "      <td>-2.133132</td>\n",
       "      <td>-1.692339</td>\n",
       "      <td>-2.436666</td>\n",
       "      <td>-2.234559</td>\n",
       "      <td>-2.091568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.809789</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-2.109587</td>\n",
       "      <td>-2.359718</td>\n",
       "      <td>-2.097421</td>\n",
       "      <td>-1.673984</td>\n",
       "      <td>-2.389041</td>\n",
       "      <td>-2.198310</td>\n",
       "      <td>-2.058896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.814212</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-2.074479</td>\n",
       "      <td>-2.326517</td>\n",
       "      <td>-2.061709</td>\n",
       "      <td>-1.655629</td>\n",
       "      <td>-2.341417</td>\n",
       "      <td>-2.162061</td>\n",
       "      <td>-2.026224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.818635</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.990458</td>\n",
       "      <td>-2.292670</td>\n",
       "      <td>-2.025998</td>\n",
       "      <td>-1.637274</td>\n",
       "      <td>-2.293792</td>\n",
       "      <td>-2.125812</td>\n",
       "      <td>-1.993552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.300589</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>0.747301</td>\n",
       "      <td>0.928050</td>\n",
       "      <td>1.431308</td>\n",
       "      <td>1.193935</td>\n",
       "      <td>-0.099354</td>\n",
       "      <td>0.924381</td>\n",
       "      <td>1.014355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.292964</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>0.751028</td>\n",
       "      <td>0.933525</td>\n",
       "      <td>1.429336</td>\n",
       "      <td>1.195558</td>\n",
       "      <td>-0.105914</td>\n",
       "      <td>0.923232</td>\n",
       "      <td>1.010769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.285339</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>0.748338</td>\n",
       "      <td>0.939401</td>\n",
       "      <td>1.427365</td>\n",
       "      <td>1.197181</td>\n",
       "      <td>-0.112475</td>\n",
       "      <td>0.922084</td>\n",
       "      <td>1.007184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.277715</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>0.708461</td>\n",
       "      <td>0.946049</td>\n",
       "      <td>1.425393</td>\n",
       "      <td>1.198804</td>\n",
       "      <td>-0.119036</td>\n",
       "      <td>0.920935</td>\n",
       "      <td>1.003598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.270090</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>0.733986</td>\n",
       "      <td>0.941985</td>\n",
       "      <td>1.423422</td>\n",
       "      <td>1.200427</td>\n",
       "      <td>-0.125597</td>\n",
       "      <td>0.919786</td>\n",
       "      <td>1.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Paraíba - Desemprego   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0               -0.800943                                          2.723741   \n",
       "1               -0.805366                                          2.350880   \n",
       "2               -0.809789                                          2.123016   \n",
       "3               -0.814212                                          2.021477   \n",
       "4               -0.818635                                          1.887113   \n",
       "..                    ...                                               ...   \n",
       "157              1.300589                                         -0.214006   \n",
       "158              1.292964                                         -0.434717   \n",
       "159              1.285339                                         -0.524091   \n",
       "160              1.277715                                         -0.614500   \n",
       "161              1.270090                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     Paraíba - Produção de Cimento (t)  Paraíba - value  Paraíba - IDH  \\\n",
       "0                            -2.092830        -2.424081      -2.168844   \n",
       "1                            -2.140285        -2.392248      -2.133132   \n",
       "2                            -2.109587        -2.359718      -2.097421   \n",
       "3                            -2.074479        -2.326517      -2.061709   \n",
       "4                            -1.990458        -2.292670      -2.025998   \n",
       "..                                 ...              ...            ...   \n",
       "157                           0.747301         0.928050       1.431308   \n",
       "158                           0.751028         0.933525       1.429336   \n",
       "159                           0.748338         0.939401       1.427365   \n",
       "160                           0.708461         0.946049       1.425393   \n",
       "161                           0.733986         0.941985       1.423422   \n",
       "\n",
       "     Paraíba - PIB - Estadual  Paraíba - PIB - Construção Civil  \\\n",
       "0                   -1.710694                         -2.484291   \n",
       "1                   -1.692339                         -2.436666   \n",
       "2                   -1.673984                         -2.389041   \n",
       "3                   -1.655629                         -2.341417   \n",
       "4                   -1.637274                         -2.293792   \n",
       "..                        ...                               ...   \n",
       "157                  1.193935                         -0.099354   \n",
       "158                  1.195558                         -0.105914   \n",
       "159                  1.197181                         -0.112475   \n",
       "160                  1.198804                         -0.119036   \n",
       "161                  1.200427                         -0.125597   \n",
       "\n",
       "     Paraíba - PIB - Per Capita  Paraíba - PIB - Preços de Mercado  \n",
       "0                     -2.270808                          -2.124240  \n",
       "1                     -2.234559                          -2.091568  \n",
       "2                     -2.198310                          -2.058896  \n",
       "3                     -2.162061                          -2.026224  \n",
       "4                     -2.125812                          -1.993552  \n",
       "..                          ...                                ...  \n",
       "157                    0.924381                           1.014355  \n",
       "158                    0.923232                           1.010769  \n",
       "159                    0.922084                           1.007184  \n",
       "160                    0.920935                           1.003598  \n",
       "161                    0.919786                           1.000013  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      31.891\n",
       "1      26.089\n",
       "2      32.066\n",
       "3      26.351\n",
       "4      27.348\n",
       "        ...  \n",
       "157    58.962\n",
       "158    73.459\n",
       "159    59.150\n",
       "160    64.833\n",
       "161    63.840\n",
       "Name: Paraíba - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paraíba - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Paraíba - Produção de Cimento (t)</th>\n",
       "      <th>Paraíba - value</th>\n",
       "      <th>Paraíba - IDH</th>\n",
       "      <th>Paraíba - PIB - Estadual</th>\n",
       "      <th>Paraíba - PIB - Construção Civil</th>\n",
       "      <th>Paraíba - PIB - Per Capita</th>\n",
       "      <th>Paraíba - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.262465</td>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>0.726315</td>\n",
       "      <td>0.936730</td>\n",
       "      <td>1.421451</td>\n",
       "      <td>1.202050</td>\n",
       "      <td>-0.132158</td>\n",
       "      <td>0.918637</td>\n",
       "      <td>0.996428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.254841</td>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>0.750997</td>\n",
       "      <td>0.933298</td>\n",
       "      <td>1.419479</td>\n",
       "      <td>1.203673</td>\n",
       "      <td>-0.138719</td>\n",
       "      <td>0.917488</td>\n",
       "      <td>0.992842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.247216</td>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>0.769881</td>\n",
       "      <td>0.933283</td>\n",
       "      <td>1.417508</td>\n",
       "      <td>1.205296</td>\n",
       "      <td>-0.145280</td>\n",
       "      <td>0.916339</td>\n",
       "      <td>0.989257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.239591</td>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>0.777131</td>\n",
       "      <td>0.932533</td>\n",
       "      <td>1.415536</td>\n",
       "      <td>1.206919</td>\n",
       "      <td>-0.151841</td>\n",
       "      <td>0.915191</td>\n",
       "      <td>0.985671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.231967</td>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>0.793980</td>\n",
       "      <td>0.931678</td>\n",
       "      <td>1.413565</td>\n",
       "      <td>1.208543</td>\n",
       "      <td>-0.158402</td>\n",
       "      <td>0.914042</td>\n",
       "      <td>0.982086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.224342</td>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>0.777065</td>\n",
       "      <td>0.928951</td>\n",
       "      <td>1.411594</td>\n",
       "      <td>1.210166</td>\n",
       "      <td>-0.164963</td>\n",
       "      <td>0.912893</td>\n",
       "      <td>0.978500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.216717</td>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>0.786100</td>\n",
       "      <td>0.926306</td>\n",
       "      <td>1.409622</td>\n",
       "      <td>1.211789</td>\n",
       "      <td>-0.171524</td>\n",
       "      <td>0.911744</td>\n",
       "      <td>0.974915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.218526</td>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>0.771458</td>\n",
       "      <td>0.922846</td>\n",
       "      <td>1.399462</td>\n",
       "      <td>1.207161</td>\n",
       "      <td>-0.175977</td>\n",
       "      <td>0.901862</td>\n",
       "      <td>0.962308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.220334</td>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>0.775076</td>\n",
       "      <td>0.919596</td>\n",
       "      <td>1.389302</td>\n",
       "      <td>1.202533</td>\n",
       "      <td>-0.180431</td>\n",
       "      <td>0.891981</td>\n",
       "      <td>0.949700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.222142</td>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>0.761078</td>\n",
       "      <td>0.916956</td>\n",
       "      <td>1.379141</td>\n",
       "      <td>1.197906</td>\n",
       "      <td>-0.184884</td>\n",
       "      <td>0.882099</td>\n",
       "      <td>0.937093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.223951</td>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>0.821657</td>\n",
       "      <td>0.915121</td>\n",
       "      <td>1.368981</td>\n",
       "      <td>1.193278</td>\n",
       "      <td>-0.189338</td>\n",
       "      <td>0.872217</td>\n",
       "      <td>0.924486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.225759</td>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>0.890142</td>\n",
       "      <td>0.914458</td>\n",
       "      <td>1.358821</td>\n",
       "      <td>1.188650</td>\n",
       "      <td>-0.193791</td>\n",
       "      <td>0.862335</td>\n",
       "      <td>0.911879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.227567</td>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>0.969380</td>\n",
       "      <td>0.913891</td>\n",
       "      <td>1.348660</td>\n",
       "      <td>1.184023</td>\n",
       "      <td>-0.198245</td>\n",
       "      <td>0.852453</td>\n",
       "      <td>0.899272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.229376</td>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>1.062516</td>\n",
       "      <td>0.912523</td>\n",
       "      <td>1.338500</td>\n",
       "      <td>1.179395</td>\n",
       "      <td>-0.202698</td>\n",
       "      <td>0.842572</td>\n",
       "      <td>0.886665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.231184</td>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>1.072912</td>\n",
       "      <td>0.912571</td>\n",
       "      <td>1.328340</td>\n",
       "      <td>1.174767</td>\n",
       "      <td>-0.207152</td>\n",
       "      <td>0.832690</td>\n",
       "      <td>0.874057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.232992</td>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>1.138251</td>\n",
       "      <td>0.912227</td>\n",
       "      <td>1.318179</td>\n",
       "      <td>1.170140</td>\n",
       "      <td>-0.211605</td>\n",
       "      <td>0.822808</td>\n",
       "      <td>0.861450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.234801</td>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>1.189559</td>\n",
       "      <td>0.911806</td>\n",
       "      <td>1.308019</td>\n",
       "      <td>1.165512</td>\n",
       "      <td>-0.216059</td>\n",
       "      <td>0.812926</td>\n",
       "      <td>0.848843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.236609</td>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>1.250012</td>\n",
       "      <td>0.910543</td>\n",
       "      <td>1.297859</td>\n",
       "      <td>1.160884</td>\n",
       "      <td>-0.220512</td>\n",
       "      <td>0.803044</td>\n",
       "      <td>0.836236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.238417</td>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>1.316417</td>\n",
       "      <td>0.909648</td>\n",
       "      <td>1.287699</td>\n",
       "      <td>1.156257</td>\n",
       "      <td>-0.224966</td>\n",
       "      <td>0.793163</td>\n",
       "      <td>0.823629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.243306</td>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>1.381387</td>\n",
       "      <td>0.908590</td>\n",
       "      <td>1.280311</td>\n",
       "      <td>1.146412</td>\n",
       "      <td>-0.217249</td>\n",
       "      <td>0.776332</td>\n",
       "      <td>0.810101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.248195</td>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>1.458136</td>\n",
       "      <td>0.907688</td>\n",
       "      <td>1.272924</td>\n",
       "      <td>1.136567</td>\n",
       "      <td>-0.209532</td>\n",
       "      <td>0.759501</td>\n",
       "      <td>0.796574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.253084</td>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>1.481498</td>\n",
       "      <td>0.907341</td>\n",
       "      <td>1.265537</td>\n",
       "      <td>1.126722</td>\n",
       "      <td>-0.201815</td>\n",
       "      <td>0.742669</td>\n",
       "      <td>0.783047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.257974</td>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>1.569731</td>\n",
       "      <td>0.906434</td>\n",
       "      <td>1.258150</td>\n",
       "      <td>1.116876</td>\n",
       "      <td>-0.194098</td>\n",
       "      <td>0.725838</td>\n",
       "      <td>0.769519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.262863</td>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>1.708290</td>\n",
       "      <td>0.904833</td>\n",
       "      <td>1.250763</td>\n",
       "      <td>1.107031</td>\n",
       "      <td>-0.186381</td>\n",
       "      <td>0.709007</td>\n",
       "      <td>0.755992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.267752</td>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>1.779425</td>\n",
       "      <td>0.913626</td>\n",
       "      <td>1.243375</td>\n",
       "      <td>1.097186</td>\n",
       "      <td>-0.178665</td>\n",
       "      <td>0.692176</td>\n",
       "      <td>0.742464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.272641</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.885384</td>\n",
       "      <td>0.924040</td>\n",
       "      <td>1.235988</td>\n",
       "      <td>1.087341</td>\n",
       "      <td>-0.170948</td>\n",
       "      <td>0.675345</td>\n",
       "      <td>0.728937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.277530</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.959697</td>\n",
       "      <td>0.934231</td>\n",
       "      <td>1.228601</td>\n",
       "      <td>1.077496</td>\n",
       "      <td>-0.163231</td>\n",
       "      <td>0.658514</td>\n",
       "      <td>0.715410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.282419</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>2.094602</td>\n",
       "      <td>0.957607</td>\n",
       "      <td>1.221214</td>\n",
       "      <td>1.067651</td>\n",
       "      <td>-0.155514</td>\n",
       "      <td>0.641683</td>\n",
       "      <td>0.701882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.287308</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>2.203705</td>\n",
       "      <td>0.987746</td>\n",
       "      <td>1.213827</td>\n",
       "      <td>1.057806</td>\n",
       "      <td>-0.147797</td>\n",
       "      <td>0.624852</td>\n",
       "      <td>0.688355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.292197</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>2.288246</td>\n",
       "      <td>1.015598</td>\n",
       "      <td>1.206439</td>\n",
       "      <td>1.047961</td>\n",
       "      <td>-0.140080</td>\n",
       "      <td>0.608021</td>\n",
       "      <td>0.674827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Paraíba - Desemprego   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162              1.262465                                         -0.601510   \n",
       "163              1.254841                                         -0.786068   \n",
       "164              1.247216                                         -0.830387   \n",
       "165              1.239591                                         -0.801089   \n",
       "166              1.231967                                         -0.959917   \n",
       "167              1.224342                                         -1.022309   \n",
       "168              1.216717                                         -1.074401   \n",
       "169              1.218526                                         -1.119597   \n",
       "170              1.220334                                         -1.078648   \n",
       "171              1.222142                                         -1.055426   \n",
       "172              1.223951                                         -1.101053   \n",
       "173              1.225759                                         -1.211370   \n",
       "174              1.227567                                         -1.157198   \n",
       "175              1.229376                                         -1.223444   \n",
       "176              1.231184                                         -1.311519   \n",
       "177              1.232992                                         -1.362602   \n",
       "178              1.234801                                         -1.380125   \n",
       "179              1.236609                                         -1.219296   \n",
       "180              1.238417                                         -1.300284   \n",
       "181              1.243306                                         -1.336476   \n",
       "182              1.248195                                         -1.415774   \n",
       "183              1.253084                                         -1.526021   \n",
       "184              1.257974                                         -1.681806   \n",
       "185              1.262863                                         -1.735167   \n",
       "186              1.267752                                         -1.962315   \n",
       "187              1.272641                                         -2.010387   \n",
       "188              1.277530                                         -1.870713   \n",
       "189              1.282419                                         -1.806230   \n",
       "190              1.287308                                         -1.727496   \n",
       "191              1.292197                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "162                                0.763466  -1.213929   \n",
       "163                                0.752299  -1.292173   \n",
       "164                                0.741131  -1.324219   \n",
       "165                                0.729964  -1.344446   \n",
       "166                                0.718796  -1.381638   \n",
       "167                                0.707629  -1.411208   \n",
       "168                                0.696461  -1.412953   \n",
       "169                                0.681823  -1.491464   \n",
       "170                                0.667184  -1.573805   \n",
       "171                                0.652545  -1.564950   \n",
       "172                                0.637906  -1.581584   \n",
       "173                                0.623268  -1.565976   \n",
       "174                                0.608629  -1.648556   \n",
       "175                                0.593990  -1.650049   \n",
       "176                                0.579351  -1.653957   \n",
       "177                                0.564713  -1.652572   \n",
       "178                                0.550074  -1.715349   \n",
       "179                                0.535435  -1.750917   \n",
       "180                                0.520796  -1.718448   \n",
       "181                                0.501996  -1.733426   \n",
       "182                                0.483195  -1.729362   \n",
       "183                                0.464395  -1.748544   \n",
       "184                                0.445594  -1.778060   \n",
       "185                                0.426794  -1.773710   \n",
       "186                                0.407993  -1.757007   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Paraíba - Produção de Cimento (t)  Paraíba - value  Paraíba - IDH  \\\n",
       "162                           0.726315         0.936730       1.421451   \n",
       "163                           0.750997         0.933298       1.419479   \n",
       "164                           0.769881         0.933283       1.417508   \n",
       "165                           0.777131         0.932533       1.415536   \n",
       "166                           0.793980         0.931678       1.413565   \n",
       "167                           0.777065         0.928951       1.411594   \n",
       "168                           0.786100         0.926306       1.409622   \n",
       "169                           0.771458         0.922846       1.399462   \n",
       "170                           0.775076         0.919596       1.389302   \n",
       "171                           0.761078         0.916956       1.379141   \n",
       "172                           0.821657         0.915121       1.368981   \n",
       "173                           0.890142         0.914458       1.358821   \n",
       "174                           0.969380         0.913891       1.348660   \n",
       "175                           1.062516         0.912523       1.338500   \n",
       "176                           1.072912         0.912571       1.328340   \n",
       "177                           1.138251         0.912227       1.318179   \n",
       "178                           1.189559         0.911806       1.308019   \n",
       "179                           1.250012         0.910543       1.297859   \n",
       "180                           1.316417         0.909648       1.287699   \n",
       "181                           1.381387         0.908590       1.280311   \n",
       "182                           1.458136         0.907688       1.272924   \n",
       "183                           1.481498         0.907341       1.265537   \n",
       "184                           1.569731         0.906434       1.258150   \n",
       "185                           1.708290         0.904833       1.250763   \n",
       "186                           1.779425         0.913626       1.243375   \n",
       "187                           1.885384         0.924040       1.235988   \n",
       "188                           1.959697         0.934231       1.228601   \n",
       "189                           2.094602         0.957607       1.221214   \n",
       "190                           2.203705         0.987746       1.213827   \n",
       "191                           2.288246         1.015598       1.206439   \n",
       "\n",
       "     Paraíba - PIB - Estadual  Paraíba - PIB - Construção Civil  \\\n",
       "162                  1.202050                         -0.132158   \n",
       "163                  1.203673                         -0.138719   \n",
       "164                  1.205296                         -0.145280   \n",
       "165                  1.206919                         -0.151841   \n",
       "166                  1.208543                         -0.158402   \n",
       "167                  1.210166                         -0.164963   \n",
       "168                  1.211789                         -0.171524   \n",
       "169                  1.207161                         -0.175977   \n",
       "170                  1.202533                         -0.180431   \n",
       "171                  1.197906                         -0.184884   \n",
       "172                  1.193278                         -0.189338   \n",
       "173                  1.188650                         -0.193791   \n",
       "174                  1.184023                         -0.198245   \n",
       "175                  1.179395                         -0.202698   \n",
       "176                  1.174767                         -0.207152   \n",
       "177                  1.170140                         -0.211605   \n",
       "178                  1.165512                         -0.216059   \n",
       "179                  1.160884                         -0.220512   \n",
       "180                  1.156257                         -0.224966   \n",
       "181                  1.146412                         -0.217249   \n",
       "182                  1.136567                         -0.209532   \n",
       "183                  1.126722                         -0.201815   \n",
       "184                  1.116876                         -0.194098   \n",
       "185                  1.107031                         -0.186381   \n",
       "186                  1.097186                         -0.178665   \n",
       "187                  1.087341                         -0.170948   \n",
       "188                  1.077496                         -0.163231   \n",
       "189                  1.067651                         -0.155514   \n",
       "190                  1.057806                         -0.147797   \n",
       "191                  1.047961                         -0.140080   \n",
       "\n",
       "     Paraíba - PIB - Per Capita  Paraíba - PIB - Preços de Mercado  \n",
       "162                    0.918637                           0.996428  \n",
       "163                    0.917488                           0.992842  \n",
       "164                    0.916339                           0.989257  \n",
       "165                    0.915191                           0.985671  \n",
       "166                    0.914042                           0.982086  \n",
       "167                    0.912893                           0.978500  \n",
       "168                    0.911744                           0.974915  \n",
       "169                    0.901862                           0.962308  \n",
       "170                    0.891981                           0.949700  \n",
       "171                    0.882099                           0.937093  \n",
       "172                    0.872217                           0.924486  \n",
       "173                    0.862335                           0.911879  \n",
       "174                    0.852453                           0.899272  \n",
       "175                    0.842572                           0.886665  \n",
       "176                    0.832690                           0.874057  \n",
       "177                    0.822808                           0.861450  \n",
       "178                    0.812926                           0.848843  \n",
       "179                    0.803044                           0.836236  \n",
       "180                    0.793163                           0.823629  \n",
       "181                    0.776332                           0.810101  \n",
       "182                    0.759501                           0.796574  \n",
       "183                    0.742669                           0.783047  \n",
       "184                    0.725838                           0.769519  \n",
       "185                    0.709007                           0.755992  \n",
       "186                    0.692176                           0.742464  \n",
       "187                    0.675345                           0.728937  \n",
       "188                    0.658514                           0.715410  \n",
       "189                    0.641683                           0.701882  \n",
       "190                    0.624852                           0.688355  \n",
       "191                    0.608021                           0.674827  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    61.721\n",
       "163    69.240\n",
       "164    70.048\n",
       "165    67.172\n",
       "166    64.220\n",
       "167    63.021\n",
       "168    62.639\n",
       "169    53.839\n",
       "170    56.652\n",
       "171    53.408\n",
       "172    50.543\n",
       "173    64.699\n",
       "174    60.219\n",
       "175    64.217\n",
       "176    57.591\n",
       "177    64.307\n",
       "178    61.971\n",
       "179    57.480\n",
       "180    68.053\n",
       "181    55.231\n",
       "182    53.723\n",
       "183    57.457\n",
       "184    62.755\n",
       "185    48.148\n",
       "186    62.190\n",
       "187    62.219\n",
       "188    61.329\n",
       "189    81.988\n",
       "190    79.341\n",
       "191    76.646\n",
       "Name: Paraíba - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "#     train, train_val = validation_splitter(train_input, 7)\n",
    "#     target,target_val = validation_splitter(train_target, 7)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train_input, \n",
    "                        train_target, \n",
    "                        epochs=10000,\n",
    "#                         validation_data=(train_val, target_val),\n",
    "                        validation_split=0.07,\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3338745688, 3087408476, 2364554179, 666689671, 4036094267, 3803191913, 3352577067, 4167914819, 225680327, 1390433809, 1194511708, 1331593267, 2883884418, 2900680921, 3520223069, 1184473861, 1554391231, 1539697097, 3627971799, 2398163906, 2214948678, 1015090953, 2843841181, 3517400832, 2318076606]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 36.38425827026367\n",
      "winner_seed: 3338745688\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 56.37985610961914\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 106.8461685180664\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 343.1228942871094\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 889.9884643554688\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 2358.986328125\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 317.0262451171875\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 288.93560791015625\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 439.4405212402344\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 4063.949951171875\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 1453.8492431640625\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 379.84521484375\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 193.8367919921875\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 330.38482666015625\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 108.71964263916016\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 447.6324462890625\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 58.5760612487793\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 71.13094329833984\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 53.8583869934082\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 373.6614685058594\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 163.2958984375\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 256.4981994628906\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 92.846923828125\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 16.061063766479492\n",
      "winner_seed: 3517400832\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 24.012123107910156\n",
      "\n",
      "\n",
      "final_seed: 3517400832\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 1s 29ms/step - loss: 4399.2231 - val_loss: 16641.0020\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5106.0923 - val_loss: 9025.3906\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4021.1650 - val_loss: 3220.3352\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3643.2112 - val_loss: 1628.6798\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3064.3596 - val_loss: 421.6983\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1475.9205 - val_loss: 1027.2563\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 999.8858 - val_loss: 51.5988\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 247.0626 - val_loss: 33.0362\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 166.3291 - val_loss: 43.3526\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 134.2321 - val_loss: 69.7349\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 114.1077 - val_loss: 136.6978\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.1410 - val_loss: 90.7085\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 114.9968 - val_loss: 78.3462\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 117.8057 - val_loss: 192.2792\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.3159 - val_loss: 71.5310\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.6190 - val_loss: 222.3605\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.6111 - val_loss: 132.9870\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.2101 - val_loss: 322.7050\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 86.5378 - val_loss: 162.8856\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 82.8165 - val_loss: 192.8140\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 85.3966 - val_loss: 330.9438\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.2441 - val_loss: 252.2028\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.7574 - val_loss: 143.8080\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 84.9790 - val_loss: 215.9153\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 78.4186 - val_loss: 237.5114\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.1245 - val_loss: 215.2363\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.0414 - val_loss: 246.3820\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.5932 - val_loss: 242.1797\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.6204 - val_loss: 244.6404\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.4794 - val_loss: 309.8707\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.7613 - val_loss: 239.6657\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.3064 - val_loss: 322.1851\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.9499 - val_loss: 329.2673\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.9616 - val_loss: 132.0437\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 121.6080 - val_loss: 179.0991\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.4097 - val_loss: 186.3354\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 79.2524 - val_loss: 145.0817\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 81.7615 - val_loss: 175.0116\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.2120 - val_loss: 136.1092\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 82.5219 - val_loss: 158.3769\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 79.5173 - val_loss: 296.8055\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.0604 - val_loss: 261.9043\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 76.6699 - val_loss: 208.9531\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 72.6728 - val_loss: 192.7519\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.4277 - val_loss: 177.4400\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 71.8604 - val_loss: 223.7506\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.7747 - val_loss: 172.0676\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.9278 - val_loss: 249.6503\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.9236 - val_loss: 170.1180\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.3230 - val_loss: 198.2529\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.5500 - val_loss: 140.8963\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 71.9157 - val_loss: 158.1590\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 78.2608 - val_loss: 165.5684\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.4495 - val_loss: 137.1705\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 69.6449 - val_loss: 235.9134\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.9387 - val_loss: 227.2335\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.8414 - val_loss: 189.3415\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 77.8193 - val_loss: 86.6502\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.9734 - val_loss: 154.9931\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.6031 - val_loss: 121.0689\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.4806 - val_loss: 106.0948\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 70.1668 - val_loss: 105.9877\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.2717 - val_loss: 327.2041\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.9850 - val_loss: 470.7055\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.0807 - val_loss: 568.7100\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 71.9691 - val_loss: 593.2418\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.6293 - val_loss: 577.7534\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.5676 - val_loss: 640.6921\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 78.4761 - val_loss: 632.7202\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 71.4281 - val_loss: 503.4695\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.4514 - val_loss: 562.4673\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 77.7198 - val_loss: 448.9311\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.1639 - val_loss: 373.8926\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.4764 - val_loss: 562.6838\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 72.2946 - val_loss: 734.1231\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.1672 - val_loss: 855.1172\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 76.8891 - val_loss: 976.1215\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 84.2987 - val_loss: 692.0554\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 84.9307 - val_loss: 826.0037\n",
      "Epoch 80/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 78.6784 - val_loss: 612.5465\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.3290 - val_loss: 677.4516\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 72.8131 - val_loss: 570.6199\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.9838 - val_loss: 572.2950\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 76.5303 - val_loss: 896.0635\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 76.3154 - val_loss: 711.0923\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 76.6020 - val_loss: 758.5078\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 71.9346 - val_loss: 884.5350\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.9657 - val_loss: 943.3680\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.7501 - val_loss: 956.9575\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.4114 - val_loss: 1214.8541\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 73.2413 - val_loss: 820.7033\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.1541 - val_loss: 857.6787\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.9086 - val_loss: 974.3737\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 66.4746 - val_loss: 908.6304\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 72.6545 - val_loss: 994.5332\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.6876 - val_loss: 997.2923\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 68.7320 - val_loss: 1051.7301\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 71.9513 - val_loss: 955.8554\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.7694 - val_loss: 825.9089\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 67.6645 - val_loss: 867.0609\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.7485 - val_loss: 936.6407\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 74.8131 - val_loss: 803.7457\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 73.2983 - val_loss: 889.4451\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 72.0336 - val_loss: 961.4769\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.1321 - val_loss: 897.5289\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 84.9952 - val_loss: 1082.1444\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 74.5788 - val_loss: 1028.6190\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 80.2874 - val_loss: 1111.9821\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 76.4210 - val_loss: 887.0274\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 72.9441 - val_loss: 1515.5350\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.2644 - val_loss: 1501.3705\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.4842 - val_loss: 1181.2479\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.5496 - val_loss: 1255.9215\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.3438 - val_loss: 1411.9141\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 79.9800 - val_loss: 1074.6771\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.8646 - val_loss: 482.4106\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.1110 - val_loss: 471.4308\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.4398 - val_loss: 525.5195\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 75.1451 - val_loss: 430.5842\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.8840 - val_loss: 472.6571\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.4430 - val_loss: 586.7921\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.3737 - val_loss: 447.5668\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.2723 - val_loss: 481.2497\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 72.7347 - val_loss: 524.0829\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.4205 - val_loss: 558.9223\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 68.0976 - val_loss: 589.1049\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 71.4958 - val_loss: 680.4570\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.4622 - val_loss: 605.1587\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.6176 - val_loss: 555.1223\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.7870 - val_loss: 576.0574\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.3313 - val_loss: 549.1845\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.5443 - val_loss: 596.7493\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.7999 - val_loss: 580.3707\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 71.1565 - val_loss: 511.3181\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.2263 - val_loss: 526.3620\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.5944 - val_loss: 450.0350\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.7640 - val_loss: 495.2566\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.1711 - val_loss: 562.4852\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.1353 - val_loss: 379.7859\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 71.9024 - val_loss: 441.1623\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 76.5458 - val_loss: 512.5221\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.0411 - val_loss: 411.3666\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 71.2122 - val_loss: 519.8391\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.2198 - val_loss: 581.5872\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.4745 - val_loss: 586.7398\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.8158 - val_loss: 545.5364\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.3141 - val_loss: 639.0820\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.5357 - val_loss: 662.0765\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.2870 - val_loss: 618.6555\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.6461 - val_loss: 771.9374\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.3175 - val_loss: 813.4962\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 66.6932 - val_loss: 641.6708\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.7267 - val_loss: 717.2966\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 65.3706 - val_loss: 573.0976\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 65.1945 - val_loss: 835.0679\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.4332 - val_loss: 954.2471\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 72.7591 - val_loss: 741.5821\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.1447 - val_loss: 821.1699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.9798 - val_loss: 681.9469\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 66.4384 - val_loss: 547.0549\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.1732 - val_loss: 572.5684\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.9170 - val_loss: 517.1859\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.8781 - val_loss: 477.6942\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 77.3391 - val_loss: 557.6382\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.9562 - val_loss: 580.3812\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.3333 - val_loss: 708.1721\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.2235 - val_loss: 515.1901\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 78.6360 - val_loss: 747.8697\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 82.3380 - val_loss: 845.5099\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.8279 - val_loss: 637.3148\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.5056 - val_loss: 548.9882\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 64.5189 - val_loss: 612.4250\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.3913 - val_loss: 729.8613\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.0916 - val_loss: 708.7300\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.3011 - val_loss: 735.7896\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 71.6545 - val_loss: 614.6669\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.2458 - val_loss: 752.8367\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.1507 - val_loss: 560.1614\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 69.2807 - val_loss: 617.7804\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 72.3780 - val_loss: 576.7886\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.8721 - val_loss: 788.9263\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.5969 - val_loss: 874.5495\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.9781 - val_loss: 744.4997\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.2150 - val_loss: 803.7873\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 68.5308 - val_loss: 805.9167\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.2306 - val_loss: 802.1243\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 67.6072 - val_loss: 692.1652\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 65.1993 - val_loss: 879.4695\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.1628 - val_loss: 772.5503\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 65.8752 - val_loss: 766.5521\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.8621 - val_loss: 781.3711\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 65.5461 - val_loss: 739.5667\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.4371 - val_loss: 593.8096\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.3581 - val_loss: 629.4395\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 71.0651 - val_loss: 625.5717\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.6853 - val_loss: 741.5187\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.9491 - val_loss: 739.9211\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 64.2374 - val_loss: 793.9473\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.7314 - val_loss: 681.2723\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.1454 - val_loss: 854.2617\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.9258 - val_loss: 929.0554\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.2991 - val_loss: 838.4368\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 65.5491 - val_loss: 648.0605\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 67.2828 - val_loss: 904.0529\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.1768 - val_loss: 853.2097\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.7428 - val_loss: 826.9775\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.5484 - val_loss: 788.7581\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.2218 - val_loss: 573.9061\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 72.5626 - val_loss: 731.0652\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 71.5431 - val_loss: 710.6100\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 68.8868 - val_loss: 708.2273\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.9029 - val_loss: 688.5350\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.3626 - val_loss: 847.5306\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 76.4404 - val_loss: 592.5276\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.8977 - val_loss: 580.6491\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.4482 - val_loss: 509.8774\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.5641 - val_loss: 1223.8087\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.3520 - val_loss: 1456.3555\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 67.5954 - val_loss: 2392.5789\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.2234 - val_loss: 878.4360\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.8916 - val_loss: 1138.5773\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.5962 - val_loss: 1063.4315\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.9462 - val_loss: 850.8135\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 76.1238 - val_loss: 794.8516\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 74.5454 - val_loss: 983.8282\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.4318 - val_loss: 1107.6646\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.1365 - val_loss: 1129.2102\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.3832 - val_loss: 1374.7159\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.2688 - val_loss: 1450.1144\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.5426 - val_loss: 3801.5098\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 752.2964 - val_loss: 656.6603\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 471.9794 - val_loss: 229.1262\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.6434 - val_loss: 364.6471\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.9501 - val_loss: 423.7071\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.7103 - val_loss: 349.5724\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.2669 - val_loss: 490.9893\n",
      "Epoch 237/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 75.6615 - val_loss: 481.1342\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 71.7350 - val_loss: 456.8993\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.4725 - val_loss: 327.2173\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.0091 - val_loss: 386.9530\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 74.1895 - val_loss: 403.3883\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.5930 - val_loss: 377.9859\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.5546 - val_loss: 371.9011\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.2286 - val_loss: 286.1267\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.5647 - val_loss: 255.3579\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 72.9745 - val_loss: 190.8031\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 72.3086 - val_loss: 252.5174\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.5540 - val_loss: 197.6835\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.2038 - val_loss: 298.6331\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.5849 - val_loss: 191.8780\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 81.4759 - val_loss: 149.4866\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.0866 - val_loss: 165.1715\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.0549 - val_loss: 191.6846\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 67.2609 - val_loss: 207.4587\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 67.5240 - val_loss: 250.0016\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 73.6118 - val_loss: 232.3200\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.6248 - val_loss: 273.2745\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.2763 - val_loss: 150.2150\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.2018 - val_loss: 167.2042\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.7759 - val_loss: 161.5094\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.9452 - val_loss: 154.0616\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.5628 - val_loss: 147.2299\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.7918 - val_loss: 152.2155\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.6736 - val_loss: 142.8372\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.3337 - val_loss: 151.6090\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.4257 - val_loss: 84.5626\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.3057 - val_loss: 78.8698\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.9030 - val_loss: 116.2873\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.8279 - val_loss: 118.8162\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.1126 - val_loss: 106.2094\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 55.3588 - val_loss: 76.6415\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.0254 - val_loss: 105.3639\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.5348 - val_loss: 124.3155\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.3475 - val_loss: 88.5721\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.7060 - val_loss: 68.6663\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.6373 - val_loss: 74.7959\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.8389 - val_loss: 84.6628\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.0958 - val_loss: 82.3477\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.4783 - val_loss: 91.4685\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.3990 - val_loss: 65.3014\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.5263 - val_loss: 78.3617\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.4221 - val_loss: 57.2701\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.1183 - val_loss: 80.7609\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.6504 - val_loss: 51.9831\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.0526 - val_loss: 60.1925\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.0243 - val_loss: 116.9077\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.5628 - val_loss: 69.9916\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 48.9380 - val_loss: 75.4788\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 47.7590 - val_loss: 73.6923\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.4307 - val_loss: 64.8125\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 46.6192 - val_loss: 85.9623\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.6183 - val_loss: 217.8970\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.7471 - val_loss: 107.1367\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 47.0048 - val_loss: 65.6153\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.2642 - val_loss: 64.0922\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.2454 - val_loss: 51.8030\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.2451 - val_loss: 29.2015\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 55.8253 - val_loss: 41.0449\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 84.1419 - val_loss: 128.1934\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.6095 - val_loss: 156.4714\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.6907 - val_loss: 80.5900\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 51.9651 - val_loss: 108.3794\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.7776 - val_loss: 224.1487\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.8269 - val_loss: 136.8808\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.7071 - val_loss: 182.6315\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 39.8415 - val_loss: 251.1018\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.0565 - val_loss: 1766.9945\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 43.3528 - val_loss: 1885.2198\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 39.7853 - val_loss: 2316.0022\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.9505 - val_loss: 120.9007\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.6505 - val_loss: 84.5168\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.7519 - val_loss: 50.7143\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.4377 - val_loss: 69.6479\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.3186 - val_loss: 101.5809\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.7548 - val_loss: 73.1725\n",
      "Epoch 316/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 54.4349 - val_loss: 110.9269\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.3213 - val_loss: 52.9511\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.8082 - val_loss: 35.7379\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 46.7570 - val_loss: 50.9392\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.4035 - val_loss: 708.1318\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.7435 - val_loss: 1018.3501\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.7962 - val_loss: 1561.1986\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.1122 - val_loss: 2059.8303\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.3901 - val_loss: 779.3244\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.3571 - val_loss: 1527.3721\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.1451 - val_loss: 1601.1842\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.7530 - val_loss: 1748.4614\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 55.9511 - val_loss: 535.3184\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 50.4592 - val_loss: 429.3744\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.3128 - val_loss: 870.9713\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.5794 - val_loss: 1067.7231\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.4502 - val_loss: 787.3411\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.5536 - val_loss: 567.5743\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.1633 - val_loss: 758.8024\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.5251 - val_loss: 1066.2914\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.8184 - val_loss: 634.6927\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.0394 - val_loss: 736.6530\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.1466 - val_loss: 351.0052\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.9052 - val_loss: 855.8885\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.4515 - val_loss: 516.1446\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.6670 - val_loss: 675.8148\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.3199 - val_loss: 1011.2083\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.4602 - val_loss: 1240.2775\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.4752 - val_loss: 1442.1891\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.1572 - val_loss: 1362.2772\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 46.2165 - val_loss: 1602.4990\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.2490 - val_loss: 1218.0365\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.4865 - val_loss: 1350.6304\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.8158 - val_loss: 1146.5538\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 44.6957 - val_loss: 834.1063\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.4707 - val_loss: 698.8955\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.8493 - val_loss: 345.5086\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 38.8514 - val_loss: 793.0515\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.7864 - val_loss: 442.3855\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.6594 - val_loss: 593.4767\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 38.2449 - val_loss: 586.7095\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.2601 - val_loss: 905.3032\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 44.5680 - val_loss: 679.6271\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.0034 - val_loss: 928.6585\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.9140 - val_loss: 1273.2299\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.3086 - val_loss: 1133.2045\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.8574 - val_loss: 756.8633\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.2265 - val_loss: 614.4079\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.8058 - val_loss: 921.4361\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 38.8079 - val_loss: 948.9658\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.9033 - val_loss: 1254.2295\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 40.8373 - val_loss: 1664.2318\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.5531 - val_loss: 791.7142\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.0988 - val_loss: 1329.0243\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.3122 - val_loss: 1167.3793\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37.9149 - val_loss: 1322.4150\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.0123 - val_loss: 1872.6195\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.3642 - val_loss: 1577.6078\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.1231 - val_loss: 936.8431\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.6157 - val_loss: 1073.4193\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.4052 - val_loss: 1276.6251\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.5385 - val_loss: 1513.7567\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 39.1043 - val_loss: 983.3904\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 41.7632 - val_loss: 1119.8732\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.7663 - val_loss: 1095.1957\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.7326 - val_loss: 1819.2599\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.3239 - val_loss: 1264.1886\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.0822 - val_loss: 705.6286\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.9262 - val_loss: 686.7429\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.1380 - val_loss: 772.7062\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.7370 - val_loss: 951.8795\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.5653 - val_loss: 1326.7103\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.2755 - val_loss: 1227.1313\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.5673 - val_loss: 1384.9399\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.9050 - val_loss: 1022.9651\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.0018 - val_loss: 977.9951\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.9320 - val_loss: 1003.0524\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 47.9774 - val_loss: 1059.7489\n",
      "Epoch 394/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 50.8112 - val_loss: 825.3597\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 44.9522 - val_loss: 772.6541\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.4727 - val_loss: 1020.5200\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 33.9956 - val_loss: 1007.2230\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 34.6248 - val_loss: 1007.8884\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.3613 - val_loss: 1099.0216\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 45.2860 - val_loss: 1258.7019\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 34.1902 - val_loss: 1339.2408\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.9693 - val_loss: 1674.3090\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 46.1099 - val_loss: 1272.6234\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.2547 - val_loss: 1125.8257\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.0275 - val_loss: 1856.0400\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.9912 - val_loss: 1165.0096\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.6879 - val_loss: 2173.1248\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.3438 - val_loss: 1966.8872\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 34.9508 - val_loss: 1809.6703\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 33.5170 - val_loss: 1650.2428\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.0310 - val_loss: 1426.3363\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.7763 - val_loss: 1674.7202\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.4291 - val_loss: 1261.3679\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.0493 - val_loss: 1189.5469\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.1020 - val_loss: 1303.0045\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.6941 - val_loss: 1171.8964\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.1214 - val_loss: 1237.9038\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.0927 - val_loss: 983.6116\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.1299 - val_loss: 2813.3328\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.4936 - val_loss: 2427.5623\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.3699 - val_loss: 2482.5232\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.3060 - val_loss: 2165.4998\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.8026 - val_loss: 3521.2148\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.8123 - val_loss: 2227.7458\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.4666 - val_loss: 2214.5735\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.3476 - val_loss: 1921.4482\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.8746 - val_loss: 2238.6230\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.3998 - val_loss: 2435.4832\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.9750 - val_loss: 1905.0648\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.4926 - val_loss: 2764.6438\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.8526 - val_loss: 2548.5149\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.4738 - val_loss: 2636.7161\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.0296 - val_loss: 2619.4670\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.6926 - val_loss: 2468.1345\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.4291 - val_loss: 2095.3044\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.0329 - val_loss: 2561.6965\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.9673 - val_loss: 2789.9817\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.6646 - val_loss: 2365.2849\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.0058 - val_loss: 3126.6602\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.5272 - val_loss: 2826.1965\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.9123 - val_loss: 3241.9690\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.2463 - val_loss: 3215.7666\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.8944 - val_loss: 2322.8889\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.7913 - val_loss: 1261.9287\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.0331 - val_loss: 1173.9053\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.5928 - val_loss: 1271.2306\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.6086 - val_loss: 1076.4650\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.0580 - val_loss: 675.0043\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.0971 - val_loss: 1379.8170\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 31.8032 - val_loss: 1305.3330\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.9133 - val_loss: 1434.5596\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 31.0108 - val_loss: 1172.8918\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.1968 - val_loss: 485.3496\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.8992 - val_loss: 955.5488\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.2395 - val_loss: 1381.9398\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.2307 - val_loss: 1515.4598\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.3306 - val_loss: 1301.6014\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 38.1228 - val_loss: 1390.1440\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 40.7761 - val_loss: 1474.5768\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.4500 - val_loss: 1213.0219\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.9362 - val_loss: 896.7125\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 31.6359 - val_loss: 1163.5336\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.0815 - val_loss: 755.8011\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 47.1294 - val_loss: 3080.7581\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.1987 - val_loss: 844.7636\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.7993 - val_loss: 1738.1852\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.6749 - val_loss: 1834.0665\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.6424 - val_loss: 2547.8359\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 34.6590 - val_loss: 1629.1729\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 44.2704 - val_loss: 2232.3049\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.9059 - val_loss: 2414.2058\n",
      "Epoch 472/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 35.3420 - val_loss: 2491.9485\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.8392 - val_loss: 2348.7268\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 33.6312 - val_loss: 2688.4954\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.3177 - val_loss: 2303.5828\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 32.4407 - val_loss: 2295.7419\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 31.3736 - val_loss: 1977.7877\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.9039 - val_loss: 2138.2937\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 41.6737 - val_loss: 2146.2637\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.2313 - val_loss: 2531.9905\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.4755 - val_loss: 2630.0906\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.6943 - val_loss: 4065.8125\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 806.0960 - val_loss: 149.0524\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 49.2271 - val_loss: 113.1531\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 53.3603 - val_loss: 69.0967\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 51.5498 - val_loss: 65.0066\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.3077 - val_loss: 53.8686\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.6728 - val_loss: 63.2534\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 57.7613 - val_loss: 83.6183\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.8452 - val_loss: 60.4224\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.3525 - val_loss: 59.5355\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.1735 - val_loss: 68.1883\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 47.1650 - val_loss: 62.4399\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 52.6303 - val_loss: 72.9979\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 43.9405 - val_loss: 68.0706\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.3758 - val_loss: 68.6196\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.1677 - val_loss: 51.6655\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.6629 - val_loss: 64.0786\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 41.6274 - val_loss: 69.0854\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.0713 - val_loss: 74.0919\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51.7842 - val_loss: 78.3589\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 38.3462 - val_loss: 46.9668\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.5257 - val_loss: 65.0832\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 43.8433 - val_loss: 56.2692\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.7324 - val_loss: 51.1213\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.4279 - val_loss: 48.8407\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 44.8873 - val_loss: 39.7040\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 43.5417 - val_loss: 59.4279\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.7617 - val_loss: 49.3651\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 43.6681 - val_loss: 50.6604\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 40.5167 - val_loss: 46.1249\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 50.6045 - val_loss: 59.2071\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.9361 - val_loss: 51.6102\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 43.2092 - val_loss: 38.1140\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.1725 - val_loss: 46.4591\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.5172 - val_loss: 48.6097\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 38.4315 - val_loss: 56.5789\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.3570 - val_loss: 67.8517\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 41.5400 - val_loss: 53.7776\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 54.5346 - val_loss: 45.1997\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 48.7414 - val_loss: 45.0877\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 48.4159 - val_loss: 57.7083\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 42.3463 - val_loss: 45.1022\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.6997 - val_loss: 56.7356\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.0916 - val_loss: 51.0747\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 40.7753 - val_loss: 51.8607\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 44.4448 - val_loss: 51.3003\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.4314 - val_loss: 51.6638\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 38.3689 - val_loss: 47.1063\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 36.9595 - val_loss: 19.4579\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 38.6144 - val_loss: 18.2896\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 33.2898 - val_loss: 18.1062\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.9636 - val_loss: 18.8790\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 48.8265 - val_loss: 34.5906\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 41.9551 - val_loss: 26.6343\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 43.9711 - val_loss: 17.8358\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 47.5085 - val_loss: 16.0611\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.5712 - val_loss: 33.7176\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 38.4601 - val_loss: 34.9960\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.3805 - val_loss: 39.3721\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.1617 - val_loss: 35.5800\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.6123 - val_loss: 31.6556\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.1189 - val_loss: 35.6100\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 43.0619 - val_loss: 19.9322\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.7100 - val_loss: 39.0109\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 40.7786 - val_loss: 30.8468\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 44.6052 - val_loss: 64.0385\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 72.3205 - val_loss: 17.3482\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.2561 - val_loss: 20.2092\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.0986 - val_loss: 23.1949\n",
      "Epoch 551/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 40.8428 - val_loss: 18.7026\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.2887 - val_loss: 37.2125\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.5125 - val_loss: 24.8059\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.1089 - val_loss: 30.5427\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.2476 - val_loss: 27.7725\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.6169 - val_loss: 31.4771\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 38.9404 - val_loss: 39.6849\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.3949 - val_loss: 24.3603\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.6774 - val_loss: 31.4758\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.9034 - val_loss: 32.5352\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.8550 - val_loss: 43.1078\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.0252 - val_loss: 53.3473\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 38.7270 - val_loss: 43.4159\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.0498 - val_loss: 40.3881\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 33.1032 - val_loss: 34.7640\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.3930 - val_loss: 37.4971\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.0781 - val_loss: 29.2889\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.3946 - val_loss: 69.3769\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.8098 - val_loss: 36.6585\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 38.0726 - val_loss: 46.7911\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.6832 - val_loss: 74.5068\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.3177 - val_loss: 66.4241\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.7999 - val_loss: 45.6363\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 45.2091 - val_loss: 55.2997\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 38.9124 - val_loss: 44.0709\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.5195 - val_loss: 70.7654\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.9474 - val_loss: 31.6309\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.0983 - val_loss: 50.6449\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.6850 - val_loss: 39.6535\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 43.8883 - val_loss: 40.1022\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 37.8717 - val_loss: 53.2710\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 40.5876 - val_loss: 65.2958\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 39.7087 - val_loss: 67.4533\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 50.1369 - val_loss: 101.0794\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 39.5423 - val_loss: 109.2168\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.0616 - val_loss: 143.5953\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.5297 - val_loss: 105.8903\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 34.2458 - val_loss: 126.7058\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.6948 - val_loss: 99.5703\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 37.2526 - val_loss: 73.1302\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.2904 - val_loss: 100.6800\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.0069 - val_loss: 133.2651\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 42.5597 - val_loss: 82.6027\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.3413 - val_loss: 97.3252\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.9813 - val_loss: 109.4081\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.6047 - val_loss: 102.1250\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.6227 - val_loss: 202.5207\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.8327 - val_loss: 41.7036\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.7321 - val_loss: 45.8593\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.3813 - val_loss: 33.2401\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.7521 - val_loss: 42.7274\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.4591 - val_loss: 30.6621\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.9812 - val_loss: 31.1997\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.5798 - val_loss: 28.8491\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.6252 - val_loss: 34.5021\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 34.7253 - val_loss: 35.4053\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 41.8843 - val_loss: 41.0541\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.1215 - val_loss: 35.3189\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.8887 - val_loss: 30.7080\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 37.7335 - val_loss: 20.0031\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 45.8026 - val_loss: 18.2186\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.7863 - val_loss: 29.1306\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.6184 - val_loss: 27.8424\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.5052 - val_loss: 32.6027\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.8714 - val_loss: 36.1008\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.4239 - val_loss: 38.3343\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.2953 - val_loss: 33.4672\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.4621 - val_loss: 34.6792\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.0345 - val_loss: 40.5945\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.3360 - val_loss: 39.8371\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.9131 - val_loss: 39.6022\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.8136 - val_loss: 42.1672\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 37.4294 - val_loss: 40.4014\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 37.1438 - val_loss: 32.7933\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.6559 - val_loss: 72.7460\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.3675 - val_loss: 41.9617\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.2988 - val_loss: 51.6446\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.0626 - val_loss: 32.3072\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.6483 - val_loss: 47.9867\n",
      "Epoch 630/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 37.2050 - val_loss: 31.7525\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.4301 - val_loss: 61.3509\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.4130 - val_loss: 1750.0127\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.8655 - val_loss: 1755.6802\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.6726 - val_loss: 1711.8989\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 33.0022 - val_loss: 1737.1118\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.1074 - val_loss: 1949.1045\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.7139 - val_loss: 1552.0518\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.0197 - val_loss: 1842.6415\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 38.1768 - val_loss: 1972.1289\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.6437 - val_loss: 1841.3695\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.8291 - val_loss: 1607.4950\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.8423 - val_loss: 1605.3354\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.5349 - val_loss: 1931.8085\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.8922 - val_loss: 1687.6315\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.6788 - val_loss: 1617.4330\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.8265 - val_loss: 1706.0365\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.7365 - val_loss: 1748.2870\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.0357 - val_loss: 1825.1786\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 44.0477 - val_loss: 1729.3154\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 41.6152 - val_loss: 1935.6107\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.0442 - val_loss: 1658.6945\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 41.4132 - val_loss: 1756.8605\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.2934 - val_loss: 1971.5947\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 43.8590 - val_loss: 1758.1793\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.6686 - val_loss: 1715.7206\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.1728 - val_loss: 1646.0156\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.2217 - val_loss: 1729.2177\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.2222 - val_loss: 1615.0248\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.2980 - val_loss: 1621.0345\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 50.1019 - val_loss: 2003.0231\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 57.0697 - val_loss: 1789.2169\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.7860 - val_loss: 1214.7152\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.2401 - val_loss: 1257.3793\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.5076 - val_loss: 1261.9204\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.6634 - val_loss: 1273.4272\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.3623 - val_loss: 1268.2565\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 40.9866 - val_loss: 1348.8828\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 34.7936 - val_loss: 1216.5259\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.1454 - val_loss: 1370.9155\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.6990 - val_loss: 1339.5039\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.4049 - val_loss: 1278.5741\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.9104 - val_loss: 1367.0673\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.1549 - val_loss: 1318.5288\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.0854 - val_loss: 1223.8573\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.6160 - val_loss: 1234.5380\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37.5754 - val_loss: 1168.9652\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.6530 - val_loss: 1238.3798\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.2611 - val_loss: 1213.3610\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 36.0247 - val_loss: 1434.5446\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 36.1034 - val_loss: 1244.3788\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.7290 - val_loss: 1073.0997\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.5287 - val_loss: 1167.6962\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.2001 - val_loss: 1282.7970\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.4202 - val_loss: 1241.7032\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.6681 - val_loss: 1258.9832\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.3578 - val_loss: 1318.9020\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.8666 - val_loss: 1368.7363\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.3300 - val_loss: 1331.8918\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.4444 - val_loss: 1284.6637\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.5760 - val_loss: 1145.2660\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.4088 - val_loss: 1273.4352\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.0023 - val_loss: 1453.4844\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.8181 - val_loss: 1286.7299\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.4060 - val_loss: 1412.5031\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 31.9192 - val_loss: 1319.9810\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.3295 - val_loss: 1292.0913\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.2041 - val_loss: 1329.0936\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.5000 - val_loss: 1299.5175\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.5357 - val_loss: 1300.8180\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.0189 - val_loss: 1491.1680\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.2508 - val_loss: 1520.6295\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.8138 - val_loss: 1508.6538\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.9202 - val_loss: 1440.2681\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 35.4066 - val_loss: 1426.2354\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.9851 - val_loss: 1238.8033\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.1614 - val_loss: 1304.8182\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.3235 - val_loss: 1449.3973\n",
      "Epoch 708/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 31.5011 - val_loss: 1437.6378\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 30.8749 - val_loss: 1350.7703\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 33.7209 - val_loss: 1447.8707\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 33.2275 - val_loss: 1310.1191\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.2230 - val_loss: 1311.0045\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.2657 - val_loss: 1342.7612\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 35.9088 - val_loss: 1400.0397\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.8278 - val_loss: 1392.0282\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.0420 - val_loss: 1314.4199\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 31.3687 - val_loss: 1431.3685\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.9348 - val_loss: 1313.9249\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.5009 - val_loss: 1380.4503\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.0410 - val_loss: 1348.0848\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 31.2058 - val_loss: 1306.2826\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.9770 - val_loss: 1249.8131\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.6279 - val_loss: 1343.9874\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.8555 - val_loss: 1453.4620\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.9717 - val_loss: 1319.3524\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.1550 - val_loss: 1203.2046\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.2840 - val_loss: 1315.9730\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.5672 - val_loss: 1383.8365\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 30.2254 - val_loss: 1362.5045\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.8747 - val_loss: 1469.6112\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.1649 - val_loss: 1421.8285\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.7281 - val_loss: 1471.7456\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.4406 - val_loss: 1412.7788\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.9537 - val_loss: 1515.0311\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.7908 - val_loss: 1536.3568\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.8920 - val_loss: 1412.8467\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.6867 - val_loss: 1647.9756\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.4762 - val_loss: 1458.1007\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.0884 - val_loss: 1604.2694\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.6357 - val_loss: 1539.1244\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 34.2138 - val_loss: 1449.3491\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.4660 - val_loss: 1590.3882\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.5204 - val_loss: 1527.3009\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.3923 - val_loss: 1511.1117\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.6595 - val_loss: 1523.5127\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.9149 - val_loss: 1320.0292\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.1295 - val_loss: 1539.0653\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.6213 - val_loss: 1438.8627\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.6529 - val_loss: 1470.8447\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 32.7968 - val_loss: 1410.1503\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.0485 - val_loss: 1482.6678\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.2943 - val_loss: 1367.9889\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.7601 - val_loss: 1508.1401\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.7991 - val_loss: 1583.7010\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.1529 - val_loss: 1499.1489\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.7251 - val_loss: 1472.4722\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 34.8396 - val_loss: 1537.8945\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.6804 - val_loss: 1554.0973\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.4675 - val_loss: 1403.2345\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.4916 - val_loss: 1708.0514\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.8344 - val_loss: 1573.0277\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 35.4587 - val_loss: 1565.8834\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.9411 - val_loss: 1524.8226\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.2492 - val_loss: 1427.3105\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.0571 - val_loss: 1430.7632\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.5175 - val_loss: 1631.3306\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.7303 - val_loss: 1549.3799\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.4841 - val_loss: 1560.4623\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.4262 - val_loss: 1529.8739\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.9828 - val_loss: 1460.9023\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.9034 - val_loss: 1466.6173\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.2155 - val_loss: 1523.4269\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 36.5783 - val_loss: 1400.3789\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.1651 - val_loss: 1491.3345\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.6828 - val_loss: 1446.0132\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.9674 - val_loss: 1420.5889\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.6380 - val_loss: 1426.3832\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.3834 - val_loss: 1340.6044\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.3242 - val_loss: 1214.7266\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.2647 - val_loss: 1348.7402\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.8295 - val_loss: 1468.6176\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.2343 - val_loss: 1507.3970\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.4768 - val_loss: 1423.8378\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.4581 - val_loss: 1512.0809\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.3954 - val_loss: 1456.3419\n",
      "Epoch 786/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 31.9104 - val_loss: 1334.2910\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.3664 - val_loss: 1612.7943\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.7361 - val_loss: 1347.6956\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.3288 - val_loss: 1351.4532\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.0452 - val_loss: 1353.4082\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.4976 - val_loss: 1536.2852\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.1882 - val_loss: 1506.3639\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.4601 - val_loss: 1544.4633\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.6349 - val_loss: 1496.4152\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.2353 - val_loss: 1525.4551\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 28.6264 - val_loss: 1597.5680\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.3233 - val_loss: 1544.5269\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.0248 - val_loss: 1333.4786\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.8469 - val_loss: 1363.4740\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 37.0141 - val_loss: 1499.9092\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.7873 - val_loss: 1307.3879\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 31.4425 - val_loss: 1325.2861\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 27.9163 - val_loss: 1257.1888\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 31.9303 - val_loss: 1366.7379\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.0050 - val_loss: 1351.9896\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.6275 - val_loss: 1235.4747\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.7973 - val_loss: 1315.3536\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.3632 - val_loss: 1399.7760\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.2364 - val_loss: 1398.4253\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.8641 - val_loss: 1522.8383\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.0798 - val_loss: 1422.0049\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.0025 - val_loss: 1514.4625\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.1673 - val_loss: 1456.3248\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 31.5282 - val_loss: 1388.6074\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 34.9217 - val_loss: 1425.8107\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 31.4123 - val_loss: 1468.7065\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.9170 - val_loss: 1456.8258\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 38.9548 - val_loss: 1451.1688\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.3668 - val_loss: 1508.6802\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.0147 - val_loss: 1626.8789\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.4451 - val_loss: 1621.1533\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.6580 - val_loss: 1594.0073\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.0864 - val_loss: 1401.7465\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.9437 - val_loss: 1459.9237\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.3049 - val_loss: 1573.0146\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.4401 - val_loss: 1528.0035\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.7679 - val_loss: 1606.5923\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.4260 - val_loss: 1493.3126\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.2617 - val_loss: 1572.1263\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.4019 - val_loss: 1691.7679\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.4942 - val_loss: 1414.5228\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.4220 - val_loss: 1565.3221\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.7868 - val_loss: 1627.1356\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.7737 - val_loss: 1590.1891\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 37.7897 - val_loss: 1621.3975\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.1753 - val_loss: 1552.7476\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.9167 - val_loss: 1536.2036\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.3558 - val_loss: 1510.1510\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.2277 - val_loss: 1691.0752\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.5712 - val_loss: 1632.3485\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.6815 - val_loss: 1651.5699\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 40.8119 - val_loss: 1496.7350\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.3921 - val_loss: 1558.6484\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.1149 - val_loss: 1636.6436\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36.1401 - val_loss: 1676.0944\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.3183 - val_loss: 1652.9740\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.0267 - val_loss: 1540.2626\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.8265 - val_loss: 1508.5973\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.8335 - val_loss: 1717.2767\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.6430 - val_loss: 1546.8649\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.4714 - val_loss: 1660.5143\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.7100 - val_loss: 1788.2836\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.9933 - val_loss: 1818.7842\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.2813 - val_loss: 1873.4990\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 27.6705 - val_loss: 1753.1224\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.3194 - val_loss: 1702.9769\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.0929 - val_loss: 1681.3340\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.2369 - val_loss: 1761.8320\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 33.6747 - val_loss: 1597.5176\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 29.5843 - val_loss: 1612.3036\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.5157 - val_loss: 1733.7330\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 30.4544 - val_loss: 1663.3887\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.2708 - val_loss: 1905.2324\n",
      "Epoch 864/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 37.6486 - val_loss: 1662.6445\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 39.7691 - val_loss: 1749.5250\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.5481 - val_loss: 1813.2904\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.7919 - val_loss: 1874.9281\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.3704 - val_loss: 1714.7933\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 28.3670 - val_loss: 1616.4176\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.2183 - val_loss: 1617.1354\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.1265 - val_loss: 1812.0737\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 30.3891 - val_loss: 1820.0566\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 28.2973 - val_loss: 1752.0879\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.4532 - val_loss: 1633.8053\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 30.1856 - val_loss: 1779.7467\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.1182 - val_loss: 1974.4808\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 28.4808 - val_loss: 1658.4209\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.6120 - val_loss: 1688.2914\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.4294 - val_loss: 1737.6881\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.8729 - val_loss: 1623.6582\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.1981 - val_loss: 1599.8641\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.1756 - val_loss: 1781.0795\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.9910 - val_loss: 1672.0215\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.9366 - val_loss: 1743.1730\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 31.9422 - val_loss: 1604.2041\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.2454 - val_loss: 1511.8043\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.1694 - val_loss: 1405.7748\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.9366 - val_loss: 1603.8348\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 28.4764 - val_loss: 1577.4686\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.3210 - val_loss: 1528.7451\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.4148 - val_loss: 1644.2242\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.5773 - val_loss: 1626.5488\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.7949 - val_loss: 1581.3311\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.7297 - val_loss: 1716.1475\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.1633 - val_loss: 1558.5951\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 33.3064 - val_loss: 1655.2552\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.5420 - val_loss: 1683.9966\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 28.5647 - val_loss: 1612.0822\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 28.6429 - val_loss: 1600.8995\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 27.8859 - val_loss: 1778.2539\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.7259 - val_loss: 1690.8165\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.9307 - val_loss: 1641.2328\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.5675 - val_loss: 1522.8027\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.0859 - val_loss: 1619.5619\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 35.2602 - val_loss: 1494.3116\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.6852 - val_loss: 1592.9498\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 28.1883 - val_loss: 1599.4102\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.0693 - val_loss: 1742.4440\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.5311 - val_loss: 1835.7178\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.2626 - val_loss: 1694.0294\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.8567 - val_loss: 1808.9043\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.2043 - val_loss: 1633.7832\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.0354 - val_loss: 1672.2230\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 28.3559 - val_loss: 1570.6469\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 33.0413 - val_loss: 1657.2748\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.7792 - val_loss: 1625.6940\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.1234 - val_loss: 1807.8551\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.1698 - val_loss: 1127.6178\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37.4920 - val_loss: 1277.9982\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.4303 - val_loss: 1403.3794\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.5803 - val_loss: 1296.1069\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.5134 - val_loss: 1222.2648\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.8656 - val_loss: 1290.5059\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.7336 - val_loss: 1331.7108\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.2482 - val_loss: 1390.0914\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.1720 - val_loss: 1308.9633\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 33.1676 - val_loss: 1300.3058\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 34.8675 - val_loss: 1429.2230\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 35.1242 - val_loss: 1432.1534\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.8691 - val_loss: 1196.7333\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 27.2758 - val_loss: 1307.0360\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.4154 - val_loss: 1259.8549\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.8235 - val_loss: 1252.1782\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.1038 - val_loss: 1291.1979\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.8983 - val_loss: 1260.3253\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.3913 - val_loss: 1357.1833\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.1228 - val_loss: 1246.6539\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 28.8780 - val_loss: 1232.8804\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.8868 - val_loss: 1215.5651\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.6982 - val_loss: 1183.2010\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.3404 - val_loss: 1185.9681\n",
      "Epoch 942/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 26.4084 - val_loss: 1524.8472\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.5043 - val_loss: 1338.3390\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.0974 - val_loss: 1529.0732\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.6393 - val_loss: 1379.1279\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.7461 - val_loss: 1333.2509\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.8762 - val_loss: 1344.9806\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.1233 - val_loss: 1368.7054\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 28.7504 - val_loss: 1412.9492\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.7985 - val_loss: 1363.0436\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.9723 - val_loss: 1376.8844\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.9290 - val_loss: 1461.0490\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 28.1429 - val_loss: 1527.2638\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.6430 - val_loss: 1433.1870\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.1233 - val_loss: 1451.5830\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.5081 - val_loss: 1330.5170\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.9783 - val_loss: 1524.4171\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.0546 - val_loss: 1455.7324\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.7159 - val_loss: 1559.6676\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 26.3194 - val_loss: 1535.8429\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.2018 - val_loss: 1604.2992\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.0270 - val_loss: 1540.3789\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.6944 - val_loss: 1448.4590\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.1946 - val_loss: 1670.0010\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 36.4215 - val_loss: 2180.6841\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.3828 - val_loss: 1601.7623\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.1731 - val_loss: 1435.1318\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 28.7495 - val_loss: 1574.9083\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.8160 - val_loss: 1356.4120\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.8370 - val_loss: 1453.7460\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.1710 - val_loss: 1399.8309\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.8819 - val_loss: 1234.1759\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.2056 - val_loss: 1557.9764\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.1590 - val_loss: 1642.5894\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.0700 - val_loss: 1518.8617\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.6024 - val_loss: 1461.5377\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 27.3943 - val_loss: 1488.4491\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.5326 - val_loss: 1474.5262\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.2402 - val_loss: 1359.2675\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.0923 - val_loss: 1517.0800\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.9140 - val_loss: 1520.4708\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 26.9569 - val_loss: 1582.6097\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 26.2184 - val_loss: 1473.7427\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 30.4136 - val_loss: 1300.8364\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.5737 - val_loss: 1326.0028\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.8034 - val_loss: 1275.1422\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.1671 - val_loss: 1407.9430\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.7673 - val_loss: 1461.7057\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.8785 - val_loss: 1362.8159\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.5167 - val_loss: 1346.4700\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.1993 - val_loss: 1398.3851\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.4112 - val_loss: 1546.7445\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.3182 - val_loss: 1881.1005\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.8874 - val_loss: 1460.9821\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 29.2248 - val_loss: 1496.1823\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.7166 - val_loss: 1550.8138\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.8864 - val_loss: 1577.2089\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.3454 - val_loss: 1548.2593\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.3791 - val_loss: 1563.7780\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.7968 - val_loss: 1340.0848\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.1125 - val_loss: 1746.5045\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 25.1008 - val_loss: 1674.7504\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 28.6112 - val_loss: 1640.1969\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 28.4497 - val_loss: 1630.7162\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.1894 - val_loss: 1755.5018\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.7302 - val_loss: 1707.1841\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.6624 - val_loss: 1781.3701\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 28.3274 - val_loss: 1587.2596\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.0501 - val_loss: 1720.8663\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.2455 - val_loss: 2330.9922\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 39.5145 - val_loss: 1883.9990\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.8016 - val_loss: 1578.4213\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.6939 - val_loss: 1711.4034\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.1612 - val_loss: 1828.6958\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 33.4257 - val_loss: 1649.9438\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.1423 - val_loss: 1655.3339\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.8690 - val_loss: 1784.1681\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 28.7005 - val_loss: 1766.2251\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.5979 - val_loss: 1677.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.4197 - val_loss: 2192.4187\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 28.2354 - val_loss: 2038.3004\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34.9314 - val_loss: 2244.7988\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 34.7720 - val_loss: 2228.0142\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.1910 - val_loss: 2023.0586\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 34.1582 - val_loss: 1835.4386\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.1365 - val_loss: 2061.3318\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29.1340 - val_loss: 1997.1396\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.4204 - val_loss: 1884.0278\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.2312 - val_loss: 1794.8265\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 28.6230 - val_loss: 2001.2731\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 29.6394 - val_loss: 1631.3121\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 35.8253 - val_loss: 1874.0387\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 30.4181 - val_loss: 1992.4308\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 30.9837 - val_loss: 1747.3973\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 31.0158 - val_loss: 1771.4398\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31.1598 - val_loss: 2099.6782\n",
      "Epoch 1037/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 23.9267Restoring model weights from the end of the best epoch: 537.\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 30.7366 - val_loss: 1850.6920\n",
      "Epoch 1037: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>58.010674</td>\n",
       "      <td>56.281158</td>\n",
       "      <td>56.054428</td>\n",
       "      <td>55.564255</td>\n",
       "      <td>52.551437</td>\n",
       "      <td>49.811447</td>\n",
       "      <td>39.715195</td>\n",
       "      <td>38.651131</td>\n",
       "      <td>38.898132</td>\n",
       "      <td>39.590118</td>\n",
       "      <td>36.523102</td>\n",
       "      <td>48.932991</td>\n",
       "      <td>36.97216</td>\n",
       "      <td>33.383018</td>\n",
       "      <td>37.866478</td>\n",
       "      <td>40.76004</td>\n",
       "      <td>43.972759</td>\n",
       "      <td>33.386143</td>\n",
       "      <td>29.533875</td>\n",
       "      <td>31.392685</td>\n",
       "      <td>32.231926</td>\n",
       "      <td>29.122335</td>\n",
       "      <td>24.162369</td>\n",
       "      <td>22.392145</td>\n",
       "      <td>24.230759</td>\n",
       "      <td>33.933983</td>\n",
       "      <td>48.56424</td>\n",
       "      <td>61.095856</td>\n",
       "      <td>76.48497</td>\n",
       "      <td>79.722137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>61.721</td>\n",
       "      <td>69.24</td>\n",
       "      <td>70.048</td>\n",
       "      <td>67.172</td>\n",
       "      <td>64.22</td>\n",
       "      <td>63.021</td>\n",
       "      <td>62.639</td>\n",
       "      <td>53.839</td>\n",
       "      <td>56.652</td>\n",
       "      <td>53.408</td>\n",
       "      <td>50.543</td>\n",
       "      <td>64.699</td>\n",
       "      <td>60.219</td>\n",
       "      <td>64.217</td>\n",
       "      <td>57.591</td>\n",
       "      <td>64.307</td>\n",
       "      <td>61.971</td>\n",
       "      <td>57.48</td>\n",
       "      <td>68.053</td>\n",
       "      <td>55.231</td>\n",
       "      <td>53.723</td>\n",
       "      <td>57.457</td>\n",
       "      <td>62.755</td>\n",
       "      <td>48.148</td>\n",
       "      <td>62.19</td>\n",
       "      <td>62.219</td>\n",
       "      <td>61.329</td>\n",
       "      <td>81.988</td>\n",
       "      <td>79.341</td>\n",
       "      <td>76.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>3.710327</td>\n",
       "      <td>12.958839</td>\n",
       "      <td>13.993568</td>\n",
       "      <td>11.607742</td>\n",
       "      <td>11.668564</td>\n",
       "      <td>13.209553</td>\n",
       "      <td>22.923805</td>\n",
       "      <td>15.18787</td>\n",
       "      <td>17.753868</td>\n",
       "      <td>13.817883</td>\n",
       "      <td>14.019897</td>\n",
       "      <td>15.766006</td>\n",
       "      <td>23.246841</td>\n",
       "      <td>30.833984</td>\n",
       "      <td>19.724522</td>\n",
       "      <td>23.546959</td>\n",
       "      <td>17.998241</td>\n",
       "      <td>24.093857</td>\n",
       "      <td>38.519127</td>\n",
       "      <td>23.838314</td>\n",
       "      <td>21.491074</td>\n",
       "      <td>28.334665</td>\n",
       "      <td>38.592632</td>\n",
       "      <td>25.755854</td>\n",
       "      <td>37.95924</td>\n",
       "      <td>28.285019</td>\n",
       "      <td>12.764759</td>\n",
       "      <td>20.892143</td>\n",
       "      <td>2.856033</td>\n",
       "      <td>3.076134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1          2          3          4          5   \\\n",
       "Month         Month-1    Month-2    Month-3    Month-4    Month-5    Month-6   \n",
       "Prediction  58.010674  56.281158  56.054428  55.564255  52.551437  49.811447   \n",
       "Target         61.721      69.24     70.048     67.172      64.22     63.021   \n",
       "Error        3.710327  12.958839  13.993568  11.607742  11.668564  13.209553   \n",
       "\n",
       "                   6          7          8          9          10         11  \\\n",
       "Month         Month-7    Month-8    Month-9   Month-10   Month-11   Month-12   \n",
       "Prediction  39.715195  38.651131  38.898132  39.590118  36.523102  48.932991   \n",
       "Target         62.639     53.839     56.652     53.408     50.543     64.699   \n",
       "Error       22.923805   15.18787  17.753868  13.817883  14.019897  15.766006   \n",
       "\n",
       "                   12         13         14         15         16         17  \\\n",
       "Month        Month-13   Month-14   Month-15   Month-16   Month-17   Month-18   \n",
       "Prediction   36.97216  33.383018  37.866478   40.76004  43.972759  33.386143   \n",
       "Target         60.219     64.217     57.591     64.307     61.971      57.48   \n",
       "Error       23.246841  30.833984  19.724522  23.546959  17.998241  24.093857   \n",
       "\n",
       "                   18         19         20         21         22         23  \\\n",
       "Month        Month-19   Month-20   Month-21   Month-22   Month-23   Month-24   \n",
       "Prediction  29.533875  31.392685  32.231926  29.122335  24.162369  22.392145   \n",
       "Target         68.053     55.231     53.723     57.457     62.755     48.148   \n",
       "Error       38.519127  23.838314  21.491074  28.334665  38.592632  25.755854   \n",
       "\n",
       "                   24         25         26         27        28         29  \n",
       "Month        Month-25   Month-26   Month-27   Month-28  Month-29   Month-30  \n",
       "Prediction  24.230759  33.933983   48.56424  61.095856  76.48497  79.722137  \n",
       "Target          62.19     62.219     61.329     81.988    79.341     76.646  \n",
       "Error        37.95924  28.285019  12.764759  20.892143  2.856033   3.076134  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.614244"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.3227207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Ano-0: |Prediction[[570.58405]] - Target[737.202]| =  Error: [[166.61798]]; MAPE:[[0.226014]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Ano-0: |Prediction[[395.17596]] - Target[711.152]| =  Error: [[315.976]]; MAPE:[[0.44431573]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Ano-5: |Prediction[[324.03192]] - Target[423.713]| =  Error: [[99.68109]]; MAPE:[[0.23525615]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[166.61798]], dtype=float32),\n",
       " array([[315.976]], dtype=float32),\n",
       " array([[99.68109]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "194.09169"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.30186197"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
