{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Rio De Janeiro - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rio de-01eiro - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rio De Janeiro - Produção de Cimento (t)</th>\n",
       "      <th>Rio de Janeiro - IDH</th>\n",
       "      <th>Rio de Janeiro - PIB - Estadual</th>\n",
       "      <th>Rio de Janeiro - PIB - Construção Civil</th>\n",
       "      <th>Rio de Janeiro - PIB - Per Capita</th>\n",
       "      <th>Rio de Janeiro - PIB Preços de Mercado</th>\n",
       "      <th>Rio de Janeiro - Desemprego</th>\n",
       "      <th>Rio De Janeiro - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.291137</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>199.081280</td>\n",
       "      <td>0.773489</td>\n",
       "      <td>3.583430e+08</td>\n",
       "      <td>1.813534e+07</td>\n",
       "      <td>22.143720</td>\n",
       "      <td>3.472846e+08</td>\n",
       "      <td>8.356512</td>\n",
       "      <td>254.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.293538</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>198.561780</td>\n",
       "      <td>0.773547</td>\n",
       "      <td>3.587441e+08</td>\n",
       "      <td>1.814108e+07</td>\n",
       "      <td>22.149228</td>\n",
       "      <td>3.474056e+08</td>\n",
       "      <td>8.350332</td>\n",
       "      <td>252.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.295914</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>198.773336</td>\n",
       "      <td>0.773606</td>\n",
       "      <td>3.591452e+08</td>\n",
       "      <td>1.814681e+07</td>\n",
       "      <td>22.154735</td>\n",
       "      <td>3.475266e+08</td>\n",
       "      <td>8.344152</td>\n",
       "      <td>229.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.298264</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>198.753800</td>\n",
       "      <td>0.773665</td>\n",
       "      <td>3.595464e+08</td>\n",
       "      <td>1.815255e+07</td>\n",
       "      <td>22.160243</td>\n",
       "      <td>3.476476e+08</td>\n",
       "      <td>8.337971</td>\n",
       "      <td>243.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.300588</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>198.721455</td>\n",
       "      <td>0.773724</td>\n",
       "      <td>3.599475e+08</td>\n",
       "      <td>1.815828e+07</td>\n",
       "      <td>22.165750</td>\n",
       "      <td>3.477686e+08</td>\n",
       "      <td>8.331791</td>\n",
       "      <td>256.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>0.559828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232.917513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>0.558289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232.658000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>0.556367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232.339116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>0.554021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.667333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>0.550789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.946659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221.319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Rio de-01eiro - value  \\\n",
       "0       2003-1               0.291137   \n",
       "1       2003-2               0.293538   \n",
       "2       2003-3               0.295914   \n",
       "3       2003-4               0.298264   \n",
       "4       2003-5               0.300588   \n",
       "..         ...                    ...   \n",
       "235     2022-8               0.559828   \n",
       "236     2022-9               0.558289   \n",
       "237    2022-10               0.556367   \n",
       "238    2022-11               0.554021   \n",
       "239    2022-12               0.550789   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     Rio De Janeiro - Produção de Cimento (t)  Rio de Janeiro - IDH  \\\n",
       "0                                  199.081280              0.773489   \n",
       "1                                  198.561780              0.773547   \n",
       "2                                  198.773336              0.773606   \n",
       "3                                  198.753800              0.773665   \n",
       "4                                  198.721455              0.773724   \n",
       "..                                        ...                   ...   \n",
       "235                                232.917513                   NaN   \n",
       "236                                232.658000                   NaN   \n",
       "237                                232.339116                   NaN   \n",
       "238                                231.667333                   NaN   \n",
       "239                                231.946659                   NaN   \n",
       "\n",
       "     Rio de Janeiro - PIB - Estadual  Rio de Janeiro - PIB - Construção Civil  \\\n",
       "0                       3.583430e+08                             1.813534e+07   \n",
       "1                       3.587441e+08                             1.814108e+07   \n",
       "2                       3.591452e+08                             1.814681e+07   \n",
       "3                       3.595464e+08                             1.815255e+07   \n",
       "4                       3.599475e+08                             1.815828e+07   \n",
       "..                               ...                                      ...   \n",
       "235                              NaN                                      NaN   \n",
       "236                              NaN                                      NaN   \n",
       "237                              NaN                                      NaN   \n",
       "238                              NaN                                      NaN   \n",
       "239                              NaN                                      NaN   \n",
       "\n",
       "     Rio de Janeiro - PIB - Per Capita  \\\n",
       "0                            22.143720   \n",
       "1                            22.149228   \n",
       "2                            22.154735   \n",
       "3                            22.160243   \n",
       "4                            22.165750   \n",
       "..                                 ...   \n",
       "235                                NaN   \n",
       "236                                NaN   \n",
       "237                                NaN   \n",
       "238                                NaN   \n",
       "239                                NaN   \n",
       "\n",
       "     Rio de Janeiro - PIB Preços de Mercado  Rio de Janeiro - Desemprego  \\\n",
       "0                              3.472846e+08                     8.356512   \n",
       "1                              3.474056e+08                     8.350332   \n",
       "2                              3.475266e+08                     8.344152   \n",
       "3                              3.476476e+08                     8.337971   \n",
       "4                              3.477686e+08                     8.331791   \n",
       "..                                      ...                          ...   \n",
       "235                                     NaN                          NaN   \n",
       "236                                     NaN                          NaN   \n",
       "237                                     NaN                          NaN   \n",
       "238                                     NaN                          NaN   \n",
       "239                                     NaN                          NaN   \n",
       "\n",
       "     Rio De Janeiro - Consumo de Cimento (t)  \n",
       "0                                    254.362  \n",
       "1                                    252.842  \n",
       "2                                    229.385  \n",
       "3                                    243.407  \n",
       "4                                    256.535  \n",
       "..                                       ...  \n",
       "235                                  241.702  \n",
       "236                                  221.036  \n",
       "237                                  224.399  \n",
       "238                                  221.319  \n",
       "239                                  221.319  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_RJ.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rio de-01eiro - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rio De Janeiro - Produção de Cimento (t)</th>\n",
       "      <th>Rio de Janeiro - IDH</th>\n",
       "      <th>Rio de Janeiro - PIB - Estadual</th>\n",
       "      <th>Rio de Janeiro - PIB - Construção Civil</th>\n",
       "      <th>Rio de Janeiro - PIB - Per Capita</th>\n",
       "      <th>Rio de Janeiro - PIB Preços de Mercado</th>\n",
       "      <th>Rio de Janeiro - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.533996</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.060779</td>\n",
       "      <td>-1.723389</td>\n",
       "      <td>-1.790542</td>\n",
       "      <td>0.136347</td>\n",
       "      <td>0.121226</td>\n",
       "      <td>-1.445055</td>\n",
       "      <td>-0.790925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.486609</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.079132</td>\n",
       "      <td>-1.706702</td>\n",
       "      <td>-1.768299</td>\n",
       "      <td>0.149077</td>\n",
       "      <td>0.152115</td>\n",
       "      <td>-1.365321</td>\n",
       "      <td>-0.794037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.439709</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.071658</td>\n",
       "      <td>-1.690015</td>\n",
       "      <td>-1.746055</td>\n",
       "      <td>0.161806</td>\n",
       "      <td>0.183005</td>\n",
       "      <td>-1.285587</td>\n",
       "      <td>-0.797148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.393318</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.072349</td>\n",
       "      <td>-1.673328</td>\n",
       "      <td>-1.723811</td>\n",
       "      <td>0.174535</td>\n",
       "      <td>0.213895</td>\n",
       "      <td>-1.205853</td>\n",
       "      <td>-0.800259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.347462</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.073491</td>\n",
       "      <td>-1.656642</td>\n",
       "      <td>-1.701567</td>\n",
       "      <td>0.187264</td>\n",
       "      <td>0.244784</td>\n",
       "      <td>-1.126118</td>\n",
       "      <td>-0.803370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.438978</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-0.476880</td>\n",
       "      <td>0.839598</td>\n",
       "      <td>1.110414</td>\n",
       "      <td>-1.635096</td>\n",
       "      <td>-1.325228</td>\n",
       "      <td>-1.036232</td>\n",
       "      <td>1.324172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.443990</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>-0.460898</td>\n",
       "      <td>0.793634</td>\n",
       "      <td>1.098172</td>\n",
       "      <td>-1.625552</td>\n",
       "      <td>-1.326867</td>\n",
       "      <td>-1.053116</td>\n",
       "      <td>1.322796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.457014</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>-0.421271</td>\n",
       "      <td>0.747671</td>\n",
       "      <td>1.085930</td>\n",
       "      <td>-1.616009</td>\n",
       "      <td>-1.328507</td>\n",
       "      <td>-1.070000</td>\n",
       "      <td>1.321421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.470138</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-0.402090</td>\n",
       "      <td>0.701707</td>\n",
       "      <td>1.073688</td>\n",
       "      <td>-1.606465</td>\n",
       "      <td>-1.330147</td>\n",
       "      <td>-1.086883</td>\n",
       "      <td>1.320046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.485431</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-0.385375</td>\n",
       "      <td>0.655743</td>\n",
       "      <td>1.061447</td>\n",
       "      <td>-1.596921</td>\n",
       "      <td>-1.331787</td>\n",
       "      <td>-1.103767</td>\n",
       "      <td>1.318671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rio de-01eiro - value   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                -1.533996                                          2.723741   \n",
       "1                -1.486609                                          2.350880   \n",
       "2                -1.439709                                          2.123016   \n",
       "3                -1.393318                                          2.021477   \n",
       "4                -1.347462                                          1.887113   \n",
       "..                     ...                                               ...   \n",
       "187               1.438978                                         -2.010387   \n",
       "188               1.443990                                         -1.870713   \n",
       "189               1.457014                                         -1.806230   \n",
       "190               1.470138                                         -1.727496   \n",
       "191               1.485431                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Rio De Janeiro - Produção de Cimento (t)  Rio de Janeiro - IDH  \\\n",
       "0                                   -1.060779             -1.723389   \n",
       "1                                   -1.079132             -1.706702   \n",
       "2                                   -1.071658             -1.690015   \n",
       "3                                   -1.072349             -1.673328   \n",
       "4                                   -1.073491             -1.656642   \n",
       "..                                        ...                   ...   \n",
       "187                                 -0.476880              0.839598   \n",
       "188                                 -0.460898              0.793634   \n",
       "189                                 -0.421271              0.747671   \n",
       "190                                 -0.402090              0.701707   \n",
       "191                                 -0.385375              0.655743   \n",
       "\n",
       "     Rio de Janeiro - PIB - Estadual  Rio de Janeiro - PIB - Construção Civil  \\\n",
       "0                          -1.790542                                 0.136347   \n",
       "1                          -1.768299                                 0.149077   \n",
       "2                          -1.746055                                 0.161806   \n",
       "3                          -1.723811                                 0.174535   \n",
       "4                          -1.701567                                 0.187264   \n",
       "..                               ...                                      ...   \n",
       "187                         1.110414                                -1.635096   \n",
       "188                         1.098172                                -1.625552   \n",
       "189                         1.085930                                -1.616009   \n",
       "190                         1.073688                                -1.606465   \n",
       "191                         1.061447                                -1.596921   \n",
       "\n",
       "     Rio de Janeiro - PIB - Per Capita  \\\n",
       "0                             0.121226   \n",
       "1                             0.152115   \n",
       "2                             0.183005   \n",
       "3                             0.213895   \n",
       "4                             0.244784   \n",
       "..                                 ...   \n",
       "187                          -1.325228   \n",
       "188                          -1.326867   \n",
       "189                          -1.328507   \n",
       "190                          -1.330147   \n",
       "191                          -1.331787   \n",
       "\n",
       "     Rio de Janeiro - PIB Preços de Mercado  Rio de Janeiro - Desemprego  \n",
       "0                                 -1.445055                    -0.790925  \n",
       "1                                 -1.365321                    -0.794037  \n",
       "2                                 -1.285587                    -0.797148  \n",
       "3                                 -1.205853                    -0.800259  \n",
       "4                                 -1.126118                    -0.803370  \n",
       "..                                      ...                          ...  \n",
       "187                               -1.036232                     1.324172  \n",
       "188                               -1.053116                     1.322796  \n",
       "189                               -1.070000                     1.321421  \n",
       "190                               -1.086883                     1.320046  \n",
       "191                               -1.103767                     1.318671  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      256.494\n",
       "1      214.974\n",
       "2      273.646\n",
       "3      238.045\n",
       "4      254.860\n",
       "        ...   \n",
       "235        NaN\n",
       "236        NaN\n",
       "237        NaN\n",
       "238        NaN\n",
       "239        NaN\n",
       "Name: Rio De Janeiro - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rio de-01eiro - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rio De Janeiro - Produção de Cimento (t)</th>\n",
       "      <th>Rio de Janeiro - IDH</th>\n",
       "      <th>Rio de Janeiro - PIB - Estadual</th>\n",
       "      <th>Rio de Janeiro - PIB - Construção Civil</th>\n",
       "      <th>Rio de Janeiro - PIB - Per Capita</th>\n",
       "      <th>Rio de Janeiro - PIB Preços de Mercado</th>\n",
       "      <th>Rio de Janeiro - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.533996</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.060779</td>\n",
       "      <td>-1.723389</td>\n",
       "      <td>-1.790542</td>\n",
       "      <td>0.136347</td>\n",
       "      <td>0.121226</td>\n",
       "      <td>-1.445055</td>\n",
       "      <td>-0.790925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.486609</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.079132</td>\n",
       "      <td>-1.706702</td>\n",
       "      <td>-1.768299</td>\n",
       "      <td>0.149077</td>\n",
       "      <td>0.152115</td>\n",
       "      <td>-1.365321</td>\n",
       "      <td>-0.794037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.439709</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.071658</td>\n",
       "      <td>-1.690015</td>\n",
       "      <td>-1.746055</td>\n",
       "      <td>0.161806</td>\n",
       "      <td>0.183005</td>\n",
       "      <td>-1.285587</td>\n",
       "      <td>-0.797148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.393318</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.072349</td>\n",
       "      <td>-1.673328</td>\n",
       "      <td>-1.723811</td>\n",
       "      <td>0.174535</td>\n",
       "      <td>0.213895</td>\n",
       "      <td>-1.205853</td>\n",
       "      <td>-0.800259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.347462</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.073491</td>\n",
       "      <td>-1.656642</td>\n",
       "      <td>-1.701567</td>\n",
       "      <td>0.187264</td>\n",
       "      <td>0.244784</td>\n",
       "      <td>-1.126118</td>\n",
       "      <td>-0.803370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.395833</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>-1.418673</td>\n",
       "      <td>1.438456</td>\n",
       "      <td>1.098176</td>\n",
       "      <td>-1.500012</td>\n",
       "      <td>-1.660268</td>\n",
       "      <td>-1.692180</td>\n",
       "      <td>1.473338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.389960</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>-1.470839</td>\n",
       "      <td>1.429097</td>\n",
       "      <td>1.105247</td>\n",
       "      <td>-1.521309</td>\n",
       "      <td>-1.646368</td>\n",
       "      <td>-1.657425</td>\n",
       "      <td>1.467585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.384722</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>-1.532363</td>\n",
       "      <td>1.419738</td>\n",
       "      <td>1.112318</td>\n",
       "      <td>-1.542605</td>\n",
       "      <td>-1.632469</td>\n",
       "      <td>-1.622671</td>\n",
       "      <td>1.461833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.379646</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>-1.608317</td>\n",
       "      <td>1.410379</td>\n",
       "      <td>1.119389</td>\n",
       "      <td>-1.563902</td>\n",
       "      <td>-1.618570</td>\n",
       "      <td>-1.587917</td>\n",
       "      <td>1.456081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.382791</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>-1.594522</td>\n",
       "      <td>1.401021</td>\n",
       "      <td>1.126460</td>\n",
       "      <td>-1.585199</td>\n",
       "      <td>-1.604671</td>\n",
       "      <td>-1.553162</td>\n",
       "      <td>1.450328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rio de-01eiro - value   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                -1.533996                                          2.723741   \n",
       "1                -1.486609                                          2.350880   \n",
       "2                -1.439709                                          2.123016   \n",
       "3                -1.393318                                          2.021477   \n",
       "4                -1.347462                                          1.887113   \n",
       "..                     ...                                               ...   \n",
       "157               1.395833                                         -0.214006   \n",
       "158               1.389960                                         -0.434717   \n",
       "159               1.384722                                         -0.524091   \n",
       "160               1.379646                                         -0.614500   \n",
       "161               1.382791                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     Rio De Janeiro - Produção de Cimento (t)  Rio de Janeiro - IDH  \\\n",
       "0                                   -1.060779             -1.723389   \n",
       "1                                   -1.079132             -1.706702   \n",
       "2                                   -1.071658             -1.690015   \n",
       "3                                   -1.072349             -1.673328   \n",
       "4                                   -1.073491             -1.656642   \n",
       "..                                        ...                   ...   \n",
       "157                                 -1.418673              1.438456   \n",
       "158                                 -1.470839              1.429097   \n",
       "159                                 -1.532363              1.419738   \n",
       "160                                 -1.608317              1.410379   \n",
       "161                                 -1.594522              1.401021   \n",
       "\n",
       "     Rio de Janeiro - PIB - Estadual  Rio de Janeiro - PIB - Construção Civil  \\\n",
       "0                          -1.790542                                 0.136347   \n",
       "1                          -1.768299                                 0.149077   \n",
       "2                          -1.746055                                 0.161806   \n",
       "3                          -1.723811                                 0.174535   \n",
       "4                          -1.701567                                 0.187264   \n",
       "..                               ...                                      ...   \n",
       "157                         1.098176                                -1.500012   \n",
       "158                         1.105247                                -1.521309   \n",
       "159                         1.112318                                -1.542605   \n",
       "160                         1.119389                                -1.563902   \n",
       "161                         1.126460                                -1.585199   \n",
       "\n",
       "     Rio de Janeiro - PIB - Per Capita  \\\n",
       "0                             0.121226   \n",
       "1                             0.152115   \n",
       "2                             0.183005   \n",
       "3                             0.213895   \n",
       "4                             0.244784   \n",
       "..                                 ...   \n",
       "157                          -1.660268   \n",
       "158                          -1.646368   \n",
       "159                          -1.632469   \n",
       "160                          -1.618570   \n",
       "161                          -1.604671   \n",
       "\n",
       "     Rio de Janeiro - PIB Preços de Mercado  Rio de Janeiro - Desemprego  \n",
       "0                                 -1.445055                    -0.790925  \n",
       "1                                 -1.365321                    -0.794037  \n",
       "2                                 -1.285587                    -0.797148  \n",
       "3                                 -1.205853                    -0.800259  \n",
       "4                                 -1.126118                    -0.803370  \n",
       "..                                      ...                          ...  \n",
       "157                               -1.692180                     1.473338  \n",
       "158                               -1.657425                     1.467585  \n",
       "159                               -1.622671                     1.461833  \n",
       "160                               -1.587917                     1.456081  \n",
       "161                               -1.553162                     1.450328  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      256.494\n",
       "1      214.974\n",
       "2      273.646\n",
       "3      238.045\n",
       "4      254.860\n",
       "        ...   \n",
       "157    175.917\n",
       "158    208.629\n",
       "159    181.933\n",
       "160    187.947\n",
       "161    181.556\n",
       "Name: Rio De Janeiro - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rio de-01eiro - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rio De Janeiro - Produção de Cimento (t)</th>\n",
       "      <th>Rio de Janeiro - IDH</th>\n",
       "      <th>Rio de Janeiro - PIB - Estadual</th>\n",
       "      <th>Rio de Janeiro - PIB - Construção Civil</th>\n",
       "      <th>Rio de Janeiro - PIB - Per Capita</th>\n",
       "      <th>Rio de Janeiro - PIB Preços de Mercado</th>\n",
       "      <th>Rio de Janeiro - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.385142</td>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>-1.590732</td>\n",
       "      <td>1.391662</td>\n",
       "      <td>1.133531</td>\n",
       "      <td>-1.606496</td>\n",
       "      <td>-1.590771</td>\n",
       "      <td>-1.518408</td>\n",
       "      <td>1.444576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.390794</td>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>-1.573361</td>\n",
       "      <td>1.382303</td>\n",
       "      <td>1.140602</td>\n",
       "      <td>-1.627793</td>\n",
       "      <td>-1.576872</td>\n",
       "      <td>-1.483654</td>\n",
       "      <td>1.438823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.397927</td>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>-1.562551</td>\n",
       "      <td>1.372945</td>\n",
       "      <td>1.147673</td>\n",
       "      <td>-1.649090</td>\n",
       "      <td>-1.562973</td>\n",
       "      <td>-1.448899</td>\n",
       "      <td>1.433071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.406003</td>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>-1.541145</td>\n",
       "      <td>1.363586</td>\n",
       "      <td>1.154744</td>\n",
       "      <td>-1.670387</td>\n",
       "      <td>-1.549074</td>\n",
       "      <td>-1.414145</td>\n",
       "      <td>1.427318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.411586</td>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>-1.535254</td>\n",
       "      <td>1.354227</td>\n",
       "      <td>1.161815</td>\n",
       "      <td>-1.691684</td>\n",
       "      <td>-1.535175</td>\n",
       "      <td>-1.379390</td>\n",
       "      <td>1.421566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.415246</td>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>-1.519728</td>\n",
       "      <td>1.344868</td>\n",
       "      <td>1.168886</td>\n",
       "      <td>-1.712981</td>\n",
       "      <td>-1.521275</td>\n",
       "      <td>-1.344636</td>\n",
       "      <td>1.415813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.414247</td>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>-1.494936</td>\n",
       "      <td>1.335510</td>\n",
       "      <td>1.175958</td>\n",
       "      <td>-1.734278</td>\n",
       "      <td>-1.507376</td>\n",
       "      <td>-1.309882</td>\n",
       "      <td>1.410061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.414005</td>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>-1.473917</td>\n",
       "      <td>1.320996</td>\n",
       "      <td>1.177637</td>\n",
       "      <td>-1.731580</td>\n",
       "      <td>-1.491240</td>\n",
       "      <td>-1.277229</td>\n",
       "      <td>1.403706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.417239</td>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>-1.434195</td>\n",
       "      <td>1.306482</td>\n",
       "      <td>1.179316</td>\n",
       "      <td>-1.728882</td>\n",
       "      <td>-1.475105</td>\n",
       "      <td>-1.244576</td>\n",
       "      <td>1.397351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.414571</td>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>-1.397799</td>\n",
       "      <td>1.291968</td>\n",
       "      <td>1.180995</td>\n",
       "      <td>-1.726184</td>\n",
       "      <td>-1.458969</td>\n",
       "      <td>-1.211923</td>\n",
       "      <td>1.390995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.409311</td>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>-1.314015</td>\n",
       "      <td>1.277454</td>\n",
       "      <td>1.182674</td>\n",
       "      <td>-1.723486</td>\n",
       "      <td>-1.442834</td>\n",
       "      <td>-1.179270</td>\n",
       "      <td>1.384640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.407501</td>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>-1.211817</td>\n",
       "      <td>1.262940</td>\n",
       "      <td>1.184353</td>\n",
       "      <td>-1.720788</td>\n",
       "      <td>-1.426698</td>\n",
       "      <td>-1.146617</td>\n",
       "      <td>1.378285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.405686</td>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>-1.111326</td>\n",
       "      <td>1.248426</td>\n",
       "      <td>1.186032</td>\n",
       "      <td>-1.718090</td>\n",
       "      <td>-1.410563</td>\n",
       "      <td>-1.113964</td>\n",
       "      <td>1.371930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.411734</td>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>-1.004959</td>\n",
       "      <td>1.233912</td>\n",
       "      <td>1.187711</td>\n",
       "      <td>-1.715392</td>\n",
       "      <td>-1.394427</td>\n",
       "      <td>-1.081311</td>\n",
       "      <td>1.365574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.432151</td>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>-0.966195</td>\n",
       "      <td>1.219399</td>\n",
       "      <td>1.189390</td>\n",
       "      <td>-1.712694</td>\n",
       "      <td>-1.378292</td>\n",
       "      <td>-1.048658</td>\n",
       "      <td>1.359219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.444833</td>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>-0.922184</td>\n",
       "      <td>1.204885</td>\n",
       "      <td>1.191069</td>\n",
       "      <td>-1.709996</td>\n",
       "      <td>-1.362156</td>\n",
       "      <td>-1.016006</td>\n",
       "      <td>1.352864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.449659</td>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>-0.867121</td>\n",
       "      <td>1.190371</td>\n",
       "      <td>1.192748</td>\n",
       "      <td>-1.707298</td>\n",
       "      <td>-1.346020</td>\n",
       "      <td>-0.983353</td>\n",
       "      <td>1.346509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.451322</td>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>-0.842929</td>\n",
       "      <td>1.175857</td>\n",
       "      <td>1.194428</td>\n",
       "      <td>-1.704599</td>\n",
       "      <td>-1.329885</td>\n",
       "      <td>-0.950700</td>\n",
       "      <td>1.340153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.451791</td>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>-0.807578</td>\n",
       "      <td>1.161343</td>\n",
       "      <td>1.196107</td>\n",
       "      <td>-1.701901</td>\n",
       "      <td>-1.313749</td>\n",
       "      <td>-0.918047</td>\n",
       "      <td>1.333798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.458391</td>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>-0.782126</td>\n",
       "      <td>1.115380</td>\n",
       "      <td>1.183865</td>\n",
       "      <td>-1.692358</td>\n",
       "      <td>-1.315389</td>\n",
       "      <td>-0.934931</td>\n",
       "      <td>1.332423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.465710</td>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>-0.720565</td>\n",
       "      <td>1.069416</td>\n",
       "      <td>1.171623</td>\n",
       "      <td>-1.682814</td>\n",
       "      <td>-1.317029</td>\n",
       "      <td>-0.951814</td>\n",
       "      <td>1.331048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.466853</td>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>-0.691000</td>\n",
       "      <td>1.023452</td>\n",
       "      <td>1.159381</td>\n",
       "      <td>-1.673271</td>\n",
       "      <td>-1.318669</td>\n",
       "      <td>-0.968698</td>\n",
       "      <td>1.329673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.463212</td>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>-0.628278</td>\n",
       "      <td>0.977489</td>\n",
       "      <td>1.147139</td>\n",
       "      <td>-1.663727</td>\n",
       "      <td>-1.320308</td>\n",
       "      <td>-0.985582</td>\n",
       "      <td>1.328297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.456378</td>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>-0.522164</td>\n",
       "      <td>0.931525</td>\n",
       "      <td>1.134897</td>\n",
       "      <td>-1.654183</td>\n",
       "      <td>-1.321948</td>\n",
       "      <td>-1.002465</td>\n",
       "      <td>1.326922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.445796</td>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>-0.500228</td>\n",
       "      <td>0.885561</td>\n",
       "      <td>1.122656</td>\n",
       "      <td>-1.644640</td>\n",
       "      <td>-1.323588</td>\n",
       "      <td>-1.019349</td>\n",
       "      <td>1.325547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.438978</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-0.476880</td>\n",
       "      <td>0.839598</td>\n",
       "      <td>1.110414</td>\n",
       "      <td>-1.635096</td>\n",
       "      <td>-1.325228</td>\n",
       "      <td>-1.036232</td>\n",
       "      <td>1.324172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.443990</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>-0.460898</td>\n",
       "      <td>0.793634</td>\n",
       "      <td>1.098172</td>\n",
       "      <td>-1.625552</td>\n",
       "      <td>-1.326867</td>\n",
       "      <td>-1.053116</td>\n",
       "      <td>1.322796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.457014</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>-0.421271</td>\n",
       "      <td>0.747671</td>\n",
       "      <td>1.085930</td>\n",
       "      <td>-1.616009</td>\n",
       "      <td>-1.328507</td>\n",
       "      <td>-1.070000</td>\n",
       "      <td>1.321421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.470138</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-0.402090</td>\n",
       "      <td>0.701707</td>\n",
       "      <td>1.073688</td>\n",
       "      <td>-1.606465</td>\n",
       "      <td>-1.330147</td>\n",
       "      <td>-1.086883</td>\n",
       "      <td>1.320046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.485431</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-0.385375</td>\n",
       "      <td>0.655743</td>\n",
       "      <td>1.061447</td>\n",
       "      <td>-1.596921</td>\n",
       "      <td>-1.331787</td>\n",
       "      <td>-1.103767</td>\n",
       "      <td>1.318671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rio de-01eiro - value   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162               1.385142                                         -0.601510   \n",
       "163               1.390794                                         -0.786068   \n",
       "164               1.397927                                         -0.830387   \n",
       "165               1.406003                                         -0.801089   \n",
       "166               1.411586                                         -0.959917   \n",
       "167               1.415246                                         -1.022309   \n",
       "168               1.414247                                         -1.074401   \n",
       "169               1.414005                                         -1.119597   \n",
       "170               1.417239                                         -1.078648   \n",
       "171               1.414571                                         -1.055426   \n",
       "172               1.409311                                         -1.101053   \n",
       "173               1.407501                                         -1.211370   \n",
       "174               1.405686                                         -1.157198   \n",
       "175               1.411734                                         -1.223444   \n",
       "176               1.432151                                         -1.311519   \n",
       "177               1.444833                                         -1.362602   \n",
       "178               1.449659                                         -1.380125   \n",
       "179               1.451322                                         -1.219296   \n",
       "180               1.451791                                         -1.300284   \n",
       "181               1.458391                                         -1.336476   \n",
       "182               1.465710                                         -1.415774   \n",
       "183               1.466853                                         -1.526021   \n",
       "184               1.463212                                         -1.681806   \n",
       "185               1.456378                                         -1.735167   \n",
       "186               1.445796                                         -1.962315   \n",
       "187               1.438978                                         -2.010387   \n",
       "188               1.443990                                         -1.870713   \n",
       "189               1.457014                                         -1.806230   \n",
       "190               1.470138                                         -1.727496   \n",
       "191               1.485431                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "162                                0.763466  -1.213929   \n",
       "163                                0.752299  -1.292173   \n",
       "164                                0.741131  -1.324219   \n",
       "165                                0.729964  -1.344446   \n",
       "166                                0.718796  -1.381638   \n",
       "167                                0.707629  -1.411208   \n",
       "168                                0.696461  -1.412953   \n",
       "169                                0.681823  -1.491464   \n",
       "170                                0.667184  -1.573805   \n",
       "171                                0.652545  -1.564950   \n",
       "172                                0.637906  -1.581584   \n",
       "173                                0.623268  -1.565976   \n",
       "174                                0.608629  -1.648556   \n",
       "175                                0.593990  -1.650049   \n",
       "176                                0.579351  -1.653957   \n",
       "177                                0.564713  -1.652572   \n",
       "178                                0.550074  -1.715349   \n",
       "179                                0.535435  -1.750917   \n",
       "180                                0.520796  -1.718448   \n",
       "181                                0.501996  -1.733426   \n",
       "182                                0.483195  -1.729362   \n",
       "183                                0.464395  -1.748544   \n",
       "184                                0.445594  -1.778060   \n",
       "185                                0.426794  -1.773710   \n",
       "186                                0.407993  -1.757007   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Rio De Janeiro - Produção de Cimento (t)  Rio de Janeiro - IDH  \\\n",
       "162                                 -1.590732              1.391662   \n",
       "163                                 -1.573361              1.382303   \n",
       "164                                 -1.562551              1.372945   \n",
       "165                                 -1.541145              1.363586   \n",
       "166                                 -1.535254              1.354227   \n",
       "167                                 -1.519728              1.344868   \n",
       "168                                 -1.494936              1.335510   \n",
       "169                                 -1.473917              1.320996   \n",
       "170                                 -1.434195              1.306482   \n",
       "171                                 -1.397799              1.291968   \n",
       "172                                 -1.314015              1.277454   \n",
       "173                                 -1.211817              1.262940   \n",
       "174                                 -1.111326              1.248426   \n",
       "175                                 -1.004959              1.233912   \n",
       "176                                 -0.966195              1.219399   \n",
       "177                                 -0.922184              1.204885   \n",
       "178                                 -0.867121              1.190371   \n",
       "179                                 -0.842929              1.175857   \n",
       "180                                 -0.807578              1.161343   \n",
       "181                                 -0.782126              1.115380   \n",
       "182                                 -0.720565              1.069416   \n",
       "183                                 -0.691000              1.023452   \n",
       "184                                 -0.628278              0.977489   \n",
       "185                                 -0.522164              0.931525   \n",
       "186                                 -0.500228              0.885561   \n",
       "187                                 -0.476880              0.839598   \n",
       "188                                 -0.460898              0.793634   \n",
       "189                                 -0.421271              0.747671   \n",
       "190                                 -0.402090              0.701707   \n",
       "191                                 -0.385375              0.655743   \n",
       "\n",
       "     Rio de Janeiro - PIB - Estadual  Rio de Janeiro - PIB - Construção Civil  \\\n",
       "162                         1.133531                                -1.606496   \n",
       "163                         1.140602                                -1.627793   \n",
       "164                         1.147673                                -1.649090   \n",
       "165                         1.154744                                -1.670387   \n",
       "166                         1.161815                                -1.691684   \n",
       "167                         1.168886                                -1.712981   \n",
       "168                         1.175958                                -1.734278   \n",
       "169                         1.177637                                -1.731580   \n",
       "170                         1.179316                                -1.728882   \n",
       "171                         1.180995                                -1.726184   \n",
       "172                         1.182674                                -1.723486   \n",
       "173                         1.184353                                -1.720788   \n",
       "174                         1.186032                                -1.718090   \n",
       "175                         1.187711                                -1.715392   \n",
       "176                         1.189390                                -1.712694   \n",
       "177                         1.191069                                -1.709996   \n",
       "178                         1.192748                                -1.707298   \n",
       "179                         1.194428                                -1.704599   \n",
       "180                         1.196107                                -1.701901   \n",
       "181                         1.183865                                -1.692358   \n",
       "182                         1.171623                                -1.682814   \n",
       "183                         1.159381                                -1.673271   \n",
       "184                         1.147139                                -1.663727   \n",
       "185                         1.134897                                -1.654183   \n",
       "186                         1.122656                                -1.644640   \n",
       "187                         1.110414                                -1.635096   \n",
       "188                         1.098172                                -1.625552   \n",
       "189                         1.085930                                -1.616009   \n",
       "190                         1.073688                                -1.606465   \n",
       "191                         1.061447                                -1.596921   \n",
       "\n",
       "     Rio de Janeiro - PIB - Per Capita  \\\n",
       "162                          -1.590771   \n",
       "163                          -1.576872   \n",
       "164                          -1.562973   \n",
       "165                          -1.549074   \n",
       "166                          -1.535175   \n",
       "167                          -1.521275   \n",
       "168                          -1.507376   \n",
       "169                          -1.491240   \n",
       "170                          -1.475105   \n",
       "171                          -1.458969   \n",
       "172                          -1.442834   \n",
       "173                          -1.426698   \n",
       "174                          -1.410563   \n",
       "175                          -1.394427   \n",
       "176                          -1.378292   \n",
       "177                          -1.362156   \n",
       "178                          -1.346020   \n",
       "179                          -1.329885   \n",
       "180                          -1.313749   \n",
       "181                          -1.315389   \n",
       "182                          -1.317029   \n",
       "183                          -1.318669   \n",
       "184                          -1.320308   \n",
       "185                          -1.321948   \n",
       "186                          -1.323588   \n",
       "187                          -1.325228   \n",
       "188                          -1.326867   \n",
       "189                          -1.328507   \n",
       "190                          -1.330147   \n",
       "191                          -1.331787   \n",
       "\n",
       "     Rio de Janeiro - PIB Preços de Mercado  Rio de Janeiro - Desemprego  \n",
       "162                               -1.518408                     1.444576  \n",
       "163                               -1.483654                     1.438823  \n",
       "164                               -1.448899                     1.433071  \n",
       "165                               -1.414145                     1.427318  \n",
       "166                               -1.379390                     1.421566  \n",
       "167                               -1.344636                     1.415813  \n",
       "168                               -1.309882                     1.410061  \n",
       "169                               -1.277229                     1.403706  \n",
       "170                               -1.244576                     1.397351  \n",
       "171                               -1.211923                     1.390995  \n",
       "172                               -1.179270                     1.384640  \n",
       "173                               -1.146617                     1.378285  \n",
       "174                               -1.113964                     1.371930  \n",
       "175                               -1.081311                     1.365574  \n",
       "176                               -1.048658                     1.359219  \n",
       "177                               -1.016006                     1.352864  \n",
       "178                               -0.983353                     1.346509  \n",
       "179                               -0.950700                     1.340153  \n",
       "180                               -0.918047                     1.333798  \n",
       "181                               -0.934931                     1.332423  \n",
       "182                               -0.951814                     1.331048  \n",
       "183                               -0.968698                     1.329673  \n",
       "184                               -0.985582                     1.328297  \n",
       "185                               -1.002465                     1.326922  \n",
       "186                               -1.019349                     1.325547  \n",
       "187                               -1.036232                     1.324172  \n",
       "188                               -1.053116                     1.322796  \n",
       "189                               -1.070000                     1.321421  \n",
       "190                               -1.086883                     1.320046  \n",
       "191                               -1.103767                     1.318671  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    185.846\n",
       "163    200.671\n",
       "164    207.913\n",
       "165    188.107\n",
       "166    193.661\n",
       "167    175.783\n",
       "168    185.078\n",
       "169    146.761\n",
       "170    173.121\n",
       "171    169.841\n",
       "172    142.706\n",
       "173    242.422\n",
       "174    226.205\n",
       "175    229.696\n",
       "176    232.624\n",
       "177    234.262\n",
       "178    217.727\n",
       "179    190.769\n",
       "180    232.609\n",
       "181    195.364\n",
       "182    205.690\n",
       "183    231.354\n",
       "184    236.711\n",
       "185    215.360\n",
       "186    258.015\n",
       "187    244.870\n",
       "188    225.410\n",
       "189    252.849\n",
       "190    226.618\n",
       "191    190.993\n",
       "Name: Rio De Janeiro - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    train, train_val = validation_splitter(train_input, 7)\n",
    "    target,target_val = validation_splitter(train_target, 7)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val, target_val),\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2089684263, 2277822558, 2898425750, 538055457, 1630526047, 4233354627, 2888230847, 575712257, 3177830526, 3113755950, 2622919630, 2909073623, 3910595106, 1298604852, 3459440832, 1566510971, 3908218066, 1953599832, 3390749086, 3392239787, 4408170, 2710683579, 2004160963, 3867701419, 2452263265]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 758.587890625\n",
      "winner_seed: 2089684263\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 650.8851318359375\n",
      "winner_seed: 2277822558\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 768.8203125\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 832.4859619140625\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 747.8405151367188\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 663.3236083984375\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 903.0841674804688\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 972.6277465820312\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 778.548828125\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 944.1800537109375\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 858.2849731445312\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 878.5787353515625\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 817.9857177734375\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 610.3222045898438\n",
      "winner_seed: 1298604852\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 966.1262817382812\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 685.294677734375\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 661.1280517578125\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 828.0824584960938\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 926.3626098632812\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 850.4693603515625\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 748.1659545898438\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 792.9487915039062\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 813.4198608398438\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 695.19921875\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 817.7054443359375\n",
      "\n",
      "\n",
      "final_seed: 1298604852\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 91416.4844 - val_loss: 64497.7617\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78090.2891 - val_loss: 48317.6094\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 50201.7812 - val_loss: 47390.9023\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47453.5742 - val_loss: 40839.3438\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 41996.7891 - val_loss: 33339.1055\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 35509.4922 - val_loss: 28519.9980\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 31243.0938 - val_loss: 44888.1602\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31696.3809 - val_loss: 33353.6367\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 31205.6406 - val_loss: 28548.3613\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 33916.5664 - val_loss: 27065.2227\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28086.3145 - val_loss: 15522.8125\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20863.3125 - val_loss: 15253.8994\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13682.3545 - val_loss: 16719.9082\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14562.2334 - val_loss: 13815.5312\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14199.2402 - val_loss: 8350.7402\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9238.6309 - val_loss: 14981.1699\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14737.5283 - val_loss: 13689.4023\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14107.8232 - val_loss: 10118.0762\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9256.0059 - val_loss: 9814.6484\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7129.0259 - val_loss: 6511.6343\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8533.8086 - val_loss: 8688.9619\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9731.7988 - val_loss: 8788.5000\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10448.4375 - val_loss: 11093.0859\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8578.6084 - val_loss: 5999.8193\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3730.8240 - val_loss: 2968.5315\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2393.7061 - val_loss: 2326.9832\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2461.1914 - val_loss: 3097.0583\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3274.3760 - val_loss: 2151.0479\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2592.2114 - val_loss: 1855.0077\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2068.0198 - val_loss: 1268.5763\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2201.5698 - val_loss: 1700.0398\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1690.8439 - val_loss: 2115.9993\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1825.1836 - val_loss: 1341.1014\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2533.9919 - val_loss: 5385.2817\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3980.0432 - val_loss: 4581.7026\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4524.4751 - val_loss: 5229.5142\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2994.2825 - val_loss: 2634.6084\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2213.1221 - val_loss: 2288.1721\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3006.4006 - val_loss: 3528.5266\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2150.1953 - val_loss: 1974.5479\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2050.3254 - val_loss: 3059.0530\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2704.1467 - val_loss: 2752.4758\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2038.4843 - val_loss: 1565.6829\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1334.2153 - val_loss: 1982.0244\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1888.1129 - val_loss: 1063.2504\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1510.8226 - val_loss: 1615.7803\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1417.2753 - val_loss: 1386.2931\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1675.6641 - val_loss: 1779.1957\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1386.0262 - val_loss: 1035.8478\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1331.3032 - val_loss: 1721.0616\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1437.7771 - val_loss: 1949.0570\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1462.8594 - val_loss: 1358.5359\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1251.4110 - val_loss: 2110.9312\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1533.0028 - val_loss: 1783.8577\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1546.7904 - val_loss: 1236.7599\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1133.9727 - val_loss: 1569.7406\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1331.0907 - val_loss: 1130.6958\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1778.6328 - val_loss: 1114.8615\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1721.5647 - val_loss: 1372.6338\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1598.2970 - val_loss: 1744.2443\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1238.4296 - val_loss: 1106.8204\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1485.8430 - val_loss: 1276.6437\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1394.2234 - val_loss: 1407.3422\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1817.6566 - val_loss: 1667.5712\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1590.3617 - val_loss: 1881.9535\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2308.2610 - val_loss: 1542.8667\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1810.2217 - val_loss: 1664.9862\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1727.2313 - val_loss: 1623.0055\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1567.3907 - val_loss: 1349.0623\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1719.0782 - val_loss: 2380.2087\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1895.9525 - val_loss: 1649.3975\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1417.4957 - val_loss: 1241.7234\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1454.1877 - val_loss: 1978.1904\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1529.3202 - val_loss: 1203.4139\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1406.8265 - val_loss: 1693.3281\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1346.6880 - val_loss: 1169.0532\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1282.0353 - val_loss: 1317.6390\n",
      "Epoch 78/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 1409.4347 - val_loss: 1451.2772\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1266.4531 - val_loss: 1616.2607\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1763.4379 - val_loss: 2736.4568\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1437.7145 - val_loss: 1695.2435\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1473.1610 - val_loss: 1489.8159\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1346.0850 - val_loss: 2306.7319\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1490.2224 - val_loss: 1794.2968\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1373.5532 - val_loss: 2061.2380\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2162.1877 - val_loss: 2220.8145\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2466.0452 - val_loss: 2712.4062\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1560.3583 - val_loss: 1850.5387\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1344.5366 - val_loss: 1545.2738\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1505.1014 - val_loss: 1870.0314\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1887.6520 - val_loss: 2088.3630\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1694.9019 - val_loss: 2385.0901\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1583.6968 - val_loss: 2507.8606\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1738.5415 - val_loss: 1898.0531\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1320.6105 - val_loss: 2190.1482\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1363.4302 - val_loss: 1950.2850\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1398.8662 - val_loss: 3111.0132\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1812.4492 - val_loss: 2665.5232\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1928.5798 - val_loss: 1155.0708\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1391.1859 - val_loss: 2720.9822\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1822.6553 - val_loss: 2012.7786\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1581.3019 - val_loss: 2483.4246\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1473.0166 - val_loss: 1539.5902\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1227.2725 - val_loss: 2480.5945\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1780.6140 - val_loss: 1618.8662\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1499.0562 - val_loss: 2189.3796\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2337.4409 - val_loss: 1228.3163\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1565.6581 - val_loss: 1333.6016\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1550.9075 - val_loss: 1363.6497\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1768.6727 - val_loss: 1938.0900\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1686.8267 - val_loss: 2281.3821\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1854.8375 - val_loss: 2405.5579\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1909.1315 - val_loss: 2780.1206\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1752.4148 - val_loss: 2028.0413\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2498.3071 - val_loss: 2934.3438\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3104.0752 - val_loss: 3174.3010\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2079.5442 - val_loss: 1761.0586\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1362.1599 - val_loss: 2090.5791\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1428.1295 - val_loss: 2362.0029\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1389.2469 - val_loss: 2432.8123\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2696.2969 - val_loss: 3811.4038\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3325.4446 - val_loss: 3560.4512\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2488.2593 - val_loss: 2157.7100\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1910.2601 - val_loss: 2102.0159\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2374.0010 - val_loss: 2297.0696\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2480.0432 - val_loss: 2081.6492\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1633.0887 - val_loss: 2313.0085\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1739.6600 - val_loss: 2391.4824\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2093.5742 - val_loss: 2935.7351\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1869.0239 - val_loss: 1742.5516\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1613.7710 - val_loss: 3065.8796\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3962.8979 - val_loss: 4710.3760\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4166.0791 - val_loss: 3016.1917\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2676.9700 - val_loss: 3117.4429\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2673.0400 - val_loss: 2405.4932\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1942.5529 - val_loss: 2795.9241\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1489.2601 - val_loss: 2332.3752\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1477.6904 - val_loss: 1719.2626\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1713.6460 - val_loss: 2027.2452\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1605.1206 - val_loss: 1697.6632\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3649.5906 - val_loss: 4989.9067\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2971.3955 - val_loss: 2108.5830\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2111.2183 - val_loss: 2721.5623\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2134.5266 - val_loss: 1829.3052\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1904.4143 - val_loss: 1846.8628\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2483.5759 - val_loss: 1827.1667\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1774.6886 - val_loss: 1450.8350\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1689.8103 - val_loss: 1568.9259\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1657.5737 - val_loss: 1734.8573\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2024.4028 - val_loss: 1848.3816\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1840.3932 - val_loss: 1483.4695\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2311.8967 - val_loss: 2389.9238\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2195.1646 - val_loss: 1552.4912\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1212.8507 - val_loss: 1037.0120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1411.2170 - val_loss: 1888.3042\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1917.7476 - val_loss: 1779.5872\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1426.9624 - val_loss: 1273.1796\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1183.0291 - val_loss: 1218.4137\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1263.0789 - val_loss: 1247.0142\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1028.7429 - val_loss: 1997.6240\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1474.6305 - val_loss: 1592.5565\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1006.0785 - val_loss: 1028.8981\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1244.1014 - val_loss: 1392.0179\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1290.9989 - val_loss: 1787.9781\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1373.2983 - val_loss: 2051.1313\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1251.0760 - val_loss: 1877.7360\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1191.7521 - val_loss: 1720.3663\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1020.3506 - val_loss: 1698.3268\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1136.7401 - val_loss: 1841.0074\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1169.6139 - val_loss: 2198.6716\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1557.6709 - val_loss: 1448.1481\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1282.0566 - val_loss: 1840.9965\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1217.7854 - val_loss: 1913.2410\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1235.4694 - val_loss: 2464.6431\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1528.0626 - val_loss: 2145.5681\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1315.8009 - val_loss: 2071.1265\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1671.7787 - val_loss: 2822.8054\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1838.7743 - val_loss: 1962.9274\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1291.2417 - val_loss: 1783.8138\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1500.7993 - val_loss: 1935.0958\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1233.9366 - val_loss: 2124.7964\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1403.4370 - val_loss: 2033.4725\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1827.8015 - val_loss: 1981.9896\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2056.3945 - val_loss: 1549.7283\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1686.6018 - val_loss: 2225.6560\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1647.1494 - val_loss: 1926.2405\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1517.6346 - val_loss: 1222.3280\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1306.5292 - val_loss: 1554.6705\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1515.3855 - val_loss: 1679.3342\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1415.1301 - val_loss: 1265.0479\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1281.5431 - val_loss: 1500.9895\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1562.5601 - val_loss: 1722.8972\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1478.8690 - val_loss: 1729.1631\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1797.5682 - val_loss: 1828.9146\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1463.0815 - val_loss: 1562.6711\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1735.9121 - val_loss: 1940.3060\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2563.2627 - val_loss: 1885.6154\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2357.3481 - val_loss: 2577.2837\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2020.4524 - val_loss: 1843.2227\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2437.5229 - val_loss: 3487.8801\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3022.6565 - val_loss: 2961.8584\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1765.9879 - val_loss: 2295.1460\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1649.5375 - val_loss: 2954.2986\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2331.7112 - val_loss: 2483.3735\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2072.4551 - val_loss: 2630.7263\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1498.9211 - val_loss: 2375.4863\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1535.9868 - val_loss: 2851.6841\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1504.6497 - val_loss: 2545.0298\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2126.2742 - val_loss: 3757.8733\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2170.9265 - val_loss: 2516.5901\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2228.7964 - val_loss: 2274.0398\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2065.5732 - val_loss: 3504.5833\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2202.5757 - val_loss: 3466.8237\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2080.7871 - val_loss: 3009.7659\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1622.8048 - val_loss: 3952.0125\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1833.5522 - val_loss: 2881.6191\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1366.1981 - val_loss: 2294.2871\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1287.4633 - val_loss: 2743.5034\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1271.8226 - val_loss: 3732.9053\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2106.1064 - val_loss: 2847.3669\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1233.8820 - val_loss: 2646.7441\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1510.2845 - val_loss: 2072.4539\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1343.6052 - val_loss: 2346.4724\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1382.4946 - val_loss: 2469.7437\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1375.7369 - val_loss: 2022.6179\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1457.8667 - val_loss: 2150.2844\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1343.2681 - val_loss: 3014.0833\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1419.9386 - val_loss: 2092.4009\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1288.7742 - val_loss: 2044.3553\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1842.5857 - val_loss: 2309.4807\n",
      "Epoch 231/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 1702.5714 - val_loss: 1904.5372\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1581.0991 - val_loss: 2111.5320\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1209.1536 - val_loss: 1902.5336\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1760.6720 - val_loss: 2117.7710\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2112.6521 - val_loss: 2068.3591\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1440.7548 - val_loss: 2617.3240\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1459.1549 - val_loss: 2693.7969\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1612.7552 - val_loss: 2300.8562\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1623.3331 - val_loss: 3437.9707\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1879.9022 - val_loss: 2486.0447\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1871.2229 - val_loss: 3359.4329\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2064.7173 - val_loss: 2346.1270\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1658.0815 - val_loss: 2566.6912\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1794.7502 - val_loss: 2769.1030\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1676.3225 - val_loss: 2762.8696\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1798.7059 - val_loss: 1862.7510\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1659.8171 - val_loss: 2346.7820\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1732.9126 - val_loss: 1893.5947\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1367.0273 - val_loss: 2438.4338\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1416.1079 - val_loss: 2333.2329\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1405.5249 - val_loss: 1523.3125\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1351.9626 - val_loss: 992.6555\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1256.3966 - val_loss: 1508.5133\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1440.7653 - val_loss: 1994.2384\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1730.7161 - val_loss: 1735.6101\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1910.4252 - val_loss: 3025.0720\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1965.2223 - val_loss: 2883.3579\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1835.2786 - val_loss: 2970.5857\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2088.7429 - val_loss: 2231.0898\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1641.5831 - val_loss: 2673.4216\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1520.4038 - val_loss: 1906.0824\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1252.0775 - val_loss: 2048.4568\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1549.0385 - val_loss: 2136.5208\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1730.8121 - val_loss: 2021.3837\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1316.9507 - val_loss: 2370.4058\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1713.5676 - val_loss: 2233.5195\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1787.4287 - val_loss: 2302.7676\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1328.2478 - val_loss: 1709.6758\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1333.8707 - val_loss: 1019.0874\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1487.5192 - val_loss: 1616.6237\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1587.3929 - val_loss: 1924.3640\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1732.0876 - val_loss: 2755.0764\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1949.0320 - val_loss: 6878.6304\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3159.3372 - val_loss: 2468.4548\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1953.4229 - val_loss: 1660.1359\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1639.4598 - val_loss: 1681.0433\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1749.0190 - val_loss: 1658.2856\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1456.4886 - val_loss: 1419.9504\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1462.1935 - val_loss: 1235.6359\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1121.7473 - val_loss: 1158.9460\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1268.4026 - val_loss: 1669.2609\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1622.2301 - val_loss: 1756.7396\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1241.5320 - val_loss: 1082.3982\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1323.9095 - val_loss: 1497.3993\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 978.9665 - val_loss: 2011.2174\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1206.2760 - val_loss: 2681.4951\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1696.8383 - val_loss: 2786.5005\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1315.8341 - val_loss: 2029.8584\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1613.2123 - val_loss: 2545.2510\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1902.9492 - val_loss: 3175.3530\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2050.1089 - val_loss: 4093.4539\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1985.5647 - val_loss: 3562.4011\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1728.8870 - val_loss: 1846.8632\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1550.0409 - val_loss: 1028.7738\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1511.4117 - val_loss: 1626.7004\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1407.7264 - val_loss: 1957.1918\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1704.9587 - val_loss: 1536.1848\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1896.2946 - val_loss: 2327.5144\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1427.6329 - val_loss: 1389.6056\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1515.0413 - val_loss: 1896.8363\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1498.3992 - val_loss: 1828.0472\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1429.5013 - val_loss: 1945.1124\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1570.8975 - val_loss: 3401.6162\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1769.5535 - val_loss: 2214.1831\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1317.6221 - val_loss: 2079.9485\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2022.9725 - val_loss: 3116.0488\n",
      "Epoch 307/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 2173.2073 - val_loss: 1774.6364\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1607.0024 - val_loss: 1514.7787\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1382.7909 - val_loss: 1579.8716\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1307.3246 - val_loss: 1369.8098\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1148.4207 - val_loss: 1560.7870\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1294.4552 - val_loss: 1942.2169\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1912.8757 - val_loss: 1486.0906\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1206.0388 - val_loss: 1396.1447\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1193.2767 - val_loss: 1536.5057\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1430.7905 - val_loss: 1724.6388\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1279.7393 - val_loss: 2352.5671\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1181.8314 - val_loss: 1649.2877\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1075.7919 - val_loss: 1528.3668\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1352.0388 - val_loss: 1789.6871\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 994.3116 - val_loss: 1185.9872\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1079.7542 - val_loss: 1061.6094\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1074.4362 - val_loss: 1339.0203\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1029.4111 - val_loss: 1146.9857\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1111.1171 - val_loss: 1300.5614\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1266.2904 - val_loss: 1562.0392\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1498.5360 - val_loss: 1170.1492\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1223.4463 - val_loss: 1035.8469\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1210.5632 - val_loss: 1259.1167\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1582.8119 - val_loss: 959.5933\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1409.1069 - val_loss: 1213.4664\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1508.2595 - val_loss: 1608.1440\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1215.5122 - val_loss: 1071.8999\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1001.5861 - val_loss: 979.9127\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1035.0295 - val_loss: 860.3660\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1326.7535 - val_loss: 1887.3660\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1215.9559 - val_loss: 2432.7312\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1169.6094 - val_loss: 1649.9540\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1148.9296 - val_loss: 1152.9800\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1179.4298 - val_loss: 1502.7135\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1434.0758 - val_loss: 1358.8079\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1194.4010 - val_loss: 1180.4235\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1116.9637 - val_loss: 1067.8851\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 967.6810 - val_loss: 1100.8451\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1078.8004 - val_loss: 1589.4845\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1239.0436 - val_loss: 1564.8424\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1045.4452 - val_loss: 1372.2322\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1065.4489 - val_loss: 1252.2224\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1210.0554 - val_loss: 1520.2976\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1363.9087 - val_loss: 1857.4059\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1119.8647 - val_loss: 2233.2280\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1112.3967 - val_loss: 2321.0176\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1481.9402 - val_loss: 2512.4937\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1438.5813 - val_loss: 2359.6089\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1726.3433 - val_loss: 2606.8760\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1185.7106 - val_loss: 1976.3860\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1295.3826 - val_loss: 1971.2687\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1105.8844 - val_loss: 2441.8462\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1508.9883 - val_loss: 1691.8699\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1489.2144 - val_loss: 2947.5149\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2417.9099 - val_loss: 1675.0920\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1492.8718 - val_loss: 1583.1271\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1255.8591 - val_loss: 1289.6458\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1010.7726 - val_loss: 1100.8424\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 960.8773 - val_loss: 1052.6492\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1120.9958 - val_loss: 1276.2577\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1259.1515 - val_loss: 2329.9019\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1801.4580 - val_loss: 1602.0654\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1263.1759 - val_loss: 1538.4001\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1235.4823 - val_loss: 1478.0972\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1491.1083 - val_loss: 1983.6038\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1652.7762 - val_loss: 1745.9259\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2142.6421 - val_loss: 2058.6675\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1152.4910 - val_loss: 1525.9335\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1165.8546 - val_loss: 1370.1254\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1090.2805 - val_loss: 903.3433\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1214.4240 - val_loss: 2056.7615\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1748.6309 - val_loss: 2636.3467\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2208.1167 - val_loss: 2036.9476\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1902.3044 - val_loss: 1564.1736\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1403.2233 - val_loss: 1493.6107\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1623.3340 - val_loss: 1761.8212\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1098.0234 - val_loss: 1536.7870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1024.5380 - val_loss: 2151.2754\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1235.9581 - val_loss: 1590.6505\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1193.3840 - val_loss: 2130.5332\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1692.5427 - val_loss: 2606.5806\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1433.5168 - val_loss: 1658.4962\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1363.6604 - val_loss: 1407.2690\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 913.7115 - val_loss: 1385.2472\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1443.5195 - val_loss: 1333.5762\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1713.3868 - val_loss: 1898.2426\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1831.4097 - val_loss: 1742.0586\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1041.1698 - val_loss: 1512.3273\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 984.4407 - val_loss: 2149.6426\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1308.0344 - val_loss: 2045.2435\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1513.7382 - val_loss: 2258.2883\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1537.4017 - val_loss: 2065.0120\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1724.5159 - val_loss: 1777.8347\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1625.8375 - val_loss: 1755.3354\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1431.9749 - val_loss: 2021.2100\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1404.9053 - val_loss: 1944.7214\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1585.1409 - val_loss: 1538.0941\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1963.4465 - val_loss: 2506.4424\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1547.7296 - val_loss: 1757.6158\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1633.0089 - val_loss: 1670.5129\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1270.7188 - val_loss: 1765.4596\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1334.9750 - val_loss: 1650.2571\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1494.1332 - val_loss: 1729.0569\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1610.7295 - val_loss: 1501.8026\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1572.4425 - val_loss: 1750.9500\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1192.1506 - val_loss: 1977.5356\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1263.6522 - val_loss: 1455.6246\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1159.6295 - val_loss: 878.0735\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1131.0684 - val_loss: 1398.0704\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1134.4987 - val_loss: 1356.1475\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1641.1807 - val_loss: 1483.8060\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1601.7991 - val_loss: 1414.3402\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1221.7255 - val_loss: 1340.0540\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1657.0938 - val_loss: 2297.8591\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1563.4288 - val_loss: 2130.0608\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1442.5425 - val_loss: 2057.8342\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1292.8978 - val_loss: 1822.2054\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1406.1594 - val_loss: 1691.6675\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1312.5865 - val_loss: 1904.8815\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1514.2292 - val_loss: 1705.7649\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1110.5673 - val_loss: 1313.8785\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1177.6887 - val_loss: 1596.6155\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1398.3513 - val_loss: 2724.6809\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1803.3939 - val_loss: 2075.4556\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1393.9615 - val_loss: 1853.6094\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1587.6243 - val_loss: 2044.3984\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1494.6981 - val_loss: 2176.2424\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1700.7111 - val_loss: 1599.1653\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1476.7435 - val_loss: 1579.1254\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1422.4012 - val_loss: 1687.6875\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1312.9258 - val_loss: 1548.7427\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1183.3944 - val_loss: 2118.8245\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2015.8197 - val_loss: 1376.3169\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2280.5020 - val_loss: 2053.0852\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1517.6763 - val_loss: 1885.6984\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1236.5879 - val_loss: 1300.5392\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1447.3884 - val_loss: 1503.6218\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1144.1758 - val_loss: 1434.5582\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1012.8480 - val_loss: 1255.9354\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1112.0803 - val_loss: 1491.6915\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1024.0760 - val_loss: 1480.2529\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1092.1616 - val_loss: 1342.3777\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1054.9597 - val_loss: 2049.2063\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1449.2450 - val_loss: 1617.0820\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1168.2886 - val_loss: 1325.8212\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1112.5741 - val_loss: 2416.7598\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1470.0222 - val_loss: 1638.6251\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1388.9293 - val_loss: 1278.1915\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1193.6729 - val_loss: 1695.9000\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1089.2445 - val_loss: 2032.9474\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1388.2635 - val_loss: 1936.2400\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1365.8807 - val_loss: 1409.6508\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1352.8131 - val_loss: 1665.9657\n",
      "Epoch 460/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 1025.7228 - val_loss: 1597.0529\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1230.2249 - val_loss: 2699.9919\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1358.6178 - val_loss: 1761.6648\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1306.7040 - val_loss: 1415.8226\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1009.9946 - val_loss: 1508.6992\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1083.5104 - val_loss: 1376.7379\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1200.0543 - val_loss: 1364.3251\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1044.7705 - val_loss: 1241.8949\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 935.5621 - val_loss: 1365.2721\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1018.7519 - val_loss: 1216.6113\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 841.9362 - val_loss: 1150.0494\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1167.8429 - val_loss: 1286.3693\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 962.7185 - val_loss: 1445.5078\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 884.4962 - val_loss: 1712.1792\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1183.7340 - val_loss: 1462.1610\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1403.2921 - val_loss: 2246.0532\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1703.4733 - val_loss: 1918.0902\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1522.9335 - val_loss: 2516.7603\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1796.1626 - val_loss: 1978.8699\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1387.1527 - val_loss: 1742.4852\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1452.2542 - val_loss: 2401.6553\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1888.6733 - val_loss: 2374.0249\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1781.4921 - val_loss: 1594.0752\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1410.6962 - val_loss: 2035.5992\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1445.3870 - val_loss: 1439.8000\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1849.6141 - val_loss: 1683.8857\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1605.9978 - val_loss: 2255.2412\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1578.2502 - val_loss: 2079.4778\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1990.0679 - val_loss: 2245.4397\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1631.1420 - val_loss: 1882.0370\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1297.0763 - val_loss: 1575.3665\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1323.6044 - val_loss: 1870.7036\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1305.9559 - val_loss: 1987.3354\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1432.4059 - val_loss: 1735.2556\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1353.3856 - val_loss: 1430.1411\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1228.4901 - val_loss: 1540.9867\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1203.9700 - val_loss: 1502.1019\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1282.2120 - val_loss: 1500.1212\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1244.4060 - val_loss: 1502.7491\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1330.8441 - val_loss: 1418.9543\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 976.4929 - val_loss: 1480.6328\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 946.7968 - val_loss: 1593.6056\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1027.1151 - val_loss: 1327.0017\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 968.6631 - val_loss: 2308.2554\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1615.3563 - val_loss: 1588.5217\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1327.9670 - val_loss: 1602.0413\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1506.3436 - val_loss: 1847.3894\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1177.8033 - val_loss: 1859.5511\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1556.0876 - val_loss: 1861.3771\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1243.9111 - val_loss: 1471.3389\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1322.3418 - val_loss: 1617.4806\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1372.1494 - val_loss: 1778.5286\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1646.6681 - val_loss: 2539.7737\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2096.6873 - val_loss: 2769.0522\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1906.2794 - val_loss: 2457.9038\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1803.6278 - val_loss: 2362.6499\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1628.7279 - val_loss: 1870.8330\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1369.0037 - val_loss: 1743.7931\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1620.8738 - val_loss: 2360.0608\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2003.0836 - val_loss: 2442.0479\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1437.9723 - val_loss: 2106.3411\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1538.6808 - val_loss: 1742.2646\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1619.4087 - val_loss: 1765.3528\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1508.4314 - val_loss: 2079.0344\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1457.8073 - val_loss: 1615.4845\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1172.1161 - val_loss: 1335.4175\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1120.6482 - val_loss: 1120.4861\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1568.9110 - val_loss: 1832.7999\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1555.4388 - val_loss: 1523.4475\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1349.6699 - val_loss: 1516.4159\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1602.6990 - val_loss: 1764.6224\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1815.5583 - val_loss: 2335.9272\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1836.8440 - val_loss: 2495.8306\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1469.8994 - val_loss: 2265.0413\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1534.2023 - val_loss: 1892.4540\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1174.4004 - val_loss: 1994.7102\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1173.6514 - val_loss: 1554.8481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1186.4794 - val_loss: 1502.8740\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1072.5397 - val_loss: 1597.6189\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1364.4611 - val_loss: 1653.3456\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1149.9600 - val_loss: 1588.5629\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1137.4229 - val_loss: 1473.1620\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1032.9535 - val_loss: 1471.6536\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1108.3394 - val_loss: 1524.3702\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1079.0024 - val_loss: 1646.2191\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1180.9171 - val_loss: 1375.4500\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1059.1293 - val_loss: 1652.7469\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1095.0179 - val_loss: 1379.6683\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1417.2712 - val_loss: 1459.8645\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1210.1729 - val_loss: 1705.8660\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 957.9014 - val_loss: 1438.0891\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1244.4487 - val_loss: 1988.5282\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1305.6356 - val_loss: 1126.6189\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1161.8846 - val_loss: 1771.0609\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1643.3978 - val_loss: 1783.0090\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1365.3557 - val_loss: 1659.1815\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1498.0408 - val_loss: 1342.9851\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1133.3362 - val_loss: 1673.4705\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1324.7157 - val_loss: 1635.7383\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1307.6981 - val_loss: 1489.1228\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1117.7858 - val_loss: 1428.8655\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1059.3473 - val_loss: 1124.8553\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 876.8909 - val_loss: 1729.5652\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1215.7437 - val_loss: 1412.2725\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 961.5174 - val_loss: 1019.7051\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1057.7603 - val_loss: 1118.2583\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1180.6908 - val_loss: 1073.3911\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1048.8259 - val_loss: 1246.5571\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1346.0817 - val_loss: 1365.1206\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1523.5157 - val_loss: 1003.7048\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1164.3768 - val_loss: 1088.6437\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1158.8866 - val_loss: 1045.0925\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1104.2211 - val_loss: 846.0598\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1080.5941 - val_loss: 610.3222\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1185.1619 - val_loss: 1126.2195\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1089.9227 - val_loss: 909.0324\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1032.3290 - val_loss: 1865.6046\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1474.5709 - val_loss: 1514.3894\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1301.9830 - val_loss: 1383.0312\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1250.0922 - val_loss: 1442.0391\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1070.0624 - val_loss: 1342.6594\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1220.9362 - val_loss: 1378.0615\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1196.7109 - val_loss: 1498.7692\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 981.9633 - val_loss: 1532.2167\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1199.9823 - val_loss: 964.4766\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1033.4762 - val_loss: 1097.2129\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1131.2822 - val_loss: 833.9562\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1172.4766 - val_loss: 890.6556\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 933.9565 - val_loss: 878.9763\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 998.7999 - val_loss: 1459.2708\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 892.6289 - val_loss: 1133.5972\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1467.3053 - val_loss: 1289.2419\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1169.9385 - val_loss: 1202.1614\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1548.3638 - val_loss: 1174.9584\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1396.5020 - val_loss: 1084.5012\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1149.1132 - val_loss: 981.1035\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1094.5404 - val_loss: 1203.5375\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1247.5192 - val_loss: 1761.3889\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1204.7509 - val_loss: 1717.8458\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1273.6177 - val_loss: 1296.1097\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1261.6960 - val_loss: 1831.3531\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1519.5927 - val_loss: 1516.1403\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1472.2793 - val_loss: 1729.5199\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1623.1976 - val_loss: 1638.8767\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1447.7396 - val_loss: 1314.1311\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1467.6157 - val_loss: 1425.4368\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1364.6057 - val_loss: 1486.1957\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1245.6251 - val_loss: 2270.6160\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1499.2524 - val_loss: 986.0685\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1221.0465 - val_loss: 1647.9834\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1147.9434 - val_loss: 995.9293\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1059.4443 - val_loss: 1364.6198\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1142.7971 - val_loss: 1239.5016\n",
      "Epoch 613/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 1524.7507 - val_loss: 1399.7034\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1208.1172 - val_loss: 1341.4779\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1226.8309 - val_loss: 1569.8840\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1241.3260 - val_loss: 1724.8920\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1145.7188 - val_loss: 1543.0479\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1139.5078 - val_loss: 1607.8785\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1215.2181 - val_loss: 1086.4625\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1118.5891 - val_loss: 1168.1334\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1062.4634 - val_loss: 1300.3649\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1145.4519 - val_loss: 1179.7878\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 968.3179 - val_loss: 1309.2679\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 984.2686 - val_loss: 1915.2271\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1596.4155 - val_loss: 2199.3555\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1375.7603 - val_loss: 1819.9921\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1143.7209 - val_loss: 1788.5797\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1258.3376 - val_loss: 2195.3225\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1226.4705 - val_loss: 1823.6603\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1268.7086 - val_loss: 1354.4452\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1010.9282 - val_loss: 1242.4679\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1039.4354 - val_loss: 1833.8607\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1011.8207 - val_loss: 946.2911\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 982.7672 - val_loss: 773.3589\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 930.9204 - val_loss: 700.2754\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 932.7779 - val_loss: 1432.2991\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1220.1943 - val_loss: 2884.3882\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1729.8516 - val_loss: 1502.2960\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1301.8807 - val_loss: 1595.3893\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1272.7075 - val_loss: 1249.0699\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1188.6981 - val_loss: 1278.9248\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1127.7505 - val_loss: 1639.3597\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1173.0278 - val_loss: 1696.6053\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1167.9562 - val_loss: 2003.7438\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1301.2057 - val_loss: 1766.0908\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1827.0315 - val_loss: 1315.5658\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1253.7936 - val_loss: 1414.1687\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1161.8584 - val_loss: 1229.6371\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1340.1174 - val_loss: 1528.8563\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1607.3623 - val_loss: 2044.8634\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1496.1232 - val_loss: 1456.6824\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1174.8022 - val_loss: 1574.0082\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1003.1854 - val_loss: 1277.3740\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1173.6931 - val_loss: 1448.5425\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1077.7545 - val_loss: 1230.1810\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 919.8825 - val_loss: 1429.3276\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 816.3963 - val_loss: 1152.7631\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1191.6089 - val_loss: 1089.5457\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1061.0918 - val_loss: 1071.6251\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1265.6898 - val_loss: 1314.2522\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1278.1021 - val_loss: 2061.0444\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1269.2223 - val_loss: 1640.7660\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1203.7166 - val_loss: 1943.9510\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1155.9362 - val_loss: 1808.0369\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1206.1641 - val_loss: 1747.9139\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1210.4269 - val_loss: 1808.6143\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1339.1304 - val_loss: 1883.6285\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1411.8662 - val_loss: 1420.5510\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1091.3473 - val_loss: 1611.0278\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1051.5010 - val_loss: 1557.1698\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1398.4742 - val_loss: 1645.7577\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1138.3250 - val_loss: 1266.8972\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1287.6569 - val_loss: 1359.0839\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 984.6553 - val_loss: 1445.6282\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1184.1187 - val_loss: 1343.0479\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1020.1782 - val_loss: 1582.1776\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1034.2646 - val_loss: 1860.3441\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1091.1576 - val_loss: 1695.8118\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1026.6307 - val_loss: 1300.4197\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1074.9856 - val_loss: 1878.3376\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1150.6812 - val_loss: 1320.3879\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1057.1733 - val_loss: 1432.3738\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 948.0690 - val_loss: 1347.5739\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 881.3841 - val_loss: 1125.4265\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1122.5718 - val_loss: 1101.6930\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1075.6477 - val_loss: 1239.4945\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 933.3740 - val_loss: 2061.2346\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1166.2999 - val_loss: 1294.6936\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1313.2524 - val_loss: 1368.3073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1479.0515 - val_loss: 1498.6729\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1158.9965 - val_loss: 1489.4341\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1154.4961 - val_loss: 1400.7244\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1271.6090 - val_loss: 1191.3754\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1344.5581 - val_loss: 1412.2273\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1248.3102 - val_loss: 1574.7267\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1168.0756 - val_loss: 1404.4086\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1198.5363 - val_loss: 1765.5387\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1291.1611 - val_loss: 956.4605\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1229.6007 - val_loss: 1524.9423\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1242.7690 - val_loss: 1439.3676\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1264.1317 - val_loss: 1283.3199\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1363.9138 - val_loss: 1531.1077\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1139.6425 - val_loss: 1045.3480\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1165.6411 - val_loss: 1587.2655\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1212.4928 - val_loss: 1357.6523\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1172.4044 - val_loss: 2616.3748\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1295.3662 - val_loss: 1049.2942\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1196.3406 - val_loss: 1154.8704\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1094.7506 - val_loss: 1060.7311\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 870.5170 - val_loss: 1536.0233\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1225.7374 - val_loss: 958.9208\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 938.5566 - val_loss: 956.6403\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1377.0460 - val_loss: 1841.7633\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1073.8187 - val_loss: 1293.7301\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1143.3925 - val_loss: 1287.5043\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1218.0966 - val_loss: 1359.7126\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1125.0792 - val_loss: 1235.5052\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 965.6799 - val_loss: 1235.5930\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 908.3416 - val_loss: 1133.3986\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1082.3560 - val_loss: 1019.9453\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1012.7239 - val_loss: 1028.5298\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1008.8494 - val_loss: 1002.8173\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 973.5378 - val_loss: 1784.7089\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1324.2511 - val_loss: 975.9169\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1131.1931 - val_loss: 1144.7384\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1088.5439 - val_loss: 1416.9614\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1031.8822 - val_loss: 1015.8486\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1176.7058 - val_loss: 1427.1714\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1092.5801 - val_loss: 991.8674\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1043.1820 - val_loss: 1099.5560\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1157.7271 - val_loss: 1228.2421\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1208.7102 - val_loss: 1435.7809\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1115.5394 - val_loss: 1969.4196\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1147.4829 - val_loss: 1971.2009\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1252.4790 - val_loss: 1892.9869\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1119.5846 - val_loss: 1391.9031\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1123.1455 - val_loss: 1508.0485\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1074.4554 - val_loss: 1413.6123\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1012.7046 - val_loss: 1549.8959\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1166.4895 - val_loss: 1613.2135\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1025.4264 - val_loss: 1542.5139\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1281.3442 - val_loss: 1120.9385\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1137.5164 - val_loss: 929.6504\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 909.6761 - val_loss: 1125.0764\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1041.1860 - val_loss: 1012.1001\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1484.0983 - val_loss: 1321.0223\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1544.6005 - val_loss: 1465.1337\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1538.2327 - val_loss: 1359.7462\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1196.8873 - val_loss: 1651.7266\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1562.9056 - val_loss: 2122.0554\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1221.4174 - val_loss: 1893.3059\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1113.5193 - val_loss: 1115.0247\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 803.1346 - val_loss: 1379.1052\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1002.2823 - val_loss: 1027.6635\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 884.6870 - val_loss: 779.3763\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1058.2607 - val_loss: 1192.5386\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 922.9105 - val_loss: 1265.3835\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1084.1512 - val_loss: 749.7122\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1084.2322 - val_loss: 1091.3329\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1071.6003 - val_loss: 1357.5217\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1188.4169 - val_loss: 1504.6375\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1095.3687 - val_loss: 1419.3221\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1107.9867 - val_loss: 1357.4536\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1249.8287 - val_loss: 1320.5537\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1155.3489 - val_loss: 1355.1484\n",
      "Epoch 766/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 1229.2850 - val_loss: 1643.9604\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1475.4442 - val_loss: 1992.4482\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1618.1926 - val_loss: 1201.3547\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1274.5979 - val_loss: 1089.9996\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1560.3649 - val_loss: 1370.7003\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1114.4220 - val_loss: 1178.9335\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 989.0553 - val_loss: 968.2563\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1080.9484 - val_loss: 998.9687\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 939.9402 - val_loss: 994.6443\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 962.7932 - val_loss: 1555.6731\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1055.9413 - val_loss: 1322.1515\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1235.4363 - val_loss: 1164.7789\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1183.6674 - val_loss: 1500.7388\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1071.3992 - val_loss: 1280.5625\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1033.9968 - val_loss: 1836.4636\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1076.6229 - val_loss: 1948.7357\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1137.8785 - val_loss: 1105.2963\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1085.7599 - val_loss: 1302.5674\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1080.9536 - val_loss: 1885.8242\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1233.2677 - val_loss: 1123.7858\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1144.5107 - val_loss: 1278.4268\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1166.8964 - val_loss: 1175.6488\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1356.4609 - val_loss: 1218.8672\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1258.8118 - val_loss: 1216.0629\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1167.8140 - val_loss: 1167.3295\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1058.2698 - val_loss: 1091.8959\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1094.5333 - val_loss: 1388.1271\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1279.4724 - val_loss: 1532.8099\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1282.7242 - val_loss: 956.8516\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1271.2606 - val_loss: 909.1383\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1039.5421 - val_loss: 1067.9427\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 989.6920 - val_loss: 1394.8315\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1220.6243 - val_loss: 1373.8395\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1166.3141 - val_loss: 1540.3556\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1180.2882 - val_loss: 1404.5819\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1152.6462 - val_loss: 1348.9226\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1141.5162 - val_loss: 1400.1772\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1356.9895 - val_loss: 1546.0269\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1344.3448 - val_loss: 1463.1367\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1799.0978 - val_loss: 2237.2576\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1480.4075 - val_loss: 2162.2573\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1402.1100 - val_loss: 1791.7408\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1136.3030 - val_loss: 1181.8184\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1196.1611 - val_loss: 1543.6554\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1103.6639 - val_loss: 1486.7744\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1377.3755 - val_loss: 1284.3115\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1512.3893 - val_loss: 2134.9878\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1425.4995 - val_loss: 1337.2676\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1327.1595 - val_loss: 1306.7787\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1256.3749 - val_loss: 1380.7590\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1196.1538 - val_loss: 1507.5682\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1222.3397 - val_loss: 1367.9318\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1379.8950 - val_loss: 1174.4779\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1443.5549 - val_loss: 1060.3490\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1385.4985 - val_loss: 912.8527\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1257.7029 - val_loss: 1370.1064\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1477.6735 - val_loss: 1151.6339\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1357.4325 - val_loss: 1456.8972\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1126.5083 - val_loss: 1047.2108\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1079.7441 - val_loss: 1419.0529\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 941.8614 - val_loss: 1371.3949\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1187.5211 - val_loss: 1805.0482\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1231.1991 - val_loss: 2283.3193\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1342.5420 - val_loss: 2049.1702\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1623.3945 - val_loss: 2155.5630\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1520.2837 - val_loss: 2112.4851\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1453.8685 - val_loss: 1796.9493\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1540.2941 - val_loss: 1706.3258\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1321.2155 - val_loss: 1645.2920\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1185.3540 - val_loss: 1695.1576\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1092.0861 - val_loss: 2354.5171\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1528.4554 - val_loss: 1440.1360\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1098.2219 - val_loss: 1910.7445\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1311.4437 - val_loss: 1688.3701\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1165.7549 - val_loss: 1856.0277\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1330.3331 - val_loss: 1678.4845\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1230.6752 - val_loss: 1893.6957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1135.3962 - val_loss: 1673.4913\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1058.5908 - val_loss: 1413.0060\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1039.4458 - val_loss: 1424.0615\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1113.2120 - val_loss: 1228.7863\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1044.1011 - val_loss: 1478.3290\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1305.6530 - val_loss: 1662.0071\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1078.6243 - val_loss: 1910.9426\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1237.7585 - val_loss: 1529.2378\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1011.7574 - val_loss: 1713.0968\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1057.9714 - val_loss: 1163.2297\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1241.3562 - val_loss: 1086.5522\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 977.9586 - val_loss: 1250.8451\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1109.7699 - val_loss: 1313.2065\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1231.7897 - val_loss: 1819.7891\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1265.8639 - val_loss: 1137.5391\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1003.8498 - val_loss: 1456.3246\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1216.8643 - val_loss: 1263.9475\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1145.9238 - val_loss: 1623.6656\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1024.1498 - val_loss: 1309.2859\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 964.5981 - val_loss: 1189.6918\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 896.9738 - val_loss: 1238.1746\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1044.3293 - val_loss: 1467.6586\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1155.0764 - val_loss: 1629.3772\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1142.0079 - val_loss: 1941.5641\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1108.6993 - val_loss: 1608.7495\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1080.4122 - val_loss: 1519.5077\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1083.0626 - val_loss: 1586.5286\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 928.0100 - val_loss: 2001.0958\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1153.1926 - val_loss: 2092.5391\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1019.0070 - val_loss: 1873.2256\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1054.3143 - val_loss: 1684.3525\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 996.1014 - val_loss: 1553.4792\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1043.2605 - val_loss: 1362.9487\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1186.2126 - val_loss: 1493.7297\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1121.3866 - val_loss: 1346.5294\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 974.5685 - val_loss: 1971.2653\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 975.4199 - val_loss: 1437.0746\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1129.1582 - val_loss: 1395.4722\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 864.8257 - val_loss: 1210.1086\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1031.3965 - val_loss: 717.1812\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1074.5277 - val_loss: 1108.7875\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 927.3300 - val_loss: 959.5889\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1017.9213 - val_loss: 1162.0741\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1055.8510 - val_loss: 969.4921\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1023.2365 - val_loss: 937.4110\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 950.6943 - val_loss: 1076.1777\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 932.9402 - val_loss: 962.0880\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 932.4828 - val_loss: 1037.0336\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1014.3430 - val_loss: 1422.0900\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1166.2162 - val_loss: 1408.5474\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1062.8298 - val_loss: 1985.8733\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 880.8251 - val_loss: 1887.7682\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 993.3141 - val_loss: 1791.3998\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 900.9333 - val_loss: 1778.3677\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 866.0723 - val_loss: 1874.7024\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1032.1426 - val_loss: 1771.6670\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1057.0537 - val_loss: 1536.4423\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1228.7938 - val_loss: 1381.5074\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1188.0134 - val_loss: 1252.5804\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1007.7191 - val_loss: 1445.0146\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1009.2952 - val_loss: 1388.9552\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1266.5289 - val_loss: 1013.8259\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1176.1925 - val_loss: 1170.0981\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1012.1293 - val_loss: 1231.6943\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 898.9619 - val_loss: 1339.6512\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 843.5427 - val_loss: 1059.9763\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 870.8519 - val_loss: 1000.6287\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 822.8367 - val_loss: 1707.7948\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 840.3986 - val_loss: 1519.6425\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1034.1974 - val_loss: 1531.0726\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1146.7410 - val_loss: 1216.1190\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1182.8600 - val_loss: 2450.7754\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1301.4958 - val_loss: 1468.5548\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1043.5262 - val_loss: 1819.1840\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1288.7955 - val_loss: 1476.7196\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 983.9427 - val_loss: 1522.7529\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1006.3901 - val_loss: 1286.6694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1090.0959 - val_loss: 1116.4929\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 994.5453 - val_loss: 1597.7157\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 912.1876 - val_loss: 1169.8291\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 937.3446 - val_loss: 1187.1949\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1010.0114 - val_loss: 1190.9686\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1009.1445 - val_loss: 1484.5863\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 930.6161 - val_loss: 1527.5022\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 927.1517 - val_loss: 1280.0897\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 896.1297 - val_loss: 1215.1201\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 868.9151 - val_loss: 1075.3510\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 920.6778 - val_loss: 960.7755\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 893.9207 - val_loss: 1118.9016\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1001.7311 - val_loss: 1214.8367\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 946.4506 - val_loss: 868.0067\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 882.2191 - val_loss: 887.9995\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 992.8555 - val_loss: 989.6578\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 927.5952 - val_loss: 995.4811\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 878.8345 - val_loss: 886.8057\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 932.1899 - val_loss: 747.0317\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 941.6548 - val_loss: 1021.9091\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 876.4762 - val_loss: 1058.3218\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 867.8029 - val_loss: 1091.5846\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 889.7169 - val_loss: 1495.8529\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 868.9517 - val_loss: 1265.0101\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 860.9952 - val_loss: 1250.3739\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 841.4785 - val_loss: 1149.7535\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 910.9057 - val_loss: 1063.7594\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 954.5960 - val_loss: 1113.5619\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1048.2137 - val_loss: 1053.6259\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1031.4141 - val_loss: 1307.4285\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1232.0916 - val_loss: 1260.9889\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1040.6917 - val_loss: 1676.4237\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 899.1495 - val_loss: 1473.7152\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1079.6688 - val_loss: 1694.6572\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1016.4498 - val_loss: 2045.4592\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1048.7980 - val_loss: 1607.8743\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 953.5792 - val_loss: 1492.2644\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 991.5349 - val_loss: 1586.2573\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1097.8461 - val_loss: 1604.4949\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 948.3921 - val_loss: 1565.4122\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 873.0103 - val_loss: 1534.3860\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1014.0615 - val_loss: 1669.0525\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 999.5183 - val_loss: 1880.4324\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 965.2898 - val_loss: 1719.8979\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1094.6073 - val_loss: 1960.7297\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1014.4546 - val_loss: 1869.7906\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 915.5710 - val_loss: 1140.3467\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 892.1994 - val_loss: 1736.9966\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1184.6387 - val_loss: 1130.5787\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1049.2423 - val_loss: 1131.0591\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1199.6840 - val_loss: 1336.6562\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1108.9280 - val_loss: 1581.8047\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1037.9269 - val_loss: 1522.0383\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 971.1161 - val_loss: 1454.6858\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1129.0913 - val_loss: 1608.4117\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1060.4945 - val_loss: 1605.0260\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1017.0366 - val_loss: 1785.8597\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 969.1295 - val_loss: 1499.1128\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1009.7930 - val_loss: 1299.7839\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1028.7692 - val_loss: 3957.0400\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1883.5854 - val_loss: 1948.8536\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1501.5264 - val_loss: 1748.9531\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1377.3627 - val_loss: 2021.0548\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1511.8925 - val_loss: 2602.0757\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1452.0549 - val_loss: 1797.2539\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1350.1948 - val_loss: 2510.6650\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1562.0179 - val_loss: 1411.9978\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1321.2797 - val_loss: 2056.5007\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1145.3671 - val_loss: 1487.6992\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1378.3131 - val_loss: 1444.3251\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1024.3026 - val_loss: 1256.8334\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1124.7462 - val_loss: 1564.2361\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1202.6249 - val_loss: 1353.2677\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1213.9644 - val_loss: 1926.8597\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1437.9137 - val_loss: 1986.9078\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1544.8369 - val_loss: 2154.9172\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1477.5193 - val_loss: 2444.7163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1556.0320 - val_loss: 2084.4075\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1512.8903 - val_loss: 2057.0779\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1312.9039 - val_loss: 2223.1719\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1533.0670 - val_loss: 3045.9348\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1370.6115 - val_loss: 2273.7532\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1229.1074 - val_loss: 1786.0048\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1184.3345 - val_loss: 1872.3685\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1151.8075 - val_loss: 1664.3665\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1245.2426 - val_loss: 2072.0312\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1215.7882 - val_loss: 1805.6641\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1016.6147 - val_loss: 2349.3179\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1047.2614 - val_loss: 2054.7781\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1182.5825 - val_loss: 1554.0907\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 843.0540 - val_loss: 1485.4301\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 869.7417 - val_loss: 1974.9032\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1231.0302 - val_loss: 1593.9662\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1108.9391 - val_loss: 1968.8677\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1150.6096 - val_loss: 1876.5803\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1039.0978 - val_loss: 2293.9688\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1251.8175 - val_loss: 2021.2468\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1407.9874 - val_loss: 2060.5288\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1426.9681 - val_loss: 1678.1841\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1348.4406 - val_loss: 1700.0956\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1342.6879 - val_loss: 1675.6619\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1292.9409 - val_loss: 1253.7250\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1118.9823 - val_loss: 1284.3369\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1030.9066 - val_loss: 1291.5039\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1038.5610 - val_loss: 1926.8710\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1145.0908 - val_loss: 1325.9707\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1053.6085 - val_loss: 1275.3783\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1118.3138 - val_loss: 1304.0841\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 982.8365 - val_loss: 1231.0685\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1110.5209 - val_loss: 1471.7252\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1054.0918 - val_loss: 1234.6887\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1020.3317 - val_loss: 1215.2358\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 932.4412 - val_loss: 1174.3192\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 983.4182 - val_loss: 1286.8571\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 931.3832 - val_loss: 1378.8031\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1126.1125 - val_loss: 1428.2697\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 951.6779 - val_loss: 1460.6533\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 803.8908 - val_loss: 1519.1211\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1055.4780 - val_loss: 1387.1630\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1116.5984 - val_loss: 1374.7844\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1089.0111 - val_loss: 1612.3285\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1112.7996 - val_loss: 1229.7415\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 939.6216 - val_loss: 1207.3485\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 933.0402 - val_loss: 1316.2476\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1074.3745 - val_loss: 1576.9001\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1042.3976 - val_loss: 1368.3406\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1087.8218 - val_loss: 1564.6199\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1134.4811 - val_loss: 1392.8444\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1118.0463 - val_loss: 1373.8895\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 958.5919 - val_loss: 1984.1710\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1086.4459 - val_loss: 1803.6437\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1062.0771 - val_loss: 1619.9879\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 984.6857 - val_loss: 1447.9309\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1103.8452 - val_loss: 1483.9197\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 968.6329 - val_loss: 1358.5829\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1021.2194 - val_loss: 1476.8500\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1008.5998 - val_loss: 1589.7245\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1181.5107 - val_loss: 1497.6735\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1042.3916 - val_loss: 1554.0322\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1334.3113 - val_loss: 1992.2140\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1449.4169 - val_loss: 1723.7622\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1465.1904 - val_loss: 1108.0073\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1016.2356 - val_loss: 778.0198\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1228.9072 - val_loss: 1000.4680\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1272.8995 - val_loss: 1299.4779\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1592.3800 - val_loss: 1913.9580\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1460.0009 - val_loss: 1750.2891\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1427.6881 - val_loss: 1415.7083\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1139.9823 - val_loss: 1176.6245\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1133.8264 - val_loss: 1544.8781\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1129.2227 - val_loss: 1309.0145\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1233.1945 - val_loss: 1213.0496\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1112.5099 - val_loss: 1168.2219\n",
      "Epoch 1073/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1279.0140Restoring model weights from the end of the best epoch: 573.\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1034.7994 - val_loss: 1087.3676\n",
      "Epoch 1073: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>243.566681</td>\n",
       "      <td>191.997208</td>\n",
       "      <td>191.997208</td>\n",
       "      <td>191.997208</td>\n",
       "      <td>191.997208</td>\n",
       "      <td>191.997208</td>\n",
       "      <td>243.570419</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>191.997208</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>239.841888</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>243.570435</td>\n",
       "      <td>191.997208</td>\n",
       "      <td>192.013977</td>\n",
       "      <td>204.335724</td>\n",
       "      <td>214.837555</td>\n",
       "      <td>214.83905</td>\n",
       "      <td>191.997208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>185.846</td>\n",
       "      <td>200.671</td>\n",
       "      <td>207.913</td>\n",
       "      <td>188.107</td>\n",
       "      <td>193.661</td>\n",
       "      <td>175.783</td>\n",
       "      <td>185.078</td>\n",
       "      <td>146.761</td>\n",
       "      <td>173.121</td>\n",
       "      <td>169.841</td>\n",
       "      <td>142.706</td>\n",
       "      <td>242.422</td>\n",
       "      <td>226.205</td>\n",
       "      <td>229.696</td>\n",
       "      <td>232.624</td>\n",
       "      <td>234.262</td>\n",
       "      <td>217.727</td>\n",
       "      <td>190.769</td>\n",
       "      <td>232.609</td>\n",
       "      <td>195.364</td>\n",
       "      <td>205.69</td>\n",
       "      <td>231.354</td>\n",
       "      <td>236.711</td>\n",
       "      <td>215.36</td>\n",
       "      <td>258.015</td>\n",
       "      <td>244.87</td>\n",
       "      <td>225.41</td>\n",
       "      <td>252.849</td>\n",
       "      <td>226.618</td>\n",
       "      <td>190.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>57.720688</td>\n",
       "      <td>8.673798</td>\n",
       "      <td>15.915787</td>\n",
       "      <td>3.890213</td>\n",
       "      <td>1.663788</td>\n",
       "      <td>16.214203</td>\n",
       "      <td>58.492416</td>\n",
       "      <td>96.809433</td>\n",
       "      <td>70.449432</td>\n",
       "      <td>73.729431</td>\n",
       "      <td>100.864441</td>\n",
       "      <td>50.424789</td>\n",
       "      <td>17.365433</td>\n",
       "      <td>13.874435</td>\n",
       "      <td>10.946442</td>\n",
       "      <td>9.308441</td>\n",
       "      <td>22.114883</td>\n",
       "      <td>52.801437</td>\n",
       "      <td>10.961441</td>\n",
       "      <td>48.206436</td>\n",
       "      <td>37.880432</td>\n",
       "      <td>12.216431</td>\n",
       "      <td>6.859436</td>\n",
       "      <td>28.210434</td>\n",
       "      <td>66.017807</td>\n",
       "      <td>52.856018</td>\n",
       "      <td>21.07428</td>\n",
       "      <td>38.011444</td>\n",
       "      <td>11.778946</td>\n",
       "      <td>1.004211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1           2           3           4   \\\n",
       "Month          Month-1     Month-2     Month-3     Month-4     Month-5   \n",
       "Prediction  243.566681  191.997208  191.997208  191.997208  191.997208   \n",
       "Target         185.846     200.671     207.913     188.107     193.661   \n",
       "Error        57.720688    8.673798   15.915787    3.890213    1.663788   \n",
       "\n",
       "                    5           6           7           8           9   \\\n",
       "Month          Month-6     Month-7     Month-8     Month-9    Month-10   \n",
       "Prediction  191.997208  243.570419  243.570435  243.570435  243.570435   \n",
       "Target         175.783     185.078     146.761     173.121     169.841   \n",
       "Error        16.214203   58.492416   96.809433   70.449432   73.729431   \n",
       "\n",
       "                    10          11          12          13          14  \\\n",
       "Month         Month-11    Month-12    Month-13    Month-14    Month-15   \n",
       "Prediction  243.570435  191.997208  243.570435  243.570435  243.570435   \n",
       "Target         142.706     242.422     226.205     229.696     232.624   \n",
       "Error       100.864441   50.424789   17.365433   13.874435   10.946442   \n",
       "\n",
       "                    15          16          17          18          19  \\\n",
       "Month         Month-16    Month-17    Month-18    Month-19    Month-20   \n",
       "Prediction  243.570435  239.841888  243.570435  243.570435  243.570435   \n",
       "Target         234.262     217.727     190.769     232.609     195.364   \n",
       "Error         9.308441   22.114883   52.801437   10.961441   48.206436   \n",
       "\n",
       "                    20          21          22          23          24  \\\n",
       "Month         Month-21    Month-22    Month-23    Month-24    Month-25   \n",
       "Prediction  243.570435  243.570435  243.570435  243.570435  191.997208   \n",
       "Target          205.69     231.354     236.711      215.36     258.015   \n",
       "Error        37.880432   12.216431    6.859436   28.210434   66.017807   \n",
       "\n",
       "                    25          26          27         28          29  \n",
       "Month         Month-26    Month-27    Month-28   Month-29    Month-30  \n",
       "Prediction  192.013977  204.335724  214.837555  214.83905  191.997208  \n",
       "Target          244.87      225.41     252.849    226.618     190.993  \n",
       "Error        52.856018    21.07428   38.011444  11.778946    1.004211  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.877895"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.1783104"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[2613.402]] - Target[2211.91]| =  Error: [[401.4922]]; MAPE:[[0.1815138]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[2919.1162]] - Target[2648.3710000000005]| =  Error: [[270.74512]]; MAPE:[[0.10223081]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Ano-5: |Prediction[[1210.0208]] - Target[1398.7549999999999]| =  Error: [[188.73425]]; MAPE:[[0.13493018]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[401.4922]], dtype=float32),\n",
       " array([[270.74512]], dtype=float32),\n",
       " array([[188.73425]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "286.9905"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.13955826"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
