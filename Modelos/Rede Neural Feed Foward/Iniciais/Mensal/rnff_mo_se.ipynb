{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Sergipe - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sergipe - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Sergipe - value</th>\n",
       "      <th>Sergipe - Produção de Cimento (t)</th>\n",
       "      <th>Sergipe - PIB - Estadual</th>\n",
       "      <th>Sergipe - PIB - Construção Civil</th>\n",
       "      <th>Sergipe - PIB - Per Capita</th>\n",
       "      <th>Sergipe - PIB - Preços de Mercado</th>\n",
       "      <th>Sergipe - Desemprego</th>\n",
       "      <th>Sergipe - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.669217</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>0.339447</td>\n",
       "      <td>152.791400</td>\n",
       "      <td>2.159732e+07</td>\n",
       "      <td>1.260978e+06</td>\n",
       "      <td>9.960678</td>\n",
       "      <td>2.029642e+07</td>\n",
       "      <td>8.389943</td>\n",
       "      <td>23.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.669542</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>0.341257</td>\n",
       "      <td>151.964054</td>\n",
       "      <td>2.162153e+07</td>\n",
       "      <td>1.262134e+06</td>\n",
       "      <td>9.961956</td>\n",
       "      <td>2.030238e+07</td>\n",
       "      <td>8.384067</td>\n",
       "      <td>21.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.669868</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>0.343016</td>\n",
       "      <td>154.467758</td>\n",
       "      <td>2.164574e+07</td>\n",
       "      <td>1.263289e+06</td>\n",
       "      <td>9.963234</td>\n",
       "      <td>2.030833e+07</td>\n",
       "      <td>8.378190</td>\n",
       "      <td>20.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.670193</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>0.344722</td>\n",
       "      <td>155.913400</td>\n",
       "      <td>2.166995e+07</td>\n",
       "      <td>1.264444e+06</td>\n",
       "      <td>9.964512</td>\n",
       "      <td>2.031429e+07</td>\n",
       "      <td>8.372313</td>\n",
       "      <td>19.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.670519</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>0.346174</td>\n",
       "      <td>157.467159</td>\n",
       "      <td>2.169416e+07</td>\n",
       "      <td>1.265599e+06</td>\n",
       "      <td>9.965790</td>\n",
       "      <td>2.032025e+07</td>\n",
       "      <td>8.366437</td>\n",
       "      <td>19.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557749</td>\n",
       "      <td>169.752591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.556659</td>\n",
       "      <td>169.621865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555237</td>\n",
       "      <td>169.855545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553445</td>\n",
       "      <td>170.188727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551255</td>\n",
       "      <td>170.903792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Sergipe - IDH  \\\n",
       "0       2003-1       0.669217   \n",
       "1       2003-2       0.669542   \n",
       "2       2003-3       0.669868   \n",
       "3       2003-4       0.670193   \n",
       "4       2003-5       0.670519   \n",
       "..         ...            ...   \n",
       "235     2022-8            NaN   \n",
       "236     2022-9            NaN   \n",
       "237    2022-10            NaN   \n",
       "238    2022-11            NaN   \n",
       "239    2022-12            NaN   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Sergipe - value  \\\n",
       "0                              7.330309e+06   0.969649         0.339447   \n",
       "1                              7.335910e+06   0.950783         0.341257   \n",
       "2                              7.341511e+06   0.938332         0.343016   \n",
       "3                              7.347112e+06   0.926401         0.344722   \n",
       "4                              7.352713e+06   0.951683         0.346174   \n",
       "..                                      ...        ...              ...   \n",
       "235                                     NaN        NaN         0.557749   \n",
       "236                                     NaN        NaN         0.556659   \n",
       "237                                     NaN        NaN         0.555237   \n",
       "238                                     NaN        NaN         0.553445   \n",
       "239                                     NaN        NaN         0.551255   \n",
       "\n",
       "     Sergipe - Produção de Cimento (t)  Sergipe - PIB - Estadual  \\\n",
       "0                           152.791400              2.159732e+07   \n",
       "1                           151.964054              2.162153e+07   \n",
       "2                           154.467758              2.164574e+07   \n",
       "3                           155.913400              2.166995e+07   \n",
       "4                           157.467159              2.169416e+07   \n",
       "..                                 ...                       ...   \n",
       "235                         169.752591                       NaN   \n",
       "236                         169.621865                       NaN   \n",
       "237                         169.855545                       NaN   \n",
       "238                         170.188727                       NaN   \n",
       "239                         170.903792                       NaN   \n",
       "\n",
       "     Sergipe - PIB - Construção Civil  Sergipe - PIB - Per Capita  \\\n",
       "0                        1.260978e+06                    9.960678   \n",
       "1                        1.262134e+06                    9.961956   \n",
       "2                        1.263289e+06                    9.963234   \n",
       "3                        1.264444e+06                    9.964512   \n",
       "4                        1.265599e+06                    9.965790   \n",
       "..                                ...                         ...   \n",
       "235                               NaN                         NaN   \n",
       "236                               NaN                         NaN   \n",
       "237                               NaN                         NaN   \n",
       "238                               NaN                         NaN   \n",
       "239                               NaN                         NaN   \n",
       "\n",
       "     Sergipe - PIB - Preços de Mercado  Sergipe - Desemprego  \\\n",
       "0                         2.029642e+07              8.389943   \n",
       "1                         2.030238e+07              8.384067   \n",
       "2                         2.030833e+07              8.378190   \n",
       "3                         2.031429e+07              8.372313   \n",
       "4                         2.032025e+07              8.366437   \n",
       "..                                 ...                   ...   \n",
       "235                                NaN                   NaN   \n",
       "236                                NaN                   NaN   \n",
       "237                                NaN                   NaN   \n",
       "238                                NaN                   NaN   \n",
       "239                                NaN                   NaN   \n",
       "\n",
       "     Sergipe - Consumo de Cimento (t)  \n",
       "0                              23.616  \n",
       "1                              21.357  \n",
       "2                              20.059  \n",
       "3                              19.920  \n",
       "4                              19.962  \n",
       "..                                ...  \n",
       "235                            34.037  \n",
       "236                            32.537  \n",
       "237                            35.215  \n",
       "238                            34.707  \n",
       "239                            34.707  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_SE.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data = data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "# data['Unnamed: 0'] = data['Unnamed: 0'].str[5:].astype(float)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sergipe - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Sergipe - value</th>\n",
       "      <th>Sergipe - Produção de Cimento (t)</th>\n",
       "      <th>Sergipe - PIB - Estadual</th>\n",
       "      <th>Sergipe - PIB - Construção Civil</th>\n",
       "      <th>Sergipe - PIB - Per Capita</th>\n",
       "      <th>Sergipe - PIB - Preços de Mercado</th>\n",
       "      <th>Sergipe - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.191597</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.329544</td>\n",
       "      <td>-1.638248</td>\n",
       "      <td>-1.769739</td>\n",
       "      <td>-0.221258</td>\n",
       "      <td>0.566843</td>\n",
       "      <td>-2.721827</td>\n",
       "      <td>-0.858763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.153964</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.294452</td>\n",
       "      <td>-1.660220</td>\n",
       "      <td>-1.748579</td>\n",
       "      <td>-0.190897</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>-2.626858</td>\n",
       "      <td>-0.861105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.116331</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.260345</td>\n",
       "      <td>-1.593729</td>\n",
       "      <td>-1.727419</td>\n",
       "      <td>-0.160535</td>\n",
       "      <td>0.603889</td>\n",
       "      <td>-2.531890</td>\n",
       "      <td>-0.863447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.078698</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.227259</td>\n",
       "      <td>-1.555337</td>\n",
       "      <td>-1.706259</td>\n",
       "      <td>-0.130173</td>\n",
       "      <td>0.622411</td>\n",
       "      <td>-2.436921</td>\n",
       "      <td>-0.865789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.041065</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.199102</td>\n",
       "      <td>-1.514074</td>\n",
       "      <td>-1.685099</td>\n",
       "      <td>-0.099812</td>\n",
       "      <td>0.640934</td>\n",
       "      <td>-2.341953</td>\n",
       "      <td>-0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.375707</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>0.926582</td>\n",
       "      <td>-1.147300</td>\n",
       "      <td>1.088440</td>\n",
       "      <td>-1.830495</td>\n",
       "      <td>-1.273118</td>\n",
       "      <td>-0.375044</td>\n",
       "      <td>1.205390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.367460</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>0.922177</td>\n",
       "      <td>-1.137939</td>\n",
       "      <td>1.080037</td>\n",
       "      <td>-1.823605</td>\n",
       "      <td>-1.263526</td>\n",
       "      <td>-0.370593</td>\n",
       "      <td>1.201393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.359213</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>0.923529</td>\n",
       "      <td>-1.097718</td>\n",
       "      <td>1.071634</td>\n",
       "      <td>-1.816716</td>\n",
       "      <td>-1.253934</td>\n",
       "      <td>-0.366142</td>\n",
       "      <td>1.197396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.350966</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>0.936477</td>\n",
       "      <td>-1.086004</td>\n",
       "      <td>1.063231</td>\n",
       "      <td>-1.809827</td>\n",
       "      <td>-1.244342</td>\n",
       "      <td>-0.361691</td>\n",
       "      <td>1.193399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.342719</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>0.961618</td>\n",
       "      <td>-1.068009</td>\n",
       "      <td>1.054828</td>\n",
       "      <td>-1.802937</td>\n",
       "      <td>-1.234750</td>\n",
       "      <td>-0.357241</td>\n",
       "      <td>1.189401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sergipe - IDH   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0        -2.191597                                          2.723741   \n",
       "1        -2.153964                                          2.350880   \n",
       "2        -2.116331                                          2.123016   \n",
       "3        -2.078698                                          2.021477   \n",
       "4        -2.041065                                          1.887113   \n",
       "..             ...                                               ...   \n",
       "187       1.375707                                         -2.010387   \n",
       "188       1.367460                                         -1.870713   \n",
       "189       1.359213                                         -1.806230   \n",
       "190       1.350966                                         -1.727496   \n",
       "191       1.342719                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Sergipe - value  \\\n",
       "0                                 -2.389042   3.122582        -1.329544   \n",
       "1                                 -2.352139   2.970356        -1.294452   \n",
       "2                                 -2.315236   2.869895        -1.260345   \n",
       "3                                 -2.278333   2.773628        -1.227259   \n",
       "4                                 -2.241431   2.977624        -1.199102   \n",
       "..                                      ...        ...              ...   \n",
       "187                                0.389193  -1.749976         0.926582   \n",
       "188                                0.370392  -1.593005         0.922177   \n",
       "189                                0.351592  -1.351489         0.923529   \n",
       "190                                0.332791  -1.198492         0.936477   \n",
       "191                                0.313991  -1.100894         0.961618   \n",
       "\n",
       "     Sergipe - Produção de Cimento (t)  Sergipe - PIB - Estadual  \\\n",
       "0                            -1.638248                 -1.769739   \n",
       "1                            -1.660220                 -1.748579   \n",
       "2                            -1.593729                 -1.727419   \n",
       "3                            -1.555337                 -1.706259   \n",
       "4                            -1.514074                 -1.685099   \n",
       "..                                 ...                       ...   \n",
       "187                          -1.147300                  1.088440   \n",
       "188                          -1.137939                  1.080037   \n",
       "189                          -1.097718                  1.071634   \n",
       "190                          -1.086004                  1.063231   \n",
       "191                          -1.068009                  1.054828   \n",
       "\n",
       "     Sergipe - PIB - Construção Civil  Sergipe - PIB - Per Capita  \\\n",
       "0                           -0.221258                    0.566843   \n",
       "1                           -0.190897                    0.585366   \n",
       "2                           -0.160535                    0.603889   \n",
       "3                           -0.130173                    0.622411   \n",
       "4                           -0.099812                    0.640934   \n",
       "..                                ...                         ...   \n",
       "187                         -1.830495                   -1.273118   \n",
       "188                         -1.823605                   -1.263526   \n",
       "189                         -1.816716                   -1.253934   \n",
       "190                         -1.809827                   -1.244342   \n",
       "191                         -1.802937                   -1.234750   \n",
       "\n",
       "     Sergipe - PIB - Preços de Mercado  Sergipe - Desemprego  \n",
       "0                            -2.721827             -0.858763  \n",
       "1                            -2.626858             -0.861105  \n",
       "2                            -2.531890             -0.863447  \n",
       "3                            -2.436921             -0.865789  \n",
       "4                            -2.341953             -0.868132  \n",
       "..                                 ...                   ...  \n",
       "187                          -0.375044              1.205390  \n",
       "188                          -0.370593              1.201393  \n",
       "189                          -0.366142              1.197396  \n",
       "190                          -0.361691              1.193399  \n",
       "191                          -0.357241              1.189401  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      19.642\n",
       "1      17.778\n",
       "2      21.180\n",
       "3      18.824\n",
       "4      16.535\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Sergipe - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sergipe - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Sergipe - value</th>\n",
       "      <th>Sergipe - Produção de Cimento (t)</th>\n",
       "      <th>Sergipe - PIB - Estadual</th>\n",
       "      <th>Sergipe - PIB - Construção Civil</th>\n",
       "      <th>Sergipe - PIB - Per Capita</th>\n",
       "      <th>Sergipe - PIB - Preços de Mercado</th>\n",
       "      <th>Sergipe - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.191597</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.329544</td>\n",
       "      <td>-1.638248</td>\n",
       "      <td>-1.769739</td>\n",
       "      <td>-0.221258</td>\n",
       "      <td>0.566843</td>\n",
       "      <td>-2.721827</td>\n",
       "      <td>-0.858763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.153964</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.294452</td>\n",
       "      <td>-1.660220</td>\n",
       "      <td>-1.748579</td>\n",
       "      <td>-0.190897</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>-2.626858</td>\n",
       "      <td>-0.861105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.116331</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.260345</td>\n",
       "      <td>-1.593729</td>\n",
       "      <td>-1.727419</td>\n",
       "      <td>-0.160535</td>\n",
       "      <td>0.603889</td>\n",
       "      <td>-2.531890</td>\n",
       "      <td>-0.863447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.078698</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.227259</td>\n",
       "      <td>-1.555337</td>\n",
       "      <td>-1.706259</td>\n",
       "      <td>-0.130173</td>\n",
       "      <td>0.622411</td>\n",
       "      <td>-2.436921</td>\n",
       "      <td>-0.865789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.041065</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.199102</td>\n",
       "      <td>-1.514074</td>\n",
       "      <td>-1.685099</td>\n",
       "      <td>-0.099812</td>\n",
       "      <td>0.640934</td>\n",
       "      <td>-2.341953</td>\n",
       "      <td>-0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.387754</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>1.521513</td>\n",
       "      <td>-0.132792</td>\n",
       "      <td>1.143453</td>\n",
       "      <td>-1.270245</td>\n",
       "      <td>-1.549275</td>\n",
       "      <td>-0.543399</td>\n",
       "      <td>1.342411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.390522</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>1.498482</td>\n",
       "      <td>-0.189562</td>\n",
       "      <td>1.147046</td>\n",
       "      <td>-1.306762</td>\n",
       "      <td>-1.539477</td>\n",
       "      <td>-0.525912</td>\n",
       "      <td>1.335629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.393291</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>1.475235</td>\n",
       "      <td>-0.253067</td>\n",
       "      <td>1.150639</td>\n",
       "      <td>-1.343278</td>\n",
       "      <td>-1.529680</td>\n",
       "      <td>-0.508425</td>\n",
       "      <td>1.328848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.396059</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>1.452580</td>\n",
       "      <td>-0.330172</td>\n",
       "      <td>1.154232</td>\n",
       "      <td>-1.379795</td>\n",
       "      <td>-1.519882</td>\n",
       "      <td>-0.490938</td>\n",
       "      <td>1.322066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.398828</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>1.433505</td>\n",
       "      <td>-0.395258</td>\n",
       "      <td>1.157825</td>\n",
       "      <td>-1.416312</td>\n",
       "      <td>-1.510084</td>\n",
       "      <td>-0.473451</td>\n",
       "      <td>1.315285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sergipe - IDH   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0        -2.191597                                          2.723741   \n",
       "1        -2.153964                                          2.350880   \n",
       "2        -2.116331                                          2.123016   \n",
       "3        -2.078698                                          2.021477   \n",
       "4        -2.041065                                          1.887113   \n",
       "..             ...                                               ...   \n",
       "157       1.387754                                         -0.214006   \n",
       "158       1.390522                                         -0.434717   \n",
       "159       1.393291                                         -0.524091   \n",
       "160       1.396059                                         -0.614500   \n",
       "161       1.398828                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Sergipe - value  \\\n",
       "0                                 -2.389042   3.122582        -1.329544   \n",
       "1                                 -2.352139   2.970356        -1.294452   \n",
       "2                                 -2.315236   2.869895        -1.260345   \n",
       "3                                 -2.278333   2.773628        -1.227259   \n",
       "4                                 -2.241431   2.977624        -1.199102   \n",
       "..                                      ...        ...              ...   \n",
       "157                                0.819304  -0.883659         1.521513   \n",
       "158                                0.808136  -0.950771         1.498482   \n",
       "159                                0.796969  -1.028465         1.475235   \n",
       "160                                0.785801  -1.103668         1.452580   \n",
       "161                                0.774634  -0.978419         1.433505   \n",
       "\n",
       "     Sergipe - Produção de Cimento (t)  Sergipe - PIB - Estadual  \\\n",
       "0                            -1.638248                 -1.769739   \n",
       "1                            -1.660220                 -1.748579   \n",
       "2                            -1.593729                 -1.727419   \n",
       "3                            -1.555337                 -1.706259   \n",
       "4                            -1.514074                 -1.685099   \n",
       "..                                 ...                       ...   \n",
       "157                          -0.132792                  1.143453   \n",
       "158                          -0.189562                  1.147046   \n",
       "159                          -0.253067                  1.150639   \n",
       "160                          -0.330172                  1.154232   \n",
       "161                          -0.395258                  1.157825   \n",
       "\n",
       "     Sergipe - PIB - Construção Civil  Sergipe - PIB - Per Capita  \\\n",
       "0                           -0.221258                    0.566843   \n",
       "1                           -0.190897                    0.585366   \n",
       "2                           -0.160535                    0.603889   \n",
       "3                           -0.130173                    0.622411   \n",
       "4                           -0.099812                    0.640934   \n",
       "..                                ...                         ...   \n",
       "157                         -1.270245                   -1.549275   \n",
       "158                         -1.306762                   -1.539477   \n",
       "159                         -1.343278                   -1.529680   \n",
       "160                         -1.379795                   -1.519882   \n",
       "161                         -1.416312                   -1.510084   \n",
       "\n",
       "     Sergipe - PIB - Preços de Mercado  Sergipe - Desemprego  \n",
       "0                            -2.721827             -0.858763  \n",
       "1                            -2.626858             -0.861105  \n",
       "2                            -2.531890             -0.863447  \n",
       "3                            -2.436921             -0.865789  \n",
       "4                            -2.341953             -0.868132  \n",
       "..                                 ...                   ...  \n",
       "157                          -0.543399              1.342411  \n",
       "158                          -0.525912              1.335629  \n",
       "159                          -0.508425              1.328848  \n",
       "160                          -0.490938              1.322066  \n",
       "161                          -0.473451              1.315285  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      19.642\n",
       "1      17.778\n",
       "2      21.180\n",
       "3      18.824\n",
       "4      16.535\n",
       "        ...  \n",
       "157    37.579\n",
       "158    48.016\n",
       "159    38.263\n",
       "160    40.413\n",
       "161    34.053\n",
       "Name: Sergipe - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sergipe - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Sergipe - value</th>\n",
       "      <th>Sergipe - Produção de Cimento (t)</th>\n",
       "      <th>Sergipe - PIB - Estadual</th>\n",
       "      <th>Sergipe - PIB - Construção Civil</th>\n",
       "      <th>Sergipe - PIB - Per Capita</th>\n",
       "      <th>Sergipe - PIB - Preços de Mercado</th>\n",
       "      <th>Sergipe - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.401596</td>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>1.414043</td>\n",
       "      <td>-0.454209</td>\n",
       "      <td>1.161418</td>\n",
       "      <td>-1.452829</td>\n",
       "      <td>-1.500286</td>\n",
       "      <td>-0.455964</td>\n",
       "      <td>1.308503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.404365</td>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>1.394507</td>\n",
       "      <td>-0.503123</td>\n",
       "      <td>1.165011</td>\n",
       "      <td>-1.489345</td>\n",
       "      <td>-1.490488</td>\n",
       "      <td>-0.438477</td>\n",
       "      <td>1.301721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.407133</td>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>1.367731</td>\n",
       "      <td>-0.562332</td>\n",
       "      <td>1.168604</td>\n",
       "      <td>-1.525862</td>\n",
       "      <td>-1.480691</td>\n",
       "      <td>-0.420990</td>\n",
       "      <td>1.294940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.409902</td>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>1.339914</td>\n",
       "      <td>-0.617004</td>\n",
       "      <td>1.172197</td>\n",
       "      <td>-1.562379</td>\n",
       "      <td>-1.470893</td>\n",
       "      <td>-0.403503</td>\n",
       "      <td>1.288158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.412671</td>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>1.313790</td>\n",
       "      <td>-0.680564</td>\n",
       "      <td>1.175790</td>\n",
       "      <td>-1.598896</td>\n",
       "      <td>-1.461095</td>\n",
       "      <td>-0.386016</td>\n",
       "      <td>1.281377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.415439</td>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>1.287929</td>\n",
       "      <td>-0.725299</td>\n",
       "      <td>1.179383</td>\n",
       "      <td>-1.635412</td>\n",
       "      <td>-1.451297</td>\n",
       "      <td>-0.368529</td>\n",
       "      <td>1.274595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.418208</td>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>1.259641</td>\n",
       "      <td>-0.772009</td>\n",
       "      <td>1.182976</td>\n",
       "      <td>-1.671929</td>\n",
       "      <td>-1.441499</td>\n",
       "      <td>-0.351042</td>\n",
       "      <td>1.267813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.419477</td>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>1.230064</td>\n",
       "      <td>-0.819918</td>\n",
       "      <td>1.179999</td>\n",
       "      <td>-1.689162</td>\n",
       "      <td>-1.433063</td>\n",
       "      <td>-0.355638</td>\n",
       "      <td>1.264943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.420746</td>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>1.206835</td>\n",
       "      <td>-0.850964</td>\n",
       "      <td>1.177023</td>\n",
       "      <td>-1.706394</td>\n",
       "      <td>-1.424626</td>\n",
       "      <td>-0.360235</td>\n",
       "      <td>1.262073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.422015</td>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>1.184830</td>\n",
       "      <td>-0.892669</td>\n",
       "      <td>1.174047</td>\n",
       "      <td>-1.723627</td>\n",
       "      <td>-1.416190</td>\n",
       "      <td>-0.364831</td>\n",
       "      <td>1.259203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.423284</td>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>1.164107</td>\n",
       "      <td>-0.908700</td>\n",
       "      <td>1.171070</td>\n",
       "      <td>-1.740859</td>\n",
       "      <td>-1.407753</td>\n",
       "      <td>-0.369428</td>\n",
       "      <td>1.256333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.424553</td>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>1.142726</td>\n",
       "      <td>-0.947516</td>\n",
       "      <td>1.168094</td>\n",
       "      <td>-1.758092</td>\n",
       "      <td>-1.399317</td>\n",
       "      <td>-0.374024</td>\n",
       "      <td>1.253463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.425822</td>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>1.124074</td>\n",
       "      <td>-0.983072</td>\n",
       "      <td>1.165118</td>\n",
       "      <td>-1.775324</td>\n",
       "      <td>-1.390880</td>\n",
       "      <td>-0.378620</td>\n",
       "      <td>1.250592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.427091</td>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>1.104711</td>\n",
       "      <td>-1.007099</td>\n",
       "      <td>1.162142</td>\n",
       "      <td>-1.792557</td>\n",
       "      <td>-1.382444</td>\n",
       "      <td>-0.383217</td>\n",
       "      <td>1.247722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.428360</td>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>1.083374</td>\n",
       "      <td>-1.018151</td>\n",
       "      <td>1.159165</td>\n",
       "      <td>-1.809789</td>\n",
       "      <td>-1.374007</td>\n",
       "      <td>-0.387813</td>\n",
       "      <td>1.244852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.429629</td>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>1.061463</td>\n",
       "      <td>-1.029671</td>\n",
       "      <td>1.156189</td>\n",
       "      <td>-1.827022</td>\n",
       "      <td>-1.365571</td>\n",
       "      <td>-0.392410</td>\n",
       "      <td>1.241982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.430898</td>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>1.037851</td>\n",
       "      <td>-1.051651</td>\n",
       "      <td>1.153213</td>\n",
       "      <td>-1.844255</td>\n",
       "      <td>-1.357134</td>\n",
       "      <td>-0.397006</td>\n",
       "      <td>1.239112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.432167</td>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>1.012823</td>\n",
       "      <td>-1.075345</td>\n",
       "      <td>1.150236</td>\n",
       "      <td>-1.861487</td>\n",
       "      <td>-1.348698</td>\n",
       "      <td>-0.401603</td>\n",
       "      <td>1.236242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.433437</td>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>0.988857</td>\n",
       "      <td>-1.100675</td>\n",
       "      <td>1.147260</td>\n",
       "      <td>-1.878720</td>\n",
       "      <td>-1.340261</td>\n",
       "      <td>-0.406199</td>\n",
       "      <td>1.233372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.425189</td>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>0.979290</td>\n",
       "      <td>-1.128556</td>\n",
       "      <td>1.138857</td>\n",
       "      <td>-1.871830</td>\n",
       "      <td>-1.330669</td>\n",
       "      <td>-0.401748</td>\n",
       "      <td>1.229374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.416942</td>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>0.969569</td>\n",
       "      <td>-1.148503</td>\n",
       "      <td>1.130454</td>\n",
       "      <td>-1.864941</td>\n",
       "      <td>-1.321078</td>\n",
       "      <td>-0.397297</td>\n",
       "      <td>1.225377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.408695</td>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>0.961387</td>\n",
       "      <td>-1.180467</td>\n",
       "      <td>1.122051</td>\n",
       "      <td>-1.858052</td>\n",
       "      <td>-1.311486</td>\n",
       "      <td>-0.392847</td>\n",
       "      <td>1.221380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.400448</td>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>0.952878</td>\n",
       "      <td>-1.178111</td>\n",
       "      <td>1.113648</td>\n",
       "      <td>-1.851162</td>\n",
       "      <td>-1.301894</td>\n",
       "      <td>-0.388396</td>\n",
       "      <td>1.217382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.392201</td>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>0.944659</td>\n",
       "      <td>-1.164457</td>\n",
       "      <td>1.105245</td>\n",
       "      <td>-1.844273</td>\n",
       "      <td>-1.292302</td>\n",
       "      <td>-0.383945</td>\n",
       "      <td>1.213385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.383954</td>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>0.935711</td>\n",
       "      <td>-1.164841</td>\n",
       "      <td>1.096843</td>\n",
       "      <td>-1.837384</td>\n",
       "      <td>-1.282710</td>\n",
       "      <td>-0.379494</td>\n",
       "      <td>1.209388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.375707</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>0.926582</td>\n",
       "      <td>-1.147300</td>\n",
       "      <td>1.088440</td>\n",
       "      <td>-1.830495</td>\n",
       "      <td>-1.273118</td>\n",
       "      <td>-0.375044</td>\n",
       "      <td>1.205390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.367460</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>0.922177</td>\n",
       "      <td>-1.137939</td>\n",
       "      <td>1.080037</td>\n",
       "      <td>-1.823605</td>\n",
       "      <td>-1.263526</td>\n",
       "      <td>-0.370593</td>\n",
       "      <td>1.201393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.359213</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>0.923529</td>\n",
       "      <td>-1.097718</td>\n",
       "      <td>1.071634</td>\n",
       "      <td>-1.816716</td>\n",
       "      <td>-1.253934</td>\n",
       "      <td>-0.366142</td>\n",
       "      <td>1.197396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.350966</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>0.936477</td>\n",
       "      <td>-1.086004</td>\n",
       "      <td>1.063231</td>\n",
       "      <td>-1.809827</td>\n",
       "      <td>-1.244342</td>\n",
       "      <td>-0.361691</td>\n",
       "      <td>1.193399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.342719</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>0.961618</td>\n",
       "      <td>-1.068009</td>\n",
       "      <td>1.054828</td>\n",
       "      <td>-1.802937</td>\n",
       "      <td>-1.234750</td>\n",
       "      <td>-0.357241</td>\n",
       "      <td>1.189401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sergipe - IDH   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162       1.401596                                         -0.601510   \n",
       "163       1.404365                                         -0.786068   \n",
       "164       1.407133                                         -0.830387   \n",
       "165       1.409902                                         -0.801089   \n",
       "166       1.412671                                         -0.959917   \n",
       "167       1.415439                                         -1.022309   \n",
       "168       1.418208                                         -1.074401   \n",
       "169       1.419477                                         -1.119597   \n",
       "170       1.420746                                         -1.078648   \n",
       "171       1.422015                                         -1.055426   \n",
       "172       1.423284                                         -1.101053   \n",
       "173       1.424553                                         -1.211370   \n",
       "174       1.425822                                         -1.157198   \n",
       "175       1.427091                                         -1.223444   \n",
       "176       1.428360                                         -1.311519   \n",
       "177       1.429629                                         -1.362602   \n",
       "178       1.430898                                         -1.380125   \n",
       "179       1.432167                                         -1.219296   \n",
       "180       1.433437                                         -1.300284   \n",
       "181       1.425189                                         -1.336476   \n",
       "182       1.416942                                         -1.415774   \n",
       "183       1.408695                                         -1.526021   \n",
       "184       1.400448                                         -1.681806   \n",
       "185       1.392201                                         -1.735167   \n",
       "186       1.383954                                         -1.962315   \n",
       "187       1.375707                                         -2.010387   \n",
       "188       1.367460                                         -1.870713   \n",
       "189       1.359213                                         -1.806230   \n",
       "190       1.350966                                         -1.727496   \n",
       "191       1.342719                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Sergipe - value  \\\n",
       "162                                0.763466  -1.213929         1.414043   \n",
       "163                                0.752299  -1.292173         1.394507   \n",
       "164                                0.741131  -1.324219         1.367731   \n",
       "165                                0.729964  -1.344446         1.339914   \n",
       "166                                0.718796  -1.381638         1.313790   \n",
       "167                                0.707629  -1.411208         1.287929   \n",
       "168                                0.696461  -1.412953         1.259641   \n",
       "169                                0.681823  -1.491464         1.230064   \n",
       "170                                0.667184  -1.573805         1.206835   \n",
       "171                                0.652545  -1.564950         1.184830   \n",
       "172                                0.637906  -1.581584         1.164107   \n",
       "173                                0.623268  -1.565976         1.142726   \n",
       "174                                0.608629  -1.648556         1.124074   \n",
       "175                                0.593990  -1.650049         1.104711   \n",
       "176                                0.579351  -1.653957         1.083374   \n",
       "177                                0.564713  -1.652572         1.061463   \n",
       "178                                0.550074  -1.715349         1.037851   \n",
       "179                                0.535435  -1.750917         1.012823   \n",
       "180                                0.520796  -1.718448         0.988857   \n",
       "181                                0.501996  -1.733426         0.979290   \n",
       "182                                0.483195  -1.729362         0.969569   \n",
       "183                                0.464395  -1.748544         0.961387   \n",
       "184                                0.445594  -1.778060         0.952878   \n",
       "185                                0.426794  -1.773710         0.944659   \n",
       "186                                0.407993  -1.757007         0.935711   \n",
       "187                                0.389193  -1.749976         0.926582   \n",
       "188                                0.370392  -1.593005         0.922177   \n",
       "189                                0.351592  -1.351489         0.923529   \n",
       "190                                0.332791  -1.198492         0.936477   \n",
       "191                                0.313991  -1.100894         0.961618   \n",
       "\n",
       "     Sergipe - Produção de Cimento (t)  Sergipe - PIB - Estadual  \\\n",
       "162                          -0.454209                  1.161418   \n",
       "163                          -0.503123                  1.165011   \n",
       "164                          -0.562332                  1.168604   \n",
       "165                          -0.617004                  1.172197   \n",
       "166                          -0.680564                  1.175790   \n",
       "167                          -0.725299                  1.179383   \n",
       "168                          -0.772009                  1.182976   \n",
       "169                          -0.819918                  1.179999   \n",
       "170                          -0.850964                  1.177023   \n",
       "171                          -0.892669                  1.174047   \n",
       "172                          -0.908700                  1.171070   \n",
       "173                          -0.947516                  1.168094   \n",
       "174                          -0.983072                  1.165118   \n",
       "175                          -1.007099                  1.162142   \n",
       "176                          -1.018151                  1.159165   \n",
       "177                          -1.029671                  1.156189   \n",
       "178                          -1.051651                  1.153213   \n",
       "179                          -1.075345                  1.150236   \n",
       "180                          -1.100675                  1.147260   \n",
       "181                          -1.128556                  1.138857   \n",
       "182                          -1.148503                  1.130454   \n",
       "183                          -1.180467                  1.122051   \n",
       "184                          -1.178111                  1.113648   \n",
       "185                          -1.164457                  1.105245   \n",
       "186                          -1.164841                  1.096843   \n",
       "187                          -1.147300                  1.088440   \n",
       "188                          -1.137939                  1.080037   \n",
       "189                          -1.097718                  1.071634   \n",
       "190                          -1.086004                  1.063231   \n",
       "191                          -1.068009                  1.054828   \n",
       "\n",
       "     Sergipe - PIB - Construção Civil  Sergipe - PIB - Per Capita  \\\n",
       "162                         -1.452829                   -1.500286   \n",
       "163                         -1.489345                   -1.490488   \n",
       "164                         -1.525862                   -1.480691   \n",
       "165                         -1.562379                   -1.470893   \n",
       "166                         -1.598896                   -1.461095   \n",
       "167                         -1.635412                   -1.451297   \n",
       "168                         -1.671929                   -1.441499   \n",
       "169                         -1.689162                   -1.433063   \n",
       "170                         -1.706394                   -1.424626   \n",
       "171                         -1.723627                   -1.416190   \n",
       "172                         -1.740859                   -1.407753   \n",
       "173                         -1.758092                   -1.399317   \n",
       "174                         -1.775324                   -1.390880   \n",
       "175                         -1.792557                   -1.382444   \n",
       "176                         -1.809789                   -1.374007   \n",
       "177                         -1.827022                   -1.365571   \n",
       "178                         -1.844255                   -1.357134   \n",
       "179                         -1.861487                   -1.348698   \n",
       "180                         -1.878720                   -1.340261   \n",
       "181                         -1.871830                   -1.330669   \n",
       "182                         -1.864941                   -1.321078   \n",
       "183                         -1.858052                   -1.311486   \n",
       "184                         -1.851162                   -1.301894   \n",
       "185                         -1.844273                   -1.292302   \n",
       "186                         -1.837384                   -1.282710   \n",
       "187                         -1.830495                   -1.273118   \n",
       "188                         -1.823605                   -1.263526   \n",
       "189                         -1.816716                   -1.253934   \n",
       "190                         -1.809827                   -1.244342   \n",
       "191                         -1.802937                   -1.234750   \n",
       "\n",
       "     Sergipe - PIB - Preços de Mercado  Sergipe - Desemprego  \n",
       "162                          -0.455964              1.308503  \n",
       "163                          -0.438477              1.301721  \n",
       "164                          -0.420990              1.294940  \n",
       "165                          -0.403503              1.288158  \n",
       "166                          -0.386016              1.281377  \n",
       "167                          -0.368529              1.274595  \n",
       "168                          -0.351042              1.267813  \n",
       "169                          -0.355638              1.264943  \n",
       "170                          -0.360235              1.262073  \n",
       "171                          -0.364831              1.259203  \n",
       "172                          -0.369428              1.256333  \n",
       "173                          -0.374024              1.253463  \n",
       "174                          -0.378620              1.250592  \n",
       "175                          -0.383217              1.247722  \n",
       "176                          -0.387813              1.244852  \n",
       "177                          -0.392410              1.241982  \n",
       "178                          -0.397006              1.239112  \n",
       "179                          -0.401603              1.236242  \n",
       "180                          -0.406199              1.233372  \n",
       "181                          -0.401748              1.229374  \n",
       "182                          -0.397297              1.225377  \n",
       "183                          -0.392847              1.221380  \n",
       "184                          -0.388396              1.217382  \n",
       "185                          -0.383945              1.213385  \n",
       "186                          -0.379494              1.209388  \n",
       "187                          -0.375044              1.205390  \n",
       "188                          -0.370593              1.201393  \n",
       "189                          -0.366142              1.197396  \n",
       "190                          -0.361691              1.193399  \n",
       "191                          -0.357241              1.189401  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    36.174\n",
       "163    38.394\n",
       "164    35.688\n",
       "165    42.076\n",
       "166    39.875\n",
       "167    38.984\n",
       "168    41.652\n",
       "169    33.904\n",
       "170    29.447\n",
       "171    29.197\n",
       "172    26.297\n",
       "173    29.209\n",
       "174    28.158\n",
       "175    31.132\n",
       "176    30.195\n",
       "177    31.537\n",
       "178    30.748\n",
       "179    30.734\n",
       "180    36.567\n",
       "181    30.849\n",
       "182    31.021\n",
       "183    31.437\n",
       "184    31.533\n",
       "185    26.431\n",
       "186    25.978\n",
       "187    29.860\n",
       "188    39.045\n",
       "189    45.213\n",
       "190    42.237\n",
       "191    39.732\n",
       "Name: Sergipe - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    train, train_val = validation_splitter(train_input, 6)\n",
    "    target,target_val = validation_splitter(train_target, 6)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val,target_val),\n",
    "#                         validation_split=0.07,\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4275842662, 3763000187, 4258013487, 1108331720, 3957147699, 1265918454, 2465243761, 3192349287, 2088304250, 2492047360, 2584724075, 886796811, 2409995501, 653697939, 2104529171, 443762208, 3905717085, 2098735409, 1141887323, 53913117, 3465569774, 833137083, 2494261180, 1835415702, 484220725]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 8.520135879516602\n",
      "winner_seed: 4275842662\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 11.903101921081543\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 9.789751052856445\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 11.427339553833008\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 10.681568145751953\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 9.971320152282715\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 8.66307258605957\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 11.673982620239258\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 8.84193229675293\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 13.487552642822266\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 11.751928329467773\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 11.887622833251953\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 12.128560066223145\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 9.394797325134277\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 8.416400909423828\n",
      "winner_seed: 2104529171\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 11.777216911315918\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 8.139666557312012\n",
      "winner_seed: 3905717085\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 11.45745849609375\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 8.842756271362305\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 11.083086967468262\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 8.301704406738281\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 10.950098037719727\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 11.43695068359375\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 9.801298141479492\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 11.920415878295898\n",
      "\n",
      "\n",
      "final_seed: 3905717085\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1658.5546 - val_loss: 1491.2922\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1197.6826 - val_loss: 1012.9887\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 309.6773 - val_loss: 40.1048\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.8866 - val_loss: 28.6067\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9359 - val_loss: 19.5852\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.9613 - val_loss: 2200.7244\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1868.9606 - val_loss: 897.6010\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 595.4797 - val_loss: 969.3063\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 566.4390 - val_loss: 152.0195\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 113.4393 - val_loss: 75.5330\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.0852 - val_loss: 25.4125\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4266 - val_loss: 33.0084\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6481 - val_loss: 17.7370\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4618 - val_loss: 16.3949\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.7000 - val_loss: 19.7388\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.7266 - val_loss: 21.6533\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.1536 - val_loss: 23.7780\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.5237 - val_loss: 22.5532\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11.7481 - val_loss: 20.8172\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.2171 - val_loss: 37.7798\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1013 - val_loss: 18.0857\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.9098 - val_loss: 16.0765\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1761 - val_loss: 30.6332\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.9337 - val_loss: 32.3149\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.0774 - val_loss: 16.8848\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.7291 - val_loss: 17.2498\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.7548 - val_loss: 17.6196\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.7042 - val_loss: 14.8539\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.8349 - val_loss: 14.7476\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.5936 - val_loss: 19.5188\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.7796 - val_loss: 21.4874\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.4370 - val_loss: 14.9764\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6720 - val_loss: 20.4291\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.4354 - val_loss: 18.4789\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.2951 - val_loss: 15.7248\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1887 - val_loss: 18.2300\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.8206 - val_loss: 17.9952\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1774 - val_loss: 21.9141\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1429 - val_loss: 14.7227\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1872 - val_loss: 14.2084\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.9715 - val_loss: 25.7269\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.1413 - val_loss: 18.0429\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8022 - val_loss: 19.8551\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.1168 - val_loss: 19.4728\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7037 - val_loss: 13.0767\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6461 - val_loss: 15.7587\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5436 - val_loss: 16.7853\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.0698 - val_loss: 25.7844\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.7063 - val_loss: 22.1233\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.7248 - val_loss: 17.3918\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.3093 - val_loss: 17.5632\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.2948 - val_loss: 21.0044\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1037 - val_loss: 15.6826\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6911 - val_loss: 15.1766\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.1427 - val_loss: 15.0563\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.5935 - val_loss: 19.1216\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.9811 - val_loss: 19.7361\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.6238 - val_loss: 14.6409\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.8477 - val_loss: 17.4531\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9685 - val_loss: 15.3269\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5415 - val_loss: 14.5440\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.7725 - val_loss: 17.4508\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.5912 - val_loss: 12.7542\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2676 - val_loss: 13.0027\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4023 - val_loss: 14.7735\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.7105 - val_loss: 15.3123\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2980 - val_loss: 17.1328\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.3460 - val_loss: 15.7326\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.4184 - val_loss: 12.6388\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.9120 - val_loss: 15.7055\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.8689 - val_loss: 32.8807\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3653 - val_loss: 15.1376\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.2767 - val_loss: 15.1234\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.6064 - val_loss: 15.8181\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.4494 - val_loss: 13.1896\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.0747 - val_loss: 13.1460\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6225 - val_loss: 29.6075\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.8469 - val_loss: 13.4596\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3985 - val_loss: 14.0050\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3541 - val_loss: 18.6450\n",
      "Epoch 81/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 8.3834 - val_loss: 15.5867\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.8395 - val_loss: 14.1013\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7305 - val_loss: 15.1996\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.2582 - val_loss: 13.5403\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.0489 - val_loss: 15.3377\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.0001 - val_loss: 15.1996\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4475 - val_loss: 15.4958\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.4319 - val_loss: 15.8349\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9181 - val_loss: 13.8498\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.0688 - val_loss: 13.9005\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.1036 - val_loss: 15.9060\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7238 - val_loss: 15.2349\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2716 - val_loss: 13.8281\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.4259 - val_loss: 13.1430\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.4975 - val_loss: 12.9808\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3910 - val_loss: 12.1491\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.0587 - val_loss: 12.7495\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.4332 - val_loss: 13.8868\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.0782 - val_loss: 12.8118\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.0710 - val_loss: 14.4068\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5354 - val_loss: 15.0983\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2417 - val_loss: 18.2734\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2624 - val_loss: 16.7524\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7685 - val_loss: 13.5086\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5930 - val_loss: 14.1796\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3198 - val_loss: 17.9286\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3499 - val_loss: 16.4178\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.8524 - val_loss: 16.7552\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6254 - val_loss: 17.4791\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5985 - val_loss: 17.9008\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.4882 - val_loss: 15.4770\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5068 - val_loss: 13.1599\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1319 - val_loss: 14.4614\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.1609 - val_loss: 15.1904\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.9010 - val_loss: 15.7984\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.2608 - val_loss: 14.8422\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.0138 - val_loss: 21.4654\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2886 - val_loss: 15.5902\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.4680 - val_loss: 25.4568\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.5327 - val_loss: 14.5020\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9245 - val_loss: 13.6019\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2297 - val_loss: 13.0457\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8493 - val_loss: 16.7595\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3842 - val_loss: 25.4261\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1303 - val_loss: 22.9033\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1643 - val_loss: 13.5375\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0817 - val_loss: 13.5519\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5648 - val_loss: 13.4925\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6524 - val_loss: 12.4213\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4157 - val_loss: 15.7105\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9812 - val_loss: 17.1793\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1769 - val_loss: 13.8449\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9753 - val_loss: 13.5853\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9006 - val_loss: 15.3970\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8737 - val_loss: 13.0384\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3054 - val_loss: 13.8358\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4102 - val_loss: 12.4557\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.6302 - val_loss: 12.6567\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3827 - val_loss: 13.6602\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2807 - val_loss: 16.9680\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.2952 - val_loss: 10.6772\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7615 - val_loss: 10.9892\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4396 - val_loss: 16.1924\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.0772 - val_loss: 26.8259\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.6617 - val_loss: 21.7820\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.3314 - val_loss: 15.1297\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0036 - val_loss: 17.8204\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.0417 - val_loss: 19.3922\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.3493 - val_loss: 29.1268\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.4273 - val_loss: 17.2933\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9526 - val_loss: 19.9722\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.3178 - val_loss: 14.3400\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.9214 - val_loss: 13.5282\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7054 - val_loss: 13.9910\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4984 - val_loss: 12.9553\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1884 - val_loss: 12.7405\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3152 - val_loss: 18.1410\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.8179 - val_loss: 16.2836\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1460 - val_loss: 15.7157\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7612 - val_loss: 17.5705\n",
      "Epoch 161/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3296 - val_loss: 22.1248\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.1774 - val_loss: 14.1492\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0450 - val_loss: 15.3477\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6388 - val_loss: 21.0966\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5323 - val_loss: 23.9086\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2883 - val_loss: 16.8561\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9691 - val_loss: 14.2586\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7618 - val_loss: 14.3101\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1715 - val_loss: 15.0927\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6436 - val_loss: 14.4976\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0129 - val_loss: 18.8642\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7323 - val_loss: 21.1441\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2788 - val_loss: 14.5619\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0745 - val_loss: 14.3926\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.4857 - val_loss: 13.1151\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.7223 - val_loss: 12.5881\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8350 - val_loss: 18.1475\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9298 - val_loss: 18.6234\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.6542 - val_loss: 13.6011\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6287 - val_loss: 13.8055\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.1622 - val_loss: 16.6652\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.3230 - val_loss: 15.2305\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1570 - val_loss: 15.0378\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5445 - val_loss: 13.1915\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4216 - val_loss: 16.2242\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6613 - val_loss: 16.5962\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.1970 - val_loss: 18.5503\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.4571 - val_loss: 12.7840\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3472 - val_loss: 15.6036\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2441 - val_loss: 14.4480\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.6111 - val_loss: 14.1948\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7226 - val_loss: 14.6839\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6985 - val_loss: 16.2776\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8598 - val_loss: 12.9249\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3166 - val_loss: 14.9198\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.9451 - val_loss: 13.4737\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6135 - val_loss: 12.6492\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3652 - val_loss: 26.8719\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.7644 - val_loss: 16.2091\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9579 - val_loss: 15.4646\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5533 - val_loss: 17.3127\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.1860 - val_loss: 14.3193\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.9091 - val_loss: 13.8216\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.4582 - val_loss: 11.5833\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6779 - val_loss: 13.8488\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.2801 - val_loss: 12.5783\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5448 - val_loss: 18.1502\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7886 - val_loss: 12.9098\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2724 - val_loss: 14.6584\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0816 - val_loss: 14.6743\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2165 - val_loss: 15.2184\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9495 - val_loss: 12.7394\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.2603 - val_loss: 13.4623\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.5998 - val_loss: 14.2347\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.2191 - val_loss: 23.6420\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8257 - val_loss: 13.8968\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6938 - val_loss: 14.3499\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2486 - val_loss: 12.0606\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7801 - val_loss: 13.6478\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.8989 - val_loss: 13.7449\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3766 - val_loss: 17.9380\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4599 - val_loss: 13.7949\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4949 - val_loss: 14.5267\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6489 - val_loss: 11.7527\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9928 - val_loss: 12.6842\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.5055 - val_loss: 12.7051\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6527 - val_loss: 11.8134\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7373 - val_loss: 14.1885\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6554 - val_loss: 19.6263\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2879 - val_loss: 13.2160\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0237 - val_loss: 17.3682\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5639 - val_loss: 21.9636\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5306 - val_loss: 12.9077\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7042 - val_loss: 12.3605\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8450 - val_loss: 12.1827\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3361 - val_loss: 12.0301\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0991 - val_loss: 12.7393\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6973 - val_loss: 12.7749\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9839 - val_loss: 13.7284\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.6628 - val_loss: 14.1728\n",
      "Epoch 241/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3214 - val_loss: 12.9523\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7067 - val_loss: 19.2807\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.9293 - val_loss: 14.8345\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7180 - val_loss: 17.3085\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.8446 - val_loss: 15.2767\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6001 - val_loss: 14.3085\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0467 - val_loss: 13.9365\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1381 - val_loss: 14.2763\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8619 - val_loss: 13.9076\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.5991 - val_loss: 13.0670\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.7874 - val_loss: 14.0577\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9952 - val_loss: 15.7271\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8937 - val_loss: 17.7823\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1206 - val_loss: 14.4331\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7419 - val_loss: 14.5345\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0350 - val_loss: 13.5609\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.5380 - val_loss: 16.8585\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8399 - val_loss: 17.3954\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6601 - val_loss: 13.4483\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4178 - val_loss: 13.1949\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8265 - val_loss: 12.3088\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2386 - val_loss: 13.4722\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4078 - val_loss: 12.4214\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0329 - val_loss: 12.4481\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7259 - val_loss: 11.3614\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5723 - val_loss: 12.6613\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.6950 - val_loss: 13.8368\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4607 - val_loss: 12.5678\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2459 - val_loss: 15.9327\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4715 - val_loss: 12.7094\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4379 - val_loss: 13.8248\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4234 - val_loss: 14.9232\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2050 - val_loss: 17.0535\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.3964 - val_loss: 13.2714\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8098 - val_loss: 16.3614\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5198 - val_loss: 12.8573\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.5257 - val_loss: 13.5320\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7927 - val_loss: 14.1233\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8563 - val_loss: 14.5383\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6248 - val_loss: 20.8775\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3980 - val_loss: 14.2118\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1035 - val_loss: 15.2166\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6018 - val_loss: 14.0551\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.8871 - val_loss: 12.5242\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0693 - val_loss: 12.8235\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.3511 - val_loss: 11.0300\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5805 - val_loss: 14.3752\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.9657 - val_loss: 12.6238\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.6544 - val_loss: 12.7745\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.8496 - val_loss: 13.4099\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8252 - val_loss: 11.9663\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.2402 - val_loss: 14.4775\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.3341 - val_loss: 13.8497\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3030 - val_loss: 19.0791\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0253 - val_loss: 12.4640\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.8306 - val_loss: 12.5890\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6669 - val_loss: 13.0360\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.2209 - val_loss: 11.9515\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7448 - val_loss: 11.4959\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5966 - val_loss: 12.5447\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4263 - val_loss: 10.8715\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.3348 - val_loss: 13.4978\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.8703 - val_loss: 11.6809\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5943 - val_loss: 11.9580\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5175 - val_loss: 22.3727\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.6459 - val_loss: 13.1822\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9258 - val_loss: 16.8907\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4865 - val_loss: 16.4941\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9729 - val_loss: 13.1751\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.7520 - val_loss: 12.7536\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6215 - val_loss: 12.4380\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0295 - val_loss: 14.7916\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.8720 - val_loss: 16.4743\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7020 - val_loss: 13.9019\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0433 - val_loss: 13.9142\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2726 - val_loss: 11.9624\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1604 - val_loss: 13.3720\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1424 - val_loss: 12.4981\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0474 - val_loss: 11.3778\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5518 - val_loss: 12.5949\n",
      "Epoch 321/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9719 - val_loss: 13.1555\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9131 - val_loss: 12.3837\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5158 - val_loss: 16.0453\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.3580 - val_loss: 23.0444\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.8467 - val_loss: 13.4149\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9903 - val_loss: 12.4806\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7347 - val_loss: 11.2962\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5765 - val_loss: 13.2860\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1762 - val_loss: 13.3976\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5143 - val_loss: 12.6060\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5971 - val_loss: 12.3154\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3814 - val_loss: 12.2108\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4250 - val_loss: 12.3961\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8567 - val_loss: 11.9578\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2143 - val_loss: 12.6922\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5454 - val_loss: 12.2305\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2020 - val_loss: 12.7491\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5171 - val_loss: 11.4419\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4435 - val_loss: 13.7807\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.6379 - val_loss: 15.2742\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.7325 - val_loss: 17.4557\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2924 - val_loss: 17.0260\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0873 - val_loss: 15.5757\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7670 - val_loss: 13.0371\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.2723 - val_loss: 13.5637\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6807 - val_loss: 13.2553\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.2681 - val_loss: 12.9918\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9229 - val_loss: 13.0531\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.2718 - val_loss: 13.4182\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7086 - val_loss: 14.2866\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5250 - val_loss: 15.2997\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7565 - val_loss: 13.0073\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0695 - val_loss: 17.3770\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8151 - val_loss: 14.0216\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2461 - val_loss: 13.1001\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7065 - val_loss: 12.6083\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5414 - val_loss: 15.8570\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5874 - val_loss: 10.9112\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6365 - val_loss: 11.8511\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1025 - val_loss: 17.9831\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5306 - val_loss: 16.4351\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3097 - val_loss: 15.7957\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5706 - val_loss: 12.1681\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4120 - val_loss: 12.6061\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7712 - val_loss: 15.4067\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1421 - val_loss: 12.4034\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5481 - val_loss: 13.7860\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9511 - val_loss: 12.1128\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5434 - val_loss: 12.9667\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2939 - val_loss: 12.4774\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8327 - val_loss: 13.5749\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8186 - val_loss: 13.1260\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1150 - val_loss: 11.7720\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5268 - val_loss: 13.0927\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5172 - val_loss: 14.5937\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6297 - val_loss: 15.8433\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.3690 - val_loss: 10.7500\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3769 - val_loss: 14.5040\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6991 - val_loss: 11.8437\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5226 - val_loss: 15.2545\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4332 - val_loss: 12.6546\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.1158 - val_loss: 14.6195\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9442 - val_loss: 13.5077\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8748 - val_loss: 15.9706\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2805 - val_loss: 11.8682\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7857 - val_loss: 12.0685\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.1957 - val_loss: 16.4466\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7327 - val_loss: 14.5639\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6185 - val_loss: 13.0006\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4523 - val_loss: 11.9301\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1453 - val_loss: 10.8454\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9623 - val_loss: 13.3879\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9258 - val_loss: 10.3304\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6574 - val_loss: 13.3309\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7530 - val_loss: 11.5057\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9213 - val_loss: 12.7221\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9208 - val_loss: 11.7694\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.8744 - val_loss: 12.7512\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7054 - val_loss: 11.6431\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7198 - val_loss: 14.2177\n",
      "Epoch 401/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3336 - val_loss: 12.5216\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6489 - val_loss: 12.6582\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7408 - val_loss: 16.0916\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0219 - val_loss: 14.0784\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5491 - val_loss: 11.0230\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2778 - val_loss: 15.7611\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0940 - val_loss: 12.6816\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9922 - val_loss: 14.1873\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4708 - val_loss: 14.7058\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7163 - val_loss: 13.5365\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2996 - val_loss: 13.9771\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8960 - val_loss: 12.6013\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4489 - val_loss: 11.1718\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4973 - val_loss: 13.0681\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5170 - val_loss: 11.9957\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6363 - val_loss: 11.3260\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1046 - val_loss: 12.3199\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3204 - val_loss: 14.8680\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8837 - val_loss: 14.4945\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2377 - val_loss: 11.8529\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9288 - val_loss: 12.1443\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1243 - val_loss: 11.7976\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0529 - val_loss: 11.5693\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0173 - val_loss: 13.1536\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7070 - val_loss: 13.3345\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1012 - val_loss: 13.5975\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2294 - val_loss: 11.2631\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9657 - val_loss: 11.3442\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7008 - val_loss: 12.6061\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5637 - val_loss: 11.6045\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0754 - val_loss: 13.4830\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1949 - val_loss: 13.4006\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1241 - val_loss: 17.0468\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2756 - val_loss: 12.1348\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0974 - val_loss: 11.4407\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6788 - val_loss: 14.6324\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1645 - val_loss: 11.5637\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.0183 - val_loss: 13.1976\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4086 - val_loss: 11.0524\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5275 - val_loss: 12.8494\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9613 - val_loss: 11.3986\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3944 - val_loss: 14.3698\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4746 - val_loss: 11.6277\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1758 - val_loss: 12.2753\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9931 - val_loss: 12.7659\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4381 - val_loss: 15.7025\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0501 - val_loss: 16.2097\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9423 - val_loss: 16.3452\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9263 - val_loss: 14.4793\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6569 - val_loss: 14.2940\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0140 - val_loss: 14.5681\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.9704 - val_loss: 16.1279\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1742 - val_loss: 13.3097\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5527 - val_loss: 13.8913\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5813 - val_loss: 12.0986\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2484 - val_loss: 12.0826\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6322 - val_loss: 16.5903\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5213 - val_loss: 12.4689\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9646 - val_loss: 17.4698\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3577 - val_loss: 12.4047\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5332 - val_loss: 11.0648\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5843 - val_loss: 12.2116\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9060 - val_loss: 19.5368\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1546 - val_loss: 12.1612\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4087 - val_loss: 14.7830\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2353 - val_loss: 12.3932\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3067 - val_loss: 12.2479\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0719 - val_loss: 11.8825\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8448 - val_loss: 12.9578\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0018 - val_loss: 10.9228\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4393 - val_loss: 12.9716\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0897 - val_loss: 12.4230\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4810 - val_loss: 13.9477\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7410 - val_loss: 12.9368\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7405 - val_loss: 14.2217\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9381 - val_loss: 12.7111\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6643 - val_loss: 11.4824\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3715 - val_loss: 17.2887\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0542 - val_loss: 11.1609\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5645 - val_loss: 10.8004\n",
      "Epoch 481/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5973 - val_loss: 10.6955\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8278 - val_loss: 15.2457\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9994 - val_loss: 11.5009\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0802 - val_loss: 11.7308\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2230 - val_loss: 12.2468\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6961 - val_loss: 12.5205\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8451 - val_loss: 12.2810\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4206 - val_loss: 12.2729\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7833 - val_loss: 11.5311\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8074 - val_loss: 10.8376\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8007 - val_loss: 10.2580\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6161 - val_loss: 11.0122\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1841 - val_loss: 11.5795\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0932 - val_loss: 12.5903\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1971 - val_loss: 12.5945\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4563 - val_loss: 11.2692\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0447 - val_loss: 12.2168\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9195 - val_loss: 12.2055\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4085 - val_loss: 14.2826\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6985 - val_loss: 11.8235\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.7884 - val_loss: 12.5467\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9474 - val_loss: 14.2153\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2245 - val_loss: 13.4987\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.6565 - val_loss: 17.6891\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6010 - val_loss: 14.3662\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.8841 - val_loss: 11.2950\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.7676 - val_loss: 10.3265\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6822 - val_loss: 12.1510\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3597 - val_loss: 13.0524\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7318 - val_loss: 13.5990\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1643 - val_loss: 12.8383\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4958 - val_loss: 13.3465\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2828 - val_loss: 13.6047\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3090 - val_loss: 13.2009\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9549 - val_loss: 12.2826\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3479 - val_loss: 11.6509\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4944 - val_loss: 11.4256\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2591 - val_loss: 11.0961\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2399 - val_loss: 16.7259\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8873 - val_loss: 14.4886\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0436 - val_loss: 12.0788\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8423 - val_loss: 12.4479\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0599 - val_loss: 12.3689\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5654 - val_loss: 11.1302\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1287 - val_loss: 10.8083\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1442 - val_loss: 14.3921\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3708 - val_loss: 12.2960\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9658 - val_loss: 13.2650\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9996 - val_loss: 13.4465\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7687 - val_loss: 15.0468\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0636 - val_loss: 14.3995\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5529 - val_loss: 12.0127\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2964 - val_loss: 11.7403\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4006 - val_loss: 12.3298\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7973 - val_loss: 13.0287\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9493 - val_loss: 12.4848\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7891 - val_loss: 14.1525\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5249 - val_loss: 13.9728\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0308 - val_loss: 13.2458\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3673 - val_loss: 13.7923\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 129.4854 - val_loss: 15.4281\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.3836 - val_loss: 14.0291\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2815 - val_loss: 13.1875\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3808 - val_loss: 13.7387\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7072 - val_loss: 15.2580\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.4335 - val_loss: 15.3879\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5157 - val_loss: 17.9707\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.2856 - val_loss: 14.2316\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6884 - val_loss: 11.5559\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1322 - val_loss: 14.4074\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.0423 - val_loss: 15.5718\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1541 - val_loss: 15.2172\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7990 - val_loss: 14.2581\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7468 - val_loss: 12.5062\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7195 - val_loss: 16.4757\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.3921 - val_loss: 13.4636\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.5340 - val_loss: 13.3007\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4469 - val_loss: 14.1011\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7005 - val_loss: 10.5642\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9121 - val_loss: 11.2087\n",
      "Epoch 561/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6807 - val_loss: 14.5829\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3222 - val_loss: 11.6547\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9935 - val_loss: 14.3090\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3944 - val_loss: 11.4579\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5417 - val_loss: 18.1340\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.3403 - val_loss: 12.3271\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6390 - val_loss: 14.9668\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0731 - val_loss: 12.0323\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8659 - val_loss: 12.8870\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8716 - val_loss: 12.6146\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1152 - val_loss: 10.6788\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8495 - val_loss: 10.6184\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5232 - val_loss: 17.8647\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9041 - val_loss: 23.7486\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.1930 - val_loss: 16.8152\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.3193 - val_loss: 17.4508\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.0295 - val_loss: 12.9414\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6145 - val_loss: 14.7820\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.8616 - val_loss: 13.5817\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.5866 - val_loss: 14.4735\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.4222 - val_loss: 12.2834\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9445 - val_loss: 14.1702\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1940 - val_loss: 18.8515\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1418 - val_loss: 15.8049\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2664 - val_loss: 12.3551\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.8705 - val_loss: 22.7418\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.7359 - val_loss: 12.6656\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.2878 - val_loss: 14.5553\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5582 - val_loss: 12.5500\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9820 - val_loss: 14.4127\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1095 - val_loss: 13.4134\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8337 - val_loss: 13.5136\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7719 - val_loss: 16.2313\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7795 - val_loss: 13.2481\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8406 - val_loss: 18.0777\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7268 - val_loss: 13.7081\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5765 - val_loss: 12.8333\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5791 - val_loss: 19.0534\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8498 - val_loss: 13.7307\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2170 - val_loss: 13.5603\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3043 - val_loss: 12.5476\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9338 - val_loss: 12.5031\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5241 - val_loss: 23.5987\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2358 - val_loss: 12.5788\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.8748 - val_loss: 13.6183\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.2628 - val_loss: 15.5198\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0832 - val_loss: 16.1723\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4550 - val_loss: 13.8414\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0768 - val_loss: 13.2917\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1908 - val_loss: 12.2881\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4587 - val_loss: 14.1892\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0300 - val_loss: 14.6539\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8926 - val_loss: 13.9577\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5812 - val_loss: 13.6035\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4948 - val_loss: 12.4294\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4139 - val_loss: 20.8281\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4416 - val_loss: 14.1204\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9350 - val_loss: 14.8858\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2724 - val_loss: 15.6738\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9717 - val_loss: 11.8218\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5279 - val_loss: 13.0251\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6752 - val_loss: 10.4292\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3275 - val_loss: 11.3661\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8809 - val_loss: 13.0866\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7847 - val_loss: 10.5998\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4084 - val_loss: 12.0311\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5462 - val_loss: 10.8555\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8664 - val_loss: 14.6335\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5541 - val_loss: 12.3167\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0818 - val_loss: 14.8624\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3215 - val_loss: 10.7594\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2889 - val_loss: 13.9018\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4967 - val_loss: 11.9703\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3903 - val_loss: 10.7672\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1821 - val_loss: 13.4883\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4925 - val_loss: 10.9979\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6317 - val_loss: 19.0431\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.0668 - val_loss: 15.7144\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1447 - val_loss: 11.8430\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7603 - val_loss: 10.4921\n",
      "Epoch 641/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7243 - val_loss: 11.4610\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8213 - val_loss: 10.7027\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1218 - val_loss: 11.1892\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0012 - val_loss: 10.3895\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4303 - val_loss: 11.1472\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6942 - val_loss: 12.3618\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0256 - val_loss: 20.4307\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4154 - val_loss: 15.3976\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5930 - val_loss: 11.7496\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0168 - val_loss: 11.6555\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2894 - val_loss: 14.6394\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.3475 - val_loss: 11.9811\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5203 - val_loss: 11.8981\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9797 - val_loss: 14.5714\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3190 - val_loss: 13.1429\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1129 - val_loss: 13.2704\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4955 - val_loss: 15.6764\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.8989 - val_loss: 11.1514\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6831 - val_loss: 14.4783\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3430 - val_loss: 10.1395\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1928 - val_loss: 11.1686\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2265 - val_loss: 12.9630\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0837 - val_loss: 12.1200\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5421 - val_loss: 12.5683\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5321 - val_loss: 12.8777\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.9010 - val_loss: 25.5359\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.1820 - val_loss: 14.4675\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.1134 - val_loss: 11.8485\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5316 - val_loss: 11.9736\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4142 - val_loss: 11.9791\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3155 - val_loss: 12.9733\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.3414 - val_loss: 11.9089\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1926 - val_loss: 9.6463\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7723 - val_loss: 10.2463\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7649 - val_loss: 11.4641\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1041 - val_loss: 11.0885\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8977 - val_loss: 10.1760\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1241 - val_loss: 11.9298\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2691 - val_loss: 12.0157\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0991 - val_loss: 11.6502\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8847 - val_loss: 14.9694\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9926 - val_loss: 11.7056\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2489 - val_loss: 12.6125\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3628 - val_loss: 10.6706\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9235 - val_loss: 11.0695\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0512 - val_loss: 11.5189\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4153 - val_loss: 11.0987\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2510 - val_loss: 11.2288\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5314 - val_loss: 12.2141\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6700 - val_loss: 12.5691\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1219 - val_loss: 10.9632\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7747 - val_loss: 11.0534\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9424 - val_loss: 13.0824\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2693 - val_loss: 12.8001\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4659 - val_loss: 12.0617\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2999 - val_loss: 12.0462\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2205 - val_loss: 13.9576\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8397 - val_loss: 13.0368\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7041 - val_loss: 10.5065\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3627 - val_loss: 12.6799\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4522 - val_loss: 13.8265\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1052 - val_loss: 17.1877\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8546 - val_loss: 11.7062\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0498 - val_loss: 11.8446\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4273 - val_loss: 10.5433\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4596 - val_loss: 12.4939\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0128 - val_loss: 12.7015\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4277 - val_loss: 11.1672\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8499 - val_loss: 15.2846\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.8258 - val_loss: 13.0216\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8445 - val_loss: 14.8024\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9101 - val_loss: 11.2104\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0347 - val_loss: 11.4393\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4015 - val_loss: 11.2399\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7384 - val_loss: 18.1672\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4946 - val_loss: 11.9460\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5353 - val_loss: 12.1915\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7731 - val_loss: 13.5150\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.3803 - val_loss: 11.8274\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2486 - val_loss: 14.7257\n",
      "Epoch 721/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 6.9633 - val_loss: 10.5688\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4131 - val_loss: 12.8977\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3919 - val_loss: 12.9325\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6052 - val_loss: 13.4790\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6095 - val_loss: 12.1914\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5960 - val_loss: 10.7159\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0715 - val_loss: 12.4650\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0452 - val_loss: 11.4779\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8144 - val_loss: 12.5433\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6672 - val_loss: 13.0293\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7536 - val_loss: 11.5047\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9307 - val_loss: 11.7182\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4668 - val_loss: 12.8874\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3140 - val_loss: 12.4412\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1870 - val_loss: 14.4317\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.3761 - val_loss: 12.8786\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7075 - val_loss: 12.2944\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0540 - val_loss: 12.0390\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5237 - val_loss: 12.8554\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6869 - val_loss: 13.4753\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0974 - val_loss: 14.7026\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8148 - val_loss: 25.9793\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.4465 - val_loss: 11.8945\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6077 - val_loss: 11.1125\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1135 - val_loss: 13.4744\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3927 - val_loss: 12.0321\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1033 - val_loss: 11.4115\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6306 - val_loss: 10.9634\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0493 - val_loss: 11.0736\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9975 - val_loss: 11.5924\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3131 - val_loss: 11.8743\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7767 - val_loss: 12.8293\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9724 - val_loss: 11.6163\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6667 - val_loss: 12.4178\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9276 - val_loss: 11.8013\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5607 - val_loss: 11.8039\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8533 - val_loss: 14.1306\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6726 - val_loss: 12.2997\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5906 - val_loss: 12.4051\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0610 - val_loss: 11.2953\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9806 - val_loss: 12.4102\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9947 - val_loss: 13.9624\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1752 - val_loss: 10.5328\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9692 - val_loss: 11.4489\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9299 - val_loss: 11.1284\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8714 - val_loss: 18.8632\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6949 - val_loss: 10.6901\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9235 - val_loss: 11.9319\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9030 - val_loss: 12.1072\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9947 - val_loss: 16.0115\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7151 - val_loss: 12.2785\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4602 - val_loss: 15.4419\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.1208 - val_loss: 11.5113\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7774 - val_loss: 12.8357\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6232 - val_loss: 13.0080\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4189 - val_loss: 13.4129\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2867 - val_loss: 12.4466\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3155 - val_loss: 10.4909\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2725 - val_loss: 11.6569\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1778 - val_loss: 14.4049\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1400 - val_loss: 12.6951\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9963 - val_loss: 16.6197\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0443 - val_loss: 14.4540\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9311 - val_loss: 12.8935\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6181 - val_loss: 16.1508\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6132 - val_loss: 12.8172\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5789 - val_loss: 11.0024\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5390 - val_loss: 14.4578\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3104 - val_loss: 11.9200\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2227 - val_loss: 10.7657\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2831 - val_loss: 10.6890\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4408 - val_loss: 12.0078\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3828 - val_loss: 15.7766\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3333 - val_loss: 13.5134\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4043 - val_loss: 13.0927\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1701 - val_loss: 11.4877\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3444 - val_loss: 12.5611\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6113 - val_loss: 11.6213\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0319 - val_loss: 14.8345\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6532 - val_loss: 13.1097\n",
      "Epoch 801/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9871 - val_loss: 11.3424\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5370 - val_loss: 12.1352\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5284 - val_loss: 10.4827\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6370 - val_loss: 12.4555\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9376 - val_loss: 11.5509\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8941 - val_loss: 12.5839\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0154 - val_loss: 15.1521\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.2572 - val_loss: 11.2219\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8775 - val_loss: 11.8797\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7499 - val_loss: 12.2136\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9380 - val_loss: 12.2679\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2758 - val_loss: 10.8790\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9709 - val_loss: 11.0281\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2276 - val_loss: 14.7842\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6627 - val_loss: 11.1857\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9040 - val_loss: 13.8772\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0362 - val_loss: 10.3089\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8568 - val_loss: 11.6132\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7993 - val_loss: 11.3171\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9667 - val_loss: 10.3973\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7146 - val_loss: 10.0252\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9931 - val_loss: 11.5262\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3336 - val_loss: 14.0679\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4169 - val_loss: 16.5635\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7764 - val_loss: 11.1145\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3366 - val_loss: 14.3399\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4102 - val_loss: 10.3798\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5871 - val_loss: 15.0683\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.8066 - val_loss: 12.1712\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5993 - val_loss: 12.0053\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5964 - val_loss: 11.3308\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9573 - val_loss: 12.6916\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9366 - val_loss: 13.4701\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0810 - val_loss: 11.4188\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9552 - val_loss: 12.2466\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8695 - val_loss: 14.0949\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3231 - val_loss: 15.7051\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8593 - val_loss: 12.7822\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3870 - val_loss: 11.4355\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5121 - val_loss: 11.5143\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7746 - val_loss: 10.5052\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3143 - val_loss: 12.0950\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9099 - val_loss: 13.3700\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5319 - val_loss: 13.5682\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0380 - val_loss: 12.2188\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1978 - val_loss: 14.1677\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5217 - val_loss: 13.5650\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3746 - val_loss: 12.5650\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6649 - val_loss: 11.7823\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9405 - val_loss: 10.9556\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6873 - val_loss: 10.5366\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2125 - val_loss: 11.6646\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7529 - val_loss: 10.9131\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9645 - val_loss: 10.0284\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4223 - val_loss: 10.4075\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3433 - val_loss: 14.7101\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4787 - val_loss: 12.7168\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0255 - val_loss: 11.1050\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.1288 - val_loss: 10.2822\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9611 - val_loss: 10.7633\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4904 - val_loss: 10.5335\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4772 - val_loss: 10.5536\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3895 - val_loss: 11.4733\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5854 - val_loss: 10.5910\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5489 - val_loss: 10.4161\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7946 - val_loss: 12.6697\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1551 - val_loss: 10.6323\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9536 - val_loss: 12.9390\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9702 - val_loss: 11.5775\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0707 - val_loss: 9.2980\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6636 - val_loss: 11.2232\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2721 - val_loss: 8.1397\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4669 - val_loss: 9.1253\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4199 - val_loss: 12.9377\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1201 - val_loss: 11.5427\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0029 - val_loss: 11.2436\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9359 - val_loss: 11.0451\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7488 - val_loss: 11.9106\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1435 - val_loss: 14.0049\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3565 - val_loss: 11.5922\n",
      "Epoch 881/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8583 - val_loss: 11.1255\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2072 - val_loss: 10.2853\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9832 - val_loss: 13.9900\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7856 - val_loss: 12.7904\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8468 - val_loss: 13.1742\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0634 - val_loss: 12.0994\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3882 - val_loss: 11.3842\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8145 - val_loss: 11.4678\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4859 - val_loss: 15.7724\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.8020 - val_loss: 10.4719\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8805 - val_loss: 10.7699\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7053 - val_loss: 11.2374\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9461 - val_loss: 13.8842\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1691 - val_loss: 15.6421\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7435 - val_loss: 10.5591\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6986 - val_loss: 14.3065\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7759 - val_loss: 13.6311\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1244 - val_loss: 11.1847\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9264 - val_loss: 13.8536\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5784 - val_loss: 9.4701\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4775 - val_loss: 11.6879\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9913 - val_loss: 11.5565\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5225 - val_loss: 11.0671\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6613 - val_loss: 14.7397\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4147 - val_loss: 13.5695\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1866 - val_loss: 12.6470\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7925 - val_loss: 12.6619\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5202 - val_loss: 13.5710\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3149 - val_loss: 11.6659\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9411 - val_loss: 10.5539\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0904 - val_loss: 11.8103\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6651 - val_loss: 11.2841\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7651 - val_loss: 11.4243\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8854 - val_loss: 13.0971\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6905 - val_loss: 12.1276\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8797 - val_loss: 10.3619\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0986 - val_loss: 9.6788\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1938 - val_loss: 10.8772\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.3702 - val_loss: 11.7319\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4945 - val_loss: 12.8240\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0979 - val_loss: 14.0967\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.3518 - val_loss: 12.9924\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.6356 - val_loss: 14.1768\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.7689 - val_loss: 12.0699\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6236 - val_loss: 12.0885\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3691 - val_loss: 12.7578\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9525 - val_loss: 11.6887\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9767 - val_loss: 14.7398\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.8773 - val_loss: 12.3760\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3184 - val_loss: 11.7834\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2929 - val_loss: 13.4009\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9560 - val_loss: 11.4721\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6510 - val_loss: 12.3855\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5675 - val_loss: 11.8219\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7226 - val_loss: 13.2618\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9305 - val_loss: 13.9042\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2560 - val_loss: 11.6030\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5136 - val_loss: 11.6116\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2802 - val_loss: 11.2248\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0606 - val_loss: 12.9184\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8893 - val_loss: 11.6695\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4444 - val_loss: 13.2004\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1486 - val_loss: 14.2738\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7626 - val_loss: 11.9370\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8738 - val_loss: 13.7729\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2062 - val_loss: 11.5188\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4146 - val_loss: 13.9838\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4438 - val_loss: 11.8701\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1249 - val_loss: 14.3364\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8631 - val_loss: 13.6734\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7191 - val_loss: 12.9582\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5028 - val_loss: 12.8051\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7226 - val_loss: 13.3623\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9248 - val_loss: 12.8382\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5910 - val_loss: 15.2433\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2470 - val_loss: 12.8739\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1009 - val_loss: 12.6903\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0181 - val_loss: 11.9902\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1032 - val_loss: 12.2485\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1096 - val_loss: 12.8290\n",
      "Epoch 961/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1174 - val_loss: 11.5971\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7991 - val_loss: 13.5409\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2845 - val_loss: 19.5284\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.6733 - val_loss: 17.7754\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1235 - val_loss: 14.3662\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4596 - val_loss: 14.3071\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8765 - val_loss: 12.7444\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1790 - val_loss: 11.8176\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4075 - val_loss: 13.6923\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5609 - val_loss: 11.9084\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6076 - val_loss: 11.5163\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2039 - val_loss: 11.3389\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0540 - val_loss: 14.3586\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3637 - val_loss: 12.5840\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1417 - val_loss: 12.8792\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1131 - val_loss: 12.1816\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0026 - val_loss: 14.4385\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4935 - val_loss: 11.7565\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8451 - val_loss: 13.0535\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6084 - val_loss: 12.4043\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9036 - val_loss: 12.0025\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9729 - val_loss: 13.3121\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9944 - val_loss: 12.5162\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2361 - val_loss: 14.6222\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0516 - val_loss: 11.3422\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1563 - val_loss: 11.4115\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6325 - val_loss: 12.2253\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5053 - val_loss: 12.4579\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5319 - val_loss: 12.6959\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0947 - val_loss: 12.8153\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0438 - val_loss: 13.1707\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6359 - val_loss: 12.1493\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9020 - val_loss: 13.8367\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7029 - val_loss: 12.2365\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3470 - val_loss: 13.2025\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8878 - val_loss: 12.4038\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0222 - val_loss: 11.7581\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0992 - val_loss: 18.9697\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8970 - val_loss: 13.4012\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6331 - val_loss: 13.1239\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2590 - val_loss: 12.0409\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1412 - val_loss: 12.1625\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3456 - val_loss: 11.6074\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9094 - val_loss: 13.5053\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6716 - val_loss: 11.8025\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6451 - val_loss: 13.2501\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1168 - val_loss: 14.9648\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3387 - val_loss: 11.4850\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8469 - val_loss: 11.1078\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3102 - val_loss: 12.4651\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3270 - val_loss: 10.8033\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3770 - val_loss: 11.6488\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2872 - val_loss: 11.8063\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8292 - val_loss: 11.0332\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5573 - val_loss: 12.8409\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6945 - val_loss: 11.3738\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9009 - val_loss: 16.9445\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3471 - val_loss: 14.3456\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2177 - val_loss: 13.5906\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8153 - val_loss: 13.1987\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.2177 - val_loss: 11.1138\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7214 - val_loss: 11.1948\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2607 - val_loss: 12.1176\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8094 - val_loss: 11.1988\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4794 - val_loss: 12.7791\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3104 - val_loss: 11.7086\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7313 - val_loss: 12.5855\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1738 - val_loss: 10.9152\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2924 - val_loss: 16.4404\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8346 - val_loss: 13.7884\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1109 - val_loss: 11.5660\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8170 - val_loss: 10.2209\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1123 - val_loss: 11.4809\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5873 - val_loss: 10.8846\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8919 - val_loss: 12.4968\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1577 - val_loss: 11.7417\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0048 - val_loss: 12.5715\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3810 - val_loss: 12.9538\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4181 - val_loss: 12.2066\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1284 - val_loss: 13.3435\n",
      "Epoch 1041/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5993 - val_loss: 12.8282\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2655 - val_loss: 12.5333\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7575 - val_loss: 12.8858\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9290 - val_loss: 11.9576\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0346 - val_loss: 12.0314\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2452 - val_loss: 12.0882\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7948 - val_loss: 12.2771\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9211 - val_loss: 12.6309\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1133 - val_loss: 14.3673\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0046 - val_loss: 13.7358\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9135 - val_loss: 12.8903\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5591 - val_loss: 11.3098\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9452 - val_loss: 15.2334\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7991 - val_loss: 11.7218\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6050 - val_loss: 14.7250\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3504 - val_loss: 12.0012\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5937 - val_loss: 17.3955\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3702 - val_loss: 12.1897\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7036 - val_loss: 12.6386\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4294 - val_loss: 14.0612\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0886 - val_loss: 11.6219\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5512 - val_loss: 12.1419\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5493 - val_loss: 11.7878\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9083 - val_loss: 12.5204\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3585 - val_loss: 12.2169\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1238 - val_loss: 14.8408\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.3154 - val_loss: 14.7374\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0956 - val_loss: 14.0387\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7548 - val_loss: 15.2905\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7318 - val_loss: 12.4215\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6835 - val_loss: 11.5105\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1216 - val_loss: 11.6094\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7327 - val_loss: 12.8050\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5316 - val_loss: 12.4556\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4625 - val_loss: 11.6358\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6278 - val_loss: 11.8313\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4782 - val_loss: 11.6556\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2467 - val_loss: 13.4203\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5896 - val_loss: 12.0893\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5370 - val_loss: 12.3956\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8818 - val_loss: 11.3088\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7294 - val_loss: 12.1448\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7772 - val_loss: 11.9878\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1008 - val_loss: 13.7998\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8030 - val_loss: 12.2213\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4604 - val_loss: 16.9957\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7495 - val_loss: 13.7050\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5142 - val_loss: 13.5313\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4129 - val_loss: 14.2765\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5867 - val_loss: 12.1474\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5516 - val_loss: 12.0646\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8410 - val_loss: 11.9888\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0906 - val_loss: 12.0287\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6227 - val_loss: 13.0656\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5145 - val_loss: 11.6898\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2739 - val_loss: 13.5185\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4607 - val_loss: 11.7176\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9137 - val_loss: 11.0972\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0054 - val_loss: 12.5109\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5591 - val_loss: 11.7638\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9329 - val_loss: 11.2634\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4418 - val_loss: 11.2031\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3872 - val_loss: 12.1310\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5629 - val_loss: 15.4130\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6727 - val_loss: 11.8800\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.2249 - val_loss: 12.5704\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5096 - val_loss: 12.8792\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3514 - val_loss: 12.5990\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5481 - val_loss: 13.4907\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2971 - val_loss: 13.4726\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9144 - val_loss: 11.5911\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4136 - val_loss: 12.2065\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7182 - val_loss: 11.9311\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3934 - val_loss: 11.4668\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8151 - val_loss: 11.4913\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7254 - val_loss: 14.1853\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4158 - val_loss: 12.9743\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6229 - val_loss: 13.9511\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5988 - val_loss: 12.0244\n",
      "Epoch 1120/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7600 - val_loss: 11.6857\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7528 - val_loss: 14.9333\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9988 - val_loss: 14.2870\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1268 - val_loss: 12.4424\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5000 - val_loss: 11.5302\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5047 - val_loss: 19.6334\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5658 - val_loss: 10.8275\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5991 - val_loss: 13.1892\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0615 - val_loss: 11.7687\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6213 - val_loss: 12.5096\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5009 - val_loss: 11.5733\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4946 - val_loss: 11.6764\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5349 - val_loss: 14.5752\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2023 - val_loss: 13.0325\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6901 - val_loss: 12.0960\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3143 - val_loss: 12.0067\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4107 - val_loss: 12.0451\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7303 - val_loss: 12.4215\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9441 - val_loss: 12.5447\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5350 - val_loss: 12.3037\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4358 - val_loss: 12.7408\n",
      "Epoch 1141/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9931 - val_loss: 11.9610\n",
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7968 - val_loss: 12.1100\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5190 - val_loss: 11.8892\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8299 - val_loss: 11.9383\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3455 - val_loss: 12.0791\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6805 - val_loss: 13.2152\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9969 - val_loss: 12.8093\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6162 - val_loss: 12.4955\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0228 - val_loss: 12.4619\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7330 - val_loss: 16.7419\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9684 - val_loss: 12.8566\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7805 - val_loss: 12.2330\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7968 - val_loss: 12.3893\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5765 - val_loss: 12.3747\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.5257 - val_loss: 12.7177\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7450 - val_loss: 11.7802\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0451 - val_loss: 11.8720\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.2022 - val_loss: 11.9139\n",
      "Epoch 1159/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3018 - val_loss: 12.4884\n",
      "Epoch 1160/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3051 - val_loss: 12.2092\n",
      "Epoch 1161/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7467 - val_loss: 12.2510\n",
      "Epoch 1162/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.8052 - val_loss: 12.2397\n",
      "Epoch 1163/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1371 - val_loss: 11.4374\n",
      "Epoch 1164/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9999 - val_loss: 13.6819\n",
      "Epoch 1165/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.6711 - val_loss: 24.2698\n",
      "Epoch 1166/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.1601 - val_loss: 12.9350\n",
      "Epoch 1167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7175 - val_loss: 12.3112\n",
      "Epoch 1168/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2203 - val_loss: 14.3735\n",
      "Epoch 1169/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.4478 - val_loss: 15.4838\n",
      "Epoch 1170/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.2415 - val_loss: 17.0642\n",
      "Epoch 1171/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.7868 - val_loss: 16.3664\n",
      "Epoch 1172/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1059 - val_loss: 12.8586\n",
      "Epoch 1173/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.4535 - val_loss: 13.2025\n",
      "Epoch 1174/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5839 - val_loss: 17.2568\n",
      "Epoch 1175/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2132 - val_loss: 10.3526\n",
      "Epoch 1176/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0407 - val_loss: 11.3618\n",
      "Epoch 1177/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9835 - val_loss: 13.0503\n",
      "Epoch 1178/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9510 - val_loss: 16.6449\n",
      "Epoch 1179/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8188 - val_loss: 12.0006\n",
      "Epoch 1180/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4534 - val_loss: 12.7037\n",
      "Epoch 1181/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6699 - val_loss: 12.5444\n",
      "Epoch 1182/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1435 - val_loss: 24.7762\n",
      "Epoch 1183/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.5749 - val_loss: 14.8001\n",
      "Epoch 1184/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2240 - val_loss: 11.7838\n",
      "Epoch 1185/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1557 - val_loss: 13.3161\n",
      "Epoch 1186/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7068 - val_loss: 12.9982\n",
      "Epoch 1187/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1535 - val_loss: 13.2584\n",
      "Epoch 1188/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0392 - val_loss: 17.2333\n",
      "Epoch 1189/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3761 - val_loss: 14.5444\n",
      "Epoch 1190/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4673 - val_loss: 12.9522\n",
      "Epoch 1191/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2599 - val_loss: 15.0900\n",
      "Epoch 1192/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7870 - val_loss: 12.2109\n",
      "Epoch 1193/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7700 - val_loss: 11.9073\n",
      "Epoch 1194/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0245 - val_loss: 12.6557\n",
      "Epoch 1195/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8825 - val_loss: 12.4821\n",
      "Epoch 1196/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4550 - val_loss: 12.0103\n",
      "Epoch 1197/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1646 - val_loss: 10.9508\n",
      "Epoch 1198/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8716 - val_loss: 13.3906\n",
      "Epoch 1199/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8117 - val_loss: 11.7882\n",
      "Epoch 1200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9321 - val_loss: 13.7704\n",
      "Epoch 1201/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6186 - val_loss: 11.7403\n",
      "Epoch 1202/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7185 - val_loss: 16.4161\n",
      "Epoch 1203/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.3435 - val_loss: 13.0826\n",
      "Epoch 1204/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7606 - val_loss: 12.1751\n",
      "Epoch 1205/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.1972 - val_loss: 12.0664\n",
      "Epoch 1206/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9071 - val_loss: 14.0377\n",
      "Epoch 1207/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9049 - val_loss: 14.4025\n",
      "Epoch 1208/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5022 - val_loss: 13.2532\n",
      "Epoch 1209/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9426 - val_loss: 13.1196\n",
      "Epoch 1210/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5854 - val_loss: 11.9942\n",
      "Epoch 1211/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3030 - val_loss: 12.1366\n",
      "Epoch 1212/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0653 - val_loss: 14.4001\n",
      "Epoch 1213/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6763 - val_loss: 11.3606\n",
      "Epoch 1214/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6889 - val_loss: 11.7860\n",
      "Epoch 1215/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5359 - val_loss: 13.5182\n",
      "Epoch 1216/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9164 - val_loss: 13.9995\n",
      "Epoch 1217/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5585 - val_loss: 13.6387\n",
      "Epoch 1218/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7076 - val_loss: 12.7963\n",
      "Epoch 1219/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4373 - val_loss: 14.1866\n",
      "Epoch 1220/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4330 - val_loss: 12.9069\n",
      "Epoch 1221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3593 - val_loss: 13.0143\n",
      "Epoch 1222/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4388 - val_loss: 13.0575\n",
      "Epoch 1223/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1239 - val_loss: 12.3659\n",
      "Epoch 1224/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2784 - val_loss: 11.9712\n",
      "Epoch 1225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.2186 - val_loss: 11.2106\n",
      "Epoch 1226/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8206 - val_loss: 12.0738\n",
      "Epoch 1227/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7324 - val_loss: 15.2746\n",
      "Epoch 1228/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4799 - val_loss: 14.6241\n",
      "Epoch 1229/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4264 - val_loss: 12.5346\n",
      "Epoch 1230/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6869 - val_loss: 15.4831\n",
      "Epoch 1231/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8116 - val_loss: 12.5960\n",
      "Epoch 1232/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5705 - val_loss: 12.4892\n",
      "Epoch 1233/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6241 - val_loss: 11.7519\n",
      "Epoch 1234/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0436 - val_loss: 11.3513\n",
      "Epoch 1235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3970 - val_loss: 12.8751\n",
      "Epoch 1236/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6405 - val_loss: 11.6991\n",
      "Epoch 1237/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6855 - val_loss: 11.7672\n",
      "Epoch 1238/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8146 - val_loss: 11.8452\n",
      "Epoch 1239/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2115 - val_loss: 11.6602\n",
      "Epoch 1240/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7292 - val_loss: 12.3397\n",
      "Epoch 1241/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0179 - val_loss: 11.7196\n",
      "Epoch 1242/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0982 - val_loss: 13.5128\n",
      "Epoch 1243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4693 - val_loss: 11.9029\n",
      "Epoch 1244/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4385 - val_loss: 14.7588\n",
      "Epoch 1245/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1362 - val_loss: 15.5101\n",
      "Epoch 1246/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0090 - val_loss: 18.9393\n",
      "Epoch 1247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5025 - val_loss: 15.0178\n",
      "Epoch 1248/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7489 - val_loss: 12.6855\n",
      "Epoch 1249/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3060 - val_loss: 12.3791\n",
      "Epoch 1250/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8526 - val_loss: 15.5783\n",
      "Epoch 1251/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1608 - val_loss: 11.6675\n",
      "Epoch 1252/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1081 - val_loss: 12.9609\n",
      "Epoch 1253/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2263 - val_loss: 10.9589\n",
      "Epoch 1254/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4087 - val_loss: 11.2127\n",
      "Epoch 1255/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5406 - val_loss: 14.2863\n",
      "Epoch 1256/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1547 - val_loss: 12.1927\n",
      "Epoch 1257/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5543 - val_loss: 12.4272\n",
      "Epoch 1258/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7121 - val_loss: 12.3620\n",
      "Epoch 1259/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5533 - val_loss: 14.8521\n",
      "Epoch 1260/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3882 - val_loss: 12.9228\n",
      "Epoch 1261/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7124 - val_loss: 12.5035\n",
      "Epoch 1262/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5312 - val_loss: 11.9700\n",
      "Epoch 1263/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3449 - val_loss: 14.2226\n",
      "Epoch 1264/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7665 - val_loss: 12.0883\n",
      "Epoch 1265/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7232 - val_loss: 15.6986\n",
      "Epoch 1266/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2370 - val_loss: 11.6195\n",
      "Epoch 1267/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8095 - val_loss: 12.0360\n",
      "Epoch 1268/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.2513 - val_loss: 11.7791\n",
      "Epoch 1269/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4084 - val_loss: 14.4416\n",
      "Epoch 1270/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7441 - val_loss: 12.7855\n",
      "Epoch 1271/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5118 - val_loss: 13.0970\n",
      "Epoch 1272/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7176 - val_loss: 13.0487\n",
      "Epoch 1273/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3465 - val_loss: 13.1290\n",
      "Epoch 1274/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5917 - val_loss: 11.9942\n",
      "Epoch 1275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5214 - val_loss: 12.1443\n",
      "Epoch 1276/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6757 - val_loss: 11.7164\n",
      "Epoch 1277/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4400 - val_loss: 11.3348\n",
      "Epoch 1278/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0948 - val_loss: 11.9661\n",
      "Epoch 1279/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4951 - val_loss: 11.5868\n",
      "Epoch 1280/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.1798 - val_loss: 11.6532\n",
      "Epoch 1281/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6159 - val_loss: 11.5814\n",
      "Epoch 1282/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5334 - val_loss: 15.1357\n",
      "Epoch 1283/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7596 - val_loss: 16.4170\n",
      "Epoch 1284/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7686 - val_loss: 14.2857\n",
      "Epoch 1285/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6277 - val_loss: 15.5481\n",
      "Epoch 1286/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7789 - val_loss: 15.2709\n",
      "Epoch 1287/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7195 - val_loss: 12.8883\n",
      "Epoch 1288/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9698 - val_loss: 13.0849\n",
      "Epoch 1289/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5036 - val_loss: 14.0805\n",
      "Epoch 1290/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1069 - val_loss: 12.3451\n",
      "Epoch 1291/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5026 - val_loss: 11.9194\n",
      "Epoch 1292/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9646 - val_loss: 11.2366\n",
      "Epoch 1293/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3748 - val_loss: 11.5547\n",
      "Epoch 1294/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6594 - val_loss: 11.9136\n",
      "Epoch 1295/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0504 - val_loss: 13.4557\n",
      "Epoch 1296/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6186 - val_loss: 12.2459\n",
      "Epoch 1297/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6236 - val_loss: 12.0396\n",
      "Epoch 1298/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6279 - val_loss: 11.4761\n",
      "Epoch 1299/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5197 - val_loss: 12.1451\n",
      "Epoch 1300/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0101 - val_loss: 11.5745\n",
      "Epoch 1301/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.1230 - val_loss: 11.5094\n",
      "Epoch 1302/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9109 - val_loss: 12.7448\n",
      "Epoch 1303/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9146 - val_loss: 11.3557\n",
      "Epoch 1304/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.0938 - val_loss: 10.2645\n",
      "Epoch 1305/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.2904 - val_loss: 12.4320\n",
      "Epoch 1306/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5891 - val_loss: 11.3598\n",
      "Epoch 1307/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7208 - val_loss: 13.2500\n",
      "Epoch 1308/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.9185 - val_loss: 13.5679\n",
      "Epoch 1309/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5374 - val_loss: 11.6587\n",
      "Epoch 1310/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2202 - val_loss: 11.1503\n",
      "Epoch 1311/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7200 - val_loss: 19.5654\n",
      "Epoch 1312/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6941 - val_loss: 15.1389\n",
      "Epoch 1313/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6010 - val_loss: 14.0568\n",
      "Epoch 1314/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6731 - val_loss: 12.4333\n",
      "Epoch 1315/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3795 - val_loss: 13.3942\n",
      "Epoch 1316/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1254 - val_loss: 13.1355\n",
      "Epoch 1317/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8170 - val_loss: 12.1382\n",
      "Epoch 1318/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4370 - val_loss: 11.1001\n",
      "Epoch 1319/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7520 - val_loss: 11.2446\n",
      "Epoch 1320/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.1173 - val_loss: 11.9189\n",
      "Epoch 1321/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4096 - val_loss: 12.2443\n",
      "Epoch 1322/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.2532 - val_loss: 11.8281\n",
      "Epoch 1323/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4052 - val_loss: 14.5934\n",
      "Epoch 1324/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8530 - val_loss: 13.0520\n",
      "Epoch 1325/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5753 - val_loss: 13.5332\n",
      "Epoch 1326/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3272 - val_loss: 12.6016\n",
      "Epoch 1327/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1568 - val_loss: 11.3817\n",
      "Epoch 1328/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0752 - val_loss: 14.9687\n",
      "Epoch 1329/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3899 - val_loss: 12.5625\n",
      "Epoch 1330/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1154 - val_loss: 11.4816\n",
      "Epoch 1331/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6182 - val_loss: 11.9072\n",
      "Epoch 1332/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3397 - val_loss: 11.0521\n",
      "Epoch 1333/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6952 - val_loss: 11.2671\n",
      "Epoch 1334/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4934 - val_loss: 11.3407\n",
      "Epoch 1335/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1527 - val_loss: 12.9664\n",
      "Epoch 1336/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.1821 - val_loss: 11.7005\n",
      "Epoch 1337/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6589 - val_loss: 12.3084\n",
      "Epoch 1338/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6571 - val_loss: 12.0186\n",
      "Epoch 1339/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4058 - val_loss: 12.4505\n",
      "Epoch 1340/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3976 - val_loss: 12.0096\n",
      "Epoch 1341/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8345 - val_loss: 12.4336\n",
      "Epoch 1342/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7793 - val_loss: 12.3757\n",
      "Epoch 1343/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5215 - val_loss: 12.7827\n",
      "Epoch 1344/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.2427 - val_loss: 13.6179\n",
      "Epoch 1345/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.2531 - val_loss: 11.5913\n",
      "Epoch 1346/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5400 - val_loss: 14.3292\n",
      "Epoch 1347/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6504 - val_loss: 11.4391\n",
      "Epoch 1348/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5811 - val_loss: 13.1560\n",
      "Epoch 1349/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4027 - val_loss: 12.0982\n",
      "Epoch 1350/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7346 - val_loss: 11.9628\n",
      "Epoch 1351/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4096 - val_loss: 12.5761\n",
      "Epoch 1352/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5831 - val_loss: 11.3371\n",
      "Epoch 1353/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6336 - val_loss: 19.1695\n",
      "Epoch 1354/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.5794 - val_loss: 10.0682\n",
      "Epoch 1355/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5677 - val_loss: 15.8490\n",
      "Epoch 1356/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.8840 - val_loss: 13.0111\n",
      "Epoch 1357/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1113 - val_loss: 19.0232\n",
      "Epoch 1358/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5838 - val_loss: 15.3658\n",
      "Epoch 1359/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5288 - val_loss: 12.2754\n",
      "Epoch 1360/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9917 - val_loss: 11.7007\n",
      "Epoch 1361/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0074 - val_loss: 11.3125\n",
      "Epoch 1362/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4784 - val_loss: 12.7253\n",
      "Epoch 1363/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6106 - val_loss: 11.4726\n",
      "Epoch 1364/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5206 - val_loss: 11.4407\n",
      "Epoch 1365/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7690 - val_loss: 12.5921\n",
      "Epoch 1366/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5115 - val_loss: 12.3644\n",
      "Epoch 1367/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7660 - val_loss: 12.6127\n",
      "Epoch 1368/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6036 - val_loss: 10.5784\n",
      "Epoch 1369/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5499 - val_loss: 10.8436\n",
      "Epoch 1370/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5922 - val_loss: 12.3457\n",
      "Epoch 1371/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5555 - val_loss: 12.4599\n",
      "Epoch 1372/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7238Restoring model weights from the end of the best epoch: 872.\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.1512 - val_loss: 12.8331\n",
      "Epoch 1372: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>38.754044</td>\n",
       "      <td>38.69566</td>\n",
       "      <td>38.367805</td>\n",
       "      <td>38.335838</td>\n",
       "      <td>38.230377</td>\n",
       "      <td>37.818172</td>\n",
       "      <td>21.458702</td>\n",
       "      <td>19.756649</td>\n",
       "      <td>19.86887</td>\n",
       "      <td>12.050808</td>\n",
       "      <td>-2.987385</td>\n",
       "      <td>24.389454</td>\n",
       "      <td>-4.126945</td>\n",
       "      <td>-4.188384</td>\n",
       "      <td>-3.913354</td>\n",
       "      <td>-1.659755</td>\n",
       "      <td>4.074056</td>\n",
       "      <td>-4.194274</td>\n",
       "      <td>-4.202342</td>\n",
       "      <td>-4.195573</td>\n",
       "      <td>-4.206163</td>\n",
       "      <td>-4.23601</td>\n",
       "      <td>-4.359323</td>\n",
       "      <td>-4.510295</td>\n",
       "      <td>-4.923594</td>\n",
       "      <td>-5.230797</td>\n",
       "      <td>-5.859454</td>\n",
       "      <td>-7.206473</td>\n",
       "      <td>-8.245431</td>\n",
       "      <td>-9.894261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>36.174</td>\n",
       "      <td>38.394</td>\n",
       "      <td>35.688</td>\n",
       "      <td>42.076</td>\n",
       "      <td>39.875</td>\n",
       "      <td>38.984</td>\n",
       "      <td>41.652</td>\n",
       "      <td>33.904</td>\n",
       "      <td>29.447</td>\n",
       "      <td>29.197</td>\n",
       "      <td>26.297</td>\n",
       "      <td>29.209</td>\n",
       "      <td>28.158</td>\n",
       "      <td>31.132</td>\n",
       "      <td>30.195</td>\n",
       "      <td>31.537</td>\n",
       "      <td>30.748</td>\n",
       "      <td>30.734</td>\n",
       "      <td>36.567</td>\n",
       "      <td>30.849</td>\n",
       "      <td>31.021</td>\n",
       "      <td>31.437</td>\n",
       "      <td>31.533</td>\n",
       "      <td>26.431</td>\n",
       "      <td>25.978</td>\n",
       "      <td>29.86</td>\n",
       "      <td>39.045</td>\n",
       "      <td>45.213</td>\n",
       "      <td>42.237</td>\n",
       "      <td>39.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>2.580044</td>\n",
       "      <td>0.301659</td>\n",
       "      <td>2.679806</td>\n",
       "      <td>3.740162</td>\n",
       "      <td>1.644623</td>\n",
       "      <td>1.165829</td>\n",
       "      <td>20.193298</td>\n",
       "      <td>14.14735</td>\n",
       "      <td>9.578131</td>\n",
       "      <td>17.146193</td>\n",
       "      <td>29.284386</td>\n",
       "      <td>4.819546</td>\n",
       "      <td>32.284946</td>\n",
       "      <td>35.320385</td>\n",
       "      <td>34.108353</td>\n",
       "      <td>33.196754</td>\n",
       "      <td>26.673943</td>\n",
       "      <td>34.928272</td>\n",
       "      <td>40.769344</td>\n",
       "      <td>35.044575</td>\n",
       "      <td>35.227165</td>\n",
       "      <td>35.673012</td>\n",
       "      <td>35.892323</td>\n",
       "      <td>30.941296</td>\n",
       "      <td>30.901596</td>\n",
       "      <td>35.090797</td>\n",
       "      <td>44.904453</td>\n",
       "      <td>52.419476</td>\n",
       "      <td>50.48243</td>\n",
       "      <td>49.626259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1          2          3          4          5   \\\n",
       "Month         Month-1   Month-2    Month-3    Month-4    Month-5    Month-6   \n",
       "Prediction  38.754044  38.69566  38.367805  38.335838  38.230377  37.818172   \n",
       "Target         36.174    38.394     35.688     42.076     39.875     38.984   \n",
       "Error        2.580044  0.301659   2.679806   3.740162   1.644623   1.165829   \n",
       "\n",
       "                   6          7         8          9          10         11  \\\n",
       "Month         Month-7    Month-8   Month-9   Month-10   Month-11   Month-12   \n",
       "Prediction  21.458702  19.756649  19.86887  12.050808  -2.987385  24.389454   \n",
       "Target         41.652     33.904    29.447     29.197     26.297     29.209   \n",
       "Error       20.193298   14.14735  9.578131  17.146193  29.284386   4.819546   \n",
       "\n",
       "                   12         13         14         15         16         17  \\\n",
       "Month        Month-13   Month-14   Month-15   Month-16   Month-17   Month-18   \n",
       "Prediction  -4.126945  -4.188384  -3.913354  -1.659755   4.074056  -4.194274   \n",
       "Target         28.158     31.132     30.195     31.537     30.748     30.734   \n",
       "Error       32.284946  35.320385  34.108353  33.196754  26.673943  34.928272   \n",
       "\n",
       "                   18         19         20         21         22         23  \\\n",
       "Month        Month-19   Month-20   Month-21   Month-22   Month-23   Month-24   \n",
       "Prediction  -4.202342  -4.195573  -4.206163   -4.23601  -4.359323  -4.510295   \n",
       "Target         36.567     30.849     31.021     31.437     31.533     26.431   \n",
       "Error       40.769344  35.044575  35.227165  35.673012  35.892323  30.941296   \n",
       "\n",
       "                   24         25         26         27        28         29  \n",
       "Month        Month-25   Month-26   Month-27   Month-28  Month-29   Month-30  \n",
       "Prediction  -4.923594  -5.230797  -5.859454  -7.206473 -8.245431  -9.894261  \n",
       "Target         25.978      29.86     39.045     45.213    42.237     39.732  \n",
       "Error       30.901596  35.090797  44.904453  52.419476  50.48243  49.626259  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.02555"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.79411304"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[324.739]] - Target[420.89700000000005]| =  Error: [[96.15799]]; MAPE:[[0.22845967]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[-39.71836]] - Target[370.34200000000004]| =  Error: [[410.06036]]; MAPE:[[1.1072477]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Ano-5: |Prediction[[-41.36001]] - Target[222.065]| =  Error: [[263.42502]]; MAPE:[[1.1862519]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[96.15799]], dtype=float32),\n",
       " array([[410.06036]], dtype=float32),\n",
       " array([[263.42502]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "256.5478"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8406531"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
