{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Minas Gerais - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Minas Gerais - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Minas Gerais - value</th>\n",
       "      <th>Minas Gerais - Produção de Cimento (t)</th>\n",
       "      <th>Minas Gerais - Desemprego</th>\n",
       "      <th>Minas Gerais - PIB - Estadual</th>\n",
       "      <th>Minas Gerais - PIB - Construção Civil</th>\n",
       "      <th>Minas Gerais - PIB - Per Capita</th>\n",
       "      <th>Minas Gerais - PIB - Preços de Mercado</th>\n",
       "      <th>Minas Gerais - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.756537</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>0.334536</td>\n",
       "      <td>648.891160</td>\n",
       "      <td>8.242462</td>\n",
       "      <td>2.937752e+08</td>\n",
       "      <td>1.725077e+07</td>\n",
       "      <td>14.096054</td>\n",
       "      <td>2.759117e+08</td>\n",
       "      <td>247.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.756708</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>0.335670</td>\n",
       "      <td>652.396314</td>\n",
       "      <td>8.236470</td>\n",
       "      <td>2.941480e+08</td>\n",
       "      <td>1.726959e+07</td>\n",
       "      <td>14.102603</td>\n",
       "      <td>2.760648e+08</td>\n",
       "      <td>305.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.756879</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>0.336553</td>\n",
       "      <td>655.911573</td>\n",
       "      <td>8.230479</td>\n",
       "      <td>2.945208e+08</td>\n",
       "      <td>1.728841e+07</td>\n",
       "      <td>14.109152</td>\n",
       "      <td>2.762178e+08</td>\n",
       "      <td>284.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.757050</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>0.336531</td>\n",
       "      <td>656.746430</td>\n",
       "      <td>8.224488</td>\n",
       "      <td>2.948935e+08</td>\n",
       "      <td>1.730723e+07</td>\n",
       "      <td>14.115701</td>\n",
       "      <td>2.763709e+08</td>\n",
       "      <td>286.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.757222</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>0.336406</td>\n",
       "      <td>660.114672</td>\n",
       "      <td>8.218497</td>\n",
       "      <td>2.952663e+08</td>\n",
       "      <td>1.732605e+07</td>\n",
       "      <td>14.122250</td>\n",
       "      <td>2.765239e+08</td>\n",
       "      <td>312.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.622619</td>\n",
       "      <td>1250.988075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>633.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.621866</td>\n",
       "      <td>1247.030458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>612.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620866</td>\n",
       "      <td>1244.634022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>579.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619585</td>\n",
       "      <td>1241.214294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>559.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617977</td>\n",
       "      <td>1243.288171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>559.950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Minas Gerais - IDH  \\\n",
       "0       2003-1            0.756537   \n",
       "1       2003-2            0.756708   \n",
       "2       2003-3            0.756879   \n",
       "3       2003-4            0.757050   \n",
       "4       2003-5            0.757222   \n",
       "..         ...                 ...   \n",
       "235     2022-8                 NaN   \n",
       "236     2022-9                 NaN   \n",
       "237    2022-10                 NaN   \n",
       "238    2022-11                 NaN   \n",
       "239    2022-12                 NaN   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Minas Gerais - value  \\\n",
       "0                              7.330309e+06   0.969649              0.334536   \n",
       "1                              7.335910e+06   0.950783              0.335670   \n",
       "2                              7.341511e+06   0.938332              0.336553   \n",
       "3                              7.347112e+06   0.926401              0.336531   \n",
       "4                              7.352713e+06   0.951683              0.336406   \n",
       "..                                      ...        ...                   ...   \n",
       "235                                     NaN        NaN              0.622619   \n",
       "236                                     NaN        NaN              0.621866   \n",
       "237                                     NaN        NaN              0.620866   \n",
       "238                                     NaN        NaN              0.619585   \n",
       "239                                     NaN        NaN              0.617977   \n",
       "\n",
       "     Minas Gerais - Produção de Cimento (t)  Minas Gerais - Desemprego  \\\n",
       "0                                648.891160                   8.242462   \n",
       "1                                652.396314                   8.236470   \n",
       "2                                655.911573                   8.230479   \n",
       "3                                656.746430                   8.224488   \n",
       "4                                660.114672                   8.218497   \n",
       "..                                      ...                        ...   \n",
       "235                             1250.988075                        NaN   \n",
       "236                             1247.030458                        NaN   \n",
       "237                             1244.634022                        NaN   \n",
       "238                             1241.214294                        NaN   \n",
       "239                             1243.288171                        NaN   \n",
       "\n",
       "     Minas Gerais - PIB - Estadual  Minas Gerais - PIB - Construção Civil  \\\n",
       "0                     2.937752e+08                           1.725077e+07   \n",
       "1                     2.941480e+08                           1.726959e+07   \n",
       "2                     2.945208e+08                           1.728841e+07   \n",
       "3                     2.948935e+08                           1.730723e+07   \n",
       "4                     2.952663e+08                           1.732605e+07   \n",
       "..                             ...                                    ...   \n",
       "235                            NaN                                    NaN   \n",
       "236                            NaN                                    NaN   \n",
       "237                            NaN                                    NaN   \n",
       "238                            NaN                                    NaN   \n",
       "239                            NaN                                    NaN   \n",
       "\n",
       "     Minas Gerais - PIB - Per Capita  Minas Gerais - PIB - Preços de Mercado  \\\n",
       "0                          14.096054                            2.759117e+08   \n",
       "1                          14.102603                            2.760648e+08   \n",
       "2                          14.109152                            2.762178e+08   \n",
       "3                          14.115701                            2.763709e+08   \n",
       "4                          14.122250                            2.765239e+08   \n",
       "..                               ...                                     ...   \n",
       "235                              NaN                                     NaN   \n",
       "236                              NaN                                     NaN   \n",
       "237                              NaN                                     NaN   \n",
       "238                              NaN                                     NaN   \n",
       "239                              NaN                                     NaN   \n",
       "\n",
       "     Minas Gerais - Consumo de Cimento (t)  \n",
       "0                                  247.134  \n",
       "1                                  305.708  \n",
       "2                                  284.168  \n",
       "3                                  286.594  \n",
       "4                                  312.455  \n",
       "..                                     ...  \n",
       "235                                633.858  \n",
       "236                                612.428  \n",
       "237                                579.831  \n",
       "238                                559.950  \n",
       "239                                559.950  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_MG.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Minas Gerais - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Minas Gerais - value</th>\n",
       "      <th>Minas Gerais - Produção de Cimento (t)</th>\n",
       "      <th>Minas Gerais - Desemprego</th>\n",
       "      <th>Minas Gerais - PIB - Estadual</th>\n",
       "      <th>Minas Gerais - PIB - Construção Civil</th>\n",
       "      <th>Minas Gerais - PIB - Per Capita</th>\n",
       "      <th>Minas Gerais - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.917914</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.524203</td>\n",
       "      <td>-2.146709</td>\n",
       "      <td>-0.699400</td>\n",
       "      <td>-1.745399</td>\n",
       "      <td>-1.973963</td>\n",
       "      <td>-3.018821</td>\n",
       "      <td>-2.686146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.892160</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.508666</td>\n",
       "      <td>-2.125900</td>\n",
       "      <td>-0.706157</td>\n",
       "      <td>-1.725016</td>\n",
       "      <td>-1.923436</td>\n",
       "      <td>-2.934320</td>\n",
       "      <td>-2.623049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.866406</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.496577</td>\n",
       "      <td>-2.105031</td>\n",
       "      <td>-0.712914</td>\n",
       "      <td>-1.704633</td>\n",
       "      <td>-1.872910</td>\n",
       "      <td>-2.849818</td>\n",
       "      <td>-2.559951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.840653</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.496879</td>\n",
       "      <td>-2.100075</td>\n",
       "      <td>-0.719672</td>\n",
       "      <td>-1.684250</td>\n",
       "      <td>-1.822384</td>\n",
       "      <td>-2.765317</td>\n",
       "      <td>-2.496853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.814899</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.498597</td>\n",
       "      <td>-2.080078</td>\n",
       "      <td>-0.726429</td>\n",
       "      <td>-1.663867</td>\n",
       "      <td>-1.771858</td>\n",
       "      <td>-2.680816</td>\n",
       "      <td>-2.433756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.315321</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>0.874645</td>\n",
       "      <td>0.774558</td>\n",
       "      <td>0.789659</td>\n",
       "      <td>1.149269</td>\n",
       "      <td>-0.772657</td>\n",
       "      <td>0.183801</td>\n",
       "      <td>0.694771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.308842</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>0.890157</td>\n",
       "      <td>0.806353</td>\n",
       "      <td>0.784605</td>\n",
       "      <td>1.140354</td>\n",
       "      <td>-0.757425</td>\n",
       "      <td>0.173158</td>\n",
       "      <td>0.684584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.302363</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>0.906034</td>\n",
       "      <td>0.844284</td>\n",
       "      <td>0.779552</td>\n",
       "      <td>1.131439</td>\n",
       "      <td>-0.742194</td>\n",
       "      <td>0.162516</td>\n",
       "      <td>0.674397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.295885</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>0.919415</td>\n",
       "      <td>0.884141</td>\n",
       "      <td>0.774498</td>\n",
       "      <td>1.122523</td>\n",
       "      <td>-0.726963</td>\n",
       "      <td>0.151874</td>\n",
       "      <td>0.664209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.289406</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>0.941476</td>\n",
       "      <td>0.912436</td>\n",
       "      <td>0.769445</td>\n",
       "      <td>1.113608</td>\n",
       "      <td>-0.711731</td>\n",
       "      <td>0.141231</td>\n",
       "      <td>0.654022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Minas Gerais - IDH   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0             -1.917914                                          2.723741   \n",
       "1             -1.892160                                          2.350880   \n",
       "2             -1.866406                                          2.123016   \n",
       "3             -1.840653                                          2.021477   \n",
       "4             -1.814899                                          1.887113   \n",
       "..                  ...                                               ...   \n",
       "187            1.315321                                         -2.010387   \n",
       "188            1.308842                                         -1.870713   \n",
       "189            1.302363                                         -1.806230   \n",
       "190            1.295885                                         -1.727496   \n",
       "191            1.289406                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Minas Gerais - value  \\\n",
       "0                                 -2.389042   3.122582             -1.524203   \n",
       "1                                 -2.352139   2.970356             -1.508666   \n",
       "2                                 -2.315236   2.869895             -1.496577   \n",
       "3                                 -2.278333   2.773628             -1.496879   \n",
       "4                                 -2.241431   2.977624             -1.498597   \n",
       "..                                      ...        ...                   ...   \n",
       "187                                0.389193  -1.749976              0.874645   \n",
       "188                                0.370392  -1.593005              0.890157   \n",
       "189                                0.351592  -1.351489              0.906034   \n",
       "190                                0.332791  -1.198492              0.919415   \n",
       "191                                0.313991  -1.100894              0.941476   \n",
       "\n",
       "     Minas Gerais - Produção de Cimento (t)  Minas Gerais - Desemprego  \\\n",
       "0                                 -2.146709                  -0.699400   \n",
       "1                                 -2.125900                  -0.706157   \n",
       "2                                 -2.105031                  -0.712914   \n",
       "3                                 -2.100075                  -0.719672   \n",
       "4                                 -2.080078                  -0.726429   \n",
       "..                                      ...                        ...   \n",
       "187                                0.774558                   0.789659   \n",
       "188                                0.806353                   0.784605   \n",
       "189                                0.844284                   0.779552   \n",
       "190                                0.884141                   0.774498   \n",
       "191                                0.912436                   0.769445   \n",
       "\n",
       "     Minas Gerais - PIB - Estadual  Minas Gerais - PIB - Construção Civil  \\\n",
       "0                        -1.745399                              -1.973963   \n",
       "1                        -1.725016                              -1.923436   \n",
       "2                        -1.704633                              -1.872910   \n",
       "3                        -1.684250                              -1.822384   \n",
       "4                        -1.663867                              -1.771858   \n",
       "..                             ...                                    ...   \n",
       "187                       1.149269                              -0.772657   \n",
       "188                       1.140354                              -0.757425   \n",
       "189                       1.131439                              -0.742194   \n",
       "190                       1.122523                              -0.726963   \n",
       "191                       1.113608                              -0.711731   \n",
       "\n",
       "     Minas Gerais - PIB - Per Capita  Minas Gerais - PIB - Preços de Mercado  \n",
       "0                          -3.018821                               -2.686146  \n",
       "1                          -2.934320                               -2.623049  \n",
       "2                          -2.849818                               -2.559951  \n",
       "3                          -2.765317                               -2.496853  \n",
       "4                          -2.680816                               -2.433756  \n",
       "..                               ...                                     ...  \n",
       "187                         0.183801                                0.694771  \n",
       "188                         0.173158                                0.684584  \n",
       "189                         0.162516                                0.674397  \n",
       "190                         0.151874                                0.664209  \n",
       "191                         0.141231                                0.654022  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      249.680\n",
       "1      219.561\n",
       "2      304.641\n",
       "3      262.564\n",
       "4      299.209\n",
       "        ...   \n",
       "235        NaN\n",
       "236        NaN\n",
       "237        NaN\n",
       "238        NaN\n",
       "239        NaN\n",
       "Name: Minas Gerais - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Minas Gerais - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Minas Gerais - value</th>\n",
       "      <th>Minas Gerais - Produção de Cimento (t)</th>\n",
       "      <th>Minas Gerais - Desemprego</th>\n",
       "      <th>Minas Gerais - PIB - Estadual</th>\n",
       "      <th>Minas Gerais - PIB - Construção Civil</th>\n",
       "      <th>Minas Gerais - PIB - Per Capita</th>\n",
       "      <th>Minas Gerais - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.917914</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.524203</td>\n",
       "      <td>-2.146709</td>\n",
       "      <td>-0.699400</td>\n",
       "      <td>-1.745399</td>\n",
       "      <td>-1.973963</td>\n",
       "      <td>-3.018821</td>\n",
       "      <td>-2.686146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.892160</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.508666</td>\n",
       "      <td>-2.125900</td>\n",
       "      <td>-0.706157</td>\n",
       "      <td>-1.725016</td>\n",
       "      <td>-1.923436</td>\n",
       "      <td>-2.934320</td>\n",
       "      <td>-2.623049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.866406</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.496577</td>\n",
       "      <td>-2.105031</td>\n",
       "      <td>-0.712914</td>\n",
       "      <td>-1.704633</td>\n",
       "      <td>-1.872910</td>\n",
       "      <td>-2.849818</td>\n",
       "      <td>-2.559951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.840653</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.496879</td>\n",
       "      <td>-2.100075</td>\n",
       "      <td>-0.719672</td>\n",
       "      <td>-1.684250</td>\n",
       "      <td>-1.822384</td>\n",
       "      <td>-2.765317</td>\n",
       "      <td>-2.496853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.814899</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.498597</td>\n",
       "      <td>-2.080078</td>\n",
       "      <td>-0.726429</td>\n",
       "      <td>-1.663867</td>\n",
       "      <td>-1.771858</td>\n",
       "      <td>-2.680816</td>\n",
       "      <td>-2.433756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.399834</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>0.832198</td>\n",
       "      <td>0.050588</td>\n",
       "      <td>1.519517</td>\n",
       "      <td>1.163052</td>\n",
       "      <td>-0.960847</td>\n",
       "      <td>-0.093961</td>\n",
       "      <td>0.627995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.402752</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>0.824048</td>\n",
       "      <td>0.042723</td>\n",
       "      <td>1.476375</td>\n",
       "      <td>1.168317</td>\n",
       "      <td>-0.968515</td>\n",
       "      <td>-0.074705</td>\n",
       "      <td>0.638908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.405671</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>0.815727</td>\n",
       "      <td>0.029152</td>\n",
       "      <td>1.433232</td>\n",
       "      <td>1.173583</td>\n",
       "      <td>-0.976183</td>\n",
       "      <td>-0.055448</td>\n",
       "      <td>0.649820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.408589</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>0.810089</td>\n",
       "      <td>-0.007439</td>\n",
       "      <td>1.390090</td>\n",
       "      <td>1.178848</td>\n",
       "      <td>-0.983851</td>\n",
       "      <td>-0.036192</td>\n",
       "      <td>0.660733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.411508</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>0.804399</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>1.346948</td>\n",
       "      <td>1.184113</td>\n",
       "      <td>-0.991519</td>\n",
       "      <td>-0.016936</td>\n",
       "      <td>0.671646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Minas Gerais - IDH   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0             -1.917914                                          2.723741   \n",
       "1             -1.892160                                          2.350880   \n",
       "2             -1.866406                                          2.123016   \n",
       "3             -1.840653                                          2.021477   \n",
       "4             -1.814899                                          1.887113   \n",
       "..                  ...                                               ...   \n",
       "157            1.399834                                         -0.214006   \n",
       "158            1.402752                                         -0.434717   \n",
       "159            1.405671                                         -0.524091   \n",
       "160            1.408589                                         -0.614500   \n",
       "161            1.411508                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Minas Gerais - value  \\\n",
       "0                                 -2.389042   3.122582             -1.524203   \n",
       "1                                 -2.352139   2.970356             -1.508666   \n",
       "2                                 -2.315236   2.869895             -1.496577   \n",
       "3                                 -2.278333   2.773628             -1.496879   \n",
       "4                                 -2.241431   2.977624             -1.498597   \n",
       "..                                      ...        ...                   ...   \n",
       "157                                0.819304  -0.883659              0.832198   \n",
       "158                                0.808136  -0.950771              0.824048   \n",
       "159                                0.796969  -1.028465              0.815727   \n",
       "160                                0.785801  -1.103668              0.810089   \n",
       "161                                0.774634  -0.978419              0.804399   \n",
       "\n",
       "     Minas Gerais - Produção de Cimento (t)  Minas Gerais - Desemprego  \\\n",
       "0                                 -2.146709                  -0.699400   \n",
       "1                                 -2.125900                  -0.706157   \n",
       "2                                 -2.105031                  -0.712914   \n",
       "3                                 -2.100075                  -0.719672   \n",
       "4                                 -2.080078                  -0.726429   \n",
       "..                                      ...                        ...   \n",
       "157                                0.050588                   1.519517   \n",
       "158                                0.042723                   1.476375   \n",
       "159                                0.029152                   1.433232   \n",
       "160                               -0.007439                   1.390090   \n",
       "161                                0.010626                   1.346948   \n",
       "\n",
       "     Minas Gerais - PIB - Estadual  Minas Gerais - PIB - Construção Civil  \\\n",
       "0                        -1.745399                              -1.973963   \n",
       "1                        -1.725016                              -1.923436   \n",
       "2                        -1.704633                              -1.872910   \n",
       "3                        -1.684250                              -1.822384   \n",
       "4                        -1.663867                              -1.771858   \n",
       "..                             ...                                    ...   \n",
       "157                       1.163052                              -0.960847   \n",
       "158                       1.168317                              -0.968515   \n",
       "159                       1.173583                              -0.976183   \n",
       "160                       1.178848                              -0.983851   \n",
       "161                       1.184113                              -0.991519   \n",
       "\n",
       "     Minas Gerais - PIB - Per Capita  Minas Gerais - PIB - Preços de Mercado  \n",
       "0                          -3.018821                               -2.686146  \n",
       "1                          -2.934320                               -2.623049  \n",
       "2                          -2.849818                               -2.559951  \n",
       "3                          -2.765317                               -2.496853  \n",
       "4                          -2.680816                               -2.433756  \n",
       "..                               ...                                     ...  \n",
       "157                        -0.093961                                0.627995  \n",
       "158                        -0.074705                                0.638908  \n",
       "159                        -0.055448                                0.649820  \n",
       "160                        -0.036192                                0.660733  \n",
       "161                        -0.016936                                0.671646  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      249.680\n",
       "1      219.561\n",
       "2      304.641\n",
       "3      262.564\n",
       "4      299.209\n",
       "        ...   \n",
       "157    338.767\n",
       "158    419.962\n",
       "159    387.800\n",
       "160    391.122\n",
       "161    409.739\n",
       "Name: Minas Gerais - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Minas Gerais - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Minas Gerais - value</th>\n",
       "      <th>Minas Gerais - Produção de Cimento (t)</th>\n",
       "      <th>Minas Gerais - Desemprego</th>\n",
       "      <th>Minas Gerais - PIB - Estadual</th>\n",
       "      <th>Minas Gerais - PIB - Construção Civil</th>\n",
       "      <th>Minas Gerais - PIB - Per Capita</th>\n",
       "      <th>Minas Gerais - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.414426</td>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>0.798904</td>\n",
       "      <td>0.018612</td>\n",
       "      <td>1.303806</td>\n",
       "      <td>1.189379</td>\n",
       "      <td>-0.999187</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.682559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.417345</td>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>0.799394</td>\n",
       "      <td>0.033397</td>\n",
       "      <td>1.260664</td>\n",
       "      <td>1.194644</td>\n",
       "      <td>-1.006855</td>\n",
       "      <td>0.021577</td>\n",
       "      <td>0.693472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.420263</td>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>0.797051</td>\n",
       "      <td>0.046888</td>\n",
       "      <td>1.217522</td>\n",
       "      <td>1.199909</td>\n",
       "      <td>-1.014523</td>\n",
       "      <td>0.040833</td>\n",
       "      <td>0.704385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.423182</td>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>0.798229</td>\n",
       "      <td>0.060840</td>\n",
       "      <td>1.174379</td>\n",
       "      <td>1.205174</td>\n",
       "      <td>-1.022191</td>\n",
       "      <td>0.060089</td>\n",
       "      <td>0.715298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.426100</td>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>0.797215</td>\n",
       "      <td>0.064701</td>\n",
       "      <td>1.131237</td>\n",
       "      <td>1.210440</td>\n",
       "      <td>-1.029859</td>\n",
       "      <td>0.079346</td>\n",
       "      <td>0.726211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.429018</td>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>0.796730</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>1.088095</td>\n",
       "      <td>1.215705</td>\n",
       "      <td>-1.037527</td>\n",
       "      <td>0.098602</td>\n",
       "      <td>0.737124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.431937</td>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>0.796755</td>\n",
       "      <td>0.083989</td>\n",
       "      <td>1.044953</td>\n",
       "      <td>1.220970</td>\n",
       "      <td>-1.045195</td>\n",
       "      <td>0.117858</td>\n",
       "      <td>0.748037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.425998</td>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>0.797325</td>\n",
       "      <td>0.093382</td>\n",
       "      <td>1.026626</td>\n",
       "      <td>1.220196</td>\n",
       "      <td>-1.031368</td>\n",
       "      <td>0.129561</td>\n",
       "      <td>0.749541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.420059</td>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>0.798479</td>\n",
       "      <td>0.117327</td>\n",
       "      <td>1.008300</td>\n",
       "      <td>1.219422</td>\n",
       "      <td>-1.017542</td>\n",
       "      <td>0.141265</td>\n",
       "      <td>0.751045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.414121</td>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>0.799847</td>\n",
       "      <td>0.135465</td>\n",
       "      <td>0.989973</td>\n",
       "      <td>1.218647</td>\n",
       "      <td>-1.003715</td>\n",
       "      <td>0.152968</td>\n",
       "      <td>0.752548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.408182</td>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>0.801447</td>\n",
       "      <td>0.205581</td>\n",
       "      <td>0.971646</td>\n",
       "      <td>1.217873</td>\n",
       "      <td>-0.989889</td>\n",
       "      <td>0.164671</td>\n",
       "      <td>0.754052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.402243</td>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>0.803298</td>\n",
       "      <td>0.251297</td>\n",
       "      <td>0.953320</td>\n",
       "      <td>1.217098</td>\n",
       "      <td>-0.976062</td>\n",
       "      <td>0.176375</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.396304</td>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>0.805358</td>\n",
       "      <td>0.323407</td>\n",
       "      <td>0.934993</td>\n",
       "      <td>1.216324</td>\n",
       "      <td>-0.962235</td>\n",
       "      <td>0.188078</td>\n",
       "      <td>0.757060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.390365</td>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>0.807467</td>\n",
       "      <td>0.390352</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.215549</td>\n",
       "      <td>-0.948409</td>\n",
       "      <td>0.199781</td>\n",
       "      <td>0.758564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.384427</td>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>0.809628</td>\n",
       "      <td>0.413850</td>\n",
       "      <td>0.898340</td>\n",
       "      <td>1.214775</td>\n",
       "      <td>-0.934582</td>\n",
       "      <td>0.211484</td>\n",
       "      <td>0.760067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.378488</td>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>0.811848</td>\n",
       "      <td>0.443618</td>\n",
       "      <td>0.880013</td>\n",
       "      <td>1.214001</td>\n",
       "      <td>-0.920756</td>\n",
       "      <td>0.223188</td>\n",
       "      <td>0.761571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.372549</td>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>0.814078</td>\n",
       "      <td>0.469495</td>\n",
       "      <td>0.861687</td>\n",
       "      <td>1.213226</td>\n",
       "      <td>-0.906929</td>\n",
       "      <td>0.234891</td>\n",
       "      <td>0.763075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.366610</td>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>0.816319</td>\n",
       "      <td>0.478700</td>\n",
       "      <td>0.843360</td>\n",
       "      <td>1.212452</td>\n",
       "      <td>-0.893102</td>\n",
       "      <td>0.246594</td>\n",
       "      <td>0.764579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.360671</td>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>0.818675</td>\n",
       "      <td>0.505772</td>\n",
       "      <td>0.825034</td>\n",
       "      <td>1.211677</td>\n",
       "      <td>-0.879276</td>\n",
       "      <td>0.258298</td>\n",
       "      <td>0.766083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.354193</td>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>0.823937</td>\n",
       "      <td>0.519514</td>\n",
       "      <td>0.819980</td>\n",
       "      <td>1.202762</td>\n",
       "      <td>-0.864045</td>\n",
       "      <td>0.247655</td>\n",
       "      <td>0.755895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.347714</td>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>0.829359</td>\n",
       "      <td>0.553944</td>\n",
       "      <td>0.814927</td>\n",
       "      <td>1.193846</td>\n",
       "      <td>-0.848813</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.745708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.341235</td>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>0.835058</td>\n",
       "      <td>0.566312</td>\n",
       "      <td>0.809873</td>\n",
       "      <td>1.184931</td>\n",
       "      <td>-0.833582</td>\n",
       "      <td>0.226370</td>\n",
       "      <td>0.735521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.334757</td>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>0.841043</td>\n",
       "      <td>0.616298</td>\n",
       "      <td>0.804820</td>\n",
       "      <td>1.176016</td>\n",
       "      <td>-0.818351</td>\n",
       "      <td>0.215728</td>\n",
       "      <td>0.725333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.328278</td>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>0.850060</td>\n",
       "      <td>0.694328</td>\n",
       "      <td>0.799766</td>\n",
       "      <td>1.167100</td>\n",
       "      <td>-0.803119</td>\n",
       "      <td>0.205086</td>\n",
       "      <td>0.715146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.321799</td>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>0.862173</td>\n",
       "      <td>0.727759</td>\n",
       "      <td>0.794713</td>\n",
       "      <td>1.158185</td>\n",
       "      <td>-0.787888</td>\n",
       "      <td>0.194443</td>\n",
       "      <td>0.704959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.315321</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>0.874645</td>\n",
       "      <td>0.774558</td>\n",
       "      <td>0.789659</td>\n",
       "      <td>1.149269</td>\n",
       "      <td>-0.772657</td>\n",
       "      <td>0.183801</td>\n",
       "      <td>0.694771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.308842</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>0.890157</td>\n",
       "      <td>0.806353</td>\n",
       "      <td>0.784605</td>\n",
       "      <td>1.140354</td>\n",
       "      <td>-0.757425</td>\n",
       "      <td>0.173158</td>\n",
       "      <td>0.684584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.302363</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>0.906034</td>\n",
       "      <td>0.844284</td>\n",
       "      <td>0.779552</td>\n",
       "      <td>1.131439</td>\n",
       "      <td>-0.742194</td>\n",
       "      <td>0.162516</td>\n",
       "      <td>0.674397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.295885</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>0.919415</td>\n",
       "      <td>0.884141</td>\n",
       "      <td>0.774498</td>\n",
       "      <td>1.122523</td>\n",
       "      <td>-0.726963</td>\n",
       "      <td>0.151874</td>\n",
       "      <td>0.664209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.289406</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>0.941476</td>\n",
       "      <td>0.912436</td>\n",
       "      <td>0.769445</td>\n",
       "      <td>1.113608</td>\n",
       "      <td>-0.711731</td>\n",
       "      <td>0.141231</td>\n",
       "      <td>0.654022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Minas Gerais - IDH   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162            1.414426                                         -0.601510   \n",
       "163            1.417345                                         -0.786068   \n",
       "164            1.420263                                         -0.830387   \n",
       "165            1.423182                                         -0.801089   \n",
       "166            1.426100                                         -0.959917   \n",
       "167            1.429018                                         -1.022309   \n",
       "168            1.431937                                         -1.074401   \n",
       "169            1.425998                                         -1.119597   \n",
       "170            1.420059                                         -1.078648   \n",
       "171            1.414121                                         -1.055426   \n",
       "172            1.408182                                         -1.101053   \n",
       "173            1.402243                                         -1.211370   \n",
       "174            1.396304                                         -1.157198   \n",
       "175            1.390365                                         -1.223444   \n",
       "176            1.384427                                         -1.311519   \n",
       "177            1.378488                                         -1.362602   \n",
       "178            1.372549                                         -1.380125   \n",
       "179            1.366610                                         -1.219296   \n",
       "180            1.360671                                         -1.300284   \n",
       "181            1.354193                                         -1.336476   \n",
       "182            1.347714                                         -1.415774   \n",
       "183            1.341235                                         -1.526021   \n",
       "184            1.334757                                         -1.681806   \n",
       "185            1.328278                                         -1.735167   \n",
       "186            1.321799                                         -1.962315   \n",
       "187            1.315321                                         -2.010387   \n",
       "188            1.308842                                         -1.870713   \n",
       "189            1.302363                                         -1.806230   \n",
       "190            1.295885                                         -1.727496   \n",
       "191            1.289406                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Minas Gerais - value  \\\n",
       "162                                0.763466  -1.213929              0.798904   \n",
       "163                                0.752299  -1.292173              0.799394   \n",
       "164                                0.741131  -1.324219              0.797051   \n",
       "165                                0.729964  -1.344446              0.798229   \n",
       "166                                0.718796  -1.381638              0.797215   \n",
       "167                                0.707629  -1.411208              0.796730   \n",
       "168                                0.696461  -1.412953              0.796755   \n",
       "169                                0.681823  -1.491464              0.797325   \n",
       "170                                0.667184  -1.573805              0.798479   \n",
       "171                                0.652545  -1.564950              0.799847   \n",
       "172                                0.637906  -1.581584              0.801447   \n",
       "173                                0.623268  -1.565976              0.803298   \n",
       "174                                0.608629  -1.648556              0.805358   \n",
       "175                                0.593990  -1.650049              0.807467   \n",
       "176                                0.579351  -1.653957              0.809628   \n",
       "177                                0.564713  -1.652572              0.811848   \n",
       "178                                0.550074  -1.715349              0.814078   \n",
       "179                                0.535435  -1.750917              0.816319   \n",
       "180                                0.520796  -1.718448              0.818675   \n",
       "181                                0.501996  -1.733426              0.823937   \n",
       "182                                0.483195  -1.729362              0.829359   \n",
       "183                                0.464395  -1.748544              0.835058   \n",
       "184                                0.445594  -1.778060              0.841043   \n",
       "185                                0.426794  -1.773710              0.850060   \n",
       "186                                0.407993  -1.757007              0.862173   \n",
       "187                                0.389193  -1.749976              0.874645   \n",
       "188                                0.370392  -1.593005              0.890157   \n",
       "189                                0.351592  -1.351489              0.906034   \n",
       "190                                0.332791  -1.198492              0.919415   \n",
       "191                                0.313991  -1.100894              0.941476   \n",
       "\n",
       "     Minas Gerais - Produção de Cimento (t)  Minas Gerais - Desemprego  \\\n",
       "162                                0.018612                   1.303806   \n",
       "163                                0.033397                   1.260664   \n",
       "164                                0.046888                   1.217522   \n",
       "165                                0.060840                   1.174379   \n",
       "166                                0.064701                   1.131237   \n",
       "167                                0.073529                   1.088095   \n",
       "168                                0.083989                   1.044953   \n",
       "169                                0.093382                   1.026626   \n",
       "170                                0.117327                   1.008300   \n",
       "171                                0.135465                   0.989973   \n",
       "172                                0.205581                   0.971646   \n",
       "173                                0.251297                   0.953320   \n",
       "174                                0.323407                   0.934993   \n",
       "175                                0.390352                   0.916667   \n",
       "176                                0.413850                   0.898340   \n",
       "177                                0.443618                   0.880013   \n",
       "178                                0.469495                   0.861687   \n",
       "179                                0.478700                   0.843360   \n",
       "180                                0.505772                   0.825034   \n",
       "181                                0.519514                   0.819980   \n",
       "182                                0.553944                   0.814927   \n",
       "183                                0.566312                   0.809873   \n",
       "184                                0.616298                   0.804820   \n",
       "185                                0.694328                   0.799766   \n",
       "186                                0.727759                   0.794713   \n",
       "187                                0.774558                   0.789659   \n",
       "188                                0.806353                   0.784605   \n",
       "189                                0.844284                   0.779552   \n",
       "190                                0.884141                   0.774498   \n",
       "191                                0.912436                   0.769445   \n",
       "\n",
       "     Minas Gerais - PIB - Estadual  Minas Gerais - PIB - Construção Civil  \\\n",
       "162                       1.189379                              -0.999187   \n",
       "163                       1.194644                              -1.006855   \n",
       "164                       1.199909                              -1.014523   \n",
       "165                       1.205174                              -1.022191   \n",
       "166                       1.210440                              -1.029859   \n",
       "167                       1.215705                              -1.037527   \n",
       "168                       1.220970                              -1.045195   \n",
       "169                       1.220196                              -1.031368   \n",
       "170                       1.219422                              -1.017542   \n",
       "171                       1.218647                              -1.003715   \n",
       "172                       1.217873                              -0.989889   \n",
       "173                       1.217098                              -0.976062   \n",
       "174                       1.216324                              -0.962235   \n",
       "175                       1.215549                              -0.948409   \n",
       "176                       1.214775                              -0.934582   \n",
       "177                       1.214001                              -0.920756   \n",
       "178                       1.213226                              -0.906929   \n",
       "179                       1.212452                              -0.893102   \n",
       "180                       1.211677                              -0.879276   \n",
       "181                       1.202762                              -0.864045   \n",
       "182                       1.193846                              -0.848813   \n",
       "183                       1.184931                              -0.833582   \n",
       "184                       1.176016                              -0.818351   \n",
       "185                       1.167100                              -0.803119   \n",
       "186                       1.158185                              -0.787888   \n",
       "187                       1.149269                              -0.772657   \n",
       "188                       1.140354                              -0.757425   \n",
       "189                       1.131439                              -0.742194   \n",
       "190                       1.122523                              -0.726963   \n",
       "191                       1.113608                              -0.711731   \n",
       "\n",
       "     Minas Gerais - PIB - Per Capita  Minas Gerais - PIB - Preços de Mercado  \n",
       "162                         0.002321                                0.682559  \n",
       "163                         0.021577                                0.693472  \n",
       "164                         0.040833                                0.704385  \n",
       "165                         0.060089                                0.715298  \n",
       "166                         0.079346                                0.726211  \n",
       "167                         0.098602                                0.737124  \n",
       "168                         0.117858                                0.748037  \n",
       "169                         0.129561                                0.749541  \n",
       "170                         0.141265                                0.751045  \n",
       "171                         0.152968                                0.752548  \n",
       "172                         0.164671                                0.754052  \n",
       "173                         0.176375                                0.755556  \n",
       "174                         0.188078                                0.757060  \n",
       "175                         0.199781                                0.758564  \n",
       "176                         0.211484                                0.760067  \n",
       "177                         0.223188                                0.761571  \n",
       "178                         0.234891                                0.763075  \n",
       "179                         0.246594                                0.764579  \n",
       "180                         0.258298                                0.766083  \n",
       "181                         0.247655                                0.755895  \n",
       "182                         0.237013                                0.745708  \n",
       "183                         0.226370                                0.735521  \n",
       "184                         0.215728                                0.725333  \n",
       "185                         0.205086                                0.715146  \n",
       "186                         0.194443                                0.704959  \n",
       "187                         0.183801                                0.694771  \n",
       "188                         0.173158                                0.684584  \n",
       "189                         0.162516                                0.674397  \n",
       "190                         0.151874                                0.664209  \n",
       "191                         0.141231                                0.654022  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    413.460\n",
       "163    497.019\n",
       "164    476.478\n",
       "165    421.395\n",
       "166    413.641\n",
       "167    338.033\n",
       "168    431.028\n",
       "169    305.105\n",
       "170    402.406\n",
       "171    419.419\n",
       "172    336.054\n",
       "173    568.395\n",
       "174    541.488\n",
       "175    537.851\n",
       "176    526.265\n",
       "177    559.293\n",
       "178    466.646\n",
       "179    416.049\n",
       "180    501.489\n",
       "181    460.699\n",
       "182    445.583\n",
       "183    509.271\n",
       "184    532.602\n",
       "185    500.905\n",
       "186    588.495\n",
       "187    589.349\n",
       "188    543.982\n",
       "189    614.074\n",
       "190    557.419\n",
       "191    412.582\n",
       "Name: Minas Gerais - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*6 + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    train, train_val = validation_splitter(train_input, 6)\n",
    "    target,target_val = validation_splitter(train_target, 6)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val, target_val),\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3081299489, 2761246306, 1333372428, 4293897367, 1627601205, 3519704158, 4056907068, 2581267171, 2708137086, 96552343, 2267660508, 1657597269, 1236305011, 1157679008, 1190657448, 1326359214, 152701572, 1636995256, 2044370783, 3010639691, 823894793, 1280381566, 1587502250, 3428340600, 3880667578]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 3370.84521484375\n",
      "winner_seed: 3081299489\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 3305.88427734375\n",
      "winner_seed: 2761246306\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 3412.970947265625\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 3890.592041015625\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 3070.677978515625\n",
      "winner_seed: 1627601205\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 2377.81982421875\n",
      "winner_seed: 3519704158\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 3547.64697265625\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 3361.701416015625\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 3240.037109375\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 3216.479736328125\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 3026.751220703125\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 2397.67236328125\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 3385.894287109375\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 3276.989990234375\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 2861.888916015625\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 17:02:44.465648: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 3253.5224609375\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 3446.580322265625\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 2988.728515625\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 2534.84375\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 2987.6923828125\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 2987.1181640625\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 2591.903564453125\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 3535.4287109375\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 17:09:44.677615: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 2793.462158203125\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 3295.8779296875\n",
      "\n",
      "\n",
      "final_seed: 3519704158\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 1s 26ms/step - loss: 291879.1250 - val_loss: 270782.0312\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 231966.1719 - val_loss: 184697.4062\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 209419.1562 - val_loss: 117732.9062\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 124370.2656 - val_loss: 114278.5938\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 121176.9453 - val_loss: 84723.2578\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92910.6875 - val_loss: 76481.1094\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90086.2031 - val_loss: 74259.4219\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79614.5625 - val_loss: 70755.6406\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72225.5312 - val_loss: 64859.6758\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 65752.7656 - val_loss: 49668.5195\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57069.9102 - val_loss: 74814.0078\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 65357.7617 - val_loss: 53796.0078\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53662.2578 - val_loss: 44423.1172\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46208.3984 - val_loss: 35291.3047\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51083.3438 - val_loss: 35864.0508\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42721.7461 - val_loss: 34338.1602\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 38974.5039 - val_loss: 38256.2812\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46086.8594 - val_loss: 35293.0781\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48308.5312 - val_loss: 38362.2773\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 44452.6289 - val_loss: 25188.6660\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28230.9414 - val_loss: 27438.2656\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 29058.0059 - val_loss: 21779.0879\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23943.3730 - val_loss: 19781.4160\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24383.3242 - val_loss: 25881.3867\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20362.8574 - val_loss: 34291.1953\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 26135.8184 - val_loss: 15179.5371\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16987.9922 - val_loss: 13551.9932\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14410.0615 - val_loss: 13069.9580\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13283.1592 - val_loss: 15055.7393\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16499.2324 - val_loss: 12228.7002\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13467.0605 - val_loss: 14724.7734\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12669.2256 - val_loss: 15574.0205\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10797.9961 - val_loss: 9044.0361\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10236.9834 - val_loss: 9412.1211\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10362.3672 - val_loss: 9995.6172\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11135.9707 - val_loss: 9431.1611\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11084.9297 - val_loss: 6839.7222\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7296.2739 - val_loss: 7241.0088\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9244.3545 - val_loss: 18664.8867\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15350.6201 - val_loss: 13334.6855\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14886.7207 - val_loss: 15452.4727\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14482.3457 - val_loss: 13311.0879\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11512.3984 - val_loss: 15003.0273\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17690.2969 - val_loss: 14232.9805\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16020.5146 - val_loss: 13159.4355\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13913.8115 - val_loss: 15211.0664\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12285.7422 - val_loss: 7661.2461\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9407.0830 - val_loss: 7725.5044\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10077.6504 - val_loss: 7137.2314\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8769.5371 - val_loss: 6769.0381\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6287.6187 - val_loss: 5299.1362\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6607.2617 - val_loss: 9892.0879\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6252.7808 - val_loss: 5720.3022\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5056.8525 - val_loss: 6082.0376\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4477.1299 - val_loss: 5683.0513\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4052.9731 - val_loss: 8176.3101\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4924.8945 - val_loss: 7290.7495\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5331.9541 - val_loss: 6152.9038\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6753.3291 - val_loss: 8115.2349\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5829.8896 - val_loss: 6156.8691\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5762.4868 - val_loss: 5958.2651\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5205.7349 - val_loss: 6003.5161\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5132.4902 - val_loss: 7352.2563\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5743.8164 - val_loss: 11116.9004\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7005.2837 - val_loss: 11909.0225\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7341.7544 - val_loss: 6001.9019\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4805.7095 - val_loss: 6476.1167\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4594.4771 - val_loss: 5263.4644\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4523.4385 - val_loss: 5350.9771\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6442.7500 - val_loss: 5126.9175\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7605.2393 - val_loss: 6866.5122\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11981.4805 - val_loss: 7147.4805\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9323.4883 - val_loss: 6999.6040\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8459.8281 - val_loss: 7095.6128\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9823.2793 - val_loss: 8488.3994\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10389.0430 - val_loss: 9957.7646\n",
      "Epoch 77/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 10383.7168 - val_loss: 6483.4688\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7527.6167 - val_loss: 6105.0347\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5346.3706 - val_loss: 3615.3635\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5340.8291 - val_loss: 3393.0864\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4914.4390 - val_loss: 7131.9058\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7749.7041 - val_loss: 5334.5186\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6708.2954 - val_loss: 4884.8184\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5894.7397 - val_loss: 7994.3447\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5318.0132 - val_loss: 3997.1926\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4755.8652 - val_loss: 3593.6250\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4298.2261 - val_loss: 6501.1353\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6244.9688 - val_loss: 5687.4292\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7989.8110 - val_loss: 8383.1787\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7717.0034 - val_loss: 6366.7271\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6723.1128 - val_loss: 5964.2959\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6916.5537 - val_loss: 4085.2761\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6066.6621 - val_loss: 4391.2129\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5694.3936 - val_loss: 3862.0330\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5081.3247 - val_loss: 6661.6221\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4353.1177 - val_loss: 2455.8176\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3313.0981 - val_loss: 4607.3369\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4558.9258 - val_loss: 2570.4124\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2931.4834 - val_loss: 2703.7810\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3398.7832 - val_loss: 4977.0669\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3341.3516 - val_loss: 3846.5439\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3418.3450 - val_loss: 3827.0859\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2980.2249 - val_loss: 3566.2302\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3214.6868 - val_loss: 3217.8860\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2848.8530 - val_loss: 3683.5310\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2883.5854 - val_loss: 3351.1987\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3302.8518 - val_loss: 3538.9189\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2864.8647 - val_loss: 3095.0654\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3123.7695 - val_loss: 3412.8223\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3091.0615 - val_loss: 4419.1343\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3767.9290 - val_loss: 3264.5464\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3345.1440 - val_loss: 3200.4600\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3105.3086 - val_loss: 4043.6699\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3431.6401 - val_loss: 4477.9507\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6562.3853 - val_loss: 4579.9648\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6404.5327 - val_loss: 4389.6860\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6112.2827 - val_loss: 5131.1567\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6370.7188 - val_loss: 5220.3911\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6113.7007 - val_loss: 5816.9502\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6372.6909 - val_loss: 5439.7231\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5570.9209 - val_loss: 5147.0229\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5493.3955 - val_loss: 4910.4707\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4752.9849 - val_loss: 4390.7559\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6014.5820 - val_loss: 5208.3315\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6600.8013 - val_loss: 9203.0332\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6895.2939 - val_loss: 5988.8521\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5845.1899 - val_loss: 8212.3428\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6251.3618 - val_loss: 5563.2437\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5536.6025 - val_loss: 6162.1479\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6923.1216 - val_loss: 5349.2461\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5471.9932 - val_loss: 5058.4536\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5447.9844 - val_loss: 5310.6099\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6092.7178 - val_loss: 5289.2500\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4974.8955 - val_loss: 5165.5249\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5368.5850 - val_loss: 5666.5415\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4755.0762 - val_loss: 3960.9199\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4727.9814 - val_loss: 5501.4810\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4831.3066 - val_loss: 5918.2026\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5231.5249 - val_loss: 5784.3848\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5141.2188 - val_loss: 4212.7710\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3640.8093 - val_loss: 4390.3350\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3855.5295 - val_loss: 5645.7617\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4157.7314 - val_loss: 7371.4731\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5236.3125 - val_loss: 5777.3145\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5143.0620 - val_loss: 6151.3999\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5892.8306 - val_loss: 6004.3599\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4945.8677 - val_loss: 5898.4556\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4461.1099 - val_loss: 6569.0439\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5788.1392 - val_loss: 5595.5098\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5626.5566 - val_loss: 11528.5234\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7925.5249 - val_loss: 7609.9512\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7227.0049 - val_loss: 6181.2808\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6132.0430 - val_loss: 5601.2822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6364.1240 - val_loss: 6306.2349\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6130.9429 - val_loss: 5369.7212\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6015.1895 - val_loss: 5137.0029\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5602.5122 - val_loss: 4951.0425\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4632.7451 - val_loss: 5305.5439\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5792.9565 - val_loss: 7286.1274\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6061.3408 - val_loss: 8645.6797\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7151.7407 - val_loss: 6447.8936\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6697.8931 - val_loss: 10219.7832\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7461.7275 - val_loss: 7660.2588\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6175.6382 - val_loss: 4692.9355\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4556.7710 - val_loss: 4851.9028\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4181.9141 - val_loss: 6832.2163\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4863.6870 - val_loss: 7809.9087\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6316.3789 - val_loss: 5068.5303\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4940.2124 - val_loss: 4385.9243\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5208.3164 - val_loss: 9055.3174\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6592.1284 - val_loss: 5903.1436\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4160.7026 - val_loss: 4283.7129\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3194.8833 - val_loss: 5096.1870\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3450.8838 - val_loss: 3674.5830\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3237.8486 - val_loss: 4008.9045\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3028.6853 - val_loss: 3764.0803\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3072.7656 - val_loss: 4813.7324\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3342.5183 - val_loss: 4492.9644\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3437.8071 - val_loss: 4359.8701\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3321.1072 - val_loss: 3485.2407\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3055.7397 - val_loss: 4263.5493\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3025.2805 - val_loss: 3480.5891\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2931.6404 - val_loss: 4090.4421\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2792.7388 - val_loss: 3484.5032\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4047.4968 - val_loss: 4295.1851\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3809.4834 - val_loss: 5962.8647\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3589.2434 - val_loss: 3522.2529\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3404.2668 - val_loss: 4446.5034\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3952.1194 - val_loss: 4670.5239\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3375.7700 - val_loss: 4064.6787\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3185.5916 - val_loss: 3904.2131\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3513.0557 - val_loss: 3877.2793\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3286.4248 - val_loss: 3539.2310\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2865.7302 - val_loss: 3753.5747\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3076.1370 - val_loss: 4165.2520\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2815.1038 - val_loss: 5931.1963\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3112.4253 - val_loss: 4068.7568\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3592.1975 - val_loss: 5304.5884\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4603.4922 - val_loss: 5923.4824\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4667.3569 - val_loss: 5040.6802\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3528.7971 - val_loss: 4246.2090\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2927.3271 - val_loss: 6490.7974\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3073.8784 - val_loss: 3929.6626\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3341.7217 - val_loss: 5236.2007\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5315.9014 - val_loss: 5818.9180\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5588.3887 - val_loss: 6260.9355\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6703.7627 - val_loss: 6014.4927\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4503.0464 - val_loss: 4114.6274\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3846.5728 - val_loss: 3971.6187\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3466.2217 - val_loss: 3892.5942\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3357.3091 - val_loss: 3820.5256\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3169.5920 - val_loss: 4434.3262\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4084.1902 - val_loss: 3983.2537\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4714.9707 - val_loss: 3491.7471\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5132.0273 - val_loss: 4789.6924\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5350.8442 - val_loss: 9475.1914\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5606.8462 - val_loss: 6323.3428\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3837.9438 - val_loss: 4935.9375\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3152.1467 - val_loss: 4343.2852\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3082.0657 - val_loss: 4153.3071\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3046.8403 - val_loss: 4598.5342\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3534.6533 - val_loss: 5498.8496\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3066.4365 - val_loss: 4650.7021\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2969.5483 - val_loss: 3960.9421\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3154.0527 - val_loss: 8115.0508\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4032.1838 - val_loss: 3824.6907\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3318.3679 - val_loss: 5756.8193\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3945.9133 - val_loss: 9700.3369\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5591.9277 - val_loss: 5793.8496\n",
      "Epoch 230/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 4012.2712 - val_loss: 4695.9829\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3534.6567 - val_loss: 3724.2778\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3113.9648 - val_loss: 3891.3159\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3217.7012 - val_loss: 3585.6177\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3451.3862 - val_loss: 4399.7866\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3856.0295 - val_loss: 4570.9697\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5115.0098 - val_loss: 5893.8154\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5539.6191 - val_loss: 4728.7144\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5023.6177 - val_loss: 7462.7769\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5142.4824 - val_loss: 5097.6655\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4469.5391 - val_loss: 4934.2744\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3017.1365 - val_loss: 3788.7146\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3253.4097 - val_loss: 5172.7114\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3607.0708 - val_loss: 5047.5635\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4347.6816 - val_loss: 4940.0713\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3832.6394 - val_loss: 6073.0464\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4478.9351 - val_loss: 3623.8010\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3865.9675 - val_loss: 3716.2903\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4045.0022 - val_loss: 5138.6240\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4704.7305 - val_loss: 4343.0688\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3905.7883 - val_loss: 3310.1184\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3196.7400 - val_loss: 3543.2771\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3257.7732 - val_loss: 3197.0530\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4075.3496 - val_loss: 3827.3120\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4944.9043 - val_loss: 5410.3320\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5413.3359 - val_loss: 4543.8149\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4840.1011 - val_loss: 6073.3501\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6063.1689 - val_loss: 6525.1978\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5769.8247 - val_loss: 8191.9600\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6312.0962 - val_loss: 8577.0264\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5444.2456 - val_loss: 5952.2524\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4607.1655 - val_loss: 5385.9595\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3621.6084 - val_loss: 7542.4624\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3587.5701 - val_loss: 4873.0967\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3787.8291 - val_loss: 4328.3491\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4268.7544 - val_loss: 5231.9331\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5208.6636 - val_loss: 5678.4414\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4780.1865 - val_loss: 6827.7998\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5443.0088 - val_loss: 5431.5942\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4236.5078 - val_loss: 4833.2305\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3707.1841 - val_loss: 4403.2910\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3732.2515 - val_loss: 3970.5532\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3169.6335 - val_loss: 7909.2964\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4843.5464 - val_loss: 3432.2573\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4006.1135 - val_loss: 4482.6133\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4285.4727 - val_loss: 4696.7363\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4795.7593 - val_loss: 4323.6362\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4164.7368 - val_loss: 5543.0068\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4202.2710 - val_loss: 5166.7168\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5864.8857 - val_loss: 5397.9214\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6818.4639 - val_loss: 5480.1714\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6020.6055 - val_loss: 5270.1689\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4675.8452 - val_loss: 4238.2979\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4628.6426 - val_loss: 4788.8179\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4614.6665 - val_loss: 4812.1748\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4225.2319 - val_loss: 4346.5996\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3534.0042 - val_loss: 3350.5842\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4641.8364 - val_loss: 4056.3083\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4610.9526 - val_loss: 4971.6089\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4479.2197 - val_loss: 4601.1025\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3843.3032 - val_loss: 3928.7546\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4155.8652 - val_loss: 4089.3850\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4018.6875 - val_loss: 3746.9326\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4308.9946 - val_loss: 3922.0972\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4432.6260 - val_loss: 4870.0601\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4182.6099 - val_loss: 5264.4844\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4367.9678 - val_loss: 4002.0317\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5203.8828 - val_loss: 5158.1318\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5669.5835 - val_loss: 3815.3276\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5782.6318 - val_loss: 3904.5486\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5420.9062 - val_loss: 4505.7261\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7601.5381 - val_loss: 6732.6094\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7405.6851 - val_loss: 5794.2090\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6545.0127 - val_loss: 8052.3345\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8092.7065 - val_loss: 4594.6353\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5440.8486 - val_loss: 4240.0430\n",
      "Epoch 306/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 4717.9155 - val_loss: 4379.7993\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5418.6294 - val_loss: 8144.3130\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7970.9556 - val_loss: 6168.2437\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7278.2021 - val_loss: 6983.7144\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5454.9478 - val_loss: 5701.6587\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4765.2290 - val_loss: 5520.0073\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4883.7769 - val_loss: 5101.7271\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4550.9214 - val_loss: 7490.6411\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4991.9336 - val_loss: 5727.4385\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4175.9946 - val_loss: 4519.1328\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3676.1018 - val_loss: 5673.5708\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3959.2434 - val_loss: 4658.9380\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3485.0464 - val_loss: 4958.7744\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3179.3826 - val_loss: 5658.7573\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3340.3584 - val_loss: 5886.1602\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3381.6160 - val_loss: 5532.0083\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3878.3333 - val_loss: 5419.6592\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3906.6628 - val_loss: 5610.4263\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3762.1211 - val_loss: 4841.1802\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4831.3589 - val_loss: 7913.6572\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6914.9639 - val_loss: 6233.8003\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5104.6895 - val_loss: 5491.1162\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4242.8599 - val_loss: 6655.5557\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4833.6660 - val_loss: 4698.1943\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3522.1807 - val_loss: 7010.7070\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4729.5312 - val_loss: 5760.0562\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3473.7927 - val_loss: 6198.1538\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3404.2300 - val_loss: 7781.3696\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4004.9985 - val_loss: 4848.5977\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4036.3176 - val_loss: 4419.5591\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3771.6992 - val_loss: 5229.4800\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4106.6392 - val_loss: 4641.0493\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4847.6025 - val_loss: 5919.2637\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5243.8975 - val_loss: 5854.7163\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4735.3828 - val_loss: 5121.8438\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4232.3613 - val_loss: 7030.4438\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5199.7607 - val_loss: 5521.0127\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4397.0195 - val_loss: 3714.3879\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3795.7002 - val_loss: 9204.6387\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5557.4180 - val_loss: 4046.0435\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4443.1670 - val_loss: 4809.2710\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4400.1597 - val_loss: 4217.1460\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4313.4717 - val_loss: 5478.4756\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4843.1206 - val_loss: 10212.3086\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6780.4844 - val_loss: 3476.4792\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4335.4790 - val_loss: 4253.4224\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4836.7573 - val_loss: 8133.3218\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4789.6738 - val_loss: 3763.6016\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4165.6841 - val_loss: 5101.6104\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4963.2432 - val_loss: 4079.5996\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4029.6819 - val_loss: 4415.4961\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4169.4741 - val_loss: 4130.4023\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3826.8076 - val_loss: 4211.4448\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3721.0586 - val_loss: 4619.1621\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3592.4358 - val_loss: 4352.9536\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3829.0720 - val_loss: 3833.1912\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3896.7898 - val_loss: 3678.3452\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3703.5537 - val_loss: 5303.2720\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3460.4524 - val_loss: 3959.0620\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3197.9443 - val_loss: 3896.0537\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3448.2400 - val_loss: 4218.3818\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3533.2983 - val_loss: 4919.0557\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3200.8228 - val_loss: 5275.5752\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3399.7776 - val_loss: 4528.9907\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3516.6321 - val_loss: 4114.3335\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3384.4250 - val_loss: 4218.9883\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3391.4702 - val_loss: 4369.0459\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3328.8496 - val_loss: 4963.6245\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3300.2388 - val_loss: 4127.6675\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3171.2427 - val_loss: 4155.8984\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3323.1724 - val_loss: 4928.2275\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3067.1792 - val_loss: 6181.3081\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3260.5984 - val_loss: 5419.1118\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3219.2163 - val_loss: 4191.7998\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3042.8345 - val_loss: 4489.4668\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2927.8284 - val_loss: 4460.5068\n",
      "Epoch 382/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 3170.1526 - val_loss: 5822.8506\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3126.9319 - val_loss: 6924.7241\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3636.3240 - val_loss: 4383.0210\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3527.9189 - val_loss: 6347.7822\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3242.1763 - val_loss: 4400.8984\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3219.4956 - val_loss: 6018.1411\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4344.6187 - val_loss: 3991.0525\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3016.0510 - val_loss: 4615.1626\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3012.6421 - val_loss: 4775.9219\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2748.8325 - val_loss: 5065.8638\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3845.3306 - val_loss: 5847.8604\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3085.0469 - val_loss: 3846.4033\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3296.5229 - val_loss: 3746.2100\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3217.6360 - val_loss: 3486.8750\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3247.4041 - val_loss: 3717.3787\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3245.1230 - val_loss: 4413.3833\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3276.2749 - val_loss: 3826.6504\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3194.8904 - val_loss: 3692.4233\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3327.2573 - val_loss: 6667.4512\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3796.7515 - val_loss: 3955.8645\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4077.7732 - val_loss: 14166.3564\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10650.4072 - val_loss: 5371.4312\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6270.3257 - val_loss: 4451.2803\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6036.2002 - val_loss: 5469.3311\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5231.3823 - val_loss: 4891.9995\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4747.5063 - val_loss: 3937.4153\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4481.3706 - val_loss: 5833.2568\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4504.4497 - val_loss: 4027.6162\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3852.5884 - val_loss: 7297.2817\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5146.3052 - val_loss: 3474.7053\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3322.9934 - val_loss: 4645.1074\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4338.5562 - val_loss: 4276.6860\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4832.4902 - val_loss: 4389.1787\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4408.1377 - val_loss: 5483.2095\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5070.0400 - val_loss: 6947.4351\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7723.4355 - val_loss: 6079.6875\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6798.3960 - val_loss: 6763.3867\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6712.7905 - val_loss: 7098.5947\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6800.8994 - val_loss: 6208.7876\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6083.5020 - val_loss: 6574.2036\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6133.9761 - val_loss: 7024.1919\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7735.5264 - val_loss: 6150.7134\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6171.2192 - val_loss: 7012.0498\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6051.2358 - val_loss: 6591.1191\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7778.7407 - val_loss: 7446.2959\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8224.2803 - val_loss: 7072.0254\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12612.8398 - val_loss: 11269.1650\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7443.5376 - val_loss: 9960.0762\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7899.5464 - val_loss: 7213.9595\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6130.4619 - val_loss: 5858.4380\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6772.8638 - val_loss: 6055.9463\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6879.5811 - val_loss: 6103.6841\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6461.6978 - val_loss: 16818.0176\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8563.1279 - val_loss: 5628.7725\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4015.3005 - val_loss: 4448.2559\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3643.1575 - val_loss: 4876.5371\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3757.5513 - val_loss: 4821.1885\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3914.1121 - val_loss: 4595.7241\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3488.6975 - val_loss: 4530.9536\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3443.0515 - val_loss: 4589.5752\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3682.5337 - val_loss: 7329.3911\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4671.7275 - val_loss: 4423.2222\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3894.1523 - val_loss: 3746.7771\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3391.3699 - val_loss: 3790.4438\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3444.0911 - val_loss: 4333.4990\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3460.6675 - val_loss: 4467.5386\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3868.7271 - val_loss: 5153.7275\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3408.0425 - val_loss: 4114.2886\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3251.3110 - val_loss: 3760.8396\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3732.6384 - val_loss: 3674.4375\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3827.8303 - val_loss: 5646.0811\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3699.5815 - val_loss: 4234.4946\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3120.0112 - val_loss: 4279.1646\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2651.9199 - val_loss: 4097.3071\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3009.8042 - val_loss: 7947.0786\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3752.2217 - val_loss: 8425.5176\n",
      "Epoch 458/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 6760.1831 - val_loss: 6395.9526\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6230.8296 - val_loss: 5712.9409\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5870.6416 - val_loss: 7930.7148\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6660.0649 - val_loss: 6257.4800\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5435.8398 - val_loss: 4753.1201\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4947.4653 - val_loss: 4176.1689\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5965.3604 - val_loss: 5484.1743\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7406.7861 - val_loss: 8205.9170\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7258.7500 - val_loss: 6257.9678\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6924.1865 - val_loss: 6347.4878\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6757.0771 - val_loss: 5809.9282\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7107.8291 - val_loss: 5961.1387\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6328.0044 - val_loss: 12463.0117\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9505.3125 - val_loss: 7724.2324\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6542.3486 - val_loss: 8350.7070\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6652.9722 - val_loss: 10653.4053\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7416.8560 - val_loss: 12656.5391\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7387.3745 - val_loss: 5973.7686\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6635.5293 - val_loss: 5930.4375\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6597.2900 - val_loss: 6262.0337\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6733.4048 - val_loss: 5732.2520\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6445.2812 - val_loss: 6601.7979\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6542.7534 - val_loss: 8971.0225\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6630.1836 - val_loss: 5997.2432\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5677.9341 - val_loss: 7840.4214\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5481.1016 - val_loss: 6009.0571\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4387.2803 - val_loss: 4314.2441\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3566.7466 - val_loss: 4344.8989\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3560.5103 - val_loss: 4011.9829\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3401.8987 - val_loss: 4025.4958\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3509.7063 - val_loss: 4829.1260\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3330.4041 - val_loss: 5343.6133\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4572.9819 - val_loss: 4077.9949\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3859.4705 - val_loss: 5899.6274\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5417.7158 - val_loss: 4697.7349\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4461.2979 - val_loss: 4336.9800\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4751.3350 - val_loss: 4274.2886\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4207.5742 - val_loss: 4661.7881\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5102.0098 - val_loss: 5601.1934\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4762.5415 - val_loss: 4352.5532\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4656.6367 - val_loss: 3470.7454\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4664.7188 - val_loss: 4330.7573\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5258.8535 - val_loss: 3655.3691\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3978.1663 - val_loss: 3867.7075\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4251.6689 - val_loss: 3819.7378\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4649.9536 - val_loss: 3936.5166\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3579.6147 - val_loss: 3911.4277\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3548.6416 - val_loss: 4004.7375\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4073.9097 - val_loss: 4534.8442\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3508.6807 - val_loss: 3579.7266\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3780.3765 - val_loss: 3615.5703\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3969.9324 - val_loss: 3932.7185\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5467.9966 - val_loss: 6197.0493\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9211.2051 - val_loss: 7124.0659\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7340.8462 - val_loss: 7567.8936\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8675.0342 - val_loss: 6358.2432\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8144.0889 - val_loss: 6348.0771\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7205.7461 - val_loss: 6651.1182\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5866.3354 - val_loss: 4850.8130\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5447.0874 - val_loss: 5536.4883\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5363.9902 - val_loss: 5537.1367\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6067.8579 - val_loss: 5252.2959\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5148.7168 - val_loss: 3613.6677\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7188.9565 - val_loss: 7500.2002\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7265.4121 - val_loss: 6923.3818\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7880.6499 - val_loss: 5510.9648\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6309.2148 - val_loss: 7212.3447\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5234.5898 - val_loss: 5234.3555\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4337.5405 - val_loss: 5884.0439\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5149.0400 - val_loss: 7769.5059\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5647.1670 - val_loss: 6455.6978\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4773.1602 - val_loss: 6620.8169\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4816.2617 - val_loss: 5532.0601\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4204.5605 - val_loss: 4268.6064\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4018.0781 - val_loss: 4513.4175\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3993.9575 - val_loss: 4523.5977\n",
      "Epoch 534/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 3753.1704 - val_loss: 4868.1646\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4055.8899 - val_loss: 8873.7314\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3805.5259 - val_loss: 4491.9927\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3393.7158 - val_loss: 4893.0000\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4187.9570 - val_loss: 5120.9292\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3369.3735 - val_loss: 6521.0303\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3805.8765 - val_loss: 4716.7061\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6001.4800 - val_loss: 9348.2803\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7755.1514 - val_loss: 7276.7573\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6674.4995 - val_loss: 9346.0801\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7582.8687 - val_loss: 8677.7529\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5614.6118 - val_loss: 7987.5034\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5707.2310 - val_loss: 7019.4854\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5249.4482 - val_loss: 6467.3418\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5273.9873 - val_loss: 7033.4644\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5028.0015 - val_loss: 7080.9316\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6020.8511 - val_loss: 7167.3315\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6572.8340 - val_loss: 6936.2417\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5766.7383 - val_loss: 7401.7793\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6154.1440 - val_loss: 6536.7769\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5400.0674 - val_loss: 6139.1855\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4985.3887 - val_loss: 4357.9365\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4003.5686 - val_loss: 5365.6104\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4102.3086 - val_loss: 5623.0708\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4892.5396 - val_loss: 5425.5269\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3889.7717 - val_loss: 4320.2891\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3623.3311 - val_loss: 4330.1455\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3121.3000 - val_loss: 5552.2534\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3970.0264 - val_loss: 3312.7380\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2785.5623 - val_loss: 5100.3125\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3460.4314 - val_loss: 4966.4878\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3105.9622 - val_loss: 5813.5098\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4343.2007 - val_loss: 6724.1851\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4805.0508 - val_loss: 4887.9165\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3831.4463 - val_loss: 6500.3911\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3575.4529 - val_loss: 4247.5415\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3332.6565 - val_loss: 4154.6104\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3482.7573 - val_loss: 5204.4927\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3323.9958 - val_loss: 5424.8833\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3035.4292 - val_loss: 5324.8970\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2905.9211 - val_loss: 5151.3901\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2891.1589 - val_loss: 4616.2817\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2624.1621 - val_loss: 5011.9409\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2774.2383 - val_loss: 3703.1917\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2222.5332 - val_loss: 3766.2854\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2492.3240 - val_loss: 4890.8896\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3113.9143 - val_loss: 4873.9478\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2658.7542 - val_loss: 5158.4272\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3118.4128 - val_loss: 5904.2803\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2821.7441 - val_loss: 4318.6050\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2743.3289 - val_loss: 4434.8081\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2551.3110 - val_loss: 4590.6963\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2585.7783 - val_loss: 4695.2695\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2722.7393 - val_loss: 6697.1401\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2962.8582 - val_loss: 6214.5962\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3251.9507 - val_loss: 4630.3809\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2564.8738 - val_loss: 4074.0410\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3080.1184 - val_loss: 4463.9854\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2894.3384 - val_loss: 5077.1084\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3635.2510 - val_loss: 4519.9414\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3106.9973 - val_loss: 9220.1016\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5675.1255 - val_loss: 4566.5322\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4486.7456 - val_loss: 8426.9551\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5461.6577 - val_loss: 6483.9019\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4593.9722 - val_loss: 7029.6138\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5018.5205 - val_loss: 4563.6396\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4393.5186 - val_loss: 5055.7349\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4506.7461 - val_loss: 8627.0020\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4644.6875 - val_loss: 8345.4443\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6343.7310 - val_loss: 6999.8877\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6403.5015 - val_loss: 6530.6909\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4809.6108 - val_loss: 3781.1667\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4234.8789 - val_loss: 4500.2554\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5365.4829 - val_loss: 6184.0996\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4020.4412 - val_loss: 5125.5200\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3551.2131 - val_loss: 4996.9062\n",
      "Epoch 610/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 3425.7725 - val_loss: 4180.1992\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3162.4993 - val_loss: 6135.1958\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3739.8833 - val_loss: 7361.6255\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4206.6548 - val_loss: 6850.1006\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3558.0276 - val_loss: 4469.3784\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3340.0645 - val_loss: 4127.2573\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3297.8462 - val_loss: 4876.4771\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3479.4844 - val_loss: 6118.4976\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3698.6499 - val_loss: 4393.2949\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2947.3333 - val_loss: 6043.4443\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3578.3501 - val_loss: 3974.7073\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3818.8296 - val_loss: 4230.2524\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2861.8352 - val_loss: 6283.8774\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3143.7395 - val_loss: 4032.1072\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2896.2649 - val_loss: 3969.2734\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2899.8931 - val_loss: 6030.5762\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2953.9851 - val_loss: 5606.4434\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3291.6182 - val_loss: 4064.1909\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3323.6897 - val_loss: 3866.7087\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2926.1453 - val_loss: 3863.7715\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2886.1321 - val_loss: 6201.7583\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3266.9231 - val_loss: 4283.8306\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4690.6260 - val_loss: 6948.5625\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5496.9131 - val_loss: 10229.5117\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8501.0635 - val_loss: 6331.9966\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6677.7485 - val_loss: 6039.1528\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5411.5034 - val_loss: 9337.6357\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6925.4028 - val_loss: 6468.2466\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6783.0078 - val_loss: 5821.8521\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6390.3613 - val_loss: 6074.8403\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6439.7368 - val_loss: 5621.6729\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6219.4175 - val_loss: 5166.0571\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5740.8198 - val_loss: 5217.1216\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4153.8584 - val_loss: 4197.1240\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3605.8125 - val_loss: 6978.1587\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4972.1333 - val_loss: 4133.8979\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3127.7085 - val_loss: 4026.3455\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3312.7644 - val_loss: 5362.3682\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3435.4319 - val_loss: 6145.6157\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3465.8240 - val_loss: 5180.7363\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3303.0139 - val_loss: 6154.4824\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3774.0127 - val_loss: 5458.9219\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3376.3425 - val_loss: 5072.5625\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3128.6987 - val_loss: 7233.9868\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3790.1704 - val_loss: 5154.7915\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3680.0735 - val_loss: 5180.6001\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3711.9504 - val_loss: 5855.3120\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5517.8892 - val_loss: 8337.2354\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5956.2710 - val_loss: 8390.7002\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5970.3130 - val_loss: 6534.6353\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5057.1396 - val_loss: 10418.7266\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6562.9526 - val_loss: 9356.0674\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7227.7568 - val_loss: 6296.6313\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6336.4067 - val_loss: 7228.9468\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4868.3291 - val_loss: 7003.8584\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4314.7407 - val_loss: 14529.1514\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6742.3906 - val_loss: 6634.5757\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4673.7783 - val_loss: 5189.6680\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4258.5405 - val_loss: 5077.8208\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3998.8936 - val_loss: 5696.2090\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3910.0242 - val_loss: 5401.0815\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3550.7983 - val_loss: 5390.8184\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3583.1152 - val_loss: 5543.5352\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4504.0640 - val_loss: 4736.2661\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4514.9722 - val_loss: 6971.7368\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5210.9868 - val_loss: 5170.0000\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3598.6482 - val_loss: 5890.5762\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4240.1968 - val_loss: 5073.5371\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6037.2500 - val_loss: 6116.4536\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5688.0186 - val_loss: 5810.0522\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5731.7583 - val_loss: 8579.2988\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5476.6328 - val_loss: 7578.2256\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5040.5576 - val_loss: 9200.0957\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5487.5537 - val_loss: 9492.7539\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4897.2534 - val_loss: 6884.5034\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5236.4561 - val_loss: 6245.6689\n",
      "Epoch 686/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 5098.4468 - val_loss: 6157.5332\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5053.0283 - val_loss: 6557.5337\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5502.1592 - val_loss: 6814.0010\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4918.2798 - val_loss: 6074.9106\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6066.0371 - val_loss: 7499.3657\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4096.1982 - val_loss: 5158.4966\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4050.7334 - val_loss: 5199.0688\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4033.9111 - val_loss: 5004.4341\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3747.1267 - val_loss: 4889.4526\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4038.0774 - val_loss: 4891.3574\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3514.2373 - val_loss: 6972.6187\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4863.3013 - val_loss: 6684.7256\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4573.7900 - val_loss: 7298.3535\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5454.3384 - val_loss: 11083.8203\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6414.2710 - val_loss: 7483.5005\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5389.5840 - val_loss: 5605.5620\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4950.7290 - val_loss: 5452.7480\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4947.1216 - val_loss: 5950.8462\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5193.0117 - val_loss: 8146.1665\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6710.7007 - val_loss: 7441.9980\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5214.5059 - val_loss: 12685.5400\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6281.0713 - val_loss: 6091.3901\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4691.1279 - val_loss: 8354.6768\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5452.9976 - val_loss: 5905.4956\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6265.7759 - val_loss: 7189.2344\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5999.7500 - val_loss: 7632.6240\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7184.3643 - val_loss: 7828.2700\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5673.3804 - val_loss: 5901.2500\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5143.0083 - val_loss: 6732.9131\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5220.4141 - val_loss: 5611.4121\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4491.2832 - val_loss: 5485.9644\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4681.0249 - val_loss: 8304.0322\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4700.4736 - val_loss: 4631.7456\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4614.5405 - val_loss: 5264.4932\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3400.6794 - val_loss: 4654.9512\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3741.6995 - val_loss: 7029.3833\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4529.2295 - val_loss: 4267.4883\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3093.0027 - val_loss: 4573.1548\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3042.4163 - val_loss: 4243.7212\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2978.1567 - val_loss: 4239.9443\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2936.4119 - val_loss: 3859.8113\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3002.3796 - val_loss: 4639.5581\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3168.4478 - val_loss: 4273.1670\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3105.5603 - val_loss: 4619.6333\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3283.6912 - val_loss: 5119.1406\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3266.5896 - val_loss: 3308.6436\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2689.8584 - val_loss: 4404.2573\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3101.0796 - val_loss: 3582.5139\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2787.6643 - val_loss: 4714.5854\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3037.9312 - val_loss: 4516.7900\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2417.4578 - val_loss: 3687.8582\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2816.2671 - val_loss: 3978.4150\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2935.7214 - val_loss: 3846.9597\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2499.3511 - val_loss: 3890.1162\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2616.4771 - val_loss: 4619.7744\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2763.4561 - val_loss: 6069.9932\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3160.8132 - val_loss: 3849.3970\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2477.0476 - val_loss: 3912.9580\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2705.7231 - val_loss: 5900.3188\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3299.3413 - val_loss: 4193.1069\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2533.8936 - val_loss: 4129.2246\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2398.9080 - val_loss: 4154.3296\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2318.8167 - val_loss: 4083.7639\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3060.9480 - val_loss: 6029.4395\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4274.2944 - val_loss: 3825.1719\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3511.0334 - val_loss: 4278.5879\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3036.8608 - val_loss: 3501.9978\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3073.7981 - val_loss: 2377.8198\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3326.2119 - val_loss: 2670.2004\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3034.7605 - val_loss: 2539.5208\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3069.4668 - val_loss: 4096.2417\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3475.8967 - val_loss: 2660.6853\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2452.1946 - val_loss: 2829.1609\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2977.3105 - val_loss: 3124.9971\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2997.5737 - val_loss: 3340.7173\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2924.5845 - val_loss: 2959.1182\n",
      "Epoch 762/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 2744.1492 - val_loss: 3542.2480\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3467.2324 - val_loss: 3197.4016\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3134.2837 - val_loss: 3890.2698\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3658.2961 - val_loss: 6291.8916\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5217.6514 - val_loss: 5755.6099\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5196.9800 - val_loss: 6762.6660\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5186.2993 - val_loss: 6341.5435\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5577.4785 - val_loss: 6993.5664\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5431.5938 - val_loss: 5446.3667\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4219.0132 - val_loss: 4885.2603\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4516.9888 - val_loss: 4485.1992\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4956.4888 - val_loss: 4185.9526\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3524.4055 - val_loss: 5316.3252\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3820.4116 - val_loss: 4790.9800\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3863.1521 - val_loss: 4860.9863\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3173.9934 - val_loss: 7095.4873\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4384.8101 - val_loss: 4417.5493\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3730.6128 - val_loss: 4758.7842\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3517.8728 - val_loss: 4493.5708\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3994.5662 - val_loss: 4572.6270\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3763.8010 - val_loss: 6487.6943\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3648.0457 - val_loss: 3832.7468\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3403.6460 - val_loss: 5026.1665\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4275.6265 - val_loss: 4390.2007\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3524.7488 - val_loss: 5736.6245\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4225.8198 - val_loss: 4024.4612\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3952.6147 - val_loss: 4346.1367\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3350.7190 - val_loss: 3868.5935\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3505.2019 - val_loss: 4750.0757\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3675.5640 - val_loss: 4073.3052\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3285.6934 - val_loss: 4412.2222\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2830.7656 - val_loss: 6450.0596\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3552.3811 - val_loss: 4769.5947\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3087.5637 - val_loss: 6961.7979\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3197.0281 - val_loss: 4977.6909\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3473.5571 - val_loss: 4837.9165\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3232.1086 - val_loss: 5045.5942\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3231.2341 - val_loss: 4454.2007\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3004.1560 - val_loss: 4593.0024\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3319.9219 - val_loss: 4528.9927\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4068.3694 - val_loss: 5190.5532\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4244.7188 - val_loss: 4153.0591\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3273.9695 - val_loss: 4504.4692\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3247.1584 - val_loss: 6708.3242\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3573.3884 - val_loss: 3749.8682\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3155.1191 - val_loss: 4497.2451\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3035.0156 - val_loss: 5064.4878\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2820.1658 - val_loss: 3988.7256\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2929.3933 - val_loss: 4791.6401\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3217.0273 - val_loss: 10182.6299\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4603.3242 - val_loss: 4337.8135\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2494.8416 - val_loss: 4135.6426\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2692.0864 - val_loss: 5825.2222\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3686.6672 - val_loss: 5811.1162\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2968.9971 - val_loss: 4942.0718\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2850.2922 - val_loss: 5332.0635\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2875.0195 - val_loss: 4785.5132\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2987.9841 - val_loss: 7385.5269\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4966.8276 - val_loss: 5562.0474\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4331.9131 - val_loss: 5143.2349\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4076.8240 - val_loss: 5218.6724\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4528.5938 - val_loss: 5236.7729\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4090.4060 - val_loss: 5337.3760\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3998.8801 - val_loss: 5364.9771\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3990.6721 - val_loss: 5498.4678\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4182.5215 - val_loss: 6800.6772\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4372.7407 - val_loss: 9530.6904\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5848.7627 - val_loss: 9048.9023\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4992.2446 - val_loss: 6334.8691\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4286.1338 - val_loss: 9671.1133\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4980.5205 - val_loss: 8773.1699\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4150.6084 - val_loss: 5528.1934\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3682.4497 - val_loss: 5801.0571\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4242.4038 - val_loss: 5247.2915\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3248.6362 - val_loss: 5762.1206\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4580.7886 - val_loss: 5933.3564\n",
      "Epoch 838/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 3511.5498 - val_loss: 4948.7495\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3463.2834 - val_loss: 5988.9150\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3743.6648 - val_loss: 5325.5928\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3140.1165 - val_loss: 4824.8052\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3387.6697 - val_loss: 4926.4741\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4169.1943 - val_loss: 4501.6455\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3637.2551 - val_loss: 3613.9534\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3938.0764 - val_loss: 3176.4924\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3617.0369 - val_loss: 3038.5291\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3716.8435 - val_loss: 4736.1641\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3453.0291 - val_loss: 4052.0042\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3187.0315 - val_loss: 3915.8035\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3214.8904 - val_loss: 7529.0962\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3931.7268 - val_loss: 4017.7141\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3187.7969 - val_loss: 5107.3521\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3621.8721 - val_loss: 5622.4062\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3473.5576 - val_loss: 3348.3044\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2659.2446 - val_loss: 3569.4119\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2764.1194 - val_loss: 4055.1042\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3055.2795 - val_loss: 3864.4246\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2726.4658 - val_loss: 4121.8013\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2687.2202 - val_loss: 4680.4541\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2576.1528 - val_loss: 4660.3423\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2515.6587 - val_loss: 4379.3696\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2730.7041 - val_loss: 4901.6582\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2752.4280 - val_loss: 4659.6270\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3145.6907 - val_loss: 5059.9526\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2778.8384 - val_loss: 3613.0923\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3133.1743 - val_loss: 7212.7949\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4309.0928 - val_loss: 5709.6182\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3234.4329 - val_loss: 5204.2227\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2720.5022 - val_loss: 4988.2119\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2615.9187 - val_loss: 5605.9502\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2687.1069 - val_loss: 4962.0244\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2537.6487 - val_loss: 7073.4805\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6267.0908 - val_loss: 5570.0605\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4023.2861 - val_loss: 4282.0103\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3580.2375 - val_loss: 5428.2935\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4117.4419 - val_loss: 5716.6206\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4464.6514 - val_loss: 7491.7251\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3998.4380 - val_loss: 4894.0962\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4275.5234 - val_loss: 6394.5605\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4269.5264 - val_loss: 5555.9570\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3385.4778 - val_loss: 3907.8137\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4221.4985 - val_loss: 4162.0151\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3443.6594 - val_loss: 4979.3306\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3619.5935 - val_loss: 4526.5781\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3693.0212 - val_loss: 7419.1831\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6310.2261 - val_loss: 5304.1787\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4129.5200 - val_loss: 4701.8286\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4759.4990 - val_loss: 11883.5557\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8636.7217 - val_loss: 4652.7778\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5142.5332 - val_loss: 6086.1968\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4558.7007 - val_loss: 4502.1396\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3766.6521 - val_loss: 7252.4419\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4242.3926 - val_loss: 3896.5256\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3542.4956 - val_loss: 4194.6553\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3125.7522 - val_loss: 4299.0342\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3371.2317 - val_loss: 3970.4402\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3158.4656 - val_loss: 4072.2500\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3206.2478 - val_loss: 3912.5376\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3187.3647 - val_loss: 3932.8818\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3279.6953 - val_loss: 4775.7065\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3345.4480 - val_loss: 4587.7222\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2893.1997 - val_loss: 5226.4561\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6361.1538 - val_loss: 4764.1636\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4632.9351 - val_loss: 8581.3965\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4853.4961 - val_loss: 6308.7163\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4707.9282 - val_loss: 6334.9912\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5016.0293 - val_loss: 6468.0278\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4762.0791 - val_loss: 5953.4688\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4760.7378 - val_loss: 5360.0332\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4448.6372 - val_loss: 4928.6699\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3509.4167 - val_loss: 6637.5981\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3784.8999 - val_loss: 5386.0459\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4014.8052 - val_loss: 4627.8721\n",
      "Epoch 914/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 3450.4983 - val_loss: 4478.1953\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3946.7532 - val_loss: 9313.4531\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4494.2070 - val_loss: 4883.1987\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4328.8232 - val_loss: 4785.8364\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4103.3149 - val_loss: 5160.8184\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3811.3928 - val_loss: 6478.5210\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4373.6372 - val_loss: 5713.0400\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3949.1084 - val_loss: 6038.7036\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3390.4072 - val_loss: 7243.3252\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3999.4717 - val_loss: 6918.8970\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3957.4407 - val_loss: 6138.0225\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3473.4019 - val_loss: 5191.4214\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2709.6858 - val_loss: 6136.6743\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2854.3125 - val_loss: 5483.0425\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3819.2556 - val_loss: 5355.2441\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4840.0723 - val_loss: 5663.5962\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5741.8110 - val_loss: 5857.2856\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5488.0728 - val_loss: 5118.0708\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5339.2056 - val_loss: 5634.5684\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5488.4194 - val_loss: 6740.0059\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6317.3296 - val_loss: 5934.2212\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6206.9312 - val_loss: 5070.7104\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5123.4761 - val_loss: 5493.4814\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5019.8989 - val_loss: 5133.8193\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4621.0801 - val_loss: 4314.7661\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3509.8293 - val_loss: 4508.1763\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3836.3425 - val_loss: 4944.7065\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3741.9185 - val_loss: 4587.1777\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3634.1416 - val_loss: 7383.3511\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4478.2080 - val_loss: 4607.6787\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3488.5935 - val_loss: 5993.7290\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3531.3518 - val_loss: 6053.8042\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4036.4561 - val_loss: 4217.2041\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3414.8384 - val_loss: 3910.7310\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3906.2935 - val_loss: 5977.6504\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5074.9351 - val_loss: 4476.0205\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4666.6816 - val_loss: 4506.3872\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4168.9731 - val_loss: 6036.7290\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4770.8389 - val_loss: 4724.8843\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4518.5547 - val_loss: 4648.1895\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4555.2959 - val_loss: 5182.0249\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5046.4673 - val_loss: 4689.8013\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4269.5981 - val_loss: 4807.3438\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4157.3872 - val_loss: 4556.5195\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3717.0552 - val_loss: 4175.1055\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3815.5076 - val_loss: 3976.3833\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3600.7336 - val_loss: 6115.3159\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4251.2124 - val_loss: 5513.9946\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3522.8560 - val_loss: 3648.6279\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3697.8745 - val_loss: 4150.7915\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3148.5583 - val_loss: 3687.6411\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3460.2810 - val_loss: 3885.7693\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3257.8250 - val_loss: 3801.7168\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3642.5159 - val_loss: 4087.1223\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4323.1558 - val_loss: 4305.2261\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3649.3035 - val_loss: 4759.3740\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4731.7095 - val_loss: 4011.4902\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3089.5828 - val_loss: 3902.0081\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3610.5205 - val_loss: 5783.3574\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3986.3481 - val_loss: 4737.8438\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3667.7476 - val_loss: 3417.9785\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3820.5667 - val_loss: 4368.1943\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4719.4697 - val_loss: 4631.3384\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3969.1829 - val_loss: 5040.9551\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4291.3188 - val_loss: 6370.1157\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4724.8896 - val_loss: 5895.2754\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4339.3389 - val_loss: 5001.8438\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3989.4204 - val_loss: 5403.7383\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4130.2007 - val_loss: 5963.8228\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3510.9321 - val_loss: 5281.2197\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4352.1172 - val_loss: 5825.6416\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3987.6538 - val_loss: 4431.7568\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3442.0979 - val_loss: 5849.9688\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3339.5852 - val_loss: 4743.1699\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3540.1467 - val_loss: 4460.5166\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3576.6406 - val_loss: 4686.0122\n",
      "Epoch 990/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 3369.1404 - val_loss: 5072.3262\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3347.2029 - val_loss: 5446.8740\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3382.3772 - val_loss: 5131.7812\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3458.4353 - val_loss: 8208.6484\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3662.4319 - val_loss: 7196.5991\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2918.6274 - val_loss: 8184.9512\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3620.2712 - val_loss: 6801.6445\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3163.9038 - val_loss: 6570.4067\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3128.1541 - val_loss: 5178.2134\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2960.6797 - val_loss: 5060.1992\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2502.1267 - val_loss: 4477.3613\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3312.3689 - val_loss: 3871.7153\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5528.4331 - val_loss: 4221.6978\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4509.5332 - val_loss: 4610.8569\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4356.9795 - val_loss: 4352.2881\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4942.9434 - val_loss: 4880.4121\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4005.0408 - val_loss: 5011.9756\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4051.1943 - val_loss: 4768.3735\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4029.8787 - val_loss: 4973.1001\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5091.3506 - val_loss: 6004.0464\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5018.4888 - val_loss: 14012.3584\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6502.3892 - val_loss: 5828.5557\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4061.2097 - val_loss: 5263.8286\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4426.6313 - val_loss: 6171.2646\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4453.7056 - val_loss: 5246.2524\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4879.6709 - val_loss: 4836.3496\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4778.0596 - val_loss: 6204.2402\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4404.6426 - val_loss: 4816.3413\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3548.2222 - val_loss: 5068.9155\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3946.9705 - val_loss: 5037.3179\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4419.1245 - val_loss: 4739.4146\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5028.8149 - val_loss: 4713.7383\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4954.7158 - val_loss: 5326.0854\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4639.4707 - val_loss: 5329.9419\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4839.4775 - val_loss: 5159.8569\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5717.7847 - val_loss: 6121.4683\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4382.1724 - val_loss: 5624.0625\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4426.5151 - val_loss: 8076.5117\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4791.7524 - val_loss: 5827.1445\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3762.0383 - val_loss: 5649.9810\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3717.5466 - val_loss: 6256.6958\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4351.3647 - val_loss: 5791.0508\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4656.6504 - val_loss: 5254.7598\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4510.9512 - val_loss: 4444.7329\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4565.7998 - val_loss: 3697.2563\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3926.2700 - val_loss: 4375.4355\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3683.0505 - val_loss: 4712.3843\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3480.0652 - val_loss: 5840.8369\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3774.7410 - val_loss: 4601.1372\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4167.2251 - val_loss: 4320.6401\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4441.3330 - val_loss: 4651.2104\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4589.0830 - val_loss: 3719.0537\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3676.6311 - val_loss: 3979.4436\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3279.7576 - val_loss: 4212.2222\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3789.6714 - val_loss: 5294.6499\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3146.2590 - val_loss: 5715.9756\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3090.9351 - val_loss: 6093.7090\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3161.1028 - val_loss: 5701.0742\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3060.3218 - val_loss: 7256.8945\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3610.4624 - val_loss: 4393.6167\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3956.8347 - val_loss: 5896.7695\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3294.6599 - val_loss: 4174.4204\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3685.7188 - val_loss: 4332.5146\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3817.8386 - val_loss: 5181.8521\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3531.1819 - val_loss: 5189.5972\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3943.8574 - val_loss: 6531.6309\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3386.2112 - val_loss: 7803.9121\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4166.7007 - val_loss: 6405.3657\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3944.3547 - val_loss: 6176.6260\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3805.0874 - val_loss: 5246.6294\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4138.8579 - val_loss: 5573.2534\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3991.3193 - val_loss: 4231.7544\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4677.3169 - val_loss: 5830.5127\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5991.8618 - val_loss: 8045.1958\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6603.6875 - val_loss: 5816.6396\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5562.2124 - val_loss: 7128.5801\n",
      "Epoch 1066/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 5553.0977 - val_loss: 7770.9448\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5091.3652 - val_loss: 4311.6650\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3905.2075 - val_loss: 5615.0444\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4269.8135 - val_loss: 6571.4907\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4115.8057 - val_loss: 4307.0356\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3644.0693 - val_loss: 6363.1104\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5139.7231 - val_loss: 6496.1191\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4682.1812 - val_loss: 10444.8066\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5799.5854 - val_loss: 5417.5669\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4425.8457 - val_loss: 4697.7812\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5086.8364 - val_loss: 6863.3784\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5939.6538 - val_loss: 5876.4668\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5308.3726 - val_loss: 5890.4263\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4453.7676 - val_loss: 3736.4641\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3818.8772 - val_loss: 3707.6729\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2847.6284 - val_loss: 6058.7197\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4354.5200 - val_loss: 5708.9556\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3233.2615 - val_loss: 5441.3838\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2993.9138 - val_loss: 4837.0400\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3486.5867 - val_loss: 4846.4688\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3407.1167 - val_loss: 5580.8335\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3924.3596 - val_loss: 7270.2212\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4050.5066 - val_loss: 5651.8091\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3990.0242 - val_loss: 5851.6606\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3814.4932 - val_loss: 4670.4292\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3017.1008 - val_loss: 5402.3691\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3114.0078 - val_loss: 7254.0303\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3813.2705 - val_loss: 4917.4351\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3251.5176 - val_loss: 7681.7363\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3675.4785 - val_loss: 4917.0273\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3234.8855 - val_loss: 4502.2622\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3207.6343 - val_loss: 8255.2119\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3842.6108 - val_loss: 4975.2808\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3800.0535 - val_loss: 5601.5405\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3794.9709 - val_loss: 5408.6538\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3863.4998 - val_loss: 5233.5781\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3817.5569 - val_loss: 7034.4502\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4255.6772 - val_loss: 4860.7637\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4259.3892 - val_loss: 5611.3462\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3881.0605 - val_loss: 6189.4824\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4048.3550 - val_loss: 10424.7275\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4452.5801 - val_loss: 6812.5122\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4807.0835 - val_loss: 6725.3882\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6152.1475 - val_loss: 5318.1792\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4316.7949 - val_loss: 4600.3770\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3912.8838 - val_loss: 4768.5273\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3690.9658 - val_loss: 5502.2905\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3675.2456 - val_loss: 4747.2944\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3663.5952 - val_loss: 5154.8599\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4175.8208 - val_loss: 13807.0137\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6086.0864 - val_loss: 6329.8555\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3789.8411 - val_loss: 6172.7500\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4789.9224 - val_loss: 6388.3804\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4976.8887 - val_loss: 6488.2207\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3900.0288 - val_loss: 7282.8057\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3768.6238 - val_loss: 7828.7456\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4078.7742 - val_loss: 5713.7788\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3378.8462 - val_loss: 5838.0981\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3920.9038 - val_loss: 4810.1592\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3364.6624 - val_loss: 4559.1973\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3049.2656 - val_loss: 4583.0269\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2773.2593 - val_loss: 4354.2344\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2854.0273 - val_loss: 6016.0845\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3618.2246 - val_loss: 5315.3472\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2905.5801 - val_loss: 4753.6299\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3047.9312 - val_loss: 12833.6826\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7886.7417 - val_loss: 12068.2383\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6626.9575 - val_loss: 10318.6729\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6456.8701 - val_loss: 6788.0835\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4821.3247 - val_loss: 9051.3389\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4456.6577 - val_loss: 5603.8911\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4032.5667 - val_loss: 5492.0625\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4016.0166 - val_loss: 5017.6460\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3542.0396 - val_loss: 6744.3262\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4633.1909 - val_loss: 7476.9561\n",
      "Epoch 1141/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4606.3081 - val_loss: 6432.0737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4961.5801 - val_loss: 5769.2026\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3620.0208 - val_loss: 6554.9839\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4531.3984 - val_loss: 10912.4932\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6420.7939 - val_loss: 7784.1738\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4958.8301 - val_loss: 13439.9014\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6114.8398 - val_loss: 8812.9619\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6192.6094 - val_loss: 8095.7178\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5324.2788 - val_loss: 4946.2993\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4012.6301 - val_loss: 6962.8599\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3594.7734 - val_loss: 4210.5415\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3880.7344 - val_loss: 4078.6682\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3376.0320 - val_loss: 4842.4355\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3533.9602 - val_loss: 3674.5503\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3220.4353 - val_loss: 3662.5205\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8453.7715 - val_loss: 5088.0117\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5542.8384 - val_loss: 6276.4604\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5575.7085 - val_loss: 4380.8696\n",
      "Epoch 1159/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4916.4707 - val_loss: 5748.9038\n",
      "Epoch 1160/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4635.9849 - val_loss: 5297.6270\n",
      "Epoch 1161/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3768.2917 - val_loss: 4499.2319\n",
      "Epoch 1162/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3941.0579 - val_loss: 5507.3413\n",
      "Epoch 1163/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3398.6301 - val_loss: 3537.7927\n",
      "Epoch 1164/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3781.9485 - val_loss: 5453.0659\n",
      "Epoch 1165/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4000.8462 - val_loss: 3802.0754\n",
      "Epoch 1166/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3596.1465 - val_loss: 6038.6992\n",
      "Epoch 1167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3771.0933 - val_loss: 4976.3535\n",
      "Epoch 1168/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3713.6282 - val_loss: 4901.7974\n",
      "Epoch 1169/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3785.2212 - val_loss: 4592.4404\n",
      "Epoch 1170/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3393.6384 - val_loss: 4199.0283\n",
      "Epoch 1171/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3437.1851 - val_loss: 4872.9697\n",
      "Epoch 1172/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2994.2314 - val_loss: 3812.4810\n",
      "Epoch 1173/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3014.2732 - val_loss: 7849.9463\n",
      "Epoch 1174/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4004.6667 - val_loss: 4521.4634\n",
      "Epoch 1175/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3037.2434 - val_loss: 4882.4463\n",
      "Epoch 1176/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3545.0681 - val_loss: 6550.6709\n",
      "Epoch 1177/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4963.8193 - val_loss: 3730.7869\n",
      "Epoch 1178/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4233.6562 - val_loss: 5495.1646\n",
      "Epoch 1179/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4998.2817 - val_loss: 5153.9258\n",
      "Epoch 1180/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4737.0156 - val_loss: 7387.6318\n",
      "Epoch 1181/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5002.3433 - val_loss: 3974.8235\n",
      "Epoch 1182/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4206.6460 - val_loss: 11093.3193\n",
      "Epoch 1183/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5023.0479 - val_loss: 5003.8433\n",
      "Epoch 1184/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3620.2585 - val_loss: 3651.0452\n",
      "Epoch 1185/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3521.2461 - val_loss: 3246.8997\n",
      "Epoch 1186/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2924.5938 - val_loss: 3223.6355\n",
      "Epoch 1187/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3469.8296 - val_loss: 3821.5510\n",
      "Epoch 1188/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3169.7515 - val_loss: 3506.2598\n",
      "Epoch 1189/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2975.8462 - val_loss: 3525.3396\n",
      "Epoch 1190/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3316.5745 - val_loss: 3357.7188\n",
      "Epoch 1191/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3031.7471 - val_loss: 2789.5505\n",
      "Epoch 1192/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3189.0173 - val_loss: 3890.8088\n",
      "Epoch 1193/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2693.0103 - val_loss: 3541.0176\n",
      "Epoch 1194/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2906.9265 - val_loss: 3426.8455\n",
      "Epoch 1195/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2897.9739 - val_loss: 3377.1621\n",
      "Epoch 1196/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2812.8914 - val_loss: 6013.1133\n",
      "Epoch 1197/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2967.5676 - val_loss: 4312.5522\n",
      "Epoch 1198/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2255.5691 - val_loss: 5034.0132\n",
      "Epoch 1199/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2808.7603 - val_loss: 4862.0571\n",
      "Epoch 1200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4710.1118 - val_loss: 5096.0137\n",
      "Epoch 1201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4475.9380 - val_loss: 4674.6738\n",
      "Epoch 1202/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4412.8730 - val_loss: 4371.6123\n",
      "Epoch 1203/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4622.2568 - val_loss: 5449.2002\n",
      "Epoch 1204/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3591.6990 - val_loss: 5992.4434\n",
      "Epoch 1205/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4088.0342 - val_loss: 9117.3838\n",
      "Epoch 1206/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5816.1426 - val_loss: 5562.5771\n",
      "Epoch 1207/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4905.0703 - val_loss: 5690.1680\n",
      "Epoch 1208/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4704.2900 - val_loss: 4140.0981\n",
      "Epoch 1209/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4156.1943 - val_loss: 4104.4092\n",
      "Epoch 1210/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4712.9639 - val_loss: 4906.5947\n",
      "Epoch 1211/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4580.5874 - val_loss: 8536.3838\n",
      "Epoch 1212/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4702.1670 - val_loss: 5484.3169\n",
      "Epoch 1213/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4157.4932 - val_loss: 4180.5117\n",
      "Epoch 1214/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4269.3228 - val_loss: 4346.5405\n",
      "Epoch 1215/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4356.8086 - val_loss: 4251.5488\n",
      "Epoch 1216/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3849.6702 - val_loss: 5612.9741\n",
      "Epoch 1217/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4417.1069 - val_loss: 3954.2246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1218/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4233.9214 - val_loss: 4117.9385\n",
      "Epoch 1219/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4097.2192 - val_loss: 4214.1299\n",
      "Epoch 1220/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4115.5376 - val_loss: 6793.2822\n",
      "Epoch 1221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6095.6367 - val_loss: 7231.1553\n",
      "Epoch 1222/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6480.8462 - val_loss: 6342.2510\n",
      "Epoch 1223/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5182.1489 - val_loss: 5592.7407\n",
      "Epoch 1224/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4527.3906 - val_loss: 6547.6226\n",
      "Epoch 1225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4429.6274 - val_loss: 6638.0947\n",
      "Epoch 1226/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4382.2749 - val_loss: 6825.2520\n",
      "Epoch 1227/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4018.8291 - val_loss: 6582.1367\n",
      "Epoch 1228/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3944.6306 - val_loss: 5861.6396\n",
      "Epoch 1229/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4504.4424 - val_loss: 6614.6699\n",
      "Epoch 1230/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3731.1855 - val_loss: 5747.5156\n",
      "Epoch 1231/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3148.4885 - val_loss: 5935.6406\n",
      "Epoch 1232/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2917.2236 - val_loss: 6095.3428\n",
      "Epoch 1233/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2984.6201 - val_loss: 6171.8179\n",
      "Epoch 1234/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2991.5435 - val_loss: 5736.6714\n",
      "Epoch 1235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3164.8213 - val_loss: 6571.7432\n",
      "Epoch 1236/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3724.3630 - val_loss: 5887.8613\n",
      "Epoch 1237/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3351.6416 - val_loss: 5314.8135\n",
      "Epoch 1238/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2882.2700 - val_loss: 4920.8228\n",
      "Epoch 1239/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2732.4961 - val_loss: 4593.3887\n",
      "Epoch 1240/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3151.6443 - val_loss: 7087.7661\n",
      "Epoch 1241/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4209.1118 - val_loss: 5641.1206\n",
      "Epoch 1242/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3037.1650 - val_loss: 3610.4685\n",
      "Epoch 1243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2583.9270 - val_loss: 3665.5764\n",
      "Epoch 1244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2526.2964 - val_loss: 3605.5525\n",
      "Epoch 1245/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2673.5388 - val_loss: 3684.9504\n",
      "Epoch 1246/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2425.9155 - val_loss: 3557.2939\n",
      "Epoch 1247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2350.8101 - val_loss: 3728.6501\n",
      "Epoch 1248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2220.1277 - val_loss: 3350.9011\n",
      "Epoch 1249/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2383.8340 - val_loss: 3420.2161\n",
      "Epoch 1250/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2236.3105 - val_loss: 3528.3193\n",
      "Epoch 1251/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2295.6331 - val_loss: 3669.7300\n",
      "Epoch 1252/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2518.5857 - val_loss: 3549.0254\n",
      "Epoch 1253/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2412.2969Restoring model weights from the end of the best epoch: 753.\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2444.1450 - val_loss: 4310.0371\n",
      "Epoch 1253: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>420.905212</td>\n",
       "      <td>420.905212</td>\n",
       "      <td>420.905212</td>\n",
       "      <td>420.905212</td>\n",
       "      <td>420.905212</td>\n",
       "      <td>420.905212</td>\n",
       "      <td>531.633057</td>\n",
       "      <td>531.633057</td>\n",
       "      <td>531.633057</td>\n",
       "      <td>531.633057</td>\n",
       "      <td>531.633057</td>\n",
       "      <td>420.905212</td>\n",
       "      <td>531.633057</td>\n",
       "      <td>603.826294</td>\n",
       "      <td>531.633057</td>\n",
       "      <td>531.633057</td>\n",
       "      <td>531.633057</td>\n",
       "      <td>603.789612</td>\n",
       "      <td>603.826355</td>\n",
       "      <td>603.826355</td>\n",
       "      <td>603.826355</td>\n",
       "      <td>603.826355</td>\n",
       "      <td>603.826355</td>\n",
       "      <td>603.826355</td>\n",
       "      <td>603.826355</td>\n",
       "      <td>603.826355</td>\n",
       "      <td>603.823914</td>\n",
       "      <td>603.826172</td>\n",
       "      <td>531.633057</td>\n",
       "      <td>531.633057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>413.46</td>\n",
       "      <td>497.019</td>\n",
       "      <td>476.478</td>\n",
       "      <td>421.395</td>\n",
       "      <td>413.641</td>\n",
       "      <td>338.033</td>\n",
       "      <td>431.028</td>\n",
       "      <td>305.105</td>\n",
       "      <td>402.406</td>\n",
       "      <td>419.419</td>\n",
       "      <td>336.054</td>\n",
       "      <td>568.395</td>\n",
       "      <td>541.488</td>\n",
       "      <td>537.851</td>\n",
       "      <td>526.265</td>\n",
       "      <td>559.293</td>\n",
       "      <td>466.646</td>\n",
       "      <td>416.049</td>\n",
       "      <td>501.489</td>\n",
       "      <td>460.699</td>\n",
       "      <td>445.583</td>\n",
       "      <td>509.271</td>\n",
       "      <td>532.602</td>\n",
       "      <td>500.905</td>\n",
       "      <td>588.495</td>\n",
       "      <td>589.349</td>\n",
       "      <td>543.982</td>\n",
       "      <td>614.074</td>\n",
       "      <td>557.419</td>\n",
       "      <td>412.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>7.445221</td>\n",
       "      <td>76.1138</td>\n",
       "      <td>55.572784</td>\n",
       "      <td>0.489777</td>\n",
       "      <td>7.264221</td>\n",
       "      <td>82.872223</td>\n",
       "      <td>100.605042</td>\n",
       "      <td>226.528046</td>\n",
       "      <td>129.227051</td>\n",
       "      <td>112.21405</td>\n",
       "      <td>195.579071</td>\n",
       "      <td>147.489807</td>\n",
       "      <td>9.854919</td>\n",
       "      <td>65.975281</td>\n",
       "      <td>5.368042</td>\n",
       "      <td>27.659973</td>\n",
       "      <td>64.987061</td>\n",
       "      <td>187.740601</td>\n",
       "      <td>102.337341</td>\n",
       "      <td>143.12735</td>\n",
       "      <td>158.243347</td>\n",
       "      <td>94.555359</td>\n",
       "      <td>71.224365</td>\n",
       "      <td>102.921356</td>\n",
       "      <td>15.33136</td>\n",
       "      <td>14.477356</td>\n",
       "      <td>59.841919</td>\n",
       "      <td>10.247803</td>\n",
       "      <td>25.78595</td>\n",
       "      <td>119.051056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1           2           3           4   \\\n",
       "Month          Month-1     Month-2     Month-3     Month-4     Month-5   \n",
       "Prediction  420.905212  420.905212  420.905212  420.905212  420.905212   \n",
       "Target          413.46     497.019     476.478     421.395     413.641   \n",
       "Error         7.445221     76.1138   55.572784    0.489777    7.264221   \n",
       "\n",
       "                    5           6           7           8           9   \\\n",
       "Month          Month-6     Month-7     Month-8     Month-9    Month-10   \n",
       "Prediction  420.905212  531.633057  531.633057  531.633057  531.633057   \n",
       "Target         338.033     431.028     305.105     402.406     419.419   \n",
       "Error        82.872223  100.605042  226.528046  129.227051   112.21405   \n",
       "\n",
       "                    10          11          12          13          14  \\\n",
       "Month         Month-11    Month-12    Month-13    Month-14    Month-15   \n",
       "Prediction  531.633057  420.905212  531.633057  603.826294  531.633057   \n",
       "Target         336.054     568.395     541.488     537.851     526.265   \n",
       "Error       195.579071  147.489807    9.854919   65.975281    5.368042   \n",
       "\n",
       "                    15          16          17          18          19  \\\n",
       "Month         Month-16    Month-17    Month-18    Month-19    Month-20   \n",
       "Prediction  531.633057  531.633057  603.789612  603.826355  603.826355   \n",
       "Target         559.293     466.646     416.049     501.489     460.699   \n",
       "Error        27.659973   64.987061  187.740601  102.337341   143.12735   \n",
       "\n",
       "                    20          21          22          23          24  \\\n",
       "Month         Month-21    Month-22    Month-23    Month-24    Month-25   \n",
       "Prediction  603.826355  603.826355  603.826355  603.826355  603.826355   \n",
       "Target         445.583     509.271     532.602     500.905     588.495   \n",
       "Error       158.243347   94.555359   71.224365  102.921356    15.33136   \n",
       "\n",
       "                    25          26          27          28          29  \n",
       "Month         Month-26    Month-27    Month-28    Month-29    Month-30  \n",
       "Prediction  603.826355  603.823914  603.826172  531.633057  531.633057  \n",
       "Target         589.349     543.982     614.074     557.419     412.582  \n",
       "Error        14.477356   59.841919   10.247803    25.78595  119.051056  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.671036"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.18851952"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Ano-0: |Prediction[[5604.502]] - Target[5022.433000000001]| =  Error: [[582.06885]]; MAPE:[[0.1158938]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Ano-0: |Prediction[[6957.1055]] - Target[5998.141]| =  Error: [[958.96436]]; MAPE:[[0.15987693]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-5: |Prediction[[3478.5688]] - Target[3305.901]| =  Error: [[172.66797]]; MAPE:[[0.05223023]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[582.06885]], dtype=float32),\n",
       " array([[958.96436]], dtype=float32),\n",
       " array([[172.66797]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "571.2337"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.10933366"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
