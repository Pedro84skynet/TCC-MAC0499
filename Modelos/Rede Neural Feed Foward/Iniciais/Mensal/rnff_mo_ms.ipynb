{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Mato Grosso Do Sul - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Mato Grosso do Sul - IDH</th>\n",
       "      <th>Mato Grosso Do Sul - Produção de Cimento (t)</th>\n",
       "      <th>Mato Grosso do Sul - Desemprego</th>\n",
       "      <th>Mato Grosso do Sul - value</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Estadual</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Construção Civil</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Per Capita</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Preços de Mercado</th>\n",
       "      <th>Mato Grosso Do Sul - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>0.741626</td>\n",
       "      <td>53.166560</td>\n",
       "      <td>8.248824</td>\n",
       "      <td>0.282837</td>\n",
       "      <td>4.562945e+07</td>\n",
       "      <td>2.151917e+06</td>\n",
       "      <td>16.203179</td>\n",
       "      <td>3.957545e+07</td>\n",
       "      <td>33.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>0.741710</td>\n",
       "      <td>53.245714</td>\n",
       "      <td>8.242935</td>\n",
       "      <td>0.284487</td>\n",
       "      <td>4.568706e+07</td>\n",
       "      <td>2.153542e+06</td>\n",
       "      <td>16.206131</td>\n",
       "      <td>3.959155e+07</td>\n",
       "      <td>32.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>0.741794</td>\n",
       "      <td>52.994640</td>\n",
       "      <td>8.237046</td>\n",
       "      <td>0.285379</td>\n",
       "      <td>4.574467e+07</td>\n",
       "      <td>2.155168e+06</td>\n",
       "      <td>16.209084</td>\n",
       "      <td>3.960765e+07</td>\n",
       "      <td>33.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>0.741878</td>\n",
       "      <td>53.019283</td>\n",
       "      <td>8.231157</td>\n",
       "      <td>0.286089</td>\n",
       "      <td>4.580228e+07</td>\n",
       "      <td>2.156794e+06</td>\n",
       "      <td>16.212036</td>\n",
       "      <td>3.962375e+07</td>\n",
       "      <td>34.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>0.741962</td>\n",
       "      <td>53.539593</td>\n",
       "      <td>8.225268</td>\n",
       "      <td>0.286122</td>\n",
       "      <td>4.585990e+07</td>\n",
       "      <td>2.158419e+06</td>\n",
       "      <td>16.214989</td>\n",
       "      <td>3.963985e+07</td>\n",
       "      <td>36.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.097125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.657488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.966263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.518616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.205635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.243342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0       2003-1                                          0.724032   \n",
       "1       2003-2                                          0.690297   \n",
       "2       2003-3                                          0.669681   \n",
       "3       2003-4                                          0.660494   \n",
       "4       2003-5                                          0.648337   \n",
       "..         ...                                               ...   \n",
       "235     2022-8                                               NaN   \n",
       "236     2022-9                                               NaN   \n",
       "237    2022-10                                               NaN   \n",
       "238    2022-11                                               NaN   \n",
       "239    2022-12                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     Mato Grosso do Sul - IDH  Mato Grosso Do Sul - Produção de Cimento (t)  \\\n",
       "0                    0.741626                                     53.166560   \n",
       "1                    0.741710                                     53.245714   \n",
       "2                    0.741794                                     52.994640   \n",
       "3                    0.741878                                     53.019283   \n",
       "4                    0.741962                                     53.539593   \n",
       "..                        ...                                           ...   \n",
       "235                       NaN                                     72.097125   \n",
       "236                       NaN                                     71.657488   \n",
       "237                       NaN                                     71.966263   \n",
       "238                       NaN                                     72.205635   \n",
       "239                       NaN                                     72.243342   \n",
       "\n",
       "     Mato Grosso do Sul - Desemprego  Mato Grosso do Sul - value  \\\n",
       "0                           8.248824                    0.282837   \n",
       "1                           8.242935                    0.284487   \n",
       "2                           8.237046                    0.285379   \n",
       "3                           8.231157                    0.286089   \n",
       "4                           8.225268                    0.286122   \n",
       "..                               ...                         ...   \n",
       "235                              NaN                    0.523445   \n",
       "236                              NaN                    0.521590   \n",
       "237                              NaN                    0.518616   \n",
       "238                              NaN                    0.515040   \n",
       "239                              NaN                    0.511979   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Estadual  \\\n",
       "0                           4.562945e+07   \n",
       "1                           4.568706e+07   \n",
       "2                           4.574467e+07   \n",
       "3                           4.580228e+07   \n",
       "4                           4.585990e+07   \n",
       "..                                   ...   \n",
       "235                                  NaN   \n",
       "236                                  NaN   \n",
       "237                                  NaN   \n",
       "238                                  NaN   \n",
       "239                                  NaN   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Construção Civil  \\\n",
       "0                                   2.151917e+06   \n",
       "1                                   2.153542e+06   \n",
       "2                                   2.155168e+06   \n",
       "3                                   2.156794e+06   \n",
       "4                                   2.158419e+06   \n",
       "..                                           ...   \n",
       "235                                          NaN   \n",
       "236                                          NaN   \n",
       "237                                          NaN   \n",
       "238                                          NaN   \n",
       "239                                          NaN   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Per Capita  \\\n",
       "0                                16.203179   \n",
       "1                                16.206131   \n",
       "2                                16.209084   \n",
       "3                                16.212036   \n",
       "4                                16.214989   \n",
       "..                                     ...   \n",
       "235                                    NaN   \n",
       "236                                    NaN   \n",
       "237                                    NaN   \n",
       "238                                    NaN   \n",
       "239                                    NaN   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Preços de Mercado  \\\n",
       "0                                    3.957545e+07   \n",
       "1                                    3.959155e+07   \n",
       "2                                    3.960765e+07   \n",
       "3                                    3.962375e+07   \n",
       "4                                    3.963985e+07   \n",
       "..                                            ...   \n",
       "235                                           NaN   \n",
       "236                                           NaN   \n",
       "237                                           NaN   \n",
       "238                                           NaN   \n",
       "239                                           NaN   \n",
       "\n",
       "     Mato Grosso Do Sul - Consumo de Cimento (t)  \n",
       "0                                         33.744  \n",
       "1                                         32.230  \n",
       "2                                         33.559  \n",
       "3                                         34.283  \n",
       "4                                         36.066  \n",
       "..                                           ...  \n",
       "235                                      103.854  \n",
       "236                                       95.890  \n",
       "237                                       89.679  \n",
       "238                                       99.356  \n",
       "239                                       99.356  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_MS.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Mato Grosso do Sul - IDH</th>\n",
       "      <th>Mato Grosso Do Sul - Produção de Cimento (t)</th>\n",
       "      <th>Mato Grosso do Sul - Desemprego</th>\n",
       "      <th>Mato Grosso do Sul - value</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Estadual</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Construção Civil</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Per Capita</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.739598</td>\n",
       "      <td>-1.432541</td>\n",
       "      <td>1.216541</td>\n",
       "      <td>-0.459341</td>\n",
       "      <td>-1.637645</td>\n",
       "      <td>-2.402906</td>\n",
       "      <td>-1.784438</td>\n",
       "      <td>-1.738619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.720624</td>\n",
       "      <td>-1.423955</td>\n",
       "      <td>1.206220</td>\n",
       "      <td>-0.422027</td>\n",
       "      <td>-1.622679</td>\n",
       "      <td>-2.361122</td>\n",
       "      <td>-1.774070</td>\n",
       "      <td>-1.724323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.701651</td>\n",
       "      <td>-1.451188</td>\n",
       "      <td>1.195898</td>\n",
       "      <td>-0.401858</td>\n",
       "      <td>-1.607713</td>\n",
       "      <td>-2.319339</td>\n",
       "      <td>-1.763703</td>\n",
       "      <td>-1.710027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.682677</td>\n",
       "      <td>-1.448515</td>\n",
       "      <td>1.185577</td>\n",
       "      <td>-0.385815</td>\n",
       "      <td>-1.592747</td>\n",
       "      <td>-2.277555</td>\n",
       "      <td>-1.753336</td>\n",
       "      <td>-1.695732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.663704</td>\n",
       "      <td>-1.392079</td>\n",
       "      <td>1.175256</td>\n",
       "      <td>-0.385067</td>\n",
       "      <td>-1.577781</td>\n",
       "      <td>-2.235771</td>\n",
       "      <td>-1.742968</td>\n",
       "      <td>-1.681436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.190288</td>\n",
       "      <td>-0.831849</td>\n",
       "      <td>-1.205180</td>\n",
       "      <td>0.316446</td>\n",
       "      <td>1.171465</td>\n",
       "      <td>-0.292680</td>\n",
       "      <td>0.923349</td>\n",
       "      <td>1.021439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.165389</td>\n",
       "      <td>-0.799920</td>\n",
       "      <td>-1.216425</td>\n",
       "      <td>0.383902</td>\n",
       "      <td>1.161163</td>\n",
       "      <td>-0.292842</td>\n",
       "      <td>0.905256</td>\n",
       "      <td>1.007593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.140489</td>\n",
       "      <td>-0.711338</td>\n",
       "      <td>-1.227670</td>\n",
       "      <td>0.452548</td>\n",
       "      <td>1.150861</td>\n",
       "      <td>-0.293004</td>\n",
       "      <td>0.887162</td>\n",
       "      <td>0.993747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.115590</td>\n",
       "      <td>-0.636591</td>\n",
       "      <td>-1.238915</td>\n",
       "      <td>0.528940</td>\n",
       "      <td>1.140559</td>\n",
       "      <td>-0.293166</td>\n",
       "      <td>0.869069</td>\n",
       "      <td>0.979902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.090690</td>\n",
       "      <td>-0.611490</td>\n",
       "      <td>-1.250161</td>\n",
       "      <td>0.606406</td>\n",
       "      <td>1.130257</td>\n",
       "      <td>-0.293327</td>\n",
       "      <td>0.850975</td>\n",
       "      <td>0.966056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Mato Grosso do Sul - IDH  Mato Grosso Do Sul - Produção de Cimento (t)  \\\n",
       "0                   -1.739598                                     -1.432541   \n",
       "1                   -1.720624                                     -1.423955   \n",
       "2                   -1.701651                                     -1.451188   \n",
       "3                   -1.682677                                     -1.448515   \n",
       "4                   -1.663704                                     -1.392079   \n",
       "..                        ...                                           ...   \n",
       "187                  1.190288                                     -0.831849   \n",
       "188                  1.165389                                     -0.799920   \n",
       "189                  1.140489                                     -0.711338   \n",
       "190                  1.115590                                     -0.636591   \n",
       "191                  1.090690                                     -0.611490   \n",
       "\n",
       "     Mato Grosso do Sul - Desemprego  Mato Grosso do Sul - value  \\\n",
       "0                           1.216541                   -0.459341   \n",
       "1                           1.206220                   -0.422027   \n",
       "2                           1.195898                   -0.401858   \n",
       "3                           1.185577                   -0.385815   \n",
       "4                           1.175256                   -0.385067   \n",
       "..                               ...                         ...   \n",
       "187                        -1.205180                    0.316446   \n",
       "188                        -1.216425                    0.383902   \n",
       "189                        -1.227670                    0.452548   \n",
       "190                        -1.238915                    0.528940   \n",
       "191                        -1.250161                    0.606406   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Estadual  \\\n",
       "0                              -1.637645   \n",
       "1                              -1.622679   \n",
       "2                              -1.607713   \n",
       "3                              -1.592747   \n",
       "4                              -1.577781   \n",
       "..                                   ...   \n",
       "187                             1.171465   \n",
       "188                             1.161163   \n",
       "189                             1.150861   \n",
       "190                             1.140559   \n",
       "191                             1.130257   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Construção Civil  \\\n",
       "0                                      -2.402906   \n",
       "1                                      -2.361122   \n",
       "2                                      -2.319339   \n",
       "3                                      -2.277555   \n",
       "4                                      -2.235771   \n",
       "..                                           ...   \n",
       "187                                    -0.292680   \n",
       "188                                    -0.292842   \n",
       "189                                    -0.293004   \n",
       "190                                    -0.293166   \n",
       "191                                    -0.293327   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Per Capita  \\\n",
       "0                                -1.784438   \n",
       "1                                -1.774070   \n",
       "2                                -1.763703   \n",
       "3                                -1.753336   \n",
       "4                                -1.742968   \n",
       "..                                     ...   \n",
       "187                               0.923349   \n",
       "188                               0.905256   \n",
       "189                               0.887162   \n",
       "190                               0.869069   \n",
       "191                               0.850975   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Preços de Mercado  \n",
       "0                                       -1.738619  \n",
       "1                                       -1.724323  \n",
       "2                                       -1.710027  \n",
       "3                                       -1.695732  \n",
       "4                                       -1.681436  \n",
       "..                                            ...  \n",
       "187                                      1.021439  \n",
       "188                                      1.007593  \n",
       "189                                      0.993747  \n",
       "190                                      0.979902  \n",
       "191                                      0.966056  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      36.256\n",
       "1      33.675\n",
       "2      43.734\n",
       "3      36.187\n",
       "4      33.413\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Mato Grosso Do Sul - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Mato Grosso do Sul - IDH</th>\n",
       "      <th>Mato Grosso Do Sul - Produção de Cimento (t)</th>\n",
       "      <th>Mato Grosso do Sul - Desemprego</th>\n",
       "      <th>Mato Grosso do Sul - value</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Estadual</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Construção Civil</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Per Capita</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.739598</td>\n",
       "      <td>-1.432541</td>\n",
       "      <td>1.216541</td>\n",
       "      <td>-0.459341</td>\n",
       "      <td>-1.637645</td>\n",
       "      <td>-2.402906</td>\n",
       "      <td>-1.784438</td>\n",
       "      <td>-1.738619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.720624</td>\n",
       "      <td>-1.423955</td>\n",
       "      <td>1.206220</td>\n",
       "      <td>-0.422027</td>\n",
       "      <td>-1.622679</td>\n",
       "      <td>-2.361122</td>\n",
       "      <td>-1.774070</td>\n",
       "      <td>-1.724323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.701651</td>\n",
       "      <td>-1.451188</td>\n",
       "      <td>1.195898</td>\n",
       "      <td>-0.401858</td>\n",
       "      <td>-1.607713</td>\n",
       "      <td>-2.319339</td>\n",
       "      <td>-1.763703</td>\n",
       "      <td>-1.710027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.682677</td>\n",
       "      <td>-1.448515</td>\n",
       "      <td>1.185577</td>\n",
       "      <td>-0.385815</td>\n",
       "      <td>-1.592747</td>\n",
       "      <td>-2.277555</td>\n",
       "      <td>-1.753336</td>\n",
       "      <td>-1.695732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.663704</td>\n",
       "      <td>-1.392079</td>\n",
       "      <td>1.175256</td>\n",
       "      <td>-0.385067</td>\n",
       "      <td>-1.577781</td>\n",
       "      <td>-2.235771</td>\n",
       "      <td>-1.742968</td>\n",
       "      <td>-1.681436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>1.523477</td>\n",
       "      <td>-0.303048</td>\n",
       "      <td>-0.435460</td>\n",
       "      <td>0.586449</td>\n",
       "      <td>1.207622</td>\n",
       "      <td>0.129567</td>\n",
       "      <td>1.062247</td>\n",
       "      <td>1.123802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>1.520281</td>\n",
       "      <td>-0.384401</td>\n",
       "      <td>-0.482211</td>\n",
       "      <td>0.549251</td>\n",
       "      <td>1.211468</td>\n",
       "      <td>0.098041</td>\n",
       "      <td>1.062771</td>\n",
       "      <td>1.125391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>1.517085</td>\n",
       "      <td>-0.431034</td>\n",
       "      <td>-0.528962</td>\n",
       "      <td>0.512196</td>\n",
       "      <td>1.215313</td>\n",
       "      <td>0.066515</td>\n",
       "      <td>1.063296</td>\n",
       "      <td>1.126980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>1.513890</td>\n",
       "      <td>-0.493901</td>\n",
       "      <td>-0.575713</td>\n",
       "      <td>0.470611</td>\n",
       "      <td>1.219159</td>\n",
       "      <td>0.034989</td>\n",
       "      <td>1.063820</td>\n",
       "      <td>1.128569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>1.510694</td>\n",
       "      <td>-0.530657</td>\n",
       "      <td>-0.622465</td>\n",
       "      <td>0.431872</td>\n",
       "      <td>1.223005</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>1.064344</td>\n",
       "      <td>1.130158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     Mato Grosso do Sul - IDH  Mato Grosso Do Sul - Produção de Cimento (t)  \\\n",
       "0                   -1.739598                                     -1.432541   \n",
       "1                   -1.720624                                     -1.423955   \n",
       "2                   -1.701651                                     -1.451188   \n",
       "3                   -1.682677                                     -1.448515   \n",
       "4                   -1.663704                                     -1.392079   \n",
       "..                        ...                                           ...   \n",
       "157                  1.523477                                     -0.303048   \n",
       "158                  1.520281                                     -0.384401   \n",
       "159                  1.517085                                     -0.431034   \n",
       "160                  1.513890                                     -0.493901   \n",
       "161                  1.510694                                     -0.530657   \n",
       "\n",
       "     Mato Grosso do Sul - Desemprego  Mato Grosso do Sul - value  \\\n",
       "0                           1.216541                   -0.459341   \n",
       "1                           1.206220                   -0.422027   \n",
       "2                           1.195898                   -0.401858   \n",
       "3                           1.185577                   -0.385815   \n",
       "4                           1.175256                   -0.385067   \n",
       "..                               ...                         ...   \n",
       "157                        -0.435460                    0.586449   \n",
       "158                        -0.482211                    0.549251   \n",
       "159                        -0.528962                    0.512196   \n",
       "160                        -0.575713                    0.470611   \n",
       "161                        -0.622465                    0.431872   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Estadual  \\\n",
       "0                              -1.637645   \n",
       "1                              -1.622679   \n",
       "2                              -1.607713   \n",
       "3                              -1.592747   \n",
       "4                              -1.577781   \n",
       "..                                   ...   \n",
       "157                             1.207622   \n",
       "158                             1.211468   \n",
       "159                             1.215313   \n",
       "160                             1.219159   \n",
       "161                             1.223005   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Construção Civil  \\\n",
       "0                                      -2.402906   \n",
       "1                                      -2.361122   \n",
       "2                                      -2.319339   \n",
       "3                                      -2.277555   \n",
       "4                                      -2.235771   \n",
       "..                                           ...   \n",
       "157                                     0.129567   \n",
       "158                                     0.098041   \n",
       "159                                     0.066515   \n",
       "160                                     0.034989   \n",
       "161                                     0.003463   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Per Capita  \\\n",
       "0                                -1.784438   \n",
       "1                                -1.774070   \n",
       "2                                -1.763703   \n",
       "3                                -1.753336   \n",
       "4                                -1.742968   \n",
       "..                                     ...   \n",
       "157                               1.062247   \n",
       "158                               1.062771   \n",
       "159                               1.063296   \n",
       "160                               1.063820   \n",
       "161                               1.064344   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Preços de Mercado  \n",
       "0                                       -1.738619  \n",
       "1                                       -1.724323  \n",
       "2                                       -1.710027  \n",
       "3                                       -1.695732  \n",
       "4                                       -1.681436  \n",
       "..                                            ...  \n",
       "157                                      1.123802  \n",
       "158                                      1.125391  \n",
       "159                                      1.126980  \n",
       "160                                      1.128569  \n",
       "161                                      1.130158  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      36.256\n",
       "1      33.675\n",
       "2      43.734\n",
       "3      36.187\n",
       "4      33.413\n",
       "        ...  \n",
       "157    66.462\n",
       "158    79.514\n",
       "159    63.281\n",
       "160    77.205\n",
       "161    71.168\n",
       "Name: Mato Grosso Do Sul - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Mato Grosso do Sul - IDH</th>\n",
       "      <th>Mato Grosso Do Sul - Produção de Cimento (t)</th>\n",
       "      <th>Mato Grosso do Sul - Desemprego</th>\n",
       "      <th>Mato Grosso do Sul - value</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Estadual</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Construção Civil</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Per Capita</th>\n",
       "      <th>Mato Grosso do Sul - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>1.507498</td>\n",
       "      <td>-0.558761</td>\n",
       "      <td>-0.669216</td>\n",
       "      <td>0.395858</td>\n",
       "      <td>1.226851</td>\n",
       "      <td>-0.028063</td>\n",
       "      <td>1.064869</td>\n",
       "      <td>1.131747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>1.504302</td>\n",
       "      <td>-0.590305</td>\n",
       "      <td>-0.715967</td>\n",
       "      <td>0.361218</td>\n",
       "      <td>1.230696</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>1.065393</td>\n",
       "      <td>1.133336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>1.501107</td>\n",
       "      <td>-0.641603</td>\n",
       "      <td>-0.762718</td>\n",
       "      <td>0.329709</td>\n",
       "      <td>1.234542</td>\n",
       "      <td>-0.091115</td>\n",
       "      <td>1.065917</td>\n",
       "      <td>1.134925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>1.497911</td>\n",
       "      <td>-0.706731</td>\n",
       "      <td>-0.809470</td>\n",
       "      <td>0.303630</td>\n",
       "      <td>1.238388</td>\n",
       "      <td>-0.122641</td>\n",
       "      <td>1.066442</td>\n",
       "      <td>1.136514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>1.494715</td>\n",
       "      <td>-0.754771</td>\n",
       "      <td>-0.856221</td>\n",
       "      <td>0.282160</td>\n",
       "      <td>1.242233</td>\n",
       "      <td>-0.154167</td>\n",
       "      <td>1.066966</td>\n",
       "      <td>1.138104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>1.491520</td>\n",
       "      <td>-0.803758</td>\n",
       "      <td>-0.902972</td>\n",
       "      <td>0.262035</td>\n",
       "      <td>1.246079</td>\n",
       "      <td>-0.185693</td>\n",
       "      <td>1.067490</td>\n",
       "      <td>1.139693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>1.488324</td>\n",
       "      <td>-0.858755</td>\n",
       "      <td>-0.949723</td>\n",
       "      <td>0.247167</td>\n",
       "      <td>1.249925</td>\n",
       "      <td>-0.217219</td>\n",
       "      <td>1.068015</td>\n",
       "      <td>1.141282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>1.478012</td>\n",
       "      <td>-0.900149</td>\n",
       "      <td>-0.964452</td>\n",
       "      <td>0.238710</td>\n",
       "      <td>1.249396</td>\n",
       "      <td>-0.223413</td>\n",
       "      <td>1.066514</td>\n",
       "      <td>1.139372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>1.467701</td>\n",
       "      <td>-0.923483</td>\n",
       "      <td>-0.979180</td>\n",
       "      <td>0.230368</td>\n",
       "      <td>1.248867</td>\n",
       "      <td>-0.229608</td>\n",
       "      <td>1.065013</td>\n",
       "      <td>1.137461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>1.457389</td>\n",
       "      <td>-0.970684</td>\n",
       "      <td>-0.993908</td>\n",
       "      <td>0.219296</td>\n",
       "      <td>1.248338</td>\n",
       "      <td>-0.235802</td>\n",
       "      <td>1.063512</td>\n",
       "      <td>1.135551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>1.447078</td>\n",
       "      <td>-0.960896</td>\n",
       "      <td>-1.008637</td>\n",
       "      <td>0.211078</td>\n",
       "      <td>1.247810</td>\n",
       "      <td>-0.241996</td>\n",
       "      <td>1.062011</td>\n",
       "      <td>1.133641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>1.436766</td>\n",
       "      <td>-0.986845</td>\n",
       "      <td>-1.023365</td>\n",
       "      <td>0.200833</td>\n",
       "      <td>1.247281</td>\n",
       "      <td>-0.248190</td>\n",
       "      <td>1.060510</td>\n",
       "      <td>1.131730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>1.426455</td>\n",
       "      <td>-0.997784</td>\n",
       "      <td>-1.038093</td>\n",
       "      <td>0.192341</td>\n",
       "      <td>1.246752</td>\n",
       "      <td>-0.254384</td>\n",
       "      <td>1.059009</td>\n",
       "      <td>1.129820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>1.416143</td>\n",
       "      <td>-1.006891</td>\n",
       "      <td>-1.052822</td>\n",
       "      <td>0.192080</td>\n",
       "      <td>1.246223</td>\n",
       "      <td>-0.260578</td>\n",
       "      <td>1.057508</td>\n",
       "      <td>1.127910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>1.405832</td>\n",
       "      <td>-1.026796</td>\n",
       "      <td>-1.067550</td>\n",
       "      <td>0.194833</td>\n",
       "      <td>1.245695</td>\n",
       "      <td>-0.266772</td>\n",
       "      <td>1.056007</td>\n",
       "      <td>1.125999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>1.395520</td>\n",
       "      <td>-1.043886</td>\n",
       "      <td>-1.082278</td>\n",
       "      <td>0.197762</td>\n",
       "      <td>1.245166</td>\n",
       "      <td>-0.272966</td>\n",
       "      <td>1.054506</td>\n",
       "      <td>1.124089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>1.385208</td>\n",
       "      <td>-1.021998</td>\n",
       "      <td>-1.097007</td>\n",
       "      <td>0.202778</td>\n",
       "      <td>1.244637</td>\n",
       "      <td>-0.279160</td>\n",
       "      <td>1.053005</td>\n",
       "      <td>1.122179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>1.374897</td>\n",
       "      <td>-1.020739</td>\n",
       "      <td>-1.111735</td>\n",
       "      <td>0.208836</td>\n",
       "      <td>1.244108</td>\n",
       "      <td>-0.285354</td>\n",
       "      <td>1.051504</td>\n",
       "      <td>1.120268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>1.364585</td>\n",
       "      <td>-1.025848</td>\n",
       "      <td>-1.126463</td>\n",
       "      <td>0.215368</td>\n",
       "      <td>1.243579</td>\n",
       "      <td>-0.291549</td>\n",
       "      <td>1.050003</td>\n",
       "      <td>1.118358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>1.339686</td>\n",
       "      <td>-0.967996</td>\n",
       "      <td>-1.137708</td>\n",
       "      <td>0.222552</td>\n",
       "      <td>1.233277</td>\n",
       "      <td>-0.291710</td>\n",
       "      <td>1.031910</td>\n",
       "      <td>1.104513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>1.314786</td>\n",
       "      <td>-0.960024</td>\n",
       "      <td>-1.148954</td>\n",
       "      <td>0.228966</td>\n",
       "      <td>1.222975</td>\n",
       "      <td>-0.291872</td>\n",
       "      <td>1.013816</td>\n",
       "      <td>1.090667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>1.289887</td>\n",
       "      <td>-0.939108</td>\n",
       "      <td>-1.160199</td>\n",
       "      <td>0.231656</td>\n",
       "      <td>1.212673</td>\n",
       "      <td>-0.292034</td>\n",
       "      <td>0.995723</td>\n",
       "      <td>1.076821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>1.264987</td>\n",
       "      <td>-0.937871</td>\n",
       "      <td>-1.171444</td>\n",
       "      <td>0.238849</td>\n",
       "      <td>1.202371</td>\n",
       "      <td>-0.292195</td>\n",
       "      <td>0.977629</td>\n",
       "      <td>1.062976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>1.240087</td>\n",
       "      <td>-0.888583</td>\n",
       "      <td>-1.182689</td>\n",
       "      <td>0.247036</td>\n",
       "      <td>1.192069</td>\n",
       "      <td>-0.292357</td>\n",
       "      <td>0.959536</td>\n",
       "      <td>1.049130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>1.215188</td>\n",
       "      <td>-0.851167</td>\n",
       "      <td>-1.193935</td>\n",
       "      <td>0.265408</td>\n",
       "      <td>1.181767</td>\n",
       "      <td>-0.292519</td>\n",
       "      <td>0.941443</td>\n",
       "      <td>1.035284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.190288</td>\n",
       "      <td>-0.831849</td>\n",
       "      <td>-1.205180</td>\n",
       "      <td>0.316446</td>\n",
       "      <td>1.171465</td>\n",
       "      <td>-0.292680</td>\n",
       "      <td>0.923349</td>\n",
       "      <td>1.021439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.165389</td>\n",
       "      <td>-0.799920</td>\n",
       "      <td>-1.216425</td>\n",
       "      <td>0.383902</td>\n",
       "      <td>1.161163</td>\n",
       "      <td>-0.292842</td>\n",
       "      <td>0.905256</td>\n",
       "      <td>1.007593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.140489</td>\n",
       "      <td>-0.711338</td>\n",
       "      <td>-1.227670</td>\n",
       "      <td>0.452548</td>\n",
       "      <td>1.150861</td>\n",
       "      <td>-0.293004</td>\n",
       "      <td>0.887162</td>\n",
       "      <td>0.993747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.115590</td>\n",
       "      <td>-0.636591</td>\n",
       "      <td>-1.238915</td>\n",
       "      <td>0.528940</td>\n",
       "      <td>1.140559</td>\n",
       "      <td>-0.293166</td>\n",
       "      <td>0.869069</td>\n",
       "      <td>0.979902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.090690</td>\n",
       "      <td>-0.611490</td>\n",
       "      <td>-1.250161</td>\n",
       "      <td>0.606406</td>\n",
       "      <td>1.130257</td>\n",
       "      <td>-0.293327</td>\n",
       "      <td>0.850975</td>\n",
       "      <td>0.966056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162                                         -0.601510   \n",
       "163                                         -0.786068   \n",
       "164                                         -0.830387   \n",
       "165                                         -0.801089   \n",
       "166                                         -0.959917   \n",
       "167                                         -1.022309   \n",
       "168                                         -1.074401   \n",
       "169                                         -1.119597   \n",
       "170                                         -1.078648   \n",
       "171                                         -1.055426   \n",
       "172                                         -1.101053   \n",
       "173                                         -1.211370   \n",
       "174                                         -1.157198   \n",
       "175                                         -1.223444   \n",
       "176                                         -1.311519   \n",
       "177                                         -1.362602   \n",
       "178                                         -1.380125   \n",
       "179                                         -1.219296   \n",
       "180                                         -1.300284   \n",
       "181                                         -1.336476   \n",
       "182                                         -1.415774   \n",
       "183                                         -1.526021   \n",
       "184                                         -1.681806   \n",
       "185                                         -1.735167   \n",
       "186                                         -1.962315   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "162                                0.763466  -1.213929   \n",
       "163                                0.752299  -1.292173   \n",
       "164                                0.741131  -1.324219   \n",
       "165                                0.729964  -1.344446   \n",
       "166                                0.718796  -1.381638   \n",
       "167                                0.707629  -1.411208   \n",
       "168                                0.696461  -1.412953   \n",
       "169                                0.681823  -1.491464   \n",
       "170                                0.667184  -1.573805   \n",
       "171                                0.652545  -1.564950   \n",
       "172                                0.637906  -1.581584   \n",
       "173                                0.623268  -1.565976   \n",
       "174                                0.608629  -1.648556   \n",
       "175                                0.593990  -1.650049   \n",
       "176                                0.579351  -1.653957   \n",
       "177                                0.564713  -1.652572   \n",
       "178                                0.550074  -1.715349   \n",
       "179                                0.535435  -1.750917   \n",
       "180                                0.520796  -1.718448   \n",
       "181                                0.501996  -1.733426   \n",
       "182                                0.483195  -1.729362   \n",
       "183                                0.464395  -1.748544   \n",
       "184                                0.445594  -1.778060   \n",
       "185                                0.426794  -1.773710   \n",
       "186                                0.407993  -1.757007   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Mato Grosso do Sul - IDH  Mato Grosso Do Sul - Produção de Cimento (t)  \\\n",
       "162                  1.507498                                     -0.558761   \n",
       "163                  1.504302                                     -0.590305   \n",
       "164                  1.501107                                     -0.641603   \n",
       "165                  1.497911                                     -0.706731   \n",
       "166                  1.494715                                     -0.754771   \n",
       "167                  1.491520                                     -0.803758   \n",
       "168                  1.488324                                     -0.858755   \n",
       "169                  1.478012                                     -0.900149   \n",
       "170                  1.467701                                     -0.923483   \n",
       "171                  1.457389                                     -0.970684   \n",
       "172                  1.447078                                     -0.960896   \n",
       "173                  1.436766                                     -0.986845   \n",
       "174                  1.426455                                     -0.997784   \n",
       "175                  1.416143                                     -1.006891   \n",
       "176                  1.405832                                     -1.026796   \n",
       "177                  1.395520                                     -1.043886   \n",
       "178                  1.385208                                     -1.021998   \n",
       "179                  1.374897                                     -1.020739   \n",
       "180                  1.364585                                     -1.025848   \n",
       "181                  1.339686                                     -0.967996   \n",
       "182                  1.314786                                     -0.960024   \n",
       "183                  1.289887                                     -0.939108   \n",
       "184                  1.264987                                     -0.937871   \n",
       "185                  1.240087                                     -0.888583   \n",
       "186                  1.215188                                     -0.851167   \n",
       "187                  1.190288                                     -0.831849   \n",
       "188                  1.165389                                     -0.799920   \n",
       "189                  1.140489                                     -0.711338   \n",
       "190                  1.115590                                     -0.636591   \n",
       "191                  1.090690                                     -0.611490   \n",
       "\n",
       "     Mato Grosso do Sul - Desemprego  Mato Grosso do Sul - value  \\\n",
       "162                        -0.669216                    0.395858   \n",
       "163                        -0.715967                    0.361218   \n",
       "164                        -0.762718                    0.329709   \n",
       "165                        -0.809470                    0.303630   \n",
       "166                        -0.856221                    0.282160   \n",
       "167                        -0.902972                    0.262035   \n",
       "168                        -0.949723                    0.247167   \n",
       "169                        -0.964452                    0.238710   \n",
       "170                        -0.979180                    0.230368   \n",
       "171                        -0.993908                    0.219296   \n",
       "172                        -1.008637                    0.211078   \n",
       "173                        -1.023365                    0.200833   \n",
       "174                        -1.038093                    0.192341   \n",
       "175                        -1.052822                    0.192080   \n",
       "176                        -1.067550                    0.194833   \n",
       "177                        -1.082278                    0.197762   \n",
       "178                        -1.097007                    0.202778   \n",
       "179                        -1.111735                    0.208836   \n",
       "180                        -1.126463                    0.215368   \n",
       "181                        -1.137708                    0.222552   \n",
       "182                        -1.148954                    0.228966   \n",
       "183                        -1.160199                    0.231656   \n",
       "184                        -1.171444                    0.238849   \n",
       "185                        -1.182689                    0.247036   \n",
       "186                        -1.193935                    0.265408   \n",
       "187                        -1.205180                    0.316446   \n",
       "188                        -1.216425                    0.383902   \n",
       "189                        -1.227670                    0.452548   \n",
       "190                        -1.238915                    0.528940   \n",
       "191                        -1.250161                    0.606406   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Estadual  \\\n",
       "162                             1.226851   \n",
       "163                             1.230696   \n",
       "164                             1.234542   \n",
       "165                             1.238388   \n",
       "166                             1.242233   \n",
       "167                             1.246079   \n",
       "168                             1.249925   \n",
       "169                             1.249396   \n",
       "170                             1.248867   \n",
       "171                             1.248338   \n",
       "172                             1.247810   \n",
       "173                             1.247281   \n",
       "174                             1.246752   \n",
       "175                             1.246223   \n",
       "176                             1.245695   \n",
       "177                             1.245166   \n",
       "178                             1.244637   \n",
       "179                             1.244108   \n",
       "180                             1.243579   \n",
       "181                             1.233277   \n",
       "182                             1.222975   \n",
       "183                             1.212673   \n",
       "184                             1.202371   \n",
       "185                             1.192069   \n",
       "186                             1.181767   \n",
       "187                             1.171465   \n",
       "188                             1.161163   \n",
       "189                             1.150861   \n",
       "190                             1.140559   \n",
       "191                             1.130257   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Construção Civil  \\\n",
       "162                                    -0.028063   \n",
       "163                                    -0.059589   \n",
       "164                                    -0.091115   \n",
       "165                                    -0.122641   \n",
       "166                                    -0.154167   \n",
       "167                                    -0.185693   \n",
       "168                                    -0.217219   \n",
       "169                                    -0.223413   \n",
       "170                                    -0.229608   \n",
       "171                                    -0.235802   \n",
       "172                                    -0.241996   \n",
       "173                                    -0.248190   \n",
       "174                                    -0.254384   \n",
       "175                                    -0.260578   \n",
       "176                                    -0.266772   \n",
       "177                                    -0.272966   \n",
       "178                                    -0.279160   \n",
       "179                                    -0.285354   \n",
       "180                                    -0.291549   \n",
       "181                                    -0.291710   \n",
       "182                                    -0.291872   \n",
       "183                                    -0.292034   \n",
       "184                                    -0.292195   \n",
       "185                                    -0.292357   \n",
       "186                                    -0.292519   \n",
       "187                                    -0.292680   \n",
       "188                                    -0.292842   \n",
       "189                                    -0.293004   \n",
       "190                                    -0.293166   \n",
       "191                                    -0.293327   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Per Capita  \\\n",
       "162                               1.064869   \n",
       "163                               1.065393   \n",
       "164                               1.065917   \n",
       "165                               1.066442   \n",
       "166                               1.066966   \n",
       "167                               1.067490   \n",
       "168                               1.068015   \n",
       "169                               1.066514   \n",
       "170                               1.065013   \n",
       "171                               1.063512   \n",
       "172                               1.062011   \n",
       "173                               1.060510   \n",
       "174                               1.059009   \n",
       "175                               1.057508   \n",
       "176                               1.056007   \n",
       "177                               1.054506   \n",
       "178                               1.053005   \n",
       "179                               1.051504   \n",
       "180                               1.050003   \n",
       "181                               1.031910   \n",
       "182                               1.013816   \n",
       "183                               0.995723   \n",
       "184                               0.977629   \n",
       "185                               0.959536   \n",
       "186                               0.941443   \n",
       "187                               0.923349   \n",
       "188                               0.905256   \n",
       "189                               0.887162   \n",
       "190                               0.869069   \n",
       "191                               0.850975   \n",
       "\n",
       "     Mato Grosso do Sul - PIB - Preços de Mercado  \n",
       "162                                      1.131747  \n",
       "163                                      1.133336  \n",
       "164                                      1.134925  \n",
       "165                                      1.136514  \n",
       "166                                      1.138104  \n",
       "167                                      1.139693  \n",
       "168                                      1.141282  \n",
       "169                                      1.139372  \n",
       "170                                      1.137461  \n",
       "171                                      1.135551  \n",
       "172                                      1.133641  \n",
       "173                                      1.131730  \n",
       "174                                      1.129820  \n",
       "175                                      1.127910  \n",
       "176                                      1.125999  \n",
       "177                                      1.124089  \n",
       "178                                      1.122179  \n",
       "179                                      1.120268  \n",
       "180                                      1.118358  \n",
       "181                                      1.104513  \n",
       "182                                      1.090667  \n",
       "183                                      1.076821  \n",
       "184                                      1.062976  \n",
       "185                                      1.049130  \n",
       "186                                      1.035284  \n",
       "187                                      1.021439  \n",
       "188                                      1.007593  \n",
       "189                                      0.993747  \n",
       "190                                      0.979902  \n",
       "191                                      0.966056  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    80.517\n",
       "163    81.348\n",
       "164    76.509\n",
       "165    71.851\n",
       "166    71.187\n",
       "167    58.020\n",
       "168    63.194\n",
       "169    60.580\n",
       "170    69.448\n",
       "171    74.472\n",
       "172    63.776\n",
       "173    81.732\n",
       "174    83.858\n",
       "175    87.863\n",
       "176    69.723\n",
       "177    72.765\n",
       "178    77.937\n",
       "179    64.332\n",
       "180    77.048\n",
       "181    65.660\n",
       "182    65.445\n",
       "183    78.095\n",
       "184    80.998\n",
       "185    69.415\n",
       "186    87.346\n",
       "187    82.888\n",
       "188    79.287\n",
       "189    81.855\n",
       "190    77.495\n",
       "191    56.612\n",
       "Name: Mato Grosso Do Sul - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor//2):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "        pos = df.shape[0] - (i*div_factor + 3)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    train, train_val = validation_splitter(train_input, 6)\n",
    "    target,target_val = validation_splitter(train_target, 6)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val, target_val),\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1246087175, 2184783715, 2582528527, 1053111234, 348725400, 1291293116, 801014609, 3005362731, 3647643016, 2841889144, 2144919270, 4154215439, 2891408204, 3105058538, 1877066431, 238022320, 2521715964, 2330700615, 2597399158, 1262788948, 1097606053, 3636711877, 3003188941, 377532714, 3505716841]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 62.81085205078125\n",
      "winner_seed: 1246087175\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 37.40751266479492\n",
      "winner_seed: 2184783715\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 28.450897216796875\n",
      "winner_seed: 2582528527\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 44.097755432128906\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 40.52454376220703\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 46.374942779541016\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 38.58902359008789\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 106.10022735595703\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 97.59952545166016\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 59.963443756103516\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 38.47271728515625\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 63.35239791870117\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 32.357337951660156\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 75.89253234863281\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 38.04692459106445\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 84.87531280517578\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 29.030912399291992\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 530.0030517578125\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 59.877685546875\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 33.81769561767578\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 36.51062774658203\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 37.878108978271484\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 37.92164993286133\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 17:08:34.302685: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 109.46446990966797\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 36.738101959228516\n",
      "\n",
      "\n",
      "final_seed: 2582528527\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 1s 27ms/step - loss: 5324.3745 - val_loss: 25440.9980\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6052.7866 - val_loss: 15549.3447\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4801.5972 - val_loss: 7877.1777\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4121.6235 - val_loss: 6036.8262\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3688.6619 - val_loss: 2726.4482\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2124.7351 - val_loss: 5712.1484\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1824.8846 - val_loss: 2203.9241\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 631.4060 - val_loss: 835.1866\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 284.5677 - val_loss: 533.0089\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 234.5342 - val_loss: 574.6963\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 231.3189 - val_loss: 547.0743\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 235.1188 - val_loss: 592.8422\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 238.7178 - val_loss: 547.6627\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 197.9015 - val_loss: 490.2813\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 644.8878 - val_loss: 1147.3044\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 358.1490 - val_loss: 783.0457\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 587.4764 - val_loss: 520.7701\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 250.4388 - val_loss: 410.2979\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 141.1485 - val_loss: 389.5839\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 185.9380 - val_loss: 424.2437\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 187.7577 - val_loss: 357.8520\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 157.8565 - val_loss: 238.0496\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 238.5412 - val_loss: 433.2440\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 162.1702 - val_loss: 375.1466\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 200.6456 - val_loss: 363.1490\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 112.9180 - val_loss: 268.1015\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.9839 - val_loss: 310.9871\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 131.4302 - val_loss: 272.5764\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 143.9705 - val_loss: 438.5144\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 167.0930 - val_loss: 464.1927\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 113.2945 - val_loss: 448.1931\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 118.5508 - val_loss: 307.0232\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 106.8298 - val_loss: 221.2766\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.9431 - val_loss: 194.7668\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 142.6873 - val_loss: 285.0875\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 79.5189 - val_loss: 442.6993\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 159.4113 - val_loss: 239.1448\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.4457 - val_loss: 442.1652\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.3682 - val_loss: 156.0692\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.6128 - val_loss: 201.2990\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 169.3667 - val_loss: 251.6514\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 120.0622 - val_loss: 271.8364\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 159.5432 - val_loss: 486.6515\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 149.2606 - val_loss: 538.1561\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 174.5838 - val_loss: 444.0005\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 124.4007 - val_loss: 287.3390\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.9979 - val_loss: 202.6142\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 78.1355 - val_loss: 158.9666\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.3504 - val_loss: 205.1951\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 75.2889 - val_loss: 178.7785\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 118.2127 - val_loss: 158.8461\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.4069 - val_loss: 614.1703\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 171.9178 - val_loss: 621.5045\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 147.1246 - val_loss: 328.7969\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 119.3996 - val_loss: 332.2550\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 105.5477 - val_loss: 290.0254\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 139.3331 - val_loss: 180.7589\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 116.8619 - val_loss: 455.5547\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 147.1113 - val_loss: 358.8703\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 121.5664 - val_loss: 244.5569\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 134.2677 - val_loss: 257.8265\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 95.5704 - val_loss: 326.0884\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 112.6781 - val_loss: 169.9500\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 64.1612 - val_loss: 151.5158\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.4994 - val_loss: 132.3114\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.4788 - val_loss: 148.8562\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 177.9807 - val_loss: 204.1970\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.3411 - val_loss: 216.7309\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 72.4983 - val_loss: 140.8069\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.2969 - val_loss: 321.7688\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 192.5818 - val_loss: 550.8588\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 137.3600 - val_loss: 261.3475\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.9583 - val_loss: 292.4536\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.3694 - val_loss: 272.1254\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.9996 - val_loss: 157.6095\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.1428 - val_loss: 237.4842\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.6435 - val_loss: 154.8815\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.3246 - val_loss: 180.7773\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.9218 - val_loss: 325.6465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 117.0551 - val_loss: 312.2980\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 118.0498 - val_loss: 146.6781\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 77.2554 - val_loss: 117.8890\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.2545 - val_loss: 214.2281\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.4067 - val_loss: 121.1719\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 82.8026 - val_loss: 225.6489\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.8658 - val_loss: 368.0295\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.2502 - val_loss: 264.4512\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.7175 - val_loss: 761.4329\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 174.1193 - val_loss: 310.4967\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.9399 - val_loss: 207.9365\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.1910 - val_loss: 237.0287\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.0844 - val_loss: 264.0725\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.1364 - val_loss: 214.4379\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.7736 - val_loss: 267.9409\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.2329 - val_loss: 425.3039\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.6601 - val_loss: 267.2599\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.3589 - val_loss: 172.4644\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.0458 - val_loss: 174.4710\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.0235 - val_loss: 635.1861\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 198.2787 - val_loss: 517.5081\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 147.9179 - val_loss: 480.7852\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 122.5673 - val_loss: 347.7375\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 129.3263 - val_loss: 335.8027\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 124.2130 - val_loss: 353.9579\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.3892 - val_loss: 332.7198\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 118.9295 - val_loss: 335.4922\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 197.5985 - val_loss: 444.2787\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 159.5546 - val_loss: 377.8472\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 125.7029 - val_loss: 455.9219\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 152.4777 - val_loss: 460.5210\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 117.2307 - val_loss: 296.5148\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.0554 - val_loss: 302.0967\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.1378 - val_loss: 352.9926\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.3586 - val_loss: 322.5269\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.1805 - val_loss: 316.1015\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.4603 - val_loss: 328.0122\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.5480 - val_loss: 251.7846\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.2944 - val_loss: 265.0474\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.1992 - val_loss: 254.0685\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.5493 - val_loss: 240.2995\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 82.0295 - val_loss: 220.4214\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 81.7168 - val_loss: 235.7029\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.2567 - val_loss: 300.2671\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 76.8419 - val_loss: 234.9129\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 111.1586 - val_loss: 242.9960\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 79.0361 - val_loss: 520.3026\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 163.2035 - val_loss: 440.3683\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 123.0891 - val_loss: 336.8612\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.5582 - val_loss: 211.1140\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.1134 - val_loss: 172.9993\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.6436 - val_loss: 139.0221\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.1921 - val_loss: 102.4940\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.4748 - val_loss: 127.1442\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.9284 - val_loss: 568.2697\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 234.7702 - val_loss: 555.7167\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 180.2201 - val_loss: 357.9651\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 182.0908 - val_loss: 290.4126\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 131.9868 - val_loss: 315.6236\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.3775 - val_loss: 264.0959\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 126.0250 - val_loss: 252.2168\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 127.1579 - val_loss: 123.3830\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 72.5771 - val_loss: 72.1091\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.4505 - val_loss: 101.3944\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.9919 - val_loss: 112.7000\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.0154 - val_loss: 129.8359\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.5697 - val_loss: 169.6593\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.4222 - val_loss: 550.5541\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 202.1315 - val_loss: 115.9764\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 62.8023 - val_loss: 128.9422\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.2985 - val_loss: 113.8505\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.4552 - val_loss: 98.8153\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.5428 - val_loss: 348.6861\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 115.2229 - val_loss: 245.9929\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.7677 - val_loss: 332.9291\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.5704 - val_loss: 232.5763\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.5923 - val_loss: 292.4253\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.4768 - val_loss: 562.5300\n",
      "Epoch 158/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 126.9817 - val_loss: 238.5633\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.0964 - val_loss: 210.0903\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 82.7859 - val_loss: 317.7822\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 118.7606 - val_loss: 211.0091\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.2638 - val_loss: 569.3248\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 150.9623 - val_loss: 433.3993\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.1594 - val_loss: 331.1935\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.3850 - val_loss: 175.0906\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.4923 - val_loss: 180.8896\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.7607 - val_loss: 152.7361\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.2664 - val_loss: 186.4876\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.4512 - val_loss: 202.0844\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.1916 - val_loss: 192.2104\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 70.7696 - val_loss: 175.7820\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 82.0753 - val_loss: 146.9326\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.3648 - val_loss: 93.8053\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 61.1132 - val_loss: 158.9042\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.7481 - val_loss: 163.6024\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 79.9001 - val_loss: 174.1926\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.8123 - val_loss: 134.5225\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.6763 - val_loss: 99.1146\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 126.5175 - val_loss: 179.9709\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.5550 - val_loss: 294.4697\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.6089 - val_loss: 130.9812\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 76.2383 - val_loss: 369.0873\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 127.1801 - val_loss: 390.9663\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 67.7140 - val_loss: 228.8100\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.3204 - val_loss: 332.3234\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 116.6050 - val_loss: 168.4829\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.7293 - val_loss: 123.6950\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 66.2858 - val_loss: 100.0478\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.2411 - val_loss: 452.8032\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.2858 - val_loss: 201.7885\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1022.6093 - val_loss: 390.0791\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 285.4753 - val_loss: 185.7206\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 78.7399 - val_loss: 345.4625\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 126.1907 - val_loss: 170.4300\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.4357 - val_loss: 173.9976\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.7129 - val_loss: 119.7750\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.8423 - val_loss: 129.9384\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.7023 - val_loss: 689.0654\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 200.0014 - val_loss: 271.8896\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.6775 - val_loss: 222.8002\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 81.3782 - val_loss: 147.9567\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 77.3643 - val_loss: 118.6075\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.6180 - val_loss: 106.4199\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.3406 - val_loss: 117.6533\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.2023 - val_loss: 95.2691\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 62.9621 - val_loss: 171.3846\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 144.1269 - val_loss: 326.9020\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 155.5909 - val_loss: 94.0051\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 78.7566 - val_loss: 111.4321\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.9446 - val_loss: 163.8113\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9691 - val_loss: 140.9807\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.4082 - val_loss: 125.0719\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.6747 - val_loss: 188.0511\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.8942 - val_loss: 127.2723\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.5296 - val_loss: 124.5943\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 167.6044 - val_loss: 174.0856\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.7765 - val_loss: 105.4193\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.3299 - val_loss: 78.3390\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.0930 - val_loss: 136.1945\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.5525 - val_loss: 140.6581\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.8905 - val_loss: 146.3264\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.1925 - val_loss: 138.3916\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 66.7257 - val_loss: 108.1648\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.1838 - val_loss: 96.5175\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.4023 - val_loss: 266.1266\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.3069 - val_loss: 514.1359\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 131.6487 - val_loss: 298.8119\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.6109 - val_loss: 302.0037\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.7053 - val_loss: 174.0137\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.1226 - val_loss: 324.2586\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.3032 - val_loss: 622.4739\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 202.5176 - val_loss: 492.6871\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 154.2405 - val_loss: 516.4712\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 211.4591 - val_loss: 434.6718\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 167.7870 - val_loss: 449.3134\n",
      "Epoch 236/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 156.1551 - val_loss: 435.8315\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 164.7958 - val_loss: 346.2262\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 139.8496 - val_loss: 245.0413\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.7612 - val_loss: 245.1460\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 158.0589 - val_loss: 312.0605\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 136.8740 - val_loss: 222.7310\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.8202 - val_loss: 269.0571\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 126.4396 - val_loss: 239.1881\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8684 - val_loss: 218.1833\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.9468 - val_loss: 225.2444\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.2867 - val_loss: 145.2358\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 77.2542 - val_loss: 142.3717\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.9704 - val_loss: 126.9738\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.0027 - val_loss: 132.8215\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.8132 - val_loss: 196.5799\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.8172 - val_loss: 259.3545\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.4433 - val_loss: 228.0572\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 82.8855 - val_loss: 109.2183\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 61.6474 - val_loss: 235.1402\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.7260 - val_loss: 139.3531\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.2883 - val_loss: 200.3893\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 138.6827 - val_loss: 246.3292\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 136.5504 - val_loss: 300.7729\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 177.4198 - val_loss: 441.9791\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 144.6629 - val_loss: 132.1122\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.4367 - val_loss: 109.9981\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 78.4253 - val_loss: 245.3416\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.6875 - val_loss: 140.0453\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 78.5621 - val_loss: 89.2046\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.0382 - val_loss: 114.5947\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.0165 - val_loss: 176.5311\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.1432 - val_loss: 179.4209\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.9195 - val_loss: 167.3769\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.3437 - val_loss: 126.3134\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.2472 - val_loss: 128.4638\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.1182 - val_loss: 114.0338\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 55.0206 - val_loss: 108.2385\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.3371 - val_loss: 394.9878\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.0152 - val_loss: 142.1156\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.8276 - val_loss: 255.9675\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.3979 - val_loss: 154.6213\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.4435 - val_loss: 278.6548\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.9356 - val_loss: 231.7733\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 123.9303 - val_loss: 196.4992\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.1650 - val_loss: 178.9498\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.2420 - val_loss: 364.3504\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 141.6871 - val_loss: 225.5791\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.4956 - val_loss: 210.2829\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.1172 - val_loss: 155.7319\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.2871 - val_loss: 168.8051\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.7444 - val_loss: 182.5360\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 73.1120 - val_loss: 226.1830\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.5483 - val_loss: 129.3130\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.3054 - val_loss: 182.9025\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.2244 - val_loss: 207.7915\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 375.3179 - val_loss: 256.7145\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.6811 - val_loss: 238.4480\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.6791 - val_loss: 135.0579\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 71.5459 - val_loss: 202.5611\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 77.5322 - val_loss: 225.0332\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 74.5867 - val_loss: 144.3690\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.3205 - val_loss: 210.0510\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.6624 - val_loss: 152.2118\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.3561 - val_loss: 117.1052\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.4673 - val_loss: 125.1989\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.3622 - val_loss: 136.5627\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 61.1135 - val_loss: 115.5504\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.2605 - val_loss: 127.5560\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.8901 - val_loss: 152.9824\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.1456 - val_loss: 126.0760\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.5811 - val_loss: 107.0173\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.9488 - val_loss: 101.6173\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.6075 - val_loss: 111.8457\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 139.0042 - val_loss: 192.4457\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 145.0619 - val_loss: 100.1310\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 77.5222 - val_loss: 89.8571\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.5885 - val_loss: 100.8656\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 75.3802 - val_loss: 107.9426\n",
      "Epoch 314/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 58.8698 - val_loss: 95.7948\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.3092 - val_loss: 89.1871\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.2096 - val_loss: 84.0837\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.5156 - val_loss: 91.9113\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 58.2803 - val_loss: 101.2591\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.8672 - val_loss: 95.4821\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 59.0806 - val_loss: 112.8269\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.5869 - val_loss: 183.1279\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.8342 - val_loss: 121.2351\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.8288 - val_loss: 162.0204\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.8983 - val_loss: 94.4673\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.4994 - val_loss: 111.1624\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.0725 - val_loss: 101.1545\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.5935 - val_loss: 102.9097\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 77.6156 - val_loss: 115.2889\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.3044 - val_loss: 141.4120\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 80.4801 - val_loss: 91.5985\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.5434 - val_loss: 290.2256\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.0920 - val_loss: 244.2424\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.7793 - val_loss: 183.9402\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.0485 - val_loss: 202.2708\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.9116 - val_loss: 175.0443\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.4244 - val_loss: 183.1793\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.6810 - val_loss: 161.2933\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.8573 - val_loss: 204.2823\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.0089 - val_loss: 161.9235\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 77.0705 - val_loss: 218.5234\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 81.8700 - val_loss: 219.8817\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.1421 - val_loss: 378.3658\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 152.1305 - val_loss: 427.7450\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.2255 - val_loss: 160.8086\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.8052 - val_loss: 149.7341\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.6863 - val_loss: 342.6988\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.9268 - val_loss: 199.8543\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.7746 - val_loss: 219.6878\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.1537 - val_loss: 190.1842\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.7875 - val_loss: 143.2267\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.7869 - val_loss: 286.8745\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 148.1417 - val_loss: 356.3778\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.2455 - val_loss: 209.5434\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.2817 - val_loss: 195.1940\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.9376 - val_loss: 260.9365\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.7331 - val_loss: 256.0468\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.3787 - val_loss: 144.0466\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 67.5876 - val_loss: 205.9624\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.6613 - val_loss: 404.1353\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 202.4927 - val_loss: 190.3893\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.6670 - val_loss: 138.2372\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.5276 - val_loss: 119.6364\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.0243 - val_loss: 120.4866\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.9745 - val_loss: 102.0640\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.4533 - val_loss: 138.6857\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.7609 - val_loss: 113.4232\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.3007 - val_loss: 107.6040\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.9226 - val_loss: 120.0285\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.6870 - val_loss: 160.9188\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.5063 - val_loss: 244.1451\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.4573 - val_loss: 192.4083\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.3814 - val_loss: 198.0006\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.0222 - val_loss: 130.9941\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.1086 - val_loss: 136.7472\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.9520 - val_loss: 109.2825\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.9682 - val_loss: 143.1038\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.6176 - val_loss: 243.5453\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.3787 - val_loss: 176.8066\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.1760 - val_loss: 149.1118\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.8867 - val_loss: 144.6606\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 69.5385 - val_loss: 126.5054\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.8267 - val_loss: 123.2981\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.0546 - val_loss: 118.2137\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.5795 - val_loss: 256.6914\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 79.6860 - val_loss: 226.4321\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.0833 - val_loss: 211.4722\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.9931 - val_loss: 203.9919\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.9246 - val_loss: 188.8661\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.6696 - val_loss: 174.3503\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.5461 - val_loss: 176.5785\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.9168 - val_loss: 278.2925\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.6605 - val_loss: 283.6074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 73.7551 - val_loss: 248.9145\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.2040 - val_loss: 226.9976\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.2699 - val_loss: 252.1200\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.3978 - val_loss: 259.9690\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.9635 - val_loss: 279.1223\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.6839 - val_loss: 282.3535\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.0981 - val_loss: 311.7250\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.4930 - val_loss: 291.3871\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 122.4607 - val_loss: 335.9922\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 131.1671 - val_loss: 258.9367\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 122.4055 - val_loss: 279.1158\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 152.4526 - val_loss: 883.9583\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 228.2939 - val_loss: 569.5330\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 191.1596 - val_loss: 632.4108\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 224.9238 - val_loss: 569.0777\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 169.5197 - val_loss: 511.3514\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 171.8409 - val_loss: 509.3111\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 172.7975 - val_loss: 552.9149\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 173.9918 - val_loss: 555.4391\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 171.3932 - val_loss: 509.9957\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 178.7801 - val_loss: 517.9045\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 162.0582 - val_loss: 511.4933\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 149.7310 - val_loss: 361.8649\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.3229 - val_loss: 249.9337\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.6458 - val_loss: 261.6558\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.7274 - val_loss: 194.4760\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.9914 - val_loss: 165.9388\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.8666 - val_loss: 155.1738\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.3887 - val_loss: 179.4325\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.0903 - val_loss: 167.7735\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 74.6614 - val_loss: 146.4516\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.1025 - val_loss: 200.1173\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.1379 - val_loss: 187.9998\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 146.8710 - val_loss: 188.9148\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 126.8598 - val_loss: 174.7103\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 74.2493 - val_loss: 178.9625\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.3661 - val_loss: 162.7460\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.5296 - val_loss: 143.1368\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.8969 - val_loss: 137.5376\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.6615 - val_loss: 155.7716\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.9844 - val_loss: 176.0923\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.6167 - val_loss: 176.2905\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.8179 - val_loss: 180.5899\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.4059 - val_loss: 165.3158\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.1109 - val_loss: 121.9160\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.5337 - val_loss: 120.6386\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.7669 - val_loss: 301.1562\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.1496 - val_loss: 171.4647\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.6557 - val_loss: 128.9474\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9119 - val_loss: 196.3863\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 138.8175 - val_loss: 109.8387\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.7554 - val_loss: 108.2665\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.0678 - val_loss: 101.9524\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 115.2256 - val_loss: 86.0214\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.2994 - val_loss: 85.8850\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 122.2252 - val_loss: 87.0869\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.1796 - val_loss: 77.7743\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.2430 - val_loss: 77.3934\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 67.1752 - val_loss: 94.9302\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.3093 - val_loss: 67.5740\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.5227 - val_loss: 97.0511\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.1482 - val_loss: 296.5705\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.0113 - val_loss: 115.4600\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.0539 - val_loss: 213.5642\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.0834 - val_loss: 109.7233\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 64.8405 - val_loss: 97.8536\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 67.0172 - val_loss: 94.0929\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 131.0975 - val_loss: 339.7630\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.9176 - val_loss: 205.6961\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.2040 - val_loss: 180.3294\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 123.7422 - val_loss: 441.4561\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 190.8950 - val_loss: 301.1884\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 122.4784 - val_loss: 310.0639\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 123.8244 - val_loss: 275.8630\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.2400 - val_loss: 481.6084\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 255.4546 - val_loss: 406.3516\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 189.9178 - val_loss: 229.4190\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 174.3776 - val_loss: 316.2890\n",
      "Epoch 471/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 130.1105 - val_loss: 250.9572\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.3058 - val_loss: 236.4308\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.8281 - val_loss: 315.8532\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 148.5746 - val_loss: 342.7450\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 163.6808 - val_loss: 363.5666\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 178.7052 - val_loss: 341.3986\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 196.6608 - val_loss: 392.2897\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 137.4732 - val_loss: 347.8380\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 123.9474 - val_loss: 271.9402\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.7813 - val_loss: 214.4754\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.6466 - val_loss: 186.7039\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 74.3029 - val_loss: 155.6571\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.5280 - val_loss: 155.2378\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.8216 - val_loss: 70.4420\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.7969 - val_loss: 73.6513\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 66.3787 - val_loss: 59.5356\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 73.0813 - val_loss: 70.4066\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.6960 - val_loss: 67.8632\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.2502 - val_loss: 78.6841\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 69.3887 - val_loss: 53.8090\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 62.9224 - val_loss: 67.8954\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 75.6180 - val_loss: 59.7147\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 54.4336 - val_loss: 70.0438\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 62.2199 - val_loss: 54.8626\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 61.0952 - val_loss: 54.3679\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53.7343 - val_loss: 53.0530\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 56.3809 - val_loss: 78.6656\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 121.3136 - val_loss: 204.5501\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.1113 - val_loss: 169.5294\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.4519 - val_loss: 225.2834\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 93.4659 - val_loss: 152.8214\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.8173 - val_loss: 208.8942\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 150.6953 - val_loss: 219.2189\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.7676 - val_loss: 193.7954\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.5150 - val_loss: 188.7699\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.9686 - val_loss: 179.2079\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.3745 - val_loss: 129.1268\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.1861 - val_loss: 163.5032\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.2871 - val_loss: 364.5873\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 112.2414 - val_loss: 93.7872\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 78.7228 - val_loss: 112.9691\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.7808 - val_loss: 227.9233\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.9229 - val_loss: 291.4683\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.7732 - val_loss: 172.1053\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 61.9165 - val_loss: 208.8605\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.8709 - val_loss: 97.0958\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.5924 - val_loss: 145.9208\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.8914 - val_loss: 108.9751\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 62.5809 - val_loss: 150.3191\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 56.9683 - val_loss: 150.2546\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 54.4326 - val_loss: 141.6369\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.6417 - val_loss: 138.0076\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.7367 - val_loss: 133.9727\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 61.0887 - val_loss: 277.3470\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.5749 - val_loss: 186.0550\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.6981 - val_loss: 179.2475\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 59.0837 - val_loss: 184.9218\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 73.9088 - val_loss: 181.5132\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 63.6752 - val_loss: 181.8616\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 67.8770 - val_loss: 177.7008\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 121.5803 - val_loss: 314.1175\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.1564 - val_loss: 279.2907\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 76.5911 - val_loss: 291.8647\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78.7465 - val_loss: 171.0836\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.6050 - val_loss: 207.3468\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 144.6482 - val_loss: 346.9388\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 158.3631 - val_loss: 260.6333\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 133.1529 - val_loss: 220.8346\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.9194 - val_loss: 370.0573\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.6481 - val_loss: 344.6346\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 229.6488 - val_loss: 242.4891\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.1798 - val_loss: 209.9147\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.4366 - val_loss: 198.9297\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 68.4931 - val_loss: 207.5079\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.7574 - val_loss: 323.1605\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.1230 - val_loss: 160.3434\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.3869 - val_loss: 153.9568\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 133.5925 - val_loss: 147.4096\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.4353 - val_loss: 94.0475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 78.7256 - val_loss: 134.8415\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.6151 - val_loss: 125.8156\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 60.7348 - val_loss: 177.0775\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 74.8861 - val_loss: 121.2878\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.8735 - val_loss: 210.4612\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.2069 - val_loss: 130.4137\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.7862 - val_loss: 103.0549\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 56.7043 - val_loss: 106.2590\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.4984 - val_loss: 150.1848\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.6865 - val_loss: 509.8304\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.3096 - val_loss: 92.9688\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.6190 - val_loss: 80.6022\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 64.4140 - val_loss: 94.3059\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.7886 - val_loss: 91.1075\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.5698 - val_loss: 334.0646\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.6429 - val_loss: 187.2665\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.4677 - val_loss: 226.0214\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 140.0378 - val_loss: 134.2367\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 67.3504 - val_loss: 204.0881\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.0358 - val_loss: 167.7597\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 119.3893 - val_loss: 186.9728\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.0166 - val_loss: 195.7567\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.3209 - val_loss: 149.8153\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.0020 - val_loss: 149.7962\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.9746 - val_loss: 210.9283\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 74.9613 - val_loss: 160.4886\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.3791 - val_loss: 122.0050\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.0544 - val_loss: 175.9379\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 74.6484 - val_loss: 116.4149\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.7654 - val_loss: 143.7257\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 67.6610 - val_loss: 158.3867\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.9639 - val_loss: 137.4902\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.2755 - val_loss: 93.3450\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.6296 - val_loss: 96.6574\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.7011 - val_loss: 78.8709\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.9577 - val_loss: 72.9905\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.0767 - val_loss: 95.7019\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.5634 - val_loss: 68.4087\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.7486 - val_loss: 89.3040\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 55.3045 - val_loss: 63.2570\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.0083 - val_loss: 70.9061\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 125.9276 - val_loss: 260.3848\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.1971 - val_loss: 271.6947\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.8793 - val_loss: 118.1445\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 74.9338 - val_loss: 116.8074\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.1086 - val_loss: 98.5782\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.7829 - val_loss: 87.5902\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.0944 - val_loss: 62.8401\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 73.6777 - val_loss: 117.0183\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 73.3416 - val_loss: 150.1506\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 72.2318 - val_loss: 58.4830\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53.6792 - val_loss: 91.2475\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.7029 - val_loss: 116.9770\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.8997 - val_loss: 124.9343\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 73.3529 - val_loss: 115.3464\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 65.4868 - val_loss: 109.6183\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.9799 - val_loss: 84.8123\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 51.5617 - val_loss: 111.4920\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.0313 - val_loss: 131.2020\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 58.3572 - val_loss: 123.1193\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 60.2641 - val_loss: 103.0528\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.1664 - val_loss: 61.9127\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.3851 - val_loss: 81.0255\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.5745 - val_loss: 1295.9745\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 371.7268 - val_loss: 269.4454\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 158.5077 - val_loss: 249.6118\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 144.8674 - val_loss: 239.5850\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.6571 - val_loss: 153.2424\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.9348 - val_loss: 128.7553\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.5132 - val_loss: 137.9121\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.6473 - val_loss: 127.8726\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 135.6876 - val_loss: 281.8929\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.8048 - val_loss: 207.4488\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.4447 - val_loss: 169.8949\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.0128 - val_loss: 128.8732\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 153.2157 - val_loss: 204.6032\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.6410 - val_loss: 240.2283\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 125.3869 - val_loss: 154.0451\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.1497 - val_loss: 116.0606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.6023 - val_loss: 64.5775\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 51.9389 - val_loss: 69.9836\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 54.3495 - val_loss: 127.2563\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 82.8029 - val_loss: 53.0879\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.5580 - val_loss: 67.2022\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.5518 - val_loss: 134.9279\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.5819 - val_loss: 214.5358\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.3232 - val_loss: 108.8295\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.9372 - val_loss: 176.3616\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 68.4915 - val_loss: 114.8042\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 54.0767 - val_loss: 120.2605\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.2568 - val_loss: 163.3834\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.2721 - val_loss: 121.1480\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.9953 - val_loss: 109.9450\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 61.2677 - val_loss: 121.1783\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 55.2412 - val_loss: 96.5274\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.8915 - val_loss: 115.8558\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.9231 - val_loss: 99.3277\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.2692 - val_loss: 74.2570\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 65.2997 - val_loss: 452.9316\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.1031 - val_loss: 198.7254\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 129.7082 - val_loss: 314.9570\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 143.1916 - val_loss: 253.8330\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 121.2973 - val_loss: 175.8584\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.9991 - val_loss: 161.4653\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.7223 - val_loss: 156.3517\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.7973 - val_loss: 175.8532\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.1580 - val_loss: 197.4610\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.9515 - val_loss: 127.5008\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 71.7679 - val_loss: 124.1145\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.7365 - val_loss: 142.6143\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 71.2840 - val_loss: 95.9525\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.7410 - val_loss: 83.6071\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 43.4278 - val_loss: 82.6630\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.9082 - val_loss: 162.3668\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.1207 - val_loss: 132.1135\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 65.4267 - val_loss: 124.3731\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.2836 - val_loss: 91.0450\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.8854 - val_loss: 288.0399\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.9430 - val_loss: 410.6971\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.0023 - val_loss: 184.7253\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 65.1707 - val_loss: 154.0479\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.3871 - val_loss: 1128.4432\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 298.7926 - val_loss: 348.5127\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 150.7083 - val_loss: 495.1982\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 123.4521 - val_loss: 189.8367\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.1911 - val_loss: 424.8768\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 173.9050 - val_loss: 370.3260\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 153.0765 - val_loss: 918.8089\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 247.1208 - val_loss: 248.9750\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 129.3764 - val_loss: 168.7765\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.3439 - val_loss: 290.9438\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.7322 - val_loss: 325.4220\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 117.0939 - val_loss: 178.0386\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.4227 - val_loss: 201.3706\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.1048 - val_loss: 107.5661\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.4774 - val_loss: 122.1224\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.6594 - val_loss: 179.6556\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.2032 - val_loss: 249.7506\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.9396 - val_loss: 492.1074\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 112.5152 - val_loss: 203.9356\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78.8725 - val_loss: 154.6065\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 61.5157 - val_loss: 103.8271\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 65.5271 - val_loss: 166.6456\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 66.8503 - val_loss: 183.8117\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.0497 - val_loss: 172.9969\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 60.7255 - val_loss: 83.3144\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 65.9663 - val_loss: 82.2077\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 66.7128 - val_loss: 244.8872\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.6142 - val_loss: 194.3644\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.3106 - val_loss: 198.1399\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.2796 - val_loss: 204.6835\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.0314 - val_loss: 147.9736\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 70.2296 - val_loss: 142.6267\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.4424 - val_loss: 271.5342\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.2575 - val_loss: 284.6602\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.3888 - val_loss: 217.2365\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 82.4944 - val_loss: 197.7970\n",
      "Epoch 707/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 64.3494 - val_loss: 149.5249\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.2945 - val_loss: 312.4129\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 128.5512 - val_loss: 177.8271\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.0374 - val_loss: 124.9191\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 63.0041 - val_loss: 85.1073\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 69.0416 - val_loss: 121.9298\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 62.5311 - val_loss: 111.1998\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 68.6507 - val_loss: 67.0529\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53.2349 - val_loss: 85.0003\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 58.2298 - val_loss: 63.5710\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 59.7104 - val_loss: 58.7249\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.3991 - val_loss: 106.1723\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 50.5000 - val_loss: 84.2291\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.1446 - val_loss: 248.9626\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 131.5109 - val_loss: 123.5047\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 126.1844 - val_loss: 158.8817\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.3173 - val_loss: 147.3840\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 56.5602 - val_loss: 100.6328\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52.3183 - val_loss: 94.7820\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.3281 - val_loss: 134.5246\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.3447 - val_loss: 116.9932\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 75.6037 - val_loss: 172.5121\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 71.8601 - val_loss: 148.6664\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.1759 - val_loss: 256.4619\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.3290 - val_loss: 171.1248\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78.4753 - val_loss: 136.5149\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 70.8466 - val_loss: 117.3442\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.1648 - val_loss: 189.2505\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 142.2039 - val_loss: 79.0440\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 74.4015 - val_loss: 128.9076\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.5814 - val_loss: 146.3945\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.4000 - val_loss: 151.6783\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.9518 - val_loss: 149.3135\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.9615 - val_loss: 67.1276\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.9577 - val_loss: 113.3464\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.5748 - val_loss: 211.0893\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 76.5637 - val_loss: 162.0322\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.1859 - val_loss: 220.0362\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.6495 - val_loss: 166.7873\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 61.3561 - val_loss: 87.7863\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 61.2905 - val_loss: 117.0584\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.4058 - val_loss: 115.7497\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.8268 - val_loss: 90.1467\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 64.2600 - val_loss: 146.2964\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 74.7136 - val_loss: 97.0580\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 55.9992 - val_loss: 53.5873\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.3538 - val_loss: 28.4509\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 56.3218 - val_loss: 42.1719\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 75.9409 - val_loss: 111.9360\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.9757 - val_loss: 68.3131\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 44.0525 - val_loss: 132.2203\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 63.0548 - val_loss: 60.9254\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 59.4086 - val_loss: 64.5018\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 64.0073 - val_loss: 69.0150\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.3201 - val_loss: 116.7568\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 54.4056 - val_loss: 183.6644\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 70.7175 - val_loss: 148.4925\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 58.1352 - val_loss: 102.7870\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.0850 - val_loss: 79.9838\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.7904 - val_loss: 74.9022\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.9098 - val_loss: 93.3634\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.3481 - val_loss: 50.8701\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52.8709 - val_loss: 74.2534\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.2115 - val_loss: 49.4039\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 51.3392 - val_loss: 55.8500\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 61.6011 - val_loss: 92.9113\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.8796 - val_loss: 69.2213\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.4392 - val_loss: 135.5557\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.9308 - val_loss: 105.0624\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.0016 - val_loss: 92.3604\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 59.7543 - val_loss: 103.4370\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.0837 - val_loss: 85.0811\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.9834 - val_loss: 155.4747\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.1694 - val_loss: 150.1879\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.2634 - val_loss: 68.6145\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 54.8037 - val_loss: 112.6323\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.7281 - val_loss: 58.1231\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.5862 - val_loss: 89.8446\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.3290 - val_loss: 85.8978\n",
      "Epoch 786/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 78.1126 - val_loss: 134.1765\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 73.2849 - val_loss: 143.9589\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.6993 - val_loss: 72.0062\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.1840 - val_loss: 58.4240\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.2662 - val_loss: 95.1513\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.7326 - val_loss: 113.3738\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.8453 - val_loss: 73.1429\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.3402 - val_loss: 84.7639\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.8649 - val_loss: 129.6007\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.3705 - val_loss: 93.7981\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.4256 - val_loss: 226.7380\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.8209 - val_loss: 225.7004\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.6021 - val_loss: 151.6319\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 73.6965 - val_loss: 154.5885\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.7039 - val_loss: 117.2629\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.3204 - val_loss: 167.5629\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.7517 - val_loss: 89.4716\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.4822 - val_loss: 186.2460\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 74.2289 - val_loss: 174.8925\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.5789 - val_loss: 151.8996\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.8196 - val_loss: 80.5110\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.6851 - val_loss: 79.1624\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.0812 - val_loss: 122.8974\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 58.0699 - val_loss: 63.9383\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52.1798 - val_loss: 85.3313\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 70.8347 - val_loss: 48.4308\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 75.9521 - val_loss: 71.3810\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 68.4637 - val_loss: 82.1117\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.2949 - val_loss: 109.6121\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.1461 - val_loss: 81.9014\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.7893 - val_loss: 298.0984\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 696.6288 - val_loss: 318.9852\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 211.3894 - val_loss: 160.7874\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.9937 - val_loss: 146.6749\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.8767 - val_loss: 118.6761\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.2878 - val_loss: 229.5644\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.9110 - val_loss: 140.2327\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.2162 - val_loss: 255.7172\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.0319 - val_loss: 156.6491\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.0094 - val_loss: 183.6712\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.8667 - val_loss: 99.2670\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.8486 - val_loss: 95.3116\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.0969 - val_loss: 188.1766\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.5030 - val_loss: 108.6521\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.0545 - val_loss: 80.6726\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 71.9760 - val_loss: 63.0776\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 55.7207 - val_loss: 62.4826\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 59.9297 - val_loss: 54.8585\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.3300 - val_loss: 55.0572\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 58.2075 - val_loss: 54.7883\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 50.8176 - val_loss: 96.1558\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52.4697 - val_loss: 118.7324\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52.2471 - val_loss: 105.9833\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.7048 - val_loss: 92.4006\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.9964 - val_loss: 128.3641\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.1332 - val_loss: 87.8307\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.6230 - val_loss: 124.3050\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 55.2478 - val_loss: 130.1028\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 62.8262 - val_loss: 160.2126\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.0448 - val_loss: 128.1884\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.8675 - val_loss: 109.8009\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.3102 - val_loss: 115.5132\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.6327 - val_loss: 85.1536\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.7619 - val_loss: 57.1253\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.8788 - val_loss: 60.4752\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.9872 - val_loss: 149.3502\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 66.4662 - val_loss: 158.5572\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.6664 - val_loss: 102.6889\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.7551 - val_loss: 93.5173\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.9036 - val_loss: 98.8959\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.3726 - val_loss: 98.9652\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 48.5943 - val_loss: 216.0890\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 62.8260 - val_loss: 123.0512\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53.8331 - val_loss: 142.5868\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 56.7495 - val_loss: 128.2716\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 54.9368 - val_loss: 82.3890\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 39.0722 - val_loss: 78.1238\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.6038 - val_loss: 117.7827\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.6269 - val_loss: 74.0830\n",
      "Epoch 865/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 41.0395 - val_loss: 108.1693\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 48.2028 - val_loss: 258.8541\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 65.4783 - val_loss: 115.1413\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 50.3035 - val_loss: 112.6506\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52.2432 - val_loss: 96.9772\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.0455 - val_loss: 142.2740\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.8831 - val_loss: 74.4330\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.8872 - val_loss: 71.2046\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.0232 - val_loss: 43.1057\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.2381 - val_loss: 53.8310\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.9102 - val_loss: 68.2123\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.9580 - val_loss: 114.9522\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.5009 - val_loss: 114.3967\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 241.2324 - val_loss: 77.3765\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.0547 - val_loss: 83.9595\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.4558 - val_loss: 76.2795\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.6699 - val_loss: 76.7554\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 61.3816 - val_loss: 74.3105\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.0993 - val_loss: 53.8977\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.0334 - val_loss: 144.4554\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.3800 - val_loss: 97.1325\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.0254 - val_loss: 56.5326\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 59.4232 - val_loss: 282.6230\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.6082 - val_loss: 239.9290\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.7840 - val_loss: 121.8893\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.3096 - val_loss: 160.0518\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 73.1568 - val_loss: 171.9603\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.2570 - val_loss: 105.3922\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.5264 - val_loss: 104.7173\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52.7067 - val_loss: 100.0895\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.6458 - val_loss: 65.8659\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 46.3797 - val_loss: 53.2982\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 43.5697 - val_loss: 116.5424\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 63.6520 - val_loss: 147.5907\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.3657 - val_loss: 83.4751\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 46.4697 - val_loss: 72.8082\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.5786 - val_loss: 67.0153\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.9156 - val_loss: 205.2473\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.5211 - val_loss: 147.0483\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.7275 - val_loss: 129.8724\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.2257 - val_loss: 128.2658\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.8566 - val_loss: 130.4776\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.2008 - val_loss: 59.5436\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.5140 - val_loss: 128.0256\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.7086 - val_loss: 150.5053\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.1802 - val_loss: 55.6174\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.6291 - val_loss: 66.5113\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.0153 - val_loss: 80.2586\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.9057 - val_loss: 55.6140\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 42.3794 - val_loss: 112.0686\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.0264 - val_loss: 94.1497\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 38.9922 - val_loss: 98.3415\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.3010 - val_loss: 186.7802\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.0324 - val_loss: 184.1019\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.6513 - val_loss: 175.9469\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.6270 - val_loss: 86.8380\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.1985 - val_loss: 77.9327\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.5417 - val_loss: 97.5141\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.4993 - val_loss: 99.9441\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.6040 - val_loss: 61.9908\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.0239 - val_loss: 99.7651\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.8907 - val_loss: 177.6536\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.6103 - val_loss: 114.4249\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.9215 - val_loss: 128.3923\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.5967 - val_loss: 77.8972\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.1837 - val_loss: 82.9936\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.2270 - val_loss: 82.3220\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.5383 - val_loss: 103.3317\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.9440 - val_loss: 114.8718\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.0951 - val_loss: 103.7757\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.2659 - val_loss: 107.3096\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.2820 - val_loss: 80.2155\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.5326 - val_loss: 298.2717\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.5116 - val_loss: 142.2077\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.7759 - val_loss: 126.0667\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.9071 - val_loss: 117.8442\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.9693 - val_loss: 183.6802\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 74.7105 - val_loss: 182.0104\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.2711 - val_loss: 141.2055\n",
      "Epoch 944/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 65.2304 - val_loss: 139.2522\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.7384 - val_loss: 147.2963\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.9182 - val_loss: 93.0417\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.1821 - val_loss: 121.6218\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.5489 - val_loss: 75.9831\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 38.5954 - val_loss: 73.3816\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 39.7236 - val_loss: 67.0732\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 44.0029 - val_loss: 60.2665\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 66.4562 - val_loss: 82.9565\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 43.6285 - val_loss: 71.4755\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 48.4414 - val_loss: 65.7315\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 43.6087 - val_loss: 79.0337\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 43.9638 - val_loss: 86.8069\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.7168 - val_loss: 89.3767\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.5762 - val_loss: 75.8163\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.2283 - val_loss: 72.5997\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.1311 - val_loss: 72.3892\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.2547 - val_loss: 141.6505\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 51.2217 - val_loss: 129.1443\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 60.0897 - val_loss: 82.3281\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 60.8105 - val_loss: 86.0352\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 42.8260 - val_loss: 81.7754\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 50.6507 - val_loss: 165.8367\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.3681 - val_loss: 138.7171\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 69.3187 - val_loss: 166.0627\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 60.1989 - val_loss: 156.4576\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 59.6711 - val_loss: 159.8871\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.7524 - val_loss: 119.0340\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 64.7806 - val_loss: 124.9576\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 58.0982 - val_loss: 114.4368\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 65.2199 - val_loss: 108.6766\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 71.9529 - val_loss: 158.9987\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78.8668 - val_loss: 171.2544\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 56.9414 - val_loss: 203.4995\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 76.1509 - val_loss: 134.8716\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 64.1957 - val_loss: 154.2327\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.9485 - val_loss: 204.0589\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.1633 - val_loss: 125.1834\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.0194 - val_loss: 165.6447\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 60.6534 - val_loss: 104.6281\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.3109 - val_loss: 89.4367\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.7572 - val_loss: 89.3214\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 46.8678 - val_loss: 144.1019\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 50.6538 - val_loss: 131.6227\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 61.2712 - val_loss: 167.0896\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.3062 - val_loss: 114.7282\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.7347 - val_loss: 153.3712\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.0446 - val_loss: 123.8153\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.2174 - val_loss: 166.2618\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.4914 - val_loss: 187.2923\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.7845 - val_loss: 131.6354\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 68.2711 - val_loss: 147.1866\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.8944 - val_loss: 104.0505\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.0684 - val_loss: 108.4078\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 66.0316 - val_loss: 93.3428\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.1791 - val_loss: 93.7619\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.7515 - val_loss: 105.4256\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.1058 - val_loss: 87.6007\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.0829 - val_loss: 127.3927\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.7427 - val_loss: 131.9404\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 67.1435 - val_loss: 107.4318\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.5108 - val_loss: 88.4099\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 36.3358 - val_loss: 54.3678\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 38.3266 - val_loss: 58.1203\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 39.0661 - val_loss: 56.7961\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52.0826 - val_loss: 65.7776\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.0925 - val_loss: 47.0109\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 34.8069 - val_loss: 115.5764\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.6300 - val_loss: 110.1059\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.2350 - val_loss: 118.0200\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.9009 - val_loss: 115.8923\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 44.7572 - val_loss: 115.3650\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.3271 - val_loss: 59.6319\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 50.1416 - val_loss: 103.6086\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.2975 - val_loss: 59.8990\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 37.4007 - val_loss: 58.8407\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 35.1822 - val_loss: 55.2656\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 34.3933 - val_loss: 52.6315\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.9924 - val_loss: 71.4976\n",
      "Epoch 1023/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 52.0367 - val_loss: 73.3556\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.8896 - val_loss: 55.7418\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.2683 - val_loss: 101.7289\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.0965 - val_loss: 125.4318\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 37.1626 - val_loss: 143.8006\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.0165 - val_loss: 103.2048\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.3684 - val_loss: 91.7062\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.5848 - val_loss: 97.4706\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.2733 - val_loss: 152.0606\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 55.2719 - val_loss: 76.3505\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.3025 - val_loss: 77.3574\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.5575 - val_loss: 46.5081\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.4513 - val_loss: 69.9858\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 39.7059 - val_loss: 64.0109\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 44.7319 - val_loss: 89.2301\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 39.7891 - val_loss: 79.1498\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 62.3727 - val_loss: 229.0878\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 64.8256 - val_loss: 126.6885\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 74.0604 - val_loss: 91.7380\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.1307 - val_loss: 72.0410\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.2260 - val_loss: 65.8584\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 46.3476 - val_loss: 77.4763\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52.5066 - val_loss: 76.8483\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.4930 - val_loss: 79.6837\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.9096 - val_loss: 76.2557\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.9573 - val_loss: 60.3400\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.5357 - val_loss: 51.8721\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.2206 - val_loss: 64.1173\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.5065 - val_loss: 106.4014\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.9692 - val_loss: 94.7884\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.4758 - val_loss: 75.9450\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.7513 - val_loss: 86.4282\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.0050 - val_loss: 141.9415\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 69.9506 - val_loss: 118.5362\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.1876 - val_loss: 106.8963\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.7588 - val_loss: 122.0172\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.7488 - val_loss: 94.0097\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.9311 - val_loss: 68.7045\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.3019 - val_loss: 62.4025\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.0855 - val_loss: 205.8286\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.5900 - val_loss: 166.8933\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 67.5410 - val_loss: 122.5742\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 58.0727 - val_loss: 96.3837\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 44.5230 - val_loss: 127.4423\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.6855 - val_loss: 59.7545\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.7218 - val_loss: 51.4929\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.4206 - val_loss: 47.4944\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 36.6906 - val_loss: 41.1743\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.1590 - val_loss: 65.7370\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.4093 - val_loss: 54.4492\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.7329 - val_loss: 67.8882\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 59.7192 - val_loss: 57.3057\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.3889 - val_loss: 154.4030\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 55.0590 - val_loss: 73.9164\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.3642 - val_loss: 94.3510\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.8345 - val_loss: 56.8436\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 39.4804 - val_loss: 82.6034\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.8360 - val_loss: 46.2276\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 38.5924 - val_loss: 39.3166\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 41.1017 - val_loss: 82.3081\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 54.6813 - val_loss: 146.9177\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 61.2552 - val_loss: 75.5029\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 46.4168 - val_loss: 170.6453\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.7006 - val_loss: 158.6103\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 39.3492 - val_loss: 55.2275\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.1580 - val_loss: 78.5087\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.3018 - val_loss: 237.7701\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.7278 - val_loss: 194.6281\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.0764 - val_loss: 153.3783\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 723.4173 - val_loss: 333.8953\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.4276 - val_loss: 91.9241\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.7388 - val_loss: 109.7633\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 65.8284 - val_loss: 72.7265\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.7239 - val_loss: 79.8645\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.8770 - val_loss: 168.4720\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.7382 - val_loss: 165.9055\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.5443 - val_loss: 86.7063\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.2106 - val_loss: 113.0589\n",
      "Epoch 1101/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 58.0632 - val_loss: 80.8861\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.0755 - val_loss: 83.2722\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 43.5759 - val_loss: 49.8679\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 48.6382 - val_loss: 51.0368\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.8990 - val_loss: 59.9301\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 42.1563 - val_loss: 82.5181\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.9979 - val_loss: 177.0907\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 72.3676 - val_loss: 185.0756\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 54.6602 - val_loss: 175.8273\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.7862 - val_loss: 91.7077\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.9270 - val_loss: 70.7995\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.0341 - val_loss: 66.5825\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.0971 - val_loss: 76.4679\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.5114 - val_loss: 62.1696\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.2907 - val_loss: 214.9122\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.9590 - val_loss: 114.9753\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.4139 - val_loss: 109.5865\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.1793 - val_loss: 116.9099\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.1600 - val_loss: 196.6341\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.5894 - val_loss: 219.6834\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.7037 - val_loss: 160.8247\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 74.1768 - val_loss: 155.2770\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.7967 - val_loss: 148.8479\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.9475 - val_loss: 115.7855\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.8818 - val_loss: 139.1721\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.6665 - val_loss: 122.1978\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 61.1726 - val_loss: 112.2361\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.8799 - val_loss: 87.9559\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 48.4974 - val_loss: 91.0163\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 48.1524 - val_loss: 100.3044\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 51.2605 - val_loss: 90.3983\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 44.0693 - val_loss: 94.9602\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 41.3895 - val_loss: 95.2798\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.6217 - val_loss: 130.6035\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.7856 - val_loss: 110.2292\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.3145 - val_loss: 146.9804\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.7117 - val_loss: 152.2862\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.2447 - val_loss: 95.5645\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 59.4137 - val_loss: 189.7166\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 73.2384 - val_loss: 235.3994\n",
      "Epoch 1141/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.0579 - val_loss: 276.8343\n",
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.4537 - val_loss: 162.5993\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.7555 - val_loss: 140.2106\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.5167 - val_loss: 150.6616\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.7080 - val_loss: 129.1987\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.4074 - val_loss: 95.3065\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 43.4603 - val_loss: 123.0277\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 56.0566 - val_loss: 60.8768\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.8919 - val_loss: 114.3012\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.7394 - val_loss: 163.2904\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.9089 - val_loss: 154.3892\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.9571 - val_loss: 145.7639\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.8705 - val_loss: 127.8121\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.4829 - val_loss: 72.7415\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 44.4234 - val_loss: 83.8542\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.8960 - val_loss: 59.3781\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.9567 - val_loss: 65.9597\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.3127 - val_loss: 98.3304\n",
      "Epoch 1159/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.7246 - val_loss: 66.7350\n",
      "Epoch 1160/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 70.9914 - val_loss: 91.3350\n",
      "Epoch 1161/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.8515 - val_loss: 118.5030\n",
      "Epoch 1162/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.1134 - val_loss: 45.8461\n",
      "Epoch 1163/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.0143 - val_loss: 128.7469\n",
      "Epoch 1164/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.4254 - val_loss: 90.7599\n",
      "Epoch 1165/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.9325 - val_loss: 132.3235\n",
      "Epoch 1166/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 62.4493 - val_loss: 126.3447\n",
      "Epoch 1167/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.1113 - val_loss: 171.2686\n",
      "Epoch 1168/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 60.5933 - val_loss: 221.8518\n",
      "Epoch 1169/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.0494 - val_loss: 86.6458\n",
      "Epoch 1170/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53.8960 - val_loss: 120.3511\n",
      "Epoch 1171/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.7922 - val_loss: 99.6425\n",
      "Epoch 1172/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.4747 - val_loss: 118.9550\n",
      "Epoch 1173/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.9087 - val_loss: 49.4116\n",
      "Epoch 1174/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.8302 - val_loss: 40.5242\n",
      "Epoch 1175/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.9234 - val_loss: 46.8020\n",
      "Epoch 1176/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.7359 - val_loss: 68.6618\n",
      "Epoch 1177/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 35.5260 - val_loss: 56.5526\n",
      "Epoch 1178/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 39.2380 - val_loss: 86.7237\n",
      "Epoch 1179/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 45.3447 - val_loss: 88.5433\n",
      "Epoch 1180/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 39.6536 - val_loss: 52.7814\n",
      "Epoch 1181/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.8180 - val_loss: 128.5506\n",
      "Epoch 1182/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.9251 - val_loss: 132.0729\n",
      "Epoch 1183/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.1766 - val_loss: 115.7136\n",
      "Epoch 1184/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.8177 - val_loss: 118.3624\n",
      "Epoch 1185/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37.1346 - val_loss: 95.3647\n",
      "Epoch 1186/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 32.3225 - val_loss: 47.9833\n",
      "Epoch 1187/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 38.7296 - val_loss: 122.7558\n",
      "Epoch 1188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.6551 - val_loss: 121.5163\n",
      "Epoch 1189/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.0741 - val_loss: 86.3964\n",
      "Epoch 1190/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.5889 - val_loss: 97.8872\n",
      "Epoch 1191/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.5433 - val_loss: 143.5885\n",
      "Epoch 1192/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.1659 - val_loss: 73.9145\n",
      "Epoch 1193/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.1015 - val_loss: 265.0077\n",
      "Epoch 1194/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 73.1057 - val_loss: 99.3010\n",
      "Epoch 1195/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.1710 - val_loss: 107.8689\n",
      "Epoch 1196/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.3211 - val_loss: 99.5431\n",
      "Epoch 1197/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 36.0357 - val_loss: 89.2493\n",
      "Epoch 1198/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.0073 - val_loss: 124.3049\n",
      "Epoch 1199/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.6589 - val_loss: 103.1647\n",
      "Epoch 1200/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 48.8298 - val_loss: 108.8897\n",
      "Epoch 1201/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.7904 - val_loss: 86.3810\n",
      "Epoch 1202/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.7410 - val_loss: 89.4126\n",
      "Epoch 1203/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 39.4670 - val_loss: 47.7024\n",
      "Epoch 1204/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 72.8622 - val_loss: 50.9610\n",
      "Epoch 1205/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37.6071 - val_loss: 70.6274\n",
      "Epoch 1206/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 36.6944 - val_loss: 67.6840\n",
      "Epoch 1207/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.8519 - val_loss: 118.7236\n",
      "Epoch 1208/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.3048 - val_loss: 77.1834\n",
      "Epoch 1209/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.9279 - val_loss: 38.3806\n",
      "Epoch 1210/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.9938 - val_loss: 49.3976\n",
      "Epoch 1211/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 32.7305 - val_loss: 45.2690\n",
      "Epoch 1212/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37.5065 - val_loss: 68.7310\n",
      "Epoch 1213/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.1989 - val_loss: 59.2340\n",
      "Epoch 1214/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.6773 - val_loss: 65.2185\n",
      "Epoch 1215/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 38.6475 - val_loss: 59.5067\n",
      "Epoch 1216/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.2777 - val_loss: 67.8020\n",
      "Epoch 1217/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 39.4707 - val_loss: 57.6565\n",
      "Epoch 1218/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 38.6047 - val_loss: 71.1348\n",
      "Epoch 1219/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.5510 - val_loss: 53.5495\n",
      "Epoch 1220/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 36.7246 - val_loss: 79.0270\n",
      "Epoch 1221/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.7238 - val_loss: 60.2389\n",
      "Epoch 1222/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.2550 - val_loss: 61.0711\n",
      "Epoch 1223/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.6118 - val_loss: 69.5736\n",
      "Epoch 1224/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.7836 - val_loss: 94.3534\n",
      "Epoch 1225/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.4837 - val_loss: 170.2231\n",
      "Epoch 1226/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.4957 - val_loss: 100.2452\n",
      "Epoch 1227/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.7166 - val_loss: 181.9003\n",
      "Epoch 1228/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.0160 - val_loss: 117.9487\n",
      "Epoch 1229/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.2753 - val_loss: 307.5887\n",
      "Epoch 1230/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.3002 - val_loss: 129.3622\n",
      "Epoch 1231/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.5522 - val_loss: 130.8477\n",
      "Epoch 1232/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.4609 - val_loss: 128.9753\n",
      "Epoch 1233/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.2252 - val_loss: 116.2664\n",
      "Epoch 1234/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.6561 - val_loss: 88.4875\n",
      "Epoch 1235/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.3967 - val_loss: 87.8571\n",
      "Epoch 1236/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.1369 - val_loss: 128.5998\n",
      "Epoch 1237/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.9443 - val_loss: 212.1007\n",
      "Epoch 1238/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.5551 - val_loss: 197.9547\n",
      "Epoch 1239/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.5010 - val_loss: 169.5188\n",
      "Epoch 1240/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.2404 - val_loss: 176.2746\n",
      "Epoch 1241/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 79.3276 - val_loss: 189.1374\n",
      "Epoch 1242/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 65.3992 - val_loss: 198.5508\n",
      "Epoch 1243/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 79.6196 - val_loss: 156.6527\n",
      "Epoch 1244/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.2012 - val_loss: 133.1870\n",
      "Epoch 1245/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.2281 - val_loss: 318.9448\n",
      "Epoch 1246/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.2711 - val_loss: 197.4973\n",
      "Epoch 1247/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.4846 - val_loss: 165.5495\n",
      "Epoch 1248/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.2508 - val_loss: 154.1727\n",
      "Epoch 1249/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.8438 - val_loss: 259.2382\n",
      "Epoch 1250/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.6945 - val_loss: 171.2933\n",
      "Epoch 1251/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.8199 - val_loss: 144.6511\n",
      "Epoch 1252/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.6291 - val_loss: 128.0405\n",
      "Epoch 1253/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 84.6706Restoring model weights from the end of the best epoch: 753.\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 65.4052 - val_loss: 123.7419\n",
      "Epoch 1253: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>74.155411</td>\n",
       "      <td>74.326218</td>\n",
       "      <td>74.668243</td>\n",
       "      <td>75.006668</td>\n",
       "      <td>79.795372</td>\n",
       "      <td>75.155807</td>\n",
       "      <td>1.72814</td>\n",
       "      <td>1.693926</td>\n",
       "      <td>1.727942</td>\n",
       "      <td>1.715376</td>\n",
       "      <td>1.328596</td>\n",
       "      <td>49.680771</td>\n",
       "      <td>1.338217</td>\n",
       "      <td>-0.627722</td>\n",
       "      <td>1.460718</td>\n",
       "      <td>1.723684</td>\n",
       "      <td>2.021902</td>\n",
       "      <td>-0.072618</td>\n",
       "      <td>-1.431263</td>\n",
       "      <td>-1.031935</td>\n",
       "      <td>-1.028112</td>\n",
       "      <td>-1.462158</td>\n",
       "      <td>-1.554167</td>\n",
       "      <td>-1.563202</td>\n",
       "      <td>-1.56782</td>\n",
       "      <td>-1.29146</td>\n",
       "      <td>1.705715</td>\n",
       "      <td>30.12989</td>\n",
       "      <td>76.895645</td>\n",
       "      <td>74.264107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>80.517</td>\n",
       "      <td>81.348</td>\n",
       "      <td>76.509</td>\n",
       "      <td>71.851</td>\n",
       "      <td>71.187</td>\n",
       "      <td>58.02</td>\n",
       "      <td>63.194</td>\n",
       "      <td>60.58</td>\n",
       "      <td>69.448</td>\n",
       "      <td>74.472</td>\n",
       "      <td>63.776</td>\n",
       "      <td>81.732</td>\n",
       "      <td>83.858</td>\n",
       "      <td>87.863</td>\n",
       "      <td>69.723</td>\n",
       "      <td>72.765</td>\n",
       "      <td>77.937</td>\n",
       "      <td>64.332</td>\n",
       "      <td>77.048</td>\n",
       "      <td>65.66</td>\n",
       "      <td>65.445</td>\n",
       "      <td>78.095</td>\n",
       "      <td>80.998</td>\n",
       "      <td>69.415</td>\n",
       "      <td>87.346</td>\n",
       "      <td>82.888</td>\n",
       "      <td>79.287</td>\n",
       "      <td>81.855</td>\n",
       "      <td>77.495</td>\n",
       "      <td>56.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>6.361588</td>\n",
       "      <td>7.021782</td>\n",
       "      <td>1.840759</td>\n",
       "      <td>3.15567</td>\n",
       "      <td>8.608376</td>\n",
       "      <td>17.135807</td>\n",
       "      <td>61.465858</td>\n",
       "      <td>58.886078</td>\n",
       "      <td>67.720055</td>\n",
       "      <td>72.756622</td>\n",
       "      <td>62.447403</td>\n",
       "      <td>32.051231</td>\n",
       "      <td>82.519783</td>\n",
       "      <td>88.490723</td>\n",
       "      <td>68.262283</td>\n",
       "      <td>71.041313</td>\n",
       "      <td>75.915092</td>\n",
       "      <td>64.404617</td>\n",
       "      <td>78.479263</td>\n",
       "      <td>66.69194</td>\n",
       "      <td>66.473114</td>\n",
       "      <td>79.557159</td>\n",
       "      <td>82.55217</td>\n",
       "      <td>70.978203</td>\n",
       "      <td>88.913818</td>\n",
       "      <td>84.179459</td>\n",
       "      <td>77.581284</td>\n",
       "      <td>51.725113</td>\n",
       "      <td>0.599358</td>\n",
       "      <td>17.652107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1          2          3          4          5   \\\n",
       "Month         Month-1    Month-2    Month-3    Month-4    Month-5    Month-6   \n",
       "Prediction  74.155411  74.326218  74.668243  75.006668  79.795372  75.155807   \n",
       "Target         80.517     81.348     76.509     71.851     71.187      58.02   \n",
       "Error        6.361588   7.021782   1.840759    3.15567   8.608376  17.135807   \n",
       "\n",
       "                   6          7          8          9          10         11  \\\n",
       "Month         Month-7    Month-8    Month-9   Month-10   Month-11   Month-12   \n",
       "Prediction    1.72814   1.693926   1.727942   1.715376   1.328596  49.680771   \n",
       "Target         63.194      60.58     69.448     74.472     63.776     81.732   \n",
       "Error       61.465858  58.886078  67.720055  72.756622  62.447403  32.051231   \n",
       "\n",
       "                   12         13         14         15         16         17  \\\n",
       "Month        Month-13   Month-14   Month-15   Month-16   Month-17   Month-18   \n",
       "Prediction   1.338217  -0.627722   1.460718   1.723684   2.021902  -0.072618   \n",
       "Target         83.858     87.863     69.723     72.765     77.937     64.332   \n",
       "Error       82.519783  88.490723  68.262283  71.041313  75.915092  64.404617   \n",
       "\n",
       "                   18        19         20         21        22         23  \\\n",
       "Month        Month-19  Month-20   Month-21   Month-22  Month-23   Month-24   \n",
       "Prediction  -1.431263 -1.031935  -1.028112  -1.462158 -1.554167  -1.563202   \n",
       "Target         77.048     65.66     65.445     78.095    80.998     69.415   \n",
       "Error       78.479263  66.69194  66.473114  79.557159  82.55217  70.978203   \n",
       "\n",
       "                   24         25         26         27         28         29  \n",
       "Month        Month-25   Month-26   Month-27   Month-28   Month-29   Month-30  \n",
       "Prediction   -1.56782   -1.29146   1.705715   30.12989  76.895645  74.264107  \n",
       "Target         87.346     82.888     79.287     81.855     77.495     56.612  \n",
       "Error       88.913818  84.179459  77.581284  51.725113   0.599358  17.652107  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.848934"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7304437"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Ano-0: |Prediction[[510.98248]] - Target[852.6339999999999]| =  Error: [[341.6515]]; MAPE:[[0.40070122]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[-2.226656]] - Target[893.1390000000001]| =  Error: [[895.36566]]; MAPE:[[1.0024931]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Ano-5: |Prediction[[180.13608]] - Target[465.48300000000006]| =  Error: [[285.34692]]; MAPE:[[0.61301255]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[341.6515]], dtype=float32),\n",
       " array([[895.36566]], dtype=float32),\n",
       " array([[285.34692]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "507.45468"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.672069"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
