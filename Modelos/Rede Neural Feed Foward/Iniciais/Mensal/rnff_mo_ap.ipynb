{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Amapá - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Amapá - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Amapá - PIB - Estadual</th>\n",
       "      <th>Amapá - PIB - Construção Civil</th>\n",
       "      <th>Amapá - PIB - Per Capita</th>\n",
       "      <th>Amapá - PIB - Preços de Mercado</th>\n",
       "      <th>Amapá - Desemprego</th>\n",
       "      <th>Amapá - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711421</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>8.035813e+06</td>\n",
       "      <td>356591.003430</td>\n",
       "      <td>10.883143</td>\n",
       "      <td>7.033593e+06</td>\n",
       "      <td>8.514392</td>\n",
       "      <td>10.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.711553</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>8.046432e+06</td>\n",
       "      <td>356647.711004</td>\n",
       "      <td>10.885206</td>\n",
       "      <td>7.037356e+06</td>\n",
       "      <td>8.508753</td>\n",
       "      <td>6.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.711685</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>8.057052e+06</td>\n",
       "      <td>356704.418579</td>\n",
       "      <td>10.887268</td>\n",
       "      <td>7.041120e+06</td>\n",
       "      <td>8.503114</td>\n",
       "      <td>7.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.711817</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>8.067671e+06</td>\n",
       "      <td>356761.126153</td>\n",
       "      <td>10.889331</td>\n",
       "      <td>7.044883e+06</td>\n",
       "      <td>8.497475</td>\n",
       "      <td>7.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.711949</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>8.078290e+06</td>\n",
       "      <td>356817.833728</td>\n",
       "      <td>10.891394</td>\n",
       "      <td>7.048646e+06</td>\n",
       "      <td>8.491835</td>\n",
       "      <td>5.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Amapá - IDH  \\\n",
       "0           1.0     0.711421   \n",
       "1           2.0     0.711553   \n",
       "2           3.0     0.711685   \n",
       "3           4.0     0.711817   \n",
       "4           5.0     0.711949   \n",
       "..          ...          ...   \n",
       "235         8.0          NaN   \n",
       "236         9.0          NaN   \n",
       "237        10.0          NaN   \n",
       "238        11.0          NaN   \n",
       "239        12.0          NaN   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     Amapá - PIB - Estadual  Amapá - PIB - Construção Civil  \\\n",
       "0              8.035813e+06                   356591.003430   \n",
       "1              8.046432e+06                   356647.711004   \n",
       "2              8.057052e+06                   356704.418579   \n",
       "3              8.067671e+06                   356761.126153   \n",
       "4              8.078290e+06                   356817.833728   \n",
       "..                      ...                             ...   \n",
       "235                     NaN                             NaN   \n",
       "236                     NaN                             NaN   \n",
       "237                     NaN                             NaN   \n",
       "238                     NaN                             NaN   \n",
       "239                     NaN                             NaN   \n",
       "\n",
       "     Amapá - PIB - Per Capita  Amapá - PIB - Preços de Mercado  \\\n",
       "0                   10.883143                     7.033593e+06   \n",
       "1                   10.885206                     7.037356e+06   \n",
       "2                   10.887268                     7.041120e+06   \n",
       "3                   10.889331                     7.044883e+06   \n",
       "4                   10.891394                     7.048646e+06   \n",
       "..                        ...                              ...   \n",
       "235                       NaN                              NaN   \n",
       "236                       NaN                              NaN   \n",
       "237                       NaN                              NaN   \n",
       "238                       NaN                              NaN   \n",
       "239                       NaN                              NaN   \n",
       "\n",
       "     Amapá - Desemprego  Amapá - Consumo de Cimento (t)  \n",
       "0              8.514392                          10.392  \n",
       "1              8.508753                           6.857  \n",
       "2              8.503114                           7.011  \n",
       "3              8.497475                           7.122  \n",
       "4              8.491835                           5.267  \n",
       "..                  ...                             ...  \n",
       "235                 NaN                          13.208  \n",
       "236                 NaN                          13.476  \n",
       "237                 NaN                          11.236  \n",
       "238                 NaN                          13.549  \n",
       "239                 NaN                          13.549  \n",
       "\n",
       "[240 rows x 15 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_AP.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data['Unnamed: 0'] = data['Unnamed: 0'].str[5:].astype(float)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Amapá - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Amapá - PIB - Estadual</th>\n",
       "      <th>Amapá - PIB - Construção Civil</th>\n",
       "      <th>Amapá - PIB - Per Capita</th>\n",
       "      <th>Amapá - PIB - Preços de Mercado</th>\n",
       "      <th>Amapá - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.593255</td>\n",
       "      <td>-2.943242</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.716825</td>\n",
       "      <td>-0.487709</td>\n",
       "      <td>-0.246236</td>\n",
       "      <td>-1.984303</td>\n",
       "      <td>-0.890357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.303572</td>\n",
       "      <td>-2.870364</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.697794</td>\n",
       "      <td>-0.479493</td>\n",
       "      <td>-0.208006</td>\n",
       "      <td>-1.951397</td>\n",
       "      <td>-0.891922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.013890</td>\n",
       "      <td>-2.797485</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.678763</td>\n",
       "      <td>-0.471277</td>\n",
       "      <td>-0.169777</td>\n",
       "      <td>-1.918491</td>\n",
       "      <td>-0.893486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.724207</td>\n",
       "      <td>-2.724606</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.659732</td>\n",
       "      <td>-0.463061</td>\n",
       "      <td>-0.131548</td>\n",
       "      <td>-1.885585</td>\n",
       "      <td>-0.895051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>-2.651728</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.640701</td>\n",
       "      <td>-0.454845</td>\n",
       "      <td>-0.093319</td>\n",
       "      <td>-1.852679</td>\n",
       "      <td>-0.896616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.434524</td>\n",
       "      <td>-0.638974</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.145925</td>\n",
       "      <td>-1.614044</td>\n",
       "      <td>-1.566534</td>\n",
       "      <td>1.010496</td>\n",
       "      <td>1.085785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.724207</td>\n",
       "      <td>-0.739823</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.135411</td>\n",
       "      <td>-1.605628</td>\n",
       "      <td>-1.579697</td>\n",
       "      <td>0.995294</td>\n",
       "      <td>1.078764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.013890</td>\n",
       "      <td>-0.840672</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.124897</td>\n",
       "      <td>-1.597213</td>\n",
       "      <td>-1.592859</td>\n",
       "      <td>0.980093</td>\n",
       "      <td>1.071742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.303572</td>\n",
       "      <td>-0.941521</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.114383</td>\n",
       "      <td>-1.588797</td>\n",
       "      <td>-1.606022</td>\n",
       "      <td>0.964891</td>\n",
       "      <td>1.064721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.593255</td>\n",
       "      <td>-1.042370</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.103869</td>\n",
       "      <td>-1.580382</td>\n",
       "      <td>-1.619185</td>\n",
       "      <td>0.949689</td>\n",
       "      <td>1.057699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Amapá - IDH  \\\n",
       "0     -1.593255    -2.943242   \n",
       "1     -1.303572    -2.870364   \n",
       "2     -1.013890    -2.797485   \n",
       "3     -0.724207    -2.724606   \n",
       "4     -0.434524    -2.651728   \n",
       "..          ...          ...   \n",
       "187    0.434524    -0.638974   \n",
       "188    0.724207    -0.739823   \n",
       "189    1.013890    -0.840672   \n",
       "190    1.303572    -0.941521   \n",
       "191    1.593255    -1.042370   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Amapá - PIB - Estadual  Amapá - PIB - Construção Civil  \\\n",
       "0                 -1.716825                       -0.487709   \n",
       "1                 -1.697794                       -0.479493   \n",
       "2                 -1.678763                       -0.471277   \n",
       "3                 -1.659732                       -0.463061   \n",
       "4                 -1.640701                       -0.454845   \n",
       "..                      ...                             ...   \n",
       "187                1.145925                       -1.614044   \n",
       "188                1.135411                       -1.605628   \n",
       "189                1.124897                       -1.597213   \n",
       "190                1.114383                       -1.588797   \n",
       "191                1.103869                       -1.580382   \n",
       "\n",
       "     Amapá - PIB - Per Capita  Amapá - PIB - Preços de Mercado  \\\n",
       "0                   -0.246236                        -1.984303   \n",
       "1                   -0.208006                        -1.951397   \n",
       "2                   -0.169777                        -1.918491   \n",
       "3                   -0.131548                        -1.885585   \n",
       "4                   -0.093319                        -1.852679   \n",
       "..                        ...                              ...   \n",
       "187                 -1.566534                         1.010496   \n",
       "188                 -1.579697                         0.995294   \n",
       "189                 -1.592859                         0.980093   \n",
       "190                 -1.606022                         0.964891   \n",
       "191                 -1.619185                         0.949689   \n",
       "\n",
       "     Amapá - Desemprego  \n",
       "0             -0.890357  \n",
       "1             -0.891922  \n",
       "2             -0.893486  \n",
       "3             -0.895051  \n",
       "4             -0.896616  \n",
       "..                  ...  \n",
       "187            1.085785  \n",
       "188            1.078764  \n",
       "189            1.071742  \n",
       "190            1.064721  \n",
       "191            1.057699  \n",
       "\n",
       "[192 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,0:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      10.000\n",
       "1       6.136\n",
       "2       5.122\n",
       "3       3.926\n",
       "4       6.197\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Amapá - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Amapá - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Amapá - PIB - Estadual</th>\n",
       "      <th>Amapá - PIB - Construção Civil</th>\n",
       "      <th>Amapá - PIB - Per Capita</th>\n",
       "      <th>Amapá - PIB - Preços de Mercado</th>\n",
       "      <th>Amapá - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.593255</td>\n",
       "      <td>-2.943242</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.716825</td>\n",
       "      <td>-0.487709</td>\n",
       "      <td>-0.246236</td>\n",
       "      <td>-1.984303</td>\n",
       "      <td>-0.890357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.303572</td>\n",
       "      <td>-2.870364</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.697794</td>\n",
       "      <td>-0.479493</td>\n",
       "      <td>-0.208006</td>\n",
       "      <td>-1.951397</td>\n",
       "      <td>-0.891922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.013890</td>\n",
       "      <td>-2.797485</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.678763</td>\n",
       "      <td>-0.471277</td>\n",
       "      <td>-0.169777</td>\n",
       "      <td>-1.918491</td>\n",
       "      <td>-0.893486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.724207</td>\n",
       "      <td>-2.724606</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.659732</td>\n",
       "      <td>-0.463061</td>\n",
       "      <td>-0.131548</td>\n",
       "      <td>-1.885585</td>\n",
       "      <td>-0.895051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>-2.651728</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.640701</td>\n",
       "      <td>-0.454845</td>\n",
       "      <td>-0.093319</td>\n",
       "      <td>-1.852679</td>\n",
       "      <td>-0.896616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-1.303572</td>\n",
       "      <td>1.388995</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>1.179199</td>\n",
       "      <td>-1.457028</td>\n",
       "      <td>-1.470096</td>\n",
       "      <td>1.047494</td>\n",
       "      <td>1.300799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-1.013890</td>\n",
       "      <td>1.332036</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>1.184540</td>\n",
       "      <td>-1.486109</td>\n",
       "      <td>-1.464204</td>\n",
       "      <td>1.056372</td>\n",
       "      <td>1.292722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.724207</td>\n",
       "      <td>1.275077</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>1.189880</td>\n",
       "      <td>-1.515190</td>\n",
       "      <td>-1.458311</td>\n",
       "      <td>1.065250</td>\n",
       "      <td>1.284645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>1.218118</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>1.195221</td>\n",
       "      <td>-1.544271</td>\n",
       "      <td>-1.452419</td>\n",
       "      <td>1.074128</td>\n",
       "      <td>1.276568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.144841</td>\n",
       "      <td>1.161159</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>1.200562</td>\n",
       "      <td>-1.573353</td>\n",
       "      <td>-1.446526</td>\n",
       "      <td>1.083006</td>\n",
       "      <td>1.268492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Amapá - IDH  \\\n",
       "0     -1.593255    -2.943242   \n",
       "1     -1.303572    -2.870364   \n",
       "2     -1.013890    -2.797485   \n",
       "3     -0.724207    -2.724606   \n",
       "4     -0.434524    -2.651728   \n",
       "..          ...          ...   \n",
       "157   -1.303572     1.388995   \n",
       "158   -1.013890     1.332036   \n",
       "159   -0.724207     1.275077   \n",
       "160   -0.434524     1.218118   \n",
       "161   -0.144841     1.161159   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     Amapá - PIB - Estadual  Amapá - PIB - Construção Civil  \\\n",
       "0                 -1.716825                       -0.487709   \n",
       "1                 -1.697794                       -0.479493   \n",
       "2                 -1.678763                       -0.471277   \n",
       "3                 -1.659732                       -0.463061   \n",
       "4                 -1.640701                       -0.454845   \n",
       "..                      ...                             ...   \n",
       "157                1.179199                       -1.457028   \n",
       "158                1.184540                       -1.486109   \n",
       "159                1.189880                       -1.515190   \n",
       "160                1.195221                       -1.544271   \n",
       "161                1.200562                       -1.573353   \n",
       "\n",
       "     Amapá - PIB - Per Capita  Amapá - PIB - Preços de Mercado  \\\n",
       "0                   -0.246236                        -1.984303   \n",
       "1                   -0.208006                        -1.951397   \n",
       "2                   -0.169777                        -1.918491   \n",
       "3                   -0.131548                        -1.885585   \n",
       "4                   -0.093319                        -1.852679   \n",
       "..                        ...                              ...   \n",
       "157                 -1.470096                         1.047494   \n",
       "158                 -1.464204                         1.056372   \n",
       "159                 -1.458311                         1.065250   \n",
       "160                 -1.452419                         1.074128   \n",
       "161                 -1.446526                         1.083006   \n",
       "\n",
       "     Amapá - Desemprego  \n",
       "0             -0.890357  \n",
       "1             -0.891922  \n",
       "2             -0.893486  \n",
       "3             -0.895051  \n",
       "4             -0.896616  \n",
       "..                  ...  \n",
       "157            1.300799  \n",
       "158            1.292722  \n",
       "159            1.284645  \n",
       "160            1.276568  \n",
       "161            1.268492  \n",
       "\n",
       "[162 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      10.000\n",
       "1       6.136\n",
       "2       5.122\n",
       "3       3.926\n",
       "4       6.197\n",
       "        ...  \n",
       "157     8.322\n",
       "158    11.373\n",
       "159     9.651\n",
       "160    10.855\n",
       "161    13.970\n",
       "Name: Amapá - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Amapá - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Amapá - PIB - Estadual</th>\n",
       "      <th>Amapá - PIB - Construção Civil</th>\n",
       "      <th>Amapá - PIB - Per Capita</th>\n",
       "      <th>Amapá - PIB - Preços de Mercado</th>\n",
       "      <th>Amapá - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.144841</td>\n",
       "      <td>1.104200</td>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>1.205903</td>\n",
       "      <td>-1.602434</td>\n",
       "      <td>-1.440634</td>\n",
       "      <td>1.091884</td>\n",
       "      <td>1.260415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.434524</td>\n",
       "      <td>1.047242</td>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>1.211243</td>\n",
       "      <td>-1.631515</td>\n",
       "      <td>-1.434741</td>\n",
       "      <td>1.100762</td>\n",
       "      <td>1.252338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.724207</td>\n",
       "      <td>0.990283</td>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>1.216584</td>\n",
       "      <td>-1.660596</td>\n",
       "      <td>-1.428849</td>\n",
       "      <td>1.109639</td>\n",
       "      <td>1.244261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.013890</td>\n",
       "      <td>0.933324</td>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>1.221925</td>\n",
       "      <td>-1.689677</td>\n",
       "      <td>-1.422956</td>\n",
       "      <td>1.118517</td>\n",
       "      <td>1.236184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.303572</td>\n",
       "      <td>0.876365</td>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>1.227266</td>\n",
       "      <td>-1.718758</td>\n",
       "      <td>-1.417063</td>\n",
       "      <td>1.127395</td>\n",
       "      <td>1.228107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.593255</td>\n",
       "      <td>0.819406</td>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>1.232606</td>\n",
       "      <td>-1.747839</td>\n",
       "      <td>-1.411171</td>\n",
       "      <td>1.136273</td>\n",
       "      <td>1.220031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-1.593255</td>\n",
       "      <td>0.762447</td>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>1.237947</td>\n",
       "      <td>-1.776921</td>\n",
       "      <td>-1.405278</td>\n",
       "      <td>1.145151</td>\n",
       "      <td>1.211954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-1.303572</td>\n",
       "      <td>0.704491</td>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>1.236412</td>\n",
       "      <td>-1.768257</td>\n",
       "      <td>-1.411038</td>\n",
       "      <td>1.142798</td>\n",
       "      <td>1.205535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-1.013890</td>\n",
       "      <td>0.646535</td>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>1.234876</td>\n",
       "      <td>-1.759592</td>\n",
       "      <td>-1.416798</td>\n",
       "      <td>1.140444</td>\n",
       "      <td>1.199117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-0.724207</td>\n",
       "      <td>0.588578</td>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>1.233341</td>\n",
       "      <td>-1.750928</td>\n",
       "      <td>-1.422558</td>\n",
       "      <td>1.138091</td>\n",
       "      <td>1.192699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>0.530622</td>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>1.231805</td>\n",
       "      <td>-1.742264</td>\n",
       "      <td>-1.428318</td>\n",
       "      <td>1.135737</td>\n",
       "      <td>1.186281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-0.144841</td>\n",
       "      <td>0.472665</td>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>1.230270</td>\n",
       "      <td>-1.733600</td>\n",
       "      <td>-1.434077</td>\n",
       "      <td>1.133384</td>\n",
       "      <td>1.179863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.144841</td>\n",
       "      <td>0.414709</td>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>1.228735</td>\n",
       "      <td>-1.724936</td>\n",
       "      <td>-1.439837</td>\n",
       "      <td>1.131030</td>\n",
       "      <td>1.173444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.434524</td>\n",
       "      <td>0.356752</td>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>1.227199</td>\n",
       "      <td>-1.716272</td>\n",
       "      <td>-1.445597</td>\n",
       "      <td>1.128677</td>\n",
       "      <td>1.167026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.724207</td>\n",
       "      <td>0.298796</td>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>1.225664</td>\n",
       "      <td>-1.707608</td>\n",
       "      <td>-1.451357</td>\n",
       "      <td>1.126323</td>\n",
       "      <td>1.160608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.013890</td>\n",
       "      <td>0.240839</td>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>1.224128</td>\n",
       "      <td>-1.698944</td>\n",
       "      <td>-1.457117</td>\n",
       "      <td>1.123970</td>\n",
       "      <td>1.154190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.303572</td>\n",
       "      <td>0.182883</td>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>1.222593</td>\n",
       "      <td>-1.690280</td>\n",
       "      <td>-1.462876</td>\n",
       "      <td>1.121616</td>\n",
       "      <td>1.147771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.593255</td>\n",
       "      <td>0.124926</td>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>1.221057</td>\n",
       "      <td>-1.681616</td>\n",
       "      <td>-1.468636</td>\n",
       "      <td>1.119263</td>\n",
       "      <td>1.141353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-1.593255</td>\n",
       "      <td>0.066970</td>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>1.219522</td>\n",
       "      <td>-1.672952</td>\n",
       "      <td>-1.474396</td>\n",
       "      <td>1.116909</td>\n",
       "      <td>1.134935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-1.303572</td>\n",
       "      <td>-0.033879</td>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>1.209008</td>\n",
       "      <td>-1.664537</td>\n",
       "      <td>-1.487559</td>\n",
       "      <td>1.101707</td>\n",
       "      <td>1.127913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-1.013890</td>\n",
       "      <td>-0.134728</td>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>1.198494</td>\n",
       "      <td>-1.656121</td>\n",
       "      <td>-1.500721</td>\n",
       "      <td>1.086506</td>\n",
       "      <td>1.120892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-0.724207</td>\n",
       "      <td>-0.235577</td>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>1.187980</td>\n",
       "      <td>-1.647706</td>\n",
       "      <td>-1.513884</td>\n",
       "      <td>1.071304</td>\n",
       "      <td>1.113871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>-0.336426</td>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>1.177466</td>\n",
       "      <td>-1.639290</td>\n",
       "      <td>-1.527046</td>\n",
       "      <td>1.056102</td>\n",
       "      <td>1.106849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-0.144841</td>\n",
       "      <td>-0.437275</td>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>1.166953</td>\n",
       "      <td>-1.630875</td>\n",
       "      <td>-1.540209</td>\n",
       "      <td>1.040900</td>\n",
       "      <td>1.099828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.144841</td>\n",
       "      <td>-0.538125</td>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>1.156439</td>\n",
       "      <td>-1.622459</td>\n",
       "      <td>-1.553372</td>\n",
       "      <td>1.025698</td>\n",
       "      <td>1.092806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.434524</td>\n",
       "      <td>-0.638974</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.145925</td>\n",
       "      <td>-1.614044</td>\n",
       "      <td>-1.566534</td>\n",
       "      <td>1.010496</td>\n",
       "      <td>1.085785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.724207</td>\n",
       "      <td>-0.739823</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.135411</td>\n",
       "      <td>-1.605628</td>\n",
       "      <td>-1.579697</td>\n",
       "      <td>0.995294</td>\n",
       "      <td>1.078764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.013890</td>\n",
       "      <td>-0.840672</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.124897</td>\n",
       "      <td>-1.597213</td>\n",
       "      <td>-1.592859</td>\n",
       "      <td>0.980093</td>\n",
       "      <td>1.071742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.303572</td>\n",
       "      <td>-0.941521</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.114383</td>\n",
       "      <td>-1.588797</td>\n",
       "      <td>-1.606022</td>\n",
       "      <td>0.964891</td>\n",
       "      <td>1.064721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.593255</td>\n",
       "      <td>-1.042370</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.103869</td>\n",
       "      <td>-1.580382</td>\n",
       "      <td>-1.619185</td>\n",
       "      <td>0.949689</td>\n",
       "      <td>1.057699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Amapá - IDH  \\\n",
       "162    0.144841     1.104200   \n",
       "163    0.434524     1.047242   \n",
       "164    0.724207     0.990283   \n",
       "165    1.013890     0.933324   \n",
       "166    1.303572     0.876365   \n",
       "167    1.593255     0.819406   \n",
       "168   -1.593255     0.762447   \n",
       "169   -1.303572     0.704491   \n",
       "170   -1.013890     0.646535   \n",
       "171   -0.724207     0.588578   \n",
       "172   -0.434524     0.530622   \n",
       "173   -0.144841     0.472665   \n",
       "174    0.144841     0.414709   \n",
       "175    0.434524     0.356752   \n",
       "176    0.724207     0.298796   \n",
       "177    1.013890     0.240839   \n",
       "178    1.303572     0.182883   \n",
       "179    1.593255     0.124926   \n",
       "180   -1.593255     0.066970   \n",
       "181   -1.303572    -0.033879   \n",
       "182   -1.013890    -0.134728   \n",
       "183   -0.724207    -0.235577   \n",
       "184   -0.434524    -0.336426   \n",
       "185   -0.144841    -0.437275   \n",
       "186    0.144841    -0.538125   \n",
       "187    0.434524    -0.638974   \n",
       "188    0.724207    -0.739823   \n",
       "189    1.013890    -0.840672   \n",
       "190    1.303572    -0.941521   \n",
       "191    1.593255    -1.042370   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162                                         -0.601510   \n",
       "163                                         -0.786068   \n",
       "164                                         -0.830387   \n",
       "165                                         -0.801089   \n",
       "166                                         -0.959917   \n",
       "167                                         -1.022309   \n",
       "168                                         -1.074401   \n",
       "169                                         -1.119597   \n",
       "170                                         -1.078648   \n",
       "171                                         -1.055426   \n",
       "172                                         -1.101053   \n",
       "173                                         -1.211370   \n",
       "174                                         -1.157198   \n",
       "175                                         -1.223444   \n",
       "176                                         -1.311519   \n",
       "177                                         -1.362602   \n",
       "178                                         -1.380125   \n",
       "179                                         -1.219296   \n",
       "180                                         -1.300284   \n",
       "181                                         -1.336476   \n",
       "182                                         -1.415774   \n",
       "183                                         -1.526021   \n",
       "184                                         -1.681806   \n",
       "185                                         -1.735167   \n",
       "186                                         -1.962315   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "162                                0.763466  -1.213929   \n",
       "163                                0.752299  -1.292173   \n",
       "164                                0.741131  -1.324219   \n",
       "165                                0.729964  -1.344446   \n",
       "166                                0.718796  -1.381638   \n",
       "167                                0.707629  -1.411208   \n",
       "168                                0.696461  -1.412953   \n",
       "169                                0.681823  -1.491464   \n",
       "170                                0.667184  -1.573805   \n",
       "171                                0.652545  -1.564950   \n",
       "172                                0.637906  -1.581584   \n",
       "173                                0.623268  -1.565976   \n",
       "174                                0.608629  -1.648556   \n",
       "175                                0.593990  -1.650049   \n",
       "176                                0.579351  -1.653957   \n",
       "177                                0.564713  -1.652572   \n",
       "178                                0.550074  -1.715349   \n",
       "179                                0.535435  -1.750917   \n",
       "180                                0.520796  -1.718448   \n",
       "181                                0.501996  -1.733426   \n",
       "182                                0.483195  -1.729362   \n",
       "183                                0.464395  -1.748544   \n",
       "184                                0.445594  -1.778060   \n",
       "185                                0.426794  -1.773710   \n",
       "186                                0.407993  -1.757007   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Amapá - PIB - Estadual  Amapá - PIB - Construção Civil  \\\n",
       "162                1.205903                       -1.602434   \n",
       "163                1.211243                       -1.631515   \n",
       "164                1.216584                       -1.660596   \n",
       "165                1.221925                       -1.689677   \n",
       "166                1.227266                       -1.718758   \n",
       "167                1.232606                       -1.747839   \n",
       "168                1.237947                       -1.776921   \n",
       "169                1.236412                       -1.768257   \n",
       "170                1.234876                       -1.759592   \n",
       "171                1.233341                       -1.750928   \n",
       "172                1.231805                       -1.742264   \n",
       "173                1.230270                       -1.733600   \n",
       "174                1.228735                       -1.724936   \n",
       "175                1.227199                       -1.716272   \n",
       "176                1.225664                       -1.707608   \n",
       "177                1.224128                       -1.698944   \n",
       "178                1.222593                       -1.690280   \n",
       "179                1.221057                       -1.681616   \n",
       "180                1.219522                       -1.672952   \n",
       "181                1.209008                       -1.664537   \n",
       "182                1.198494                       -1.656121   \n",
       "183                1.187980                       -1.647706   \n",
       "184                1.177466                       -1.639290   \n",
       "185                1.166953                       -1.630875   \n",
       "186                1.156439                       -1.622459   \n",
       "187                1.145925                       -1.614044   \n",
       "188                1.135411                       -1.605628   \n",
       "189                1.124897                       -1.597213   \n",
       "190                1.114383                       -1.588797   \n",
       "191                1.103869                       -1.580382   \n",
       "\n",
       "     Amapá - PIB - Per Capita  Amapá - PIB - Preços de Mercado  \\\n",
       "162                 -1.440634                         1.091884   \n",
       "163                 -1.434741                         1.100762   \n",
       "164                 -1.428849                         1.109639   \n",
       "165                 -1.422956                         1.118517   \n",
       "166                 -1.417063                         1.127395   \n",
       "167                 -1.411171                         1.136273   \n",
       "168                 -1.405278                         1.145151   \n",
       "169                 -1.411038                         1.142798   \n",
       "170                 -1.416798                         1.140444   \n",
       "171                 -1.422558                         1.138091   \n",
       "172                 -1.428318                         1.135737   \n",
       "173                 -1.434077                         1.133384   \n",
       "174                 -1.439837                         1.131030   \n",
       "175                 -1.445597                         1.128677   \n",
       "176                 -1.451357                         1.126323   \n",
       "177                 -1.457117                         1.123970   \n",
       "178                 -1.462876                         1.121616   \n",
       "179                 -1.468636                         1.119263   \n",
       "180                 -1.474396                         1.116909   \n",
       "181                 -1.487559                         1.101707   \n",
       "182                 -1.500721                         1.086506   \n",
       "183                 -1.513884                         1.071304   \n",
       "184                 -1.527046                         1.056102   \n",
       "185                 -1.540209                         1.040900   \n",
       "186                 -1.553372                         1.025698   \n",
       "187                 -1.566534                         1.010496   \n",
       "188                 -1.579697                         0.995294   \n",
       "189                 -1.592859                         0.980093   \n",
       "190                 -1.606022                         0.964891   \n",
       "191                 -1.619185                         0.949689   \n",
       "\n",
       "     Amapá - Desemprego  \n",
       "162            1.260415  \n",
       "163            1.252338  \n",
       "164            1.244261  \n",
       "165            1.236184  \n",
       "166            1.228107  \n",
       "167            1.220031  \n",
       "168            1.211954  \n",
       "169            1.205535  \n",
       "170            1.199117  \n",
       "171            1.192699  \n",
       "172            1.186281  \n",
       "173            1.179863  \n",
       "174            1.173444  \n",
       "175            1.167026  \n",
       "176            1.160608  \n",
       "177            1.154190  \n",
       "178            1.147771  \n",
       "179            1.141353  \n",
       "180            1.134935  \n",
       "181            1.127913  \n",
       "182            1.120892  \n",
       "183            1.113871  \n",
       "184            1.106849  \n",
       "185            1.099828  \n",
       "186            1.092806  \n",
       "187            1.085785  \n",
       "188            1.078764  \n",
       "189            1.071742  \n",
       "190            1.064721  \n",
       "191            1.057699  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    12.399\n",
       "163    11.268\n",
       "164     8.741\n",
       "165    12.358\n",
       "166    11.876\n",
       "167    11.713\n",
       "168    11.449\n",
       "169     7.805\n",
       "170     7.726\n",
       "171     8.516\n",
       "172     8.503\n",
       "173    10.175\n",
       "174    11.775\n",
       "175     9.724\n",
       "176    10.069\n",
       "177    13.930\n",
       "178    11.918\n",
       "179    11.757\n",
       "180     9.691\n",
       "181     7.378\n",
       "182     6.970\n",
       "183     7.612\n",
       "184     8.442\n",
       "185     8.835\n",
       "186    11.251\n",
       "187    11.342\n",
       "188    13.110\n",
       "189    13.195\n",
       "190    10.053\n",
       "191    12.274\n",
       "Name: Amapá - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "#     train, train_val = validation_splitter(train_input, 5)\n",
    "#     target,target_val = validation_splitter(train_target, 5)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train_input, \n",
    "                        train_target, \n",
    "                        epochs=10000,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3218670190, 1437645356, 2303635714, 1251381389, 3940570480, 789749933, 1755794941, 3063943631, 3671747053, 2798696150, 2397337414, 1851280778, 2696736403, 2651770250, 1717574788, 250892912, 1120617525, 3905137210, 4057865595, 2380847272, 2968047306, 2329841915, 4284486938, 3330446455, 3980462693]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 4.552715301513672\n",
      "winner_seed: 3218670190\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 3.2802815437316895\n",
      "winner_seed: 1437645356\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 17.710159301757812\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 3.8951847553253174\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 4.236536979675293\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 3.340890407562256\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 51.453147888183594\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 3.1624526977539062\n",
      "winner_seed: 3063943631\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 5.07053279876709\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 30.54457664489746\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 8.62646484375\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 7.047788619995117\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 31.68213653564453\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 3.100656270980835\n",
      "winner_seed: 2651770250\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 4.373219966888428\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 9.6895751953125\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 35.07236862182617\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 5.834659099578857\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 5.99495267868042\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 14.664474487304688\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 6.300962448120117\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 7.733717918395996\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 14.947378158569336\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 7.549945831298828\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 7.947845458984375\n",
      "\n",
      "\n",
      "final_seed: 2651770250\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 1s 25ms/step - loss: 102.0666 - val_loss: 877.5972\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.2633 - val_loss: 112.0770\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.9159 - val_loss: 161.5453\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.2686 - val_loss: 126.7643\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 14.6316 - val_loss: 91.2276\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.1372 - val_loss: 93.0454\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.9218 - val_loss: 97.8099\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.1933 - val_loss: 141.8658\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10.5047 - val_loss: 147.7420\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.6961 - val_loss: 151.9891\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 9.3218 - val_loss: 172.6082\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.1611 - val_loss: 195.0596\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.8545 - val_loss: 164.2744\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.5859 - val_loss: 139.6984\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2696 - val_loss: 173.2224\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.5845 - val_loss: 155.2943\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.0948 - val_loss: 221.3263\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 10.2417 - val_loss: 170.2337\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.5507 - val_loss: 132.3908\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.3744 - val_loss: 134.6959\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.9838 - val_loss: 149.6223\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.8539 - val_loss: 151.5595\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.9250 - val_loss: 190.2205\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.8538 - val_loss: 172.2733\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.3659 - val_loss: 165.2462\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.9324 - val_loss: 168.0192\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.7363 - val_loss: 169.2871\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.3905 - val_loss: 136.9123\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2674 - val_loss: 148.2583\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7.5170 - val_loss: 94.2846\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.0522 - val_loss: 130.4012\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.0449 - val_loss: 143.6360\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2814 - val_loss: 131.6923\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.4478 - val_loss: 179.7889\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.3587 - val_loss: 114.1749\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.6123 - val_loss: 135.9766\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7.4255 - val_loss: 148.9736\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2446 - val_loss: 129.9198\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2278 - val_loss: 140.4154\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.5691 - val_loss: 89.6027\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.1167 - val_loss: 127.5384\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2072 - val_loss: 120.4231\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.7018 - val_loss: 130.4918\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.6906 - val_loss: 116.2408\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.5338 - val_loss: 153.4914\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.4419 - val_loss: 118.6022\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.6969 - val_loss: 109.2871\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.4499 - val_loss: 143.2760\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7.4967 - val_loss: 120.5114\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.9017 - val_loss: 158.0503\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.3553 - val_loss: 132.0299\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.9977 - val_loss: 155.1265\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.5671 - val_loss: 156.5225\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.3014 - val_loss: 132.2662\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.0418 - val_loss: 126.9758\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2350 - val_loss: 123.1415\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.6019 - val_loss: 125.6989\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.6583 - val_loss: 189.0856\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.3320 - val_loss: 144.1282\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2374 - val_loss: 104.0666\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.6732 - val_loss: 107.1380\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.9318 - val_loss: 140.0073\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.1219 - val_loss: 142.9047\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.2519 - val_loss: 117.1372\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2558 - val_loss: 122.6446\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.1091 - val_loss: 149.8428\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.4619 - val_loss: 115.1058\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.8210 - val_loss: 147.4766\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.5770 - val_loss: 150.9502\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2183 - val_loss: 163.1073\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.7191 - val_loss: 122.0103\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.9921 - val_loss: 104.0730\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.9410 - val_loss: 114.6919\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.0095 - val_loss: 110.5381\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.6194 - val_loss: 142.8499\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.0843 - val_loss: 120.4043\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.8908 - val_loss: 102.5563\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.0869 - val_loss: 127.6815\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.3084 - val_loss: 74.1501\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.3036 - val_loss: 136.8528\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2272 - val_loss: 100.0133\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.4100 - val_loss: 132.5376\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.4371 - val_loss: 161.9385\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.9396 - val_loss: 139.3545\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2952 - val_loss: 124.5125\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.8893 - val_loss: 92.6514\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.4939 - val_loss: 142.4696\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.3901 - val_loss: 60.0975\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.8614 - val_loss: 107.0029\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.1476 - val_loss: 117.3953\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.1818 - val_loss: 87.1069\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.5158 - val_loss: 92.7913\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.4105 - val_loss: 90.0123\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2453 - val_loss: 123.6021\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0602 - val_loss: 106.5942\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.7759 - val_loss: 81.1488\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.6050 - val_loss: 81.3189\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9728 - val_loss: 135.1518\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.7468 - val_loss: 124.2641\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.7985 - val_loss: 144.1416\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.2919 - val_loss: 173.2952\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.9682 - val_loss: 117.4715\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.2795 - val_loss: 80.1068\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.5977 - val_loss: 100.7202\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.0215 - val_loss: 128.5072\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2022 - val_loss: 112.8502\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.1235 - val_loss: 89.7807\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.7473 - val_loss: 66.9387\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2925 - val_loss: 130.9800\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.0081 - val_loss: 116.8206\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0238 - val_loss: 167.9602\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.7429 - val_loss: 122.3009\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.9006 - val_loss: 95.1215\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.1626 - val_loss: 118.1126\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2163 - val_loss: 129.2522\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.1118 - val_loss: 103.0035\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.3110 - val_loss: 107.5588\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.8549 - val_loss: 129.7847\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.9654 - val_loss: 146.8742\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.8245 - val_loss: 97.6934\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0288 - val_loss: 116.2143\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.8100 - val_loss: 93.4581\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.3389 - val_loss: 114.2714\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6637 - val_loss: 96.0491\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5316 - val_loss: 100.0054\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.1088 - val_loss: 103.6729\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.8821 - val_loss: 107.0747\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.9992 - val_loss: 112.4823\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.3577 - val_loss: 98.6653\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.7137 - val_loss: 111.8714\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6719 - val_loss: 102.9030\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4223 - val_loss: 98.4569\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.9105 - val_loss: 89.4417\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.8036 - val_loss: 86.6812\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2344 - val_loss: 98.3051\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.1366 - val_loss: 101.4313\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.7992 - val_loss: 116.2050\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.7572 - val_loss: 72.1580\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6095 - val_loss: 77.3778\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2140 - val_loss: 76.6253\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.9474 - val_loss: 80.1558\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5078 - val_loss: 61.8558\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.6224 - val_loss: 80.3495\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6731 - val_loss: 103.7407\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5642 - val_loss: 53.4475\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5119 - val_loss: 76.0371\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5314 - val_loss: 56.7453\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.8180 - val_loss: 92.4857\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5851 - val_loss: 74.5574\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2549 - val_loss: 94.2992\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6767 - val_loss: 64.2315\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.8175 - val_loss: 97.4491\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1943 - val_loss: 93.1458\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5224 - val_loss: 68.6129\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2212 - val_loss: 50.5379\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4678 - val_loss: 81.0632\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6894 - val_loss: 77.3250\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.2997 - val_loss: 98.4279\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.9508 - val_loss: 55.4215\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3307 - val_loss: 80.2688\n",
      "Epoch 161/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 5.7157 - val_loss: 67.9485\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4192 - val_loss: 73.7561\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3152 - val_loss: 87.3635\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.8317 - val_loss: 50.0908\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2975 - val_loss: 61.3773\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0529 - val_loss: 59.6463\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3674 - val_loss: 57.4173\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3439 - val_loss: 81.0288\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0234 - val_loss: 65.6255\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2354 - val_loss: 39.4689\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2713 - val_loss: 79.4880\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0242 - val_loss: 72.3577\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3366 - val_loss: 82.9257\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2478 - val_loss: 73.9163\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3273 - val_loss: 68.4633\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.4796 - val_loss: 62.8001\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.1652 - val_loss: 62.4014\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2215 - val_loss: 51.1361\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4241 - val_loss: 60.1036\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2975 - val_loss: 71.4046\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2118 - val_loss: 34.7279\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2862 - val_loss: 61.1075\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4324 - val_loss: 41.1159\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7246 - val_loss: 39.9737\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0195 - val_loss: 51.7439\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5897 - val_loss: 71.4328\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0855 - val_loss: 35.3898\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3136 - val_loss: 64.2616\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.0846 - val_loss: 26.9708\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3324 - val_loss: 47.8962\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.2468 - val_loss: 56.3702\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2297 - val_loss: 52.7406\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.1805 - val_loss: 43.5394\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.6013 - val_loss: 49.1250\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1139 - val_loss: 43.4552\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2752 - val_loss: 53.1728\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8684 - val_loss: 65.7523\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2363 - val_loss: 45.5208\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5687 - val_loss: 25.3803\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8019 - val_loss: 34.5670\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7193 - val_loss: 46.4413\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9534 - val_loss: 29.9253\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9190 - val_loss: 43.6120\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.6254 - val_loss: 52.5072\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4020 - val_loss: 31.5535\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4573 - val_loss: 44.4624\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9598 - val_loss: 28.8285\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.4997 - val_loss: 39.9019\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2596 - val_loss: 30.2133\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8095 - val_loss: 20.2728\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0416 - val_loss: 42.6202\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2406 - val_loss: 46.4651\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9430 - val_loss: 27.4869\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1042 - val_loss: 19.5685\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2374 - val_loss: 38.7037\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3959 - val_loss: 17.7416\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9571 - val_loss: 13.7859\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7320 - val_loss: 29.6393\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2655 - val_loss: 20.0503\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9882 - val_loss: 12.3517\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8614 - val_loss: 22.3940\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0603 - val_loss: 33.8546\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4278 - val_loss: 22.1000\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.7126 - val_loss: 26.5549\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9181 - val_loss: 27.7427\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.7616 - val_loss: 24.0016\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7956 - val_loss: 20.9010\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8232 - val_loss: 21.4301\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1668 - val_loss: 16.7257\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7235 - val_loss: 19.6600\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7069 - val_loss: 13.2049\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1435 - val_loss: 20.7377\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0652 - val_loss: 10.6078\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7468 - val_loss: 20.5905\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9945 - val_loss: 10.0462\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6538 - val_loss: 13.6432\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7760 - val_loss: 9.5440\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9532 - val_loss: 10.0585\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1357 - val_loss: 9.3717\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2428 - val_loss: 17.1096\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1569 - val_loss: 19.0595\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6562 - val_loss: 13.4995\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4576 - val_loss: 18.4932\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7485 - val_loss: 8.0058\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6780 - val_loss: 14.4294\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6448 - val_loss: 12.0090\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1430 - val_loss: 7.6100\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2018 - val_loss: 6.3359\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5868 - val_loss: 8.5755\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8470 - val_loss: 6.5913\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2736 - val_loss: 4.8736\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3975 - val_loss: 8.9121\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.4968 - val_loss: 15.7989\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3402 - val_loss: 5.0146\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5416 - val_loss: 5.1296\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1702 - val_loss: 5.8168\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5694 - val_loss: 4.9636\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6197 - val_loss: 5.1320\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5548 - val_loss: 6.1287\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7580 - val_loss: 7.2182\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9052 - val_loss: 4.8212\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5543 - val_loss: 4.6190\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4593 - val_loss: 4.5356\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6244 - val_loss: 4.0956\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3018 - val_loss: 5.6789\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1517 - val_loss: 5.5338\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0438 - val_loss: 5.6187\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.4370 - val_loss: 5.3797\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8038 - val_loss: 6.2675\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7768 - val_loss: 5.3396\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2829 - val_loss: 5.4277\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0327 - val_loss: 10.0327\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8348 - val_loss: 7.3495\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3958 - val_loss: 5.4065\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3742 - val_loss: 5.6945\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1938 - val_loss: 5.2091\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8350 - val_loss: 3.7458\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1170 - val_loss: 6.6274\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6626 - val_loss: 8.9118\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.4494 - val_loss: 5.0781\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6195 - val_loss: 6.4628\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5517 - val_loss: 7.7322\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.3789 - val_loss: 4.0438\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3872 - val_loss: 5.3965\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1900 - val_loss: 4.2185\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9220 - val_loss: 6.0932\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3355 - val_loss: 6.2655\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3279 - val_loss: 5.9707\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2258 - val_loss: 4.6099\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2923 - val_loss: 4.1544\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1430 - val_loss: 7.3027\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8532 - val_loss: 5.1467\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2363 - val_loss: 6.7497\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7646 - val_loss: 4.6151\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5896 - val_loss: 3.6059\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1131 - val_loss: 5.6222\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3842 - val_loss: 6.5211\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3395 - val_loss: 5.1221\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9507 - val_loss: 4.6550\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9341 - val_loss: 4.3660\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0860 - val_loss: 4.3248\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0501 - val_loss: 3.6686\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1782 - val_loss: 5.2842\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1788 - val_loss: 6.5172\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3812 - val_loss: 5.6711\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2222 - val_loss: 4.7380\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9194 - val_loss: 5.5770\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8090 - val_loss: 4.4989\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9105 - val_loss: 5.1240\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9596 - val_loss: 4.8745\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9411 - val_loss: 5.1503\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2375 - val_loss: 4.1969\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4542 - val_loss: 3.9510\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3910 - val_loss: 6.2005\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.0187 - val_loss: 4.8299\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.3272 - val_loss: 8.2420\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.8920 - val_loss: 6.8537\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.3618 - val_loss: 4.5801\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.2246 - val_loss: 5.2558\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6480 - val_loss: 5.8449\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7654 - val_loss: 4.2155\n",
      "Epoch 322/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 4.0372 - val_loss: 4.7153\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5868 - val_loss: 4.5411\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7357 - val_loss: 4.7760\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6474 - val_loss: 9.0031\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0258 - val_loss: 5.0046\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1501 - val_loss: 5.5459\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5190 - val_loss: 5.0495\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5626 - val_loss: 3.7257\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5614 - val_loss: 5.4574\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7062 - val_loss: 3.7255\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7308 - val_loss: 4.1460\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8175 - val_loss: 5.1136\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3125 - val_loss: 3.8056\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.4853 - val_loss: 5.5221\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3856 - val_loss: 4.8062\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4241 - val_loss: 5.9067\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8976 - val_loss: 5.1731\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3216 - val_loss: 5.2857\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5654 - val_loss: 3.7892\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.0711 - val_loss: 4.3368\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4429 - val_loss: 4.6419\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.5780 - val_loss: 4.4423\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1812 - val_loss: 4.4260\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.3226 - val_loss: 4.3866\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7117 - val_loss: 5.6370\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2245 - val_loss: 7.3558\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7078 - val_loss: 5.0573\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7923 - val_loss: 4.2823\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5418 - val_loss: 4.7219\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.9396 - val_loss: 4.4453\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.4926 - val_loss: 5.1764\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5980 - val_loss: 4.7642\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3734 - val_loss: 4.6038\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7645 - val_loss: 4.2689\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4692 - val_loss: 4.3347\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.1908 - val_loss: 4.9706\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4849 - val_loss: 6.7305\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8816 - val_loss: 4.8546\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5688 - val_loss: 4.7886\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0213 - val_loss: 4.7554\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2275 - val_loss: 5.5951\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4453 - val_loss: 4.4964\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2147 - val_loss: 4.8093\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9748 - val_loss: 6.4718\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8162 - val_loss: 4.6203\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2541 - val_loss: 5.2196\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7199 - val_loss: 4.4455\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8524 - val_loss: 5.3808\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7361 - val_loss: 4.5129\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0610 - val_loss: 5.5348\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5499 - val_loss: 4.8074\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6509 - val_loss: 4.6903\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4184 - val_loss: 5.5652\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.5849 - val_loss: 5.7202\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0894 - val_loss: 5.5133\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2125 - val_loss: 5.7700\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1589 - val_loss: 4.5538\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2466 - val_loss: 5.3886\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6490 - val_loss: 4.3724\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2484 - val_loss: 4.3063\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5556 - val_loss: 4.7808\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3595 - val_loss: 5.1416\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2991 - val_loss: 5.2934\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8772 - val_loss: 4.9403\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9132 - val_loss: 5.1131\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3006 - val_loss: 5.4407\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2524 - val_loss: 5.4133\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1896 - val_loss: 4.0925\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1048 - val_loss: 5.3648\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0446 - val_loss: 5.3244\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4641 - val_loss: 7.0780\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6942 - val_loss: 4.3228\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0126 - val_loss: 6.7349\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3478 - val_loss: 4.5073\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7907 - val_loss: 4.6646\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1294 - val_loss: 4.2973\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4251 - val_loss: 5.8555\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7469 - val_loss: 5.6058\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3681 - val_loss: 5.3507\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3130 - val_loss: 4.5352\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8287 - val_loss: 6.3017\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0327 - val_loss: 5.1136\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2408 - val_loss: 4.9048\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1066 - val_loss: 6.8576\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.5358 - val_loss: 8.7097\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.6649 - val_loss: 5.8300\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1917 - val_loss: 4.2194\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7248 - val_loss: 10.7072\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2264 - val_loss: 6.3369\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.0598 - val_loss: 4.9206\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9121 - val_loss: 5.7124\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.2505 - val_loss: 5.0620\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3538 - val_loss: 6.0663\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9351 - val_loss: 6.5504\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0493 - val_loss: 6.6269\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3007 - val_loss: 12.0065\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9994 - val_loss: 7.3262\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0986 - val_loss: 6.5901\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9573 - val_loss: 8.3980\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1506 - val_loss: 6.9832\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0531 - val_loss: 6.2693\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5197 - val_loss: 5.4212\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9147 - val_loss: 5.5526\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7942 - val_loss: 5.5408\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2923 - val_loss: 6.5343\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0247 - val_loss: 5.1032\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.0884 - val_loss: 6.9647\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2925 - val_loss: 9.8649\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4501 - val_loss: 6.1304\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.2435 - val_loss: 8.9603\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4946 - val_loss: 7.4665\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7706 - val_loss: 5.8576\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9549 - val_loss: 6.0982\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1294 - val_loss: 7.8200\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6032 - val_loss: 7.0087\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6773 - val_loss: 7.1739\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9517 - val_loss: 5.5794\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0061 - val_loss: 9.5520\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9162 - val_loss: 5.7013\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0093 - val_loss: 5.9910\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9423 - val_loss: 6.9156\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8310 - val_loss: 7.2517\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0284 - val_loss: 7.0857\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.4849 - val_loss: 5.1528\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8086 - val_loss: 6.4991\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6653 - val_loss: 6.3063\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6875 - val_loss: 6.0890\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.1933 - val_loss: 6.8642\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4592 - val_loss: 5.0263\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0352 - val_loss: 9.1753\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1753 - val_loss: 5.6805\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0782 - val_loss: 8.4850\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2028 - val_loss: 6.0907\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0700 - val_loss: 6.8290\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6605 - val_loss: 8.0144\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6695 - val_loss: 4.9834\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9532 - val_loss: 6.4406\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5751 - val_loss: 6.2518\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5503 - val_loss: 7.4290\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7843 - val_loss: 6.6137\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7094 - val_loss: 5.9015\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4979 - val_loss: 6.9821\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3905 - val_loss: 4.9769\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8748 - val_loss: 6.1175\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8141 - val_loss: 6.3438\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0077 - val_loss: 7.3342\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4295 - val_loss: 5.8031\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7779 - val_loss: 4.9890\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8477 - val_loss: 7.6257\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6864 - val_loss: 8.6682\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8496 - val_loss: 8.2906\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1162 - val_loss: 5.4395\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2043 - val_loss: 7.0414\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9035 - val_loss: 7.7316\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6453 - val_loss: 4.1865\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9427 - val_loss: 11.7776\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7026 - val_loss: 7.4143\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5764 - val_loss: 6.2739\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3466 - val_loss: 7.4683\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6554 - val_loss: 6.4527\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4725 - val_loss: 8.2177\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5975 - val_loss: 9.0628\n",
      "Epoch 484/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9404 - val_loss: 6.1652\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.3066 - val_loss: 6.0419\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2736 - val_loss: 7.4122\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.7253 - val_loss: 7.9875\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.4965 - val_loss: 5.9132\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.4038 - val_loss: 8.1951\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3650 - val_loss: 9.6586\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4962 - val_loss: 9.2071\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6416 - val_loss: 7.1713\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1806 - val_loss: 8.8999\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2868 - val_loss: 7.0373\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.6137 - val_loss: 7.2892\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3634 - val_loss: 6.7390\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7938 - val_loss: 6.4768\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5970 - val_loss: 6.3174\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3104 - val_loss: 7.2022\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3743 - val_loss: 6.7334\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.5106 - val_loss: 6.7763\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2866 - val_loss: 10.5218\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.5681 - val_loss: 5.2742\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.7221 - val_loss: 4.5855\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3409 - val_loss: 6.3706\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2379 - val_loss: 8.8468\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1010 - val_loss: 6.6788\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3293 - val_loss: 6.3855\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2206 - val_loss: 8.2692\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0956 - val_loss: 9.4542\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9585 - val_loss: 6.1545\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3389 - val_loss: 4.9219\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.4144 - val_loss: 7.3629\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3499 - val_loss: 6.0331\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1564 - val_loss: 9.4555\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5035 - val_loss: 10.1580\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5430 - val_loss: 7.7002\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2908 - val_loss: 7.8413\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4650 - val_loss: 9.0538\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8946 - val_loss: 6.4735\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0596 - val_loss: 7.0810\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4452 - val_loss: 8.0216\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1836 - val_loss: 6.2626\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.4641 - val_loss: 8.0284\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2172 - val_loss: 8.6008\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.4141 - val_loss: 6.2916\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7602 - val_loss: 8.1584\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2749 - val_loss: 8.9275\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0523 - val_loss: 7.5048\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0094 - val_loss: 7.0502\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.6551 - val_loss: 9.3195\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.2927 - val_loss: 5.9972\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1853 - val_loss: 7.6015\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1316 - val_loss: 5.6296\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9346 - val_loss: 6.9854\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3280 - val_loss: 10.7737\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0972 - val_loss: 8.7629\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2776 - val_loss: 7.6703\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3736 - val_loss: 8.0264\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1076 - val_loss: 6.4213\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3009 - val_loss: 8.2101\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1178 - val_loss: 7.5397\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3129 - val_loss: 7.7776\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2378 - val_loss: 7.9064\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4575 - val_loss: 6.5073\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0450 - val_loss: 10.1473\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8310 - val_loss: 8.8776\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.7099 - val_loss: 9.4761\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.6135 - val_loss: 7.2435\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4029 - val_loss: 6.9725\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0038 - val_loss: 6.7930\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8141 - val_loss: 6.3886\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.4773 - val_loss: 9.2368\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1801 - val_loss: 7.9772\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8046 - val_loss: 7.6972\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4337 - val_loss: 8.3272\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0611 - val_loss: 8.3728\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0600 - val_loss: 7.4875\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9301 - val_loss: 7.5957\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2743 - val_loss: 6.2937\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0766 - val_loss: 7.9526\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8398 - val_loss: 7.1943\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8734 - val_loss: 7.7850\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4192 - val_loss: 6.6557\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3617 - val_loss: 6.3863\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4926 - val_loss: 7.1179\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8470 - val_loss: 9.2902\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9819 - val_loss: 7.9601\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3730 - val_loss: 6.4738\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8495 - val_loss: 4.6079\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1929 - val_loss: 8.8811\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2790 - val_loss: 5.8824\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9454 - val_loss: 7.1220\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1697 - val_loss: 8.4357\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7597 - val_loss: 6.8915\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8557 - val_loss: 5.3157\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9659 - val_loss: 8.7510\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0114 - val_loss: 6.4550\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1809 - val_loss: 6.2739\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9458 - val_loss: 7.7072\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0280 - val_loss: 6.6796\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.2295 - val_loss: 8.4757\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.8273 - val_loss: 3.8489\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8725 - val_loss: 4.9111\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0736 - val_loss: 5.5420\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2918 - val_loss: 6.5461\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6431 - val_loss: 8.3640\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8019 - val_loss: 5.2597\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7406 - val_loss: 5.5417\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8226 - val_loss: 7.5045\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8255 - val_loss: 5.0326\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6836 - val_loss: 5.8601\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7908 - val_loss: 6.2692\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8430 - val_loss: 6.4143\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7800 - val_loss: 6.5457\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1515 - val_loss: 9.6046\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9375 - val_loss: 7.9650\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7105 - val_loss: 6.4071\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0799 - val_loss: 7.2877\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4055 - val_loss: 5.6624\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8765 - val_loss: 5.8188\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5493 - val_loss: 5.3355\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8788 - val_loss: 7.6907\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1133 - val_loss: 4.4955\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9736 - val_loss: 5.3935\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9330 - val_loss: 5.1413\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0087 - val_loss: 4.0331\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0495 - val_loss: 5.3036\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6877 - val_loss: 6.8318\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.8431 - val_loss: 4.6376\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6683 - val_loss: 4.4843\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8739 - val_loss: 5.9301\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7312 - val_loss: 4.3161\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7519 - val_loss: 5.3091\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7476 - val_loss: 3.7050\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7681 - val_loss: 3.5193\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7891 - val_loss: 3.4058\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6514 - val_loss: 3.7668\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8626 - val_loss: 4.1408\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8641 - val_loss: 4.6157\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7773 - val_loss: 4.9397\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6521 - val_loss: 4.2599\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.7912 - val_loss: 6.3214\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6773 - val_loss: 3.5447\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5037 - val_loss: 4.4818\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9894 - val_loss: 4.1563\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0683 - val_loss: 5.7677\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4592 - val_loss: 4.5916\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6449 - val_loss: 5.1015\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8532 - val_loss: 5.2959\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5286 - val_loss: 3.5856\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6298 - val_loss: 4.1883\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9418 - val_loss: 4.7711\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5323 - val_loss: 4.6402\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7509 - val_loss: 4.1689\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4444 - val_loss: 3.7108\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6395 - val_loss: 3.8478\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7904 - val_loss: 5.6022\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6814 - val_loss: 5.1991\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6390 - val_loss: 4.8360\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4736 - val_loss: 4.3685\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4697 - val_loss: 5.3957\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5051 - val_loss: 5.0708\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5863 - val_loss: 3.9181\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6544 - val_loss: 5.3789\n",
      "Epoch 646/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2854 - val_loss: 4.7164\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.7402 - val_loss: 4.6348\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7487 - val_loss: 6.5318\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.7678 - val_loss: 6.8126\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7580 - val_loss: 5.9381\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5740 - val_loss: 4.7796\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0748 - val_loss: 5.0839\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5660 - val_loss: 6.0346\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4663 - val_loss: 6.5540\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5915 - val_loss: 4.4564\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5319 - val_loss: 4.5554\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4402 - val_loss: 5.0260\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4010 - val_loss: 4.5401\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4787 - val_loss: 7.5234\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6652 - val_loss: 4.8109\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4584 - val_loss: 4.5183\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2988 - val_loss: 6.0707\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3070 - val_loss: 5.5347\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3008 - val_loss: 5.2429\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3987 - val_loss: 5.3101\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6038 - val_loss: 4.9076\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4644 - val_loss: 5.9159\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6731 - val_loss: 5.4905\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1700 - val_loss: 5.6031\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3778 - val_loss: 5.2232\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4318 - val_loss: 4.1198\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4846 - val_loss: 5.0990\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4465 - val_loss: 6.6137\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5888 - val_loss: 5.7498\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5300 - val_loss: 4.9689\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5231 - val_loss: 5.2265\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5840 - val_loss: 6.3625\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4545 - val_loss: 4.9324\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3148 - val_loss: 8.4179\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6456 - val_loss: 6.9915\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2947 - val_loss: 5.5943\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5479 - val_loss: 4.9188\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4343 - val_loss: 5.2656\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4380 - val_loss: 5.6298\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4412 - val_loss: 4.9526\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3312 - val_loss: 4.6754\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1970 - val_loss: 6.9146\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0473 - val_loss: 4.9052\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3563 - val_loss: 5.9376\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4220 - val_loss: 5.6524\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2548 - val_loss: 6.3334\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6068 - val_loss: 6.0466\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2474 - val_loss: 8.8136\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3338 - val_loss: 6.4024\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6035 - val_loss: 6.4608\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3293 - val_loss: 6.1625\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2379 - val_loss: 4.5681\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5744 - val_loss: 4.9044\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4531 - val_loss: 6.0914\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3493 - val_loss: 3.5590\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3021 - val_loss: 3.8491\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4595 - val_loss: 5.9349\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3754 - val_loss: 3.3578\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4884 - val_loss: 5.0992\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2968 - val_loss: 4.1676\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3379 - val_loss: 4.0169\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5167 - val_loss: 4.2000\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2936 - val_loss: 4.1874\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2702 - val_loss: 7.3681\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3293 - val_loss: 4.5771\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3985 - val_loss: 4.7339\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2646 - val_loss: 4.1314\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4765 - val_loss: 4.9067\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2838 - val_loss: 6.1948\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3543 - val_loss: 3.7666\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1689 - val_loss: 5.8583\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0919 - val_loss: 4.2825\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4675 - val_loss: 4.2666\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3013 - val_loss: 3.6000\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2907 - val_loss: 4.5357\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2028 - val_loss: 4.7211\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1978 - val_loss: 5.6855\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3836 - val_loss: 7.0827\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3265 - val_loss: 4.6481\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2933 - val_loss: 6.6475\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2829 - val_loss: 4.8607\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3404 - val_loss: 4.7532\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5131 - val_loss: 4.2360\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2985 - val_loss: 6.3663\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3466 - val_loss: 5.5427\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3064 - val_loss: 5.2609\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.1329 - val_loss: 5.7722\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2886 - val_loss: 3.8504\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5593 - val_loss: 6.2974\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1201 - val_loss: 7.0793\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2804 - val_loss: 4.9582\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2389 - val_loss: 4.9669\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0376 - val_loss: 6.1524\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2719 - val_loss: 5.1951\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1023 - val_loss: 5.2917\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4093 - val_loss: 6.0972\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1515 - val_loss: 6.7432\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2268 - val_loss: 4.9309\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3764 - val_loss: 5.7119\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4530 - val_loss: 6.6577\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0046 - val_loss: 4.7631\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1988 - val_loss: 6.5666\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2252 - val_loss: 6.3789\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1199 - val_loss: 4.8719\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4131 - val_loss: 5.4317\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3569 - val_loss: 4.2255\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3145 - val_loss: 4.1744\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0794 - val_loss: 4.5808\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2356 - val_loss: 5.5723\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0073 - val_loss: 4.6774\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0572 - val_loss: 5.8839\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1182 - val_loss: 4.7842\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1853 - val_loss: 5.1024\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0535 - val_loss: 6.2075\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3277 - val_loss: 5.2379\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4415 - val_loss: 4.8306\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2357 - val_loss: 3.8724\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3510 - val_loss: 5.5534\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2946 - val_loss: 5.4538\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.3277 - val_loss: 6.4052\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2348 - val_loss: 4.4825\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0090 - val_loss: 6.0390\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0834 - val_loss: 4.7051\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2474 - val_loss: 6.0456\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9217 - val_loss: 4.9717\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0612 - val_loss: 5.3285\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0033 - val_loss: 4.6793\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1556 - val_loss: 4.4860\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3296 - val_loss: 5.4220\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3439 - val_loss: 3.9049\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0075 - val_loss: 4.7549\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0132 - val_loss: 4.7110\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0453 - val_loss: 5.4560\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0021 - val_loss: 3.2983\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1975 - val_loss: 4.5245\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2426 - val_loss: 4.7368\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.2376 - val_loss: 5.5219\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2276 - val_loss: 3.6813\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5007 - val_loss: 4.4111\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0143 - val_loss: 3.6368\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1299 - val_loss: 5.5395\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1744 - val_loss: 4.1723\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2304 - val_loss: 3.5655\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2775 - val_loss: 5.2378\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4098 - val_loss: 4.3530\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1670 - val_loss: 4.7423\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1828 - val_loss: 4.3007\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9103 - val_loss: 4.3010\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0075 - val_loss: 4.2965\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.2338 - val_loss: 3.5517\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2264 - val_loss: 4.9793\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4679 - val_loss: 3.7782\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1358 - val_loss: 4.8493\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1011 - val_loss: 3.9726\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0086 - val_loss: 4.1275\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1131 - val_loss: 4.0683\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0147 - val_loss: 4.3263\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.1711 - val_loss: 4.4795\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1643 - val_loss: 4.4371\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9878 - val_loss: 4.2365\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0462 - val_loss: 3.8001\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8980 - val_loss: 5.3747\n",
      "Epoch 808/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9184 - val_loss: 4.3564\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0054 - val_loss: 4.7861\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9119 - val_loss: 3.9291\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2374 - val_loss: 3.5838\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3786 - val_loss: 3.9273\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0852 - val_loss: 5.1257\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9111 - val_loss: 4.5025\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0242 - val_loss: 4.8258\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0235 - val_loss: 5.4702\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9867 - val_loss: 5.0523\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1170 - val_loss: 4.8412\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9330 - val_loss: 4.6481\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9021 - val_loss: 4.0938\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8153 - val_loss: 4.8669\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8681 - val_loss: 4.8030\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8839 - val_loss: 3.9196\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0624 - val_loss: 5.0008\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8985 - val_loss: 6.4180\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8434 - val_loss: 4.4674\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0619 - val_loss: 5.1779\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0054 - val_loss: 4.7742\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9113 - val_loss: 3.8724\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1929 - val_loss: 4.2169\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2159 - val_loss: 4.2195\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8504 - val_loss: 3.9533\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9463 - val_loss: 5.6034\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8898 - val_loss: 4.9694\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0067 - val_loss: 4.6690\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8855 - val_loss: 3.9154\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0737 - val_loss: 5.4375\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7679 - val_loss: 4.6029\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0470 - val_loss: 5.0496\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9915 - val_loss: 5.3060\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9822 - val_loss: 4.2588\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0701 - val_loss: 3.9620\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4096 - val_loss: 5.6631\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8641 - val_loss: 4.4549\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8192 - val_loss: 4.7663\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9846 - val_loss: 4.3476\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7868 - val_loss: 4.3531\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9324 - val_loss: 5.3492\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0541 - val_loss: 4.7318\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9119 - val_loss: 5.5981\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7168 - val_loss: 5.8302\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0064 - val_loss: 4.2300\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8796 - val_loss: 5.2487\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8260 - val_loss: 3.9942\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0512 - val_loss: 4.4559\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9715 - val_loss: 5.2313\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8632 - val_loss: 4.9379\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9081 - val_loss: 4.6352\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9982 - val_loss: 4.0066\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9754 - val_loss: 4.3658\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9068 - val_loss: 4.0397\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8961 - val_loss: 3.3963\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8899 - val_loss: 5.1952\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1295 - val_loss: 5.2674\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7559 - val_loss: 4.7646\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8459 - val_loss: 6.7111\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3041 - val_loss: 4.8927\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1964 - val_loss: 3.1007\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9277 - val_loss: 4.6273\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9127 - val_loss: 6.9654\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8579 - val_loss: 4.3778\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9210 - val_loss: 4.9898\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9022 - val_loss: 5.7862\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1021 - val_loss: 7.3580\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9250 - val_loss: 4.5741\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9720 - val_loss: 5.7278\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9033 - val_loss: 3.9792\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8494 - val_loss: 4.5378\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0508 - val_loss: 4.7517\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8484 - val_loss: 5.3798\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9509 - val_loss: 5.5216\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8430 - val_loss: 6.1247\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8831 - val_loss: 6.2032\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7106 - val_loss: 4.8817\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7613 - val_loss: 4.8048\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8333 - val_loss: 4.8479\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9542 - val_loss: 3.5581\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8688 - val_loss: 4.8422\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8903 - val_loss: 4.5960\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8266 - val_loss: 5.2908\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1329 - val_loss: 3.5232\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6171 - val_loss: 4.2882\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9136 - val_loss: 4.1548\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9640 - val_loss: 4.2711\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1022 - val_loss: 4.5355\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3382 - val_loss: 4.9743\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8746 - val_loss: 4.5345\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7525 - val_loss: 6.3334\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9617 - val_loss: 5.7307\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7695 - val_loss: 4.9421\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7454 - val_loss: 4.7884\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7619 - val_loss: 4.9660\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7585 - val_loss: 4.7307\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8293 - val_loss: 4.0484\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.1012 - val_loss: 5.1324\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8672 - val_loss: 3.9527\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8166 - val_loss: 3.5869\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7757 - val_loss: 4.1604\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7788 - val_loss: 6.1767\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8994 - val_loss: 4.7144\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6564 - val_loss: 6.7877\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6944 - val_loss: 5.5484\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9125 - val_loss: 4.4968\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8455 - val_loss: 4.8227\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0608 - val_loss: 5.1620\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8854 - val_loss: 5.5235\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8382 - val_loss: 5.6098\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7473 - val_loss: 4.6608\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8462 - val_loss: 6.1749\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9440 - val_loss: 5.0891\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7895 - val_loss: 4.9420\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8774 - val_loss: 4.4910\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9482 - val_loss: 4.8690\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8513 - val_loss: 5.9875\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9107 - val_loss: 5.6367\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8493 - val_loss: 4.4581\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7316 - val_loss: 3.8757\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7752 - val_loss: 4.8345\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7198 - val_loss: 5.1057\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7710 - val_loss: 4.9654\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8155 - val_loss: 4.6814\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7918 - val_loss: 5.4483\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8098 - val_loss: 4.8440\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7458 - val_loss: 4.6066\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9215 - val_loss: 4.1026\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8695 - val_loss: 4.4211\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8078 - val_loss: 4.9741\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2141 - val_loss: 4.3665\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7220 - val_loss: 4.8025\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8035 - val_loss: 5.4850\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9355 - val_loss: 4.3508\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7590 - val_loss: 4.5676\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6935 - val_loss: 3.9552\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6882 - val_loss: 4.9056\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7126 - val_loss: 5.5035\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8797 - val_loss: 5.9087\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6972 - val_loss: 4.8906\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9602 - val_loss: 5.9016\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7317 - val_loss: 4.5415\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8634 - val_loss: 5.3017\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8642 - val_loss: 4.9931\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6810 - val_loss: 5.5720\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7933 - val_loss: 5.4350\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6200 - val_loss: 5.6533\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6958 - val_loss: 4.9537\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8628 - val_loss: 4.6465\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6230 - val_loss: 5.1264\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8549 - val_loss: 5.8294\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6872 - val_loss: 4.9620\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8822 - val_loss: 6.0338\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7625 - val_loss: 5.7487\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7721 - val_loss: 5.3443\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7213 - val_loss: 4.2899\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8705 - val_loss: 4.9605\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7045 - val_loss: 4.7817\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7934 - val_loss: 4.1956\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8144 - val_loss: 4.6442\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7350 - val_loss: 5.1891\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7671 - val_loss: 4.3966\n",
      "Epoch 970/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7629 - val_loss: 4.9954\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7745 - val_loss: 4.5991\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6871 - val_loss: 4.6895\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6177 - val_loss: 5.1097\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8705 - val_loss: 5.2033\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9929 - val_loss: 5.0159\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7092 - val_loss: 5.9600\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6807 - val_loss: 4.4909\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7086 - val_loss: 6.3260\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6262 - val_loss: 4.9531\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8546 - val_loss: 4.6796\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8260 - val_loss: 3.8884\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2679 - val_loss: 4.5837\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8149 - val_loss: 4.3896\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7762 - val_loss: 5.0949\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7121 - val_loss: 4.8176\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7147 - val_loss: 4.9544\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6981 - val_loss: 4.5480\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0276 - val_loss: 4.8241\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6598 - val_loss: 4.8073\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6343 - val_loss: 4.5872\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7771 - val_loss: 4.2546\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8483 - val_loss: 7.1638\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7341 - val_loss: 5.3915\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7267 - val_loss: 4.0016\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7038 - val_loss: 3.7202\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7149 - val_loss: 6.0287\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6763 - val_loss: 5.0522\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6798 - val_loss: 4.3857\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7329 - val_loss: 4.9889\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7402 - val_loss: 5.6560\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8255 - val_loss: 5.2480\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6885 - val_loss: 5.6705\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9176 - val_loss: 5.6779\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7335 - val_loss: 5.4902\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7359 - val_loss: 4.6033\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7238 - val_loss: 5.6108\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8974 - val_loss: 5.2425\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7705 - val_loss: 6.5088\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6545 - val_loss: 6.7485\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8616 - val_loss: 4.5752\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7335 - val_loss: 6.8499\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6870 - val_loss: 6.5751\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6490 - val_loss: 6.3633\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7950 - val_loss: 5.9581\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8968 - val_loss: 5.1164\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7352 - val_loss: 5.0629\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6215 - val_loss: 6.0060\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8016 - val_loss: 5.7472\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6223 - val_loss: 5.0576\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6221 - val_loss: 5.6493\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5834 - val_loss: 6.9822\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7003 - val_loss: 5.2239\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8317 - val_loss: 6.5177\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7641 - val_loss: 5.9913\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6129 - val_loss: 5.6117\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7191 - val_loss: 5.4682\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7041 - val_loss: 6.0914\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6163 - val_loss: 5.6255\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5508 - val_loss: 4.7670\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6329 - val_loss: 5.7901\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6969 - val_loss: 5.6959\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6281 - val_loss: 5.1415\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7322 - val_loss: 5.0912\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7631 - val_loss: 5.2401\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5696 - val_loss: 5.1671\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6816 - val_loss: 5.9809\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7330 - val_loss: 5.0996\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6325 - val_loss: 4.6041\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6893 - val_loss: 5.4665\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5820 - val_loss: 5.3212\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5612 - val_loss: 5.6338\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8309 - val_loss: 6.5191\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8538 - val_loss: 6.6355\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8752 - val_loss: 5.4741\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6404 - val_loss: 6.4104\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6429 - val_loss: 5.3102\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6498 - val_loss: 6.9320\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5883 - val_loss: 5.1276\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5281 - val_loss: 5.2586\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6607 - val_loss: 6.0532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6961 - val_loss: 5.8216\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7267 - val_loss: 8.0474\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6331 - val_loss: 5.9910\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7004 - val_loss: 6.2604\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8152 - val_loss: 5.1709\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5678 - val_loss: 6.1682\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7975 - val_loss: 4.7512\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6875 - val_loss: 6.5581\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6219 - val_loss: 6.7865\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6816 - val_loss: 5.3999\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6593 - val_loss: 5.5726\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8574 - val_loss: 7.0221\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6892 - val_loss: 6.1805\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7694 - val_loss: 5.9446\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7026 - val_loss: 5.5724\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7799 - val_loss: 6.3651\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7152 - val_loss: 6.0044\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6244 - val_loss: 7.0464\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5864 - val_loss: 6.3473\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6344 - val_loss: 5.6547\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6360 - val_loss: 7.1189\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8731 - val_loss: 6.1603\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6479 - val_loss: 4.9588\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6820 - val_loss: 5.2951\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9470 - val_loss: 5.0755\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6823 - val_loss: 5.0879\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5714 - val_loss: 6.2531\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5379 - val_loss: 6.1270\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6848 - val_loss: 5.8808\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7751 - val_loss: 4.6373\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5921 - val_loss: 5.1702\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6592 - val_loss: 5.2555\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7440 - val_loss: 4.9826\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6443 - val_loss: 4.4095\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5633 - val_loss: 5.5529\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6316 - val_loss: 5.0864\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5186 - val_loss: 5.1059\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6607 - val_loss: 4.7007\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6522 - val_loss: 6.0102\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6891 - val_loss: 5.3573\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5636 - val_loss: 5.5065\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5225 - val_loss: 5.9621\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7168 - val_loss: 5.7587\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7422 - val_loss: 5.5418\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5985 - val_loss: 5.7905\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6614 - val_loss: 5.0529\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6179 - val_loss: 5.7776\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7426 - val_loss: 6.2608\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6116 - val_loss: 5.9914\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5888 - val_loss: 5.9763\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6228 - val_loss: 6.1681\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6435 - val_loss: 5.6113\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6400 - val_loss: 5.1650\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7087 - val_loss: 5.8841\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7419 - val_loss: 5.5426\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6488 - val_loss: 5.8246\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5464 - val_loss: 5.1506\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7557 - val_loss: 4.7918\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7143 - val_loss: 5.2785\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7911 - val_loss: 6.2474\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6602 - val_loss: 4.3782\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5295 - val_loss: 5.3912\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7300 - val_loss: 6.0061\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6320 - val_loss: 6.3111\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6356 - val_loss: 6.2294\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5881 - val_loss: 5.2289\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5848 - val_loss: 5.1512\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6708 - val_loss: 5.4715\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6425 - val_loss: 5.5386\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6477 - val_loss: 6.0208\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5905 - val_loss: 5.4774\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6017 - val_loss: 5.6391\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5562 - val_loss: 7.0055\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8622 - val_loss: 5.4872\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6618 - val_loss: 5.8465\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5443 - val_loss: 6.2496\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6984 - val_loss: 7.2782\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6890 - val_loss: 6.2737\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5998 - val_loss: 4.7783\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7391 - val_loss: 5.4634\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5840 - val_loss: 5.3347\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5970 - val_loss: 5.9700\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6281 - val_loss: 6.3708\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8443 - val_loss: 6.1709\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6912 - val_loss: 4.8745\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6301 - val_loss: 5.2651\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6362 - val_loss: 5.9030\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4681 - val_loss: 5.5471\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5840 - val_loss: 5.6156\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5323 - val_loss: 4.9585\n",
      "Epoch 1141/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5117 - val_loss: 5.5216\n",
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6340 - val_loss: 5.3454\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5327 - val_loss: 5.4302\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4882 - val_loss: 5.3497\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5395 - val_loss: 5.7619\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6053 - val_loss: 5.5809\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7077 - val_loss: 5.6041\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5790 - val_loss: 5.5731\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5722 - val_loss: 5.5751\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7105 - val_loss: 5.1644\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5224 - val_loss: 5.1901\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6124 - val_loss: 5.5806\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6097 - val_loss: 5.1799\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7484 - val_loss: 4.7714\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7534 - val_loss: 5.6354\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5496 - val_loss: 5.3348\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5932 - val_loss: 4.7628\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6544 - val_loss: 4.9569\n",
      "Epoch 1159/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5548 - val_loss: 5.2113\n",
      "Epoch 1160/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5510 - val_loss: 4.5569\n",
      "Epoch 1161/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6887 - val_loss: 6.5710\n",
      "Epoch 1162/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7778 - val_loss: 5.8278\n",
      "Epoch 1163/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6736 - val_loss: 4.6293\n",
      "Epoch 1164/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5254 - val_loss: 5.4310\n",
      "Epoch 1165/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4920 - val_loss: 4.7734\n",
      "Epoch 1166/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7761 - val_loss: 4.4183\n",
      "Epoch 1167/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5502 - val_loss: 5.3883\n",
      "Epoch 1168/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6264 - val_loss: 5.1568\n",
      "Epoch 1169/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4800 - val_loss: 4.9482\n",
      "Epoch 1170/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 4.7205\n",
      "Epoch 1171/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5769 - val_loss: 5.0642\n",
      "Epoch 1172/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5801 - val_loss: 4.9999\n",
      "Epoch 1173/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4998 - val_loss: 5.6075\n",
      "Epoch 1174/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5358 - val_loss: 5.2196\n",
      "Epoch 1175/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6298 - val_loss: 4.5492\n",
      "Epoch 1176/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5046 - val_loss: 5.1870\n",
      "Epoch 1177/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4892 - val_loss: 5.4982\n",
      "Epoch 1178/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4773 - val_loss: 5.2074\n",
      "Epoch 1179/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6699 - val_loss: 5.4423\n",
      "Epoch 1180/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4691 - val_loss: 5.1018\n",
      "Epoch 1181/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5072 - val_loss: 5.8820\n",
      "Epoch 1182/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5168 - val_loss: 5.3736\n",
      "Epoch 1183/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4972 - val_loss: 5.7830\n",
      "Epoch 1184/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6173 - val_loss: 5.0634\n",
      "Epoch 1185/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5605 - val_loss: 5.7082\n",
      "Epoch 1186/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4786 - val_loss: 6.0304\n",
      "Epoch 1187/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5126 - val_loss: 4.7369\n",
      "Epoch 1188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6133 - val_loss: 5.1279\n",
      "Epoch 1189/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5835 - val_loss: 5.5969\n",
      "Epoch 1190/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5010 - val_loss: 4.8496\n",
      "Epoch 1191/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7016 - val_loss: 5.2313\n",
      "Epoch 1192/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4930 - val_loss: 4.9492\n",
      "Epoch 1193/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6553 - val_loss: 4.6408\n",
      "Epoch 1194/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5399 - val_loss: 5.0358\n",
      "Epoch 1195/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5169 - val_loss: 4.6514\n",
      "Epoch 1196/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6737 - val_loss: 4.3897\n",
      "Epoch 1197/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5556 - val_loss: 5.1926\n",
      "Epoch 1198/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4529 - val_loss: 5.3925\n",
      "Epoch 1199/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5774 - val_loss: 5.1644\n",
      "Epoch 1200/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4548 - val_loss: 4.8882\n",
      "Epoch 1201/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4560 - val_loss: 4.7902\n",
      "Epoch 1202/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5397 - val_loss: 5.0716\n",
      "Epoch 1203/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6423 - val_loss: 5.1472\n",
      "Epoch 1204/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4542 - val_loss: 5.0927\n",
      "Epoch 1205/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4848 - val_loss: 5.8898\n",
      "Epoch 1206/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5083 - val_loss: 4.5252\n",
      "Epoch 1207/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5697 - val_loss: 5.0493\n",
      "Epoch 1208/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4965 - val_loss: 6.2672\n",
      "Epoch 1209/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3967 - val_loss: 4.9388\n",
      "Epoch 1210/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5863 - val_loss: 5.3236\n",
      "Epoch 1211/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4945 - val_loss: 5.4902\n",
      "Epoch 1212/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5482 - val_loss: 4.6730\n",
      "Epoch 1213/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5381 - val_loss: 4.5836\n",
      "Epoch 1214/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6263 - val_loss: 5.1027\n",
      "Epoch 1215/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5015 - val_loss: 5.4914\n",
      "Epoch 1216/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5298 - val_loss: 5.8562\n",
      "Epoch 1217/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5619 - val_loss: 5.0148\n",
      "Epoch 1218/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6488 - val_loss: 5.1220\n",
      "Epoch 1219/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4848 - val_loss: 4.9843\n",
      "Epoch 1220/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6158 - val_loss: 5.2180\n",
      "Epoch 1221/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3918 - val_loss: 5.1639\n",
      "Epoch 1222/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6126 - val_loss: 5.0202\n",
      "Epoch 1223/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5221 - val_loss: 5.1915\n",
      "Epoch 1224/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5938 - val_loss: 4.7280\n",
      "Epoch 1225/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6929 - val_loss: 4.9349\n",
      "Epoch 1226/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5918 - val_loss: 4.6082\n",
      "Epoch 1227/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4400 - val_loss: 5.0744\n",
      "Epoch 1228/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5379 - val_loss: 5.0836\n",
      "Epoch 1229/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4672 - val_loss: 5.8921\n",
      "Epoch 1230/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4925 - val_loss: 5.7316\n",
      "Epoch 1231/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4355 - val_loss: 5.0203\n",
      "Epoch 1232/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5247 - val_loss: 4.7649\n",
      "Epoch 1233/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5070 - val_loss: 4.6367\n",
      "Epoch 1234/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3737 - val_loss: 4.9997\n",
      "Epoch 1235/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4267 - val_loss: 5.2401\n",
      "Epoch 1236/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5519 - val_loss: 5.0690\n",
      "Epoch 1237/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4576 - val_loss: 4.9479\n",
      "Epoch 1238/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5263 - val_loss: 5.0706\n",
      "Epoch 1239/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5493 - val_loss: 4.5407\n",
      "Epoch 1240/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5323 - val_loss: 4.8955\n",
      "Epoch 1241/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5585 - val_loss: 5.1406\n",
      "Epoch 1242/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5509 - val_loss: 4.7607\n",
      "Epoch 1243/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5535 - val_loss: 4.9741\n",
      "Epoch 1244/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5216 - val_loss: 5.3718\n",
      "Epoch 1245/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4561 - val_loss: 4.6933\n",
      "Epoch 1246/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5522 - val_loss: 4.2503\n",
      "Epoch 1247/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4115 - val_loss: 4.2754\n",
      "Epoch 1248/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5123 - val_loss: 4.7614\n",
      "Epoch 1249/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5131 - val_loss: 4.9723\n",
      "Epoch 1250/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7001 - val_loss: 4.6338\n",
      "Epoch 1251/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5881 - val_loss: 4.7436\n",
      "Epoch 1252/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8793 - val_loss: 4.4821\n",
      "Epoch 1253/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4918 - val_loss: 4.4097\n",
      "Epoch 1254/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6649 - val_loss: 5.1401\n",
      "Epoch 1255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7904 - val_loss: 4.6100\n",
      "Epoch 1256/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4321 - val_loss: 5.0022\n",
      "Epoch 1257/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5119 - val_loss: 4.9855\n",
      "Epoch 1258/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4580 - val_loss: 5.1811\n",
      "Epoch 1259/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5094 - val_loss: 5.0398\n",
      "Epoch 1260/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4077 - val_loss: 5.0309\n",
      "Epoch 1261/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4672 - val_loss: 5.0543\n",
      "Epoch 1262/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4591 - val_loss: 4.9975\n",
      "Epoch 1263/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4960 - val_loss: 4.9259\n",
      "Epoch 1264/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4658 - val_loss: 4.6274\n",
      "Epoch 1265/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4945 - val_loss: 4.8376\n",
      "Epoch 1266/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4642 - val_loss: 4.4813\n",
      "Epoch 1267/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5095 - val_loss: 4.7795\n",
      "Epoch 1268/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5450 - val_loss: 4.8810\n",
      "Epoch 1269/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5830 - val_loss: 4.7707\n",
      "Epoch 1270/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6031 - val_loss: 5.1295\n",
      "Epoch 1271/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5518 - val_loss: 5.3149\n",
      "Epoch 1272/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4691 - val_loss: 4.7337\n",
      "Epoch 1273/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5912 - val_loss: 5.1099\n",
      "Epoch 1274/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6089 - val_loss: 5.0757\n",
      "Epoch 1275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5680 - val_loss: 5.3842\n",
      "Epoch 1276/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4142 - val_loss: 5.1462\n",
      "Epoch 1277/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5078 - val_loss: 4.9223\n",
      "Epoch 1278/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5927 - val_loss: 5.3820\n",
      "Epoch 1279/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7840 - val_loss: 4.7724\n",
      "Epoch 1280/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5833 - val_loss: 4.7597\n",
      "Epoch 1281/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8317 - val_loss: 4.7915\n",
      "Epoch 1282/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4922 - val_loss: 4.8459\n",
      "Epoch 1283/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4700 - val_loss: 4.7922\n",
      "Epoch 1284/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5820 - val_loss: 5.0264\n",
      "Epoch 1285/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4160 - val_loss: 4.6760\n",
      "Epoch 1286/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4801 - val_loss: 4.3821\n",
      "Epoch 1287/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4582 - val_loss: 4.6399\n",
      "Epoch 1288/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4480 - val_loss: 4.4166\n",
      "Epoch 1289/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4572 - val_loss: 4.5960\n",
      "Epoch 1290/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3720 - val_loss: 4.2444\n",
      "Epoch 1291/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6137 - val_loss: 4.6819\n",
      "Epoch 1292/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6440 - val_loss: 5.0434\n",
      "Epoch 1293/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5851 - val_loss: 4.5559\n",
      "Epoch 1294/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5144 - val_loss: 5.0445\n",
      "Epoch 1295/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5489 - val_loss: 4.7749\n",
      "Epoch 1296/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4812 - val_loss: 4.4055\n",
      "Epoch 1297/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4324 - val_loss: 4.4372\n",
      "Epoch 1298/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4112 - val_loss: 4.3651\n",
      "Epoch 1299/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4737 - val_loss: 4.8855\n",
      "Epoch 1300/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4981 - val_loss: 4.6406\n",
      "Epoch 1301/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4146 - val_loss: 4.7120\n",
      "Epoch 1302/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6091 - val_loss: 4.3514\n",
      "Epoch 1303/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5298 - val_loss: 4.6505\n",
      "Epoch 1304/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4857 - val_loss: 5.1215\n",
      "Epoch 1305/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4978 - val_loss: 4.8377\n",
      "Epoch 1306/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5604 - val_loss: 4.9010\n",
      "Epoch 1307/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5151 - val_loss: 4.6133\n",
      "Epoch 1308/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4003 - val_loss: 4.5805\n",
      "Epoch 1309/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3377 - val_loss: 4.8131\n",
      "Epoch 1310/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4367 - val_loss: 4.6996\n",
      "Epoch 1311/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5566 - val_loss: 4.9865\n",
      "Epoch 1312/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3740 - val_loss: 5.0542\n",
      "Epoch 1313/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4358 - val_loss: 4.9745\n",
      "Epoch 1314/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4970 - val_loss: 4.7900\n",
      "Epoch 1315/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5084 - val_loss: 5.5118\n",
      "Epoch 1316/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4379 - val_loss: 4.9091\n",
      "Epoch 1317/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4731 - val_loss: 4.5259\n",
      "Epoch 1318/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4286 - val_loss: 4.8660\n",
      "Epoch 1319/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5016 - val_loss: 5.2809\n",
      "Epoch 1320/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4120 - val_loss: 4.7533\n",
      "Epoch 1321/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3645 - val_loss: 4.9400\n",
      "Epoch 1322/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5115 - val_loss: 4.9444\n",
      "Epoch 1323/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4609 - val_loss: 5.0596\n",
      "Epoch 1324/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4932 - val_loss: 4.9967\n",
      "Epoch 1325/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3739 - val_loss: 4.8994\n",
      "Epoch 1326/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5168 - val_loss: 4.9781\n",
      "Epoch 1327/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4573 - val_loss: 5.3869\n",
      "Epoch 1328/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4729 - val_loss: 5.2750\n",
      "Epoch 1329/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3652 - val_loss: 4.9005\n",
      "Epoch 1330/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3737 - val_loss: 4.9379\n",
      "Epoch 1331/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4161 - val_loss: 5.2466\n",
      "Epoch 1332/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3278 - val_loss: 4.6544\n",
      "Epoch 1333/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4852 - val_loss: 4.5582\n",
      "Epoch 1334/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7448 - val_loss: 4.7472\n",
      "Epoch 1335/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3908 - val_loss: 4.7650\n",
      "Epoch 1336/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4643 - val_loss: 4.8439\n",
      "Epoch 1337/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5113 - val_loss: 4.6489\n",
      "Epoch 1338/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3632 - val_loss: 4.6161\n",
      "Epoch 1339/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5064 - val_loss: 4.4889\n",
      "Epoch 1340/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4717 - val_loss: 5.3247\n",
      "Epoch 1341/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3881 - val_loss: 4.7278\n",
      "Epoch 1342/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4639 - val_loss: 4.7170\n",
      "Epoch 1343/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4317 - val_loss: 4.9478\n",
      "Epoch 1344/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4876 - val_loss: 4.9710\n",
      "Epoch 1345/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6258 - val_loss: 4.9548\n",
      "Epoch 1346/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5072 - val_loss: 4.8565\n",
      "Epoch 1347/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3894 - val_loss: 4.6898\n",
      "Epoch 1348/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4057 - val_loss: 4.8532\n",
      "Epoch 1349/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4869 - val_loss: 5.5035\n",
      "Epoch 1350/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3440 - val_loss: 5.5220\n",
      "Epoch 1351/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3691 - val_loss: 5.1411\n",
      "Epoch 1352/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3955 - val_loss: 5.3664\n",
      "Epoch 1353/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4636 - val_loss: 4.9610\n",
      "Epoch 1354/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3927 - val_loss: 5.2962\n",
      "Epoch 1355/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4979 - val_loss: 5.0101\n",
      "Epoch 1356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5164 - val_loss: 4.8562\n",
      "Epoch 1357/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3919 - val_loss: 5.5645\n",
      "Epoch 1358/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3456 - val_loss: 5.4407\n",
      "Epoch 1359/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4181 - val_loss: 5.3023\n",
      "Epoch 1360/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4566 - val_loss: 5.1754\n",
      "Epoch 1361/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5520 - val_loss: 4.9816\n",
      "Epoch 1362/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4798 - val_loss: 5.0247\n",
      "Epoch 1363/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5217 - val_loss: 5.1047\n",
      "Epoch 1364/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4254 - val_loss: 5.3607\n",
      "Epoch 1365/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4186 - val_loss: 5.1839\n",
      "Epoch 1366/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3668 - val_loss: 4.9188\n",
      "Epoch 1367/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4437 - val_loss: 4.8154\n",
      "Epoch 1368/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2763Restoring model weights from the end of the best epoch: 868.\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3106 - val_loss: 5.2130\n",
      "Epoch 1368: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>12.075612</td>\n",
       "      <td>11.794294</td>\n",
       "      <td>12.725159</td>\n",
       "      <td>13.369139</td>\n",
       "      <td>13.474021</td>\n",
       "      <td>15.497648</td>\n",
       "      <td>-5.337283</td>\n",
       "      <td>-3.581975</td>\n",
       "      <td>2.114866</td>\n",
       "      <td>7.417327</td>\n",
       "      <td>6.852262</td>\n",
       "      <td>10.898136</td>\n",
       "      <td>15.082037</td>\n",
       "      <td>12.370364</td>\n",
       "      <td>16.457823</td>\n",
       "      <td>15.02827</td>\n",
       "      <td>14.124835</td>\n",
       "      <td>18.845181</td>\n",
       "      <td>1.78677</td>\n",
       "      <td>1.825071</td>\n",
       "      <td>4.085227</td>\n",
       "      <td>4.000364</td>\n",
       "      <td>5.643169</td>\n",
       "      <td>5.922133</td>\n",
       "      <td>7.649185</td>\n",
       "      <td>16.481382</td>\n",
       "      <td>17.689068</td>\n",
       "      <td>17.943319</td>\n",
       "      <td>17.191544</td>\n",
       "      <td>17.607769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>12.399</td>\n",
       "      <td>11.268</td>\n",
       "      <td>8.741</td>\n",
       "      <td>12.358</td>\n",
       "      <td>11.876</td>\n",
       "      <td>11.713</td>\n",
       "      <td>11.449</td>\n",
       "      <td>7.805</td>\n",
       "      <td>7.726</td>\n",
       "      <td>8.516</td>\n",
       "      <td>8.503</td>\n",
       "      <td>10.175</td>\n",
       "      <td>11.775</td>\n",
       "      <td>9.724</td>\n",
       "      <td>10.069</td>\n",
       "      <td>13.93</td>\n",
       "      <td>11.918</td>\n",
       "      <td>11.757</td>\n",
       "      <td>9.691</td>\n",
       "      <td>7.378</td>\n",
       "      <td>6.97</td>\n",
       "      <td>7.612</td>\n",
       "      <td>8.442</td>\n",
       "      <td>8.835</td>\n",
       "      <td>11.251</td>\n",
       "      <td>11.342</td>\n",
       "      <td>13.11</td>\n",
       "      <td>13.195</td>\n",
       "      <td>10.053</td>\n",
       "      <td>12.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>0.323388</td>\n",
       "      <td>0.526295</td>\n",
       "      <td>3.984159</td>\n",
       "      <td>1.011139</td>\n",
       "      <td>1.598021</td>\n",
       "      <td>3.784648</td>\n",
       "      <td>16.786283</td>\n",
       "      <td>11.386975</td>\n",
       "      <td>5.611134</td>\n",
       "      <td>1.098672</td>\n",
       "      <td>1.650738</td>\n",
       "      <td>0.723136</td>\n",
       "      <td>3.307037</td>\n",
       "      <td>2.646364</td>\n",
       "      <td>6.388823</td>\n",
       "      <td>1.098269</td>\n",
       "      <td>2.206835</td>\n",
       "      <td>7.088181</td>\n",
       "      <td>7.90423</td>\n",
       "      <td>5.552928</td>\n",
       "      <td>2.884773</td>\n",
       "      <td>3.611636</td>\n",
       "      <td>2.798831</td>\n",
       "      <td>2.912867</td>\n",
       "      <td>3.601815</td>\n",
       "      <td>5.139382</td>\n",
       "      <td>4.579068</td>\n",
       "      <td>4.74832</td>\n",
       "      <td>7.138543</td>\n",
       "      <td>5.333769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1          2          3          4          5   \\\n",
       "Month         Month-1    Month-2    Month-3    Month-4    Month-5    Month-6   \n",
       "Prediction  12.075612  11.794294  12.725159  13.369139  13.474021  15.497648   \n",
       "Target         12.399     11.268      8.741     12.358     11.876     11.713   \n",
       "Error        0.323388   0.526295   3.984159   1.011139   1.598021   3.784648   \n",
       "\n",
       "                   6          7         8         9         10         11  \\\n",
       "Month         Month-7    Month-8   Month-9  Month-10  Month-11   Month-12   \n",
       "Prediction  -5.337283  -3.581975  2.114866  7.417327  6.852262  10.898136   \n",
       "Target         11.449      7.805     7.726     8.516     8.503     10.175   \n",
       "Error       16.786283  11.386975  5.611134  1.098672  1.650738   0.723136   \n",
       "\n",
       "                   12         13         14        15         16         17  \\\n",
       "Month        Month-13   Month-14   Month-15  Month-16   Month-17   Month-18   \n",
       "Prediction  15.082037  12.370364  16.457823  15.02827  14.124835  18.845181   \n",
       "Target         11.775      9.724     10.069     13.93     11.918     11.757   \n",
       "Error        3.307037   2.646364   6.388823  1.098269   2.206835   7.088181   \n",
       "\n",
       "                  18        19        20        21        22        23  \\\n",
       "Month       Month-19  Month-20  Month-21  Month-22  Month-23  Month-24   \n",
       "Prediction   1.78677  1.825071  4.085227  4.000364  5.643169  5.922133   \n",
       "Target         9.691     7.378      6.97     7.612     8.442     8.835   \n",
       "Error        7.90423  5.552928  2.884773  3.611636  2.798831  2.912867   \n",
       "\n",
       "                  24         25         26         27         28         29  \n",
       "Month       Month-25   Month-26   Month-27   Month-28   Month-29   Month-30  \n",
       "Prediction  7.649185  16.481382  17.689068  17.943319  17.191544  17.607769  \n",
       "Target        11.251     11.342      13.11     13.195     10.053     12.274  \n",
       "Error       3.601815   5.139382   4.579068    4.74832   7.138543   5.333769  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.247542"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4304326"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[97.29921]] - Target[122.52900000000001]| =  Error: [[25.22979]]; MAPE:[[0.20590872]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[115.17125]] - Target[118.101]| =  Error: [[2.9297485]]; MAPE:[[0.02480714]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-5: |Prediction[[94.56227]] - Target[71.22500000000001]| =  Error: [[23.337273]]; MAPE:[[0.32765564]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[25.22979]], dtype=float32),\n",
       " array([[2.9297485]], dtype=float32),\n",
       " array([[23.337273]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "17.165604"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.18612383"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
