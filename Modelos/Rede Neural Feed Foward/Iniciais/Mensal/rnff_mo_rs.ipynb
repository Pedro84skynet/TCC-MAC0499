{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Rio Grande Do Sul - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rio Grande do Sul - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rio Grande Do Sul - Produção de Cimento (t)</th>\n",
       "      <th>Rio Grande do Sul - PIB - Estadual</th>\n",
       "      <th>Rio Grande do Sul - PIB - Construção Civil</th>\n",
       "      <th>Rio Grande do Sul - PIB - Per Capita</th>\n",
       "      <th>Rio Grande do Sul - PIB - Preços de Mercado</th>\n",
       "      <th>Rio Grande do Sul - value</th>\n",
       "      <th>Rio Grande do Sul - IDH</th>\n",
       "      <th>Rio Grande Do Sul - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>8.192273</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>135.543840</td>\n",
       "      <td>2.066295e+08</td>\n",
       "      <td>8.907130e+06</td>\n",
       "      <td>18.206952</td>\n",
       "      <td>1.960625e+08</td>\n",
       "      <td>0.399576</td>\n",
       "      <td>0.775641</td>\n",
       "      <td>188.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>8.186359</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>134.468148</td>\n",
       "      <td>2.068579e+08</td>\n",
       "      <td>8.912326e+06</td>\n",
       "      <td>18.211286</td>\n",
       "      <td>1.961183e+08</td>\n",
       "      <td>0.398811</td>\n",
       "      <td>0.775686</td>\n",
       "      <td>170.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>8.180446</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>134.242963</td>\n",
       "      <td>2.070864e+08</td>\n",
       "      <td>8.917522e+06</td>\n",
       "      <td>18.215621</td>\n",
       "      <td>1.961742e+08</td>\n",
       "      <td>0.397898</td>\n",
       "      <td>0.775731</td>\n",
       "      <td>174.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>8.174533</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>133.169391</td>\n",
       "      <td>2.073148e+08</td>\n",
       "      <td>8.922718e+06</td>\n",
       "      <td>18.219955</td>\n",
       "      <td>1.962300e+08</td>\n",
       "      <td>0.397042</td>\n",
       "      <td>0.775775</td>\n",
       "      <td>178.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>8.168619</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>132.046874</td>\n",
       "      <td>2.075433e+08</td>\n",
       "      <td>8.927915e+06</td>\n",
       "      <td>18.224290</td>\n",
       "      <td>1.962858e+08</td>\n",
       "      <td>0.396050</td>\n",
       "      <td>0.775820</td>\n",
       "      <td>184.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.034199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.832392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.001080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.829742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.052788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.665535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.823550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.388905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275.972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Rio Grande do Sul - Desemprego  \\\n",
       "0       2003-1                        8.192273   \n",
       "1       2003-2                        8.186359   \n",
       "2       2003-3                        8.180446   \n",
       "3       2003-4                        8.174533   \n",
       "4       2003-5                        8.168619   \n",
       "..         ...                             ...   \n",
       "235     2022-8                             NaN   \n",
       "236     2022-9                             NaN   \n",
       "237    2022-10                             NaN   \n",
       "238    2022-11                             NaN   \n",
       "239    2022-12                             NaN   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     Rio Grande Do Sul - Produção de Cimento (t)  \\\n",
       "0                                     135.543840   \n",
       "1                                     134.468148   \n",
       "2                                     134.242963   \n",
       "3                                     133.169391   \n",
       "4                                     132.046874   \n",
       "..                                           ...   \n",
       "235                                   133.034199   \n",
       "236                                   133.001080   \n",
       "237                                   133.052788   \n",
       "238                                   132.665535   \n",
       "239                                   132.388905   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Estadual  \\\n",
       "0                          2.066295e+08   \n",
       "1                          2.068579e+08   \n",
       "2                          2.070864e+08   \n",
       "3                          2.073148e+08   \n",
       "4                          2.075433e+08   \n",
       "..                                  ...   \n",
       "235                                 NaN   \n",
       "236                                 NaN   \n",
       "237                                 NaN   \n",
       "238                                 NaN   \n",
       "239                                 NaN   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Construção Civil  \\\n",
       "0                                  8.907130e+06   \n",
       "1                                  8.912326e+06   \n",
       "2                                  8.917522e+06   \n",
       "3                                  8.922718e+06   \n",
       "4                                  8.927915e+06   \n",
       "..                                          ...   \n",
       "235                                         NaN   \n",
       "236                                         NaN   \n",
       "237                                         NaN   \n",
       "238                                         NaN   \n",
       "239                                         NaN   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Per Capita  \\\n",
       "0                               18.206952   \n",
       "1                               18.211286   \n",
       "2                               18.215621   \n",
       "3                               18.219955   \n",
       "4                               18.224290   \n",
       "..                                    ...   \n",
       "235                                   NaN   \n",
       "236                                   NaN   \n",
       "237                                   NaN   \n",
       "238                                   NaN   \n",
       "239                                   NaN   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Preços de Mercado  Rio Grande do Sul - value  \\\n",
       "0                                   1.960625e+08                   0.399576   \n",
       "1                                   1.961183e+08                   0.398811   \n",
       "2                                   1.961742e+08                   0.397898   \n",
       "3                                   1.962300e+08                   0.397042   \n",
       "4                                   1.962858e+08                   0.396050   \n",
       "..                                           ...                        ...   \n",
       "235                                          NaN                   0.832392   \n",
       "236                                          NaN                   0.829742   \n",
       "237                                          NaN                   0.826925   \n",
       "238                                          NaN                   0.823550   \n",
       "239                                          NaN                   0.820378   \n",
       "\n",
       "     Rio Grande do Sul - IDH  Rio Grande Do Sul - Consumo de Cimento (t)  \n",
       "0                   0.775641                                     188.093  \n",
       "1                   0.775686                                     170.973  \n",
       "2                   0.775731                                     174.880  \n",
       "3                   0.775775                                     178.111  \n",
       "4                   0.775820                                     184.331  \n",
       "..                       ...                                         ...  \n",
       "235                      NaN                                     288.217  \n",
       "236                      NaN                                     272.178  \n",
       "237                      NaN                                     272.665  \n",
       "238                      NaN                                     275.972  \n",
       "239                      NaN                                     275.972  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_RS.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data = data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rio Grande do Sul - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rio Grande Do Sul - Produção de Cimento (t)</th>\n",
       "      <th>Rio Grande do Sul - PIB - Estadual</th>\n",
       "      <th>Rio Grande do Sul - PIB - Construção Civil</th>\n",
       "      <th>Rio Grande do Sul - PIB - Per Capita</th>\n",
       "      <th>Rio Grande do Sul - PIB - Preços de Mercado</th>\n",
       "      <th>Rio Grande do Sul - value</th>\n",
       "      <th>Rio Grande do Sul - IDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.274013</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-0.577787</td>\n",
       "      <td>-1.677139</td>\n",
       "      <td>-1.973850</td>\n",
       "      <td>-2.280022</td>\n",
       "      <td>-2.069914</td>\n",
       "      <td>-1.362004</td>\n",
       "      <td>-1.691101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.259068</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-0.629575</td>\n",
       "      <td>-1.660252</td>\n",
       "      <td>-1.934055</td>\n",
       "      <td>-2.253080</td>\n",
       "      <td>-2.045065</td>\n",
       "      <td>-1.371141</td>\n",
       "      <td>-1.675868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.244123</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-0.640416</td>\n",
       "      <td>-1.643365</td>\n",
       "      <td>-1.894260</td>\n",
       "      <td>-2.226138</td>\n",
       "      <td>-2.020217</td>\n",
       "      <td>-1.382062</td>\n",
       "      <td>-1.660635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.229178</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-0.692102</td>\n",
       "      <td>-1.626477</td>\n",
       "      <td>-1.854466</td>\n",
       "      <td>-2.199196</td>\n",
       "      <td>-1.995368</td>\n",
       "      <td>-1.392283</td>\n",
       "      <td>-1.645402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.214233</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-0.746144</td>\n",
       "      <td>-1.609590</td>\n",
       "      <td>-1.814671</td>\n",
       "      <td>-2.172254</td>\n",
       "      <td>-1.970520</td>\n",
       "      <td>-1.404146</td>\n",
       "      <td>-1.630170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-0.966721</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-1.420132</td>\n",
       "      <td>1.083219</td>\n",
       "      <td>-0.768157</td>\n",
       "      <td>0.374323</td>\n",
       "      <td>0.568222</td>\n",
       "      <td>1.591021</td>\n",
       "      <td>0.807464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-0.973649</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>-1.417824</td>\n",
       "      <td>1.070530</td>\n",
       "      <td>-0.760321</td>\n",
       "      <td>0.347418</td>\n",
       "      <td>0.545097</td>\n",
       "      <td>1.635348</td>\n",
       "      <td>0.773102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-0.980576</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>-1.381727</td>\n",
       "      <td>1.057841</td>\n",
       "      <td>-0.752485</td>\n",
       "      <td>0.320513</td>\n",
       "      <td>0.521971</td>\n",
       "      <td>1.689944</td>\n",
       "      <td>0.738739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-0.987503</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-1.359803</td>\n",
       "      <td>1.045153</td>\n",
       "      <td>-0.744649</td>\n",
       "      <td>0.293608</td>\n",
       "      <td>0.498846</td>\n",
       "      <td>1.737741</td>\n",
       "      <td>0.704377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-0.994431</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-1.370922</td>\n",
       "      <td>1.032464</td>\n",
       "      <td>-0.736812</td>\n",
       "      <td>0.266704</td>\n",
       "      <td>0.475721</td>\n",
       "      <td>1.781133</td>\n",
       "      <td>0.670015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rio Grande do Sul - Desemprego  \\\n",
       "0                          1.274013   \n",
       "1                          1.259068   \n",
       "2                          1.244123   \n",
       "3                          1.229178   \n",
       "4                          1.214233   \n",
       "..                              ...   \n",
       "187                       -0.966721   \n",
       "188                       -0.973649   \n",
       "189                       -0.980576   \n",
       "190                       -0.987503   \n",
       "191                       -0.994431   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Rio Grande Do Sul - Produção de Cimento (t)  \\\n",
       "0                                      -0.577787   \n",
       "1                                      -0.629575   \n",
       "2                                      -0.640416   \n",
       "3                                      -0.692102   \n",
       "4                                      -0.746144   \n",
       "..                                           ...   \n",
       "187                                    -1.420132   \n",
       "188                                    -1.417824   \n",
       "189                                    -1.381727   \n",
       "190                                    -1.359803   \n",
       "191                                    -1.370922   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Estadual  \\\n",
       "0                             -1.677139   \n",
       "1                             -1.660252   \n",
       "2                             -1.643365   \n",
       "3                             -1.626477   \n",
       "4                             -1.609590   \n",
       "..                                  ...   \n",
       "187                            1.083219   \n",
       "188                            1.070530   \n",
       "189                            1.057841   \n",
       "190                            1.045153   \n",
       "191                            1.032464   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Construção Civil  \\\n",
       "0                                     -1.973850   \n",
       "1                                     -1.934055   \n",
       "2                                     -1.894260   \n",
       "3                                     -1.854466   \n",
       "4                                     -1.814671   \n",
       "..                                          ...   \n",
       "187                                   -0.768157   \n",
       "188                                   -0.760321   \n",
       "189                                   -0.752485   \n",
       "190                                   -0.744649   \n",
       "191                                   -0.736812   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Per Capita  \\\n",
       "0                               -2.280022   \n",
       "1                               -2.253080   \n",
       "2                               -2.226138   \n",
       "3                               -2.199196   \n",
       "4                               -2.172254   \n",
       "..                                    ...   \n",
       "187                              0.374323   \n",
       "188                              0.347418   \n",
       "189                              0.320513   \n",
       "190                              0.293608   \n",
       "191                              0.266704   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Preços de Mercado  Rio Grande do Sul - value  \\\n",
       "0                                      -2.069914                  -1.362004   \n",
       "1                                      -2.045065                  -1.371141   \n",
       "2                                      -2.020217                  -1.382062   \n",
       "3                                      -1.995368                  -1.392283   \n",
       "4                                      -1.970520                  -1.404146   \n",
       "..                                           ...                        ...   \n",
       "187                                     0.568222                   1.591021   \n",
       "188                                     0.545097                   1.635348   \n",
       "189                                     0.521971                   1.689944   \n",
       "190                                     0.498846                   1.737741   \n",
       "191                                     0.475721                   1.781133   \n",
       "\n",
       "     Rio Grande do Sul - IDH  \n",
       "0                  -1.691101  \n",
       "1                  -1.675868  \n",
       "2                  -1.660635  \n",
       "3                  -1.645402  \n",
       "4                  -1.630170  \n",
       "..                       ...  \n",
       "187                 0.807464  \n",
       "188                 0.773102  \n",
       "189                 0.738739  \n",
       "190                 0.704377  \n",
       "191                 0.670015  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      174.261\n",
       "1      164.909\n",
       "2      202.662\n",
       "3      174.149\n",
       "4      159.955\n",
       "        ...   \n",
       "235        NaN\n",
       "236        NaN\n",
       "237        NaN\n",
       "238        NaN\n",
       "239        NaN\n",
       "Name: Rio Grande Do Sul - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rio Grande do Sul - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rio Grande Do Sul - Produção de Cimento (t)</th>\n",
       "      <th>Rio Grande do Sul - PIB - Estadual</th>\n",
       "      <th>Rio Grande do Sul - PIB - Construção Civil</th>\n",
       "      <th>Rio Grande do Sul - PIB - Per Capita</th>\n",
       "      <th>Rio Grande do Sul - PIB - Preços de Mercado</th>\n",
       "      <th>Rio Grande do Sul - value</th>\n",
       "      <th>Rio Grande do Sul - IDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.274013</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-0.577787</td>\n",
       "      <td>-1.677139</td>\n",
       "      <td>-1.973850</td>\n",
       "      <td>-2.280022</td>\n",
       "      <td>-2.069914</td>\n",
       "      <td>-1.362004</td>\n",
       "      <td>-1.691101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.259068</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-0.629575</td>\n",
       "      <td>-1.660252</td>\n",
       "      <td>-1.934055</td>\n",
       "      <td>-2.253080</td>\n",
       "      <td>-2.045065</td>\n",
       "      <td>-1.371141</td>\n",
       "      <td>-1.675868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.244123</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-0.640416</td>\n",
       "      <td>-1.643365</td>\n",
       "      <td>-1.894260</td>\n",
       "      <td>-2.226138</td>\n",
       "      <td>-2.020217</td>\n",
       "      <td>-1.382062</td>\n",
       "      <td>-1.660635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.229178</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-0.692102</td>\n",
       "      <td>-1.626477</td>\n",
       "      <td>-1.854466</td>\n",
       "      <td>-2.199196</td>\n",
       "      <td>-1.995368</td>\n",
       "      <td>-1.392283</td>\n",
       "      <td>-1.645402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.214233</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-0.746144</td>\n",
       "      <td>-1.609590</td>\n",
       "      <td>-1.814671</td>\n",
       "      <td>-2.172254</td>\n",
       "      <td>-1.970520</td>\n",
       "      <td>-1.404146</td>\n",
       "      <td>-1.630170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.092018</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>-0.647118</td>\n",
       "      <td>1.197586</td>\n",
       "      <td>-0.541459</td>\n",
       "      <td>0.739492</td>\n",
       "      <td>0.925913</td>\n",
       "      <td>0.936850</td>\n",
       "      <td>1.430588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-0.148891</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>-0.689363</td>\n",
       "      <td>1.198866</td>\n",
       "      <td>-0.569240</td>\n",
       "      <td>0.731546</td>\n",
       "      <td>0.918346</td>\n",
       "      <td>0.935032</td>\n",
       "      <td>1.419848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.205765</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>-0.746341</td>\n",
       "      <td>1.200147</td>\n",
       "      <td>-0.597022</td>\n",
       "      <td>0.723600</td>\n",
       "      <td>0.910778</td>\n",
       "      <td>0.935266</td>\n",
       "      <td>1.409108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.262638</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>-0.811207</td>\n",
       "      <td>1.201428</td>\n",
       "      <td>-0.624803</td>\n",
       "      <td>0.715654</td>\n",
       "      <td>0.903211</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>1.398368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.319512</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>-0.838113</td>\n",
       "      <td>1.202708</td>\n",
       "      <td>-0.652584</td>\n",
       "      <td>0.707708</td>\n",
       "      <td>0.895643</td>\n",
       "      <td>0.944453</td>\n",
       "      <td>1.387628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rio Grande do Sul - Desemprego  \\\n",
       "0                          1.274013   \n",
       "1                          1.259068   \n",
       "2                          1.244123   \n",
       "3                          1.229178   \n",
       "4                          1.214233   \n",
       "..                              ...   \n",
       "157                       -0.092018   \n",
       "158                       -0.148891   \n",
       "159                       -0.205765   \n",
       "160                       -0.262638   \n",
       "161                       -0.319512   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     Rio Grande Do Sul - Produção de Cimento (t)  \\\n",
       "0                                      -0.577787   \n",
       "1                                      -0.629575   \n",
       "2                                      -0.640416   \n",
       "3                                      -0.692102   \n",
       "4                                      -0.746144   \n",
       "..                                           ...   \n",
       "157                                    -0.647118   \n",
       "158                                    -0.689363   \n",
       "159                                    -0.746341   \n",
       "160                                    -0.811207   \n",
       "161                                    -0.838113   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Estadual  \\\n",
       "0                             -1.677139   \n",
       "1                             -1.660252   \n",
       "2                             -1.643365   \n",
       "3                             -1.626477   \n",
       "4                             -1.609590   \n",
       "..                                  ...   \n",
       "157                            1.197586   \n",
       "158                            1.198866   \n",
       "159                            1.200147   \n",
       "160                            1.201428   \n",
       "161                            1.202708   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Construção Civil  \\\n",
       "0                                     -1.973850   \n",
       "1                                     -1.934055   \n",
       "2                                     -1.894260   \n",
       "3                                     -1.854466   \n",
       "4                                     -1.814671   \n",
       "..                                          ...   \n",
       "157                                   -0.541459   \n",
       "158                                   -0.569240   \n",
       "159                                   -0.597022   \n",
       "160                                   -0.624803   \n",
       "161                                   -0.652584   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Per Capita  \\\n",
       "0                               -2.280022   \n",
       "1                               -2.253080   \n",
       "2                               -2.226138   \n",
       "3                               -2.199196   \n",
       "4                               -2.172254   \n",
       "..                                    ...   \n",
       "157                              0.739492   \n",
       "158                              0.731546   \n",
       "159                              0.723600   \n",
       "160                              0.715654   \n",
       "161                              0.707708   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Preços de Mercado  Rio Grande do Sul - value  \\\n",
       "0                                      -2.069914                  -1.362004   \n",
       "1                                      -2.045065                  -1.371141   \n",
       "2                                      -2.020217                  -1.382062   \n",
       "3                                      -1.995368                  -1.392283   \n",
       "4                                      -1.970520                  -1.404146   \n",
       "..                                           ...                        ...   \n",
       "157                                     0.925913                   0.936850   \n",
       "158                                     0.918346                   0.935032   \n",
       "159                                     0.910778                   0.935266   \n",
       "160                                     0.903211                   0.937596   \n",
       "161                                     0.895643                   0.944453   \n",
       "\n",
       "     Rio Grande do Sul - IDH  \n",
       "0                  -1.691101  \n",
       "1                  -1.675868  \n",
       "2                  -1.660635  \n",
       "3                  -1.645402  \n",
       "4                  -1.630170  \n",
       "..                       ...  \n",
       "157                 1.430588  \n",
       "158                 1.419848  \n",
       "159                 1.409108  \n",
       "160                 1.398368  \n",
       "161                 1.387628  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      174.261\n",
       "1      164.909\n",
       "2      202.662\n",
       "3      174.149\n",
       "4      159.955\n",
       "        ...   \n",
       "157    196.675\n",
       "158    251.395\n",
       "159    199.081\n",
       "160    220.793\n",
       "161    211.546\n",
       "Name: Rio Grande Do Sul - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rio Grande do Sul - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rio Grande Do Sul - Produção de Cimento (t)</th>\n",
       "      <th>Rio Grande do Sul - PIB - Estadual</th>\n",
       "      <th>Rio Grande do Sul - PIB - Construção Civil</th>\n",
       "      <th>Rio Grande do Sul - PIB - Per Capita</th>\n",
       "      <th>Rio Grande do Sul - PIB - Preços de Mercado</th>\n",
       "      <th>Rio Grande do Sul - value</th>\n",
       "      <th>Rio Grande do Sul - IDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-0.376385</td>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>-0.909322</td>\n",
       "      <td>1.203989</td>\n",
       "      <td>-0.680365</td>\n",
       "      <td>0.699762</td>\n",
       "      <td>0.888076</td>\n",
       "      <td>0.953539</td>\n",
       "      <td>1.376889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.433259</td>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>-0.941615</td>\n",
       "      <td>1.205269</td>\n",
       "      <td>-0.708146</td>\n",
       "      <td>0.691816</td>\n",
       "      <td>0.880509</td>\n",
       "      <td>0.972469</td>\n",
       "      <td>1.366149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-0.490132</td>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>-0.987957</td>\n",
       "      <td>1.206550</td>\n",
       "      <td>-0.735928</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.872941</td>\n",
       "      <td>0.991650</td>\n",
       "      <td>1.355409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-0.547006</td>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>-1.017508</td>\n",
       "      <td>1.207830</td>\n",
       "      <td>-0.763709</td>\n",
       "      <td>0.675925</td>\n",
       "      <td>0.865374</td>\n",
       "      <td>1.020849</td>\n",
       "      <td>1.344669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.603879</td>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>-1.040475</td>\n",
       "      <td>1.209111</td>\n",
       "      <td>-0.791490</td>\n",
       "      <td>0.667979</td>\n",
       "      <td>0.857806</td>\n",
       "      <td>1.045546</td>\n",
       "      <td>1.333929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-0.660753</td>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>-1.083059</td>\n",
       "      <td>1.210392</td>\n",
       "      <td>-0.819271</td>\n",
       "      <td>0.660033</td>\n",
       "      <td>0.850239</td>\n",
       "      <td>1.075359</td>\n",
       "      <td>1.323189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-0.717627</td>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>-1.125192</td>\n",
       "      <td>1.211672</td>\n",
       "      <td>-0.847052</td>\n",
       "      <td>0.652087</td>\n",
       "      <td>0.842671</td>\n",
       "      <td>1.100640</td>\n",
       "      <td>1.312450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-0.734343</td>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>-1.157418</td>\n",
       "      <td>1.208369</td>\n",
       "      <td>-0.845049</td>\n",
       "      <td>0.644635</td>\n",
       "      <td>0.833290</td>\n",
       "      <td>1.128617</td>\n",
       "      <td>1.290412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-0.751060</td>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>-1.173773</td>\n",
       "      <td>1.205067</td>\n",
       "      <td>-0.843045</td>\n",
       "      <td>0.637182</td>\n",
       "      <td>0.823909</td>\n",
       "      <td>1.152032</td>\n",
       "      <td>1.268375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-0.767777</td>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>-1.209404</td>\n",
       "      <td>1.201764</td>\n",
       "      <td>-0.841042</td>\n",
       "      <td>0.629730</td>\n",
       "      <td>0.814528</td>\n",
       "      <td>1.175722</td>\n",
       "      <td>1.246337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-0.784494</td>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>-1.233079</td>\n",
       "      <td>1.198462</td>\n",
       "      <td>-0.839038</td>\n",
       "      <td>0.622277</td>\n",
       "      <td>0.805147</td>\n",
       "      <td>1.204828</td>\n",
       "      <td>1.224300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-0.801211</td>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>-1.256156</td>\n",
       "      <td>1.195159</td>\n",
       "      <td>-0.837035</td>\n",
       "      <td>0.614825</td>\n",
       "      <td>0.795766</td>\n",
       "      <td>1.229669</td>\n",
       "      <td>1.202262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-0.817928</td>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>-1.264146</td>\n",
       "      <td>1.191856</td>\n",
       "      <td>-0.835032</td>\n",
       "      <td>0.607372</td>\n",
       "      <td>0.786385</td>\n",
       "      <td>1.255047</td>\n",
       "      <td>1.180225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-0.834645</td>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>-1.279820</td>\n",
       "      <td>1.188554</td>\n",
       "      <td>-0.833028</td>\n",
       "      <td>0.599920</td>\n",
       "      <td>0.777004</td>\n",
       "      <td>1.280987</td>\n",
       "      <td>1.158187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-0.851362</td>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>-1.324559</td>\n",
       "      <td>1.185251</td>\n",
       "      <td>-0.831025</td>\n",
       "      <td>0.592467</td>\n",
       "      <td>0.767623</td>\n",
       "      <td>1.309954</td>\n",
       "      <td>1.136149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-0.868079</td>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>-1.352090</td>\n",
       "      <td>1.181948</td>\n",
       "      <td>-0.829021</td>\n",
       "      <td>0.585015</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>1.339484</td>\n",
       "      <td>1.114112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-0.884796</td>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>-1.365774</td>\n",
       "      <td>1.178646</td>\n",
       "      <td>-0.827018</td>\n",
       "      <td>0.577562</td>\n",
       "      <td>0.748861</td>\n",
       "      <td>1.362236</td>\n",
       "      <td>1.092074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-0.901513</td>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>-1.392429</td>\n",
       "      <td>1.175343</td>\n",
       "      <td>-0.825014</td>\n",
       "      <td>0.570110</td>\n",
       "      <td>0.739480</td>\n",
       "      <td>1.385449</td>\n",
       "      <td>1.070037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-0.918230</td>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>-1.402793</td>\n",
       "      <td>1.172040</td>\n",
       "      <td>-0.823011</td>\n",
       "      <td>0.562657</td>\n",
       "      <td>0.730099</td>\n",
       "      <td>1.411581</td>\n",
       "      <td>1.047999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-0.925157</td>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>-1.411243</td>\n",
       "      <td>1.159352</td>\n",
       "      <td>-0.815174</td>\n",
       "      <td>0.535753</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>1.438313</td>\n",
       "      <td>1.013637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-0.932085</td>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>-1.439081</td>\n",
       "      <td>1.146663</td>\n",
       "      <td>-0.807338</td>\n",
       "      <td>0.508848</td>\n",
       "      <td>0.683849</td>\n",
       "      <td>1.458302</td>\n",
       "      <td>0.979275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-0.939012</td>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>-1.464344</td>\n",
       "      <td>1.133974</td>\n",
       "      <td>-0.799502</td>\n",
       "      <td>0.481943</td>\n",
       "      <td>0.660723</td>\n",
       "      <td>1.478736</td>\n",
       "      <td>0.944913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-0.945939</td>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>-1.463090</td>\n",
       "      <td>1.121285</td>\n",
       "      <td>-0.791666</td>\n",
       "      <td>0.455038</td>\n",
       "      <td>0.637598</td>\n",
       "      <td>1.499582</td>\n",
       "      <td>0.910551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-0.952867</td>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>-1.450395</td>\n",
       "      <td>1.108597</td>\n",
       "      <td>-0.783830</td>\n",
       "      <td>0.428133</td>\n",
       "      <td>0.614473</td>\n",
       "      <td>1.520807</td>\n",
       "      <td>0.876188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-0.959794</td>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>-1.469658</td>\n",
       "      <td>1.095908</td>\n",
       "      <td>-0.775993</td>\n",
       "      <td>0.401228</td>\n",
       "      <td>0.591347</td>\n",
       "      <td>1.547201</td>\n",
       "      <td>0.841826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-0.966721</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-1.420132</td>\n",
       "      <td>1.083219</td>\n",
       "      <td>-0.768157</td>\n",
       "      <td>0.374323</td>\n",
       "      <td>0.568222</td>\n",
       "      <td>1.591021</td>\n",
       "      <td>0.807464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-0.973649</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>-1.417824</td>\n",
       "      <td>1.070530</td>\n",
       "      <td>-0.760321</td>\n",
       "      <td>0.347418</td>\n",
       "      <td>0.545097</td>\n",
       "      <td>1.635348</td>\n",
       "      <td>0.773102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-0.980576</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>-1.381727</td>\n",
       "      <td>1.057841</td>\n",
       "      <td>-0.752485</td>\n",
       "      <td>0.320513</td>\n",
       "      <td>0.521971</td>\n",
       "      <td>1.689944</td>\n",
       "      <td>0.738739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-0.987503</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-1.359803</td>\n",
       "      <td>1.045153</td>\n",
       "      <td>-0.744649</td>\n",
       "      <td>0.293608</td>\n",
       "      <td>0.498846</td>\n",
       "      <td>1.737741</td>\n",
       "      <td>0.704377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-0.994431</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-1.370922</td>\n",
       "      <td>1.032464</td>\n",
       "      <td>-0.736812</td>\n",
       "      <td>0.266704</td>\n",
       "      <td>0.475721</td>\n",
       "      <td>1.781133</td>\n",
       "      <td>0.670015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rio Grande do Sul - Desemprego  \\\n",
       "162                       -0.376385   \n",
       "163                       -0.433259   \n",
       "164                       -0.490132   \n",
       "165                       -0.547006   \n",
       "166                       -0.603879   \n",
       "167                       -0.660753   \n",
       "168                       -0.717627   \n",
       "169                       -0.734343   \n",
       "170                       -0.751060   \n",
       "171                       -0.767777   \n",
       "172                       -0.784494   \n",
       "173                       -0.801211   \n",
       "174                       -0.817928   \n",
       "175                       -0.834645   \n",
       "176                       -0.851362   \n",
       "177                       -0.868079   \n",
       "178                       -0.884796   \n",
       "179                       -0.901513   \n",
       "180                       -0.918230   \n",
       "181                       -0.925157   \n",
       "182                       -0.932085   \n",
       "183                       -0.939012   \n",
       "184                       -0.945939   \n",
       "185                       -0.952867   \n",
       "186                       -0.959794   \n",
       "187                       -0.966721   \n",
       "188                       -0.973649   \n",
       "189                       -0.980576   \n",
       "190                       -0.987503   \n",
       "191                       -0.994431   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162                                         -0.601510   \n",
       "163                                         -0.786068   \n",
       "164                                         -0.830387   \n",
       "165                                         -0.801089   \n",
       "166                                         -0.959917   \n",
       "167                                         -1.022309   \n",
       "168                                         -1.074401   \n",
       "169                                         -1.119597   \n",
       "170                                         -1.078648   \n",
       "171                                         -1.055426   \n",
       "172                                         -1.101053   \n",
       "173                                         -1.211370   \n",
       "174                                         -1.157198   \n",
       "175                                         -1.223444   \n",
       "176                                         -1.311519   \n",
       "177                                         -1.362602   \n",
       "178                                         -1.380125   \n",
       "179                                         -1.219296   \n",
       "180                                         -1.300284   \n",
       "181                                         -1.336476   \n",
       "182                                         -1.415774   \n",
       "183                                         -1.526021   \n",
       "184                                         -1.681806   \n",
       "185                                         -1.735167   \n",
       "186                                         -1.962315   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "162                                0.763466  -1.213929   \n",
       "163                                0.752299  -1.292173   \n",
       "164                                0.741131  -1.324219   \n",
       "165                                0.729964  -1.344446   \n",
       "166                                0.718796  -1.381638   \n",
       "167                                0.707629  -1.411208   \n",
       "168                                0.696461  -1.412953   \n",
       "169                                0.681823  -1.491464   \n",
       "170                                0.667184  -1.573805   \n",
       "171                                0.652545  -1.564950   \n",
       "172                                0.637906  -1.581584   \n",
       "173                                0.623268  -1.565976   \n",
       "174                                0.608629  -1.648556   \n",
       "175                                0.593990  -1.650049   \n",
       "176                                0.579351  -1.653957   \n",
       "177                                0.564713  -1.652572   \n",
       "178                                0.550074  -1.715349   \n",
       "179                                0.535435  -1.750917   \n",
       "180                                0.520796  -1.718448   \n",
       "181                                0.501996  -1.733426   \n",
       "182                                0.483195  -1.729362   \n",
       "183                                0.464395  -1.748544   \n",
       "184                                0.445594  -1.778060   \n",
       "185                                0.426794  -1.773710   \n",
       "186                                0.407993  -1.757007   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Rio Grande Do Sul - Produção de Cimento (t)  \\\n",
       "162                                    -0.909322   \n",
       "163                                    -0.941615   \n",
       "164                                    -0.987957   \n",
       "165                                    -1.017508   \n",
       "166                                    -1.040475   \n",
       "167                                    -1.083059   \n",
       "168                                    -1.125192   \n",
       "169                                    -1.157418   \n",
       "170                                    -1.173773   \n",
       "171                                    -1.209404   \n",
       "172                                    -1.233079   \n",
       "173                                    -1.256156   \n",
       "174                                    -1.264146   \n",
       "175                                    -1.279820   \n",
       "176                                    -1.324559   \n",
       "177                                    -1.352090   \n",
       "178                                    -1.365774   \n",
       "179                                    -1.392429   \n",
       "180                                    -1.402793   \n",
       "181                                    -1.411243   \n",
       "182                                    -1.439081   \n",
       "183                                    -1.464344   \n",
       "184                                    -1.463090   \n",
       "185                                    -1.450395   \n",
       "186                                    -1.469658   \n",
       "187                                    -1.420132   \n",
       "188                                    -1.417824   \n",
       "189                                    -1.381727   \n",
       "190                                    -1.359803   \n",
       "191                                    -1.370922   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Estadual  \\\n",
       "162                            1.203989   \n",
       "163                            1.205269   \n",
       "164                            1.206550   \n",
       "165                            1.207830   \n",
       "166                            1.209111   \n",
       "167                            1.210392   \n",
       "168                            1.211672   \n",
       "169                            1.208369   \n",
       "170                            1.205067   \n",
       "171                            1.201764   \n",
       "172                            1.198462   \n",
       "173                            1.195159   \n",
       "174                            1.191856   \n",
       "175                            1.188554   \n",
       "176                            1.185251   \n",
       "177                            1.181948   \n",
       "178                            1.178646   \n",
       "179                            1.175343   \n",
       "180                            1.172040   \n",
       "181                            1.159352   \n",
       "182                            1.146663   \n",
       "183                            1.133974   \n",
       "184                            1.121285   \n",
       "185                            1.108597   \n",
       "186                            1.095908   \n",
       "187                            1.083219   \n",
       "188                            1.070530   \n",
       "189                            1.057841   \n",
       "190                            1.045153   \n",
       "191                            1.032464   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Construção Civil  \\\n",
       "162                                   -0.680365   \n",
       "163                                   -0.708146   \n",
       "164                                   -0.735928   \n",
       "165                                   -0.763709   \n",
       "166                                   -0.791490   \n",
       "167                                   -0.819271   \n",
       "168                                   -0.847052   \n",
       "169                                   -0.845049   \n",
       "170                                   -0.843045   \n",
       "171                                   -0.841042   \n",
       "172                                   -0.839038   \n",
       "173                                   -0.837035   \n",
       "174                                   -0.835032   \n",
       "175                                   -0.833028   \n",
       "176                                   -0.831025   \n",
       "177                                   -0.829021   \n",
       "178                                   -0.827018   \n",
       "179                                   -0.825014   \n",
       "180                                   -0.823011   \n",
       "181                                   -0.815174   \n",
       "182                                   -0.807338   \n",
       "183                                   -0.799502   \n",
       "184                                   -0.791666   \n",
       "185                                   -0.783830   \n",
       "186                                   -0.775993   \n",
       "187                                   -0.768157   \n",
       "188                                   -0.760321   \n",
       "189                                   -0.752485   \n",
       "190                                   -0.744649   \n",
       "191                                   -0.736812   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Per Capita  \\\n",
       "162                              0.699762   \n",
       "163                              0.691816   \n",
       "164                              0.683871   \n",
       "165                              0.675925   \n",
       "166                              0.667979   \n",
       "167                              0.660033   \n",
       "168                              0.652087   \n",
       "169                              0.644635   \n",
       "170                              0.637182   \n",
       "171                              0.629730   \n",
       "172                              0.622277   \n",
       "173                              0.614825   \n",
       "174                              0.607372   \n",
       "175                              0.599920   \n",
       "176                              0.592467   \n",
       "177                              0.585015   \n",
       "178                              0.577562   \n",
       "179                              0.570110   \n",
       "180                              0.562657   \n",
       "181                              0.535753   \n",
       "182                              0.508848   \n",
       "183                              0.481943   \n",
       "184                              0.455038   \n",
       "185                              0.428133   \n",
       "186                              0.401228   \n",
       "187                              0.374323   \n",
       "188                              0.347418   \n",
       "189                              0.320513   \n",
       "190                              0.293608   \n",
       "191                              0.266704   \n",
       "\n",
       "     Rio Grande do Sul - PIB - Preços de Mercado  Rio Grande do Sul - value  \\\n",
       "162                                     0.888076                   0.953539   \n",
       "163                                     0.880509                   0.972469   \n",
       "164                                     0.872941                   0.991650   \n",
       "165                                     0.865374                   1.020849   \n",
       "166                                     0.857806                   1.045546   \n",
       "167                                     0.850239                   1.075359   \n",
       "168                                     0.842671                   1.100640   \n",
       "169                                     0.833290                   1.128617   \n",
       "170                                     0.823909                   1.152032   \n",
       "171                                     0.814528                   1.175722   \n",
       "172                                     0.805147                   1.204828   \n",
       "173                                     0.795766                   1.229669   \n",
       "174                                     0.786385                   1.255047   \n",
       "175                                     0.777004                   1.280987   \n",
       "176                                     0.767623                   1.309954   \n",
       "177                                     0.758242                   1.339484   \n",
       "178                                     0.748861                   1.362236   \n",
       "179                                     0.739480                   1.385449   \n",
       "180                                     0.730099                   1.411581   \n",
       "181                                     0.706974                   1.438313   \n",
       "182                                     0.683849                   1.458302   \n",
       "183                                     0.660723                   1.478736   \n",
       "184                                     0.637598                   1.499582   \n",
       "185                                     0.614473                   1.520807   \n",
       "186                                     0.591347                   1.547201   \n",
       "187                                     0.568222                   1.591021   \n",
       "188                                     0.545097                   1.635348   \n",
       "189                                     0.521971                   1.689944   \n",
       "190                                     0.498846                   1.737741   \n",
       "191                                     0.475721                   1.781133   \n",
       "\n",
       "     Rio Grande do Sul - IDH  \n",
       "162                 1.376889  \n",
       "163                 1.366149  \n",
       "164                 1.355409  \n",
       "165                 1.344669  \n",
       "166                 1.333929  \n",
       "167                 1.323189  \n",
       "168                 1.312450  \n",
       "169                 1.290412  \n",
       "170                 1.268375  \n",
       "171                 1.246337  \n",
       "172                 1.224300  \n",
       "173                 1.202262  \n",
       "174                 1.180225  \n",
       "175                 1.158187  \n",
       "176                 1.136149  \n",
       "177                 1.114112  \n",
       "178                 1.092074  \n",
       "179                 1.070037  \n",
       "180                 1.047999  \n",
       "181                 1.013637  \n",
       "182                 0.979275  \n",
       "183                 0.944913  \n",
       "184                 0.910551  \n",
       "185                 0.876188  \n",
       "186                 0.841826  \n",
       "187                 0.807464  \n",
       "188                 0.773102  \n",
       "189                 0.738739  \n",
       "190                 0.704377  \n",
       "191                 0.670015  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    244.680\n",
       "163    252.183\n",
       "164    249.403\n",
       "165    208.299\n",
       "166    238.414\n",
       "167    213.179\n",
       "168    221.534\n",
       "169    212.139\n",
       "170    228.994\n",
       "171    226.827\n",
       "172    186.855\n",
       "173    253.021\n",
       "174    194.988\n",
       "175    244.406\n",
       "176    201.372\n",
       "177    251.369\n",
       "178    242.782\n",
       "179    201.288\n",
       "180    226.547\n",
       "181    228.500\n",
       "182    223.896\n",
       "183    234.132\n",
       "184    207.586\n",
       "185    228.583\n",
       "186    234.565\n",
       "187    249.519\n",
       "188    230.086\n",
       "189    233.136\n",
       "190    233.800\n",
       "191    223.214\n",
       "Name: Rio Grande Do Sul - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "#     train, train_val = validation_splitter(train_input, 8)\n",
    "#     target,target_val = validation_splitter(train_target, 8)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train_input, \n",
    "                        train_target, \n",
    "                        epochs=10000,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1790102656, 151355657, 3576083982, 1398084632, 4099399470, 9990582, 854507576, 1304042801, 2202375554, 1248764028, 2828668761, 1758614753, 403069063, 2056082736, 1692249364, 4102641171, 2546655372, 2627101091, 1925135277, 2397082750, 2729439295, 1078423881, 1561188886, 4269907804, 1988894673]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 33443.1953125\n",
      "winner_seed: 1790102656\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 35682.6015625\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 47971.71875\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 954.5722045898438\n",
      "winner_seed: 1398084632\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 4154.68359375\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 66926.953125\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 31430.224609375\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 17:59:51.966337: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 1418.941650390625\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 48369.0\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 24542.88671875\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 51664.375\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 42983.67578125\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 314.195068359375\n",
      "winner_seed: 403069063\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 36009.46484375\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 13663.6796875\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 14244.6748046875\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 48368.65625\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 66097.296875\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 37000.72265625\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 18:06:44.192480: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 73321.6953125\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 53892.4921875\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 18:07:52.494423: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 30812.08203125\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 45299.1640625\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 3850.033203125\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 64862.41796875\n",
      "\n",
      "\n",
      "final_seed: 403069063\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 57694.2344 - val_loss: 60628.8594\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52362.3477 - val_loss: 35821.8477\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45410.7578 - val_loss: 43446.7891\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52019.3672 - val_loss: 3630.3198\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 38942.8398 - val_loss: 10932.9355\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 34312.6914 - val_loss: 21837.4004\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30380.0957 - val_loss: 49817.4531\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30372.2617 - val_loss: 2058.1643\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27513.4336 - val_loss: 843.0748\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29778.2207 - val_loss: 9740.3037\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20485.1953 - val_loss: 3165.1189\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20723.0957 - val_loss: 19795.4492\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18362.0215 - val_loss: 4150.3179\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16403.0957 - val_loss: 1617.4760\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14445.5410 - val_loss: 10702.6201\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13789.7119 - val_loss: 2371.4202\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12268.9434 - val_loss: 3126.4934\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10609.0820 - val_loss: 2445.6931\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9923.5723 - val_loss: 2623.0332\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8943.2432 - val_loss: 4275.6289\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8008.5396 - val_loss: 283.8358\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8035.1675 - val_loss: 286.6829\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7254.9800 - val_loss: 1028.7650\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6011.4463 - val_loss: 289.5793\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6242.5190 - val_loss: 677.7549\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5317.2515 - val_loss: 351.6446\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4544.6079 - val_loss: 486.1999\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4145.9580 - val_loss: 774.4240\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4046.1768 - val_loss: 312.9797\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3513.5642 - val_loss: 614.0835\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3703.2371 - val_loss: 936.7506\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3128.1833 - val_loss: 1532.1031\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3077.5332 - val_loss: 465.1794\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2787.7197 - val_loss: 844.6534\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2404.3384 - val_loss: 977.1993\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2235.2178 - val_loss: 333.3221\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2106.6936 - val_loss: 1441.7826\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2019.8948 - val_loss: 1241.4734\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2038.1390 - val_loss: 399.0100\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1731.6548 - val_loss: 302.9634\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1698.3997 - val_loss: 800.2610\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1614.6749 - val_loss: 286.5635\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1464.0240 - val_loss: 621.7549\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1362.1416 - val_loss: 1397.6248\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1316.5687 - val_loss: 430.2742\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1364.8083 - val_loss: 660.7322\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1128.8657 - val_loss: 839.0375\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 934.8668 - val_loss: 540.2476\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 780.5338 - val_loss: 1157.0356\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 700.8435 - val_loss: 2159.6016\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 644.3669 - val_loss: 1541.2211\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 490.9946 - val_loss: 1400.8976\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 505.4902 - val_loss: 1672.4333\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 479.9124 - val_loss: 2973.2324\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 443.8854 - val_loss: 1687.9185\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 396.5351 - val_loss: 2025.5248\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.5259 - val_loss: 1357.8868\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 340.9032 - val_loss: 1516.4852\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 428.5016 - val_loss: 2086.3262\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 364.8515 - val_loss: 1505.8434\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 337.1321 - val_loss: 682.6392\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 416.8903 - val_loss: 857.7152\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 402.1144 - val_loss: 497.3042\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 412.3098 - val_loss: 1548.4668\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 366.0067 - val_loss: 521.3196\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.8792 - val_loss: 807.0699\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 442.1829 - val_loss: 844.8956\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.5293 - val_loss: 1212.6250\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 294.2418 - val_loss: 1132.0785\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 474.1615 - val_loss: 2329.8892\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 335.3682 - val_loss: 2431.9570\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 340.9771 - val_loss: 1062.8644\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 363.0805 - val_loss: 1143.0070\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 464.2552 - val_loss: 1495.1029\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 328.5979 - val_loss: 1244.3693\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 349.6381 - val_loss: 1761.5656\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 285.4282 - val_loss: 1635.6488\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 275.5001 - val_loss: 1206.7020\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 275.0416 - val_loss: 1569.7794\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 275.5730 - val_loss: 1819.4697\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 278.1313 - val_loss: 1556.5338\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.6769 - val_loss: 2401.0015\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 380.7807 - val_loss: 1234.7076\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 471.2283 - val_loss: 1738.8525\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 329.2014 - val_loss: 1182.2783\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 363.0654 - val_loss: 1148.9174\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 275.4034 - val_loss: 2066.8672\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 282.2545 - val_loss: 1430.3733\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 293.7568 - val_loss: 1570.1338\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 261.4532 - val_loss: 1201.5248\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 274.8497 - val_loss: 1840.9960\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 255.9993 - val_loss: 1914.9409\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 270.5639 - val_loss: 1219.1202\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 282.8922 - val_loss: 1187.4219\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 294.2251 - val_loss: 1989.4172\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 267.1208 - val_loss: 1578.3889\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 263.6414 - val_loss: 1037.4673\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 298.2554 - val_loss: 2457.7126\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 278.7298 - val_loss: 1407.9789\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.5646 - val_loss: 1707.2866\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 275.7116 - val_loss: 1274.4462\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 279.7795 - val_loss: 1910.6226\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 296.7236 - val_loss: 826.7468\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 292.2211 - val_loss: 1316.2238\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 251.3594 - val_loss: 1052.7737\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 263.0649 - val_loss: 1079.0682\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 262.9252 - val_loss: 1194.0544\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 326.5197 - val_loss: 2094.4993\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 274.3862 - val_loss: 1891.5038\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 275.7992 - val_loss: 1198.5981\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 271.2161 - val_loss: 1259.1221\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.2766 - val_loss: 1491.2018\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 267.2368 - val_loss: 1293.2736\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 273.7656 - val_loss: 1735.2382\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 265.0641 - val_loss: 1206.9689\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 302.1390 - val_loss: 1810.7654\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 276.9588 - val_loss: 1733.5596\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245.9804 - val_loss: 1557.8086\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 262.4374 - val_loss: 1004.9703\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 277.3092 - val_loss: 1612.4664\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 253.0786 - val_loss: 1999.5367\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.1952 - val_loss: 1271.2853\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 282.4600 - val_loss: 1275.6346\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 277.5173 - val_loss: 732.3873\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.1576 - val_loss: 1529.1232\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 267.5855 - val_loss: 892.7153\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 271.2740 - val_loss: 2001.1808\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.2265 - val_loss: 1634.5863\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 270.0760 - val_loss: 1125.1555\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 310.6442 - val_loss: 1494.2438\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 259.4975 - val_loss: 1964.0039\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 271.0596 - val_loss: 1679.5737\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 268.9237 - val_loss: 1375.6486\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 270.2564 - val_loss: 1328.5060\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 278.6367 - val_loss: 1090.6205\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 269.7358 - val_loss: 1875.0255\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 289.1593 - val_loss: 1322.0105\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 319.7923 - val_loss: 1766.3291\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 284.2322 - val_loss: 2168.4260\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 281.7121 - val_loss: 2291.4141\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 268.3230 - val_loss: 1173.7559\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 267.8882 - val_loss: 1929.2190\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 324.8061 - val_loss: 2105.4351\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.3597 - val_loss: 820.2714\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.9514 - val_loss: 1896.4766\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 265.9500 - val_loss: 1520.5117\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 283.6146 - val_loss: 1083.4863\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 276.9180 - val_loss: 1482.0166\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 251.8986 - val_loss: 1547.4763\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.9172 - val_loss: 1966.8727\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 274.0337 - val_loss: 1542.8010\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 287.0980 - val_loss: 1501.4187\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.8626 - val_loss: 1930.7229\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 265.6421 - val_loss: 1756.1821\n",
      "Epoch 155/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 266.0916 - val_loss: 1958.2817\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 262.2174 - val_loss: 1404.2802\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 296.9482 - val_loss: 1299.2500\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 297.5364 - val_loss: 1170.3308\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 292.0518 - val_loss: 1724.3141\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 271.2528 - val_loss: 1420.6588\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 282.2485 - val_loss: 1705.8157\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.2555 - val_loss: 2430.6985\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 275.5690 - val_loss: 1286.4933\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 288.9530 - val_loss: 1093.4000\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 278.0741 - val_loss: 2304.2520\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 264.6280 - val_loss: 1948.0381\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 278.1725 - val_loss: 1549.2341\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 255.5876 - val_loss: 1695.4026\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.1432 - val_loss: 1587.1279\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 261.3951 - val_loss: 1595.8435\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 272.9080 - val_loss: 1281.2510\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 274.4456 - val_loss: 2378.9741\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.7101 - val_loss: 1785.0558\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.6185 - val_loss: 1885.2156\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.5173 - val_loss: 1579.1940\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.7114 - val_loss: 1721.2739\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 231.0907 - val_loss: 1551.1587\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 239.9446 - val_loss: 1767.7170\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 288.3929 - val_loss: 2029.2404\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.6749 - val_loss: 1973.8083\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 285.7062 - val_loss: 1936.7516\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 313.6087 - val_loss: 1857.7181\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 255.8490 - val_loss: 1730.5992\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 250.9074 - val_loss: 1680.8584\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.4985 - val_loss: 2093.7507\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 285.1412 - val_loss: 2031.0570\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.0427 - val_loss: 1546.2385\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 269.3553 - val_loss: 1237.8539\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 312.8722 - val_loss: 1285.4558\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 258.2491 - val_loss: 1815.1754\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 282.5010 - val_loss: 829.8712\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 262.0081 - val_loss: 1417.6003\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 260.7940 - val_loss: 1667.0566\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 261.0187 - val_loss: 1327.5391\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 269.4048 - val_loss: 1238.6313\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 282.9962 - val_loss: 1278.6381\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 258.7628 - val_loss: 1708.5981\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.1445 - val_loss: 1786.9204\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 278.0885 - val_loss: 1574.1323\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 263.6100 - val_loss: 1769.7979\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 280.7360 - val_loss: 1320.9658\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 264.4761 - val_loss: 857.4131\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 339.6778 - val_loss: 1623.8531\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 268.5685 - val_loss: 1360.4685\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 275.5583 - val_loss: 1318.4126\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.9384 - val_loss: 1539.8427\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.2943 - val_loss: 1740.1359\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.5491 - val_loss: 1333.1277\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.0993 - val_loss: 965.6682\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.7081 - val_loss: 1034.1407\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 275.8247 - val_loss: 1428.7791\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.8593 - val_loss: 1351.7721\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.1730 - val_loss: 1233.8871\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.0418 - val_loss: 1661.5656\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.2461 - val_loss: 1266.5968\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.5350 - val_loss: 1582.4712\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.9844 - val_loss: 1260.3374\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 304.8871 - val_loss: 1428.5649\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 259.0513 - val_loss: 921.8348\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 259.1501 - val_loss: 1665.0355\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 279.4498 - val_loss: 1251.5740\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 267.7650 - val_loss: 1674.5067\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 249.5602 - val_loss: 1271.6055\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 227.4655 - val_loss: 1405.6058\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.6270 - val_loss: 1596.7396\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 233.9287 - val_loss: 1607.8728\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.5776 - val_loss: 1322.4617\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.8172 - val_loss: 1067.4817\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 271.2320 - val_loss: 1064.9172\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.5822 - val_loss: 1555.2284\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 271.9955 - val_loss: 1536.0851\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.8707 - val_loss: 1564.0210\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.8280 - val_loss: 1449.8275\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 236.0319 - val_loss: 1208.5719\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.3325 - val_loss: 1473.8634\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.0117 - val_loss: 1342.2224\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.9107 - val_loss: 1220.9355\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 276.0896 - val_loss: 1324.1940\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.2453 - val_loss: 1370.4185\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 270.0189 - val_loss: 1461.5798\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.8882 - val_loss: 1089.7039\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 267.1230 - val_loss: 1401.2450\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.6896 - val_loss: 747.5118\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.6498 - val_loss: 1052.0024\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 249.4952 - val_loss: 1270.6136\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.7867 - val_loss: 1077.0229\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.2218 - val_loss: 1182.4408\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221.1425 - val_loss: 1723.7039\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 220.8600 - val_loss: 1221.4030\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 246.0818 - val_loss: 1472.8488\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 216.6587 - val_loss: 1177.6466\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 229.1389 - val_loss: 786.7798\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 255.1040 - val_loss: 1271.1359\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.4522 - val_loss: 1618.1379\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 266.7312 - val_loss: 1616.3479\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.6578 - val_loss: 1684.5216\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245.4949 - val_loss: 1761.1920\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.2891 - val_loss: 1744.0872\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.8966 - val_loss: 1816.3324\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.4213 - val_loss: 1790.1558\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.8510 - val_loss: 904.9372\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 230.0804 - val_loss: 1628.0382\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223.7097 - val_loss: 1329.3221\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 230.4721 - val_loss: 1512.8938\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 227.8145 - val_loss: 1149.0200\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 228.9947 - val_loss: 1300.4098\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 260.3459 - val_loss: 1256.9563\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.1276 - val_loss: 1212.5168\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 262.9252 - val_loss: 1300.6846\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.4783 - val_loss: 1470.3408\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.4244 - val_loss: 557.8866\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.8400 - val_loss: 1058.4880\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 220.6243 - val_loss: 1072.7194\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.8045 - val_loss: 1521.8051\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.9238 - val_loss: 1478.6533\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.3742 - val_loss: 1610.8885\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.7573 - val_loss: 1210.2152\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 269.1745 - val_loss: 1582.9268\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.7348 - val_loss: 1315.5518\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.2706 - val_loss: 1489.1403\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.8521 - val_loss: 1240.4856\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 242.5836 - val_loss: 1450.5306\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.6881 - val_loss: 1485.7981\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 250.4587 - val_loss: 1027.3656\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.3387 - val_loss: 1418.5175\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.7391 - val_loss: 1308.2274\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.6525 - val_loss: 1096.1390\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 258.0802 - val_loss: 1042.4619\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 242.5564 - val_loss: 1741.5835\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.1585 - val_loss: 820.0915\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 252.7764 - val_loss: 1419.0933\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 248.8060 - val_loss: 1588.4769\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 274.5166 - val_loss: 1558.1708\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 248.0018 - val_loss: 1151.6489\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 280.7047 - val_loss: 1003.8466\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 261.9727 - val_loss: 764.9744\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.2498 - val_loss: 1246.7269\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.3295 - val_loss: 987.2675\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.6497 - val_loss: 1635.7284\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.1059 - val_loss: 1486.7841\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.9985 - val_loss: 1452.5262\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 220.7495 - val_loss: 1460.8458\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.9929 - val_loss: 1130.9773\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 256.2954 - val_loss: 1442.1398\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 248.3660 - val_loss: 1116.5179\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.8613 - val_loss: 1310.1300\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.3464 - val_loss: 1445.7183\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 274.2662 - val_loss: 1609.0880\n",
      "Epoch 309/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 252.0975 - val_loss: 1607.2413\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 300.3772 - val_loss: 1553.9188\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 269.1984 - val_loss: 1275.1514\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 263.7887 - val_loss: 1309.1901\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 285.1822 - val_loss: 1228.4229\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 278.1650 - val_loss: 1445.5284\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.5631 - val_loss: 1382.7882\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 290.3789 - val_loss: 1388.2947\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 290.8592 - val_loss: 1449.0311\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 251.8263 - val_loss: 1345.8777\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.5866 - val_loss: 1446.3431\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.3631 - val_loss: 1002.0902\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 268.8155 - val_loss: 1223.6863\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.4097 - val_loss: 1624.5085\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.7278 - val_loss: 889.5374\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 239.2930 - val_loss: 1408.4855\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 334.4635 - val_loss: 872.5586\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 333.6999 - val_loss: 1146.4984\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 284.6774 - val_loss: 998.9387\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 271.3602 - val_loss: 1496.8319\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.7821 - val_loss: 1532.0667\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 255.9849 - val_loss: 1289.6013\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.2266 - val_loss: 1293.6390\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.9446 - val_loss: 1445.3751\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 251.3509 - val_loss: 1326.3287\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 277.4868 - val_loss: 1428.9695\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.3665 - val_loss: 1419.4037\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.2089 - val_loss: 1251.7471\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.5253 - val_loss: 1399.1483\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 232.5845 - val_loss: 1261.7163\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 225.4021 - val_loss: 1222.3517\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 238.3642 - val_loss: 1183.7975\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 277.8774 - val_loss: 1176.3762\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 265.0902 - val_loss: 1129.8275\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 271.8010 - val_loss: 894.8557\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 248.0127 - val_loss: 953.7567\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 270.9336 - val_loss: 1078.7726\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 266.3165 - val_loss: 1047.9418\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 267.7494 - val_loss: 1344.2094\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.1936 - val_loss: 1431.9707\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.3041 - val_loss: 1039.5925\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.8223 - val_loss: 1093.6233\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.2003 - val_loss: 1045.0619\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.3628 - val_loss: 1115.7220\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245.2783 - val_loss: 1687.7178\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 248.2343 - val_loss: 1551.6570\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.1120 - val_loss: 1157.6909\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.3433 - val_loss: 1374.8081\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.8716 - val_loss: 1169.3877\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.7825 - val_loss: 1321.6323\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.3474 - val_loss: 1076.4200\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 245.6272 - val_loss: 1155.1484\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245.2016 - val_loss: 1085.6458\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 260.5854 - val_loss: 1450.3868\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 297.7371 - val_loss: 1225.9863\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 267.9196 - val_loss: 1233.2321\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 258.4561 - val_loss: 1009.6835\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 279.0465 - val_loss: 1427.9172\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 258.0697 - val_loss: 853.8895\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.8195 - val_loss: 960.2272\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 309.9289 - val_loss: 989.4714\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.1073 - val_loss: 1413.9437\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 245.7229 - val_loss: 1352.5891\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 315.0717 - val_loss: 1232.9231\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 271.8898 - val_loss: 191.5765\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 301.0417 - val_loss: 1403.6042\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301.3458 - val_loss: 1499.8213\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.3058 - val_loss: 1227.6888\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 256.1909 - val_loss: 820.0646\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.3248 - val_loss: 1904.3463\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.7613 - val_loss: 1252.0128\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 274.2859 - val_loss: 1485.1981\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 281.1716 - val_loss: 1234.1484\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 277.7500 - val_loss: 1092.2236\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 263.2089 - val_loss: 1170.0040\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.4524 - val_loss: 910.8914\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.5670 - val_loss: 1333.9276\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.2803 - val_loss: 1576.9159\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.1940 - val_loss: 1377.0160\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.3320 - val_loss: 1790.8939\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.0616 - val_loss: 1103.3615\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 288.6420 - val_loss: 1358.9714\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.6046 - val_loss: 1112.7794\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 234.7209 - val_loss: 925.3509\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 226.0238 - val_loss: 1290.8180\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 242.1324 - val_loss: 1040.3800\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 235.7720 - val_loss: 921.0176\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.7124 - val_loss: 1125.0482\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.8115 - val_loss: 1440.2406\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.5732 - val_loss: 1256.3829\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 266.6447 - val_loss: 1182.8661\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.3264 - val_loss: 1279.6710\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.0943 - val_loss: 1644.7887\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.2592 - val_loss: 1380.6229\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.5290 - val_loss: 1532.7678\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.2503 - val_loss: 1169.7759\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.6554 - val_loss: 1525.3408\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 239.1521 - val_loss: 1449.3940\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 222.7573 - val_loss: 1490.8541\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 229.5716 - val_loss: 449.8937\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 255.3809 - val_loss: 857.5690\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.8896 - val_loss: 1253.5435\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.7031 - val_loss: 1872.4192\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223.5573 - val_loss: 1710.5432\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.4879 - val_loss: 1271.4438\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 255.4316 - val_loss: 1035.8895\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.0773 - val_loss: 818.8091\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 255.2925 - val_loss: 1069.3560\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.5175 - val_loss: 1041.5757\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 263.0469 - val_loss: 1444.1963\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.2456 - val_loss: 1237.4189\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.1543 - val_loss: 1126.8759\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 268.7919 - val_loss: 1554.3458\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.5197 - val_loss: 1205.7461\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.9398 - val_loss: 1026.5372\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.5397 - val_loss: 1265.0619\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.5235 - val_loss: 1339.9984\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.1037 - val_loss: 1222.4904\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 235.7302 - val_loss: 1168.7151\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 237.3103 - val_loss: 1051.7656\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.9775 - val_loss: 1314.1241\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.8972 - val_loss: 1288.8127\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.7714 - val_loss: 1419.7880\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.0655 - val_loss: 1543.1117\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.5815 - val_loss: 1247.9791\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.0752 - val_loss: 1012.3726\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.0578 - val_loss: 966.1523\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.6362 - val_loss: 1571.5062\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 218.7627 - val_loss: 1282.5188\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 217.4419 - val_loss: 1317.9287\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 216.3331 - val_loss: 1390.3710\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 251.6459 - val_loss: 1111.7959\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.0553 - val_loss: 1608.5752\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.3598 - val_loss: 1433.9641\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.1571 - val_loss: 1273.5695\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 213.5281 - val_loss: 1412.1362\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.8285 - val_loss: 1509.7394\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.4622 - val_loss: 1226.7085\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 235.2745 - val_loss: 1459.2421\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.6426 - val_loss: 1407.5225\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 218.0365 - val_loss: 1340.2416\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.3845 - val_loss: 1599.1875\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.4310 - val_loss: 1369.3865\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.7944 - val_loss: 1418.0891\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.2425 - val_loss: 1319.8844\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 223.6970 - val_loss: 1257.8018\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.2511 - val_loss: 968.2181\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 220.9124 - val_loss: 1126.9320\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 233.7311 - val_loss: 1020.9948\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 231.6062 - val_loss: 1403.5726\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.3340 - val_loss: 1574.6910\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.6262 - val_loss: 1402.7977\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.4709 - val_loss: 1131.9196\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 219.2221 - val_loss: 1058.1997\n",
      "Epoch 463/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 217.1038 - val_loss: 1002.9897\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221.5432 - val_loss: 1262.1476\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221.1649 - val_loss: 959.2180\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.5123 - val_loss: 1375.0604\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 241.7386 - val_loss: 1572.9575\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 224.8563 - val_loss: 1215.7365\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.1152 - val_loss: 1602.3231\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 267.2530 - val_loss: 1285.7974\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 278.6769 - val_loss: 1199.3130\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.3986 - val_loss: 355.2322\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 266.8637 - val_loss: 1089.0450\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 261.3965 - val_loss: 1176.6965\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.6501 - val_loss: 847.7010\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 260.2710 - val_loss: 1103.5785\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 251.0943 - val_loss: 1044.2748\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.3428 - val_loss: 1173.2585\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.0013 - val_loss: 1348.9675\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.9570 - val_loss: 1261.6173\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.3511 - val_loss: 1420.5981\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223.5175 - val_loss: 923.7739\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.5210 - val_loss: 1023.8226\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.5735 - val_loss: 1196.3418\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.7841 - val_loss: 1177.6373\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.8570 - val_loss: 1015.8533\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.9860 - val_loss: 986.9607\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.8945 - val_loss: 783.7834\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.7045 - val_loss: 1474.3281\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 235.6635 - val_loss: 1239.2769\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 229.5387 - val_loss: 1087.9812\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245.4645 - val_loss: 1544.8138\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 241.6815 - val_loss: 1393.3639\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.1478 - val_loss: 1262.1515\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.4101 - val_loss: 1396.0482\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 218.6291 - val_loss: 1068.8817\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 230.2540 - val_loss: 882.1116\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.7215 - val_loss: 1069.7919\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 217.7265 - val_loss: 1421.9021\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 218.7324 - val_loss: 1186.7625\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 222.6745 - val_loss: 1098.2306\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.7137 - val_loss: 1205.5696\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.7433 - val_loss: 1144.5127\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.8089 - val_loss: 1306.3799\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 256.0599 - val_loss: 1229.4749\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 223.1369 - val_loss: 1430.3152\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 215.6977 - val_loss: 971.7805\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.8046 - val_loss: 985.4435\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.9336 - val_loss: 1179.3525\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 287.8672 - val_loss: 892.8470\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 254.0797 - val_loss: 1210.5107\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.9338 - val_loss: 1439.0302\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.5191 - val_loss: 1527.9182\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 283.0656 - val_loss: 781.9517\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 260.0222 - val_loss: 1494.6260\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 242.4881 - val_loss: 817.8554\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 243.0027 - val_loss: 1514.9443\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 237.1134 - val_loss: 587.4692\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 284.1057 - val_loss: 1408.5499\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.7095 - val_loss: 1059.5760\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 227.7063 - val_loss: 1826.0786\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 231.4065 - val_loss: 1340.8213\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.2122 - val_loss: 1404.2682\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.7706 - val_loss: 1616.2202\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 217.2141 - val_loss: 1436.2393\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.9749 - val_loss: 1644.8127\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 218.2006 - val_loss: 1438.8409\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 226.1459 - val_loss: 1306.4213\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.0916 - val_loss: 1456.6011\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.3987 - val_loss: 1269.7490\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.7440 - val_loss: 1382.6577\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.4926 - val_loss: 1720.3990\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.5269 - val_loss: 592.6152\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 279.3533 - val_loss: 1263.5629\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.8389 - val_loss: 1344.6896\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.2693 - val_loss: 1442.1104\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.4200 - val_loss: 1081.6960\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.2910 - val_loss: 1192.3009\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 229.6317 - val_loss: 1710.0078\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.2186 - val_loss: 1170.1172\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.5132 - val_loss: 1001.8159\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.3357 - val_loss: 1348.3118\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 220.7451 - val_loss: 1107.3939\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.3289 - val_loss: 1167.4386\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.3647 - val_loss: 1070.2719\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.0416 - val_loss: 1484.6099\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.7681 - val_loss: 941.9884\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 244.9212 - val_loss: 1731.7239\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 261.7920 - val_loss: 1533.1362\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 247.3671 - val_loss: 1121.2998\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 223.7400 - val_loss: 1072.5068\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 242.2421 - val_loss: 1171.8140\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.3193 - val_loss: 1692.7412\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.8328 - val_loss: 1340.4983\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.3362 - val_loss: 1273.5887\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.1091 - val_loss: 1214.5297\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.8785 - val_loss: 1123.6763\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.8635 - val_loss: 1244.7190\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 264.6960 - val_loss: 1223.5363\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.6210 - val_loss: 1827.1229\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 294.6080 - val_loss: 1306.3483\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.2051 - val_loss: 1809.3857\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 274.5569 - val_loss: 1184.3722\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.2611 - val_loss: 1215.5054\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 251.1912 - val_loss: 1151.8604\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 269.6075 - val_loss: 1270.5353\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.9438 - val_loss: 1230.3713\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221.3310 - val_loss: 1447.2655\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.6057 - val_loss: 1194.2947\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 243.3100 - val_loss: 1173.7794\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.6788 - val_loss: 1437.1870\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 244.5331 - val_loss: 1309.6421\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 239.2663 - val_loss: 1255.0615\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245.6620 - val_loss: 1617.1444\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 264.9891 - val_loss: 1229.6912\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.6797 - val_loss: 1085.8359\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.1530 - val_loss: 1375.9677\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.7804 - val_loss: 1341.3281\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.9977 - val_loss: 1125.8549\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.7802 - val_loss: 1003.0287\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.9837 - val_loss: 993.1829\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 252.9395 - val_loss: 1504.1395\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 219.2678 - val_loss: 1349.0978\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.6341 - val_loss: 1368.1165\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.9960 - val_loss: 1399.5443\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 265.0488 - val_loss: 1048.2896\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.7564 - val_loss: 1187.1665\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.0376 - val_loss: 1158.1586\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.0061 - val_loss: 1307.1163\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 255.8647 - val_loss: 896.1574\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.5388 - val_loss: 1161.7863\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.3325 - val_loss: 1223.5829\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245.6115 - val_loss: 1115.4056\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 227.6416 - val_loss: 1153.8997\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 261.4575 - val_loss: 987.0576\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.8768 - val_loss: 1307.2401\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.0844 - val_loss: 1459.8013\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.0736 - val_loss: 1118.0210\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 270.5135 - val_loss: 1014.0898\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 233.5706 - val_loss: 1356.5479\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.9638 - val_loss: 1052.1376\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.7734 - val_loss: 1395.1799\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.3134 - val_loss: 1022.3862\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.9680 - val_loss: 1112.6351\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.3101 - val_loss: 1502.4980\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.9676 - val_loss: 1396.7556\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.1517 - val_loss: 814.6050\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.6323 - val_loss: 990.3072\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.3489 - val_loss: 1212.0441\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.3727 - val_loss: 1459.7383\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.3344 - val_loss: 1544.5591\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.6251 - val_loss: 1053.2222\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.4406 - val_loss: 986.5242\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.3772 - val_loss: 1305.1604\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.4008 - val_loss: 1652.8240\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.0523 - val_loss: 887.1050\n",
      "Epoch 617/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 251.6989 - val_loss: 1223.1825\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 248.4798 - val_loss: 1071.2006\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 259.8005 - val_loss: 1373.8176\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.7286 - val_loss: 1255.0175\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.0316 - val_loss: 1489.7004\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.7098 - val_loss: 1079.4583\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.6557 - val_loss: 1177.8988\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.1266 - val_loss: 1143.3358\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.6392 - val_loss: 1249.9678\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.5968 - val_loss: 936.7249\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 265.7843 - val_loss: 1379.0786\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.1836 - val_loss: 919.7369\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 230.4704 - val_loss: 1650.1010\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 240.8036 - val_loss: 1103.3373\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 230.5009 - val_loss: 1532.5045\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.0853 - val_loss: 1116.3176\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.2941 - val_loss: 1238.9033\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 230.3017 - val_loss: 1020.1469\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.4193 - val_loss: 1177.4733\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.7147 - val_loss: 933.2743\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.3371 - val_loss: 857.1671\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 217.7440 - val_loss: 1128.7104\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 223.6270 - val_loss: 1127.0771\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223.9262 - val_loss: 1309.8174\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.7702 - val_loss: 1329.4565\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.8854 - val_loss: 1065.5867\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.3575 - val_loss: 1215.1431\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 220.7538 - val_loss: 1248.9030\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.0788 - val_loss: 1176.7031\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.2417 - val_loss: 1153.2515\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.4505 - val_loss: 1222.7635\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.0719 - val_loss: 1321.6737\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.3941 - val_loss: 1339.2333\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 317.4328 - val_loss: 1138.5579\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.6497 - val_loss: 1292.7266\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.4820 - val_loss: 1736.3386\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.8918 - val_loss: 1581.6108\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.6329 - val_loss: 982.9331\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 259.8883 - val_loss: 609.2312\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.5890 - val_loss: 1268.8911\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.8552 - val_loss: 1420.9980\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 259.6130 - val_loss: 1421.6777\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 287.4599 - val_loss: 314.1951\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.1862 - val_loss: 941.5698\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 265.1864 - val_loss: 1048.5579\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.7025 - val_loss: 1036.3208\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.5032 - val_loss: 1286.2755\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 251.6611 - val_loss: 1867.5931\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 273.4806 - val_loss: 1250.1490\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 264.7101 - val_loss: 801.0060\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.6247 - val_loss: 1118.9418\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.8452 - val_loss: 1250.0399\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 230.4165 - val_loss: 1198.6940\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.2439 - val_loss: 995.5344\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.1175 - val_loss: 1369.9508\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.2518 - val_loss: 1297.7034\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.7102 - val_loss: 1189.7792\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.2498 - val_loss: 1323.7158\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.4934 - val_loss: 1140.0234\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.3121 - val_loss: 882.2365\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.6400 - val_loss: 1128.1794\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.4164 - val_loss: 1409.0192\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.6686 - val_loss: 935.6766\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.8399 - val_loss: 1111.9861\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.6892 - val_loss: 1114.6930\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.5428 - val_loss: 726.4948\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 268.1505 - val_loss: 980.5198\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 250.1212 - val_loss: 696.3072\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.4738 - val_loss: 1086.1632\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.5502 - val_loss: 1878.6144\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.0006 - val_loss: 1221.7211\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.3477 - val_loss: 895.6995\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.5861 - val_loss: 1292.4979\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 225.8511 - val_loss: 940.2238\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 272.8670 - val_loss: 1357.9456\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.1995 - val_loss: 1010.7657\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.1480 - val_loss: 1076.8829\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221.1449 - val_loss: 1144.4764\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.3273 - val_loss: 909.9881\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 233.3235 - val_loss: 1219.1379\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 226.1850 - val_loss: 765.6936\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 240.5481 - val_loss: 941.9810\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 271.0650 - val_loss: 1025.4644\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.4344 - val_loss: 1141.5331\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.5655 - val_loss: 760.8228\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.1763 - val_loss: 1015.3957\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.0988 - val_loss: 1493.1691\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.3023 - val_loss: 1237.4420\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.8635 - val_loss: 1176.5123\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 207.2928 - val_loss: 1206.4736\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.1627 - val_loss: 1112.7411\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.4158 - val_loss: 1406.2491\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.0814 - val_loss: 1004.9221\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.2200 - val_loss: 1237.0391\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.1826 - val_loss: 1860.7561\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 255.1445 - val_loss: 765.2761\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.5246 - val_loss: 1036.6071\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 233.8720 - val_loss: 882.2379\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.1661 - val_loss: 944.6298\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 214.3885 - val_loss: 1474.9150\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.5776 - val_loss: 1219.7319\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 213.0540 - val_loss: 1181.5085\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 212.6198 - val_loss: 951.3129\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.0533 - val_loss: 868.7330\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 223.2931 - val_loss: 1043.7927\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 227.6896 - val_loss: 1096.6287\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.1310 - val_loss: 875.1711\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.6293 - val_loss: 1611.7833\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.2481 - val_loss: 1087.1637\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 267.5766 - val_loss: 471.5443\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.4114 - val_loss: 502.7116\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.3486 - val_loss: 2050.4351\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.8433 - val_loss: 826.6612\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223.9229 - val_loss: 920.4697\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.5329 - val_loss: 1271.5668\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 219.5900 - val_loss: 847.6886\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 220.3383 - val_loss: 815.4805\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.8689 - val_loss: 971.6036\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.4022 - val_loss: 786.7889\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.7542 - val_loss: 1088.2603\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.2750 - val_loss: 968.3534\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.1717 - val_loss: 1420.4808\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221.3822 - val_loss: 547.2080\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.4550 - val_loss: 989.3239\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 213.3734 - val_loss: 979.0477\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 215.8625 - val_loss: 875.3268\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221.4716 - val_loss: 1021.9637\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.4533 - val_loss: 991.1027\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 209.6038 - val_loss: 810.0947\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 208.9407 - val_loss: 1259.0457\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 230.0352 - val_loss: 1098.9258\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.9307 - val_loss: 1058.5990\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.3821 - val_loss: 1279.7800\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.6828 - val_loss: 1400.9320\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.4870 - val_loss: 1018.4018\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.1317 - val_loss: 1223.5519\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221.3716 - val_loss: 1313.5858\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 218.6606 - val_loss: 1320.5013\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 220.5536 - val_loss: 688.4346\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.7390 - val_loss: 982.7820\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.3305 - val_loss: 1074.3773\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.7096 - val_loss: 1588.0544\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.2273 - val_loss: 1290.4987\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.4803 - val_loss: 1151.3988\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.2148 - val_loss: 1066.6865\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223.7673 - val_loss: 1187.7979\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 246.9049 - val_loss: 373.4531\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 244.8604 - val_loss: 1271.0935\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 262.7480 - val_loss: 852.0455\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 271.5086 - val_loss: 1117.3030\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245.0482 - val_loss: 1078.3997\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 278.1672 - val_loss: 1162.8143\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.4152 - val_loss: 940.0793\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.8460 - val_loss: 852.6344\n",
      "Epoch 771/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 227.8656 - val_loss: 901.8935\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.2110 - val_loss: 1193.4719\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 262.7018 - val_loss: 1075.1208\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 220.5192 - val_loss: 1130.8827\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.6620 - val_loss: 1136.2539\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.1158 - val_loss: 662.6960\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.0614 - val_loss: 1254.6074\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.8330 - val_loss: 834.9895\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 240.6155 - val_loss: 1241.8505\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.2221 - val_loss: 1107.5468\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.1846 - val_loss: 1067.5355\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.8534 - val_loss: 1124.2114\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.7043 - val_loss: 1091.1737\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.0019 - val_loss: 1082.6613\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 255.8909 - val_loss: 1047.9481\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.3695 - val_loss: 835.0187\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 245.8150 - val_loss: 913.2675\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.6208 - val_loss: 1281.6818\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.0946 - val_loss: 749.4284\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 268.0182 - val_loss: 1002.4518\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.1342 - val_loss: 724.3464\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.2405 - val_loss: 1339.3762\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.8053 - val_loss: 1177.0828\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.8387 - val_loss: 1284.4874\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.4869 - val_loss: 1084.1028\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.0253 - val_loss: 860.1833\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.4379 - val_loss: 694.4102\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 255.9146 - val_loss: 968.1301\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 220.9297 - val_loss: 660.7761\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 270.3997 - val_loss: 819.7934\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 245.8542 - val_loss: 1389.3706\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.3716 - val_loss: 1386.2964\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 247.9178 - val_loss: 915.7017\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 255.0590 - val_loss: 615.8164\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245.6045 - val_loss: 1157.5088\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.9975 - val_loss: 928.4203\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.1653 - val_loss: 797.3484\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.2675 - val_loss: 863.3828\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 216.3090 - val_loss: 1121.5972\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.4172 - val_loss: 1086.4559\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.6336 - val_loss: 1114.0764\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.2460 - val_loss: 1213.5516\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 231.8271 - val_loss: 1287.4054\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.8255 - val_loss: 942.9487\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.8529 - val_loss: 806.9641\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.7160 - val_loss: 1456.6279\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.7820 - val_loss: 1229.8827\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.5801 - val_loss: 1525.9434\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.0240 - val_loss: 1178.5680\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.8799 - val_loss: 997.4931\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.6130 - val_loss: 636.9055\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.9261 - val_loss: 980.0250\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 235.1400 - val_loss: 836.3469\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.0219 - val_loss: 632.2515\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.4416 - val_loss: 804.0947\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.1653 - val_loss: 630.4965\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.8790 - val_loss: 543.7449\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.2717 - val_loss: 1005.8410\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.3759 - val_loss: 1025.0781\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.9320 - val_loss: 1259.0074\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 260.4156 - val_loss: 757.1912\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.3147 - val_loss: 377.7575\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.3058 - val_loss: 1247.8560\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 234.9127 - val_loss: 1118.4674\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.1423 - val_loss: 1402.9606\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 230.8391 - val_loss: 630.5534\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.1093 - val_loss: 1073.2222\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.5538 - val_loss: 960.4702\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.7573 - val_loss: 1379.5038\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 268.7680 - val_loss: 1437.6971\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.3865 - val_loss: 1673.2207\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 265.5282 - val_loss: 1315.4353\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 230.7868 - val_loss: 1373.7990\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.9508 - val_loss: 1397.0186\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.4244 - val_loss: 784.5978\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 269.2620 - val_loss: 1225.1473\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 274.1402 - val_loss: 1332.2938\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 234.2367 - val_loss: 1635.0466\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.4092 - val_loss: 1309.1440\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.9179 - val_loss: 1094.5909\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223.4613 - val_loss: 1741.0255\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.0516 - val_loss: 959.2258\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.0323 - val_loss: 1052.8978\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.1735 - val_loss: 864.4872\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.5506 - val_loss: 1511.9282\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.8429 - val_loss: 907.5130\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 216.4714 - val_loss: 1082.9852\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 214.5352 - val_loss: 1487.7694\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.8218 - val_loss: 907.5704\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 226.0858 - val_loss: 1246.6647\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.3832 - val_loss: 758.3450\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.9053 - val_loss: 671.2274\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 217.9248 - val_loss: 1339.3541\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.8471 - val_loss: 841.0130\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 220.7209 - val_loss: 1274.2617\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223.8127 - val_loss: 857.2684\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.0083 - val_loss: 1062.4194\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 216.5617 - val_loss: 1144.3451\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.1484 - val_loss: 1099.9550\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 214.4966 - val_loss: 989.9763\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 230.9368 - val_loss: 738.8304\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 240.9814 - val_loss: 459.5686\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 281.6652 - val_loss: 1232.4908\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.8502 - val_loss: 1435.2773\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 251.2462 - val_loss: 1213.6212\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.5922 - val_loss: 954.6691\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 265.3081 - val_loss: 1264.0492\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.1766 - val_loss: 1063.5017\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.6167 - val_loss: 473.8572\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 293.6657 - val_loss: 823.7822\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 295.4799 - val_loss: 1527.5555\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 301.7647 - val_loss: 1238.2303\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 271.9082 - val_loss: 636.5575\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 264.0319 - val_loss: 1086.0704\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 280.6261 - val_loss: 972.5633\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 269.4070 - val_loss: 1766.0938\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 260.9690 - val_loss: 918.0100\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.7048 - val_loss: 1572.4360\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 244.9551 - val_loss: 1442.6267\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.7272 - val_loss: 811.5580\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223.1229 - val_loss: 1064.7393\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 217.7629 - val_loss: 988.4510\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.2608 - val_loss: 1170.8732\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 214.6515 - val_loss: 1473.9218\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.1224 - val_loss: 1374.5585\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 238.7274 - val_loss: 703.4836\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.1103 - val_loss: 1069.1610\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.8725 - val_loss: 1091.2980\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.0173 - val_loss: 1084.1475\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.0395 - val_loss: 1075.6907\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.1384 - val_loss: 1010.6660\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.1468 - val_loss: 373.3990\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 279.0661 - val_loss: 1044.0404\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 231.5884 - val_loss: 1111.7198\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.7928 - val_loss: 801.1100\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.5107 - val_loss: 954.4313\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.1990 - val_loss: 1054.3151\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223.1193 - val_loss: 995.4208\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.0271 - val_loss: 1240.8557\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 244.9595 - val_loss: 802.1819\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 240.6942 - val_loss: 1329.7341\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.4987 - val_loss: 1326.2849\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.3030 - val_loss: 1319.8192\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 230.3615 - val_loss: 1216.4760\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221.0433 - val_loss: 928.1938\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 218.5006 - val_loss: 1362.4602\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.9767 - val_loss: 1147.7057\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 219.9718 - val_loss: 1147.1798\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.9843 - val_loss: 1253.4717\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.2322 - val_loss: 1137.7598\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 233.6186 - val_loss: 1416.1740\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.3989 - val_loss: 1147.3798\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 222.9565 - val_loss: 886.6680\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.0718 - val_loss: 1137.5862\n",
      "Epoch 925/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 215.1687 - val_loss: 1422.0089\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 217.1254 - val_loss: 1104.0159\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.4868 - val_loss: 1371.3263\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.2391 - val_loss: 1738.1672\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 259.2599 - val_loss: 1046.4808\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.2163 - val_loss: 1006.1827\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 220.9178 - val_loss: 984.8759\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.4394 - val_loss: 1153.0354\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 224.9665 - val_loss: 1383.8069\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 219.7309 - val_loss: 1280.0728\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.8548 - val_loss: 1053.1368\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 305.2441 - val_loss: 1010.9631\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 276.9583 - val_loss: 909.9177\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.6283 - val_loss: 1114.7162\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.1654 - val_loss: 2063.7952\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 287.0382 - val_loss: 1138.9407\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 219.4355 - val_loss: 1184.6622\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.7401 - val_loss: 1113.0283\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 249.3110 - val_loss: 817.5912\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.8749 - val_loss: 818.3007\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.6219 - val_loss: 1197.1553\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.9801 - val_loss: 1112.6046\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.6427 - val_loss: 990.2089\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 246.9383 - val_loss: 1090.1783\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 255.7635 - val_loss: 1002.5782\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.3799 - val_loss: 1200.6865\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245.6654 - val_loss: 1507.8531\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.9531 - val_loss: 619.3921\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.7319 - val_loss: 845.1249\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 255.3748 - val_loss: 831.7661\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.1878 - val_loss: 950.8545\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.0722 - val_loss: 1074.5524\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.9730 - val_loss: 952.5551\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.8621 - val_loss: 1363.1355\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.5718 - val_loss: 1326.3350\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.4763 - val_loss: 789.7004\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221.8627 - val_loss: 799.7596\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 219.4023 - val_loss: 880.1749\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 237.0673 - val_loss: 1371.0657\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.9916 - val_loss: 995.6559\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 234.0509 - val_loss: 1741.2024\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 228.1057 - val_loss: 843.0967\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.7817 - val_loss: 1413.7262\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.4031 - val_loss: 1327.6584\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.4794 - val_loss: 979.8535\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 218.8313 - val_loss: 1388.1935\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.0285 - val_loss: 1399.2092\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.7309 - val_loss: 1331.0894\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.5109 - val_loss: 1346.0162\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 225.9813 - val_loss: 1087.9556\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 225.9199 - val_loss: 833.3471\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 240.5895 - val_loss: 611.8231\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.1718 - val_loss: 779.3002\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.9874 - val_loss: 1733.2386\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.3156 - val_loss: 1306.1987\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.8582 - val_loss: 1177.1619\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.4969 - val_loss: 1140.8669\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 251.2047 - val_loss: 1660.8850\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.8179 - val_loss: 855.2703\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 272.6324 - val_loss: 1327.8557\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 248.8778 - val_loss: 1547.2250\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 220.3274 - val_loss: 1086.4561\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.8459 - val_loss: 977.0490\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.3381 - val_loss: 830.3178\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.3727 - val_loss: 1036.2872\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 257.4748 - val_loss: 800.4642\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.1221 - val_loss: 1008.4224\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.5524 - val_loss: 1062.5870\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.3809 - val_loss: 1260.0813\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 226.7432 - val_loss: 912.8528\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.4028 - val_loss: 1592.7429\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 282.2298 - val_loss: 1404.9755\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.6517 - val_loss: 962.2711\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.8240 - val_loss: 904.3057\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.0090 - val_loss: 1153.3578\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.3179 - val_loss: 999.4401\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.9636 - val_loss: 857.6733\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.4904 - val_loss: 800.5906\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 259.8503 - val_loss: 1494.2229\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 255.4637 - val_loss: 1342.5575\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.7175 - val_loss: 966.6306\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 222.7973 - val_loss: 1026.0862\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.2545 - val_loss: 1268.0591\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.1870 - val_loss: 1425.6063\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.9377 - val_loss: 1040.2559\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.1567 - val_loss: 783.7798\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 231.9186 - val_loss: 1060.0067\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.5309 - val_loss: 1282.7194\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.4106 - val_loss: 522.7937\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.5638 - val_loss: 970.5991\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 275.5208 - val_loss: 865.7166\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 241.3604 - val_loss: 1071.8480\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.5306 - val_loss: 1032.5649\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 238.5414 - val_loss: 1241.0856\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 274.6982 - val_loss: 2158.9312\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 248.7540 - val_loss: 1497.0182\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.0471 - val_loss: 1371.1196\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 266.6356 - val_loss: 1361.8002\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.6282 - val_loss: 1262.1757\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.0656 - val_loss: 1009.0328\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.7027 - val_loss: 1305.6921\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 230.7714 - val_loss: 1099.7164\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 230.1558 - val_loss: 1253.6299\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 259.6364 - val_loss: 831.8618\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.7914 - val_loss: 799.0387\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.0638 - val_loss: 1015.1088\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.0480 - val_loss: 653.0201\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.6352 - val_loss: 1521.6843\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.0668 - val_loss: 1038.3750\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.0899 - val_loss: 978.6671\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 262.0702 - val_loss: 1252.3137\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.7298 - val_loss: 1333.4210\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 221.8000 - val_loss: 1584.0380\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.5663 - val_loss: 1129.3660\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.8139 - val_loss: 1190.0182\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.5303 - val_loss: 956.2198\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 263.6494 - val_loss: 1214.5698\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.9546 - val_loss: 1379.4756\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 256.4351 - val_loss: 893.0022\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.7727 - val_loss: 1582.2944\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.0645 - val_loss: 1436.9022\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.6666 - val_loss: 1500.3009\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.0238 - val_loss: 1157.4197\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.8837 - val_loss: 1037.5912\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 253.5582 - val_loss: 1728.9801\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.8984 - val_loss: 1609.8728\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.5261 - val_loss: 1075.8156\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.0190 - val_loss: 1242.0107\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.7617 - val_loss: 1357.4240\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 261.9212 - val_loss: 1056.2737\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 259.5044 - val_loss: 1246.0870\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 259.6692 - val_loss: 718.8188\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.7131 - val_loss: 1195.6140\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.0523 - val_loss: 1216.9586\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 237.8290 - val_loss: 926.8378\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221.5460 - val_loss: 1250.5260\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 275.6516 - val_loss: 1109.9231\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.8243 - val_loss: 1248.1465\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.0520 - val_loss: 1236.2247\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 265.1717 - val_loss: 1321.3345\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 230.3313 - val_loss: 989.8019\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223.7533 - val_loss: 957.5383\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.0514 - val_loss: 821.6292\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.6692 - val_loss: 1454.0300\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 217.2455 - val_loss: 769.0455\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.1313 - val_loss: 1829.3048\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 231.8262 - val_loss: 1323.3282\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.0962 - val_loss: 1242.3551\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 230.2019 - val_loss: 1659.4031\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.1780 - val_loss: 1521.5573\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.0013 - val_loss: 951.1287\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.4498 - val_loss: 892.4891\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 258.7179 - val_loss: 1598.1539\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 221.2962 - val_loss: 1486.9382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.8741 - val_loss: 1163.7994\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.0398 - val_loss: 1434.4365\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.1622 - val_loss: 901.4365\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 230.5806 - val_loss: 1023.6575\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.4783 - val_loss: 1079.3618\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.3439 - val_loss: 1537.1134\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 251.5629 - val_loss: 1196.1147\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.7512 - val_loss: 828.7026\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.6339 - val_loss: 861.4819\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.1079 - val_loss: 1159.4189\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 245.5547 - val_loss: 1256.5214\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 214.7006 - val_loss: 874.0854\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.1117 - val_loss: 1511.1934\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.0944 - val_loss: 1212.8424\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.8413 - val_loss: 1048.5055\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.4940 - val_loss: 1152.6647\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.3871 - val_loss: 879.2867\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.9127 - val_loss: 1108.8936\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.2054 - val_loss: 945.2961\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.6398 - val_loss: 912.4871\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 250.8851 - val_loss: 1057.9661\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 239.9361 - val_loss: 824.4837\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 253.4058 - val_loss: 716.4530\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.4969 - val_loss: 1182.3936\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 240.7045 - val_loss: 1382.0258\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 265.7960 - val_loss: 1630.8685\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 247.3202 - val_loss: 1747.7461\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 257.5200 - val_loss: 1120.2408\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 262.7721 - val_loss: 1623.7776\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245.7883 - val_loss: 1852.9493\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 272.8989 - val_loss: 1566.4874\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 242.4583 - val_loss: 907.0829\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.4659 - val_loss: 1662.2422\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 251.6577 - val_loss: 1109.3248\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 227.1843 - val_loss: 919.7075\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 269.9614 - val_loss: 1323.1409\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 286.3825 - val_loss: 938.3647\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 270.3924 - val_loss: 760.9094\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.7410 - val_loss: 1255.1383\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.7301 - val_loss: 1114.4874\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.3790 - val_loss: 984.9534\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 233.3266 - val_loss: 899.8734\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253.1962 - val_loss: 1006.3862\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 235.5286 - val_loss: 1372.0760\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 247.8984 - val_loss: 754.6043\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.8088 - val_loss: 1105.7843\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 232.1469 - val_loss: 1286.8099\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.4494 - val_loss: 1306.7367\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 224.1018 - val_loss: 1749.2959\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 248.5655 - val_loss: 1583.4513\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 276.0734 - val_loss: 1334.8785\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 251.0753 - val_loss: 1003.8363\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 228.8812 - val_loss: 1219.9641\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.6822 - val_loss: 1374.1901\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 254.7170 - val_loss: 1899.8857\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 268.6440 - val_loss: 1691.1482\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.3951 - val_loss: 1316.0614\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 238.5288 - val_loss: 1263.5236\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 268.9783 - val_loss: 1033.5262\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 254.9485 - val_loss: 995.5845\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 260.5111 - val_loss: 1407.5581\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 246.4809 - val_loss: 1103.0636\n",
      "Epoch 1141/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 269.6770 - val_loss: 1145.8463\n",
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 256.3860 - val_loss: 1359.4393\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 252.6466 - val_loss: 1604.7352\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 237.9230 - val_loss: 1489.2446\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 234.5180 - val_loss: 1330.7844\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 238.9595 - val_loss: 1524.2563\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 220.6110 - val_loss: 1220.0303\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 223.0948 - val_loss: 1530.0077\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 217.1744 - val_loss: 1298.8934\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.2084 - val_loss: 1232.2677\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 236.6705 - val_loss: 1264.9060\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.3536 - val_loss: 1069.8596\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 249.4927 - val_loss: 1149.9053\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 243.4339 - val_loss: 1333.8412\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 232.4500 - val_loss: 1503.2471\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 225.5887 - val_loss: 1573.6104\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 226.5049 - val_loss: 1431.5551\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 245.6238 - val_loss: 1704.2582\n",
      "Epoch 1159/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 192.2133Restoring model weights from the end of the best epoch: 659.\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 241.9332 - val_loss: 1857.5167\n",
      "Epoch 1159: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>215.792313</td>\n",
       "      <td>225.769333</td>\n",
       "      <td>215.916931</td>\n",
       "      <td>217.477066</td>\n",
       "      <td>216.576797</td>\n",
       "      <td>220.918655</td>\n",
       "      <td>221.44046</td>\n",
       "      <td>221.449417</td>\n",
       "      <td>221.456848</td>\n",
       "      <td>221.059464</td>\n",
       "      <td>215.87355</td>\n",
       "      <td>221.430389</td>\n",
       "      <td>219.539581</td>\n",
       "      <td>219.849106</td>\n",
       "      <td>215.967514</td>\n",
       "      <td>216.052292</td>\n",
       "      <td>219.472076</td>\n",
       "      <td>215.551147</td>\n",
       "      <td>210.588837</td>\n",
       "      <td>214.347183</td>\n",
       "      <td>209.921326</td>\n",
       "      <td>209.681305</td>\n",
       "      <td>209.662384</td>\n",
       "      <td>209.657181</td>\n",
       "      <td>209.65564</td>\n",
       "      <td>209.65744</td>\n",
       "      <td>209.655304</td>\n",
       "      <td>209.655243</td>\n",
       "      <td>209.655365</td>\n",
       "      <td>209.655197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>244.68</td>\n",
       "      <td>252.183</td>\n",
       "      <td>249.403</td>\n",
       "      <td>208.299</td>\n",
       "      <td>238.414</td>\n",
       "      <td>213.179</td>\n",
       "      <td>221.534</td>\n",
       "      <td>212.139</td>\n",
       "      <td>228.994</td>\n",
       "      <td>226.827</td>\n",
       "      <td>186.855</td>\n",
       "      <td>253.021</td>\n",
       "      <td>194.988</td>\n",
       "      <td>244.406</td>\n",
       "      <td>201.372</td>\n",
       "      <td>251.369</td>\n",
       "      <td>242.782</td>\n",
       "      <td>201.288</td>\n",
       "      <td>226.547</td>\n",
       "      <td>228.5</td>\n",
       "      <td>223.896</td>\n",
       "      <td>234.132</td>\n",
       "      <td>207.586</td>\n",
       "      <td>228.583</td>\n",
       "      <td>234.565</td>\n",
       "      <td>249.519</td>\n",
       "      <td>230.086</td>\n",
       "      <td>233.136</td>\n",
       "      <td>233.8</td>\n",
       "      <td>223.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>28.88768</td>\n",
       "      <td>26.413666</td>\n",
       "      <td>33.486069</td>\n",
       "      <td>9.17807</td>\n",
       "      <td>21.837204</td>\n",
       "      <td>7.739655</td>\n",
       "      <td>0.093536</td>\n",
       "      <td>9.31041</td>\n",
       "      <td>7.537155</td>\n",
       "      <td>5.767532</td>\n",
       "      <td>29.018555</td>\n",
       "      <td>31.590607</td>\n",
       "      <td>24.551575</td>\n",
       "      <td>24.5569</td>\n",
       "      <td>14.59552</td>\n",
       "      <td>35.316711</td>\n",
       "      <td>23.309921</td>\n",
       "      <td>14.263153</td>\n",
       "      <td>15.95816</td>\n",
       "      <td>14.152817</td>\n",
       "      <td>13.97467</td>\n",
       "      <td>24.450699</td>\n",
       "      <td>2.076385</td>\n",
       "      <td>18.925812</td>\n",
       "      <td>24.909363</td>\n",
       "      <td>39.861557</td>\n",
       "      <td>20.430695</td>\n",
       "      <td>23.480759</td>\n",
       "      <td>24.144638</td>\n",
       "      <td>13.558807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1           2           3           4   \\\n",
       "Month          Month-1     Month-2     Month-3     Month-4     Month-5   \n",
       "Prediction  215.792313  225.769333  215.916931  217.477066  216.576797   \n",
       "Target          244.68     252.183     249.403     208.299     238.414   \n",
       "Error         28.88768   26.413666   33.486069     9.17807   21.837204   \n",
       "\n",
       "                    5          6           7           8           9   \\\n",
       "Month          Month-6    Month-7     Month-8     Month-9    Month-10   \n",
       "Prediction  220.918655  221.44046  221.449417  221.456848  221.059464   \n",
       "Target         213.179    221.534     212.139     228.994     226.827   \n",
       "Error         7.739655   0.093536     9.31041    7.537155    5.767532   \n",
       "\n",
       "                   10          11          12          13          14  \\\n",
       "Month        Month-11    Month-12    Month-13    Month-14    Month-15   \n",
       "Prediction  215.87355  221.430389  219.539581  219.849106  215.967514   \n",
       "Target        186.855     253.021     194.988     244.406     201.372   \n",
       "Error       29.018555   31.590607   24.551575     24.5569    14.59552   \n",
       "\n",
       "                    15          16          17          18          19  \\\n",
       "Month         Month-16    Month-17    Month-18    Month-19    Month-20   \n",
       "Prediction  216.052292  219.472076  215.551147  210.588837  214.347183   \n",
       "Target         251.369     242.782     201.288     226.547       228.5   \n",
       "Error        35.316711   23.309921   14.263153    15.95816   14.152817   \n",
       "\n",
       "                    20          21          22          23         24  \\\n",
       "Month         Month-21    Month-22    Month-23    Month-24   Month-25   \n",
       "Prediction  209.921326  209.681305  209.662384  209.657181  209.65564   \n",
       "Target         223.896     234.132     207.586     228.583    234.565   \n",
       "Error         13.97467   24.450699    2.076385   18.925812  24.909363   \n",
       "\n",
       "                   25          26          27          28          29  \n",
       "Month        Month-26    Month-27    Month-28    Month-29    Month-30  \n",
       "Prediction  209.65744  209.655304  209.655243  209.655365  209.655197  \n",
       "Target        249.519     230.086     233.136       233.8     223.214  \n",
       "Error       39.861557   20.430695   23.480759   24.144638   13.558807  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.445944"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.08431907"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[2635.1614]] - Target[2735.5280000000002]| =  Error: [[100.3667]]; MAPE:[[0.03669006]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[2570.29]] - Target[2685.449]| =  Error: [[115.158936]]; MAPE:[[0.04288256]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Ano-5: |Prediction[[1257.9342]] - Target[1404.32]| =  Error: [[146.38574]]; MAPE:[[0.1042396]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[100.3667]], dtype=float32),\n",
       " array([[115.158936]], dtype=float32),\n",
       " array([[146.38574]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "120.63712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.061270744"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
