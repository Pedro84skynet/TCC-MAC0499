{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Bahia - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>Bahia - Desemprego</th>\n",
       "      <th>Bahia - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.299858</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>0.669899</td>\n",
       "      <td>39.798880</td>\n",
       "      <td>1.317344e+08</td>\n",
       "      <td>8.384593e+06</td>\n",
       "      <td>8.566149</td>\n",
       "      <td>1.216359e+08</td>\n",
       "      <td>8.348779</td>\n",
       "      <td>151.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.301903</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>0.670210</td>\n",
       "      <td>39.480034</td>\n",
       "      <td>1.318964e+08</td>\n",
       "      <td>8.391946e+06</td>\n",
       "      <td>8.569210</td>\n",
       "      <td>1.216914e+08</td>\n",
       "      <td>8.342979</td>\n",
       "      <td>138.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.303709</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>0.670521</td>\n",
       "      <td>39.400256</td>\n",
       "      <td>1.320584e+08</td>\n",
       "      <td>8.399299e+06</td>\n",
       "      <td>8.572270</td>\n",
       "      <td>1.217469e+08</td>\n",
       "      <td>8.337179</td>\n",
       "      <td>135.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.305311</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>0.670831</td>\n",
       "      <td>39.417185</td>\n",
       "      <td>1.322204e+08</td>\n",
       "      <td>8.406652e+06</td>\n",
       "      <td>8.575331</td>\n",
       "      <td>1.218023e+08</td>\n",
       "      <td>8.331379</td>\n",
       "      <td>126.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.306860</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>0.671142</td>\n",
       "      <td>39.479943</td>\n",
       "      <td>1.323824e+08</td>\n",
       "      <td>8.414005e+06</td>\n",
       "      <td>8.578392</td>\n",
       "      <td>1.218578e+08</td>\n",
       "      <td>8.325579</td>\n",
       "      <td>137.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>0.597113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.069163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>0.596178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.752943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>0.594662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.537361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>0.592436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.971241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>0.589305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.857141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Bahia - value  \\\n",
       "0       2003-1       0.299858   \n",
       "1       2003-2       0.301903   \n",
       "2       2003-3       0.303709   \n",
       "3       2003-4       0.305311   \n",
       "4       2003-5       0.306860   \n",
       "..         ...            ...   \n",
       "235     2022-8       0.597113   \n",
       "236     2022-9       0.596178   \n",
       "237    2022-10       0.594662   \n",
       "238    2022-11       0.592436   \n",
       "239    2022-12       0.589305   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Bahia - IDH  \\\n",
       "0                              7.330309e+06   0.969649     0.669899   \n",
       "1                              7.335910e+06   0.950783     0.670210   \n",
       "2                              7.341511e+06   0.938332     0.670521   \n",
       "3                              7.347112e+06   0.926401     0.670831   \n",
       "4                              7.352713e+06   0.951683     0.671142   \n",
       "..                                      ...        ...          ...   \n",
       "235                                     NaN        NaN          NaN   \n",
       "236                                     NaN        NaN          NaN   \n",
       "237                                     NaN        NaN          NaN   \n",
       "238                                     NaN        NaN          NaN   \n",
       "239                                     NaN        NaN          NaN   \n",
       "\n",
       "     Bahia - Produção de Cimento (t)  Bahia - PIB - Estadual  \\\n",
       "0                          39.798880            1.317344e+08   \n",
       "1                          39.480034            1.318964e+08   \n",
       "2                          39.400256            1.320584e+08   \n",
       "3                          39.417185            1.322204e+08   \n",
       "4                          39.479943            1.323824e+08   \n",
       "..                               ...                     ...   \n",
       "235                       106.069163                     NaN   \n",
       "236                       105.752943                     NaN   \n",
       "237                       105.537361                     NaN   \n",
       "238                       104.971241                     NaN   \n",
       "239                       104.857141                     NaN   \n",
       "\n",
       "     Bahia - PIB - Construção Civil  Bahia - PIB - Per Capita  \\\n",
       "0                      8.384593e+06                  8.566149   \n",
       "1                      8.391946e+06                  8.569210   \n",
       "2                      8.399299e+06                  8.572270   \n",
       "3                      8.406652e+06                  8.575331   \n",
       "4                      8.414005e+06                  8.578392   \n",
       "..                              ...                       ...   \n",
       "235                             NaN                       NaN   \n",
       "236                             NaN                       NaN   \n",
       "237                             NaN                       NaN   \n",
       "238                             NaN                       NaN   \n",
       "239                             NaN                       NaN   \n",
       "\n",
       "     Bahia - PIB - Preços de Mercado  Bahia - Desemprego  \\\n",
       "0                       1.216359e+08            8.348779   \n",
       "1                       1.216914e+08            8.342979   \n",
       "2                       1.217469e+08            8.337179   \n",
       "3                       1.218023e+08            8.331379   \n",
       "4                       1.218578e+08            8.325579   \n",
       "..                               ...                 ...   \n",
       "235                              NaN                 NaN   \n",
       "236                              NaN                 NaN   \n",
       "237                              NaN                 NaN   \n",
       "238                              NaN                 NaN   \n",
       "239                              NaN                 NaN   \n",
       "\n",
       "     Bahia - Consumo de Cimento (t)  \n",
       "0                           151.297  \n",
       "1                           138.707  \n",
       "2                           135.009  \n",
       "3                           126.554  \n",
       "4                           137.331  \n",
       "..                              ...  \n",
       "235                         366.305  \n",
       "236                         346.042  \n",
       "237                         347.901  \n",
       "238                         310.845  \n",
       "239                         310.845  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_BA.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>Bahia - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.440329</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-2.143224</td>\n",
       "      <td>-1.723080</td>\n",
       "      <td>-1.703176</td>\n",
       "      <td>-0.816345</td>\n",
       "      <td>-2.235724</td>\n",
       "      <td>-2.158201</td>\n",
       "      <td>-0.884052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.404914</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-2.108465</td>\n",
       "      <td>-1.735985</td>\n",
       "      <td>-1.684201</td>\n",
       "      <td>-0.772933</td>\n",
       "      <td>-2.194204</td>\n",
       "      <td>-2.117854</td>\n",
       "      <td>-0.885724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.373637</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-2.073707</td>\n",
       "      <td>-1.739214</td>\n",
       "      <td>-1.665225</td>\n",
       "      <td>-0.729522</td>\n",
       "      <td>-2.152684</td>\n",
       "      <td>-2.077508</td>\n",
       "      <td>-0.887395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.345888</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-2.038948</td>\n",
       "      <td>-1.738529</td>\n",
       "      <td>-1.646249</td>\n",
       "      <td>-0.686111</td>\n",
       "      <td>-2.111164</td>\n",
       "      <td>-2.037161</td>\n",
       "      <td>-0.889067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.319065</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-2.004190</td>\n",
       "      <td>-1.735989</td>\n",
       "      <td>-1.627274</td>\n",
       "      <td>-0.642700</td>\n",
       "      <td>-2.069645</td>\n",
       "      <td>-1.996814</td>\n",
       "      <td>-0.890739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.796141</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.261516</td>\n",
       "      <td>0.511535</td>\n",
       "      <td>1.096947</td>\n",
       "      <td>-1.668064</td>\n",
       "      <td>0.877256</td>\n",
       "      <td>0.724962</td>\n",
       "      <td>1.200853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.811284</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.253736</td>\n",
       "      <td>0.513264</td>\n",
       "      <td>1.085441</td>\n",
       "      <td>-1.663847</td>\n",
       "      <td>0.851021</td>\n",
       "      <td>0.704849</td>\n",
       "      <td>1.200487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.833479</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.245956</td>\n",
       "      <td>0.526782</td>\n",
       "      <td>1.073935</td>\n",
       "      <td>-1.659631</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.684737</td>\n",
       "      <td>1.200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.853109</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.238176</td>\n",
       "      <td>0.525379</td>\n",
       "      <td>1.062429</td>\n",
       "      <td>-1.655414</td>\n",
       "      <td>0.798552</td>\n",
       "      <td>0.664624</td>\n",
       "      <td>1.199756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.880066</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.230396</td>\n",
       "      <td>0.525808</td>\n",
       "      <td>1.050923</td>\n",
       "      <td>-1.651197</td>\n",
       "      <td>0.772317</td>\n",
       "      <td>0.644511</td>\n",
       "      <td>1.199390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bahia - value   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0        -1.440329                                          2.723741   \n",
       "1        -1.404914                                          2.350880   \n",
       "2        -1.373637                                          2.123016   \n",
       "3        -1.345888                                          2.021477   \n",
       "4        -1.319065                                          1.887113   \n",
       "..             ...                                               ...   \n",
       "187       1.796141                                         -2.010387   \n",
       "188       1.811284                                         -1.870713   \n",
       "189       1.833479                                         -1.806230   \n",
       "190       1.853109                                         -1.727496   \n",
       "191       1.880066                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Bahia - IDH  \\\n",
       "0                                 -2.389042   3.122582    -2.143224   \n",
       "1                                 -2.352139   2.970356    -2.108465   \n",
       "2                                 -2.315236   2.869895    -2.073707   \n",
       "3                                 -2.278333   2.773628    -2.038948   \n",
       "4                                 -2.241431   2.977624    -2.004190   \n",
       "..                                      ...        ...          ...   \n",
       "187                                0.389193  -1.749976     1.261516   \n",
       "188                                0.370392  -1.593005     1.253736   \n",
       "189                                0.351592  -1.351489     1.245956   \n",
       "190                                0.332791  -1.198492     1.238176   \n",
       "191                                0.313991  -1.100894     1.230396   \n",
       "\n",
       "     Bahia - Produção de Cimento (t)  Bahia - PIB - Estadual  \\\n",
       "0                          -1.723080               -1.703176   \n",
       "1                          -1.735985               -1.684201   \n",
       "2                          -1.739214               -1.665225   \n",
       "3                          -1.738529               -1.646249   \n",
       "4                          -1.735989               -1.627274   \n",
       "..                               ...                     ...   \n",
       "187                         0.511535                1.096947   \n",
       "188                         0.513264                1.085441   \n",
       "189                         0.526782                1.073935   \n",
       "190                         0.525379                1.062429   \n",
       "191                         0.525808                1.050923   \n",
       "\n",
       "     Bahia - PIB - Construção Civil  Bahia - PIB - Per Capita  \\\n",
       "0                         -0.816345                 -2.235724   \n",
       "1                         -0.772933                 -2.194204   \n",
       "2                         -0.729522                 -2.152684   \n",
       "3                         -0.686111                 -2.111164   \n",
       "4                         -0.642700                 -2.069645   \n",
       "..                              ...                       ...   \n",
       "187                       -1.668064                  0.877256   \n",
       "188                       -1.663847                  0.851021   \n",
       "189                       -1.659631                  0.824786   \n",
       "190                       -1.655414                  0.798552   \n",
       "191                       -1.651197                  0.772317   \n",
       "\n",
       "     Bahia - PIB - Preços de Mercado  Bahia - Desemprego  \n",
       "0                          -2.158201           -0.884052  \n",
       "1                          -2.117854           -0.885724  \n",
       "2                          -2.077508           -0.887395  \n",
       "3                          -2.037161           -0.889067  \n",
       "4                          -1.996814           -0.890739  \n",
       "..                               ...                 ...  \n",
       "187                         0.724962            1.200853  \n",
       "188                         0.704849            1.200487  \n",
       "189                         0.684737            1.200122  \n",
       "190                         0.664624            1.199756  \n",
       "191                         0.644511            1.199390  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      129.857\n",
       "1      126.813\n",
       "2      152.225\n",
       "3      136.288\n",
       "4      148.117\n",
       "        ...   \n",
       "235        NaN\n",
       "236        NaN\n",
       "237        NaN\n",
       "238        NaN\n",
       "239        NaN\n",
       "Name: Bahia - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>Bahia - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.440329</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-2.143224</td>\n",
       "      <td>-1.723080</td>\n",
       "      <td>-1.703176</td>\n",
       "      <td>-0.816345</td>\n",
       "      <td>-2.235724</td>\n",
       "      <td>-2.158201</td>\n",
       "      <td>-0.884052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.404914</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-2.108465</td>\n",
       "      <td>-1.735985</td>\n",
       "      <td>-1.684201</td>\n",
       "      <td>-0.772933</td>\n",
       "      <td>-2.194204</td>\n",
       "      <td>-2.117854</td>\n",
       "      <td>-0.885724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.373637</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-2.073707</td>\n",
       "      <td>-1.739214</td>\n",
       "      <td>-1.665225</td>\n",
       "      <td>-0.729522</td>\n",
       "      <td>-2.152684</td>\n",
       "      <td>-2.077508</td>\n",
       "      <td>-0.887395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.345888</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-2.038948</td>\n",
       "      <td>-1.738529</td>\n",
       "      <td>-1.646249</td>\n",
       "      <td>-0.686111</td>\n",
       "      <td>-2.111164</td>\n",
       "      <td>-2.037161</td>\n",
       "      <td>-0.889067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.319065</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-2.004190</td>\n",
       "      <td>-1.735989</td>\n",
       "      <td>-1.627274</td>\n",
       "      <td>-0.642700</td>\n",
       "      <td>-2.069645</td>\n",
       "      <td>-1.996814</td>\n",
       "      <td>-0.890739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.097864</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>1.430739</td>\n",
       "      <td>0.617097</td>\n",
       "      <td>1.205171</td>\n",
       "      <td>-1.332406</td>\n",
       "      <td>1.004714</td>\n",
       "      <td>1.051323</td>\n",
       "      <td>1.273469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.120412</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>1.428086</td>\n",
       "      <td>0.590103</td>\n",
       "      <td>1.206522</td>\n",
       "      <td>-1.357999</td>\n",
       "      <td>1.007770</td>\n",
       "      <td>1.045502</td>\n",
       "      <td>1.268173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.139591</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>1.425433</td>\n",
       "      <td>0.561454</td>\n",
       "      <td>1.207873</td>\n",
       "      <td>-1.383592</td>\n",
       "      <td>1.010826</td>\n",
       "      <td>1.039682</td>\n",
       "      <td>1.262877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.156903</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>1.422780</td>\n",
       "      <td>0.523492</td>\n",
       "      <td>1.209225</td>\n",
       "      <td>-1.409185</td>\n",
       "      <td>1.013881</td>\n",
       "      <td>1.033862</td>\n",
       "      <td>1.257581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.173599</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>1.420127</td>\n",
       "      <td>0.512378</td>\n",
       "      <td>1.210576</td>\n",
       "      <td>-1.434778</td>\n",
       "      <td>1.016937</td>\n",
       "      <td>1.028042</td>\n",
       "      <td>1.252286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bahia - value   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0        -1.440329                                          2.723741   \n",
       "1        -1.404914                                          2.350880   \n",
       "2        -1.373637                                          2.123016   \n",
       "3        -1.345888                                          2.021477   \n",
       "4        -1.319065                                          1.887113   \n",
       "..             ...                                               ...   \n",
       "157       1.097864                                         -0.214006   \n",
       "158       1.120412                                         -0.434717   \n",
       "159       1.139591                                         -0.524091   \n",
       "160       1.156903                                         -0.614500   \n",
       "161       1.173599                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Bahia - IDH  \\\n",
       "0                                 -2.389042   3.122582    -2.143224   \n",
       "1                                 -2.352139   2.970356    -2.108465   \n",
       "2                                 -2.315236   2.869895    -2.073707   \n",
       "3                                 -2.278333   2.773628    -2.038948   \n",
       "4                                 -2.241431   2.977624    -2.004190   \n",
       "..                                      ...        ...          ...   \n",
       "157                                0.819304  -0.883659     1.430739   \n",
       "158                                0.808136  -0.950771     1.428086   \n",
       "159                                0.796969  -1.028465     1.425433   \n",
       "160                                0.785801  -1.103668     1.422780   \n",
       "161                                0.774634  -0.978419     1.420127   \n",
       "\n",
       "     Bahia - Produção de Cimento (t)  Bahia - PIB - Estadual  \\\n",
       "0                          -1.723080               -1.703176   \n",
       "1                          -1.735985               -1.684201   \n",
       "2                          -1.739214               -1.665225   \n",
       "3                          -1.738529               -1.646249   \n",
       "4                          -1.735989               -1.627274   \n",
       "..                               ...                     ...   \n",
       "157                         0.617097                1.205171   \n",
       "158                         0.590103                1.206522   \n",
       "159                         0.561454                1.207873   \n",
       "160                         0.523492                1.209225   \n",
       "161                         0.512378                1.210576   \n",
       "\n",
       "     Bahia - PIB - Construção Civil  Bahia - PIB - Per Capita  \\\n",
       "0                         -0.816345                 -2.235724   \n",
       "1                         -0.772933                 -2.194204   \n",
       "2                         -0.729522                 -2.152684   \n",
       "3                         -0.686111                 -2.111164   \n",
       "4                         -0.642700                 -2.069645   \n",
       "..                              ...                       ...   \n",
       "157                       -1.332406                  1.004714   \n",
       "158                       -1.357999                  1.007770   \n",
       "159                       -1.383592                  1.010826   \n",
       "160                       -1.409185                  1.013881   \n",
       "161                       -1.434778                  1.016937   \n",
       "\n",
       "     Bahia - PIB - Preços de Mercado  Bahia - Desemprego  \n",
       "0                          -2.158201           -0.884052  \n",
       "1                          -2.117854           -0.885724  \n",
       "2                          -2.077508           -0.887395  \n",
       "3                          -2.037161           -0.889067  \n",
       "4                          -1.996814           -0.890739  \n",
       "..                               ...                 ...  \n",
       "157                         1.051323            1.273469  \n",
       "158                         1.045502            1.268173  \n",
       "159                         1.039682            1.262877  \n",
       "160                         1.033862            1.257581  \n",
       "161                         1.028042            1.252286  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      129.857\n",
       "1      126.813\n",
       "2      152.225\n",
       "3      136.288\n",
       "4      148.117\n",
       "        ...   \n",
       "157    213.266\n",
       "158    285.938\n",
       "159    219.576\n",
       "160    267.203\n",
       "161    240.714\n",
       "Name: Bahia - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bahia - value</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Bahia - IDH</th>\n",
       "      <th>Bahia - Produção de Cimento (t)</th>\n",
       "      <th>Bahia - PIB - Estadual</th>\n",
       "      <th>Bahia - PIB - Construção Civil</th>\n",
       "      <th>Bahia - PIB - Per Capita</th>\n",
       "      <th>Bahia - PIB - Preços de Mercado</th>\n",
       "      <th>Bahia - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.191770</td>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>1.417474</td>\n",
       "      <td>0.500213</td>\n",
       "      <td>1.211927</td>\n",
       "      <td>-1.460371</td>\n",
       "      <td>1.019993</td>\n",
       "      <td>1.022222</td>\n",
       "      <td>1.246990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.216939</td>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>1.414821</td>\n",
       "      <td>0.496834</td>\n",
       "      <td>1.213278</td>\n",
       "      <td>-1.485964</td>\n",
       "      <td>1.023048</td>\n",
       "      <td>1.016401</td>\n",
       "      <td>1.241694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.243300</td>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>1.412168</td>\n",
       "      <td>0.484739</td>\n",
       "      <td>1.214629</td>\n",
       "      <td>-1.511558</td>\n",
       "      <td>1.026104</td>\n",
       "      <td>1.010581</td>\n",
       "      <td>1.236398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.273404</td>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>1.409516</td>\n",
       "      <td>0.482071</td>\n",
       "      <td>1.215980</td>\n",
       "      <td>-1.537151</td>\n",
       "      <td>1.029160</td>\n",
       "      <td>1.004761</td>\n",
       "      <td>1.231103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.301186</td>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>1.406863</td>\n",
       "      <td>0.473941</td>\n",
       "      <td>1.217331</td>\n",
       "      <td>-1.562744</td>\n",
       "      <td>1.032215</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>1.225807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.333756</td>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>1.404210</td>\n",
       "      <td>0.434848</td>\n",
       "      <td>1.218682</td>\n",
       "      <td>-1.588337</td>\n",
       "      <td>1.035271</td>\n",
       "      <td>0.993120</td>\n",
       "      <td>1.220511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.365896</td>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>1.401557</td>\n",
       "      <td>0.435705</td>\n",
       "      <td>1.220034</td>\n",
       "      <td>-1.613930</td>\n",
       "      <td>1.038327</td>\n",
       "      <td>0.987300</td>\n",
       "      <td>1.215215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.395788</td>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>1.394425</td>\n",
       "      <td>0.428428</td>\n",
       "      <td>1.216488</td>\n",
       "      <td>-1.620901</td>\n",
       "      <td>1.040208</td>\n",
       "      <td>0.977171</td>\n",
       "      <td>1.214232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.426027</td>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>1.387293</td>\n",
       "      <td>0.426831</td>\n",
       "      <td>1.212943</td>\n",
       "      <td>-1.627872</td>\n",
       "      <td>1.042089</td>\n",
       "      <td>0.967042</td>\n",
       "      <td>1.213248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.463270</td>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>1.380162</td>\n",
       "      <td>0.407983</td>\n",
       "      <td>1.209397</td>\n",
       "      <td>-1.634843</td>\n",
       "      <td>1.043970</td>\n",
       "      <td>0.956913</td>\n",
       "      <td>1.212264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.502826</td>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>1.373030</td>\n",
       "      <td>0.413054</td>\n",
       "      <td>1.205852</td>\n",
       "      <td>-1.641814</td>\n",
       "      <td>1.045850</td>\n",
       "      <td>0.946783</td>\n",
       "      <td>1.211281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.537157</td>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>1.365898</td>\n",
       "      <td>0.396093</td>\n",
       "      <td>1.202307</td>\n",
       "      <td>-1.648785</td>\n",
       "      <td>1.047731</td>\n",
       "      <td>0.936654</td>\n",
       "      <td>1.210297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.579311</td>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>1.358766</td>\n",
       "      <td>0.392174</td>\n",
       "      <td>1.198761</td>\n",
       "      <td>-1.655755</td>\n",
       "      <td>1.049612</td>\n",
       "      <td>0.926525</td>\n",
       "      <td>1.209313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.620762</td>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>1.351635</td>\n",
       "      <td>0.389576</td>\n",
       "      <td>1.195216</td>\n",
       "      <td>-1.662726</td>\n",
       "      <td>1.051493</td>\n",
       "      <td>0.916396</td>\n",
       "      <td>1.208330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.656993</td>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>1.344503</td>\n",
       "      <td>0.388298</td>\n",
       "      <td>1.191670</td>\n",
       "      <td>-1.669697</td>\n",
       "      <td>1.053374</td>\n",
       "      <td>0.906267</td>\n",
       "      <td>1.207346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.691306</td>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>1.337371</td>\n",
       "      <td>0.396703</td>\n",
       "      <td>1.188125</td>\n",
       "      <td>-1.676668</td>\n",
       "      <td>1.055255</td>\n",
       "      <td>0.896137</td>\n",
       "      <td>1.206362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.705036</td>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>1.330240</td>\n",
       "      <td>0.391887</td>\n",
       "      <td>1.184580</td>\n",
       "      <td>-1.683639</td>\n",
       "      <td>1.057136</td>\n",
       "      <td>0.886008</td>\n",
       "      <td>1.205379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.718688</td>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>1.323108</td>\n",
       "      <td>0.397456</td>\n",
       "      <td>1.181034</td>\n",
       "      <td>-1.690610</td>\n",
       "      <td>1.059017</td>\n",
       "      <td>0.875879</td>\n",
       "      <td>1.204395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.734526</td>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>1.315976</td>\n",
       "      <td>0.416623</td>\n",
       "      <td>1.177489</td>\n",
       "      <td>-1.697581</td>\n",
       "      <td>1.060898</td>\n",
       "      <td>0.865750</td>\n",
       "      <td>1.203411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.750343</td>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>1.308196</td>\n",
       "      <td>0.428849</td>\n",
       "      <td>1.165983</td>\n",
       "      <td>-1.693364</td>\n",
       "      <td>1.034663</td>\n",
       "      <td>0.845637</td>\n",
       "      <td>1.203046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.758710</td>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>1.300416</td>\n",
       "      <td>0.433867</td>\n",
       "      <td>1.154477</td>\n",
       "      <td>-1.689147</td>\n",
       "      <td>1.008429</td>\n",
       "      <td>0.825525</td>\n",
       "      <td>1.202680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.768415</td>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>1.292636</td>\n",
       "      <td>0.426935</td>\n",
       "      <td>1.142971</td>\n",
       "      <td>-1.684931</td>\n",
       "      <td>0.982194</td>\n",
       "      <td>0.805412</td>\n",
       "      <td>1.202315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.783156</td>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>1.284856</td>\n",
       "      <td>0.436719</td>\n",
       "      <td>1.131465</td>\n",
       "      <td>-1.680714</td>\n",
       "      <td>0.955959</td>\n",
       "      <td>0.785299</td>\n",
       "      <td>1.201949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.780314</td>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>1.277076</td>\n",
       "      <td>0.479239</td>\n",
       "      <td>1.119959</td>\n",
       "      <td>-1.676497</td>\n",
       "      <td>0.929725</td>\n",
       "      <td>0.765187</td>\n",
       "      <td>1.201584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.783153</td>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>1.269296</td>\n",
       "      <td>0.496555</td>\n",
       "      <td>1.108453</td>\n",
       "      <td>-1.672281</td>\n",
       "      <td>0.903490</td>\n",
       "      <td>0.745074</td>\n",
       "      <td>1.201218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.796141</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.261516</td>\n",
       "      <td>0.511535</td>\n",
       "      <td>1.096947</td>\n",
       "      <td>-1.668064</td>\n",
       "      <td>0.877256</td>\n",
       "      <td>0.724962</td>\n",
       "      <td>1.200853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.811284</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.253736</td>\n",
       "      <td>0.513264</td>\n",
       "      <td>1.085441</td>\n",
       "      <td>-1.663847</td>\n",
       "      <td>0.851021</td>\n",
       "      <td>0.704849</td>\n",
       "      <td>1.200487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.833479</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.245956</td>\n",
       "      <td>0.526782</td>\n",
       "      <td>1.073935</td>\n",
       "      <td>-1.659631</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.684737</td>\n",
       "      <td>1.200122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.853109</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.238176</td>\n",
       "      <td>0.525379</td>\n",
       "      <td>1.062429</td>\n",
       "      <td>-1.655414</td>\n",
       "      <td>0.798552</td>\n",
       "      <td>0.664624</td>\n",
       "      <td>1.199756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.880066</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.230396</td>\n",
       "      <td>0.525808</td>\n",
       "      <td>1.050923</td>\n",
       "      <td>-1.651197</td>\n",
       "      <td>0.772317</td>\n",
       "      <td>0.644511</td>\n",
       "      <td>1.199390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bahia - value   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162       1.191770                                         -0.601510   \n",
       "163       1.216939                                         -0.786068   \n",
       "164       1.243300                                         -0.830387   \n",
       "165       1.273404                                         -0.801089   \n",
       "166       1.301186                                         -0.959917   \n",
       "167       1.333756                                         -1.022309   \n",
       "168       1.365896                                         -1.074401   \n",
       "169       1.395788                                         -1.119597   \n",
       "170       1.426027                                         -1.078648   \n",
       "171       1.463270                                         -1.055426   \n",
       "172       1.502826                                         -1.101053   \n",
       "173       1.537157                                         -1.211370   \n",
       "174       1.579311                                         -1.157198   \n",
       "175       1.620762                                         -1.223444   \n",
       "176       1.656993                                         -1.311519   \n",
       "177       1.691306                                         -1.362602   \n",
       "178       1.705036                                         -1.380125   \n",
       "179       1.718688                                         -1.219296   \n",
       "180       1.734526                                         -1.300284   \n",
       "181       1.750343                                         -1.336476   \n",
       "182       1.758710                                         -1.415774   \n",
       "183       1.768415                                         -1.526021   \n",
       "184       1.783156                                         -1.681806   \n",
       "185       1.780314                                         -1.735167   \n",
       "186       1.783153                                         -1.962315   \n",
       "187       1.796141                                         -2.010387   \n",
       "188       1.811284                                         -1.870713   \n",
       "189       1.833479                                         -1.806230   \n",
       "190       1.853109                                         -1.727496   \n",
       "191       1.880066                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Bahia - IDH  \\\n",
       "162                                0.763466  -1.213929     1.417474   \n",
       "163                                0.752299  -1.292173     1.414821   \n",
       "164                                0.741131  -1.324219     1.412168   \n",
       "165                                0.729964  -1.344446     1.409516   \n",
       "166                                0.718796  -1.381638     1.406863   \n",
       "167                                0.707629  -1.411208     1.404210   \n",
       "168                                0.696461  -1.412953     1.401557   \n",
       "169                                0.681823  -1.491464     1.394425   \n",
       "170                                0.667184  -1.573805     1.387293   \n",
       "171                                0.652545  -1.564950     1.380162   \n",
       "172                                0.637906  -1.581584     1.373030   \n",
       "173                                0.623268  -1.565976     1.365898   \n",
       "174                                0.608629  -1.648556     1.358766   \n",
       "175                                0.593990  -1.650049     1.351635   \n",
       "176                                0.579351  -1.653957     1.344503   \n",
       "177                                0.564713  -1.652572     1.337371   \n",
       "178                                0.550074  -1.715349     1.330240   \n",
       "179                                0.535435  -1.750917     1.323108   \n",
       "180                                0.520796  -1.718448     1.315976   \n",
       "181                                0.501996  -1.733426     1.308196   \n",
       "182                                0.483195  -1.729362     1.300416   \n",
       "183                                0.464395  -1.748544     1.292636   \n",
       "184                                0.445594  -1.778060     1.284856   \n",
       "185                                0.426794  -1.773710     1.277076   \n",
       "186                                0.407993  -1.757007     1.269296   \n",
       "187                                0.389193  -1.749976     1.261516   \n",
       "188                                0.370392  -1.593005     1.253736   \n",
       "189                                0.351592  -1.351489     1.245956   \n",
       "190                                0.332791  -1.198492     1.238176   \n",
       "191                                0.313991  -1.100894     1.230396   \n",
       "\n",
       "     Bahia - Produção de Cimento (t)  Bahia - PIB - Estadual  \\\n",
       "162                         0.500213                1.211927   \n",
       "163                         0.496834                1.213278   \n",
       "164                         0.484739                1.214629   \n",
       "165                         0.482071                1.215980   \n",
       "166                         0.473941                1.217331   \n",
       "167                         0.434848                1.218682   \n",
       "168                         0.435705                1.220034   \n",
       "169                         0.428428                1.216488   \n",
       "170                         0.426831                1.212943   \n",
       "171                         0.407983                1.209397   \n",
       "172                         0.413054                1.205852   \n",
       "173                         0.396093                1.202307   \n",
       "174                         0.392174                1.198761   \n",
       "175                         0.389576                1.195216   \n",
       "176                         0.388298                1.191670   \n",
       "177                         0.396703                1.188125   \n",
       "178                         0.391887                1.184580   \n",
       "179                         0.397456                1.181034   \n",
       "180                         0.416623                1.177489   \n",
       "181                         0.428849                1.165983   \n",
       "182                         0.433867                1.154477   \n",
       "183                         0.426935                1.142971   \n",
       "184                         0.436719                1.131465   \n",
       "185                         0.479239                1.119959   \n",
       "186                         0.496555                1.108453   \n",
       "187                         0.511535                1.096947   \n",
       "188                         0.513264                1.085441   \n",
       "189                         0.526782                1.073935   \n",
       "190                         0.525379                1.062429   \n",
       "191                         0.525808                1.050923   \n",
       "\n",
       "     Bahia - PIB - Construção Civil  Bahia - PIB - Per Capita  \\\n",
       "162                       -1.460371                  1.019993   \n",
       "163                       -1.485964                  1.023048   \n",
       "164                       -1.511558                  1.026104   \n",
       "165                       -1.537151                  1.029160   \n",
       "166                       -1.562744                  1.032215   \n",
       "167                       -1.588337                  1.035271   \n",
       "168                       -1.613930                  1.038327   \n",
       "169                       -1.620901                  1.040208   \n",
       "170                       -1.627872                  1.042089   \n",
       "171                       -1.634843                  1.043970   \n",
       "172                       -1.641814                  1.045850   \n",
       "173                       -1.648785                  1.047731   \n",
       "174                       -1.655755                  1.049612   \n",
       "175                       -1.662726                  1.051493   \n",
       "176                       -1.669697                  1.053374   \n",
       "177                       -1.676668                  1.055255   \n",
       "178                       -1.683639                  1.057136   \n",
       "179                       -1.690610                  1.059017   \n",
       "180                       -1.697581                  1.060898   \n",
       "181                       -1.693364                  1.034663   \n",
       "182                       -1.689147                  1.008429   \n",
       "183                       -1.684931                  0.982194   \n",
       "184                       -1.680714                  0.955959   \n",
       "185                       -1.676497                  0.929725   \n",
       "186                       -1.672281                  0.903490   \n",
       "187                       -1.668064                  0.877256   \n",
       "188                       -1.663847                  0.851021   \n",
       "189                       -1.659631                  0.824786   \n",
       "190                       -1.655414                  0.798552   \n",
       "191                       -1.651197                  0.772317   \n",
       "\n",
       "     Bahia - PIB - Preços de Mercado  Bahia - Desemprego  \n",
       "162                         1.022222            1.246990  \n",
       "163                         1.016401            1.241694  \n",
       "164                         1.010581            1.236398  \n",
       "165                         1.004761            1.231103  \n",
       "166                         0.998941            1.225807  \n",
       "167                         0.993120            1.220511  \n",
       "168                         0.987300            1.215215  \n",
       "169                         0.977171            1.214232  \n",
       "170                         0.967042            1.213248  \n",
       "171                         0.956913            1.212264  \n",
       "172                         0.946783            1.211281  \n",
       "173                         0.936654            1.210297  \n",
       "174                         0.926525            1.209313  \n",
       "175                         0.916396            1.208330  \n",
       "176                         0.906267            1.207346  \n",
       "177                         0.896137            1.206362  \n",
       "178                         0.886008            1.205379  \n",
       "179                         0.875879            1.204395  \n",
       "180                         0.865750            1.203411  \n",
       "181                         0.845637            1.203046  \n",
       "182                         0.825525            1.202680  \n",
       "183                         0.805412            1.202315  \n",
       "184                         0.785299            1.201949  \n",
       "185                         0.765187            1.201584  \n",
       "186                         0.745074            1.201218  \n",
       "187                         0.724962            1.200853  \n",
       "188                         0.704849            1.200487  \n",
       "189                         0.684737            1.200122  \n",
       "190                         0.664624            1.199756  \n",
       "191                         0.644511            1.199390  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    250.101\n",
       "163    277.528\n",
       "164    270.092\n",
       "165    278.146\n",
       "166    257.458\n",
       "167    231.748\n",
       "168    268.336\n",
       "169    223.453\n",
       "170    241.464\n",
       "171    238.901\n",
       "172    191.989\n",
       "173    272.452\n",
       "174    261.009\n",
       "175    292.688\n",
       "176    258.881\n",
       "177    276.879\n",
       "178    255.774\n",
       "179    208.326\n",
       "180    291.428\n",
       "181    249.430\n",
       "182    241.612\n",
       "183    252.303\n",
       "184    281.912\n",
       "185    200.213\n",
       "186    270.511\n",
       "187    281.466\n",
       "188    285.535\n",
       "189    328.259\n",
       "190    298.078\n",
       "191    264.838\n",
       "Name: Bahia - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "#     train, train_val = validation_splitter(train_input, 6)\n",
    "#     target,target_val = validation_splitter(train_target, 6)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train_input, \n",
    "                        train_target, \n",
    "                        epochs=10000,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3087440751, 3666903063, 2552058620, 1216835641, 929956629, 1223562457, 4179932844, 1853179175, 2395913995, 1375589850, 869057096, 3620091391, 834038104, 1019828791, 1587637726, 416357323, 2058425316, 3837850274, 3650684689, 3787766180, 1092564551, 3102168795, 2739444285, 4062915347, 3087772582]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 33596.68359375\n",
      "winner_seed: 3087440751\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 47471.6328125\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 17224.587890625\n",
      "winner_seed: 2552058620\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 48926.71484375\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 15094.115234375\n",
      "winner_seed: 929956629\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 44672.9765625\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 36193.25390625\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 28547.390625\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 24565.931640625\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 64218.96875\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 42943.5078125\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 25036.275390625\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 40715.51171875\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 5645.50537109375\n",
      "winner_seed: 1019828791\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 5784.02392578125\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 6988.509765625\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 30684.294921875\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 28373.474609375\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 35333.0703125\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 18341.94921875\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 22452.93359375\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 32252.421875\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 21332.484375\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 53528.5625\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 16232.9375\n",
      "\n",
      "\n",
      "final_seed: 1019828791\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 1s 28ms/step - loss: 70762.7188 - val_loss: 46121.8008\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68242.8281 - val_loss: 95961.1641\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59072.4258 - val_loss: 6756.4531\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 34384.9609 - val_loss: 44410.6562\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10281.8975 - val_loss: 60186.0391\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1421.1132 - val_loss: 42904.5430\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 666.6014 - val_loss: 46883.9062\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 687.3931 - val_loss: 42943.7227\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 484.3922 - val_loss: 43323.3438\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 546.3504 - val_loss: 46403.0859\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 933.1213 - val_loss: 47704.0195\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 521.8787 - val_loss: 54147.0117\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 697.3541 - val_loss: 42595.9961\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 670.9420 - val_loss: 56373.3320\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 517.9294 - val_loss: 45308.8281\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 629.1374 - val_loss: 47783.7812\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 675.1160 - val_loss: 49935.8086\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 568.6606 - val_loss: 53681.8750\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 551.8380 - val_loss: 54303.0664\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 568.6555 - val_loss: 53732.7461\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 496.5457 - val_loss: 52964.3203\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 571.2680 - val_loss: 49057.3633\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 513.6390 - val_loss: 52654.5039\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 579.8649 - val_loss: 47752.8828\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 664.4080 - val_loss: 50227.5469\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 433.6647 - val_loss: 54531.0859\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 415.2668 - val_loss: 42746.1016\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 472.6911 - val_loss: 44870.6602\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 503.8671 - val_loss: 44194.9648\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 400.3009 - val_loss: 47377.4727\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 431.2924 - val_loss: 53222.3398\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 437.4177 - val_loss: 48756.9062\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 549.0615 - val_loss: 54171.8867\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 499.8507 - val_loss: 49986.2188\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 413.3250 - val_loss: 51188.0820\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 410.1401 - val_loss: 49184.7656\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 508.5391 - val_loss: 47443.3828\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 410.2468 - val_loss: 48721.0195\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 365.1515 - val_loss: 48038.7188\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 405.4418 - val_loss: 50113.2812\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 430.0683 - val_loss: 57737.2109\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 500.9637 - val_loss: 57148.6094\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 420.2783 - val_loss: 54909.1953\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 507.2789 - val_loss: 52475.2930\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 399.8967 - val_loss: 53083.4492\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 468.3930 - val_loss: 51045.0039\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 410.2679 - val_loss: 56298.3438\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 562.7760 - val_loss: 49437.9141\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 436.9699 - val_loss: 51509.2188\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 790.8758 - val_loss: 62500.6484\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 567.6653 - val_loss: 59202.4766\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 526.3857 - val_loss: 56727.8359\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 734.9335 - val_loss: 60530.6562\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 481.6196 - val_loss: 56736.9766\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 469.2811 - val_loss: 59413.8125\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 415.4225 - val_loss: 59071.7812\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 612.0873 - val_loss: 64323.5078\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 606.1981 - val_loss: 57043.9180\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1037.4808 - val_loss: 65089.3438\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 692.4703 - val_loss: 60252.0273\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 626.6808 - val_loss: 74218.9531\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 565.8890 - val_loss: 75801.4219\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 482.9784 - val_loss: 70663.7422\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 604.7797 - val_loss: 75553.0391\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 710.8105 - val_loss: 76028.6328\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 746.8112 - val_loss: 80778.8594\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 797.3768 - val_loss: 75728.6328\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 665.5087 - val_loss: 77802.5469\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 666.9763 - val_loss: 74749.6953\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 603.3775 - val_loss: 74861.7969\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 596.7578 - val_loss: 61437.3750\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 634.9323 - val_loss: 64982.2344\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 698.1390 - val_loss: 63919.8828\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 826.1656 - val_loss: 72086.8047\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 818.7443 - val_loss: 76187.1406\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 846.1675 - val_loss: 107899.2109\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1559.7681 - val_loss: 96718.7031\n",
      "Epoch 78/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 1510.1134 - val_loss: 96975.4453\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1896.3263 - val_loss: 82857.5469\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1985.5701 - val_loss: 101212.6953\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2577.6733 - val_loss: 110327.7969\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2454.4644 - val_loss: 101100.6484\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2088.8042 - val_loss: 89751.5312\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1916.1552 - val_loss: 109212.0547\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1945.4108 - val_loss: 89018.7266\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2179.8508 - val_loss: 108407.7734\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1368.8250 - val_loss: 94434.9453\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1099.5148 - val_loss: 91170.9375\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2049.0066 - val_loss: 109370.8750\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2265.8940 - val_loss: 108310.3828\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2181.3901 - val_loss: 100602.6797\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1823.0638 - val_loss: 92652.8125\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1775.6469 - val_loss: 93238.0547\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2520.2104 - val_loss: 104858.1641\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2766.6833 - val_loss: 115006.6875\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2555.2488 - val_loss: 101344.0000\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2617.7617 - val_loss: 110934.0703\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2389.9146 - val_loss: 125291.8125\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2284.3423 - val_loss: 98475.2812\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 14318.3711 - val_loss: 3845.6133\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 36473.7500 - val_loss: 150479.9375\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 31982.7070 - val_loss: 41687.2773\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2401.6333 - val_loss: 19814.1543\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1347.2583 - val_loss: 28250.8945\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1372.1932 - val_loss: 28745.0332\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 963.8102 - val_loss: 29387.7793\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 855.3362 - val_loss: 23358.0840\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 742.8229 - val_loss: 22806.9199\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 692.1235 - val_loss: 20386.3281\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 783.9676 - val_loss: 30066.8730\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 714.6666 - val_loss: 26789.4805\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 660.8080 - val_loss: 23922.0781\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 629.4551 - val_loss: 26458.9785\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 542.4443 - val_loss: 26493.4082\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 587.9843 - val_loss: 24543.2305\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 555.3748 - val_loss: 25302.0430\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 541.7059 - val_loss: 23833.1953\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 559.5471 - val_loss: 24662.0898\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1108.6669 - val_loss: 22474.2793\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 917.8766 - val_loss: 30769.4043\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 685.9794 - val_loss: 34078.9180\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 685.3665 - val_loss: 30569.8535\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 617.5169 - val_loss: 31419.0254\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 455.3827 - val_loss: 30265.0137\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 503.1170 - val_loss: 34198.2031\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 554.0135 - val_loss: 28256.8477\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 467.3551 - val_loss: 27054.2051\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 528.9901 - val_loss: 26052.6230\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 491.4062 - val_loss: 25094.3105\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 553.5784 - val_loss: 27821.6172\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 786.1281 - val_loss: 56133.9375\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 823.3091 - val_loss: 54098.8984\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 684.7310 - val_loss: 53471.3906\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 828.4064 - val_loss: 59895.0820\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 631.1946 - val_loss: 57810.2969\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 640.2061 - val_loss: 50863.3008\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 637.1050 - val_loss: 58515.2617\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 731.8090 - val_loss: 49215.3164\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 568.5768 - val_loss: 48435.0312\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 570.1772 - val_loss: 43659.3906\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 551.0210 - val_loss: 41573.5000\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 722.0717 - val_loss: 46839.2266\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 698.6311 - val_loss: 43716.2539\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 504.6648 - val_loss: 44887.3633\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 500.7657 - val_loss: 46244.7422\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 468.9298 - val_loss: 46334.1836\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 558.3857 - val_loss: 47312.6484\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 487.7069 - val_loss: 47473.5000\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 482.5509 - val_loss: 45542.1758\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 468.5953 - val_loss: 41438.9922\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 446.5707 - val_loss: 41769.9492\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 583.5257 - val_loss: 49938.9922\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 528.5336 - val_loss: 45436.1953\n",
      "Epoch 154/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 474.9884 - val_loss: 44659.4219\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 551.1142 - val_loss: 48855.2070\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 580.3477 - val_loss: 48995.8047\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 498.7071 - val_loss: 48354.2969\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 628.9984 - val_loss: 50176.6289\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 593.8937 - val_loss: 44674.0469\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 613.4746 - val_loss: 46238.7812\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 645.7176 - val_loss: 48555.9766\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 575.7727 - val_loss: 44770.0430\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 560.6746 - val_loss: 50799.8711\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 580.6221 - val_loss: 45727.7539\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 589.1898 - val_loss: 44395.6680\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 741.4115 - val_loss: 42494.0039\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 619.1909 - val_loss: 41437.2305\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 576.1244 - val_loss: 42818.4648\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 615.7261 - val_loss: 34993.2656\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 525.6260 - val_loss: 32165.4199\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 532.1415 - val_loss: 31326.6992\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 666.6171 - val_loss: 35649.5977\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 737.7002 - val_loss: 51416.7812\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 800.3329 - val_loss: 40354.1406\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 622.3660 - val_loss: 39894.3164\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 644.3260 - val_loss: 45688.2734\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 630.4724 - val_loss: 40800.4023\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 648.9387 - val_loss: 43707.4844\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 622.2850 - val_loss: 37577.8438\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 603.9057 - val_loss: 45187.6992\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 549.2927 - val_loss: 41351.6016\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 512.4811 - val_loss: 38460.6953\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 497.2788 - val_loss: 35468.5156\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 540.2502 - val_loss: 46702.8477\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 589.4258 - val_loss: 37310.4805\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 574.7713 - val_loss: 36608.3125\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 586.8621 - val_loss: 38080.6484\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 520.6323 - val_loss: 40704.5312\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 562.4067 - val_loss: 38376.2266\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 571.3912 - val_loss: 42180.0898\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 642.3025 - val_loss: 53791.2656\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 829.8815 - val_loss: 54732.3828\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 828.5590 - val_loss: 50516.4531\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 827.8511 - val_loss: 51156.2188\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 858.3483 - val_loss: 44901.2344\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 905.7956 - val_loss: 53870.5117\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1264.6078 - val_loss: 56080.4844\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1160.8682 - val_loss: 56539.5312\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1152.8708 - val_loss: 53213.6680\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1127.1338 - val_loss: 56049.6992\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1141.1466 - val_loss: 59179.9648\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1131.5972 - val_loss: 55624.4375\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1174.0632 - val_loss: 52672.4297\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1067.5419 - val_loss: 50788.3555\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 828.5588 - val_loss: 48573.0898\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 546.1473 - val_loss: 45453.2656\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 474.5274 - val_loss: 44777.9766\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 440.2939 - val_loss: 46900.7734\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 431.6024 - val_loss: 47059.4688\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 442.4485 - val_loss: 43856.5703\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 501.3667 - val_loss: 41677.5352\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 547.8104 - val_loss: 48225.2578\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 545.3839 - val_loss: 41703.9766\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 534.0653 - val_loss: 48889.7539\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 527.7298 - val_loss: 34083.6406\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 482.5764 - val_loss: 36199.8555\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 415.0906 - val_loss: 34119.5703\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 508.5196 - val_loss: 37401.7344\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 543.3257 - val_loss: 37515.8438\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 540.0404 - val_loss: 39686.2188\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 505.6871 - val_loss: 39127.4492\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 536.4081 - val_loss: 38589.1562\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 515.9814 - val_loss: 36085.0820\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 482.5780 - val_loss: 39076.9023\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 678.4495 - val_loss: 34801.3984\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 543.6668 - val_loss: 36627.5938\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 631.0223 - val_loss: 40529.7305\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 706.4343 - val_loss: 34312.6406\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 499.1843 - val_loss: 37321.7812\n",
      "Epoch 230/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 751.0035 - val_loss: 34240.3359\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 502.9473 - val_loss: 32191.5508\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 647.2759 - val_loss: 50572.3125\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1065.3741 - val_loss: 45578.4297\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 739.0164 - val_loss: 45059.6758\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 764.3983 - val_loss: 41380.9883\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 557.7856 - val_loss: 41827.1367\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 668.1111 - val_loss: 40999.6992\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 694.3544 - val_loss: 40450.5312\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 672.1030 - val_loss: 40999.8633\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 701.5574 - val_loss: 40838.7578\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 680.9931 - val_loss: 38625.2188\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 894.3035 - val_loss: 42803.7266\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 722.5080 - val_loss: 40411.6094\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 601.9398 - val_loss: 42877.2812\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 553.0521 - val_loss: 37476.7891\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 497.2534 - val_loss: 42610.3398\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 511.5956 - val_loss: 40280.2812\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 466.9653 - val_loss: 37996.1914\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 614.7905 - val_loss: 44569.4414\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 548.9280 - val_loss: 39067.8320\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 655.2913 - val_loss: 49707.9180\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 579.2241 - val_loss: 47993.4766\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 551.0733 - val_loss: 47685.9258\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 502.8391 - val_loss: 53794.3203\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 525.4478 - val_loss: 52210.5938\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 455.4277 - val_loss: 48866.5977\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 415.1725 - val_loss: 49753.2148\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 504.2344 - val_loss: 47850.5938\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 447.5684 - val_loss: 48057.2656\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 431.1982 - val_loss: 47502.8477\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 429.8559 - val_loss: 44114.5625\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 485.0633 - val_loss: 50221.4414\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 567.0160 - val_loss: 43170.0430\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 496.2657 - val_loss: 49952.4688\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 519.8024 - val_loss: 43599.3281\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 543.7949 - val_loss: 49121.8164\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 526.3372 - val_loss: 45375.2539\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 534.2245 - val_loss: 51045.9766\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 687.7859 - val_loss: 53984.6797\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 668.2068 - val_loss: 51363.7852\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 756.7817 - val_loss: 54569.5703\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 591.5925 - val_loss: 50006.2734\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 486.4165 - val_loss: 46948.2070\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 457.9447 - val_loss: 45138.7109\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 499.2348 - val_loss: 48887.9766\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 463.7067 - val_loss: 42240.1289\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 479.7395 - val_loss: 44365.0977\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 469.9346 - val_loss: 44428.4805\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 489.9625 - val_loss: 41658.8047\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 552.3173 - val_loss: 42695.1602\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 474.3377 - val_loss: 42271.7734\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 485.9329 - val_loss: 42375.7500\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 570.8380 - val_loss: 47855.7617\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 543.9742 - val_loss: 50360.3477\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 786.1747 - val_loss: 47764.1016\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 523.1437 - val_loss: 47090.3164\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 520.6560 - val_loss: 47740.7188\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 606.7209 - val_loss: 41689.1016\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 552.4027 - val_loss: 44172.8555\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 512.4656 - val_loss: 42414.9766\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 536.0251 - val_loss: 42797.6914\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 473.1328 - val_loss: 44959.4180\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 560.5025 - val_loss: 46593.9297\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 571.2999 - val_loss: 48002.3281\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 652.8625 - val_loss: 53167.4922\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 561.4877 - val_loss: 53590.6094\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 615.9814 - val_loss: 44624.6406\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 449.5300 - val_loss: 55320.9062\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 638.4398 - val_loss: 47653.4414\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 536.0937 - val_loss: 48830.8008\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 484.6765 - val_loss: 53856.4336\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 525.2097 - val_loss: 53382.6250\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 514.7903 - val_loss: 53328.8516\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 533.9589 - val_loss: 49348.7188\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 550.2174 - val_loss: 47439.2188\n",
      "Epoch 306/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 642.7585 - val_loss: 48895.8672\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 974.8203 - val_loss: 59154.8359\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 840.3202 - val_loss: 49425.0586\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 944.4700 - val_loss: 57350.7188\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 855.0098 - val_loss: 53721.4922\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 733.2249 - val_loss: 60189.4492\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 694.0012 - val_loss: 54691.0195\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 646.1424 - val_loss: 49523.7148\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 674.5055 - val_loss: 50761.8008\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 684.3633 - val_loss: 52778.6602\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 652.9984 - val_loss: 47394.4062\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 506.8177 - val_loss: 51864.0664\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 474.0759 - val_loss: 48000.0234\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 480.2923 - val_loss: 49422.0430\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 575.7198 - val_loss: 46243.4922\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 506.8753 - val_loss: 48420.8711\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 680.4186 - val_loss: 51884.3320\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 883.6580 - val_loss: 51808.9258\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 642.3903 - val_loss: 48178.8398\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 663.6147 - val_loss: 52397.8203\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 611.9897 - val_loss: 48938.9844\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 613.5762 - val_loss: 51385.4648\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 579.9715 - val_loss: 51877.3242\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 556.7841 - val_loss: 50559.2383\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 602.3673 - val_loss: 53204.2617\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 552.0795 - val_loss: 48980.0273\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 523.6754 - val_loss: 50230.3594\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 557.2179 - val_loss: 49558.2500\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1064.9293 - val_loss: 62280.2930\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1121.1960 - val_loss: 64989.2344\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1054.9647 - val_loss: 58689.2891\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 949.9078 - val_loss: 53272.0000\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1107.9396 - val_loss: 49939.0156\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 662.5021 - val_loss: 47797.7383\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 614.5441 - val_loss: 53499.0312\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 717.2854 - val_loss: 53565.5977\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 529.5936 - val_loss: 55902.4062\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1034.3456 - val_loss: 55290.2383\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1148.7849 - val_loss: 58100.6211\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1089.0790 - val_loss: 62643.0234\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1155.7832 - val_loss: 57011.5742\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1079.3352 - val_loss: 59873.1875\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1026.4713 - val_loss: 61044.4688\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 960.8964 - val_loss: 56194.5664\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 916.4453 - val_loss: 59970.0156\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 901.6084 - val_loss: 57641.1094\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 925.3518 - val_loss: 55096.2578\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 825.1770 - val_loss: 58100.8750\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 966.4854 - val_loss: 54265.1016\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 977.5466 - val_loss: 60560.8750\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 955.8541 - val_loss: 58807.8906\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 955.8427 - val_loss: 63001.0820\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 954.4015 - val_loss: 60723.8984\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 803.0738 - val_loss: 58522.8281\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 738.7227 - val_loss: 56776.9297\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 689.3741 - val_loss: 52845.7812\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 538.1589 - val_loss: 54163.2656\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 541.2700 - val_loss: 41429.7969\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 499.6400 - val_loss: 50855.8555\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 515.1987 - val_loss: 46806.9141\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 505.4482 - val_loss: 45995.0742\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 497.7437 - val_loss: 48519.8438\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 453.8351 - val_loss: 63849.0742\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 595.2086 - val_loss: 58784.9648\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 668.9757 - val_loss: 59020.1602\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 656.8271 - val_loss: 50909.4023\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 657.1623 - val_loss: 50041.8281\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 597.3538 - val_loss: 49632.1484\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 720.7563 - val_loss: 62430.4844\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 577.3821 - val_loss: 66959.6641\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 638.6284 - val_loss: 64287.8320\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 625.8666 - val_loss: 71421.3125\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 610.5090 - val_loss: 66162.0234\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 617.6578 - val_loss: 66174.2578\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 731.3184 - val_loss: 67049.6484\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 633.5468 - val_loss: 71582.2188\n",
      "Epoch 382/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 606.6561 - val_loss: 60233.2930\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 476.9404 - val_loss: 59695.9805\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 719.6329 - val_loss: 64536.9922\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 743.4510 - val_loss: 64183.7578\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 764.0748 - val_loss: 52566.9766\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 682.8452 - val_loss: 57323.0117\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 638.5187 - val_loss: 49897.6250\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 599.8776 - val_loss: 51771.0273\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 582.5887 - val_loss: 55335.7227\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 542.2227 - val_loss: 54819.6172\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 516.9270 - val_loss: 57032.0156\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 618.8384 - val_loss: 53009.1914\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 633.1304 - val_loss: 49747.9141\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 500.2033 - val_loss: 50020.2109\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 513.7208 - val_loss: 49160.9688\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 494.5801 - val_loss: 47116.1641\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 490.2047 - val_loss: 47262.1875\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 484.5768 - val_loss: 45904.3438\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 582.6708 - val_loss: 50331.4570\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 580.4245 - val_loss: 49100.2266\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 450.7688 - val_loss: 50059.9258\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 499.1320 - val_loss: 49502.3984\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 457.5560 - val_loss: 51604.1680\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 470.3459 - val_loss: 47287.9102\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 449.2930 - val_loss: 47032.1875\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 669.7587 - val_loss: 50284.4805\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 663.1319 - val_loss: 50103.3008\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 750.1613 - val_loss: 50426.3906\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 583.7986 - val_loss: 52327.2852\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 596.8043 - val_loss: 53513.6406\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 667.0333 - val_loss: 50174.5586\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 503.8354 - val_loss: 77883.0938\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1017.7141 - val_loss: 79740.1094\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1017.3678 - val_loss: 65528.3320\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 765.5439 - val_loss: 69125.2578\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 650.7400 - val_loss: 67146.3125\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 767.6439 - val_loss: 68737.4297\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 836.1856 - val_loss: 60373.1914\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 798.2133 - val_loss: 82588.0156\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1311.9899 - val_loss: 77554.2031\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1126.3704 - val_loss: 79757.0781\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1203.6410 - val_loss: 74844.3125\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1151.9805 - val_loss: 69293.7266\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1188.8251 - val_loss: 75872.4375\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1108.6115 - val_loss: 81433.1641\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1178.8788 - val_loss: 79733.8438\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1058.4929 - val_loss: 85530.4766\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1051.7706 - val_loss: 73142.4141\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 653.8864 - val_loss: 65437.0312\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 647.5831 - val_loss: 61266.1719\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 669.3215 - val_loss: 67676.8125\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 600.3160 - val_loss: 60607.9688\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 533.3273 - val_loss: 59259.4883\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 493.8708 - val_loss: 58214.1797\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 491.2589 - val_loss: 63914.8984\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 543.5652 - val_loss: 53606.9570\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 504.1114 - val_loss: 53784.6602\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 915.0436 - val_loss: 58141.3516\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 735.2402 - val_loss: 56021.0312\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 849.0142 - val_loss: 59050.1016\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 715.8368 - val_loss: 49509.3477\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 576.2685 - val_loss: 51495.0859\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 619.1121 - val_loss: 57904.5977\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 698.9543 - val_loss: 55288.7070\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 536.0190 - val_loss: 57910.5898\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 464.4438 - val_loss: 54221.9805\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 538.1664 - val_loss: 58036.9219\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 705.0687 - val_loss: 69059.8438\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 682.7169 - val_loss: 63028.4922\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 674.9490 - val_loss: 59464.9102\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 717.7534 - val_loss: 59751.2070\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 652.0182 - val_loss: 63178.7422\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 652.5128 - val_loss: 65320.4688\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 599.7753 - val_loss: 63236.8008\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 622.5244 - val_loss: 67648.1797\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 881.2415 - val_loss: 64150.2188\n",
      "Epoch 458/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 907.8095 - val_loss: 67280.0312\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 874.5809 - val_loss: 68307.5547\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 773.8878 - val_loss: 71065.7109\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 817.1711 - val_loss: 70138.1172\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 890.4361 - val_loss: 64448.7500\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 796.6820 - val_loss: 59789.0469\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1012.8525 - val_loss: 77483.1484\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 983.5948 - val_loss: 67405.8359\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 812.3415 - val_loss: 63065.9102\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 753.1025 - val_loss: 62434.0234\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 857.6559 - val_loss: 64096.8086\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 799.6494 - val_loss: 73198.7188\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 752.8400 - val_loss: 65349.6836\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 721.6752 - val_loss: 63898.0352\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 664.0743 - val_loss: 60772.9688\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 527.6384 - val_loss: 66849.8125\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 726.5004 - val_loss: 69116.5156\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 730.5677 - val_loss: 68177.7891\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 667.1871 - val_loss: 68144.1172\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 631.9382 - val_loss: 64595.9648\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 683.3867 - val_loss: 58943.3672\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 490.9407 - val_loss: 59971.1836\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 532.6907 - val_loss: 59920.0039\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 548.9043 - val_loss: 61106.6562\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 532.0421 - val_loss: 61427.7305\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1077.3810 - val_loss: 73692.6797\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1209.6473 - val_loss: 67413.8594\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1212.4097 - val_loss: 63163.1406\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1017.8102 - val_loss: 72470.6953\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 859.6162 - val_loss: 68719.3516\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 922.8807 - val_loss: 62275.4414\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1277.4917 - val_loss: 69768.8125\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1084.7828 - val_loss: 76391.1016\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1046.6226 - val_loss: 65644.4844\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 811.1828 - val_loss: 63260.6484\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 766.3807 - val_loss: 61826.2148\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 732.4370 - val_loss: 67366.2266\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 739.9682 - val_loss: 66024.9453\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 764.9630 - val_loss: 61220.1992\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 686.5117 - val_loss: 61811.6016\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 958.5297 - val_loss: 67312.2031\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1287.4066 - val_loss: 71892.6328\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1226.5784 - val_loss: 58730.6094\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1770.6284 - val_loss: 84227.8984\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4194.2476 - val_loss: 86885.5781\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4156.0786 - val_loss: 86917.0312\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4190.6685 - val_loss: 83725.7188\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4001.2219 - val_loss: 81466.6484\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4282.9429 - val_loss: 76667.1172\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4132.4175 - val_loss: 73301.5859\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3727.3345 - val_loss: 81748.6719\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3744.8484 - val_loss: 63627.1172\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4243.4053 - val_loss: 68633.0938\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3743.4714 - val_loss: 90103.8125\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3715.8057 - val_loss: 96656.1875\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3503.7107 - val_loss: 80953.3125\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3317.0884 - val_loss: 60371.2500\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2913.2190 - val_loss: 69676.5469\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2381.7200 - val_loss: 70359.3281\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2341.9700 - val_loss: 57966.6602\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2383.1633 - val_loss: 72401.2500\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2347.6294 - val_loss: 70856.7891\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1954.6379 - val_loss: 68355.2969\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1863.8857 - val_loss: 68324.4531\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1820.6658 - val_loss: 71079.0547\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1766.5927 - val_loss: 64366.5742\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1739.4818 - val_loss: 69685.1406\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1723.8383 - val_loss: 66602.8672\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1800.2401 - val_loss: 64186.5898\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1599.6758 - val_loss: 73187.6172\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1631.2645 - val_loss: 65911.4531\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1702.6119 - val_loss: 65235.9492\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2134.4590 - val_loss: 75130.5703\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2155.9998 - val_loss: 71151.0469\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2029.8130 - val_loss: 83974.2812\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1934.6678 - val_loss: 69444.7500\n",
      "Epoch 534/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 1744.2809 - val_loss: 70714.8516\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1824.6112 - val_loss: 76045.1797\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1825.8519 - val_loss: 69079.2031\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1899.5099 - val_loss: 70564.9375\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1687.9105 - val_loss: 81041.5312\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1999.2013 - val_loss: 77513.9844\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1703.2360 - val_loss: 72700.1250\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1775.7776 - val_loss: 68558.1406\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1746.0933 - val_loss: 76122.0000\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1622.7080 - val_loss: 70802.4297\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1612.8456 - val_loss: 68469.7344\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1808.6870 - val_loss: 74790.5703\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1635.0060 - val_loss: 73182.8672\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1604.5980 - val_loss: 69196.0625\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1653.4550 - val_loss: 68529.7578\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1651.4808 - val_loss: 73734.2812\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1633.2982 - val_loss: 72633.1719\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1633.2156 - val_loss: 76753.3438\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1801.1736 - val_loss: 66446.5547\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1635.3933 - val_loss: 58721.5547\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1792.1080 - val_loss: 63131.7812\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1481.6033 - val_loss: 67043.9531\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1664.9741 - val_loss: 65074.5156\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1612.4794 - val_loss: 64715.7852\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1605.4260 - val_loss: 57658.3828\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1784.0997 - val_loss: 52769.3828\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1599.0347 - val_loss: 62369.7422\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1614.3181 - val_loss: 58740.9297\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1678.2833 - val_loss: 63903.1758\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1609.9617 - val_loss: 67918.2344\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1506.9535 - val_loss: 61856.2422\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1588.9954 - val_loss: 63461.9102\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1661.0856 - val_loss: 61450.3945\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1577.8250 - val_loss: 63931.4844\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1609.2933 - val_loss: 59004.2422\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1565.4310 - val_loss: 59319.5117\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3045.5593 - val_loss: 85792.2656\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3175.0469 - val_loss: 84159.0234\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1950.6464 - val_loss: 65838.4922\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1365.2357 - val_loss: 64958.3398\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1653.1281 - val_loss: 77573.8203\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2022.3759 - val_loss: 59735.6445\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1711.6742 - val_loss: 66917.3594\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1815.0146 - val_loss: 59635.9414\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1767.7388 - val_loss: 67306.8125\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1536.3873 - val_loss: 59618.0352\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1805.1156 - val_loss: 59804.9141\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1901.2010 - val_loss: 71529.2656\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1642.8314 - val_loss: 55736.4375\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1841.1669 - val_loss: 70564.7109\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2173.4001 - val_loss: 62264.8594\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2312.0571 - val_loss: 60401.6953\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2473.6379 - val_loss: 67006.4375\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5206.2173 - val_loss: 55464.2969\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7241.8525 - val_loss: 79422.0000\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6081.1157 - val_loss: 77708.6875\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6534.7925 - val_loss: 70348.5312\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6379.9321 - val_loss: 79173.6328\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7303.5776 - val_loss: 96763.6562\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6973.5342 - val_loss: 81423.9141\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5945.4688 - val_loss: 65684.9453\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6336.1230 - val_loss: 84025.6562\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5999.9014 - val_loss: 69630.1406\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6805.3896 - val_loss: 76508.7031\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5914.3130 - val_loss: 88610.2109\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6234.2695 - val_loss: 71822.6484\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6302.4580 - val_loss: 93157.0391\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6505.3911 - val_loss: 72748.8906\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6434.4438 - val_loss: 67523.9922\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6271.7153 - val_loss: 71631.4688\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6159.5732 - val_loss: 75473.3047\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6076.7109 - val_loss: 87588.3203\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6078.9077 - val_loss: 75848.9844\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6127.2280 - val_loss: 73352.7422\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6407.0439 - val_loss: 91894.1953\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7008.1025 - val_loss: 78341.3906\n",
      "Epoch 610/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 6092.3252 - val_loss: 85416.7266\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6045.7563 - val_loss: 83255.9844\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6248.5986 - val_loss: 80143.3594\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5968.2231 - val_loss: 79826.5391\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6674.1157 - val_loss: 84419.8828\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6299.3447 - val_loss: 84628.7031\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6378.1553 - val_loss: 83946.2969\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6217.2627 - val_loss: 76062.5469\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6060.9014 - val_loss: 74642.6172\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6189.0645 - val_loss: 68865.6875\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6221.3647 - val_loss: 88892.1875\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5921.1382 - val_loss: 67170.2031\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6923.4600 - val_loss: 102717.5547\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6298.9839 - val_loss: 86032.9531\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6875.7480 - val_loss: 82153.4531\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7012.8628 - val_loss: 66495.2188\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6363.8135 - val_loss: 77324.9375\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6418.7998 - val_loss: 95356.8359\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6262.7295 - val_loss: 79231.3672\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6184.7002 - val_loss: 71223.1172\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6114.2544 - val_loss: 89346.9375\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6339.7539 - val_loss: 71002.9062\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6922.3687 - val_loss: 78159.6484\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6235.2202 - val_loss: 71671.5625\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6421.9648 - val_loss: 76039.0703\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6117.2598 - val_loss: 83692.6328\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6033.6431 - val_loss: 71884.7578\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6280.9482 - val_loss: 89114.1484\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6085.3467 - val_loss: 73558.7812\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6185.7974 - val_loss: 84702.3594\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6716.7700 - val_loss: 87899.9609\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6069.9282 - val_loss: 90826.8672\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6035.2251 - val_loss: 93549.9453\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6129.9541 - val_loss: 77183.1875\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6821.7471 - val_loss: 80995.9766\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5976.7183 - val_loss: 83319.6016\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5998.4727 - val_loss: 76438.7422\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6111.0205 - val_loss: 74934.2109\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6394.4497 - val_loss: 72939.8047\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6150.1689 - val_loss: 95334.4609\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6140.7573 - val_loss: 71317.7891\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6146.5571 - val_loss: 84968.3828\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6001.5986 - val_loss: 86972.7188\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6901.3696 - val_loss: 67649.8750\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6668.6626 - val_loss: 64703.3086\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6472.9741 - val_loss: 80660.3359\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6222.7915 - val_loss: 72280.6562\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6153.4541 - val_loss: 82583.8594\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6071.3081 - val_loss: 68061.0625\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6048.1812 - val_loss: 59764.3438\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7270.6465 - val_loss: 69572.9531\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6175.2173 - val_loss: 67388.5938\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6457.0513 - val_loss: 93610.3594\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6532.5679 - val_loss: 70465.6250\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6418.7979 - val_loss: 79835.9141\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6050.1943 - val_loss: 77159.2344\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6593.1011 - val_loss: 75210.0078\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5966.9600 - val_loss: 86495.7812\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6031.2476 - val_loss: 80762.9141\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5976.0044 - val_loss: 79428.5234\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6198.2573 - val_loss: 80755.6562\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5972.0718 - val_loss: 72840.8359\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6083.6387 - val_loss: 96676.7422\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6315.6929 - val_loss: 73641.1719\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6262.9883 - val_loss: 72607.2969\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6059.0630 - val_loss: 80541.8672\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6167.4785 - val_loss: 93000.0234\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6123.8462 - val_loss: 81960.9766\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6140.3896 - val_loss: 97139.7266\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6864.2622 - val_loss: 86073.3359\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6184.4263 - val_loss: 72272.6797\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6547.4282 - val_loss: 85636.7969\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6135.0352 - val_loss: 73494.0312\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6225.9946 - val_loss: 81869.5234\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6176.8550 - val_loss: 75393.5859\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6458.6904 - val_loss: 73949.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6208.0508 - val_loss: 91029.2891\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6400.7939 - val_loss: 80053.4609\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6236.5171 - val_loss: 78471.5781\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6065.3760 - val_loss: 90607.6875\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6497.7095 - val_loss: 85221.4766\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6246.1953 - val_loss: 62369.6328\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6453.0532 - val_loss: 91765.8047\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6096.2720 - val_loss: 81205.5000\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6201.2090 - val_loss: 94791.0781\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6285.7964 - val_loss: 78291.5078\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6739.4429 - val_loss: 78475.7500\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6147.1162 - val_loss: 85996.3203\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6872.0259 - val_loss: 77331.7344\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6110.9370 - val_loss: 72689.9062\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6265.0610 - val_loss: 72795.0703\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6199.9609 - val_loss: 82625.4219\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6034.9097 - val_loss: 79656.9375\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5982.6289 - val_loss: 80766.4688\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6051.2202 - val_loss: 94169.3906\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6897.6792 - val_loss: 81463.7500\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6567.0659 - val_loss: 84611.3828\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6909.9980 - val_loss: 72583.9922\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6329.5532 - val_loss: 77033.6875\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6041.7861 - val_loss: 87921.3672\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6617.9414 - val_loss: 78906.1953\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6176.4751 - val_loss: 79098.3750\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6416.0229 - val_loss: 80746.8984\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6014.7539 - val_loss: 71079.6953\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6278.5977 - val_loss: 91786.7734\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6267.4678 - val_loss: 59787.0859\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6663.3999 - val_loss: 82069.6562\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5949.0459 - val_loss: 77264.4453\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6587.5527 - val_loss: 62460.1602\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7818.3511 - val_loss: 92941.2500\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6362.8589 - val_loss: 73269.5703\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7206.1016 - val_loss: 67195.2578\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6506.9062 - val_loss: 81966.2500\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6020.3242 - val_loss: 76386.6875\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6008.6562 - val_loss: 68507.1094\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6546.6343 - val_loss: 72968.4062\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6039.4404 - val_loss: 78614.1797\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6569.5679 - val_loss: 82383.5469\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6553.6436 - val_loss: 73399.1797\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6290.2856 - val_loss: 67298.9453\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6728.7231 - val_loss: 92812.7812\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6798.7656 - val_loss: 68995.1094\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6487.4136 - val_loss: 78863.4453\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6634.2402 - val_loss: 88501.2266\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7107.6313 - val_loss: 95637.5938\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6294.4321 - val_loss: 81292.3828\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6923.0479 - val_loss: 87592.1094\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6149.8481 - val_loss: 93249.4062\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6576.4575 - val_loss: 82692.1797\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6387.1733 - val_loss: 99954.6016\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6590.0552 - val_loss: 83914.8125\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6089.8335 - val_loss: 70835.1719\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6010.5898 - val_loss: 87048.5703\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6314.6328 - val_loss: 77996.2266\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6369.0864 - val_loss: 65561.1328\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6427.7422 - val_loss: 72408.6016\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6234.9043 - val_loss: 83529.5078\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6536.8369 - val_loss: 77749.3594\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7040.1299 - val_loss: 85308.5859\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6387.2012 - val_loss: 74537.5703\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6074.1294 - val_loss: 69091.0547\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6502.4927 - val_loss: 62949.9844\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6998.6509 - val_loss: 81414.6250\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6594.7842 - val_loss: 102217.6641\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6995.4609 - val_loss: 77171.0703\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6131.4199 - val_loss: 80157.5625\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6832.5396 - val_loss: 83798.2891\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6801.7812 - val_loss: 80889.6328\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6641.6636 - val_loss: 92793.9141\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6434.8389 - val_loss: 73330.4531\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5965.3042 - val_loss: 89024.3203\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6024.2075 - val_loss: 81618.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6187.4375 - val_loss: 82921.5234\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5906.5254 - val_loss: 105018.7188\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4081.2932 - val_loss: 53812.1133\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2609.0247 - val_loss: 51267.8047\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2613.0825 - val_loss: 75466.9375\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2391.6042 - val_loss: 65258.3438\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2028.2008 - val_loss: 70378.3281\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1836.1062 - val_loss: 66472.4922\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1912.3347 - val_loss: 74910.0000\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2082.6292 - val_loss: 68174.1016\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1664.6920 - val_loss: 60580.8711\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1442.5680 - val_loss: 63799.6484\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1346.8644 - val_loss: 59222.1992\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1337.2196 - val_loss: 58945.2891\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1280.6003 - val_loss: 65672.3594\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1128.4435 - val_loss: 66476.5625\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1151.1356 - val_loss: 63072.5742\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 981.2521 - val_loss: 60111.3984\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1013.8633 - val_loss: 56258.5664\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 978.5747 - val_loss: 55684.7109\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 937.6944 - val_loss: 55974.6016\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1103.7560 - val_loss: 57555.4219\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 968.7555 - val_loss: 54082.4102\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1119.5997 - val_loss: 58270.0898\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 988.3207 - val_loss: 55737.6680\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 983.6451 - val_loss: 63388.2070\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 994.0246 - val_loss: 58378.2422\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 965.4716 - val_loss: 59627.9102\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 967.7593 - val_loss: 54763.3438\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1143.0857 - val_loss: 65706.0625\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1553.4701 - val_loss: 68443.5938\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1477.2974 - val_loss: 73539.9531\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1594.1969 - val_loss: 70314.7109\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1352.7363 - val_loss: 61795.0820\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1241.9674 - val_loss: 64517.5508\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1184.9325 - val_loss: 55192.1797\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1223.6436 - val_loss: 62424.4102\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1318.7333 - val_loss: 64771.7422\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1416.1364 - val_loss: 58652.9766\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1553.8702 - val_loss: 59629.4609\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1902.1599 - val_loss: 60449.0352\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1485.5879 - val_loss: 60940.8477\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1975.5620 - val_loss: 68177.9531\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1262.3591 - val_loss: 62692.9414\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1018.4716 - val_loss: 60819.5391\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 993.2744 - val_loss: 51610.3867\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1212.2812 - val_loss: 54978.8359\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 980.3419 - val_loss: 61624.3945\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1186.5066 - val_loss: 58032.0703\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1049.1028 - val_loss: 52900.4648\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 891.7475 - val_loss: 58486.8906\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1120.0421 - val_loss: 50253.4453\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 864.0814 - val_loss: 55603.5898\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 852.9174 - val_loss: 60156.0000\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 923.1667 - val_loss: 50364.0742\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 893.7762 - val_loss: 57484.3320\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 978.7382 - val_loss: 65132.0156\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1028.1704 - val_loss: 67008.8516\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1196.6971 - val_loss: 59876.8867\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1252.2643 - val_loss: 70415.2734\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1262.2045 - val_loss: 54481.8555\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 858.0184 - val_loss: 49140.7109\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1004.8308 - val_loss: 54141.7734\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 922.9858 - val_loss: 49947.0625\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 984.2765 - val_loss: 50851.0508\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 820.5068 - val_loss: 57794.9727\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 986.6868 - val_loss: 55742.8086\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 806.0790 - val_loss: 53461.0508\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 858.7079 - val_loss: 55693.3281\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1548.5098 - val_loss: 65150.9766\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1541.3079 - val_loss: 55124.8711\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1024.7228 - val_loss: 53542.0273\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1009.6289 - val_loss: 58759.0430\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1103.6880 - val_loss: 53214.5938\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 903.4821 - val_loss: 56865.7344\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1118.4741 - val_loss: 54631.7930\n",
      "Epoch 838/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 991.7265 - val_loss: 49088.7188\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1266.4680 - val_loss: 49816.1680\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1220.0951 - val_loss: 60499.5508\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1256.9331 - val_loss: 46736.4961\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1564.7593 - val_loss: 62949.8086\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1464.7955 - val_loss: 61714.7148\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1231.4192 - val_loss: 61740.2734\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2735.2046 - val_loss: 58464.6836\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2091.8389 - val_loss: 58332.5312\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2227.4719 - val_loss: 48340.0430\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2180.0823 - val_loss: 52939.4570\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1418.2063 - val_loss: 52127.0820\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1263.9154 - val_loss: 58489.5430\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1162.4362 - val_loss: 62934.2812\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1115.0035 - val_loss: 50344.3594\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1085.6608 - val_loss: 55718.3125\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1149.5265 - val_loss: 54250.0234\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1187.2141 - val_loss: 56079.8555\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1024.6805 - val_loss: 58322.8203\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1064.6125 - val_loss: 57450.5039\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1107.3363 - val_loss: 58877.5312\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1014.5450 - val_loss: 52099.8438\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1103.6732 - val_loss: 62540.8164\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1038.9711 - val_loss: 67302.0000\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 952.6896 - val_loss: 57735.6641\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 883.9617 - val_loss: 66532.8984\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 938.1147 - val_loss: 60603.0156\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 841.9269 - val_loss: 60321.1562\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 939.3660 - val_loss: 63161.6484\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 863.8012 - val_loss: 68276.3984\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 818.0229 - val_loss: 59278.3516\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 863.8225 - val_loss: 61070.0195\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 833.4930 - val_loss: 66419.3125\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 867.5454 - val_loss: 60964.1758\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 777.3204 - val_loss: 70302.9531\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 901.2709 - val_loss: 60127.8828\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 813.0411 - val_loss: 65792.0156\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 778.4185 - val_loss: 58751.6367\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 814.2759 - val_loss: 61445.8438\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 878.7360 - val_loss: 56194.8438\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 830.5375 - val_loss: 59061.1680\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 882.3077 - val_loss: 59283.8242\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 864.1926 - val_loss: 58858.0898\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 761.5517 - val_loss: 57232.1328\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 841.4971 - val_loss: 54892.9062\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 816.7211 - val_loss: 63442.4766\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 944.9916 - val_loss: 52048.3359\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1112.8832 - val_loss: 39322.1289\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 828.6316 - val_loss: 46238.3125\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 915.6547 - val_loss: 45871.6641\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 877.6734 - val_loss: 52863.7578\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 803.4993 - val_loss: 56675.5703\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 924.6526 - val_loss: 47425.0938\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 790.5705 - val_loss: 62332.0430\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 811.3115 - val_loss: 54023.6602\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 688.0214 - val_loss: 55676.6406\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 699.7880 - val_loss: 51723.4375\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 665.0036 - val_loss: 56127.1680\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 669.6768 - val_loss: 58069.6875\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 812.2731 - val_loss: 40934.6094\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1056.1757 - val_loss: 68599.7109\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1498.0951 - val_loss: 69506.1406\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1384.9821 - val_loss: 64178.5078\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1086.7709 - val_loss: 67408.1172\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1078.8748 - val_loss: 65633.7188\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1135.4929 - val_loss: 61161.4297\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1065.9684 - val_loss: 64645.6094\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1010.6464 - val_loss: 74082.2734\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1003.9536 - val_loss: 28711.7656\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 936.8791 - val_loss: 25128.0449\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 929.8388 - val_loss: 53416.0859\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1121.5073 - val_loss: 39246.0352\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 683.3267 - val_loss: 41202.2422\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 641.9634 - val_loss: 36260.2422\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 594.5846 - val_loss: 43368.0312\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 598.5101 - val_loss: 42206.1250\n",
      "Epoch 914/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 700.9818 - val_loss: 75944.6406\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3314.3926 - val_loss: 40434.7227\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1003.1689 - val_loss: 30123.5723\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 746.7333 - val_loss: 49023.8281\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 785.5565 - val_loss: 36782.3047\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 640.0292 - val_loss: 43476.8867\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 642.2939 - val_loss: 39991.3359\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 646.7294 - val_loss: 42526.3438\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 807.1319 - val_loss: 52189.0039\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 726.4735 - val_loss: 49549.9062\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 632.1503 - val_loss: 47357.8203\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 525.0141 - val_loss: 43524.1523\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 624.1165 - val_loss: 56795.7812\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 735.7849 - val_loss: 48144.6797\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 593.8951 - val_loss: 47008.4844\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 562.7477 - val_loss: 46487.4023\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 539.1373 - val_loss: 42965.0703\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 734.8488 - val_loss: 44550.6055\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 602.6163 - val_loss: 46057.2109\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 481.2520 - val_loss: 45439.6133\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 494.1648 - val_loss: 42603.2422\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 579.9230 - val_loss: 48201.6680\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 474.4177 - val_loss: 47487.8398\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 500.9027 - val_loss: 49719.6094\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 522.7783 - val_loss: 47086.1172\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 505.2131 - val_loss: 46261.9688\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 550.3644 - val_loss: 44806.1562\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 564.9778 - val_loss: 44031.6484\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 569.3757 - val_loss: 44451.3555\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 552.5835 - val_loss: 45010.5312\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 518.5234 - val_loss: 43281.7109\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 494.4299 - val_loss: 49329.0664\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 639.3315 - val_loss: 41047.7188\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 564.2809 - val_loss: 42339.6641\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 465.5417 - val_loss: 40412.8555\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 373.8845 - val_loss: 38479.2148\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 396.9135 - val_loss: 38507.3516\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 492.9205 - val_loss: 40360.1719\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 508.9232 - val_loss: 45454.7656\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 530.4280 - val_loss: 45659.0117\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 437.0023 - val_loss: 44243.7031\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 440.7510 - val_loss: 44067.1836\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 515.5117 - val_loss: 47910.2812\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 529.3407 - val_loss: 44866.8672\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 602.9873 - val_loss: 41052.4062\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 612.0142 - val_loss: 53991.0156\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 639.7850 - val_loss: 45654.2070\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 455.3084 - val_loss: 45844.2656\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 539.5451 - val_loss: 44976.6758\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 627.7917 - val_loss: 44007.4180\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 527.4333 - val_loss: 46245.5859\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 563.4131 - val_loss: 41963.6953\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 467.3468 - val_loss: 41246.9844\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 431.6118 - val_loss: 40846.4844\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 437.8076 - val_loss: 44851.2227\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 535.1740 - val_loss: 58049.8789\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 428.3620 - val_loss: 57147.1836\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 554.4061 - val_loss: 46858.6992\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 639.5955 - val_loss: 41296.8906\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 587.5879 - val_loss: 76604.9375\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 628.6201 - val_loss: 69349.0859\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1028.3481 - val_loss: 51045.5703\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1098.6547 - val_loss: 46543.8477\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 902.5563 - val_loss: 46993.5195\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 799.7333 - val_loss: 45457.5273\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 726.5541 - val_loss: 52251.3594\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 709.2557 - val_loss: 44994.5898\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1081.8262 - val_loss: 48084.0156\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1078.3330 - val_loss: 45941.6289\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 974.2297 - val_loss: 48456.0898\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 887.8679 - val_loss: 47422.3398\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 715.5850 - val_loss: 44028.5273\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 570.7798 - val_loss: 45663.5117\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 797.9042 - val_loss: 42695.0352\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 736.0851 - val_loss: 43084.6367\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 661.5182 - val_loss: 37170.7969\n",
      "Epoch 990/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 561.4554 - val_loss: 39392.0469\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 552.9238 - val_loss: 43210.0391\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 611.5352 - val_loss: 51888.0430\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 618.9458 - val_loss: 44786.2266\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 530.2848 - val_loss: 38324.0312\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 843.7973 - val_loss: 43338.0547\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1023.4802 - val_loss: 48586.9727\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 962.1133 - val_loss: 48784.0273\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 804.9212 - val_loss: 44670.5430\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 718.4946 - val_loss: 48136.9336\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 934.3567 - val_loss: 44931.4023\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 831.4421 - val_loss: 48372.0781\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 888.0264 - val_loss: 43746.6094\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 778.5015 - val_loss: 46781.6172\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 986.1892 - val_loss: 46787.7852\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1119.3405 - val_loss: 44017.8945\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 934.3100 - val_loss: 44803.7539\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1092.7690 - val_loss: 46583.0664\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 677.0760 - val_loss: 46446.0312\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 633.3370 - val_loss: 46280.4609\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 516.9607 - val_loss: 40352.7578\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 521.7634 - val_loss: 39570.6016\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 766.5364 - val_loss: 46953.9023\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 864.7649 - val_loss: 47131.0469\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 765.0644 - val_loss: 46871.7656\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 794.0595 - val_loss: 45449.8359\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 797.0516 - val_loss: 42523.2812\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 696.4083 - val_loss: 43877.7227\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 660.9451 - val_loss: 40211.4922\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 669.9449 - val_loss: 36795.4570\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 643.8442 - val_loss: 35773.4336\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 588.8211 - val_loss: 40436.6367\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 654.3390 - val_loss: 43234.3984\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 500.7744 - val_loss: 40464.4688\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 643.4784 - val_loss: 41619.5273\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 621.1246 - val_loss: 39303.1523\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 699.6307 - val_loss: 38402.9414\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 754.5952 - val_loss: 43591.3438\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 690.6735 - val_loss: 42228.6328\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 608.6246 - val_loss: 37128.8438\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 534.4933 - val_loss: 36944.9062\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 542.0361 - val_loss: 36052.5781\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 598.6085 - val_loss: 38288.4648\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1299.7827 - val_loss: 35094.8633\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 961.9147 - val_loss: 46192.2539\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 715.8198 - val_loss: 40321.0312\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 533.9385 - val_loss: 37661.4648\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 617.1070 - val_loss: 36810.7422\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 866.4542 - val_loss: 58453.7227\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 961.5430 - val_loss: 32942.4961\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1030.2272 - val_loss: 46695.5781\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 737.2419 - val_loss: 46472.0078\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 646.1495 - val_loss: 50506.1602\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1882.9750 - val_loss: 35209.8906\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1762.6354 - val_loss: 47592.8164\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1385.6163 - val_loss: 47629.4062\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1294.7229 - val_loss: 47470.4219\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1119.9175 - val_loss: 48910.9922\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1047.1953 - val_loss: 50612.7109\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1025.9052 - val_loss: 50430.9688\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1019.9924 - val_loss: 59268.0625\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 796.1046 - val_loss: 54913.6250\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 713.0416 - val_loss: 47179.9102\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 747.4984 - val_loss: 49837.4336\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 622.6044 - val_loss: 48663.6875\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 666.4512 - val_loss: 56593.7188\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 681.5460 - val_loss: 45961.7812\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 749.6104 - val_loss: 47865.0430\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 605.7583 - val_loss: 50478.1523\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 562.8555 - val_loss: 42054.8516\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 845.3461 - val_loss: 57929.4062\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 795.3218 - val_loss: 57187.2461\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 783.8655 - val_loss: 52444.2422\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 772.5153 - val_loss: 62403.3828\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 802.7631 - val_loss: 59326.3398\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 684.8429 - val_loss: 54279.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 544.8626 - val_loss: 54007.3906\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 505.8517 - val_loss: 53613.2422\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 572.8542 - val_loss: 62713.1836\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 564.3962 - val_loss: 38131.0586\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 920.8844 - val_loss: 32241.7539\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 897.6971 - val_loss: 44006.0664\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 790.9721 - val_loss: 40649.3281\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2465.3428 - val_loss: 34516.2031\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1865.5317 - val_loss: 43549.1016\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6007.1621 - val_loss: 71866.5469\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10777.0811 - val_loss: 41940.1172\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6371.9355 - val_loss: 65096.8320\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8581.6680 - val_loss: 25619.1719\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10448.2510 - val_loss: 20626.7793\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6725.9873 - val_loss: 28526.2402\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4665.6602 - val_loss: 29095.9551\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1506.2109 - val_loss: 31725.0039\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1079.7872 - val_loss: 31561.3281\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1449.1102 - val_loss: 34457.3086\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1141.6675 - val_loss: 5645.5054\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10406.2676 - val_loss: 11381.8047\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5448.5190 - val_loss: 24004.3164\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3509.7615 - val_loss: 27028.0332\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2805.0618 - val_loss: 20479.6289\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1389.4921 - val_loss: 26639.3535\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1337.0858 - val_loss: 25681.9844\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1054.1250 - val_loss: 25210.1133\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1229.2601 - val_loss: 26414.1797\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 948.3260 - val_loss: 27961.9023\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 963.2538 - val_loss: 25289.9688\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1185.9075 - val_loss: 29384.9707\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 851.6400 - val_loss: 27225.2090\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 669.8165 - val_loss: 27071.6406\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 963.3791 - val_loss: 27821.1270\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 819.7922 - val_loss: 25689.0449\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 743.0099 - val_loss: 26676.7441\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1026.1334 - val_loss: 25161.1719\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1280.0474 - val_loss: 76892.5703\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4505.5757 - val_loss: 40498.3125\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2182.4146 - val_loss: 41381.5195\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2928.5618 - val_loss: 45903.2812\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2689.5662 - val_loss: 36105.8633\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2732.0796 - val_loss: 47249.6953\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2461.3406 - val_loss: 44250.1016\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2393.8906 - val_loss: 43598.8516\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2018.3029 - val_loss: 60822.0039\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2972.7451 - val_loss: 46953.1602\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1814.9795 - val_loss: 44845.4922\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1633.1556 - val_loss: 40842.0430\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1480.8409 - val_loss: 43444.3516\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1278.5066 - val_loss: 44687.3438\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1390.9987 - val_loss: 39061.7812\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1192.8151 - val_loss: 48999.6797\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1185.7816 - val_loss: 44356.6406\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 902.3419 - val_loss: 40029.9492\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 897.7856 - val_loss: 46603.4609\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1081.6556 - val_loss: 37972.7617\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 931.2545 - val_loss: 38936.1172\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 908.4486 - val_loss: 38204.5703\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1007.2957 - val_loss: 45293.5625\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1079.9360 - val_loss: 42257.4180\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1065.0767 - val_loss: 39971.9883\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1122.6965 - val_loss: 35453.0234\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 963.3743 - val_loss: 37662.4570\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 882.3041 - val_loss: 36079.7227\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 952.3121 - val_loss: 37409.7109\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 837.6329 - val_loss: 33827.7930\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1190.2422 - val_loss: 34415.2930\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1689.3984 - val_loss: 37461.6953\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1793.8710 - val_loss: 32803.4648\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1642.8313 - val_loss: 32741.5586\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 988.2935 - val_loss: 30690.7734\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 857.0336 - val_loss: 31178.3242\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 932.6074 - val_loss: 33320.0625\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 811.5407 - val_loss: 40332.7969\n",
      "Epoch 1141/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 1083.8467 - val_loss: 46221.1719\n",
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1514.9279 - val_loss: 39349.3789\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1178.9248 - val_loss: 37671.1523\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 987.3336 - val_loss: 36002.0781\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 700.2675 - val_loss: 34759.4258\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 696.3471 - val_loss: 33199.6016\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 699.1265 - val_loss: 26748.4570\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 738.9906 - val_loss: 23741.4805\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 690.3990 - val_loss: 24992.0762\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 725.3223 - val_loss: 24404.6641\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 705.0817 - val_loss: 26188.1426\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 689.3849 - val_loss: 25431.2012\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 681.5926 - val_loss: 26664.1973\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 894.8416 - val_loss: 25653.6230\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1016.6577 - val_loss: 23946.7598\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 877.9603 - val_loss: 22794.0566\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 899.9581 - val_loss: 26254.9766\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 789.6818 - val_loss: 25889.4512\n",
      "Epoch 1159/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 671.9921 - val_loss: 25605.5996\n",
      "Epoch 1160/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 649.2766 - val_loss: 26606.9336\n",
      "Epoch 1161/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 666.2147 - val_loss: 24192.7715\n",
      "Epoch 1162/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 612.6439 - val_loss: 24383.5508\n",
      "Epoch 1163/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 750.9276 - val_loss: 23949.2500\n",
      "Epoch 1164/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 601.7879 - val_loss: 21720.8555\n",
      "Epoch 1165/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 619.7587 - val_loss: 23128.8906\n",
      "Epoch 1166/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 517.1721 - val_loss: 22442.9824\n",
      "Epoch 1167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 437.2806 - val_loss: 23700.5957\n",
      "Epoch 1168/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 539.9312 - val_loss: 23341.9746\n",
      "Epoch 1169/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 438.2505 - val_loss: 21174.3984\n",
      "Epoch 1170/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 517.2106 - val_loss: 22579.3672\n",
      "Epoch 1171/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 448.8889 - val_loss: 21048.2324\n",
      "Epoch 1172/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 645.4527 - val_loss: 36024.7812\n",
      "Epoch 1173/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1014.1776 - val_loss: 28380.7266\n",
      "Epoch 1174/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 825.4047 - val_loss: 28141.9844\n",
      "Epoch 1175/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 869.2545 - val_loss: 26351.0098\n",
      "Epoch 1176/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 964.4569 - val_loss: 29489.0996\n",
      "Epoch 1177/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 909.6610 - val_loss: 25290.7344\n",
      "Epoch 1178/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 982.5375 - val_loss: 27541.8340\n",
      "Epoch 1179/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 827.6177 - val_loss: 27504.1250\n",
      "Epoch 1180/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 887.2107 - val_loss: 27951.3945\n",
      "Epoch 1181/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 867.2670 - val_loss: 26336.9824\n",
      "Epoch 1182/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 861.6667 - val_loss: 27053.5234\n",
      "Epoch 1183/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 894.0200 - val_loss: 27450.1973\n",
      "Epoch 1184/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 920.0872 - val_loss: 26094.3535\n",
      "Epoch 1185/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 888.1204 - val_loss: 26469.5469\n",
      "Epoch 1186/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 866.1659 - val_loss: 25409.9512\n",
      "Epoch 1187/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 795.7664 - val_loss: 25617.9082\n",
      "Epoch 1188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 707.9906 - val_loss: 24270.6445\n",
      "Epoch 1189/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 685.4661 - val_loss: 24340.1914\n",
      "Epoch 1190/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 642.3420 - val_loss: 23336.0391\n",
      "Epoch 1191/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 646.4979 - val_loss: 23417.3711\n",
      "Epoch 1192/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 645.6853 - val_loss: 22606.3477\n",
      "Epoch 1193/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 530.6520 - val_loss: 23170.3379\n",
      "Epoch 1194/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 519.8090 - val_loss: 22097.4980\n",
      "Epoch 1195/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 558.5786 - val_loss: 24634.5781\n",
      "Epoch 1196/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 501.6595 - val_loss: 23692.4883\n",
      "Epoch 1197/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 462.3620 - val_loss: 23073.0918\n",
      "Epoch 1198/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 544.8248 - val_loss: 24172.9082\n",
      "Epoch 1199/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 530.2874 - val_loss: 27696.7324\n",
      "Epoch 1200/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 665.4084 - val_loss: 23219.6406\n",
      "Epoch 1201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 547.0457 - val_loss: 21235.0996\n",
      "Epoch 1202/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 530.3821 - val_loss: 21830.4004\n",
      "Epoch 1203/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 528.2389 - val_loss: 22141.7109\n",
      "Epoch 1204/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 511.6332 - val_loss: 22179.4453\n",
      "Epoch 1205/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 738.7263 - val_loss: 24602.8047\n",
      "Epoch 1206/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 626.4355 - val_loss: 24223.1602\n",
      "Epoch 1207/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 546.4453 - val_loss: 26653.5371\n",
      "Epoch 1208/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 493.5370 - val_loss: 24625.3340\n",
      "Epoch 1209/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 517.0283 - val_loss: 24940.9414\n",
      "Epoch 1210/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 569.0113 - val_loss: 25516.2598\n",
      "Epoch 1211/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 606.3870 - val_loss: 25664.7910\n",
      "Epoch 1212/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 607.5792 - val_loss: 24969.4688\n",
      "Epoch 1213/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 603.2534 - val_loss: 26321.8008\n",
      "Epoch 1214/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 725.1873 - val_loss: 28651.3867\n",
      "Epoch 1215/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 721.8957 - val_loss: 30535.3281\n",
      "Epoch 1216/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 799.9228 - val_loss: 27987.8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1217/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 669.9072 - val_loss: 21776.1387\n",
      "Epoch 1218/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 497.5457 - val_loss: 27139.6953\n",
      "Epoch 1219/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 484.6211 - val_loss: 27370.3770\n",
      "Epoch 1220/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 509.6815 - val_loss: 28700.6875\n",
      "Epoch 1221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 456.0750 - val_loss: 31030.4082\n",
      "Epoch 1222/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 679.0002 - val_loss: 23807.8906\n",
      "Epoch 1223/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 547.5131 - val_loss: 31777.9121\n",
      "Epoch 1224/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 474.3041 - val_loss: 31058.6406\n",
      "Epoch 1225/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 486.9378 - val_loss: 31764.4004\n",
      "Epoch 1226/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 544.9979 - val_loss: 33168.3633\n",
      "Epoch 1227/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 494.5731 - val_loss: 44928.3594\n",
      "Epoch 1228/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 943.6491 - val_loss: 33366.1250\n",
      "Epoch 1229/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 547.4003 - val_loss: 35478.3359\n",
      "Epoch 1230/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 560.1630 - val_loss: 26215.6367\n",
      "Epoch 1231/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 529.1100 - val_loss: 25849.1641\n",
      "Epoch 1232/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 558.5977 - val_loss: 26471.5254\n",
      "Epoch 1233/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 499.4536 - val_loss: 26936.2578\n",
      "Epoch 1234/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 511.7765 - val_loss: 25492.2891\n",
      "Epoch 1235/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 695.3240 - val_loss: 34442.0156\n",
      "Epoch 1236/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 611.2053 - val_loss: 30663.9531\n",
      "Epoch 1237/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 621.1448 - val_loss: 33470.5000\n",
      "Epoch 1238/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 689.4913 - val_loss: 37905.0625\n",
      "Epoch 1239/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 677.7259 - val_loss: 33230.4102\n",
      "Epoch 1240/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 575.3527 - val_loss: 32141.7656\n",
      "Epoch 1241/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 534.3179 - val_loss: 25575.4062\n",
      "Epoch 1242/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 917.1647 - val_loss: 32465.4004\n",
      "Epoch 1243/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 744.8188 - val_loss: 30887.1133\n",
      "Epoch 1244/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 639.3897 - val_loss: 32498.3535\n",
      "Epoch 1245/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 629.2329 - val_loss: 30003.5078\n",
      "Epoch 1246/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 806.7476 - val_loss: 33390.2188\n",
      "Epoch 1247/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 797.1880 - val_loss: 32724.4082\n",
      "Epoch 1248/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 848.4735 - val_loss: 33695.8398\n",
      "Epoch 1249/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 808.0884 - val_loss: 32507.3535\n",
      "Epoch 1250/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 560.9221 - val_loss: 28209.9473\n",
      "Epoch 1251/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 543.2322 - val_loss: 33064.4336\n",
      "Epoch 1252/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 636.8225 - val_loss: 29506.3750\n",
      "Epoch 1253/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 583.8571 - val_loss: 30390.8047\n",
      "Epoch 1254/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 563.1215 - val_loss: 29588.7461\n",
      "Epoch 1255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 533.1403 - val_loss: 28752.6348\n",
      "Epoch 1256/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 523.1113 - val_loss: 27502.9922\n",
      "Epoch 1257/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 568.1983 - val_loss: 26699.0645\n",
      "Epoch 1258/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 796.0972 - val_loss: 26068.2148\n",
      "Epoch 1259/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 735.7050 - val_loss: 23888.3633\n",
      "Epoch 1260/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 725.5467 - val_loss: 25388.7715\n",
      "Epoch 1261/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 710.9291 - val_loss: 24753.1523\n",
      "Epoch 1262/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 567.8230 - val_loss: 25213.4023\n",
      "Epoch 1263/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 505.5455 - val_loss: 25110.9590\n",
      "Epoch 1264/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 600.8107 - val_loss: 24169.0098\n",
      "Epoch 1265/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 516.1956 - val_loss: 24941.4766\n",
      "Epoch 1266/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 586.2327 - val_loss: 23779.4570\n",
      "Epoch 1267/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 620.1505 - val_loss: 24407.7031\n",
      "Epoch 1268/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 622.5620 - val_loss: 23988.5566\n",
      "Epoch 1269/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 637.5522 - val_loss: 22979.7031\n",
      "Epoch 1270/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 698.5308 - val_loss: 26353.2656\n",
      "Epoch 1271/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 658.4547 - val_loss: 25503.5293\n",
      "Epoch 1272/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 672.3967 - val_loss: 22521.6348\n",
      "Epoch 1273/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 572.3711 - val_loss: 23444.1836\n",
      "Epoch 1274/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 559.4521 - val_loss: 22528.9160\n",
      "Epoch 1275/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 544.0440 - val_loss: 33958.3906\n",
      "Epoch 1276/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1037.5963 - val_loss: 27209.4531\n",
      "Epoch 1277/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 868.3592 - val_loss: 25402.5508\n",
      "Epoch 1278/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 793.4634 - val_loss: 25613.9902\n",
      "Epoch 1279/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 800.4707 - val_loss: 26500.3574\n",
      "Epoch 1280/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 807.4873 - val_loss: 29373.8008\n",
      "Epoch 1281/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 975.4424 - val_loss: 26530.2793\n",
      "Epoch 1282/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 900.3913 - val_loss: 25515.9727\n",
      "Epoch 1283/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1035.6191 - val_loss: 27283.2402\n",
      "Epoch 1284/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 944.3168 - val_loss: 29468.7812\n",
      "Epoch 1285/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 966.3996 - val_loss: 29415.3398\n",
      "Epoch 1286/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1030.9651 - val_loss: 28685.7129\n",
      "Epoch 1287/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 695.1519 - val_loss: 25504.9375\n",
      "Epoch 1288/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 693.1971 - val_loss: 27272.6699\n",
      "Epoch 1289/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 728.4291 - val_loss: 24649.2402\n",
      "Epoch 1290/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 782.3145 - val_loss: 27193.6133\n",
      "Epoch 1291/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 697.0648 - val_loss: 28976.5293\n",
      "Epoch 1292/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 688.3541 - val_loss: 28104.7852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1293/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 707.8546 - val_loss: 26983.5527\n",
      "Epoch 1294/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 665.3494 - val_loss: 27713.5801\n",
      "Epoch 1295/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 694.5486 - val_loss: 26556.1973\n",
      "Epoch 1296/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 638.8948 - val_loss: 24981.4375\n",
      "Epoch 1297/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 714.3447 - val_loss: 24435.6934\n",
      "Epoch 1298/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 646.4563 - val_loss: 23341.0273\n",
      "Epoch 1299/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 641.2899 - val_loss: 23150.3340\n",
      "Epoch 1300/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 662.5024 - val_loss: 24486.3633\n",
      "Epoch 1301/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 703.4500 - val_loss: 19198.0527\n",
      "Epoch 1302/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 534.1677 - val_loss: 19814.9473\n",
      "Epoch 1303/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 622.1086 - val_loss: 26608.4766\n",
      "Epoch 1304/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 553.0046 - val_loss: 27358.9785\n",
      "Epoch 1305/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 707.3600 - val_loss: 25870.4258\n",
      "Epoch 1306/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 588.2093 - val_loss: 27068.4355\n",
      "Epoch 1307/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 542.0153 - val_loss: 26647.7324\n",
      "Epoch 1308/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 492.8168 - val_loss: 27445.7676\n",
      "Epoch 1309/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 517.4392 - val_loss: 28336.2695\n",
      "Epoch 1310/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 538.7682 - val_loss: 27115.0469\n",
      "Epoch 1311/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 599.1691 - val_loss: 28041.2539\n",
      "Epoch 1312/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 754.1898 - val_loss: 27939.5723\n",
      "Epoch 1313/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 619.7354 - val_loss: 30468.6367\n",
      "Epoch 1314/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 675.8764 - val_loss: 28440.1289\n",
      "Epoch 1315/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 715.0930 - val_loss: 28091.7500\n",
      "Epoch 1316/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 710.4553 - val_loss: 26196.3223\n",
      "Epoch 1317/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 682.1413 - val_loss: 32507.3965\n",
      "Epoch 1318/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 621.4959 - val_loss: 31495.0742\n",
      "Epoch 1319/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 650.9395 - val_loss: 31108.9922\n",
      "Epoch 1320/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 548.6088 - val_loss: 30484.5957\n",
      "Epoch 1321/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 562.7315 - val_loss: 31065.6172\n",
      "Epoch 1322/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 608.6765 - val_loss: 30255.8379\n",
      "Epoch 1323/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 505.6561 - val_loss: 30794.8496\n",
      "Epoch 1324/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 569.2581 - val_loss: 29670.7969\n",
      "Epoch 1325/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 560.9282 - val_loss: 32882.2383\n",
      "Epoch 1326/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1031.7312 - val_loss: 31144.9297\n",
      "Epoch 1327/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1162.2302 - val_loss: 29345.1582\n",
      "Epoch 1328/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 987.1347 - val_loss: 32025.9785\n",
      "Epoch 1329/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 898.9661 - val_loss: 32487.1875\n",
      "Epoch 1330/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 856.7222 - val_loss: 29951.2656\n",
      "Epoch 1331/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 561.0318 - val_loss: 32587.9844\n",
      "Epoch 1332/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 593.5134 - val_loss: 31436.9531\n",
      "Epoch 1333/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 554.1974 - val_loss: 32516.3418\n",
      "Epoch 1334/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 538.8130 - val_loss: 32039.9746\n",
      "Epoch 1335/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 626.6227 - val_loss: 29095.1367\n",
      "Epoch 1336/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 572.2295 - val_loss: 29039.2910\n",
      "Epoch 1337/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 580.7476 - val_loss: 30059.1836\n",
      "Epoch 1338/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 636.6642 - val_loss: 33203.6836\n",
      "Epoch 1339/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 648.8587 - val_loss: 26046.7422\n",
      "Epoch 1340/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 550.2339 - val_loss: 26069.5781\n",
      "Epoch 1341/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 543.9344 - val_loss: 25115.9688\n",
      "Epoch 1342/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 568.6946 - val_loss: 31209.8926\n",
      "Epoch 1343/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 645.4830 - val_loss: 29530.1738\n",
      "Epoch 1344/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 513.9083 - val_loss: 28618.4941\n",
      "Epoch 1345/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 633.5678 - val_loss: 28893.6348\n",
      "Epoch 1346/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 573.1344 - val_loss: 31337.2246\n",
      "Epoch 1347/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 649.7856 - val_loss: 28142.8926\n",
      "Epoch 1348/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 714.7501 - val_loss: 29648.4746\n",
      "Epoch 1349/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 542.8959 - val_loss: 27673.6328\n",
      "Epoch 1350/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 514.8821 - val_loss: 29542.6719\n",
      "Epoch 1351/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 532.4473 - val_loss: 30687.0742\n",
      "Epoch 1352/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 593.5153 - val_loss: 28754.7969\n",
      "Epoch 1353/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 674.1822 - val_loss: 33184.6211\n",
      "Epoch 1354/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 608.2170 - val_loss: 32365.8242\n",
      "Epoch 1355/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 608.4437 - val_loss: 29300.6719\n",
      "Epoch 1356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 574.0043 - val_loss: 29135.3281\n",
      "Epoch 1357/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 569.6749 - val_loss: 30851.4961\n",
      "Epoch 1358/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 559.9444 - val_loss: 29636.6055\n",
      "Epoch 1359/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 597.0331 - val_loss: 31114.4121\n",
      "Epoch 1360/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 559.9699 - val_loss: 30900.0117\n",
      "Epoch 1361/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 672.4991 - val_loss: 32686.6328\n",
      "Epoch 1362/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 697.0214 - val_loss: 32678.2285\n",
      "Epoch 1363/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 668.5929 - val_loss: 28004.6230\n",
      "Epoch 1364/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 688.5160 - val_loss: 25822.6758\n",
      "Epoch 1365/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 642.4356 - val_loss: 43552.3984\n",
      "Epoch 1366/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1690.8588 - val_loss: 41235.6094\n",
      "Epoch 1367/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1303.1541 - val_loss: 38043.3711\n",
      "Epoch 1368/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1248.3679 - val_loss: 39987.8867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1369/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1159.5173 - val_loss: 35898.4727\n",
      "Epoch 1370/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1177.7231 - val_loss: 35447.8438\n",
      "Epoch 1371/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1215.6058 - val_loss: 26445.8184\n",
      "Epoch 1372/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 953.1254 - val_loss: 25858.3105\n",
      "Epoch 1373/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 839.0909 - val_loss: 23975.3105\n",
      "Epoch 1374/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 848.3754 - val_loss: 24842.9766\n",
      "Epoch 1375/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 840.6279 - val_loss: 25618.4316\n",
      "Epoch 1376/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 822.3115 - val_loss: 26793.6602\n",
      "Epoch 1377/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 804.2288 - val_loss: 30392.2969\n",
      "Epoch 1378/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 887.9656 - val_loss: 24601.5137\n",
      "Epoch 1379/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 881.0568 - val_loss: 23479.4512\n",
      "Epoch 1380/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 749.8852 - val_loss: 24267.5508\n",
      "Epoch 1381/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1086.5304 - val_loss: 27939.7051\n",
      "Epoch 1382/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1165.9136 - val_loss: 27842.0469\n",
      "Epoch 1383/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1145.6193 - val_loss: 26778.5762\n",
      "Epoch 1384/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1199.5582 - val_loss: 26798.1250\n",
      "Epoch 1385/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1011.6942 - val_loss: 25403.6094\n",
      "Epoch 1386/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 733.8348 - val_loss: 27073.7812\n",
      "Epoch 1387/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 763.1915 - val_loss: 22407.3809\n",
      "Epoch 1388/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 520.0699 - val_loss: 22576.0898\n",
      "Epoch 1389/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 601.0261 - val_loss: 26731.2051\n",
      "Epoch 1390/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 607.1050 - val_loss: 22790.9258\n",
      "Epoch 1391/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 545.0791 - val_loss: 23858.6543\n",
      "Epoch 1392/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 478.9612 - val_loss: 25077.8926\n",
      "Epoch 1393/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 442.9645 - val_loss: 29564.4785\n",
      "Epoch 1394/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 519.6898 - val_loss: 25358.9746\n",
      "Epoch 1395/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 479.9771 - val_loss: 26183.9531\n",
      "Epoch 1396/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 489.6289 - val_loss: 26546.8984\n",
      "Epoch 1397/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 542.5710 - val_loss: 32212.1328\n",
      "Epoch 1398/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 608.1065 - val_loss: 30573.6680\n",
      "Epoch 1399/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 598.6557 - val_loss: 27769.4922\n",
      "Epoch 1400/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 575.9875 - val_loss: 29301.4492\n",
      "Epoch 1401/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 637.3316 - val_loss: 30202.9941\n",
      "Epoch 1402/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 607.0067 - val_loss: 30577.2578\n",
      "Epoch 1403/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 690.8049 - val_loss: 29692.6445\n",
      "Epoch 1404/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 627.3486 - val_loss: 31316.6074\n",
      "Epoch 1405/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 638.7621 - val_loss: 31160.4531\n",
      "Epoch 1406/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 571.4585 - val_loss: 30643.9336\n",
      "Epoch 1407/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 635.6536 - val_loss: 29949.0508\n",
      "Epoch 1408/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 618.7003 - val_loss: 29796.8379\n",
      "Epoch 1409/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 667.6768 - val_loss: 31763.3633\n",
      "Epoch 1410/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 617.3636 - val_loss: 31156.6875\n",
      "Epoch 1411/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 602.9837 - val_loss: 30127.7891\n",
      "Epoch 1412/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 604.6192 - val_loss: 28201.4121\n",
      "Epoch 1413/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 606.7584 - val_loss: 30026.0273\n",
      "Epoch 1414/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 569.1321 - val_loss: 29646.4160\n",
      "Epoch 1415/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 602.2498 - val_loss: 31248.5293\n",
      "Epoch 1416/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 584.6282 - val_loss: 28896.5117\n",
      "Epoch 1417/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 579.4313 - val_loss: 30052.9453\n",
      "Epoch 1418/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 635.6226 - val_loss: 29800.6367\n",
      "Epoch 1419/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 570.1053 - val_loss: 29387.6367\n",
      "Epoch 1420/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 549.3040 - val_loss: 32939.2930\n",
      "Epoch 1421/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 576.5729 - val_loss: 31760.6426\n",
      "Epoch 1422/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 565.3575 - val_loss: 33558.5820\n",
      "Epoch 1423/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 557.7287 - val_loss: 32284.3047\n",
      "Epoch 1424/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 698.6462 - val_loss: 32601.1328\n",
      "Epoch 1425/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 691.5966 - val_loss: 33690.3398\n",
      "Epoch 1426/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 655.4360 - val_loss: 31833.8594\n",
      "Epoch 1427/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 654.1720 - val_loss: 34330.9141\n",
      "Epoch 1428/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 663.6337 - val_loss: 32311.7051\n",
      "Epoch 1429/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 656.7891 - val_loss: 34591.0391\n",
      "Epoch 1430/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 673.8661 - val_loss: 34619.9062\n",
      "Epoch 1431/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 660.4213 - val_loss: 33210.8086\n",
      "Epoch 1432/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 685.2487 - val_loss: 33491.4414\n",
      "Epoch 1433/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 636.8807 - val_loss: 33132.3125\n",
      "Epoch 1434/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 648.9827 - val_loss: 32234.0508\n",
      "Epoch 1435/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 658.9299 - val_loss: 31967.3906\n",
      "Epoch 1436/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 632.7870 - val_loss: 30136.6133\n",
      "Epoch 1437/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 623.0787 - val_loss: 31387.7246\n",
      "Epoch 1438/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 639.6253 - val_loss: 31899.0781\n",
      "Epoch 1439/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 601.7034 - val_loss: 31648.0078\n",
      "Epoch 1440/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 585.9687 - val_loss: 32154.0254\n",
      "Epoch 1441/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 570.2924 - val_loss: 31361.9551\n",
      "Epoch 1442/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 626.5442 - val_loss: 32902.1523\n",
      "Epoch 1443/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 585.0358 - val_loss: 32142.7832\n",
      "Epoch 1444/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 580.3990 - val_loss: 31687.5801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1445/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 596.4387 - val_loss: 31435.3633\n",
      "Epoch 1446/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 562.9383 - val_loss: 33111.1250\n",
      "Epoch 1447/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 604.1426 - val_loss: 32696.1289\n",
      "Epoch 1448/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 602.9065 - val_loss: 31091.4746\n",
      "Epoch 1449/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 674.7493 - val_loss: 32145.1074\n",
      "Epoch 1450/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 626.3325 - val_loss: 31397.6992\n",
      "Epoch 1451/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 614.9904 - val_loss: 30557.9824\n",
      "Epoch 1452/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 603.6635 - val_loss: 32463.8164\n",
      "Epoch 1453/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 592.7338 - val_loss: 32065.6426\n",
      "Epoch 1454/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 772.2272 - val_loss: 34540.8555\n",
      "Epoch 1455/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 830.6484 - val_loss: 33543.3711\n",
      "Epoch 1456/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 683.3074 - val_loss: 30192.8809\n",
      "Epoch 1457/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 775.3679 - val_loss: 28447.4863\n",
      "Epoch 1458/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 614.0555 - val_loss: 33957.6562\n",
      "Epoch 1459/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 615.0475 - val_loss: 32208.7793\n",
      "Epoch 1460/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 557.1521 - val_loss: 32018.0840\n",
      "Epoch 1461/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 625.6428 - val_loss: 30423.9590\n",
      "Epoch 1462/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 558.1376 - val_loss: 30222.7695\n",
      "Epoch 1463/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 555.3061 - val_loss: 29407.2461\n",
      "Epoch 1464/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 542.2571 - val_loss: 29617.3613\n",
      "Epoch 1465/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 567.2119 - val_loss: 29651.4648\n",
      "Epoch 1466/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 652.6547 - val_loss: 26930.4375\n",
      "Epoch 1467/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 601.7144 - val_loss: 27562.7930\n",
      "Epoch 1468/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 654.0926 - val_loss: 28259.0156\n",
      "Epoch 1469/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 753.7892 - val_loss: 34414.1680\n",
      "Epoch 1470/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 743.0347 - val_loss: 33290.0859\n",
      "Epoch 1471/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 790.9350 - val_loss: 31127.2422\n",
      "Epoch 1472/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 612.8937 - val_loss: 28742.5059\n",
      "Epoch 1473/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 593.5274 - val_loss: 29791.4531\n",
      "Epoch 1474/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 513.1526 - val_loss: 25923.0117\n",
      "Epoch 1475/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 608.3114 - val_loss: 26837.6230\n",
      "Epoch 1476/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 606.9552 - val_loss: 27155.2363\n",
      "Epoch 1477/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 571.9045 - val_loss: 26224.1172\n",
      "Epoch 1478/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 584.9907 - val_loss: 26740.9668\n",
      "Epoch 1479/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 522.5010 - val_loss: 27951.4395\n",
      "Epoch 1480/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 549.9743 - val_loss: 27448.8613\n",
      "Epoch 1481/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 530.1520 - val_loss: 26303.8613\n",
      "Epoch 1482/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 555.8171 - val_loss: 27363.2656\n",
      "Epoch 1483/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 523.4310 - val_loss: 28439.5391\n",
      "Epoch 1484/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 564.6294 - val_loss: 27276.7480\n",
      "Epoch 1485/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 486.3327 - val_loss: 25524.4141\n",
      "Epoch 1486/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 559.1040 - val_loss: 25587.5137\n",
      "Epoch 1487/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 585.1221 - val_loss: 26607.4766\n",
      "Epoch 1488/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 485.1389 - val_loss: 25840.6953\n",
      "Epoch 1489/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 505.1283 - val_loss: 28786.4941\n",
      "Epoch 1490/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 572.1407 - val_loss: 26892.0410\n",
      "Epoch 1491/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 728.6219 - val_loss: 26357.3555\n",
      "Epoch 1492/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 879.2728 - val_loss: 27291.6914\n",
      "Epoch 1493/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 839.3284 - val_loss: 30098.2461\n",
      "Epoch 1494/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 898.5898 - val_loss: 29598.5859\n",
      "Epoch 1495/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 866.1873 - val_loss: 29137.9473\n",
      "Epoch 1496/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 829.4648 - val_loss: 26722.5078\n",
      "Epoch 1497/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 851.6160 - val_loss: 28859.1465\n",
      "Epoch 1498/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 677.6334 - val_loss: 27857.3145\n",
      "Epoch 1499/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 601.2323 - val_loss: 26750.6992\n",
      "Epoch 1500/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 594.7375 - val_loss: 24501.2812\n",
      "Epoch 1501/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1075.3699 - val_loss: 28994.2520\n",
      "Epoch 1502/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 784.9982 - val_loss: 31852.5000\n",
      "Epoch 1503/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 807.4709 - val_loss: 29372.0625\n",
      "Epoch 1504/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 789.8587 - val_loss: 28271.0078\n",
      "Epoch 1505/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 796.8999 - val_loss: 28283.4434\n",
      "Epoch 1506/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 810.8036 - val_loss: 29282.1309\n",
      "Epoch 1507/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 893.1241 - val_loss: 26768.1074\n",
      "Epoch 1508/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 858.9030 - val_loss: 29537.8965\n",
      "Epoch 1509/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 923.9988 - val_loss: 25757.8672\n",
      "Epoch 1510/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 903.4744 - val_loss: 27723.4062\n",
      "Epoch 1511/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 795.6149 - val_loss: 27292.7148\n",
      "Epoch 1512/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 884.6566 - val_loss: 28863.1035\n",
      "Epoch 1513/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 817.1771 - val_loss: 27207.2637\n",
      "Epoch 1514/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 716.2780 - val_loss: 30742.9492\n",
      "Epoch 1515/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 812.4349 - val_loss: 28225.9629\n",
      "Epoch 1516/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 851.9844 - val_loss: 28201.8477\n",
      "Epoch 1517/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 789.2730 - val_loss: 26989.2285\n",
      "Epoch 1518/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 839.1425 - val_loss: 29774.4805\n",
      "Epoch 1519/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 867.3547 - val_loss: 28291.3164\n",
      "Epoch 1520/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 809.7700 - val_loss: 26485.6973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1521/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 859.9147 - val_loss: 27437.6426\n",
      "Epoch 1522/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 799.2729 - val_loss: 27728.4707\n",
      "Epoch 1523/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 832.4785 - val_loss: 28213.1309\n",
      "Epoch 1524/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 834.8546 - val_loss: 28008.1133\n",
      "Epoch 1525/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 760.8140 - val_loss: 27386.8555\n",
      "Epoch 1526/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 726.2781 - val_loss: 26400.0547\n",
      "Epoch 1527/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 811.9570 - val_loss: 28332.8887\n",
      "Epoch 1528/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 798.7429 - val_loss: 29172.6641\n",
      "Epoch 1529/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 802.0542 - val_loss: 29372.6055\n",
      "Epoch 1530/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1290.0267 - val_loss: 34276.7891\n",
      "Epoch 1531/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1186.8484 - val_loss: 31380.5625\n",
      "Epoch 1532/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1164.1920 - val_loss: 30887.5586\n",
      "Epoch 1533/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1086.8105 - val_loss: 32239.1914\n",
      "Epoch 1534/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1020.0738 - val_loss: 30602.3164\n",
      "Epoch 1535/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 931.4412 - val_loss: 31930.4844\n",
      "Epoch 1536/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 941.4161 - val_loss: 28182.5781\n",
      "Epoch 1537/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 947.8329 - val_loss: 30798.9648\n",
      "Epoch 1538/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 994.7866 - val_loss: 28400.9375\n",
      "Epoch 1539/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 894.0294 - val_loss: 31088.2871\n",
      "Epoch 1540/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 832.9200 - val_loss: 33414.4570\n",
      "Epoch 1541/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1091.3818 - val_loss: 29164.3438\n",
      "Epoch 1542/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 913.4863 - val_loss: 31914.3574\n",
      "Epoch 1543/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 929.6719 - val_loss: 27871.7930\n",
      "Epoch 1544/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 864.7629 - val_loss: 29393.3555\n",
      "Epoch 1545/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 771.4086 - val_loss: 29512.3828\n",
      "Epoch 1546/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 697.8394 - val_loss: 31410.1875\n",
      "Epoch 1547/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 777.9573 - val_loss: 28498.3867\n",
      "Epoch 1548/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 548.2899 - val_loss: 27618.2344\n",
      "Epoch 1549/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 604.9972 - val_loss: 31149.1992\n",
      "Epoch 1550/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 590.5165 - val_loss: 29901.1113\n",
      "Epoch 1551/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 617.3613 - val_loss: 28910.4082\n",
      "Epoch 1552/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 510.5662 - val_loss: 29998.0059\n",
      "Epoch 1553/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 512.9770 - val_loss: 33750.4844\n",
      "Epoch 1554/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 883.7760 - val_loss: 30904.6797\n",
      "Epoch 1555/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 876.7651 - val_loss: 32532.0410\n",
      "Epoch 1556/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 775.8619 - val_loss: 34071.9062\n",
      "Epoch 1557/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 747.0765 - val_loss: 31613.9492\n",
      "Epoch 1558/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 671.8006 - val_loss: 30394.4883\n",
      "Epoch 1559/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 577.8297 - val_loss: 30501.4355\n",
      "Epoch 1560/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 540.2461 - val_loss: 30057.1738\n",
      "Epoch 1561/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 558.0601 - val_loss: 31365.7715\n",
      "Epoch 1562/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 573.2646 - val_loss: 27532.7422\n",
      "Epoch 1563/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 570.2366 - val_loss: 26853.1797\n",
      "Epoch 1564/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 583.6479 - val_loss: 29762.7363\n",
      "Epoch 1565/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 604.6200 - val_loss: 27806.5312\n",
      "Epoch 1566/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 689.9708 - val_loss: 26332.3184\n",
      "Epoch 1567/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 624.6103 - val_loss: 27919.1348\n",
      "Epoch 1568/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 598.5349 - val_loss: 27796.0566\n",
      "Epoch 1569/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 636.1741 - val_loss: 30726.9629\n",
      "Epoch 1570/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 654.6631 - val_loss: 30705.6094\n",
      "Epoch 1571/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 715.2937 - val_loss: 28076.7070\n",
      "Epoch 1572/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 591.3184 - val_loss: 27838.4570\n",
      "Epoch 1573/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 679.0128 - val_loss: 28422.5625\n",
      "Epoch 1574/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 566.7112 - val_loss: 28209.8359\n",
      "Epoch 1575/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 597.9159 - val_loss: 28817.1094\n",
      "Epoch 1576/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 621.3694 - val_loss: 27484.7832\n",
      "Epoch 1577/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 590.2898 - val_loss: 28261.5625\n",
      "Epoch 1578/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 574.3256 - val_loss: 28009.9297\n",
      "Epoch 1579/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 592.8285 - val_loss: 28458.5703\n",
      "Epoch 1580/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 543.9130 - val_loss: 27165.2734\n",
      "Epoch 1581/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 580.0889 - val_loss: 26287.5469\n",
      "Epoch 1582/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 636.8875 - val_loss: 28325.3730\n",
      "Epoch 1583/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 600.4504 - val_loss: 24582.7363\n",
      "Epoch 1584/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 593.2816 - val_loss: 27770.0625\n",
      "Epoch 1585/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 932.8688Restoring model weights from the end of the best epoch: 1085.\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 617.3458 - val_loss: 27469.7422\n",
      "Epoch 1585: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "      <td>137.138702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>250.101</td>\n",
       "      <td>277.528</td>\n",
       "      <td>270.092</td>\n",
       "      <td>278.146</td>\n",
       "      <td>257.458</td>\n",
       "      <td>231.748</td>\n",
       "      <td>268.336</td>\n",
       "      <td>223.453</td>\n",
       "      <td>241.464</td>\n",
       "      <td>238.901</td>\n",
       "      <td>191.989</td>\n",
       "      <td>272.452</td>\n",
       "      <td>261.009</td>\n",
       "      <td>292.688</td>\n",
       "      <td>258.881</td>\n",
       "      <td>276.879</td>\n",
       "      <td>255.774</td>\n",
       "      <td>208.326</td>\n",
       "      <td>291.428</td>\n",
       "      <td>249.43</td>\n",
       "      <td>241.612</td>\n",
       "      <td>252.303</td>\n",
       "      <td>281.912</td>\n",
       "      <td>200.213</td>\n",
       "      <td>270.511</td>\n",
       "      <td>281.466</td>\n",
       "      <td>285.535</td>\n",
       "      <td>328.259</td>\n",
       "      <td>298.078</td>\n",
       "      <td>264.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>112.962296</td>\n",
       "      <td>140.389313</td>\n",
       "      <td>132.953308</td>\n",
       "      <td>141.007294</td>\n",
       "      <td>120.319305</td>\n",
       "      <td>94.609299</td>\n",
       "      <td>131.197296</td>\n",
       "      <td>86.314301</td>\n",
       "      <td>104.325302</td>\n",
       "      <td>101.762299</td>\n",
       "      <td>54.850296</td>\n",
       "      <td>135.313293</td>\n",
       "      <td>123.8703</td>\n",
       "      <td>155.549286</td>\n",
       "      <td>121.74231</td>\n",
       "      <td>139.740295</td>\n",
       "      <td>118.6353</td>\n",
       "      <td>71.187302</td>\n",
       "      <td>154.289307</td>\n",
       "      <td>112.29129</td>\n",
       "      <td>104.473297</td>\n",
       "      <td>115.164291</td>\n",
       "      <td>144.773285</td>\n",
       "      <td>63.074295</td>\n",
       "      <td>133.372284</td>\n",
       "      <td>144.327301</td>\n",
       "      <td>148.396301</td>\n",
       "      <td>191.1203</td>\n",
       "      <td>160.939301</td>\n",
       "      <td>127.69931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1           2           3           4   \\\n",
       "Month          Month-1     Month-2     Month-3     Month-4     Month-5   \n",
       "Prediction  137.138702  137.138702  137.138702  137.138702  137.138702   \n",
       "Target         250.101     277.528     270.092     278.146     257.458   \n",
       "Error       112.962296  140.389313  132.953308  141.007294  120.319305   \n",
       "\n",
       "                    5           6           7           8           9   \\\n",
       "Month          Month-6     Month-7     Month-8     Month-9    Month-10   \n",
       "Prediction  137.138702  137.138702  137.138702  137.138702  137.138702   \n",
       "Target         231.748     268.336     223.453     241.464     238.901   \n",
       "Error        94.609299  131.197296   86.314301  104.325302  101.762299   \n",
       "\n",
       "                    10          11          12          13          14  \\\n",
       "Month         Month-11    Month-12    Month-13    Month-14    Month-15   \n",
       "Prediction  137.138702  137.138702  137.138702  137.138702  137.138702   \n",
       "Target         191.989     272.452     261.009     292.688     258.881   \n",
       "Error        54.850296  135.313293    123.8703  155.549286   121.74231   \n",
       "\n",
       "                    15          16          17          18          19  \\\n",
       "Month         Month-16    Month-17    Month-18    Month-19    Month-20   \n",
       "Prediction  137.138702  137.138702  137.138702  137.138702  137.138702   \n",
       "Target         276.879     255.774     208.326     291.428      249.43   \n",
       "Error       139.740295    118.6353   71.187302  154.289307   112.29129   \n",
       "\n",
       "                    20          21          22          23          24  \\\n",
       "Month         Month-21    Month-22    Month-23    Month-24    Month-25   \n",
       "Prediction  137.138702  137.138702  137.138702  137.138702  137.138702   \n",
       "Target         241.612     252.303     281.912     200.213     270.511   \n",
       "Error       104.473297  115.164291  144.773285   63.074295  133.372284   \n",
       "\n",
       "                    25          26          27          28          29  \n",
       "Month         Month-26    Month-27    Month-28    Month-29    Month-30  \n",
       "Prediction  137.138702  137.138702  137.138702  137.138702  137.138702  \n",
       "Target         281.466     285.535     328.259     298.078     264.838  \n",
       "Error       144.327301  148.396301    191.1203  160.939301   127.69931  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122.8883"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.46537665"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[1645.6642]] - Target[3001.6679999999997]| =  Error: [[1356.0038]]; MAPE:[[0.4517501]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[1645.6642]] - Target[3070.4549999999995]| =  Error: [[1424.7909]]; MAPE:[[0.46403247]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Ano-5: |Prediction[[822.83215]] - Target[1728.6870000000001]| =  Error: [[905.85486]]; MAPE:[[0.5240132]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[1356.0038]], dtype=float32),\n",
       " array([[1424.7909]], dtype=float32),\n",
       " array([[905.85486]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1228.8832"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.47993192"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
