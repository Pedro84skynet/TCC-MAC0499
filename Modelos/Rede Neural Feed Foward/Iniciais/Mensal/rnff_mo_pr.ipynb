{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Paraná - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Paraná - Desemprego</th>\n",
       "      <th>Paraná - value</th>\n",
       "      <th>Paraná - Produção de Cimento (t)</th>\n",
       "      <th>Paraná - PIB - Estadual</th>\n",
       "      <th>Paraná - PIB - Construção Civil</th>\n",
       "      <th>Paraná - PIB - Per Capita</th>\n",
       "      <th>Paraná - PIB - Preços de Mercado</th>\n",
       "      <th>Paraná - IDH</th>\n",
       "      <th>Paraná - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>8.284196</td>\n",
       "      <td>0.300568</td>\n",
       "      <td>332.705560</td>\n",
       "      <td>2.027147e+08</td>\n",
       "      <td>1.060612e+07</td>\n",
       "      <td>17.589536</td>\n",
       "      <td>1.851788e+08</td>\n",
       "      <td>0.776871</td>\n",
       "      <td>189.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>8.277973</td>\n",
       "      <td>0.301710</td>\n",
       "      <td>332.945945</td>\n",
       "      <td>2.029477e+08</td>\n",
       "      <td>1.061597e+07</td>\n",
       "      <td>17.592548</td>\n",
       "      <td>1.852326e+08</td>\n",
       "      <td>0.776975</td>\n",
       "      <td>174.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>8.271750</td>\n",
       "      <td>0.302645</td>\n",
       "      <td>335.222130</td>\n",
       "      <td>2.031806e+08</td>\n",
       "      <td>1.062582e+07</td>\n",
       "      <td>17.595559</td>\n",
       "      <td>1.852864e+08</td>\n",
       "      <td>0.777079</td>\n",
       "      <td>180.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>8.265527</td>\n",
       "      <td>0.303413</td>\n",
       "      <td>334.785737</td>\n",
       "      <td>2.034136e+08</td>\n",
       "      <td>1.063567e+07</td>\n",
       "      <td>17.598570</td>\n",
       "      <td>1.853401e+08</td>\n",
       "      <td>0.777183</td>\n",
       "      <td>180.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>8.259304</td>\n",
       "      <td>0.304034</td>\n",
       "      <td>335.050185</td>\n",
       "      <td>2.036466e+08</td>\n",
       "      <td>1.064551e+07</td>\n",
       "      <td>17.601581</td>\n",
       "      <td>1.853939e+08</td>\n",
       "      <td>0.777287</td>\n",
       "      <td>185.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.549782</td>\n",
       "      <td>616.073841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.546864</td>\n",
       "      <td>614.423079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.544541</td>\n",
       "      <td>613.772150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540629</td>\n",
       "      <td>614.761140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537674</td>\n",
       "      <td>614.453145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383.477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0       2003-1                                          0.724032   \n",
       "1       2003-2                                          0.690297   \n",
       "2       2003-3                                          0.669681   \n",
       "3       2003-4                                          0.660494   \n",
       "4       2003-5                                          0.648337   \n",
       "..         ...                                               ...   \n",
       "235     2022-8                                               NaN   \n",
       "236     2022-9                                               NaN   \n",
       "237    2022-10                                               NaN   \n",
       "238    2022-11                                               NaN   \n",
       "239    2022-12                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Paraná - Desemprego  \\\n",
       "0                              7.330309e+06   0.969649             8.284196   \n",
       "1                              7.335910e+06   0.950783             8.277973   \n",
       "2                              7.341511e+06   0.938332             8.271750   \n",
       "3                              7.347112e+06   0.926401             8.265527   \n",
       "4                              7.352713e+06   0.951683             8.259304   \n",
       "..                                      ...        ...                  ...   \n",
       "235                                     NaN        NaN                  NaN   \n",
       "236                                     NaN        NaN                  NaN   \n",
       "237                                     NaN        NaN                  NaN   \n",
       "238                                     NaN        NaN                  NaN   \n",
       "239                                     NaN        NaN                  NaN   \n",
       "\n",
       "     Paraná - value  Paraná - Produção de Cimento (t)  \\\n",
       "0          0.300568                        332.705560   \n",
       "1          0.301710                        332.945945   \n",
       "2          0.302645                        335.222130   \n",
       "3          0.303413                        334.785737   \n",
       "4          0.304034                        335.050185   \n",
       "..              ...                               ...   \n",
       "235        0.549782                        616.073841   \n",
       "236        0.546864                        614.423079   \n",
       "237        0.544541                        613.772150   \n",
       "238        0.540629                        614.761140   \n",
       "239        0.537674                        614.453145   \n",
       "\n",
       "     Paraná - PIB - Estadual  Paraná - PIB - Construção Civil  \\\n",
       "0               2.027147e+08                     1.060612e+07   \n",
       "1               2.029477e+08                     1.061597e+07   \n",
       "2               2.031806e+08                     1.062582e+07   \n",
       "3               2.034136e+08                     1.063567e+07   \n",
       "4               2.036466e+08                     1.064551e+07   \n",
       "..                       ...                              ...   \n",
       "235                      NaN                              NaN   \n",
       "236                      NaN                              NaN   \n",
       "237                      NaN                              NaN   \n",
       "238                      NaN                              NaN   \n",
       "239                      NaN                              NaN   \n",
       "\n",
       "     Paraná - PIB - Per Capita  Paraná - PIB - Preços de Mercado  \\\n",
       "0                    17.589536                      1.851788e+08   \n",
       "1                    17.592548                      1.852326e+08   \n",
       "2                    17.595559                      1.852864e+08   \n",
       "3                    17.598570                      1.853401e+08   \n",
       "4                    17.601581                      1.853939e+08   \n",
       "..                         ...                               ...   \n",
       "235                        NaN                               NaN   \n",
       "236                        NaN                               NaN   \n",
       "237                        NaN                               NaN   \n",
       "238                        NaN                               NaN   \n",
       "239                        NaN                               NaN   \n",
       "\n",
       "     Paraná - IDH  Paraná - Consumo de Cimento (t)  \n",
       "0        0.776871                          189.804  \n",
       "1        0.776975                          174.713  \n",
       "2        0.777079                          180.801  \n",
       "3        0.777183                          180.172  \n",
       "4        0.777287                          185.597  \n",
       "..            ...                              ...  \n",
       "235           NaN                          412.177  \n",
       "236           NaN                          337.056  \n",
       "237           NaN                          340.018  \n",
       "238           NaN                          383.477  \n",
       "239           NaN                          383.477  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_PR.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Paraná - Desemprego</th>\n",
       "      <th>Paraná - value</th>\n",
       "      <th>Paraná - Produção de Cimento (t)</th>\n",
       "      <th>Paraná - PIB - Estadual</th>\n",
       "      <th>Paraná - PIB - Construção Civil</th>\n",
       "      <th>Paraná - PIB - Per Capita</th>\n",
       "      <th>Paraná - PIB - Preços de Mercado</th>\n",
       "      <th>Paraná - IDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>1.200588</td>\n",
       "      <td>-0.990872</td>\n",
       "      <td>-1.688922</td>\n",
       "      <td>-1.661059</td>\n",
       "      <td>-2.360392</td>\n",
       "      <td>-1.926984</td>\n",
       "      <td>-1.800632</td>\n",
       "      <td>-2.165316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>1.186349</td>\n",
       "      <td>-0.972615</td>\n",
       "      <td>-1.684978</td>\n",
       "      <td>-1.644277</td>\n",
       "      <td>-2.312924</td>\n",
       "      <td>-1.907242</td>\n",
       "      <td>-1.780025</td>\n",
       "      <td>-2.131422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>1.172110</td>\n",
       "      <td>-0.957666</td>\n",
       "      <td>-1.647627</td>\n",
       "      <td>-1.627495</td>\n",
       "      <td>-2.265457</td>\n",
       "      <td>-1.887500</td>\n",
       "      <td>-1.759417</td>\n",
       "      <td>-2.097529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>1.157871</td>\n",
       "      <td>-0.945388</td>\n",
       "      <td>-1.654788</td>\n",
       "      <td>-1.610713</td>\n",
       "      <td>-2.217990</td>\n",
       "      <td>-1.867758</td>\n",
       "      <td>-1.738809</td>\n",
       "      <td>-2.063636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>1.143632</td>\n",
       "      <td>-0.935451</td>\n",
       "      <td>-1.650449</td>\n",
       "      <td>-1.593931</td>\n",
       "      <td>-2.170523</td>\n",
       "      <td>-1.848016</td>\n",
       "      <td>-1.718202</td>\n",
       "      <td>-2.029743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-0.826445</td>\n",
       "      <td>0.770388</td>\n",
       "      <td>1.208142</td>\n",
       "      <td>1.129314</td>\n",
       "      <td>-0.514291</td>\n",
       "      <td>0.743016</td>\n",
       "      <td>0.899324</td>\n",
       "      <td>0.733248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>-0.840099</td>\n",
       "      <td>0.821622</td>\n",
       "      <td>1.241242</td>\n",
       "      <td>1.120207</td>\n",
       "      <td>-0.507255</td>\n",
       "      <td>0.729140</td>\n",
       "      <td>0.888262</td>\n",
       "      <td>0.688083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>-0.853753</td>\n",
       "      <td>0.859766</td>\n",
       "      <td>1.313851</td>\n",
       "      <td>1.111101</td>\n",
       "      <td>-0.500218</td>\n",
       "      <td>0.715264</td>\n",
       "      <td>0.877199</td>\n",
       "      <td>0.642919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-0.867406</td>\n",
       "      <td>0.897253</td>\n",
       "      <td>1.363920</td>\n",
       "      <td>1.101994</td>\n",
       "      <td>-0.493182</td>\n",
       "      <td>0.701389</td>\n",
       "      <td>0.866137</td>\n",
       "      <td>0.597754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-0.881060</td>\n",
       "      <td>0.935674</td>\n",
       "      <td>1.387915</td>\n",
       "      <td>1.092888</td>\n",
       "      <td>-0.486145</td>\n",
       "      <td>0.687513</td>\n",
       "      <td>0.855075</td>\n",
       "      <td>0.552589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Paraná - Desemprego  \\\n",
       "0                                 -2.389042   3.122582             1.200588   \n",
       "1                                 -2.352139   2.970356             1.186349   \n",
       "2                                 -2.315236   2.869895             1.172110   \n",
       "3                                 -2.278333   2.773628             1.157871   \n",
       "4                                 -2.241431   2.977624             1.143632   \n",
       "..                                      ...        ...                  ...   \n",
       "187                                0.389193  -1.749976            -0.826445   \n",
       "188                                0.370392  -1.593005            -0.840099   \n",
       "189                                0.351592  -1.351489            -0.853753   \n",
       "190                                0.332791  -1.198492            -0.867406   \n",
       "191                                0.313991  -1.100894            -0.881060   \n",
       "\n",
       "     Paraná - value  Paraná - Produção de Cimento (t)  \\\n",
       "0         -0.990872                         -1.688922   \n",
       "1         -0.972615                         -1.684978   \n",
       "2         -0.957666                         -1.647627   \n",
       "3         -0.945388                         -1.654788   \n",
       "4         -0.935451                         -1.650449   \n",
       "..              ...                               ...   \n",
       "187        0.770388                          1.208142   \n",
       "188        0.821622                          1.241242   \n",
       "189        0.859766                          1.313851   \n",
       "190        0.897253                          1.363920   \n",
       "191        0.935674                          1.387915   \n",
       "\n",
       "     Paraná - PIB - Estadual  Paraná - PIB - Construção Civil  \\\n",
       "0                  -1.661059                        -2.360392   \n",
       "1                  -1.644277                        -2.312924   \n",
       "2                  -1.627495                        -2.265457   \n",
       "3                  -1.610713                        -2.217990   \n",
       "4                  -1.593931                        -2.170523   \n",
       "..                       ...                              ...   \n",
       "187                 1.129314                        -0.514291   \n",
       "188                 1.120207                        -0.507255   \n",
       "189                 1.111101                        -0.500218   \n",
       "190                 1.101994                        -0.493182   \n",
       "191                 1.092888                        -0.486145   \n",
       "\n",
       "     Paraná - PIB - Per Capita  Paraná - PIB - Preços de Mercado  Paraná - IDH  \n",
       "0                    -1.926984                         -1.800632     -2.165316  \n",
       "1                    -1.907242                         -1.780025     -2.131422  \n",
       "2                    -1.887500                         -1.759417     -2.097529  \n",
       "3                    -1.867758                         -1.738809     -2.063636  \n",
       "4                    -1.848016                         -1.718202     -2.029743  \n",
       "..                         ...                               ...           ...  \n",
       "187                   0.743016                          0.899324      0.733248  \n",
       "188                   0.729140                          0.888262      0.688083  \n",
       "189                   0.715264                          0.877199      0.642919  \n",
       "190                   0.701389                          0.866137      0.597754  \n",
       "191                   0.687513                          0.855075      0.552589  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      185.712\n",
       "1      170.875\n",
       "2      204.477\n",
       "3      173.662\n",
       "4      162.633\n",
       "        ...   \n",
       "235        NaN\n",
       "236        NaN\n",
       "237        NaN\n",
       "238        NaN\n",
       "239        NaN\n",
       "Name: Paraná - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Paraná - Desemprego</th>\n",
       "      <th>Paraná - value</th>\n",
       "      <th>Paraná - Produção de Cimento (t)</th>\n",
       "      <th>Paraná - PIB - Estadual</th>\n",
       "      <th>Paraná - PIB - Construção Civil</th>\n",
       "      <th>Paraná - PIB - Per Capita</th>\n",
       "      <th>Paraná - PIB - Preços de Mercado</th>\n",
       "      <th>Paraná - IDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>1.200588</td>\n",
       "      <td>-0.990872</td>\n",
       "      <td>-1.688922</td>\n",
       "      <td>-1.661059</td>\n",
       "      <td>-2.360392</td>\n",
       "      <td>-1.926984</td>\n",
       "      <td>-1.800632</td>\n",
       "      <td>-2.165316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>1.186349</td>\n",
       "      <td>-0.972615</td>\n",
       "      <td>-1.684978</td>\n",
       "      <td>-1.644277</td>\n",
       "      <td>-2.312924</td>\n",
       "      <td>-1.907242</td>\n",
       "      <td>-1.780025</td>\n",
       "      <td>-2.131422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>1.172110</td>\n",
       "      <td>-0.957666</td>\n",
       "      <td>-1.647627</td>\n",
       "      <td>-1.627495</td>\n",
       "      <td>-2.265457</td>\n",
       "      <td>-1.887500</td>\n",
       "      <td>-1.759417</td>\n",
       "      <td>-2.097529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>1.157871</td>\n",
       "      <td>-0.945388</td>\n",
       "      <td>-1.654788</td>\n",
       "      <td>-1.610713</td>\n",
       "      <td>-2.217990</td>\n",
       "      <td>-1.867758</td>\n",
       "      <td>-1.738809</td>\n",
       "      <td>-2.063636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>1.143632</td>\n",
       "      <td>-0.935451</td>\n",
       "      <td>-1.650449</td>\n",
       "      <td>-1.593931</td>\n",
       "      <td>-2.170523</td>\n",
       "      <td>-1.848016</td>\n",
       "      <td>-1.718202</td>\n",
       "      <td>-2.029743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>0.130907</td>\n",
       "      <td>0.732054</td>\n",
       "      <td>0.692024</td>\n",
       "      <td>1.202413</td>\n",
       "      <td>-0.413954</td>\n",
       "      <td>0.937022</td>\n",
       "      <td>1.076355</td>\n",
       "      <td>1.563435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>0.076074</td>\n",
       "      <td>0.695547</td>\n",
       "      <td>0.722303</td>\n",
       "      <td>1.204670</td>\n",
       "      <td>-0.429516</td>\n",
       "      <td>0.934746</td>\n",
       "      <td>1.074731</td>\n",
       "      <td>1.542097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>0.021241</td>\n",
       "      <td>0.667742</td>\n",
       "      <td>0.729289</td>\n",
       "      <td>1.206927</td>\n",
       "      <td>-0.445078</td>\n",
       "      <td>0.932469</td>\n",
       "      <td>1.073107</td>\n",
       "      <td>1.520760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>-0.033592</td>\n",
       "      <td>0.634897</td>\n",
       "      <td>0.709776</td>\n",
       "      <td>1.209183</td>\n",
       "      <td>-0.460640</td>\n",
       "      <td>0.930193</td>\n",
       "      <td>1.071484</td>\n",
       "      <td>1.499423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>-0.088425</td>\n",
       "      <td>0.601768</td>\n",
       "      <td>0.751631</td>\n",
       "      <td>1.211440</td>\n",
       "      <td>-0.476202</td>\n",
       "      <td>0.927916</td>\n",
       "      <td>1.069860</td>\n",
       "      <td>1.478085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Paraná - Desemprego  \\\n",
       "0                                 -2.389042   3.122582             1.200588   \n",
       "1                                 -2.352139   2.970356             1.186349   \n",
       "2                                 -2.315236   2.869895             1.172110   \n",
       "3                                 -2.278333   2.773628             1.157871   \n",
       "4                                 -2.241431   2.977624             1.143632   \n",
       "..                                      ...        ...                  ...   \n",
       "157                                0.819304  -0.883659             0.130907   \n",
       "158                                0.808136  -0.950771             0.076074   \n",
       "159                                0.796969  -1.028465             0.021241   \n",
       "160                                0.785801  -1.103668            -0.033592   \n",
       "161                                0.774634  -0.978419            -0.088425   \n",
       "\n",
       "     Paraná - value  Paraná - Produção de Cimento (t)  \\\n",
       "0         -0.990872                         -1.688922   \n",
       "1         -0.972615                         -1.684978   \n",
       "2         -0.957666                         -1.647627   \n",
       "3         -0.945388                         -1.654788   \n",
       "4         -0.935451                         -1.650449   \n",
       "..              ...                               ...   \n",
       "157        0.732054                          0.692024   \n",
       "158        0.695547                          0.722303   \n",
       "159        0.667742                          0.729289   \n",
       "160        0.634897                          0.709776   \n",
       "161        0.601768                          0.751631   \n",
       "\n",
       "     Paraná - PIB - Estadual  Paraná - PIB - Construção Civil  \\\n",
       "0                  -1.661059                        -2.360392   \n",
       "1                  -1.644277                        -2.312924   \n",
       "2                  -1.627495                        -2.265457   \n",
       "3                  -1.610713                        -2.217990   \n",
       "4                  -1.593931                        -2.170523   \n",
       "..                       ...                              ...   \n",
       "157                 1.202413                        -0.413954   \n",
       "158                 1.204670                        -0.429516   \n",
       "159                 1.206927                        -0.445078   \n",
       "160                 1.209183                        -0.460640   \n",
       "161                 1.211440                        -0.476202   \n",
       "\n",
       "     Paraná - PIB - Per Capita  Paraná - PIB - Preços de Mercado  Paraná - IDH  \n",
       "0                    -1.926984                         -1.800632     -2.165316  \n",
       "1                    -1.907242                         -1.780025     -2.131422  \n",
       "2                    -1.887500                         -1.759417     -2.097529  \n",
       "3                    -1.867758                         -1.738809     -2.063636  \n",
       "4                    -1.848016                         -1.718202     -2.029743  \n",
       "..                         ...                               ...           ...  \n",
       "157                   0.937022                          1.076355      1.563435  \n",
       "158                   0.934746                          1.074731      1.542097  \n",
       "159                   0.932469                          1.073107      1.520760  \n",
       "160                   0.930193                          1.071484      1.499423  \n",
       "161                   0.927916                          1.069860      1.478085  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      185.712\n",
       "1      170.875\n",
       "2      204.477\n",
       "3      173.662\n",
       "4      162.633\n",
       "        ...   \n",
       "157    280.736\n",
       "158    352.332\n",
       "159    280.856\n",
       "160    319.397\n",
       "161    295.932\n",
       "Name: Paraná - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Paraná - Desemprego</th>\n",
       "      <th>Paraná - value</th>\n",
       "      <th>Paraná - Produção de Cimento (t)</th>\n",
       "      <th>Paraná - PIB - Estadual</th>\n",
       "      <th>Paraná - PIB - Construção Civil</th>\n",
       "      <th>Paraná - PIB - Per Capita</th>\n",
       "      <th>Paraná - PIB - Preços de Mercado</th>\n",
       "      <th>Paraná - IDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>-0.143258</td>\n",
       "      <td>0.568952</td>\n",
       "      <td>0.770222</td>\n",
       "      <td>1.213697</td>\n",
       "      <td>-0.491764</td>\n",
       "      <td>0.925640</td>\n",
       "      <td>1.068236</td>\n",
       "      <td>1.456748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>-0.198091</td>\n",
       "      <td>0.552768</td>\n",
       "      <td>0.790292</td>\n",
       "      <td>1.215954</td>\n",
       "      <td>-0.507326</td>\n",
       "      <td>0.923363</td>\n",
       "      <td>1.066613</td>\n",
       "      <td>1.435411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>-0.252924</td>\n",
       "      <td>0.538720</td>\n",
       "      <td>0.804647</td>\n",
       "      <td>1.218210</td>\n",
       "      <td>-0.522888</td>\n",
       "      <td>0.921087</td>\n",
       "      <td>1.064989</td>\n",
       "      <td>1.414074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>-0.307757</td>\n",
       "      <td>0.529116</td>\n",
       "      <td>0.820506</td>\n",
       "      <td>1.220467</td>\n",
       "      <td>-0.538450</td>\n",
       "      <td>0.918810</td>\n",
       "      <td>1.063365</td>\n",
       "      <td>1.392736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>-0.362590</td>\n",
       "      <td>0.520829</td>\n",
       "      <td>0.835357</td>\n",
       "      <td>1.222724</td>\n",
       "      <td>-0.554011</td>\n",
       "      <td>0.916534</td>\n",
       "      <td>1.061742</td>\n",
       "      <td>1.371399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>-0.417423</td>\n",
       "      <td>0.523857</td>\n",
       "      <td>0.853711</td>\n",
       "      <td>1.224981</td>\n",
       "      <td>-0.569573</td>\n",
       "      <td>0.914257</td>\n",
       "      <td>1.060118</td>\n",
       "      <td>1.350062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>-0.472256</td>\n",
       "      <td>0.532033</td>\n",
       "      <td>0.846173</td>\n",
       "      <td>1.227237</td>\n",
       "      <td>-0.585135</td>\n",
       "      <td>0.911981</td>\n",
       "      <td>1.058494</td>\n",
       "      <td>1.328724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>-0.493807</td>\n",
       "      <td>0.541993</td>\n",
       "      <td>0.860049</td>\n",
       "      <td>1.224389</td>\n",
       "      <td>-0.583336</td>\n",
       "      <td>0.905995</td>\n",
       "      <td>1.051683</td>\n",
       "      <td>1.305447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>-0.515358</td>\n",
       "      <td>0.551845</td>\n",
       "      <td>0.885866</td>\n",
       "      <td>1.221541</td>\n",
       "      <td>-0.581537</td>\n",
       "      <td>0.900008</td>\n",
       "      <td>1.044872</td>\n",
       "      <td>1.282170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>-0.536909</td>\n",
       "      <td>0.565999</td>\n",
       "      <td>0.879636</td>\n",
       "      <td>1.218693</td>\n",
       "      <td>-0.579738</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>1.038060</td>\n",
       "      <td>1.258893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>-0.558460</td>\n",
       "      <td>0.577972</td>\n",
       "      <td>0.898014</td>\n",
       "      <td>1.215844</td>\n",
       "      <td>-0.577939</td>\n",
       "      <td>0.888036</td>\n",
       "      <td>1.031249</td>\n",
       "      <td>1.235616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>-0.580011</td>\n",
       "      <td>0.589347</td>\n",
       "      <td>0.899978</td>\n",
       "      <td>1.212996</td>\n",
       "      <td>-0.576140</td>\n",
       "      <td>0.882050</td>\n",
       "      <td>1.024438</td>\n",
       "      <td>1.212339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>-0.601562</td>\n",
       "      <td>0.603545</td>\n",
       "      <td>0.939506</td>\n",
       "      <td>1.210148</td>\n",
       "      <td>-0.574341</td>\n",
       "      <td>0.876063</td>\n",
       "      <td>1.017627</td>\n",
       "      <td>1.189062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>-0.623113</td>\n",
       "      <td>0.612658</td>\n",
       "      <td>0.951682</td>\n",
       "      <td>1.207300</td>\n",
       "      <td>-0.572542</td>\n",
       "      <td>0.870077</td>\n",
       "      <td>1.010815</td>\n",
       "      <td>1.165785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>-0.644664</td>\n",
       "      <td>0.621008</td>\n",
       "      <td>0.947530</td>\n",
       "      <td>1.204452</td>\n",
       "      <td>-0.570743</td>\n",
       "      <td>0.864091</td>\n",
       "      <td>1.004004</td>\n",
       "      <td>1.142508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>-0.666215</td>\n",
       "      <td>0.625316</td>\n",
       "      <td>0.968259</td>\n",
       "      <td>1.201603</td>\n",
       "      <td>-0.568944</td>\n",
       "      <td>0.858105</td>\n",
       "      <td>0.997193</td>\n",
       "      <td>1.119231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>-0.687766</td>\n",
       "      <td>0.633196</td>\n",
       "      <td>0.988577</td>\n",
       "      <td>1.198755</td>\n",
       "      <td>-0.567145</td>\n",
       "      <td>0.852118</td>\n",
       "      <td>0.990382</td>\n",
       "      <td>1.095954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>-0.709317</td>\n",
       "      <td>0.638659</td>\n",
       "      <td>1.005103</td>\n",
       "      <td>1.195907</td>\n",
       "      <td>-0.565346</td>\n",
       "      <td>0.846132</td>\n",
       "      <td>0.983570</td>\n",
       "      <td>1.072677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>-0.730868</td>\n",
       "      <td>0.648943</td>\n",
       "      <td>1.007585</td>\n",
       "      <td>1.193059</td>\n",
       "      <td>-0.563547</td>\n",
       "      <td>0.840146</td>\n",
       "      <td>0.976759</td>\n",
       "      <td>1.049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>-0.744522</td>\n",
       "      <td>0.662165</td>\n",
       "      <td>1.061405</td>\n",
       "      <td>1.183952</td>\n",
       "      <td>-0.556510</td>\n",
       "      <td>0.826270</td>\n",
       "      <td>0.965697</td>\n",
       "      <td>1.004235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>-0.758176</td>\n",
       "      <td>0.677642</td>\n",
       "      <td>1.071889</td>\n",
       "      <td>1.174846</td>\n",
       "      <td>-0.549474</td>\n",
       "      <td>0.812394</td>\n",
       "      <td>0.954635</td>\n",
       "      <td>0.959071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>-0.771829</td>\n",
       "      <td>0.689219</td>\n",
       "      <td>1.045458</td>\n",
       "      <td>1.165739</td>\n",
       "      <td>-0.542437</td>\n",
       "      <td>0.798519</td>\n",
       "      <td>0.943573</td>\n",
       "      <td>0.913906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>-0.785483</td>\n",
       "      <td>0.694030</td>\n",
       "      <td>1.088730</td>\n",
       "      <td>1.156633</td>\n",
       "      <td>-0.535401</td>\n",
       "      <td>0.784643</td>\n",
       "      <td>0.932510</td>\n",
       "      <td>0.868742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>-0.799137</td>\n",
       "      <td>0.706071</td>\n",
       "      <td>1.136080</td>\n",
       "      <td>1.147526</td>\n",
       "      <td>-0.528364</td>\n",
       "      <td>0.770767</td>\n",
       "      <td>0.921448</td>\n",
       "      <td>0.823577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>-0.812791</td>\n",
       "      <td>0.738090</td>\n",
       "      <td>1.153170</td>\n",
       "      <td>1.138420</td>\n",
       "      <td>-0.521328</td>\n",
       "      <td>0.756891</td>\n",
       "      <td>0.910386</td>\n",
       "      <td>0.778412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-0.826445</td>\n",
       "      <td>0.770388</td>\n",
       "      <td>1.208142</td>\n",
       "      <td>1.129314</td>\n",
       "      <td>-0.514291</td>\n",
       "      <td>0.743016</td>\n",
       "      <td>0.899324</td>\n",
       "      <td>0.733248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>-0.840099</td>\n",
       "      <td>0.821622</td>\n",
       "      <td>1.241242</td>\n",
       "      <td>1.120207</td>\n",
       "      <td>-0.507255</td>\n",
       "      <td>0.729140</td>\n",
       "      <td>0.888262</td>\n",
       "      <td>0.688083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>-0.853753</td>\n",
       "      <td>0.859766</td>\n",
       "      <td>1.313851</td>\n",
       "      <td>1.111101</td>\n",
       "      <td>-0.500218</td>\n",
       "      <td>0.715264</td>\n",
       "      <td>0.877199</td>\n",
       "      <td>0.642919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-0.867406</td>\n",
       "      <td>0.897253</td>\n",
       "      <td>1.363920</td>\n",
       "      <td>1.101994</td>\n",
       "      <td>-0.493182</td>\n",
       "      <td>0.701389</td>\n",
       "      <td>0.866137</td>\n",
       "      <td>0.597754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-0.881060</td>\n",
       "      <td>0.935674</td>\n",
       "      <td>1.387915</td>\n",
       "      <td>1.092888</td>\n",
       "      <td>-0.486145</td>\n",
       "      <td>0.687513</td>\n",
       "      <td>0.855075</td>\n",
       "      <td>0.552589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162                                         -0.601510   \n",
       "163                                         -0.786068   \n",
       "164                                         -0.830387   \n",
       "165                                         -0.801089   \n",
       "166                                         -0.959917   \n",
       "167                                         -1.022309   \n",
       "168                                         -1.074401   \n",
       "169                                         -1.119597   \n",
       "170                                         -1.078648   \n",
       "171                                         -1.055426   \n",
       "172                                         -1.101053   \n",
       "173                                         -1.211370   \n",
       "174                                         -1.157198   \n",
       "175                                         -1.223444   \n",
       "176                                         -1.311519   \n",
       "177                                         -1.362602   \n",
       "178                                         -1.380125   \n",
       "179                                         -1.219296   \n",
       "180                                         -1.300284   \n",
       "181                                         -1.336476   \n",
       "182                                         -1.415774   \n",
       "183                                         -1.526021   \n",
       "184                                         -1.681806   \n",
       "185                                         -1.735167   \n",
       "186                                         -1.962315   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Paraná - Desemprego  \\\n",
       "162                                0.763466  -1.213929            -0.143258   \n",
       "163                                0.752299  -1.292173            -0.198091   \n",
       "164                                0.741131  -1.324219            -0.252924   \n",
       "165                                0.729964  -1.344446            -0.307757   \n",
       "166                                0.718796  -1.381638            -0.362590   \n",
       "167                                0.707629  -1.411208            -0.417423   \n",
       "168                                0.696461  -1.412953            -0.472256   \n",
       "169                                0.681823  -1.491464            -0.493807   \n",
       "170                                0.667184  -1.573805            -0.515358   \n",
       "171                                0.652545  -1.564950            -0.536909   \n",
       "172                                0.637906  -1.581584            -0.558460   \n",
       "173                                0.623268  -1.565976            -0.580011   \n",
       "174                                0.608629  -1.648556            -0.601562   \n",
       "175                                0.593990  -1.650049            -0.623113   \n",
       "176                                0.579351  -1.653957            -0.644664   \n",
       "177                                0.564713  -1.652572            -0.666215   \n",
       "178                                0.550074  -1.715349            -0.687766   \n",
       "179                                0.535435  -1.750917            -0.709317   \n",
       "180                                0.520796  -1.718448            -0.730868   \n",
       "181                                0.501996  -1.733426            -0.744522   \n",
       "182                                0.483195  -1.729362            -0.758176   \n",
       "183                                0.464395  -1.748544            -0.771829   \n",
       "184                                0.445594  -1.778060            -0.785483   \n",
       "185                                0.426794  -1.773710            -0.799137   \n",
       "186                                0.407993  -1.757007            -0.812791   \n",
       "187                                0.389193  -1.749976            -0.826445   \n",
       "188                                0.370392  -1.593005            -0.840099   \n",
       "189                                0.351592  -1.351489            -0.853753   \n",
       "190                                0.332791  -1.198492            -0.867406   \n",
       "191                                0.313991  -1.100894            -0.881060   \n",
       "\n",
       "     Paraná - value  Paraná - Produção de Cimento (t)  \\\n",
       "162        0.568952                          0.770222   \n",
       "163        0.552768                          0.790292   \n",
       "164        0.538720                          0.804647   \n",
       "165        0.529116                          0.820506   \n",
       "166        0.520829                          0.835357   \n",
       "167        0.523857                          0.853711   \n",
       "168        0.532033                          0.846173   \n",
       "169        0.541993                          0.860049   \n",
       "170        0.551845                          0.885866   \n",
       "171        0.565999                          0.879636   \n",
       "172        0.577972                          0.898014   \n",
       "173        0.589347                          0.899978   \n",
       "174        0.603545                          0.939506   \n",
       "175        0.612658                          0.951682   \n",
       "176        0.621008                          0.947530   \n",
       "177        0.625316                          0.968259   \n",
       "178        0.633196                          0.988577   \n",
       "179        0.638659                          1.005103   \n",
       "180        0.648943                          1.007585   \n",
       "181        0.662165                          1.061405   \n",
       "182        0.677642                          1.071889   \n",
       "183        0.689219                          1.045458   \n",
       "184        0.694030                          1.088730   \n",
       "185        0.706071                          1.136080   \n",
       "186        0.738090                          1.153170   \n",
       "187        0.770388                          1.208142   \n",
       "188        0.821622                          1.241242   \n",
       "189        0.859766                          1.313851   \n",
       "190        0.897253                          1.363920   \n",
       "191        0.935674                          1.387915   \n",
       "\n",
       "     Paraná - PIB - Estadual  Paraná - PIB - Construção Civil  \\\n",
       "162                 1.213697                        -0.491764   \n",
       "163                 1.215954                        -0.507326   \n",
       "164                 1.218210                        -0.522888   \n",
       "165                 1.220467                        -0.538450   \n",
       "166                 1.222724                        -0.554011   \n",
       "167                 1.224981                        -0.569573   \n",
       "168                 1.227237                        -0.585135   \n",
       "169                 1.224389                        -0.583336   \n",
       "170                 1.221541                        -0.581537   \n",
       "171                 1.218693                        -0.579738   \n",
       "172                 1.215844                        -0.577939   \n",
       "173                 1.212996                        -0.576140   \n",
       "174                 1.210148                        -0.574341   \n",
       "175                 1.207300                        -0.572542   \n",
       "176                 1.204452                        -0.570743   \n",
       "177                 1.201603                        -0.568944   \n",
       "178                 1.198755                        -0.567145   \n",
       "179                 1.195907                        -0.565346   \n",
       "180                 1.193059                        -0.563547   \n",
       "181                 1.183952                        -0.556510   \n",
       "182                 1.174846                        -0.549474   \n",
       "183                 1.165739                        -0.542437   \n",
       "184                 1.156633                        -0.535401   \n",
       "185                 1.147526                        -0.528364   \n",
       "186                 1.138420                        -0.521328   \n",
       "187                 1.129314                        -0.514291   \n",
       "188                 1.120207                        -0.507255   \n",
       "189                 1.111101                        -0.500218   \n",
       "190                 1.101994                        -0.493182   \n",
       "191                 1.092888                        -0.486145   \n",
       "\n",
       "     Paraná - PIB - Per Capita  Paraná - PIB - Preços de Mercado  Paraná - IDH  \n",
       "162                   0.925640                          1.068236      1.456748  \n",
       "163                   0.923363                          1.066613      1.435411  \n",
       "164                   0.921087                          1.064989      1.414074  \n",
       "165                   0.918810                          1.063365      1.392736  \n",
       "166                   0.916534                          1.061742      1.371399  \n",
       "167                   0.914257                          1.060118      1.350062  \n",
       "168                   0.911981                          1.058494      1.328724  \n",
       "169                   0.905995                          1.051683      1.305447  \n",
       "170                   0.900008                          1.044872      1.282170  \n",
       "171                   0.894022                          1.038060      1.258893  \n",
       "172                   0.888036                          1.031249      1.235616  \n",
       "173                   0.882050                          1.024438      1.212339  \n",
       "174                   0.876063                          1.017627      1.189062  \n",
       "175                   0.870077                          1.010815      1.165785  \n",
       "176                   0.864091                          1.004004      1.142508  \n",
       "177                   0.858105                          0.997193      1.119231  \n",
       "178                   0.852118                          0.990382      1.095954  \n",
       "179                   0.846132                          0.983570      1.072677  \n",
       "180                   0.840146                          0.976759      1.049400  \n",
       "181                   0.826270                          0.965697      1.004235  \n",
       "182                   0.812394                          0.954635      0.959071  \n",
       "183                   0.798519                          0.943573      0.913906  \n",
       "184                   0.784643                          0.932510      0.868742  \n",
       "185                   0.770767                          0.921448      0.823577  \n",
       "186                   0.756891                          0.910386      0.778412  \n",
       "187                   0.743016                          0.899324      0.733248  \n",
       "188                   0.729140                          0.888262      0.688083  \n",
       "189                   0.715264                          0.877199      0.642919  \n",
       "190                   0.701389                          0.866137      0.597754  \n",
       "191                   0.687513                          0.855075      0.552589  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    354.558\n",
       "163    360.106\n",
       "164    350.123\n",
       "165    288.254\n",
       "166    301.687\n",
       "167    268.901\n",
       "168    274.431\n",
       "169    298.219\n",
       "170    328.955\n",
       "171    335.039\n",
       "172    260.723\n",
       "173    366.929\n",
       "174    353.426\n",
       "175    344.937\n",
       "176    302.082\n",
       "177    294.467\n",
       "178    336.029\n",
       "179    278.117\n",
       "180    323.005\n",
       "181    291.453\n",
       "182    300.203\n",
       "183    317.058\n",
       "184    314.142\n",
       "185    301.878\n",
       "186    358.797\n",
       "187    356.169\n",
       "188    316.188\n",
       "189    346.214\n",
       "190    323.401\n",
       "191    238.466\n",
       "Name: Paraná - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*6 + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    train, train_val = validation_splitter(train_input, 7)\n",
    "    target,target_val = validation_splitter(train_target, 7)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val, target_val),\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1633467630, 1675636196, 3809596830, 1616354214, 3912200630, 1217486749, 3813094631, 3609619645, 36530721, 2380056462, 1038529129, 1238414210, 297138764, 3210089238, 1488807308, 300420039, 3988177086, 2575384715, 647476135, 800966040, 3810540045, 206373658, 1909072379, 712135588, 921838056]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 408.8321228027344\n",
      "winner_seed: 1633467630\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 17:54:55.967025: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2023-10-14 17:54:56.006967: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 462.48223876953125\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 410.6127014160156\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 499.3442077636719\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 1334.7939453125\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 480.9276123046875\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 465.77288818359375\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 542.5612182617188\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 528.1002197265625\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 444.2518310546875\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 488.12286376953125\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 499.8350524902344\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 18:01:43.844521: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 586.665283203125\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 495.22332763671875\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 459.454345703125\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 435.5867919921875\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 446.0794372558594\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 551.1141967773438\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 580.7311401367188\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 504.1854553222656\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 504.8590393066406\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 541.8212280273438\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 446.889892578125\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 525.7512817382812\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 338.4856262207031\n",
      "winner_seed: 921838056\n",
      "\n",
      "\n",
      "final_seed: 921838056\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 1s 24ms/step - loss: 87894.1484 - val_loss: 108002.1094\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68085.7812 - val_loss: 44666.4062\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 36365.4766 - val_loss: 79111.8047\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 67545.5938 - val_loss: 58297.9844\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 43658.4570 - val_loss: 34464.5273\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42621.1758 - val_loss: 32112.8691\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 21456.6836 - val_loss: 6417.7412\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12491.0537 - val_loss: 14838.9971\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12106.9736 - val_loss: 7461.1875\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 29075.6621 - val_loss: 25867.2129\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28765.9746 - val_loss: 33391.8633\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22174.5879 - val_loss: 24489.9844\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26078.4004 - val_loss: 22060.4512\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 19567.5371 - val_loss: 12582.1328\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12209.2969 - val_loss: 9132.3877\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6426.4092 - val_loss: 2762.3499\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2009.1041 - val_loss: 2979.7156\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1990.3894 - val_loss: 1688.5625\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1729.4636 - val_loss: 1445.5352\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1652.6539 - val_loss: 1096.4866\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1004.9603 - val_loss: 764.5137\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 870.5593 - val_loss: 1214.2418\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 985.6411 - val_loss: 810.1888\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 767.5251 - val_loss: 1125.4515\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 946.6672 - val_loss: 959.5942\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 759.3608 - val_loss: 657.5460\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 857.9955 - val_loss: 1039.9777\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 677.7809 - val_loss: 1792.7205\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 693.7589 - val_loss: 1581.3942\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 771.2226 - val_loss: 1460.3344\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 721.5779 - val_loss: 1358.3015\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 882.3892 - val_loss: 2213.5146\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 913.4410 - val_loss: 1241.9446\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 583.9210 - val_loss: 2679.1157\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 991.8005 - val_loss: 1157.6149\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 815.1573 - val_loss: 1098.3840\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 495.3077 - val_loss: 1433.1450\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 636.1027 - val_loss: 1419.3646\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 765.4297 - val_loss: 1107.9200\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 638.9556 - val_loss: 994.7233\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 598.9459 - val_loss: 1195.4122\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 687.4719 - val_loss: 633.8226\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 660.3437 - val_loss: 964.3294\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 635.6829 - val_loss: 794.2675\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 614.0820 - val_loss: 1388.2668\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 534.3239 - val_loss: 1486.4432\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 691.2346 - val_loss: 1015.8124\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 544.1443 - val_loss: 1075.0018\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 473.4167 - val_loss: 769.9722\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 597.5244 - val_loss: 581.5092\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 729.7592 - val_loss: 1317.9736\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 700.7487 - val_loss: 1876.4871\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 736.9743 - val_loss: 1089.4938\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 674.3022 - val_loss: 1281.2358\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 666.8192 - val_loss: 865.3231\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 733.1566 - val_loss: 920.9243\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 786.3079 - val_loss: 773.0306\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 747.1064 - val_loss: 859.8777\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 797.3314 - val_loss: 1145.5536\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 743.6833 - val_loss: 1271.5209\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 661.5603 - val_loss: 1431.1028\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 651.8244 - val_loss: 1033.3329\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 614.0490 - val_loss: 822.8845\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 668.1721 - val_loss: 1280.5618\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 599.9309 - val_loss: 868.4479\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 598.2038 - val_loss: 591.2958\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 855.1105 - val_loss: 907.6840\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 798.6572 - val_loss: 745.8078\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 726.4453 - val_loss: 971.8541\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 769.6679 - val_loss: 947.3448\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 774.2767 - val_loss: 685.5467\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 837.2660 - val_loss: 654.7135\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 859.4282 - val_loss: 722.4360\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 881.5817 - val_loss: 1104.5646\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 984.6686 - val_loss: 885.3115\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 731.0308 - val_loss: 846.7715\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 777.2614 - val_loss: 1090.7174\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 759.5854 - val_loss: 1347.6942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 795.2693 - val_loss: 724.8357\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 680.4286 - val_loss: 1317.9315\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 588.4490 - val_loss: 1186.5858\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 541.9902 - val_loss: 1154.7334\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 611.9245 - val_loss: 754.1584\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 559.5034 - val_loss: 787.6329\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 835.6395 - val_loss: 1043.9237\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 674.1232 - val_loss: 1217.0898\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 579.6667 - val_loss: 1577.1969\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 546.9611 - val_loss: 737.5052\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 619.0789 - val_loss: 672.4992\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 557.5121 - val_loss: 810.2268\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 703.6055 - val_loss: 1051.6816\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 682.2143 - val_loss: 672.6856\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 569.5842 - val_loss: 676.0139\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 556.1835 - val_loss: 606.3178\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 581.1520 - val_loss: 1078.4714\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 575.8503 - val_loss: 960.3180\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 490.8336 - val_loss: 1011.6391\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 676.8022 - val_loss: 1300.6605\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 960.2036 - val_loss: 1129.1884\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 924.2982 - val_loss: 1058.8201\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 787.7144 - val_loss: 1120.2708\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 800.6979 - val_loss: 1187.6438\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 829.8071 - val_loss: 1272.9169\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 801.9929 - val_loss: 1438.3945\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 922.3157 - val_loss: 1089.3025\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 993.2552 - val_loss: 1257.9308\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1114.4679 - val_loss: 1809.8031\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1178.1060 - val_loss: 1099.0406\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1038.1556 - val_loss: 996.2743\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1039.9473 - val_loss: 1523.6746\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 927.2543 - val_loss: 1527.1885\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 980.3328 - val_loss: 1404.1989\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 872.5849 - val_loss: 911.7166\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 803.2430 - val_loss: 1087.3743\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 676.5365 - val_loss: 1815.6002\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 794.5781 - val_loss: 1173.2523\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 617.5596 - val_loss: 1126.4166\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 622.4685 - val_loss: 1490.4984\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 607.9600 - val_loss: 1063.0164\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 596.2988 - val_loss: 952.6149\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 555.3787 - val_loss: 1311.9501\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 630.3052 - val_loss: 957.6098\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 614.3608 - val_loss: 959.0337\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 792.6014 - val_loss: 1470.7004\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 815.3955 - val_loss: 1166.8347\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 731.0671 - val_loss: 1584.6368\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 540.2510 - val_loss: 1348.5459\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 562.2968 - val_loss: 1092.2369\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 483.6891 - val_loss: 696.6733\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 536.8141 - val_loss: 570.0714\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 662.1197 - val_loss: 821.4720\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 984.3244 - val_loss: 3160.2537\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 662.8408 - val_loss: 684.5323\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 548.1160 - val_loss: 884.6381\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 641.5488 - val_loss: 912.6834\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 936.6693 - val_loss: 1013.6296\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 714.5227 - val_loss: 1238.5922\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 504.5016 - val_loss: 1014.8512\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 742.5291 - val_loss: 752.3980\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 599.5577 - val_loss: 1030.4789\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 755.4881 - val_loss: 2344.3159\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2100.9277 - val_loss: 1110.5736\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 563.6491 - val_loss: 1207.1388\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 721.4890 - val_loss: 549.2924\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 577.4222 - val_loss: 834.5641\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 666.8148 - val_loss: 1105.6826\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 700.2029 - val_loss: 1152.6897\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 680.9749 - val_loss: 1337.2191\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 761.9258 - val_loss: 920.3438\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 913.0542 - val_loss: 1251.4072\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 806.4224 - val_loss: 1867.3585\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 691.8289 - val_loss: 755.8873\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 648.5233 - val_loss: 1744.7271\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 735.8770 - val_loss: 804.3930\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 768.4957 - val_loss: 1037.4044\n",
      "Epoch 156/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 756.3920 - val_loss: 957.1919\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 598.0702 - val_loss: 1071.9407\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 645.1237 - val_loss: 831.5080\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 651.2945 - val_loss: 739.2527\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 512.5764 - val_loss: 778.6285\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 479.7567 - val_loss: 1058.2808\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 656.7845 - val_loss: 1235.2994\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 940.2617 - val_loss: 1540.2517\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 976.1498 - val_loss: 927.7648\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 777.9911 - val_loss: 1149.8949\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 794.8906 - val_loss: 1159.5969\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 861.3040 - val_loss: 1093.9305\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 705.2911 - val_loss: 1233.5754\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 663.1342 - val_loss: 1204.6465\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 805.9805 - val_loss: 854.3810\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 714.4944 - val_loss: 847.2810\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 617.7922 - val_loss: 983.6660\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 576.9878 - val_loss: 1098.4186\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 667.6389 - val_loss: 926.6626\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 616.7674 - val_loss: 1515.9219\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 769.7162 - val_loss: 1008.2833\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 588.2599 - val_loss: 922.1302\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 593.3854 - val_loss: 1769.6311\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 660.4954 - val_loss: 1452.3531\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 768.6299 - val_loss: 1520.6320\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 633.5306 - val_loss: 1132.8052\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 608.7249 - val_loss: 1384.6996\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 721.0677 - val_loss: 1398.2111\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 713.1333 - val_loss: 1399.0355\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 691.8064 - val_loss: 933.9857\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 624.8517 - val_loss: 684.0107\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 647.8657 - val_loss: 1326.9016\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 804.5173 - val_loss: 1497.0563\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 818.5583 - val_loss: 1261.9701\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1090.7982 - val_loss: 1550.2646\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 685.7950 - val_loss: 1343.6046\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 600.6677 - val_loss: 1042.9106\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 679.9730 - val_loss: 1052.1327\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 682.3569 - val_loss: 932.3348\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 525.9506 - val_loss: 1079.5736\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 550.8665 - val_loss: 1006.6182\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 478.0497 - val_loss: 821.3868\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 458.2424 - val_loss: 563.8437\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 601.1646 - val_loss: 1073.9946\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 524.9646 - val_loss: 1293.5065\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 608.5338 - val_loss: 1045.7321\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 600.5976 - val_loss: 898.3359\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 583.5381 - val_loss: 742.8632\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 553.1479 - val_loss: 838.5269\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 567.9560 - val_loss: 871.0500\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 756.9121 - val_loss: 984.2667\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 670.9275 - val_loss: 1065.7656\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 668.2802 - val_loss: 801.5840\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 585.9177 - val_loss: 1292.6318\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 724.2715 - val_loss: 963.3032\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 694.9322 - val_loss: 772.9913\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 647.2565 - val_loss: 1428.4266\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 593.7541 - val_loss: 915.6142\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 643.4832 - val_loss: 1288.2484\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 584.2413 - val_loss: 781.4391\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 531.4946 - val_loss: 1139.5652\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 548.1965 - val_loss: 1430.1133\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 566.9155 - val_loss: 1321.0511\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 546.7988 - val_loss: 1026.7079\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 567.5408 - val_loss: 1113.2195\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 525.5797 - val_loss: 1249.9773\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 614.9916 - val_loss: 868.6968\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 589.1619 - val_loss: 1426.5178\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 641.0598 - val_loss: 1625.5594\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 603.3209 - val_loss: 1041.3448\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 609.0338 - val_loss: 1199.7350\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 559.3620 - val_loss: 1165.3723\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 573.5309 - val_loss: 860.4902\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 587.6475 - val_loss: 935.5215\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 714.9387 - val_loss: 984.5245\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 562.9965 - val_loss: 903.7402\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 623.0589 - val_loss: 745.7825\n",
      "Epoch 233/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 539.9505 - val_loss: 1382.1191\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 649.1176 - val_loss: 974.3289\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 615.9639 - val_loss: 879.7438\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 578.7269 - val_loss: 1179.0375\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 582.0931 - val_loss: 1120.8492\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 600.3574 - val_loss: 1064.5204\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 608.9382 - val_loss: 1055.3241\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 658.1074 - val_loss: 1111.8187\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 594.2588 - val_loss: 455.1496\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 678.3990 - val_loss: 932.0280\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 569.2104 - val_loss: 792.1984\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 564.6971 - val_loss: 1289.7239\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 535.7610 - val_loss: 924.7611\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 457.4465 - val_loss: 2256.9995\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 661.5935 - val_loss: 1223.0778\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 496.5206 - val_loss: 668.8588\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 489.9846 - val_loss: 760.0545\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 585.0663 - val_loss: 1931.1340\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 737.9443 - val_loss: 1110.5686\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 604.9156 - val_loss: 1107.9860\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 525.5298 - val_loss: 1112.9000\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 515.9644 - val_loss: 1222.9148\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 628.7983 - val_loss: 1096.1774\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 553.0887 - val_loss: 1137.8129\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 636.7604 - val_loss: 961.7834\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 482.6289 - val_loss: 759.0362\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 539.3400 - val_loss: 1230.6321\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 569.9896 - val_loss: 1099.1743\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 827.5677 - val_loss: 1124.1243\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 827.1837 - val_loss: 1249.6095\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1326.2388 - val_loss: 1875.0452\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1226.3888 - val_loss: 2400.4434\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 692.8113 - val_loss: 1530.1970\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 724.8667 - val_loss: 1274.5255\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 754.0568 - val_loss: 1099.9767\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 600.9443 - val_loss: 1858.9181\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 539.7963 - val_loss: 1244.4180\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 534.5973 - val_loss: 817.8180\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 714.5328 - val_loss: 1032.7135\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 559.5076 - val_loss: 1053.1901\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 618.7150 - val_loss: 776.7195\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 684.6765 - val_loss: 983.4551\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 688.8098 - val_loss: 1440.4335\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 600.9176 - val_loss: 1076.5763\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 582.4153 - val_loss: 1083.2063\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 549.2380 - val_loss: 1171.8234\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 490.1470 - val_loss: 866.4484\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 727.2249 - val_loss: 1059.5970\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 661.9416 - val_loss: 1004.7209\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 526.3535 - val_loss: 1330.3888\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 572.3925 - val_loss: 1457.0065\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 468.1490 - val_loss: 1027.5668\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 508.2358 - val_loss: 1232.0128\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 460.5470 - val_loss: 1391.5693\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 645.1838 - val_loss: 599.5640\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 556.5819 - val_loss: 1202.6733\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 563.8516 - val_loss: 1030.9460\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 694.2043 - val_loss: 1327.6797\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 605.8809 - val_loss: 1018.1026\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 519.4715 - val_loss: 1011.2578\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 649.9525 - val_loss: 1324.0441\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 533.9373 - val_loss: 974.6744\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 497.3691 - val_loss: 1106.3684\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 490.4647 - val_loss: 971.3618\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 430.5779 - val_loss: 1068.7422\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 473.9675 - val_loss: 1219.6575\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 474.6548 - val_loss: 1225.6681\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 558.6881 - val_loss: 1044.0490\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 572.7108 - val_loss: 1157.9694\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 601.1168 - val_loss: 1314.9672\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 557.4217 - val_loss: 1322.6449\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 500.5683 - val_loss: 1436.3563\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 514.9496 - val_loss: 861.2164\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 497.6139 - val_loss: 1185.8896\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 478.9684 - val_loss: 1672.2925\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 673.0006 - val_loss: 1388.8269\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 467.9214 - val_loss: 1236.5897\n",
      "Epoch 310/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 557.1807 - val_loss: 1113.0728\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 518.2212 - val_loss: 686.0107\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 674.4453 - val_loss: 895.5922\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 619.4511 - val_loss: 961.7487\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 584.0399 - val_loss: 1228.3269\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 675.6328 - val_loss: 707.6927\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 715.1331 - val_loss: 915.5080\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 618.5643 - val_loss: 867.6795\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 488.3541 - val_loss: 912.6249\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 453.7829 - val_loss: 1075.1326\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 464.3053 - val_loss: 1283.6653\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 486.1396 - val_loss: 733.6105\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 554.2035 - val_loss: 823.6977\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 580.1085 - val_loss: 902.5451\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 508.8842 - val_loss: 853.0952\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 439.6355 - val_loss: 954.2637\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 436.0955 - val_loss: 1026.6167\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 481.8156 - val_loss: 647.2941\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 478.6270 - val_loss: 968.4258\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 492.9943 - val_loss: 1151.6814\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 475.3274 - val_loss: 769.3439\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 573.1684 - val_loss: 1122.1735\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 451.5262 - val_loss: 937.5321\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 507.6934 - val_loss: 897.9484\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 623.9402 - val_loss: 1076.2668\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 695.1083 - val_loss: 832.4349\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 544.4276 - val_loss: 1685.4608\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 523.0457 - val_loss: 1087.0239\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 559.1069 - val_loss: 1872.9650\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 559.4935 - val_loss: 960.0432\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 515.4304 - val_loss: 1471.4509\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 528.3270 - val_loss: 1006.8983\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 524.8889 - val_loss: 608.2460\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 552.4355 - val_loss: 736.7698\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 472.4026 - val_loss: 781.4173\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 545.0018 - val_loss: 725.7437\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 556.9271 - val_loss: 1006.1348\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 529.9393 - val_loss: 765.2216\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 607.1034 - val_loss: 1356.5841\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 530.0369 - val_loss: 881.3424\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 532.9666 - val_loss: 742.0927\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 478.6443 - val_loss: 807.8987\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 506.3543 - val_loss: 921.1006\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 505.3629 - val_loss: 890.9080\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 541.5064 - val_loss: 970.2007\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 482.8361 - val_loss: 848.5104\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 597.7360 - val_loss: 1269.5895\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 517.0875 - val_loss: 1145.5782\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 545.0325 - val_loss: 1240.0161\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 497.2211 - val_loss: 1155.9290\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 489.9207 - val_loss: 896.2215\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 631.7747 - val_loss: 911.1179\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 524.3373 - val_loss: 1236.9084\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 539.8393 - val_loss: 1191.4406\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 434.8293 - val_loss: 1581.9769\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 510.7725 - val_loss: 1242.6664\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 426.8391 - val_loss: 1314.1761\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 484.5360 - val_loss: 705.7679\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 459.6088 - val_loss: 610.6623\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 629.5607 - val_loss: 731.3967\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 773.1545 - val_loss: 948.9750\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 633.4194 - val_loss: 726.9802\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 610.4698 - val_loss: 961.9772\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 484.0982 - val_loss: 1165.2593\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 553.9116 - val_loss: 1302.9115\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 497.6968 - val_loss: 1011.2799\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 447.4376 - val_loss: 1029.5175\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 423.0821 - val_loss: 1062.6750\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 430.6381 - val_loss: 1143.5881\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 521.5555 - val_loss: 1236.7096\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 493.0234 - val_loss: 1384.0214\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 460.1156 - val_loss: 1251.1481\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 460.1067 - val_loss: 1185.1793\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 412.3265 - val_loss: 930.7520\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 403.5476 - val_loss: 842.3998\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 446.8142 - val_loss: 687.3130\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 526.8651 - val_loss: 958.6375\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 460.3932 - val_loss: 820.2478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 976.1439 - val_loss: 793.5499\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 634.9764 - val_loss: 801.6070\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 461.9664 - val_loss: 594.3451\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 641.8574 - val_loss: 1371.1212\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 620.4861 - val_loss: 3049.9871\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 762.8513 - val_loss: 1818.4427\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 488.2977 - val_loss: 1460.9244\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 406.9027 - val_loss: 932.2505\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 381.2935 - val_loss: 1736.0188\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 442.1213 - val_loss: 1376.8394\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 495.9451 - val_loss: 1316.1550\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 518.7355 - val_loss: 1371.6154\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 499.9050 - val_loss: 1174.9230\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 372.8883 - val_loss: 1450.9672\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 470.7768 - val_loss: 1300.3480\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 495.1213 - val_loss: 1193.2004\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 412.4313 - val_loss: 1126.3101\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 455.0978 - val_loss: 914.8304\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 437.8942 - val_loss: 1891.5305\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 735.3445 - val_loss: 1184.3635\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 577.1368 - val_loss: 1804.9144\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 510.2668 - val_loss: 1243.2125\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 457.4996 - val_loss: 1255.0680\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 471.7362 - val_loss: 1076.8640\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 507.4571 - val_loss: 1088.5745\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 491.4767 - val_loss: 1072.7809\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 420.7200 - val_loss: 1122.3257\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 412.3215 - val_loss: 1197.8383\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 475.0735 - val_loss: 882.0834\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 425.8620 - val_loss: 973.4872\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 398.7589 - val_loss: 1277.8885\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 475.8066 - val_loss: 1173.6488\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 400.8298 - val_loss: 951.5375\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 410.0446 - val_loss: 1285.5320\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 464.0479 - val_loss: 1241.3534\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 388.9536 - val_loss: 1206.3464\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 423.6455 - val_loss: 1113.8928\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 414.6023 - val_loss: 1124.3688\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 401.3319 - val_loss: 1158.5010\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 465.7399 - val_loss: 996.6141\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 447.6327 - val_loss: 825.8333\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 491.8524 - val_loss: 964.7067\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 417.9467 - val_loss: 867.2392\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 495.4628 - val_loss: 1090.1779\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 446.4334 - val_loss: 892.0605\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 552.7206 - val_loss: 1291.1960\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 473.8801 - val_loss: 1218.6038\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 590.2848 - val_loss: 1201.5017\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 451.2929 - val_loss: 1341.9619\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 410.4175 - val_loss: 1064.2321\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 447.5194 - val_loss: 1175.7024\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 405.2992 - val_loss: 966.3303\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 458.1258 - val_loss: 779.3375\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 460.8232 - val_loss: 914.1984\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 472.5364 - val_loss: 925.0610\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 455.3192 - val_loss: 949.7130\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 467.9467 - val_loss: 1172.5544\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 538.0424 - val_loss: 780.8056\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 574.7353 - val_loss: 807.4909\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 533.8789 - val_loss: 652.1942\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 543.5846 - val_loss: 839.8777\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 494.3156 - val_loss: 830.1562\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 453.5638 - val_loss: 838.3600\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 487.9281 - val_loss: 788.3570\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 426.2572 - val_loss: 1102.2032\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 459.7705 - val_loss: 1107.4867\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 521.5793 - val_loss: 1277.9285\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 511.1600 - val_loss: 1156.7898\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 539.6483 - val_loss: 1616.2184\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 651.9457 - val_loss: 1256.1899\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 688.6506 - val_loss: 1078.2596\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 668.2424 - val_loss: 1531.4366\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 711.5938 - val_loss: 1106.5703\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 577.9248 - val_loss: 1042.8197\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 592.1382 - val_loss: 985.4597\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 545.1158 - val_loss: 1168.3810\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 501.2682 - val_loss: 1093.0599\n",
      "Epoch 465/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 480.2037 - val_loss: 927.8808\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 448.6257 - val_loss: 1050.0754\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 475.5967 - val_loss: 1059.8108\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 501.4213 - val_loss: 1256.6570\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 566.5018 - val_loss: 1189.0808\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 454.5598 - val_loss: 955.5527\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 484.2208 - val_loss: 1035.0859\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 434.7965 - val_loss: 1068.4420\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 511.8556 - val_loss: 866.3761\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 626.0579 - val_loss: 853.0695\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 638.7352 - val_loss: 837.2040\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 580.5768 - val_loss: 1133.8352\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 782.3578 - val_loss: 953.4694\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1337.0240 - val_loss: 897.9688\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 876.7027 - val_loss: 1534.4314\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 717.5989 - val_loss: 1313.2979\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 658.3882 - val_loss: 728.4816\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 628.8030 - val_loss: 1197.4403\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 616.3689 - val_loss: 1319.5092\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 578.9034 - val_loss: 907.1263\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 490.4156 - val_loss: 911.8842\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 436.5620 - val_loss: 1178.7590\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 444.1487 - val_loss: 1354.7242\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 460.9362 - val_loss: 1435.0916\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 517.5193 - val_loss: 2041.7546\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 719.8205 - val_loss: 1224.2375\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 819.9430 - val_loss: 963.5601\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 668.2781 - val_loss: 836.3614\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 612.8578 - val_loss: 815.4853\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 544.8724 - val_loss: 1157.8875\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 595.5082 - val_loss: 823.8181\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 537.3901 - val_loss: 808.3604\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 506.3946 - val_loss: 1255.9141\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 519.6498 - val_loss: 1208.3854\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 433.6166 - val_loss: 1222.7922\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 459.8605 - val_loss: 1114.9413\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 476.9962 - val_loss: 1163.2579\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 422.2742 - val_loss: 1188.3154\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 674.6616 - val_loss: 1189.8921\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 705.9077 - val_loss: 1752.0557\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 566.4310 - val_loss: 1247.0695\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 594.9814 - val_loss: 1103.0099\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 608.4265 - val_loss: 1383.4062\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 622.0434 - val_loss: 1270.6558\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 535.8229 - val_loss: 1201.5103\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 504.3446 - val_loss: 1017.3294\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 488.4254 - val_loss: 1013.6124\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 476.1742 - val_loss: 1295.8716\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 506.3612 - val_loss: 1042.3007\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 455.9135 - val_loss: 722.1805\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 437.6067 - val_loss: 758.7081\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 425.8409 - val_loss: 832.2781\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 401.4057 - val_loss: 796.8824\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 395.4395 - val_loss: 869.7703\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 394.8353 - val_loss: 707.8359\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 534.9370 - val_loss: 1084.6930\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 534.0843 - val_loss: 1067.0972\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 477.1036 - val_loss: 709.1473\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 510.5292 - val_loss: 580.1322\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 501.8211 - val_loss: 765.1584\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 514.5297 - val_loss: 771.4366\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 496.1018 - val_loss: 667.7830\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 587.9314 - val_loss: 741.4034\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 502.4663 - val_loss: 1105.5801\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 654.0676 - val_loss: 1231.2162\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 513.0089 - val_loss: 665.2123\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 463.3460 - val_loss: 1197.7554\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 667.0469 - val_loss: 1194.9595\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 622.5579 - val_loss: 1065.0914\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 597.5839 - val_loss: 989.4507\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 524.5505 - val_loss: 852.7007\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 468.1380 - val_loss: 1189.6344\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 497.7971 - val_loss: 794.5692\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 493.3888 - val_loss: 983.1721\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 450.1355 - val_loss: 1099.4215\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 430.7058 - val_loss: 943.9942\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 483.4664 - val_loss: 1068.7406\n",
      "Epoch 542/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 447.4333 - val_loss: 1542.1910\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 493.1487 - val_loss: 959.5926\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 441.4045 - val_loss: 1489.2928\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 532.9263 - val_loss: 2249.2507\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 653.8300 - val_loss: 695.7853\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 525.9670 - val_loss: 1059.4762\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 521.0235 - val_loss: 1009.5150\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 519.6624 - val_loss: 1071.1927\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 439.0933 - val_loss: 1295.6945\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 468.2446 - val_loss: 1114.6440\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 489.2960 - val_loss: 1054.2433\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 516.1672 - val_loss: 1121.3182\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 454.6497 - val_loss: 1230.4403\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 497.0106 - val_loss: 1439.7323\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 500.4732 - val_loss: 865.0128\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 517.6489 - val_loss: 1294.5411\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 660.8771 - val_loss: 967.0896\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 452.1858 - val_loss: 1202.5863\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 419.8188 - val_loss: 1119.0922\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 497.1045 - val_loss: 959.1646\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 470.0017 - val_loss: 926.9474\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 477.2044 - val_loss: 1198.4139\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 550.6478 - val_loss: 1811.6204\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 781.6539 - val_loss: 961.5387\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 670.6852 - val_loss: 1142.6486\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 519.2369 - val_loss: 996.0170\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 567.1541 - val_loss: 1235.1947\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 460.4478 - val_loss: 1026.7731\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 475.4796 - val_loss: 1319.3699\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 515.8120 - val_loss: 1175.5262\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 443.0935 - val_loss: 985.5806\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 556.6428 - val_loss: 947.2031\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 476.9613 - val_loss: 960.6561\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 523.5048 - val_loss: 1267.2303\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 536.8239 - val_loss: 982.9677\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 482.1010 - val_loss: 1063.0750\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 526.5695 - val_loss: 868.0321\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 489.6729 - val_loss: 1002.6174\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 488.7955 - val_loss: 851.9855\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 476.5470 - val_loss: 1404.8210\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 497.9091 - val_loss: 848.8257\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 563.4446 - val_loss: 1266.6697\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 602.7348 - val_loss: 775.0687\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 602.3369 - val_loss: 722.6914\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 660.4222 - val_loss: 818.6802\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 618.4832 - val_loss: 824.6741\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 527.6958 - val_loss: 757.1000\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 540.3629 - val_loss: 711.6739\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 521.0666 - val_loss: 1016.3175\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 688.3921 - val_loss: 993.6382\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 567.7992 - val_loss: 910.9510\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 606.6840 - val_loss: 866.2923\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 597.6253 - val_loss: 975.8539\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 581.6125 - val_loss: 1052.1848\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 555.0865 - val_loss: 1105.8947\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 565.2245 - val_loss: 871.5232\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 645.5111 - val_loss: 792.1917\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 584.8596 - val_loss: 1023.0109\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 671.6501 - val_loss: 1129.6902\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 731.3207 - val_loss: 685.3335\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 691.4356 - val_loss: 1284.9092\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 554.3305 - val_loss: 781.2070\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 469.5227 - val_loss: 737.3424\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 485.9348 - val_loss: 1179.7091\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 417.3804 - val_loss: 962.2507\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 436.4838 - val_loss: 1019.2298\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 557.3030 - val_loss: 1068.0701\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 745.8793 - val_loss: 807.6068\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 867.9119 - val_loss: 750.3342\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 736.1019 - val_loss: 1152.0255\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 608.6584 - val_loss: 923.2847\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 672.9589 - val_loss: 850.4720\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 637.4789 - val_loss: 974.4933\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 844.1876 - val_loss: 1234.1949\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 719.4999 - val_loss: 835.9961\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 566.2286 - val_loss: 1025.7189\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 515.2610 - val_loss: 772.4516\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 494.1253 - val_loss: 935.1616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 518.8477 - val_loss: 1026.9785\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 614.5306 - val_loss: 760.1779\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 466.6469 - val_loss: 1422.1812\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 519.2203 - val_loss: 1081.7291\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 530.7479 - val_loss: 811.9728\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 405.1960 - val_loss: 689.1399\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 426.0753 - val_loss: 1106.0404\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 435.2464 - val_loss: 597.0477\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 449.8984 - val_loss: 798.8672\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 477.2585 - val_loss: 1036.7435\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 500.6006 - val_loss: 869.3678\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 487.6326 - val_loss: 1429.6123\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 538.3996 - val_loss: 1234.5621\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 475.4852 - val_loss: 1043.7184\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 456.2589 - val_loss: 913.8802\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 497.8955 - val_loss: 1359.4886\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 466.1736 - val_loss: 929.9736\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 463.8741 - val_loss: 1376.8154\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 425.0668 - val_loss: 1271.9515\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 480.0212 - val_loss: 1115.8848\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 417.5614 - val_loss: 1379.4164\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 507.6020 - val_loss: 883.7712\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 519.8543 - val_loss: 1284.2363\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 550.1843 - val_loss: 847.7801\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 509.1778 - val_loss: 1299.6965\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 488.0487 - val_loss: 1248.9312\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 469.3610 - val_loss: 1230.5422\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 394.5020 - val_loss: 1135.5732\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 475.1235 - val_loss: 1144.8027\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 474.5911 - val_loss: 996.2665\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 521.9144 - val_loss: 823.6209\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 600.1971 - val_loss: 501.9255\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 593.5521 - val_loss: 978.9065\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 706.6396 - val_loss: 1056.3643\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 726.7682 - val_loss: 2020.7373\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 832.4890 - val_loss: 1382.2017\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 751.4526 - val_loss: 959.7834\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 742.9090 - val_loss: 937.2441\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 744.4705 - val_loss: 1154.2186\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 734.4542 - val_loss: 1418.1194\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 699.9586 - val_loss: 705.3857\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 734.0726 - val_loss: 1164.5822\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 757.9385 - val_loss: 899.1160\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 690.3790 - val_loss: 1151.7769\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 696.8083 - val_loss: 1318.0339\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 730.9752 - val_loss: 824.6746\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 716.5338 - val_loss: 987.0061\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 703.3193 - val_loss: 1149.5446\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 663.7550 - val_loss: 885.8074\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 542.5005 - val_loss: 878.0803\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 590.0801 - val_loss: 800.7882\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 552.0339 - val_loss: 902.2208\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 625.8280 - val_loss: 911.0156\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 529.9362 - val_loss: 798.7322\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 576.7345 - val_loss: 1103.7211\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 593.0703 - val_loss: 976.0399\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 621.1060 - val_loss: 825.5734\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 593.7396 - val_loss: 887.6164\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 589.8818 - val_loss: 1033.2124\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 571.4769 - val_loss: 986.6700\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 512.1421 - val_loss: 1186.8472\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 538.9928 - val_loss: 1171.1595\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 560.3477 - val_loss: 620.0028\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 703.7932 - val_loss: 562.5527\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 610.6259 - val_loss: 922.6591\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 535.2078 - val_loss: 1022.3940\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 514.1063 - val_loss: 852.3696\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 563.1592 - val_loss: 888.2129\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 435.5332 - val_loss: 771.4059\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 455.5898 - val_loss: 734.0673\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 574.6768 - val_loss: 999.4315\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 542.3414 - val_loss: 924.1719\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 380.4507 - val_loss: 1099.7395\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 504.4571 - val_loss: 930.9399\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 476.7065 - val_loss: 931.1425\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 497.7964 - val_loss: 1027.3799\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 446.3506 - val_loss: 1632.6184\n",
      "Epoch 697/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 466.8783 - val_loss: 1263.6262\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 451.4120 - val_loss: 1129.2454\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 463.8022 - val_loss: 1574.8645\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 530.8734 - val_loss: 1246.9102\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 495.6357 - val_loss: 1657.3716\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 466.4443 - val_loss: 1494.7874\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 433.2906 - val_loss: 1427.0768\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 472.3531 - val_loss: 1818.2843\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 572.7687 - val_loss: 1832.8662\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 511.9849 - val_loss: 1043.0880\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 461.9453 - val_loss: 1117.7571\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 470.0739 - val_loss: 1479.3645\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 510.5374 - val_loss: 1065.1829\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 630.7377 - val_loss: 1183.3589\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 492.2041 - val_loss: 1039.5614\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 506.8033 - val_loss: 956.5545\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 415.9388 - val_loss: 1106.1648\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 569.8453 - val_loss: 1532.6357\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 598.5522 - val_loss: 595.4429\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 605.2581 - val_loss: 628.1661\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 485.8685 - val_loss: 559.0419\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 555.5232 - val_loss: 847.9965\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 456.6247 - val_loss: 677.7313\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 441.4737 - val_loss: 910.1609\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 492.1155 - val_loss: 1015.3599\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 626.4016 - val_loss: 661.4346\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 464.0859 - val_loss: 669.8830\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 600.0878 - val_loss: 752.1973\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 565.5912 - val_loss: 870.2156\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 554.2630 - val_loss: 611.1440\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 582.6717 - val_loss: 802.7161\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 534.2921 - val_loss: 786.2734\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 838.1323 - val_loss: 1194.3048\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 652.5217 - val_loss: 1282.1881\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 663.2018 - val_loss: 854.4282\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 742.3711 - val_loss: 988.2319\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 663.0430 - val_loss: 1189.7183\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 469.1154 - val_loss: 1139.7577\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 580.9084 - val_loss: 1281.6328\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 608.2726 - val_loss: 1084.1298\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3098.2830 - val_loss: 1632.2308\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1416.0613 - val_loss: 893.9054\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 930.7383 - val_loss: 1086.7878\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 705.2825 - val_loss: 1353.2683\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 641.4846 - val_loss: 890.9072\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 614.7315 - val_loss: 1087.7051\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 557.1350 - val_loss: 1102.6445\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 467.5648 - val_loss: 1333.9426\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 485.7983 - val_loss: 1338.2605\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 595.8157 - val_loss: 1376.4259\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 430.4549 - val_loss: 1304.4363\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 536.4290 - val_loss: 1410.7052\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 588.4361 - val_loss: 1240.3107\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 512.8321 - val_loss: 1272.9156\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 479.0900 - val_loss: 1480.0828\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2535.2153 - val_loss: 1047.0990\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2389.2930 - val_loss: 1328.8468\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1524.7896 - val_loss: 929.8078\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 728.7397 - val_loss: 1147.3508\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 870.4739 - val_loss: 913.0762\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 908.8406 - val_loss: 940.6820\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 667.8906 - val_loss: 693.4794\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 661.3245 - val_loss: 929.9374\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 654.8950 - val_loss: 1009.8856\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 619.0092 - val_loss: 1205.9762\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 437.4538 - val_loss: 1339.5657\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 456.3595 - val_loss: 1309.5302\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 789.5358 - val_loss: 975.5764\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 786.3153 - val_loss: 1129.3766\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 712.7853 - val_loss: 1006.0168\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1094.1587 - val_loss: 1519.9084\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1955.1805 - val_loss: 3557.0964\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2478.1982 - val_loss: 3776.2429\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2232.0576 - val_loss: 1182.2089\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1074.7415 - val_loss: 779.7924\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 925.3078 - val_loss: 922.1393\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 648.6832 - val_loss: 1379.5747\n",
      "Epoch 774/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 1104.5117 - val_loss: 613.0560\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 846.7271 - val_loss: 826.2142\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 972.5955 - val_loss: 338.4856\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 910.3549 - val_loss: 803.8580\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 971.6658 - val_loss: 829.2606\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 713.9677 - val_loss: 1028.1761\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1090.2061 - val_loss: 1273.6854\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 610.5289 - val_loss: 1042.8943\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 568.3782 - val_loss: 1504.7371\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 693.5422 - val_loss: 1251.0345\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 621.7350 - val_loss: 792.5792\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 650.6653 - val_loss: 1142.6949\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 597.6706 - val_loss: 825.6298\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1507.3956 - val_loss: 1074.0551\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 751.4299 - val_loss: 1127.7289\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 583.4705 - val_loss: 772.6445\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1685.5708 - val_loss: 1510.2968\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2000.8822 - val_loss: 670.6760\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 952.2261 - val_loss: 1503.5833\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 924.0298 - val_loss: 2079.1167\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1083.8206 - val_loss: 2208.2295\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 947.2745 - val_loss: 2073.0557\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 758.9380 - val_loss: 2690.4363\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1017.5462 - val_loss: 2095.5337\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 873.1949 - val_loss: 2539.5371\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 913.2339 - val_loss: 1650.8386\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 813.7770 - val_loss: 1474.8547\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 699.2036 - val_loss: 1784.4806\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 779.5931 - val_loss: 1614.1293\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 883.1503 - val_loss: 1231.5043\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 921.8926 - val_loss: 1376.6488\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 884.0755 - val_loss: 922.8297\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 875.6443 - val_loss: 2012.1589\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 912.4201 - val_loss: 1387.4232\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1028.2343 - val_loss: 1022.1043\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 715.9937 - val_loss: 1094.3617\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 787.7458 - val_loss: 939.0985\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 680.9790 - val_loss: 1282.0153\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 686.9620 - val_loss: 743.5090\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 899.2733 - val_loss: 744.5972\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 858.9670 - val_loss: 982.5236\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 789.4108 - val_loss: 866.6003\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 594.8958 - val_loss: 1740.9320\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 842.1616 - val_loss: 1582.9827\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 734.0815 - val_loss: 1181.0800\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 742.8813 - val_loss: 1175.9747\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 547.6524 - val_loss: 1178.1179\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 665.5082 - val_loss: 882.6788\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 725.6599 - val_loss: 2144.6895\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 845.5308 - val_loss: 1386.1891\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 561.4363 - val_loss: 1476.2504\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 602.1063 - val_loss: 1527.6021\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 522.8322 - val_loss: 1584.1893\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 502.8205 - val_loss: 1536.6614\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 489.2549 - val_loss: 1499.1620\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 567.1685 - val_loss: 1663.9032\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 587.7695 - val_loss: 1683.9462\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 713.9778 - val_loss: 1190.9126\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 611.1719 - val_loss: 1275.8831\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 671.6299 - val_loss: 1405.3069\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 553.8342 - val_loss: 1109.7471\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 515.4420 - val_loss: 1089.9796\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 525.1066 - val_loss: 1014.5887\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 478.6412 - val_loss: 823.8754\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 634.9124 - val_loss: 940.5148\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 637.4885 - val_loss: 787.6970\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 553.2268 - val_loss: 820.2949\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 500.2090 - val_loss: 1106.0190\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 700.8988 - val_loss: 1060.5759\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 625.4647 - val_loss: 747.3497\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 549.1346 - val_loss: 722.3461\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 564.6602 - val_loss: 958.0959\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 668.8876 - val_loss: 814.1723\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 561.7180 - val_loss: 877.8607\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 572.9946 - val_loss: 502.7645\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 704.9064 - val_loss: 616.9371\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 638.7297 - val_loss: 780.6281\n",
      "Epoch 851/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 612.2617 - val_loss: 824.1428\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 696.2683 - val_loss: 793.5786\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 527.0509 - val_loss: 1387.4860\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 716.6743 - val_loss: 1352.7502\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 677.2460 - val_loss: 1645.2427\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 739.1750 - val_loss: 896.7869\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 558.6664 - val_loss: 1297.3567\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 601.9834 - val_loss: 941.2612\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 559.8237 - val_loss: 1018.8359\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 572.2303 - val_loss: 1175.1014\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 633.5632 - val_loss: 1324.6492\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 829.6036 - val_loss: 1132.9934\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 644.8780 - val_loss: 871.0912\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 736.0285 - val_loss: 1149.6665\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 567.9230 - val_loss: 1118.9960\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 622.2446 - val_loss: 775.1024\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 653.7234 - val_loss: 1112.4927\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 731.0706 - val_loss: 1023.1624\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 662.1250 - val_loss: 1146.5785\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 929.2648 - val_loss: 668.4399\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 931.1134 - val_loss: 1820.8407\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1029.6292 - val_loss: 969.8424\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 956.3788 - val_loss: 1383.0254\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 776.1440 - val_loss: 1114.4193\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 691.1275 - val_loss: 1113.9077\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 572.6536 - val_loss: 1145.7612\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 605.1942 - val_loss: 951.1586\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 529.4945 - val_loss: 867.3822\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 624.0168 - val_loss: 1246.5754\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 578.6509 - val_loss: 1073.0488\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 599.1691 - val_loss: 1480.9832\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 587.8134 - val_loss: 1171.5963\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 558.8439 - val_loss: 966.9813\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 524.3922 - val_loss: 958.6957\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 516.9357 - val_loss: 985.8021\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 530.9116 - val_loss: 1245.9503\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 578.0704 - val_loss: 1078.3943\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 608.3544 - val_loss: 816.1924\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 573.3734 - val_loss: 625.1851\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 559.2125 - val_loss: 657.2471\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 481.5690 - val_loss: 766.7202\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 445.2452 - val_loss: 844.3533\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 484.6778 - val_loss: 797.2892\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 562.4312 - val_loss: 784.7651\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 528.2234 - val_loss: 1348.1332\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 535.5630 - val_loss: 826.6337\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 461.4661 - val_loss: 808.2685\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 535.9058 - val_loss: 620.9904\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 512.3090 - val_loss: 895.5965\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 634.3513 - val_loss: 983.2957\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 700.5306 - val_loss: 691.6926\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 634.1363 - val_loss: 707.2972\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 564.7444 - val_loss: 658.9218\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 519.1004 - val_loss: 906.9017\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 502.1018 - val_loss: 746.3759\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 536.8022 - val_loss: 826.8857\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 554.9092 - val_loss: 647.4923\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 606.1378 - val_loss: 1060.6090\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 652.1354 - val_loss: 1335.9948\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 647.6201 - val_loss: 936.9664\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 653.7884 - val_loss: 1152.9374\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 604.9718 - val_loss: 867.8215\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 601.8416 - val_loss: 693.5452\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 648.8278 - val_loss: 954.9852\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 539.5856 - val_loss: 1071.8025\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 543.8377 - val_loss: 955.1288\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 589.0375 - val_loss: 1045.4823\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 672.4181 - val_loss: 753.5336\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 780.0942 - val_loss: 929.2149\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 668.8425 - val_loss: 987.5084\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 808.6381 - val_loss: 921.9637\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 588.7130 - val_loss: 1506.2743\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 855.0010 - val_loss: 841.1703\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 632.7758 - val_loss: 684.9672\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 576.2208 - val_loss: 751.1672\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 506.5857 - val_loss: 934.1273\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 492.1800 - val_loss: 714.2801\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 552.7570 - val_loss: 880.1411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 500.9847 - val_loss: 1310.8259\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 521.0410 - val_loss: 727.0934\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 474.2779 - val_loss: 944.6254\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 509.3203 - val_loss: 990.5581\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 442.7108 - val_loss: 875.2349\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 511.5152 - val_loss: 985.6372\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 623.3780 - val_loss: 776.7415\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 785.1431 - val_loss: 829.0397\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 741.8402 - val_loss: 900.1965\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 646.0196 - val_loss: 736.4482\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 563.6888 - val_loss: 875.6129\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 566.5256 - val_loss: 845.5516\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 564.6652 - val_loss: 1138.8625\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 644.1619 - val_loss: 1037.9480\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 567.0054 - val_loss: 1205.4343\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 530.7213 - val_loss: 929.5883\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 698.9854 - val_loss: 831.6367\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 579.7418 - val_loss: 931.0243\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 687.9932 - val_loss: 1009.2576\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1013.2108 - val_loss: 1012.2532\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 597.1188 - val_loss: 965.6011\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 514.1455 - val_loss: 1028.0289\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 543.3028 - val_loss: 1023.0800\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 462.6235 - val_loss: 1221.0297\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 436.8694 - val_loss: 1256.4181\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 496.6588 - val_loss: 1332.0074\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 568.1973 - val_loss: 1016.4788\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 503.4911 - val_loss: 1299.4493\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 565.7266 - val_loss: 1099.6431\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 501.3230 - val_loss: 1271.5525\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 493.9109 - val_loss: 1071.9275\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 400.4804 - val_loss: 908.0128\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 457.2265 - val_loss: 1245.4387\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 403.6301 - val_loss: 1228.0884\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 423.5902 - val_loss: 1094.7343\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 473.5887 - val_loss: 831.7910\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 695.9670 - val_loss: 1110.4773\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 543.1194 - val_loss: 872.6105\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 628.4016 - val_loss: 983.8829\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 554.7889 - val_loss: 1115.6774\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 566.5615 - val_loss: 1266.9100\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 534.7739 - val_loss: 884.3270\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 590.7678 - val_loss: 1123.2660\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 659.6547 - val_loss: 1045.0409\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 658.0891 - val_loss: 3833.3499\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1259.4109 - val_loss: 1127.2284\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 635.1522 - val_loss: 1186.9781\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 554.3377 - val_loss: 1242.5077\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 787.4287 - val_loss: 834.2060\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 579.2664 - val_loss: 722.6415\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 610.7366 - val_loss: 932.3466\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 668.8251 - val_loss: 876.6488\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 524.5161 - val_loss: 1053.5369\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 541.2270 - val_loss: 923.2809\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 490.4443 - val_loss: 640.1954\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 554.8411 - val_loss: 635.3547\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 594.8395 - val_loss: 784.5079\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 558.1649 - val_loss: 670.4352\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 544.2687 - val_loss: 749.4330\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 424.2935 - val_loss: 721.1291\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 743.3454 - val_loss: 794.3192\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 644.7984 - val_loss: 932.0185\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 597.0756 - val_loss: 1042.3553\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 733.8102 - val_loss: 822.4028\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 689.6064 - val_loss: 1335.2102\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 724.0916 - val_loss: 926.9701\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 587.5170 - val_loss: 928.5859\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 595.5924 - val_loss: 1025.4294\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 555.9807 - val_loss: 1139.0360\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 462.1270 - val_loss: 1011.2812\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 590.0319 - val_loss: 703.5551\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 566.0330 - val_loss: 849.3376\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 550.0451 - val_loss: 1012.0969\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 497.9348 - val_loss: 1012.8924\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 439.1593 - val_loss: 1094.6251\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 451.2310 - val_loss: 1233.7646\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 474.4660 - val_loss: 867.7021\n",
      "Epoch 1006/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 500.2196 - val_loss: 932.0776\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 489.4536 - val_loss: 1390.7094\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 515.0904 - val_loss: 1419.5919\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 588.8121 - val_loss: 1318.6011\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 768.4432 - val_loss: 1171.0454\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 647.7180 - val_loss: 1019.5637\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 692.2153 - val_loss: 966.0377\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 754.2255 - val_loss: 834.5057\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 636.9559 - val_loss: 889.5638\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 661.2719 - val_loss: 904.1968\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 713.1084 - val_loss: 880.4583\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 628.7508 - val_loss: 1263.0206\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 609.2038 - val_loss: 1100.2697\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 564.4736 - val_loss: 743.6940\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 507.3771 - val_loss: 721.2096\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 570.6923 - val_loss: 1130.8628\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 521.0662 - val_loss: 1246.0846\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 555.1664 - val_loss: 990.5258\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 702.3613 - val_loss: 761.7960\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 702.7640 - val_loss: 799.3251\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 755.6285 - val_loss: 1426.1940\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 761.2681 - val_loss: 1265.2977\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 701.0650 - val_loss: 820.6869\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 646.8911 - val_loss: 902.8360\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 730.1380 - val_loss: 917.7377\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 736.7761 - val_loss: 854.9957\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 729.4034 - val_loss: 870.7570\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 786.7069 - val_loss: 716.9414\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 732.3965 - val_loss: 1158.3068\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 706.2510 - val_loss: 845.3870\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 713.5429 - val_loss: 2532.3958\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1007.0861 - val_loss: 1092.9680\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 891.3074 - val_loss: 942.8865\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 959.9778 - val_loss: 2074.6624\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 951.1552 - val_loss: 1227.7869\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 678.5449 - val_loss: 1131.9012\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 596.4070 - val_loss: 1189.5524\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 615.8261 - val_loss: 803.2797\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 508.7735 - val_loss: 991.0191\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 544.4355 - val_loss: 1005.1068\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 555.2664 - val_loss: 848.0894\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 505.8810 - val_loss: 1030.0111\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 494.1620 - val_loss: 1027.2136\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 458.2150 - val_loss: 907.6923\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 497.0075 - val_loss: 837.1697\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 509.3268 - val_loss: 837.3409\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 451.5417 - val_loss: 1202.2415\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 422.5518 - val_loss: 1178.6885\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 439.2065 - val_loss: 1128.6781\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 488.0490 - val_loss: 1069.5297\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 589.0591 - val_loss: 1169.7083\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 509.1021 - val_loss: 901.9391\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 491.1144 - val_loss: 966.8029\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 475.0440 - val_loss: 1023.3578\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 499.5569 - val_loss: 904.7280\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 620.2731 - val_loss: 1291.8202\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 600.9355 - val_loss: 1283.9187\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 572.3248 - val_loss: 1179.3618\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 539.2175 - val_loss: 843.4338\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 582.6782 - val_loss: 990.9666\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 630.0546 - val_loss: 1072.9042\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 588.9496 - val_loss: 1393.6227\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 574.5897 - val_loss: 1080.6327\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 482.6219 - val_loss: 1143.6298\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 571.5110 - val_loss: 814.6615\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 569.4890 - val_loss: 1027.2218\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 547.1674 - val_loss: 1318.1115\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 523.0621 - val_loss: 1123.5680\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 554.9533 - val_loss: 1418.6852\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 648.3325 - val_loss: 1128.1093\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 595.3484 - val_loss: 1009.7629\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 579.7914 - val_loss: 1129.2078\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 640.6033 - val_loss: 1111.5499\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 699.9482 - val_loss: 1017.7186\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 669.9644 - val_loss: 1628.5621\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 723.1736 - val_loss: 1086.5876\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 769.4269 - val_loss: 1012.3951\n",
      "Epoch 1083/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 714.4808 - val_loss: 1267.5438\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 863.3065 - val_loss: 1183.6096\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 821.0215 - val_loss: 1579.4722\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 848.5527 - val_loss: 1021.6116\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 904.8778 - val_loss: 1673.9808\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 853.9161 - val_loss: 1130.1882\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 783.9357 - val_loss: 1304.4878\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 799.6238 - val_loss: 1488.9207\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 797.1768 - val_loss: 1231.0822\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 799.3950 - val_loss: 1143.3782\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 907.5349 - val_loss: 1722.2006\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1114.9387 - val_loss: 2037.1697\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 856.5536 - val_loss: 1733.4470\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 856.6178 - val_loss: 1541.8086\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 872.1274 - val_loss: 1245.6580\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 813.9742 - val_loss: 1440.0216\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 771.7627 - val_loss: 973.1412\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 841.2408 - val_loss: 1924.7266\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 798.5330 - val_loss: 1286.8339\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 710.6182 - val_loss: 1025.2764\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 669.0675 - val_loss: 922.7917\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 591.3672 - val_loss: 895.6636\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 588.2720 - val_loss: 1114.2686\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 603.6898 - val_loss: 1609.9991\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 677.1350 - val_loss: 1188.0272\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 687.3926 - val_loss: 1371.8132\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 642.0011 - val_loss: 1053.8740\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 586.9335 - val_loss: 1400.1138\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 543.3440 - val_loss: 1085.8829\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 489.3662 - val_loss: 1083.9086\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 607.9427 - val_loss: 1085.9567\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 519.2714 - val_loss: 831.7836\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 794.0422 - val_loss: 1221.7106\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 587.0934 - val_loss: 1188.7448\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 681.5634 - val_loss: 790.9605\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 753.4534 - val_loss: 836.5800\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 695.1232 - val_loss: 1206.0253\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 768.4546 - val_loss: 954.0665\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 679.5091 - val_loss: 1097.0986\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 675.1478 - val_loss: 982.6495\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 707.1342 - val_loss: 771.5297\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 647.2172 - val_loss: 1041.5696\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 606.8687 - val_loss: 1184.6353\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 718.9431 - val_loss: 899.1973\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 664.1496 - val_loss: 792.4406\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 700.1218 - val_loss: 569.0434\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 933.3862 - val_loss: 1183.2106\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 951.3905 - val_loss: 1534.6099\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 871.9165 - val_loss: 1094.7545\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 741.6797 - val_loss: 809.5725\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 777.9293 - val_loss: 994.5925\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 745.4074 - val_loss: 955.9451\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 807.8631 - val_loss: 800.4410\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 675.3659 - val_loss: 1175.2885\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 764.7698 - val_loss: 890.1877\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 604.4807 - val_loss: 1146.9730\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 598.4701 - val_loss: 1214.5984\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 630.5281 - val_loss: 1763.8407\n",
      "Epoch 1141/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 800.7007 - val_loss: 1303.9337\n",
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 770.0309 - val_loss: 944.0403\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 727.7556 - val_loss: 805.8394\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 748.0889 - val_loss: 909.7521\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 616.9797 - val_loss: 889.6119\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 609.0493 - val_loss: 808.9532\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 662.0636 - val_loss: 1282.0905\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 681.9683 - val_loss: 869.1549\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 675.7846 - val_loss: 658.0889\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 584.6533 - val_loss: 682.9888\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 593.2584 - val_loss: 1398.2168\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 608.3826 - val_loss: 874.0997\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 628.2524 - val_loss: 869.6492\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 590.4858 - val_loss: 808.1858\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 571.6650 - val_loss: 1055.3894\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 611.2466 - val_loss: 1270.5248\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 708.4666 - val_loss: 1245.0392\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 696.1111 - val_loss: 1202.2833\n",
      "Epoch 1159/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 595.0594 - val_loss: 1184.8842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1160/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 689.4800 - val_loss: 934.9049\n",
      "Epoch 1161/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 513.6436 - val_loss: 1627.0942\n",
      "Epoch 1162/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 586.0114 - val_loss: 1590.6320\n",
      "Epoch 1163/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 571.3187 - val_loss: 1177.6497\n",
      "Epoch 1164/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 561.4370 - val_loss: 842.3785\n",
      "Epoch 1165/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 602.0872 - val_loss: 1105.3777\n",
      "Epoch 1166/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 689.8775 - val_loss: 1138.1012\n",
      "Epoch 1167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 550.2679 - val_loss: 1177.1516\n",
      "Epoch 1168/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 564.0504 - val_loss: 1028.2202\n",
      "Epoch 1169/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 476.3232 - val_loss: 1673.7574\n",
      "Epoch 1170/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 873.6675 - val_loss: 1279.0802\n",
      "Epoch 1171/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 672.3645 - val_loss: 1378.6290\n",
      "Epoch 1172/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 571.8411 - val_loss: 1181.1982\n",
      "Epoch 1173/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 507.1647 - val_loss: 1296.7614\n",
      "Epoch 1174/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 574.0044 - val_loss: 1260.2008\n",
      "Epoch 1175/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 457.6934 - val_loss: 1155.3528\n",
      "Epoch 1176/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 470.2857 - val_loss: 1141.5164\n",
      "Epoch 1177/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 613.6791 - val_loss: 1249.0822\n",
      "Epoch 1178/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 552.3557 - val_loss: 1511.1952\n",
      "Epoch 1179/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 720.6945 - val_loss: 974.8681\n",
      "Epoch 1180/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 691.8917 - val_loss: 904.5353\n",
      "Epoch 1181/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 559.7866 - val_loss: 814.9468\n",
      "Epoch 1182/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 688.1707 - val_loss: 966.1423\n",
      "Epoch 1183/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 773.9928 - val_loss: 735.4431\n",
      "Epoch 1184/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 903.6203 - val_loss: 1073.3994\n",
      "Epoch 1185/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 891.7455 - val_loss: 836.5187\n",
      "Epoch 1186/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 729.4206 - val_loss: 782.7332\n",
      "Epoch 1187/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 670.8494 - val_loss: 732.6767\n",
      "Epoch 1188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1042.0137 - val_loss: 753.0758\n",
      "Epoch 1189/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 721.1213 - val_loss: 832.2637\n",
      "Epoch 1190/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 710.1412 - val_loss: 868.7012\n",
      "Epoch 1191/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 594.8353 - val_loss: 1099.6536\n",
      "Epoch 1192/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 611.9340 - val_loss: 1032.3428\n",
      "Epoch 1193/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 557.1382 - val_loss: 1095.3069\n",
      "Epoch 1194/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 563.0515 - val_loss: 901.6158\n",
      "Epoch 1195/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 637.4276 - val_loss: 1463.3096\n",
      "Epoch 1196/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 738.9129 - val_loss: 934.5676\n",
      "Epoch 1197/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 617.5895 - val_loss: 1233.8751\n",
      "Epoch 1198/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 677.7953 - val_loss: 988.2995\n",
      "Epoch 1199/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 576.9245 - val_loss: 1760.3905\n",
      "Epoch 1200/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 694.3513 - val_loss: 797.9299\n",
      "Epoch 1201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 590.0799 - val_loss: 849.9288\n",
      "Epoch 1202/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 639.8583 - val_loss: 1151.4514\n",
      "Epoch 1203/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 776.4897 - val_loss: 786.8997\n",
      "Epoch 1204/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 832.4172 - val_loss: 693.3787\n",
      "Epoch 1205/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 825.3958 - val_loss: 882.6847\n",
      "Epoch 1206/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 724.6584 - val_loss: 976.8644\n",
      "Epoch 1207/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 734.5596 - val_loss: 806.8147\n",
      "Epoch 1208/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 647.3036 - val_loss: 1041.3672\n",
      "Epoch 1209/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 796.1654 - val_loss: 1523.3832\n",
      "Epoch 1210/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 520.1763 - val_loss: 1379.4979\n",
      "Epoch 1211/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 474.9731 - val_loss: 1237.0836\n",
      "Epoch 1212/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 504.7309 - val_loss: 983.3658\n",
      "Epoch 1213/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 647.0793 - val_loss: 1347.0940\n",
      "Epoch 1214/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 761.7413 - val_loss: 1912.3531\n",
      "Epoch 1215/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1174.2747 - val_loss: 1150.3672\n",
      "Epoch 1216/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 840.4965 - val_loss: 1284.0811\n",
      "Epoch 1217/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 781.2352 - val_loss: 1420.3672\n",
      "Epoch 1218/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 701.1002 - val_loss: 1119.1383\n",
      "Epoch 1219/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 623.7209 - val_loss: 1038.4268\n",
      "Epoch 1220/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 640.9711 - val_loss: 1236.9215\n",
      "Epoch 1221/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 588.7410 - val_loss: 1372.5448\n",
      "Epoch 1222/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 560.2079 - val_loss: 929.3809\n",
      "Epoch 1223/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 526.6757 - val_loss: 934.6968\n",
      "Epoch 1224/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 411.3096 - val_loss: 1330.4404\n",
      "Epoch 1225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 406.3787 - val_loss: 979.4761\n",
      "Epoch 1226/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 407.4921 - val_loss: 807.3926\n",
      "Epoch 1227/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 473.1546 - val_loss: 766.2576\n",
      "Epoch 1228/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 524.4414 - val_loss: 807.6039\n",
      "Epoch 1229/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 507.1581 - val_loss: 935.7563\n",
      "Epoch 1230/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 528.9111 - val_loss: 1288.2996\n",
      "Epoch 1231/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 571.3071 - val_loss: 1510.8871\n",
      "Epoch 1232/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 777.1144 - val_loss: 632.8417\n",
      "Epoch 1233/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 777.6945 - val_loss: 1990.2617\n",
      "Epoch 1234/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 640.1179 - val_loss: 2555.2004\n",
      "Epoch 1235/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 936.2462 - val_loss: 1085.5764\n",
      "Epoch 1236/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 850.2426 - val_loss: 886.0067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1237/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 609.2137 - val_loss: 1248.2114\n",
      "Epoch 1238/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 746.3013 - val_loss: 1190.8461\n",
      "Epoch 1239/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 603.6655 - val_loss: 1036.4572\n",
      "Epoch 1240/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 506.4192 - val_loss: 1092.4352\n",
      "Epoch 1241/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 504.7831 - val_loss: 1155.1891\n",
      "Epoch 1242/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 504.5628 - val_loss: 999.8126\n",
      "Epoch 1243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 440.7171 - val_loss: 921.9292\n",
      "Epoch 1244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 647.3358 - val_loss: 2154.2290\n",
      "Epoch 1245/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 835.5169 - val_loss: 1424.5056\n",
      "Epoch 1246/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 589.4358 - val_loss: 904.4657\n",
      "Epoch 1247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 616.2838 - val_loss: 1008.0350\n",
      "Epoch 1248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 517.0388 - val_loss: 1008.9908\n",
      "Epoch 1249/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 624.2932 - val_loss: 903.3755\n",
      "Epoch 1250/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 781.7324 - val_loss: 1156.8525\n",
      "Epoch 1251/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 567.7716 - val_loss: 914.7407\n",
      "Epoch 1252/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 495.9578 - val_loss: 1432.8030\n",
      "Epoch 1253/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 467.5005 - val_loss: 1591.2809\n",
      "Epoch 1254/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 429.2702 - val_loss: 1516.8693\n",
      "Epoch 1255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 405.2233 - val_loss: 822.6454\n",
      "Epoch 1256/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 426.3727 - val_loss: 1187.2485\n",
      "Epoch 1257/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 440.8553 - val_loss: 1134.2704\n",
      "Epoch 1258/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 376.4467 - val_loss: 890.1135\n",
      "Epoch 1259/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 460.3605 - val_loss: 1243.3380\n",
      "Epoch 1260/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 531.9799 - val_loss: 1247.0703\n",
      "Epoch 1261/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 445.4516 - val_loss: 1186.7640\n",
      "Epoch 1262/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 516.3910 - val_loss: 948.9366\n",
      "Epoch 1263/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 560.2028 - val_loss: 1349.4431\n",
      "Epoch 1264/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 532.9664 - val_loss: 1128.2141\n",
      "Epoch 1265/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 452.5811 - val_loss: 1098.6510\n",
      "Epoch 1266/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 393.5680 - val_loss: 929.3913\n",
      "Epoch 1267/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 455.7318 - val_loss: 1085.2627\n",
      "Epoch 1268/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 465.8265 - val_loss: 872.6432\n",
      "Epoch 1269/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 461.2192 - val_loss: 944.0801\n",
      "Epoch 1270/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 558.0729 - val_loss: 1406.2574\n",
      "Epoch 1271/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 494.9219 - val_loss: 1328.4490\n",
      "Epoch 1272/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 428.7370 - val_loss: 1342.3796\n",
      "Epoch 1273/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 467.9502 - val_loss: 1520.9170\n",
      "Epoch 1274/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 482.9604 - val_loss: 1111.6195\n",
      "Epoch 1275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 507.8066 - val_loss: 1111.0232\n",
      "Epoch 1276/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 645.9073Restoring model weights from the end of the best epoch: 776.\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 460.8112 - val_loss: 1036.7018\n",
      "Epoch 1276: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086426</td>\n",
       "      <td>313.086395</td>\n",
       "      <td>313.085632</td>\n",
       "      <td>312.241791</td>\n",
       "      <td>266.991028</td>\n",
       "      <td>266.982117</td>\n",
       "      <td>266.795868</td>\n",
       "      <td>303.509491</td>\n",
       "      <td>312.49646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>354.558</td>\n",
       "      <td>360.106</td>\n",
       "      <td>350.123</td>\n",
       "      <td>288.254</td>\n",
       "      <td>301.687</td>\n",
       "      <td>268.901</td>\n",
       "      <td>274.431</td>\n",
       "      <td>298.219</td>\n",
       "      <td>328.955</td>\n",
       "      <td>335.039</td>\n",
       "      <td>260.723</td>\n",
       "      <td>366.929</td>\n",
       "      <td>353.426</td>\n",
       "      <td>344.937</td>\n",
       "      <td>302.082</td>\n",
       "      <td>294.467</td>\n",
       "      <td>336.029</td>\n",
       "      <td>278.117</td>\n",
       "      <td>323.005</td>\n",
       "      <td>291.453</td>\n",
       "      <td>300.203</td>\n",
       "      <td>317.058</td>\n",
       "      <td>314.142</td>\n",
       "      <td>301.878</td>\n",
       "      <td>358.797</td>\n",
       "      <td>356.169</td>\n",
       "      <td>316.188</td>\n",
       "      <td>346.214</td>\n",
       "      <td>323.401</td>\n",
       "      <td>238.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>41.471588</td>\n",
       "      <td>47.019562</td>\n",
       "      <td>37.03656</td>\n",
       "      <td>24.832428</td>\n",
       "      <td>11.399414</td>\n",
       "      <td>44.185425</td>\n",
       "      <td>38.655426</td>\n",
       "      <td>14.867432</td>\n",
       "      <td>15.868561</td>\n",
       "      <td>21.952576</td>\n",
       "      <td>52.363434</td>\n",
       "      <td>53.84256</td>\n",
       "      <td>40.339569</td>\n",
       "      <td>31.850586</td>\n",
       "      <td>11.004425</td>\n",
       "      <td>18.619415</td>\n",
       "      <td>22.942566</td>\n",
       "      <td>34.969421</td>\n",
       "      <td>9.918579</td>\n",
       "      <td>21.633423</td>\n",
       "      <td>12.883423</td>\n",
       "      <td>3.971588</td>\n",
       "      <td>1.055603</td>\n",
       "      <td>11.207642</td>\n",
       "      <td>46.555206</td>\n",
       "      <td>89.177979</td>\n",
       "      <td>49.205872</td>\n",
       "      <td>79.418121</td>\n",
       "      <td>19.89151</td>\n",
       "      <td>74.030457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1           2           3           4   \\\n",
       "Month          Month-1     Month-2     Month-3     Month-4     Month-5   \n",
       "Prediction  313.086426  313.086426  313.086426  313.086426  313.086426   \n",
       "Target         354.558     360.106     350.123     288.254     301.687   \n",
       "Error        41.471588   47.019562    37.03656   24.832428   11.399414   \n",
       "\n",
       "                    5           6           7           8           9   \\\n",
       "Month          Month-6     Month-7     Month-8     Month-9    Month-10   \n",
       "Prediction  313.086426  313.086426  313.086426  313.086426  313.086426   \n",
       "Target         268.901     274.431     298.219     328.955     335.039   \n",
       "Error        44.185425   38.655426   14.867432   15.868561   21.952576   \n",
       "\n",
       "                    10          11          12          13          14  \\\n",
       "Month         Month-11    Month-12    Month-13    Month-14    Month-15   \n",
       "Prediction  313.086426  313.086426  313.086426  313.086426  313.086426   \n",
       "Target         260.723     366.929     353.426     344.937     302.082   \n",
       "Error        52.363434    53.84256   40.339569   31.850586   11.004425   \n",
       "\n",
       "                    15          16          17          18          19  \\\n",
       "Month         Month-16    Month-17    Month-18    Month-19    Month-20   \n",
       "Prediction  313.086426  313.086426  313.086426  313.086426  313.086426   \n",
       "Target         294.467     336.029     278.117     323.005     291.453   \n",
       "Error        18.619415   22.942566   34.969421    9.918579   21.633423   \n",
       "\n",
       "                    20          21          22          23          24  \\\n",
       "Month         Month-21    Month-22    Month-23    Month-24    Month-25   \n",
       "Prediction  313.086426  313.086426  313.086395  313.085632  312.241791   \n",
       "Target         300.203     317.058     314.142     301.878     358.797   \n",
       "Error        12.883423    3.971588    1.055603   11.207642   46.555206   \n",
       "\n",
       "                    25          26          27          28         29  \n",
       "Month         Month-26    Month-27    Month-28    Month-29   Month-30  \n",
       "Prediction  266.991028  266.982117  266.795868  303.509491  312.49646  \n",
       "Target         356.169     316.188     346.214     323.401    238.466  \n",
       "Error        89.177979   49.205872   79.418121    19.89151  74.030457  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.73901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.104391016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Ano-0: |Prediction[[3757.037]] - Target[3787.925]| =  Error: [[30.88794]]; MAPE:[[0.00815432]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Ano-0: |Prediction[[3757.0364]] - Target[3756.797]| =  Error: [[0.23925781]]; MAPE:[[6.3686646e-05]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-5: |Prediction[[1729.0167]] - Target[1939.2350000000001]| =  Error: [[210.21826]]; MAPE:[[0.10840268]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[30.88794]], dtype=float32),\n",
       " array([[0.23925781]], dtype=float32),\n",
       " array([[210.21826]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "80.44849"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.03887356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
