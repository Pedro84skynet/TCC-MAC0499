{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Amazonas - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Amazonas - IDH</th>\n",
       "      <th>Amazonas - value</th>\n",
       "      <th>Amazonas - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Amazonas - Produção de Cimento (t)</th>\n",
       "      <th>Amazonas - PIB - Estadual</th>\n",
       "      <th>Amazonas - PIB - Construção Civil</th>\n",
       "      <th>Amazonas - PIB - Per Capita</th>\n",
       "      <th>Amazonas - PIB - Preços de Mercado</th>\n",
       "      <th>Amazonas - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.695898</td>\n",
       "      <td>0.330279</td>\n",
       "      <td>8.630942</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>51.313080</td>\n",
       "      <td>4.754469e+07</td>\n",
       "      <td>2.519796e+06</td>\n",
       "      <td>12.490621</td>\n",
       "      <td>4.318518e+07</td>\n",
       "      <td>28.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.696043</td>\n",
       "      <td>0.331137</td>\n",
       "      <td>8.624872</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>51.554195</td>\n",
       "      <td>4.760190e+07</td>\n",
       "      <td>2.521321e+06</td>\n",
       "      <td>12.492164</td>\n",
       "      <td>4.320154e+07</td>\n",
       "      <td>31.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.696187</td>\n",
       "      <td>0.331306</td>\n",
       "      <td>8.618803</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>51.523306</td>\n",
       "      <td>4.765911e+07</td>\n",
       "      <td>2.522846e+06</td>\n",
       "      <td>12.493707</td>\n",
       "      <td>4.321789e+07</td>\n",
       "      <td>33.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.696332</td>\n",
       "      <td>0.331791</td>\n",
       "      <td>8.612734</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>51.639628</td>\n",
       "      <td>4.771632e+07</td>\n",
       "      <td>2.524370e+06</td>\n",
       "      <td>12.495250</td>\n",
       "      <td>4.323425e+07</td>\n",
       "      <td>31.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.696476</td>\n",
       "      <td>0.332189</td>\n",
       "      <td>8.606665</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>51.838456</td>\n",
       "      <td>4.777353e+07</td>\n",
       "      <td>2.525895e+06</td>\n",
       "      <td>12.496793</td>\n",
       "      <td>4.325060e+07</td>\n",
       "      <td>32.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.352061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.160630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.937187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.889598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.992030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Amazonas - IDH  Amazonas - value  Amazonas - Desemprego  \\\n",
       "0       2003-1        0.695898          0.330279               8.630942   \n",
       "1       2003-2        0.696043          0.331137               8.624872   \n",
       "2       2003-3        0.696187          0.331306               8.618803   \n",
       "3       2003-4        0.696332          0.331791               8.612734   \n",
       "4       2003-5        0.696476          0.332189               8.606665   \n",
       "..         ...             ...               ...                    ...   \n",
       "235     2022-8             NaN          0.746275                    NaN   \n",
       "236     2022-9             NaN          0.746582                    NaN   \n",
       "237    2022-10             NaN          0.745406                    NaN   \n",
       "238    2022-11             NaN          0.742703                    NaN   \n",
       "239    2022-12             NaN          0.737846                    NaN   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     Amazonas - Produção de Cimento (t)  Amazonas - PIB - Estadual  \\\n",
       "0                             51.313080               4.754469e+07   \n",
       "1                             51.554195               4.760190e+07   \n",
       "2                             51.523306               4.765911e+07   \n",
       "3                             51.639628               4.771632e+07   \n",
       "4                             51.838456               4.777353e+07   \n",
       "..                                  ...                        ...   \n",
       "235                           39.352061                        NaN   \n",
       "236                           39.160630                        NaN   \n",
       "237                           38.937187                        NaN   \n",
       "238                           38.889598                        NaN   \n",
       "239                           38.992030                        NaN   \n",
       "\n",
       "     Amazonas - PIB - Construção Civil  Amazonas - PIB - Per Capita  \\\n",
       "0                         2.519796e+06                    12.490621   \n",
       "1                         2.521321e+06                    12.492164   \n",
       "2                         2.522846e+06                    12.493707   \n",
       "3                         2.524370e+06                    12.495250   \n",
       "4                         2.525895e+06                    12.496793   \n",
       "..                                 ...                          ...   \n",
       "235                                NaN                          NaN   \n",
       "236                                NaN                          NaN   \n",
       "237                                NaN                          NaN   \n",
       "238                                NaN                          NaN   \n",
       "239                                NaN                          NaN   \n",
       "\n",
       "     Amazonas - PIB - Preços de Mercado  Amazonas - Consumo de Cimento (t)  \n",
       "0                          4.318518e+07                             28.193  \n",
       "1                          4.320154e+07                             31.226  \n",
       "2                          4.321789e+07                             33.484  \n",
       "3                          4.323425e+07                             31.596  \n",
       "4                          4.325060e+07                             32.919  \n",
       "..                                  ...                                ...  \n",
       "235                                 NaN                             66.077  \n",
       "236                                 NaN                             58.590  \n",
       "237                                 NaN                             58.793  \n",
       "238                                 NaN                             53.509  \n",
       "239                                 NaN                             53.509  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_AM.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amazonas - IDH</th>\n",
       "      <th>Amazonas - value</th>\n",
       "      <th>Amazonas - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Amazonas - Produção de Cimento (t)</th>\n",
       "      <th>Amazonas - PIB - Estadual</th>\n",
       "      <th>Amazonas - PIB - Construção Civil</th>\n",
       "      <th>Amazonas - PIB - Per Capita</th>\n",
       "      <th>Amazonas - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.017357</td>\n",
       "      <td>-1.841109</td>\n",
       "      <td>-0.841381</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-0.246822</td>\n",
       "      <td>-1.725325</td>\n",
       "      <td>0.115495</td>\n",
       "      <td>1.032096</td>\n",
       "      <td>-1.955531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.988164</td>\n",
       "      <td>-1.831498</td>\n",
       "      <td>-0.844328</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-0.217639</td>\n",
       "      <td>-1.704856</td>\n",
       "      <td>0.145069</td>\n",
       "      <td>1.057757</td>\n",
       "      <td>-1.907364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.958970</td>\n",
       "      <td>-1.829607</td>\n",
       "      <td>-0.847276</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-0.221378</td>\n",
       "      <td>-1.684387</td>\n",
       "      <td>0.174644</td>\n",
       "      <td>1.083417</td>\n",
       "      <td>-1.859197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.929776</td>\n",
       "      <td>-1.824180</td>\n",
       "      <td>-0.850223</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-0.207299</td>\n",
       "      <td>-1.663918</td>\n",
       "      <td>0.204218</td>\n",
       "      <td>1.109077</td>\n",
       "      <td>-1.811030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.900583</td>\n",
       "      <td>-1.819720</td>\n",
       "      <td>-0.853171</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-0.183234</td>\n",
       "      <td>-1.643449</td>\n",
       "      <td>0.233793</td>\n",
       "      <td>1.134738</td>\n",
       "      <td>-1.762863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.146285</td>\n",
       "      <td>0.624622</td>\n",
       "      <td>1.092028</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-2.063199</td>\n",
       "      <td>1.193835</td>\n",
       "      <td>-1.214518</td>\n",
       "      <td>-0.726615</td>\n",
       "      <td>1.324047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.136919</td>\n",
       "      <td>0.664868</td>\n",
       "      <td>1.088543</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>-2.019550</td>\n",
       "      <td>1.186279</td>\n",
       "      <td>-1.186673</td>\n",
       "      <td>-0.718777</td>\n",
       "      <td>1.320189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.127552</td>\n",
       "      <td>0.713988</td>\n",
       "      <td>1.085058</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>-1.981485</td>\n",
       "      <td>1.178724</td>\n",
       "      <td>-1.158827</td>\n",
       "      <td>-0.710938</td>\n",
       "      <td>1.316331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.118186</td>\n",
       "      <td>0.765366</td>\n",
       "      <td>1.081573</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-1.940641</td>\n",
       "      <td>1.171169</td>\n",
       "      <td>-1.130982</td>\n",
       "      <td>-0.703100</td>\n",
       "      <td>1.312472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.108819</td>\n",
       "      <td>0.819755</td>\n",
       "      <td>1.078088</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-1.925398</td>\n",
       "      <td>1.163614</td>\n",
       "      <td>-1.103136</td>\n",
       "      <td>-0.695262</td>\n",
       "      <td>1.308614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Amazonas - IDH  Amazonas - value  Amazonas - Desemprego  \\\n",
       "0         -2.017357         -1.841109              -0.841381   \n",
       "1         -1.988164         -1.831498              -0.844328   \n",
       "2         -1.958970         -1.829607              -0.847276   \n",
       "3         -1.929776         -1.824180              -0.850223   \n",
       "4         -1.900583         -1.819720              -0.853171   \n",
       "..              ...               ...                    ...   \n",
       "187        1.146285          0.624622               1.092028   \n",
       "188        1.136919          0.664868               1.088543   \n",
       "189        1.127552          0.713988               1.085058   \n",
       "190        1.118186          0.765366               1.081573   \n",
       "191        1.108819          0.819755               1.078088   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Amazonas - Produção de Cimento (t)  Amazonas - PIB - Estadual  \\\n",
       "0                             -0.246822                  -1.725325   \n",
       "1                             -0.217639                  -1.704856   \n",
       "2                             -0.221378                  -1.684387   \n",
       "3                             -0.207299                  -1.663918   \n",
       "4                             -0.183234                  -1.643449   \n",
       "..                                  ...                        ...   \n",
       "187                           -2.063199                   1.193835   \n",
       "188                           -2.019550                   1.186279   \n",
       "189                           -1.981485                   1.178724   \n",
       "190                           -1.940641                   1.171169   \n",
       "191                           -1.925398                   1.163614   \n",
       "\n",
       "     Amazonas - PIB - Construção Civil  Amazonas - PIB - Per Capita  \\\n",
       "0                             0.115495                     1.032096   \n",
       "1                             0.145069                     1.057757   \n",
       "2                             0.174644                     1.083417   \n",
       "3                             0.204218                     1.109077   \n",
       "4                             0.233793                     1.134738   \n",
       "..                                 ...                          ...   \n",
       "187                          -1.214518                    -0.726615   \n",
       "188                          -1.186673                    -0.718777   \n",
       "189                          -1.158827                    -0.710938   \n",
       "190                          -1.130982                    -0.703100   \n",
       "191                          -1.103136                    -0.695262   \n",
       "\n",
       "     Amazonas - PIB - Preços de Mercado  \n",
       "0                             -1.955531  \n",
       "1                             -1.907364  \n",
       "2                             -1.859197  \n",
       "3                             -1.811030  \n",
       "4                             -1.762863  \n",
       "..                                  ...  \n",
       "187                            1.324047  \n",
       "188                            1.320189  \n",
       "189                            1.316331  \n",
       "190                            1.312472  \n",
       "191                            1.308614  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      34.293\n",
       "1      48.623\n",
       "2      34.555\n",
       "3      57.805\n",
       "4      39.036\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Amazonas - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amazonas - IDH</th>\n",
       "      <th>Amazonas - value</th>\n",
       "      <th>Amazonas - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Amazonas - Produção de Cimento (t)</th>\n",
       "      <th>Amazonas - PIB - Estadual</th>\n",
       "      <th>Amazonas - PIB - Construção Civil</th>\n",
       "      <th>Amazonas - PIB - Per Capita</th>\n",
       "      <th>Amazonas - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.017357</td>\n",
       "      <td>-1.841109</td>\n",
       "      <td>-0.841381</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-0.246822</td>\n",
       "      <td>-1.725325</td>\n",
       "      <td>0.115495</td>\n",
       "      <td>1.032096</td>\n",
       "      <td>-1.955531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.988164</td>\n",
       "      <td>-1.831498</td>\n",
       "      <td>-0.844328</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-0.217639</td>\n",
       "      <td>-1.704856</td>\n",
       "      <td>0.145069</td>\n",
       "      <td>1.057757</td>\n",
       "      <td>-1.907364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.958970</td>\n",
       "      <td>-1.829607</td>\n",
       "      <td>-0.847276</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-0.221378</td>\n",
       "      <td>-1.684387</td>\n",
       "      <td>0.174644</td>\n",
       "      <td>1.083417</td>\n",
       "      <td>-1.859197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.929776</td>\n",
       "      <td>-1.824180</td>\n",
       "      <td>-0.850223</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-0.207299</td>\n",
       "      <td>-1.663918</td>\n",
       "      <td>0.204218</td>\n",
       "      <td>1.109077</td>\n",
       "      <td>-1.811030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.900583</td>\n",
       "      <td>-1.819720</td>\n",
       "      <td>-0.853171</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-0.183234</td>\n",
       "      <td>-1.643449</td>\n",
       "      <td>0.233793</td>\n",
       "      <td>1.134738</td>\n",
       "      <td>-1.762863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.448925</td>\n",
       "      <td>0.452650</td>\n",
       "      <td>1.390527</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>-0.823205</td>\n",
       "      <td>1.169567</td>\n",
       "      <td>-1.503954</td>\n",
       "      <td>-1.462487</td>\n",
       "      <td>0.955680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.452046</td>\n",
       "      <td>0.404414</td>\n",
       "      <td>1.372620</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>-0.905554</td>\n",
       "      <td>1.175278</td>\n",
       "      <td>-1.511151</td>\n",
       "      <td>-1.435811</td>\n",
       "      <td>0.975593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.455166</td>\n",
       "      <td>0.365711</td>\n",
       "      <td>1.354712</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>-0.983877</td>\n",
       "      <td>1.180989</td>\n",
       "      <td>-1.518349</td>\n",
       "      <td>-1.409135</td>\n",
       "      <td>0.995507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.458287</td>\n",
       "      <td>0.316318</td>\n",
       "      <td>1.336804</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>-1.057189</td>\n",
       "      <td>1.186700</td>\n",
       "      <td>-1.525547</td>\n",
       "      <td>-1.382459</td>\n",
       "      <td>1.015420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.461408</td>\n",
       "      <td>0.264545</td>\n",
       "      <td>1.318896</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>-1.126731</td>\n",
       "      <td>1.192411</td>\n",
       "      <td>-1.532745</td>\n",
       "      <td>-1.355783</td>\n",
       "      <td>1.035333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Amazonas - IDH  Amazonas - value  Amazonas - Desemprego  \\\n",
       "0         -2.017357         -1.841109              -0.841381   \n",
       "1         -1.988164         -1.831498              -0.844328   \n",
       "2         -1.958970         -1.829607              -0.847276   \n",
       "3         -1.929776         -1.824180              -0.850223   \n",
       "4         -1.900583         -1.819720              -0.853171   \n",
       "..              ...               ...                    ...   \n",
       "157        1.448925          0.452650               1.390527   \n",
       "158        1.452046          0.404414               1.372620   \n",
       "159        1.455166          0.365711               1.354712   \n",
       "160        1.458287          0.316318               1.336804   \n",
       "161        1.461408          0.264545               1.318896   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     Amazonas - Produção de Cimento (t)  Amazonas - PIB - Estadual  \\\n",
       "0                             -0.246822                  -1.725325   \n",
       "1                             -0.217639                  -1.704856   \n",
       "2                             -0.221378                  -1.684387   \n",
       "3                             -0.207299                  -1.663918   \n",
       "4                             -0.183234                  -1.643449   \n",
       "..                                  ...                        ...   \n",
       "157                           -0.823205                   1.169567   \n",
       "158                           -0.905554                   1.175278   \n",
       "159                           -0.983877                   1.180989   \n",
       "160                           -1.057189                   1.186700   \n",
       "161                           -1.126731                   1.192411   \n",
       "\n",
       "     Amazonas - PIB - Construção Civil  Amazonas - PIB - Per Capita  \\\n",
       "0                             0.115495                     1.032096   \n",
       "1                             0.145069                     1.057757   \n",
       "2                             0.174644                     1.083417   \n",
       "3                             0.204218                     1.109077   \n",
       "4                             0.233793                     1.134738   \n",
       "..                                 ...                          ...   \n",
       "157                          -1.503954                    -1.462487   \n",
       "158                          -1.511151                    -1.435811   \n",
       "159                          -1.518349                    -1.409135   \n",
       "160                          -1.525547                    -1.382459   \n",
       "161                          -1.532745                    -1.355783   \n",
       "\n",
       "     Amazonas - PIB - Preços de Mercado  \n",
       "0                             -1.955531  \n",
       "1                             -1.907364  \n",
       "2                             -1.859197  \n",
       "3                             -1.811030  \n",
       "4                             -1.762863  \n",
       "..                                  ...  \n",
       "157                            0.955680  \n",
       "158                            0.975593  \n",
       "159                            0.995507  \n",
       "160                            1.015420  \n",
       "161                            1.035333  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      34.293\n",
       "1      48.623\n",
       "2      34.555\n",
       "3      57.805\n",
       "4      39.036\n",
       "        ...  \n",
       "157    44.068\n",
       "158    62.847\n",
       "159    30.374\n",
       "160    60.003\n",
       "161    81.014\n",
       "Name: Amazonas - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amazonas - IDH</th>\n",
       "      <th>Amazonas - value</th>\n",
       "      <th>Amazonas - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Amazonas - Produção de Cimento (t)</th>\n",
       "      <th>Amazonas - PIB - Estadual</th>\n",
       "      <th>Amazonas - PIB - Construção Civil</th>\n",
       "      <th>Amazonas - PIB - Per Capita</th>\n",
       "      <th>Amazonas - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.464528</td>\n",
       "      <td>0.300771</td>\n",
       "      <td>1.300989</td>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>-1.196117</td>\n",
       "      <td>1.198122</td>\n",
       "      <td>-1.539943</td>\n",
       "      <td>-1.329107</td>\n",
       "      <td>1.055246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.467649</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>1.283081</td>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>-1.258972</td>\n",
       "      <td>1.203832</td>\n",
       "      <td>-1.547140</td>\n",
       "      <td>-1.302431</td>\n",
       "      <td>1.075160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.470769</td>\n",
       "      <td>0.311080</td>\n",
       "      <td>1.265173</td>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>-1.316525</td>\n",
       "      <td>1.209543</td>\n",
       "      <td>-1.554338</td>\n",
       "      <td>-1.275755</td>\n",
       "      <td>1.095073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.473890</td>\n",
       "      <td>0.323489</td>\n",
       "      <td>1.247265</td>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>-1.376631</td>\n",
       "      <td>1.215254</td>\n",
       "      <td>-1.561536</td>\n",
       "      <td>-1.249079</td>\n",
       "      <td>1.114986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.477010</td>\n",
       "      <td>0.339232</td>\n",
       "      <td>1.229358</td>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>-1.427803</td>\n",
       "      <td>1.220965</td>\n",
       "      <td>-1.568734</td>\n",
       "      <td>-1.222403</td>\n",
       "      <td>1.134899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.480131</td>\n",
       "      <td>0.356121</td>\n",
       "      <td>1.211450</td>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>-1.492489</td>\n",
       "      <td>1.226676</td>\n",
       "      <td>-1.575932</td>\n",
       "      <td>-1.195727</td>\n",
       "      <td>1.154813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.483251</td>\n",
       "      <td>0.375580</td>\n",
       "      <td>1.193542</td>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>-1.557787</td>\n",
       "      <td>1.232387</td>\n",
       "      <td>-1.583129</td>\n",
       "      <td>-1.169051</td>\n",
       "      <td>1.174726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.460634</td>\n",
       "      <td>0.394947</td>\n",
       "      <td>1.187115</td>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>-1.627941</td>\n",
       "      <td>1.233581</td>\n",
       "      <td>-1.568655</td>\n",
       "      <td>-1.136753</td>\n",
       "      <td>1.189420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.438018</td>\n",
       "      <td>0.409500</td>\n",
       "      <td>1.180689</td>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>-1.689803</td>\n",
       "      <td>1.234776</td>\n",
       "      <td>-1.554180</td>\n",
       "      <td>-1.104456</td>\n",
       "      <td>1.204114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.415401</td>\n",
       "      <td>0.414230</td>\n",
       "      <td>1.174262</td>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>-1.759409</td>\n",
       "      <td>1.235970</td>\n",
       "      <td>-1.539706</td>\n",
       "      <td>-1.072159</td>\n",
       "      <td>1.218808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.392784</td>\n",
       "      <td>0.425733</td>\n",
       "      <td>1.167835</td>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>-1.823897</td>\n",
       "      <td>1.237165</td>\n",
       "      <td>-1.525232</td>\n",
       "      <td>-1.039861</td>\n",
       "      <td>1.233502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.370167</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>1.161409</td>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>-1.897918</td>\n",
       "      <td>1.238360</td>\n",
       "      <td>-1.510757</td>\n",
       "      <td>-1.007564</td>\n",
       "      <td>1.248196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.347550</td>\n",
       "      <td>0.452423</td>\n",
       "      <td>1.154982</td>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>-1.975283</td>\n",
       "      <td>1.239554</td>\n",
       "      <td>-1.496283</td>\n",
       "      <td>-0.975266</td>\n",
       "      <td>1.262890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.324934</td>\n",
       "      <td>0.467714</td>\n",
       "      <td>1.148555</td>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>-2.041256</td>\n",
       "      <td>1.240749</td>\n",
       "      <td>-1.481808</td>\n",
       "      <td>-0.942969</td>\n",
       "      <td>1.277585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.302317</td>\n",
       "      <td>0.484392</td>\n",
       "      <td>1.142129</td>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>-2.121341</td>\n",
       "      <td>1.241944</td>\n",
       "      <td>-1.467334</td>\n",
       "      <td>-0.910672</td>\n",
       "      <td>1.292279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.279700</td>\n",
       "      <td>0.503077</td>\n",
       "      <td>1.135702</td>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>-2.192006</td>\n",
       "      <td>1.243138</td>\n",
       "      <td>-1.452860</td>\n",
       "      <td>-0.878374</td>\n",
       "      <td>1.306973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.257083</td>\n",
       "      <td>0.509446</td>\n",
       "      <td>1.129275</td>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>-2.265925</td>\n",
       "      <td>1.244333</td>\n",
       "      <td>-1.438385</td>\n",
       "      <td>-0.846077</td>\n",
       "      <td>1.321667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.234466</td>\n",
       "      <td>0.520526</td>\n",
       "      <td>1.122849</td>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>-2.354017</td>\n",
       "      <td>1.245527</td>\n",
       "      <td>-1.423911</td>\n",
       "      <td>-0.813780</td>\n",
       "      <td>1.336361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.211850</td>\n",
       "      <td>0.529402</td>\n",
       "      <td>1.116422</td>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>-2.391456</td>\n",
       "      <td>1.246722</td>\n",
       "      <td>-1.409436</td>\n",
       "      <td>-0.781482</td>\n",
       "      <td>1.351055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.202483</td>\n",
       "      <td>0.533468</td>\n",
       "      <td>1.112937</td>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>-2.352091</td>\n",
       "      <td>1.239167</td>\n",
       "      <td>-1.381591</td>\n",
       "      <td>-0.773644</td>\n",
       "      <td>1.347197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.193117</td>\n",
       "      <td>0.541972</td>\n",
       "      <td>1.109452</td>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>-2.297129</td>\n",
       "      <td>1.231611</td>\n",
       "      <td>-1.353745</td>\n",
       "      <td>-0.765806</td>\n",
       "      <td>1.343338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.183751</td>\n",
       "      <td>0.553232</td>\n",
       "      <td>1.105967</td>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>-2.269552</td>\n",
       "      <td>1.224056</td>\n",
       "      <td>-1.325900</td>\n",
       "      <td>-0.757968</td>\n",
       "      <td>1.339480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.174384</td>\n",
       "      <td>0.554774</td>\n",
       "      <td>1.102482</td>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>-2.231111</td>\n",
       "      <td>1.216501</td>\n",
       "      <td>-1.298054</td>\n",
       "      <td>-0.750129</td>\n",
       "      <td>1.335622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.165018</td>\n",
       "      <td>0.567043</td>\n",
       "      <td>1.098997</td>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>-2.139317</td>\n",
       "      <td>1.208945</td>\n",
       "      <td>-1.270209</td>\n",
       "      <td>-0.742291</td>\n",
       "      <td>1.331764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.155651</td>\n",
       "      <td>0.582904</td>\n",
       "      <td>1.095513</td>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>-2.104610</td>\n",
       "      <td>1.201390</td>\n",
       "      <td>-1.242363</td>\n",
       "      <td>-0.734453</td>\n",
       "      <td>1.327905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.146285</td>\n",
       "      <td>0.624622</td>\n",
       "      <td>1.092028</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-2.063199</td>\n",
       "      <td>1.193835</td>\n",
       "      <td>-1.214518</td>\n",
       "      <td>-0.726615</td>\n",
       "      <td>1.324047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.136919</td>\n",
       "      <td>0.664868</td>\n",
       "      <td>1.088543</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>-2.019550</td>\n",
       "      <td>1.186279</td>\n",
       "      <td>-1.186673</td>\n",
       "      <td>-0.718777</td>\n",
       "      <td>1.320189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.127552</td>\n",
       "      <td>0.713988</td>\n",
       "      <td>1.085058</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>-1.981485</td>\n",
       "      <td>1.178724</td>\n",
       "      <td>-1.158827</td>\n",
       "      <td>-0.710938</td>\n",
       "      <td>1.316331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.118186</td>\n",
       "      <td>0.765366</td>\n",
       "      <td>1.081573</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-1.940641</td>\n",
       "      <td>1.171169</td>\n",
       "      <td>-1.130982</td>\n",
       "      <td>-0.703100</td>\n",
       "      <td>1.312472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.108819</td>\n",
       "      <td>0.819755</td>\n",
       "      <td>1.078088</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-1.925398</td>\n",
       "      <td>1.163614</td>\n",
       "      <td>-1.103136</td>\n",
       "      <td>-0.695262</td>\n",
       "      <td>1.308614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Amazonas - IDH  Amazonas - value  Amazonas - Desemprego  \\\n",
       "162        1.464528          0.300771               1.300989   \n",
       "163        1.467649          0.302678               1.283081   \n",
       "164        1.470769          0.311080               1.265173   \n",
       "165        1.473890          0.323489               1.247265   \n",
       "166        1.477010          0.339232               1.229358   \n",
       "167        1.480131          0.356121               1.211450   \n",
       "168        1.483251          0.375580               1.193542   \n",
       "169        1.460634          0.394947               1.187115   \n",
       "170        1.438018          0.409500               1.180689   \n",
       "171        1.415401          0.414230               1.174262   \n",
       "172        1.392784          0.425733               1.167835   \n",
       "173        1.370167          0.438462               1.161409   \n",
       "174        1.347550          0.452423               1.154982   \n",
       "175        1.324934          0.467714               1.148555   \n",
       "176        1.302317          0.484392               1.142129   \n",
       "177        1.279700          0.503077               1.135702   \n",
       "178        1.257083          0.509446               1.129275   \n",
       "179        1.234466          0.520526               1.122849   \n",
       "180        1.211850          0.529402               1.116422   \n",
       "181        1.202483          0.533468               1.112937   \n",
       "182        1.193117          0.541972               1.109452   \n",
       "183        1.183751          0.553232               1.105967   \n",
       "184        1.174384          0.554774               1.102482   \n",
       "185        1.165018          0.567043               1.098997   \n",
       "186        1.155651          0.582904               1.095513   \n",
       "187        1.146285          0.624622               1.092028   \n",
       "188        1.136919          0.664868               1.088543   \n",
       "189        1.127552          0.713988               1.085058   \n",
       "190        1.118186          0.765366               1.081573   \n",
       "191        1.108819          0.819755               1.078088   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162                                         -0.601510   \n",
       "163                                         -0.786068   \n",
       "164                                         -0.830387   \n",
       "165                                         -0.801089   \n",
       "166                                         -0.959917   \n",
       "167                                         -1.022309   \n",
       "168                                         -1.074401   \n",
       "169                                         -1.119597   \n",
       "170                                         -1.078648   \n",
       "171                                         -1.055426   \n",
       "172                                         -1.101053   \n",
       "173                                         -1.211370   \n",
       "174                                         -1.157198   \n",
       "175                                         -1.223444   \n",
       "176                                         -1.311519   \n",
       "177                                         -1.362602   \n",
       "178                                         -1.380125   \n",
       "179                                         -1.219296   \n",
       "180                                         -1.300284   \n",
       "181                                         -1.336476   \n",
       "182                                         -1.415774   \n",
       "183                                         -1.526021   \n",
       "184                                         -1.681806   \n",
       "185                                         -1.735167   \n",
       "186                                         -1.962315   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "162                                0.763466  -1.213929   \n",
       "163                                0.752299  -1.292173   \n",
       "164                                0.741131  -1.324219   \n",
       "165                                0.729964  -1.344446   \n",
       "166                                0.718796  -1.381638   \n",
       "167                                0.707629  -1.411208   \n",
       "168                                0.696461  -1.412953   \n",
       "169                                0.681823  -1.491464   \n",
       "170                                0.667184  -1.573805   \n",
       "171                                0.652545  -1.564950   \n",
       "172                                0.637906  -1.581584   \n",
       "173                                0.623268  -1.565976   \n",
       "174                                0.608629  -1.648556   \n",
       "175                                0.593990  -1.650049   \n",
       "176                                0.579351  -1.653957   \n",
       "177                                0.564713  -1.652572   \n",
       "178                                0.550074  -1.715349   \n",
       "179                                0.535435  -1.750917   \n",
       "180                                0.520796  -1.718448   \n",
       "181                                0.501996  -1.733426   \n",
       "182                                0.483195  -1.729362   \n",
       "183                                0.464395  -1.748544   \n",
       "184                                0.445594  -1.778060   \n",
       "185                                0.426794  -1.773710   \n",
       "186                                0.407993  -1.757007   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Amazonas - Produção de Cimento (t)  Amazonas - PIB - Estadual  \\\n",
       "162                           -1.196117                   1.198122   \n",
       "163                           -1.258972                   1.203832   \n",
       "164                           -1.316525                   1.209543   \n",
       "165                           -1.376631                   1.215254   \n",
       "166                           -1.427803                   1.220965   \n",
       "167                           -1.492489                   1.226676   \n",
       "168                           -1.557787                   1.232387   \n",
       "169                           -1.627941                   1.233581   \n",
       "170                           -1.689803                   1.234776   \n",
       "171                           -1.759409                   1.235970   \n",
       "172                           -1.823897                   1.237165   \n",
       "173                           -1.897918                   1.238360   \n",
       "174                           -1.975283                   1.239554   \n",
       "175                           -2.041256                   1.240749   \n",
       "176                           -2.121341                   1.241944   \n",
       "177                           -2.192006                   1.243138   \n",
       "178                           -2.265925                   1.244333   \n",
       "179                           -2.354017                   1.245527   \n",
       "180                           -2.391456                   1.246722   \n",
       "181                           -2.352091                   1.239167   \n",
       "182                           -2.297129                   1.231611   \n",
       "183                           -2.269552                   1.224056   \n",
       "184                           -2.231111                   1.216501   \n",
       "185                           -2.139317                   1.208945   \n",
       "186                           -2.104610                   1.201390   \n",
       "187                           -2.063199                   1.193835   \n",
       "188                           -2.019550                   1.186279   \n",
       "189                           -1.981485                   1.178724   \n",
       "190                           -1.940641                   1.171169   \n",
       "191                           -1.925398                   1.163614   \n",
       "\n",
       "     Amazonas - PIB - Construção Civil  Amazonas - PIB - Per Capita  \\\n",
       "162                          -1.539943                    -1.329107   \n",
       "163                          -1.547140                    -1.302431   \n",
       "164                          -1.554338                    -1.275755   \n",
       "165                          -1.561536                    -1.249079   \n",
       "166                          -1.568734                    -1.222403   \n",
       "167                          -1.575932                    -1.195727   \n",
       "168                          -1.583129                    -1.169051   \n",
       "169                          -1.568655                    -1.136753   \n",
       "170                          -1.554180                    -1.104456   \n",
       "171                          -1.539706                    -1.072159   \n",
       "172                          -1.525232                    -1.039861   \n",
       "173                          -1.510757                    -1.007564   \n",
       "174                          -1.496283                    -0.975266   \n",
       "175                          -1.481808                    -0.942969   \n",
       "176                          -1.467334                    -0.910672   \n",
       "177                          -1.452860                    -0.878374   \n",
       "178                          -1.438385                    -0.846077   \n",
       "179                          -1.423911                    -0.813780   \n",
       "180                          -1.409436                    -0.781482   \n",
       "181                          -1.381591                    -0.773644   \n",
       "182                          -1.353745                    -0.765806   \n",
       "183                          -1.325900                    -0.757968   \n",
       "184                          -1.298054                    -0.750129   \n",
       "185                          -1.270209                    -0.742291   \n",
       "186                          -1.242363                    -0.734453   \n",
       "187                          -1.214518                    -0.726615   \n",
       "188                          -1.186673                    -0.718777   \n",
       "189                          -1.158827                    -0.710938   \n",
       "190                          -1.130982                    -0.703100   \n",
       "191                          -1.103136                    -0.695262   \n",
       "\n",
       "     Amazonas - PIB - Preços de Mercado  \n",
       "162                            1.055246  \n",
       "163                            1.075160  \n",
       "164                            1.095073  \n",
       "165                            1.114986  \n",
       "166                            1.134899  \n",
       "167                            1.154813  \n",
       "168                            1.174726  \n",
       "169                            1.189420  \n",
       "170                            1.204114  \n",
       "171                            1.218808  \n",
       "172                            1.233502  \n",
       "173                            1.248196  \n",
       "174                            1.262890  \n",
       "175                            1.277585  \n",
       "176                            1.292279  \n",
       "177                            1.306973  \n",
       "178                            1.321667  \n",
       "179                            1.336361  \n",
       "180                            1.351055  \n",
       "181                            1.347197  \n",
       "182                            1.343338  \n",
       "183                            1.339480  \n",
       "184                            1.335622  \n",
       "185                            1.331764  \n",
       "186                            1.327905  \n",
       "187                            1.324047  \n",
       "188                            1.320189  \n",
       "189                            1.316331  \n",
       "190                            1.312472  \n",
       "191                            1.308614  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    64.862\n",
       "163    49.885\n",
       "164    53.130\n",
       "165    57.796\n",
       "166    47.026\n",
       "167    74.919\n",
       "168    34.733\n",
       "169    15.022\n",
       "170    20.879\n",
       "171    36.409\n",
       "172    22.277\n",
       "173    20.529\n",
       "174    37.061\n",
       "175    23.387\n",
       "176    38.399\n",
       "177    39.652\n",
       "178    40.204\n",
       "179    21.625\n",
       "180    42.731\n",
       "181    36.026\n",
       "182    34.609\n",
       "183    40.787\n",
       "184    39.823\n",
       "185    39.957\n",
       "186    52.048\n",
       "187    53.567\n",
       "188    46.239\n",
       "189    51.066\n",
       "190    51.684\n",
       "191    44.907\n",
       "Name: Amazonas - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*6 + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "#     train, train_val = validation_splitter(train_input, 7)\n",
    "#     target,target_val = validation_splitter(train_target, 7)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train_input, \n",
    "                        train_target, \n",
    "                        epochs=10000,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[806066579, 2049285293, 2032192701, 4022980133, 153679890, 3748899833, 2641817026, 924203712, 3049072839, 909227647, 3144488690, 3978828576, 671243646, 602837307, 1492069559, 703063686, 3253050182, 2948163872, 4108259500, 1251389346, 3694369386, 590851820, 1116096677, 3826407799, 313085354]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 403.24072265625\n",
      "winner_seed: 806066579\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 2474.42578125\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 2365.111328125\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 2836.40869140625\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 229.6756134033203\n",
      "winner_seed: 153679890\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 907.9139404296875\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 1247.163818359375\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 2203.541015625\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 1638.5289306640625\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 1565.0025634765625\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 1692.8184814453125\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 447.8204345703125\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 1884.8746337890625\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 1702.86328125\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 1915.4976806640625\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 753.8850708007812\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 1132.4185791015625\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 2756.9599609375\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 3431.988525390625\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 413.28814697265625\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 2300.59521484375\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 1913.2781982421875\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 2857.294921875\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 1582.798095703125\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 6575.1396484375\n",
      "\n",
      "\n",
      "final_seed: 153679890\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 1s 26ms/step - loss: 3849.3777 - val_loss: 136.9435\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2914.7346 - val_loss: 248.1460\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2079.9385 - val_loss: 4742.7827\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 161.6531 - val_loss: 6176.8560\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 138.7357 - val_loss: 6939.2085\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 127.8624 - val_loss: 6769.6777\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.4498 - val_loss: 4997.5713\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 123.6347 - val_loss: 4740.0620\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 118.2824 - val_loss: 4936.6299\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.3225 - val_loss: 5076.8086\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 125.2783 - val_loss: 5131.0200\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.6497 - val_loss: 5803.2700\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.7389 - val_loss: 5646.2324\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.9787 - val_loss: 5377.5659\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.9126 - val_loss: 5319.7622\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.2243 - val_loss: 5390.8789\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.6511 - val_loss: 5932.3984\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.7742 - val_loss: 5788.4697\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.0718 - val_loss: 6081.4409\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 98.4489 - val_loss: 5807.0352\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 115.9211 - val_loss: 6196.9604\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.9351 - val_loss: 6906.7373\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.9128 - val_loss: 7528.5693\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 112.3284 - val_loss: 7888.3384\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2469.8557 - val_loss: 5603.2334\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2962.6682 - val_loss: 4039.5881\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1361.5585 - val_loss: 4848.2651\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 215.6161 - val_loss: 5287.6655\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 185.2491 - val_loss: 5252.5962\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 186.5692 - val_loss: 5192.5679\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 178.3602 - val_loss: 5028.3369\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 164.4208 - val_loss: 5643.3555\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 163.9498 - val_loss: 5286.0459\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 147.7325 - val_loss: 5266.0142\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 150.3011 - val_loss: 5168.7866\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 126.1927 - val_loss: 4744.2485\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 121.4102 - val_loss: 4936.6787\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.9527 - val_loss: 4944.4141\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 134.3994 - val_loss: 3208.0254\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 118.3869 - val_loss: 3700.6116\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.4118 - val_loss: 3714.2454\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 122.9812 - val_loss: 3557.9036\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.8679 - val_loss: 3829.6619\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.0959 - val_loss: 3494.1821\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 115.6335 - val_loss: 3511.6855\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.2247 - val_loss: 4094.3501\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 116.3553 - val_loss: 3554.3691\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 125.7238 - val_loss: 3634.5610\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 134.5508 - val_loss: 3603.4717\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.5139 - val_loss: 3297.7996\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 123.0104 - val_loss: 3961.2197\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.1346 - val_loss: 3993.9109\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.5594 - val_loss: 3703.2048\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 110.5288 - val_loss: 4024.2776\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.0295 - val_loss: 4044.7058\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.4720 - val_loss: 3765.5869\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 128.8333 - val_loss: 4360.4595\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 121.5208 - val_loss: 4592.3018\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 124.1339 - val_loss: 3689.4243\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.7322 - val_loss: 3883.7776\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.9575 - val_loss: 4716.3779\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 124.4607 - val_loss: 4422.9399\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 119.9330 - val_loss: 5042.3604\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.2841 - val_loss: 4768.2183\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.2529 - val_loss: 4142.2886\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.2678 - val_loss: 3010.2029\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 112.3386 - val_loss: 3523.8723\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 115.5262 - val_loss: 3711.1338\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.0725 - val_loss: 3501.2891\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.7431 - val_loss: 3665.9668\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.5609 - val_loss: 4020.6084\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.4872 - val_loss: 3710.8538\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.9646 - val_loss: 4393.8955\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.5740 - val_loss: 3825.5679\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.2318 - val_loss: 4138.3247\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.7661 - val_loss: 3793.4211\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.8585 - val_loss: 3268.1860\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 321.9398 - val_loss: 4021.5725\n",
      "Epoch 79/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 145.3287 - val_loss: 1895.9761\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 120.6947 - val_loss: 2371.4526\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.3223 - val_loss: 2826.7202\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.6572 - val_loss: 2372.3679\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.4437 - val_loss: 2429.3083\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.4791 - val_loss: 2449.1946\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.3473 - val_loss: 2674.2302\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.0487 - val_loss: 2395.4790\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.9552 - val_loss: 2809.1545\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.7636 - val_loss: 2587.1072\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.9475 - val_loss: 2590.6787\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.5073 - val_loss: 3722.8704\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.1850 - val_loss: 3893.4329\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.0282 - val_loss: 3904.7441\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.8809 - val_loss: 3789.4253\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.6512 - val_loss: 2832.5762\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.7223 - val_loss: 2889.3584\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.5443 - val_loss: 2948.5413\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.1418 - val_loss: 3507.1885\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.3946 - val_loss: 3495.0652\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.5053 - val_loss: 3696.6921\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.9143 - val_loss: 4748.8418\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.4802 - val_loss: 4208.5483\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.8774 - val_loss: 4027.4136\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.7398 - val_loss: 4346.5864\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.5512 - val_loss: 4288.7896\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.0686 - val_loss: 4282.4888\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.7241 - val_loss: 4011.7761\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.3639 - val_loss: 4304.6123\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.1984 - val_loss: 4060.1121\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.9385 - val_loss: 4728.8911\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.6652 - val_loss: 4752.5020\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.5491 - val_loss: 4409.4336\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 100.7006 - val_loss: 4108.0332\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.0929 - val_loss: 3555.8535\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.7410 - val_loss: 4171.9990\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.9346 - val_loss: 3804.2053\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.1355 - val_loss: 4859.6206\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.9874 - val_loss: 4206.2852\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.4554 - val_loss: 4229.0513\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.8359 - val_loss: 5250.4233\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.5514 - val_loss: 4458.7817\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.9513 - val_loss: 4980.8750\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 107.7260 - val_loss: 4802.5645\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 113.3911 - val_loss: 5167.1064\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.5648 - val_loss: 3259.2903\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.3782 - val_loss: 3282.9094\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.9479 - val_loss: 3021.4458\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1382.4651 - val_loss: 5860.4067\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 400.5329 - val_loss: 3130.0334\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.4768 - val_loss: 3545.0300\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.7762 - val_loss: 3651.2800\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.8383 - val_loss: 3454.7812\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9156 - val_loss: 3624.4746\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.2740 - val_loss: 3377.4097\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.3396 - val_loss: 3098.8162\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.5748 - val_loss: 3695.3901\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.1697 - val_loss: 3634.3074\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.4067 - val_loss: 3181.0203\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.4027 - val_loss: 3233.9236\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.5623 - val_loss: 3819.4297\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.2637 - val_loss: 3472.4089\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.1051 - val_loss: 4061.2395\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.3778 - val_loss: 3778.0730\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.8760 - val_loss: 3601.8289\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.8380 - val_loss: 3360.4834\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.2469 - val_loss: 3831.4316\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.3678 - val_loss: 3415.0413\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.8069 - val_loss: 3381.9375\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.6856 - val_loss: 3234.3257\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 112.7063 - val_loss: 3004.8296\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.0615 - val_loss: 3656.7188\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.8781 - val_loss: 2929.0842\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.3904 - val_loss: 3029.7893\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.0906 - val_loss: 3503.5879\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.7903 - val_loss: 3441.9795\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.6441 - val_loss: 2905.5671\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.0716 - val_loss: 3078.7358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.0253 - val_loss: 3173.3274\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.2195 - val_loss: 3110.0198\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.7383 - val_loss: 3315.2231\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.3582 - val_loss: 3432.3547\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.0511 - val_loss: 3689.3926\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.6856 - val_loss: 3746.5657\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.1830 - val_loss: 3322.9751\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.5444 - val_loss: 3563.6001\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.0244 - val_loss: 3420.8525\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.5595 - val_loss: 3878.9380\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.7245 - val_loss: 3315.0652\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.5176 - val_loss: 3519.5488\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.0725 - val_loss: 3779.8489\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.7582 - val_loss: 3677.9670\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.2129 - val_loss: 3636.8716\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.4752 - val_loss: 3688.8960\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.8295 - val_loss: 3278.1814\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.0816 - val_loss: 3587.0884\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.1644 - val_loss: 3909.2949\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.7229 - val_loss: 3204.7249\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.3129 - val_loss: 3381.2734\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.9428 - val_loss: 3377.7222\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.6806 - val_loss: 3665.6128\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.6674 - val_loss: 3178.5615\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.2968 - val_loss: 3609.1594\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.9197 - val_loss: 3708.3525\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.9048 - val_loss: 3762.9756\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.9266 - val_loss: 3560.1746\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.4894 - val_loss: 3718.0242\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9084 - val_loss: 3672.6877\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.0894 - val_loss: 3191.8057\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.4876 - val_loss: 3211.7598\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.4509 - val_loss: 3248.7363\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.3142 - val_loss: 2968.2288\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.7867 - val_loss: 3421.3254\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.5052 - val_loss: 2949.5215\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 115.6238 - val_loss: 2933.7944\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.3591 - val_loss: 2908.0703\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.2730 - val_loss: 3084.3230\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.1775 - val_loss: 3201.9492\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.9874 - val_loss: 3283.4863\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.9487 - val_loss: 3388.8840\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.6489 - val_loss: 3225.6765\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.4359 - val_loss: 3021.5864\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.0109 - val_loss: 3509.3953\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.1893 - val_loss: 3256.0330\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.5567 - val_loss: 3097.4209\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.9384 - val_loss: 2813.5371\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.6841 - val_loss: 3368.6487\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.8344 - val_loss: 3435.5874\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8783 - val_loss: 3015.1704\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.4409 - val_loss: 2969.4043\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.7471 - val_loss: 3020.5762\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.0599 - val_loss: 3419.1521\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.6906 - val_loss: 3442.5588\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.9051 - val_loss: 3425.9849\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.8061 - val_loss: 3331.3047\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.4200 - val_loss: 3632.6807\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.5967 - val_loss: 3390.9519\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.3107 - val_loss: 2214.9807\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.6805 - val_loss: 2588.5681\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.1384 - val_loss: 2546.2917\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.6245 - val_loss: 2354.0918\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.2405 - val_loss: 2406.7654\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.0463 - val_loss: 2451.1968\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.7195 - val_loss: 2648.8147\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.9206 - val_loss: 2483.8203\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.4380 - val_loss: 2223.6482\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 116.5066 - val_loss: 2868.3374\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.1523 - val_loss: 2565.5605\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.1306 - val_loss: 2540.6467\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.6721 - val_loss: 2263.7781\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.9008 - val_loss: 2563.5989\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.2766 - val_loss: 2972.6848\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.5141 - val_loss: 2600.4500\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.6380 - val_loss: 2492.3555\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.7164 - val_loss: 2499.5044\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.9032 - val_loss: 1972.9224\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.6331 - val_loss: 2487.8699\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.0141 - val_loss: 2260.9785\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.5783 - val_loss: 2406.0332\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.9986 - val_loss: 2740.2961\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.0147 - val_loss: 2370.6799\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.3746 - val_loss: 2357.3904\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.0039 - val_loss: 2391.5520\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.6746 - val_loss: 2693.8743\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.3291 - val_loss: 2674.9333\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.5870 - val_loss: 2409.8599\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.3244 - val_loss: 2681.8984\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9254 - val_loss: 2439.3040\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.0683 - val_loss: 2793.5698\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.6867 - val_loss: 2402.5278\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.8108 - val_loss: 2635.0342\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.0045 - val_loss: 2404.2917\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8505 - val_loss: 2463.8364\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.2632 - val_loss: 2390.3210\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.6660 - val_loss: 2597.8613\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.1480 - val_loss: 2617.1560\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.7494 - val_loss: 2868.6833\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.7791 - val_loss: 2563.5767\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.6407 - val_loss: 2176.9226\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.7553 - val_loss: 2660.2188\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.3206 - val_loss: 2683.3948\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.7431 - val_loss: 2288.8323\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.0850 - val_loss: 3249.4741\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.6214 - val_loss: 3099.5723\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.1681 - val_loss: 3432.6938\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.6580 - val_loss: 3296.2568\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.7522 - val_loss: 3195.4871\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.0707 - val_loss: 3652.2266\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.1647 - val_loss: 2956.9346\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.4086 - val_loss: 3078.8760\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.1819 - val_loss: 3012.1650\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.5124 - val_loss: 2974.5320\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.6153 - val_loss: 3014.8110\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.3674 - val_loss: 3199.8396\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.5310 - val_loss: 2976.4473\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.6723 - val_loss: 2561.3518\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.2428 - val_loss: 3110.4563\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.7652 - val_loss: 3183.2173\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.3617 - val_loss: 2883.2427\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.9038 - val_loss: 2771.2063\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.1563 - val_loss: 2916.9878\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.0980 - val_loss: 2607.4836\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9543 - val_loss: 2888.8560\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.8420 - val_loss: 2849.4897\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.2082 - val_loss: 2647.1377\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.2578 - val_loss: 2594.4492\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.2307 - val_loss: 2737.3384\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.5318 - val_loss: 2645.0020\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.2613 - val_loss: 2657.7854\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.9922 - val_loss: 2728.1926\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.1399 - val_loss: 2666.3496\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.4437 - val_loss: 2587.4751\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.2949 - val_loss: 2503.2366\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.8849 - val_loss: 2878.8943\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.0884 - val_loss: 2973.5813\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.6384 - val_loss: 2481.2402\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.0013 - val_loss: 2668.6301\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.3499 - val_loss: 2506.6697\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.8858 - val_loss: 2507.5298\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.1878 - val_loss: 2639.1035\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.5282 - val_loss: 2454.9170\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.5050 - val_loss: 2643.9570\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.2155 - val_loss: 3530.0657\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9667 - val_loss: 4051.9990\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.2976 - val_loss: 3716.4141\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.5279 - val_loss: 3935.8062\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.3496 - val_loss: 3931.1001\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.1659 - val_loss: 4129.5254\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.8409 - val_loss: 3862.4275\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.8582 - val_loss: 4070.1604\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.5910 - val_loss: 3931.3145\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.2815 - val_loss: 4204.5859\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.1035 - val_loss: 4034.1738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8796 - val_loss: 3999.8103\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.9771 - val_loss: 4490.8711\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.0163 - val_loss: 4539.1914\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.5390 - val_loss: 4042.8843\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.9727 - val_loss: 4133.1040\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.4091 - val_loss: 4633.0234\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.7352 - val_loss: 4351.1753\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9848 - val_loss: 4237.2930\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.5982 - val_loss: 4231.3721\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.6827 - val_loss: 4388.7300\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.5015 - val_loss: 4584.7144\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.0168 - val_loss: 4254.3628\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 85.3102 - val_loss: 3952.2173\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.1868 - val_loss: 4030.2720\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.3264 - val_loss: 3864.6177\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.3005 - val_loss: 3936.9746\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8956 - val_loss: 3478.7932\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.7388 - val_loss: 3999.1672\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.1426 - val_loss: 3853.4678\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.6674 - val_loss: 3527.3416\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.1089 - val_loss: 3115.6543\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.5911 - val_loss: 3520.6047\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 110.8572 - val_loss: 3560.6531\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.6004 - val_loss: 3881.4355\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.4297 - val_loss: 3630.1147\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.6271 - val_loss: 3666.6580\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.5402 - val_loss: 3399.8042\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.2788 - val_loss: 3938.4421\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.1643 - val_loss: 3964.1934\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.9711 - val_loss: 4011.7871\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.8947 - val_loss: 3989.5010\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.9535 - val_loss: 3817.7629\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.9891 - val_loss: 4167.7920\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.7142 - val_loss: 3751.6497\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.2383 - val_loss: 3796.1570\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.7473 - val_loss: 4137.8237\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.2923 - val_loss: 4217.4312\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.7788 - val_loss: 3927.8162\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 94.8631 - val_loss: 3817.8171\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.8018 - val_loss: 4233.6772\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.9517 - val_loss: 4324.7808\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.4445 - val_loss: 3984.7129\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.2047 - val_loss: 3932.7808\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.8912 - val_loss: 3789.9380\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.7672 - val_loss: 3400.4705\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.8140 - val_loss: 3613.0452\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.4022 - val_loss: 4296.2915\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.6061 - val_loss: 3717.1968\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.3983 - val_loss: 3911.7532\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.5177 - val_loss: 4251.3594\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.2523 - val_loss: 3988.7349\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.9870 - val_loss: 3568.1985\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.9408 - val_loss: 3681.5024\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.0592 - val_loss: 3597.9578\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.6941 - val_loss: 3815.0645\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.3507 - val_loss: 3684.9016\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.3549 - val_loss: 4058.8254\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.7518 - val_loss: 4192.0933\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9383 - val_loss: 4310.2729\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 108.1754 - val_loss: 4469.5503\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 104.4644 - val_loss: 3870.7012\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.7813 - val_loss: 3909.7563\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.9019 - val_loss: 4163.8110\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.1360 - val_loss: 4364.4224\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.7082 - val_loss: 3125.0808\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.9311 - val_loss: 2986.3953\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.4397 - val_loss: 2948.5168\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.5459 - val_loss: 2787.0098\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.0072 - val_loss: 3094.4390\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.2897 - val_loss: 3259.1577\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.5911 - val_loss: 2944.1870\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.3496 - val_loss: 3216.5247\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 98.4605 - val_loss: 3256.6387\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.7487 - val_loss: 3141.7942\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.4194 - val_loss: 2959.1516\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.7905 - val_loss: 2788.9985\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.2746 - val_loss: 3105.5522\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8600 - val_loss: 3069.8657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.4111 - val_loss: 3028.2231\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.6084 - val_loss: 3191.4304\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.9041 - val_loss: 3001.6357\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.8969 - val_loss: 2832.4233\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.1848 - val_loss: 3091.1257\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.7714 - val_loss: 3565.3311\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.7705 - val_loss: 2901.5566\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.6244 - val_loss: 3119.9365\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.6050 - val_loss: 3727.2322\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.6621 - val_loss: 3479.6545\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.3739 - val_loss: 3445.9395\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.6350 - val_loss: 4153.7773\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.7589 - val_loss: 2955.8230\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.9605 - val_loss: 3471.8770\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.0925 - val_loss: 3216.1934\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 107.6036 - val_loss: 3341.4353\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.4932 - val_loss: 3173.8943\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.1401 - val_loss: 3706.5737\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.9117 - val_loss: 3711.3401\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.5354 - val_loss: 2853.8323\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.6390 - val_loss: 3453.8469\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.2890 - val_loss: 4260.4258\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.2995 - val_loss: 4322.4419\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8968 - val_loss: 4002.5994\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.4634 - val_loss: 4176.8643\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.2910 - val_loss: 4298.4536\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.6959 - val_loss: 4229.1309\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.7598 - val_loss: 3944.1470\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.2202 - val_loss: 4229.9268\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.0717 - val_loss: 1786.6289\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 390.2844 - val_loss: 6421.9033\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 437.6686 - val_loss: 4623.1836\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 113.8956 - val_loss: 4783.9658\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.6415 - val_loss: 4227.6792\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.4453 - val_loss: 4904.5137\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.0622 - val_loss: 5001.1372\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.8857 - val_loss: 4816.7363\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.7118 - val_loss: 4552.5952\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.1176 - val_loss: 4832.7207\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 113.1099 - val_loss: 5167.4648\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 118.3456 - val_loss: 4059.3604\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.5965 - val_loss: 4312.1455\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.4480 - val_loss: 4401.1519\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.8189 - val_loss: 5187.8486\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.0077 - val_loss: 4816.2305\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.5790 - val_loss: 4521.6885\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.5186 - val_loss: 4668.8672\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 98.5996 - val_loss: 4602.5532\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.7344 - val_loss: 5002.6646\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.0751 - val_loss: 4613.6587\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 114.1381 - val_loss: 5048.9009\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.4815 - val_loss: 6041.9253\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.9882 - val_loss: 4753.9399\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.3867 - val_loss: 4325.0811\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 118.3822 - val_loss: 4500.1880\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.3736 - val_loss: 4614.4692\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 123.3771 - val_loss: 4578.6787\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.2812 - val_loss: 4417.3765\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.6842 - val_loss: 4254.5659\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.0105 - val_loss: 4314.6738\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.0741 - val_loss: 4328.0508\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 116.4405 - val_loss: 4764.7969\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.4132 - val_loss: 4846.5767\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.9327 - val_loss: 4431.0122\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.6147 - val_loss: 4330.1880\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.2023 - val_loss: 5262.0254\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.0999 - val_loss: 4377.7773\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.6382 - val_loss: 4976.8398\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.8304 - val_loss: 4717.3955\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8706 - val_loss: 4238.2930\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.4733 - val_loss: 4283.5288\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 112.1111 - val_loss: 5629.0791\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 116.9536 - val_loss: 5172.0938\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8694 - val_loss: 4697.5264\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.9565 - val_loss: 4646.0215\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.1093 - val_loss: 5585.0664\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 101.2725 - val_loss: 5688.2163\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 106.0591 - val_loss: 4186.6479\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.1719 - val_loss: 4370.2744\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.9661 - val_loss: 4611.0264\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 113.7918 - val_loss: 4162.5933\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.6680 - val_loss: 4511.6953\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.7361 - val_loss: 4740.7354\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 94.4310 - val_loss: 4542.9102\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.7624 - val_loss: 4694.4746\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.0096 - val_loss: 5159.3765\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.0128 - val_loss: 5119.9287\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.4091 - val_loss: 4278.9395\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.6016 - val_loss: 4587.5469\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.4418 - val_loss: 4168.2173\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.1728 - val_loss: 3864.3105\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.8238 - val_loss: 4374.0425\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.5357 - val_loss: 4589.9380\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 107.5560 - val_loss: 4868.9331\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.7062 - val_loss: 4556.4453\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.9366 - val_loss: 4687.6436\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.5844 - val_loss: 4558.9468\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.4190 - val_loss: 4390.3438\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.4851 - val_loss: 4532.1909\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.5317 - val_loss: 4499.1455\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.0785 - val_loss: 4658.6406\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.4476 - val_loss: 4464.6772\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.7582 - val_loss: 4367.7988\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 103.8787 - val_loss: 4497.0767\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.7059 - val_loss: 4607.7236\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.3600 - val_loss: 4643.9941\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 107.6274 - val_loss: 4101.5942\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.7114 - val_loss: 4439.1836\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.5059 - val_loss: 3982.8267\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.6566 - val_loss: 4470.1489\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.6083 - val_loss: 4436.8442\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 95.2429 - val_loss: 4253.7563\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 100.8080 - val_loss: 4235.1128\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 92.9728 - val_loss: 4204.8638\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.5549 - val_loss: 4337.4321\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.2817 - val_loss: 4512.6025\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.0378 - val_loss: 5000.8979\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.2431 - val_loss: 4508.9077\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.3790 - val_loss: 4938.7393\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 89.4341 - val_loss: 3748.4695\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 109.9117 - val_loss: 4220.4268\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.7448 - val_loss: 4134.8188\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.9447 - val_loss: 4410.6001\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.5900 - val_loss: 4302.6499\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.2735 - val_loss: 4317.9717\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.7241 - val_loss: 4226.9229\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.9590 - val_loss: 4012.9167\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.8823 - val_loss: 4295.1348\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.3900 - val_loss: 4494.2334\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.6798 - val_loss: 4699.8638\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.4178 - val_loss: 4238.3828\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.1575 - val_loss: 4676.0630\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.4135 - val_loss: 4235.9834\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.1522 - val_loss: 4591.1089\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.8508 - val_loss: 4276.8086\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.0649 - val_loss: 4085.2991\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.4124 - val_loss: 4657.7549\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9379 - val_loss: 4278.2041\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.6711 - val_loss: 4674.6445\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.7029 - val_loss: 5074.7617\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.7606 - val_loss: 4596.5698\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.9353 - val_loss: 4757.9150\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 110.9980 - val_loss: 4704.1499\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.1761 - val_loss: 4511.0459\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.9353 - val_loss: 4253.7231\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 95.2464 - val_loss: 3165.1699\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 94.4572 - val_loss: 2854.1108\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 100.1327 - val_loss: 2688.9094\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.2013 - val_loss: 3493.9106\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 112.9245 - val_loss: 3068.9338\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8982 - val_loss: 3266.3318\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.7811 - val_loss: 3067.3977\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.0425 - val_loss: 3190.4854\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.9036 - val_loss: 3036.3081\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.7156 - val_loss: 3382.1692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.7321 - val_loss: 3085.7332\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.6044 - val_loss: 3073.5088\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.7939 - val_loss: 3240.9609\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.0217 - val_loss: 3190.8276\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.6662 - val_loss: 3281.7917\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.0924 - val_loss: 3349.4082\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.3949 - val_loss: 3550.6997\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.9237 - val_loss: 3521.6892\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9047 - val_loss: 3453.4907\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.7171 - val_loss: 3182.7737\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.5836 - val_loss: 3642.4016\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.2327 - val_loss: 3390.7947\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.9994 - val_loss: 3706.3462\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 97.4271 - val_loss: 3459.4219\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.9498 - val_loss: 3756.9343\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.0003 - val_loss: 3775.8352\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.7619 - val_loss: 3672.1973\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.5130 - val_loss: 3406.1843\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.3385 - val_loss: 3946.4302\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.3867 - val_loss: 3377.9314\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.9731 - val_loss: 4192.8911\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.0041 - val_loss: 3870.8984\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.3036 - val_loss: 3987.6116\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.8298 - val_loss: 4464.7710\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.1035 - val_loss: 4790.4790\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.3743 - val_loss: 4258.5044\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.0581 - val_loss: 3772.4688\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.7916 - val_loss: 3889.8933\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 109.9905 - val_loss: 3770.2629\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8048 - val_loss: 4302.1108\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 103.9146 - val_loss: 4356.0771\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 103.7349 - val_loss: 4559.1650\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 90.8095 - val_loss: 4324.6973\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.4298 - val_loss: 4475.8130\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.0000 - val_loss: 4629.2363\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.5680 - val_loss: 4401.9956\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.4714 - val_loss: 4284.7529\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.1149 - val_loss: 4409.3965\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.8907 - val_loss: 4218.3130\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.8481 - val_loss: 4043.6975\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.0694 - val_loss: 4420.8154\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.9720 - val_loss: 4013.7073\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.5819 - val_loss: 4022.0334\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.2423 - val_loss: 4276.2383\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.4149 - val_loss: 4188.2427\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.0474 - val_loss: 4688.8164\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.0938 - val_loss: 4319.4204\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.4548 - val_loss: 4557.7759\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.5196 - val_loss: 4499.6367\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.7151 - val_loss: 4701.6812\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.4185 - val_loss: 4617.2949\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.3178 - val_loss: 5143.4492\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.5203 - val_loss: 4549.5908\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.0522 - val_loss: 4806.4443\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.0756 - val_loss: 4912.6333\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.1526 - val_loss: 4650.8896\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.6880 - val_loss: 4952.7378\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.1431 - val_loss: 4309.6611\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.7664 - val_loss: 5031.5029\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.5684 - val_loss: 4340.8159\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.6847 - val_loss: 4092.0901\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.9401 - val_loss: 4451.4141\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.4028 - val_loss: 4132.6143\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.3261 - val_loss: 4812.8794\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.2653 - val_loss: 4436.5254\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.1625 - val_loss: 4534.8091\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.3812 - val_loss: 4159.3462\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 100.7414 - val_loss: 4092.0952\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.6048 - val_loss: 4300.5488\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.6340 - val_loss: 4724.2690\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.4682 - val_loss: 4089.5488\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 96.8522 - val_loss: 4455.0186\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.5502 - val_loss: 4487.4883\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.5339 - val_loss: 4952.7617\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.3637 - val_loss: 4549.8384\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.4125 - val_loss: 4367.3042\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.5106 - val_loss: 4380.4883\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.2114 - val_loss: 4337.6050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.3931 - val_loss: 4109.2432\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.1501 - val_loss: 4004.5808\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.9770 - val_loss: 4032.2358\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.7113 - val_loss: 4118.6050\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.5738 - val_loss: 4003.7637\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.2971 - val_loss: 4014.8088\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.6730 - val_loss: 3783.7766\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.5215 - val_loss: 4526.1987\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.2403 - val_loss: 3525.3665\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.1223 - val_loss: 3826.3535\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.3773 - val_loss: 3965.1553\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 94.6783 - val_loss: 4223.6040\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.0914 - val_loss: 4263.4272\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.0556 - val_loss: 4194.7002\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.9867 - val_loss: 4479.2505\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 101.3279 - val_loss: 4792.7388\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1123 - val_loss: 4576.8979\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.3445 - val_loss: 4684.1704\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.1872 - val_loss: 4592.5796\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.9723 - val_loss: 4727.7998\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.3527 - val_loss: 4722.5303\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8152 - val_loss: 4762.2534\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.9211 - val_loss: 4564.1079\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.1703 - val_loss: 4631.3789\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.1799 - val_loss: 4679.9971\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.9822 - val_loss: 4404.5698\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.1783 - val_loss: 4657.3867\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.6413 - val_loss: 4668.3218\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.3137 - val_loss: 4866.1992\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.5576 - val_loss: 4490.1885\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.9128 - val_loss: 4901.7251\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.8478 - val_loss: 4274.1064\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.9243 - val_loss: 4492.0034\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.1539 - val_loss: 4005.2739\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.5954 - val_loss: 4568.1997\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.5898 - val_loss: 4981.6177\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.0143 - val_loss: 4572.3516\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.5184 - val_loss: 4681.2451\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.7513 - val_loss: 4938.9883\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.9323 - val_loss: 4939.8472\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.1734 - val_loss: 4564.3350\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.3032 - val_loss: 5001.4961\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.3966 - val_loss: 4642.9438\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.6297 - val_loss: 4729.7168\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8309 - val_loss: 4825.2017\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.4665 - val_loss: 4323.1538\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.6263 - val_loss: 4427.3550\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.6420 - val_loss: 4320.1113\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.3163 - val_loss: 4468.2446\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.8629 - val_loss: 4733.1035\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.5719 - val_loss: 4730.6436\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 92.3448 - val_loss: 4630.5889\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9945 - val_loss: 4488.7285\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.3156 - val_loss: 4992.4028\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.6469 - val_loss: 5006.4727\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1603 - val_loss: 4489.1768\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.0073 - val_loss: 4367.0352\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.3112 - val_loss: 3811.9468\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.2947 - val_loss: 4205.7734\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.8944 - val_loss: 4737.3394\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.8144 - val_loss: 4707.8887\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.4320 - val_loss: 5101.8823\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.2650 - val_loss: 4641.3970\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.2961 - val_loss: 4811.8413\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.5083 - val_loss: 4981.0996\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.8475 - val_loss: 4612.4922\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.6462 - val_loss: 4833.4292\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.8433 - val_loss: 4827.5356\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.8972 - val_loss: 4857.4102\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.6206 - val_loss: 4730.3311\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.6996 - val_loss: 4576.0508\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.3916 - val_loss: 4977.9326\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.1633 - val_loss: 4954.9751\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.5839 - val_loss: 5137.6602\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.1254 - val_loss: 5189.7993\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.0357 - val_loss: 4838.9258\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.1393 - val_loss: 4859.3477\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9514 - val_loss: 4867.8564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.1999 - val_loss: 4482.8716\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8017 - val_loss: 4839.0220\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.7475 - val_loss: 4426.8711\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.7139 - val_loss: 4860.3062\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.6486 - val_loss: 5115.5889\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.0346 - val_loss: 4508.4131\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.2037 - val_loss: 4484.7573\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.7067 - val_loss: 4840.1167\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.9479 - val_loss: 4682.5630\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.8272 - val_loss: 4730.8369\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.7430 - val_loss: 4902.7637\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.7785 - val_loss: 5295.8594\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.4094 - val_loss: 4086.0068\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.0507 - val_loss: 5001.3076\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.9764 - val_loss: 4578.4292\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 90.6724 - val_loss: 4733.4468\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.5523 - val_loss: 5115.5034\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.4276 - val_loss: 4439.3330\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.6288 - val_loss: 4531.4004\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.3178 - val_loss: 4978.5981\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.0557 - val_loss: 5211.2930\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.8440 - val_loss: 5264.6792\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.8580 - val_loss: 4406.2373\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.6738 - val_loss: 4411.2427\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.7665 - val_loss: 4575.7822\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.1155 - val_loss: 4867.8564\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.4327 - val_loss: 4915.8716\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.4379 - val_loss: 4367.2314\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.3992 - val_loss: 4795.6445\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 117.0104 - val_loss: 4000.3506\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.3882 - val_loss: 4500.6924\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.4797 - val_loss: 4236.2007\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 103.7015 - val_loss: 4365.2305\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.7104 - val_loss: 4598.0527\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.2058 - val_loss: 4166.1704\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.7906 - val_loss: 4281.4541\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.4255 - val_loss: 4420.8921\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.5762 - val_loss: 4902.7402\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.8713 - val_loss: 4568.1270\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.1050 - val_loss: 4768.8989\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.0404 - val_loss: 4558.4927\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.3170 - val_loss: 4741.7739\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.9555 - val_loss: 4205.9111\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.8067 - val_loss: 4570.2266\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.7598 - val_loss: 4480.0586\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.3436 - val_loss: 4761.2305\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.5936 - val_loss: 4240.7617\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.0592 - val_loss: 4500.1709\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 96.1151 - val_loss: 4141.1392\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.3214 - val_loss: 3968.0500\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.2178 - val_loss: 4298.7568\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.7770 - val_loss: 3853.2087\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.0594 - val_loss: 4553.7939\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.9347 - val_loss: 4178.1050\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.7827 - val_loss: 4703.8896\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.6107 - val_loss: 4625.8481\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.8409 - val_loss: 4703.5894\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1217 - val_loss: 4353.1528\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.6315 - val_loss: 4473.2598\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.5961 - val_loss: 4294.3877\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.6047 - val_loss: 4469.7739\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.7036 - val_loss: 4574.2427\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.2706 - val_loss: 4043.0566\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.3910 - val_loss: 4137.4385\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.2334 - val_loss: 4430.4385\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.0895 - val_loss: 4836.3457\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.7897 - val_loss: 4448.6914\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.1184 - val_loss: 4198.1938\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.5544 - val_loss: 4298.9570\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.5973 - val_loss: 4419.5669\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.5498 - val_loss: 3779.0530\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.7944 - val_loss: 5091.4102\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.5072 - val_loss: 4672.3643\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.1611 - val_loss: 4525.8896\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 107.2966 - val_loss: 4708.2520\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.7281 - val_loss: 4858.7808\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.6499 - val_loss: 4786.6128\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.0137 - val_loss: 4854.3477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.9046 - val_loss: 4346.9072\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.0851 - val_loss: 4736.6865\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.0393 - val_loss: 4205.5278\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9669 - val_loss: 4532.7607\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.7171 - val_loss: 3944.5203\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.5606 - val_loss: 4625.6289\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.3883 - val_loss: 4082.9485\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.5425 - val_loss: 4462.2651\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 86.3248 - val_loss: 4241.7480\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.8251 - val_loss: 4542.1025\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.8351 - val_loss: 4522.5015\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.2423 - val_loss: 4633.7515\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.2821 - val_loss: 4752.1719\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.7924 - val_loss: 4749.4819\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.7757 - val_loss: 4141.1934\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.9795 - val_loss: 4468.5659\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.0884 - val_loss: 4404.9170\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.8321 - val_loss: 4686.9629\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.8655 - val_loss: 4064.4355\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.8045 - val_loss: 3809.5725\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.5259 - val_loss: 3908.3667\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.7459 - val_loss: 4179.7319\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.0104 - val_loss: 4491.7075\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.4997 - val_loss: 4467.1978\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.3037 - val_loss: 4650.6606\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.1037 - val_loss: 4895.0337\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.1118 - val_loss: 4661.6426\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.7987 - val_loss: 3796.6543\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 100.7183 - val_loss: 3751.0413\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.7066 - val_loss: 3248.4138\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.8021 - val_loss: 2972.9468\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.8924 - val_loss: 3702.3384\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9920 - val_loss: 3840.1506\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.3139 - val_loss: 3358.4458\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.1310 - val_loss: 3025.1719\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.2707 - val_loss: 3574.2456\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.8843 - val_loss: 3604.3843\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.9220 - val_loss: 3599.6790\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 103.4148 - val_loss: 3675.7014\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.7410 - val_loss: 4021.5225\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.3088 - val_loss: 3922.8267\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.3126 - val_loss: 3787.1396\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.3102 - val_loss: 4290.7158\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.4395 - val_loss: 4191.5352\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.2277 - val_loss: 4321.5381\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.0888 - val_loss: 4391.2695\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.7709 - val_loss: 3837.2439\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.9654 - val_loss: 4202.9321\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.5623 - val_loss: 3610.6299\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.7220 - val_loss: 3945.3027\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.2346 - val_loss: 3738.9746\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.0567 - val_loss: 3992.0422\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.1935 - val_loss: 3928.3262\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9045 - val_loss: 3874.4241\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.0334 - val_loss: 3955.2366\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.7832 - val_loss: 3860.2974\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8505 - val_loss: 3913.9895\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.0471 - val_loss: 4204.1201\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.5430 - val_loss: 3667.0864\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9501 - val_loss: 3767.3552\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.4936 - val_loss: 3980.9365\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.4616 - val_loss: 3979.0193\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.7547 - val_loss: 3496.2095\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.5631 - val_loss: 3548.9243\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.5813 - val_loss: 3609.0874\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.5735 - val_loss: 4075.6199\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 94.8054 - val_loss: 3856.7661\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.8923 - val_loss: 4158.0933\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.5003 - val_loss: 4290.8491\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.5449 - val_loss: 3747.0623\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.2958 - val_loss: 3755.9993\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.9724 - val_loss: 3586.0547\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.1885 - val_loss: 3296.2957\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.8790 - val_loss: 3916.7646\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.5420 - val_loss: 4169.9365\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.1421 - val_loss: 4028.8635\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.7257 - val_loss: 4729.4312\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.8954 - val_loss: 4485.1455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.5511 - val_loss: 4279.4785\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.3424 - val_loss: 4549.0981\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.6985 - val_loss: 4628.2896\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.0322 - val_loss: 4808.7012\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.0980 - val_loss: 4162.0840\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.3921 - val_loss: 4710.8311\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.4736 - val_loss: 4788.0024\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.7316 - val_loss: 4152.5552\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.3039 - val_loss: 4937.3926\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.4501 - val_loss: 4357.6089\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.7667 - val_loss: 4353.0200\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.8038 - val_loss: 4129.7671\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.2841 - val_loss: 4623.6729\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.8398 - val_loss: 4425.6978\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.4190 - val_loss: 4662.6987\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.3767 - val_loss: 4573.0259\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.5393 - val_loss: 4805.2456\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.1216 - val_loss: 4473.9004\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.6666 - val_loss: 4880.3828\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.6495 - val_loss: 4965.7275\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.4664 - val_loss: 4839.9727\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.1413 - val_loss: 4842.9258\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.8407 - val_loss: 5055.0532\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.7206 - val_loss: 4821.2061\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.6777 - val_loss: 5015.3755\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.5374 - val_loss: 4770.7607\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.1236 - val_loss: 4738.3516\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.2878 - val_loss: 5007.4038\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.9097 - val_loss: 4988.3955\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.3906 - val_loss: 4659.0127\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.1046 - val_loss: 4962.0723\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.6783 - val_loss: 4757.5288\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 112.1942 - val_loss: 5107.8306\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.1235 - val_loss: 6286.1655\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 198.2775 - val_loss: 3610.3577\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.8579 - val_loss: 3953.7449\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 104.8305 - val_loss: 4050.7136\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.3037 - val_loss: 3661.5129\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.1652 - val_loss: 3615.4402\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.3561 - val_loss: 3746.1135\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.5760 - val_loss: 3752.8064\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.6662 - val_loss: 3389.8667\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.8224 - val_loss: 3757.9700\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 86.9074 - val_loss: 3951.8547\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.0592 - val_loss: 3973.3870\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.5976 - val_loss: 3925.3704\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.5536 - val_loss: 3655.3652\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.6152 - val_loss: 3591.1638\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 110.6796 - val_loss: 4053.5750\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 113.0631 - val_loss: 4530.5498\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.1749 - val_loss: 4166.3320\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.3219 - val_loss: 4483.2373\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.5105 - val_loss: 4549.7388\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.3088 - val_loss: 4854.0112\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 103.0670 - val_loss: 4644.6680\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.8390 - val_loss: 4677.9736\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.1489 - val_loss: 4743.8726\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.8636 - val_loss: 4341.7207\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.9192 - val_loss: 4461.7144\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.9804 - val_loss: 4296.8877\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.9624 - val_loss: 4423.8857\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.4265 - val_loss: 4049.6313\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.2689 - val_loss: 3367.0747\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.9919 - val_loss: 4113.3594\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.6182 - val_loss: 4664.8315\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.4446 - val_loss: 3310.4355\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 112.1320 - val_loss: 3717.8494\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.3706 - val_loss: 3378.3306\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.7926 - val_loss: 4157.2280\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.9321 - val_loss: 4376.2500\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 100.6718 - val_loss: 3982.5896\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.3634 - val_loss: 4226.0234\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.2017 - val_loss: 4348.8247\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.3461 - val_loss: 4017.2480\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.3051 - val_loss: 3771.1648\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9372 - val_loss: 3962.2688\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.2387 - val_loss: 4310.3843\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.3649 - val_loss: 4004.1042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.0547 - val_loss: 3695.8223\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.7445 - val_loss: 3781.2493\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9073 - val_loss: 3611.3452\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9824 - val_loss: 3676.1675\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.4295 - val_loss: 3694.9482\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.8233 - val_loss: 3662.4385\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.1076 - val_loss: 4151.5825\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.5856 - val_loss: 3662.6431\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.2157 - val_loss: 3449.9651\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.2572 - val_loss: 3941.8301\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.9467 - val_loss: 3875.9578\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.0016 - val_loss: 3561.3931\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.3356 - val_loss: 4012.6963\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.4134 - val_loss: 3765.6975\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.6688 - val_loss: 3706.5400\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 84.7272 - val_loss: 3463.1816\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.6297 - val_loss: 3685.2659\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.0897 - val_loss: 3055.1902\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.7230 - val_loss: 3239.0410\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.0280 - val_loss: 3071.2510\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.9703 - val_loss: 3095.8386\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.4569 - val_loss: 3007.7339\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.0954 - val_loss: 3150.5508\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.1473 - val_loss: 3563.6350\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.6486 - val_loss: 3103.0916\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.4866 - val_loss: 3000.9429\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.3414 - val_loss: 3313.0503\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.0976 - val_loss: 3405.4880\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.4533 - val_loss: 2929.4546\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.1493 - val_loss: 2914.1135\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.9442 - val_loss: 3245.9719\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.7277 - val_loss: 2926.7703\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.6623 - val_loss: 2995.5996\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.0994 - val_loss: 3087.1772\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.0438 - val_loss: 2680.4534\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 87.0065 - val_loss: 2873.2673\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.8190 - val_loss: 2732.7869\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.4665 - val_loss: 3116.8145\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.4953 - val_loss: 3166.9822\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.8880 - val_loss: 3194.1360\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.6513 - val_loss: 2886.9980\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.0370 - val_loss: 2982.9771\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 85.6075 - val_loss: 2603.9795\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9584 - val_loss: 2885.5176\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.0444 - val_loss: 2941.3855\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.8451 - val_loss: 2951.9844\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.9371 - val_loss: 3115.6653\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.1016 - val_loss: 3253.4619\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.6788 - val_loss: 3234.7637\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9763 - val_loss: 3640.2854\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.9037 - val_loss: 3528.1987\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.2813 - val_loss: 3631.7517\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.1900 - val_loss: 3599.2354\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.5970 - val_loss: 4169.9116\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.3997 - val_loss: 4634.0430\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 94.9295 - val_loss: 3957.0308\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.9485 - val_loss: 4153.9956\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8656 - val_loss: 4488.8350\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.1396 - val_loss: 4050.9558\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.6165 - val_loss: 3746.2974\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.0416 - val_loss: 4265.0493\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.5538 - val_loss: 4175.7271\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.7276 - val_loss: 4385.0503\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.6403 - val_loss: 3752.7380\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.7370 - val_loss: 4148.8545\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.2083 - val_loss: 4315.9253\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.6905 - val_loss: 4715.0186\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.2393 - val_loss: 4069.8843\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.8147 - val_loss: 4179.7827\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.4706 - val_loss: 4119.0859\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8510 - val_loss: 4661.9990\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 107.4035 - val_loss: 4660.9248\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.5729 - val_loss: 4395.6924\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.2828 - val_loss: 4504.6074\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.1933 - val_loss: 4315.1436\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.5090 - val_loss: 4653.1885\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.5750 - val_loss: 4567.3540\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 102.3506 - val_loss: 2416.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 107.5964 - val_loss: 2425.1677\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.3583 - val_loss: 2781.3145\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.8005 - val_loss: 2503.9797\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 86.1175 - val_loss: 2352.7583\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.3739 - val_loss: 2434.0188\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 88.0630 - val_loss: 2475.3193\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.9790 - val_loss: 2540.9790\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 85.8199 - val_loss: 2465.9065\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 91.1434 - val_loss: 2219.7239\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 95.6065 - val_loss: 2210.0161\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.4036 - val_loss: 2842.0500\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.9571 - val_loss: 3081.1309\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.6511 - val_loss: 2849.0066\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.1057 - val_loss: 2578.1125\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.5606 - val_loss: 2597.9814\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.0897 - val_loss: 2925.2144\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.7694 - val_loss: 2682.4927\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.0750 - val_loss: 2945.3682\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.8305 - val_loss: 2538.7483\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.3976 - val_loss: 2562.3176\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.2199 - val_loss: 2615.1309\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.0849 - val_loss: 2657.9436\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 79.9081 - val_loss: 2682.4543\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.8248 - val_loss: 2628.0547\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.8653 - val_loss: 2715.0913\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.0141 - val_loss: 2735.3806\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.8570 - val_loss: 3093.0854\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.4669 - val_loss: 2977.4775\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.3534 - val_loss: 3123.7942\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.4301 - val_loss: 2707.0701\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.6867 - val_loss: 2953.7874\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.4963 - val_loss: 3221.3848\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.1707 - val_loss: 3231.8345\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.6588 - val_loss: 2606.5254\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9075 - val_loss: 2874.6943\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.3042 - val_loss: 3027.5479\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.4407 - val_loss: 3029.6328\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.2373 - val_loss: 2760.8850\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.9620 - val_loss: 2710.7903\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.2868 - val_loss: 2992.8079\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.9650 - val_loss: 3078.6836\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.3358 - val_loss: 3294.1865\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.8915 - val_loss: 2809.1990\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.4052 - val_loss: 3016.4360\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.3365 - val_loss: 3115.1699\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.7055 - val_loss: 3161.7109\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.8298 - val_loss: 3284.5244\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.1212 - val_loss: 3377.1226\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.4700 - val_loss: 3210.6628\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.6465 - val_loss: 3224.1204\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.3999 - val_loss: 3358.5461\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1021 - val_loss: 3433.7637\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.5119 - val_loss: 3365.4768\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.9193 - val_loss: 3357.1641\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.5592 - val_loss: 3420.3765\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.0364 - val_loss: 3061.2522\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.4678 - val_loss: 3175.4990\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.8130 - val_loss: 3252.7932\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.4686 - val_loss: 3450.2371\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.3637 - val_loss: 3356.8479\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.9629 - val_loss: 3288.4980\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.2312 - val_loss: 3618.0200\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.9054 - val_loss: 3246.7974\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.2323 - val_loss: 3469.7949\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.6839 - val_loss: 3311.4666\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.3582 - val_loss: 3420.0791\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.2588 - val_loss: 3234.0278\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.7885 - val_loss: 3339.1548\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.4792 - val_loss: 3341.1614\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.0926 - val_loss: 3226.7144\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.2825 - val_loss: 3082.7671\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.4440 - val_loss: 2714.7483\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.7474 - val_loss: 3020.7839\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.6834 - val_loss: 3045.7417\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.3450 - val_loss: 3018.6643\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.0980 - val_loss: 3383.1348\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.5095 - val_loss: 3088.4902\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.5668 - val_loss: 3453.5212\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.6243 - val_loss: 3091.4495\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.4614 - val_loss: 2997.8418\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.6822 - val_loss: 3023.4197\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.1385 - val_loss: 2685.6099\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.3824 - val_loss: 3037.8157\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.2760 - val_loss: 2910.4622\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.8265 - val_loss: 3195.4941\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.9392 - val_loss: 3265.6553\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.8392 - val_loss: 3179.1445\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.9482 - val_loss: 2921.3887\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.8182 - val_loss: 2811.3901\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.6385 - val_loss: 2928.2390\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.6240 - val_loss: 2694.9939\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 88.4356 - val_loss: 3373.6023\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.5143 - val_loss: 3328.5732\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.1002 - val_loss: 3211.9421\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.8739 - val_loss: 3326.2012\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.7588 - val_loss: 3328.7158\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.0705 - val_loss: 3223.8496\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.7836 - val_loss: 3296.8425\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.3925 - val_loss: 3466.7910\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.2885 - val_loss: 3259.6313\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.9019 - val_loss: 3726.4082\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.6498 - val_loss: 3335.0510\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.0614 - val_loss: 2981.5874\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.4892 - val_loss: 3097.8547\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.9044 - val_loss: 3344.9197\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.1974 - val_loss: 3235.3989\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.2585 - val_loss: 3182.8940\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 85.9875 - val_loss: 3164.2979\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.2302 - val_loss: 3233.6812\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.7925 - val_loss: 3669.5134\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.3434 - val_loss: 3401.3813\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.6876 - val_loss: 3406.4153\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.4188 - val_loss: 3262.6377\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.7094 - val_loss: 3599.9707\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.3469 - val_loss: 3253.2559\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.5289 - val_loss: 3277.6252\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.5875 - val_loss: 3136.8843\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.8210 - val_loss: 3024.6785\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.2897 - val_loss: 2998.7483\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9137 - val_loss: 3273.8228\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.9280 - val_loss: 3539.4541\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.2038 - val_loss: 3098.2490\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.5841 - val_loss: 2930.2798\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.3439 - val_loss: 3286.9426\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 83.5325 - val_loss: 3410.9368\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.9011 - val_loss: 3062.4089\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.5823 - val_loss: 3533.7598\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 86.9282 - val_loss: 3606.4714\n",
      "Epoch 1141/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.8269 - val_loss: 3621.3828\n",
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.4533 - val_loss: 3663.6855\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.1218 - val_loss: 3170.0508\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.9732 - val_loss: 3814.9155\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.7128 - val_loss: 3671.8818\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.5815 - val_loss: 3262.9697\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.5500 - val_loss: 3297.2480\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.3322 - val_loss: 3396.6948\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.4893 - val_loss: 3347.6682\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 81.9425 - val_loss: 3283.7761\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.5484 - val_loss: 3101.7688\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.0891 - val_loss: 3477.8188\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.2673 - val_loss: 3225.5527\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.8783 - val_loss: 2843.7261\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.7484 - val_loss: 3407.3726\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.4500 - val_loss: 3192.2888\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 81.3366 - val_loss: 3776.5261\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.8417 - val_loss: 3007.3586\n",
      "Epoch 1159/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.7088 - val_loss: 3269.8535\n",
      "Epoch 1160/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.3820 - val_loss: 2929.6736\n",
      "Epoch 1161/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.4063 - val_loss: 2796.2563\n",
      "Epoch 1162/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.8628 - val_loss: 3421.8916\n",
      "Epoch 1163/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 94.3466 - val_loss: 2921.4885\n",
      "Epoch 1164/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.5641 - val_loss: 2679.1079\n",
      "Epoch 1165/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.4951 - val_loss: 2832.5671\n",
      "Epoch 1166/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.9749 - val_loss: 3358.4958\n",
      "Epoch 1167/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 90.2779 - val_loss: 3060.7151\n",
      "Epoch 1168/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.2561 - val_loss: 3190.6855\n",
      "Epoch 1169/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.0939 - val_loss: 3121.1436\n",
      "Epoch 1170/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 85.1560 - val_loss: 3248.3157\n",
      "Epoch 1171/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.8416 - val_loss: 3134.7739\n",
      "Epoch 1172/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.4667 - val_loss: 2878.0352\n",
      "Epoch 1173/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.3527 - val_loss: 3056.5466\n",
      "Epoch 1174/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.3151 - val_loss: 2908.4724\n",
      "Epoch 1175/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.7150 - val_loss: 2610.5471\n",
      "Epoch 1176/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.1226 - val_loss: 3003.0696\n",
      "Epoch 1177/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 91.8815 - val_loss: 3130.0647\n",
      "Epoch 1178/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.4456 - val_loss: 3243.2578\n",
      "Epoch 1179/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.2404 - val_loss: 3407.9761\n",
      "Epoch 1180/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.8614 - val_loss: 3685.2761\n",
      "Epoch 1181/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.9064 - val_loss: 3847.8948\n",
      "Epoch 1182/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.7477 - val_loss: 3774.3762\n",
      "Epoch 1183/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9854 - val_loss: 3774.9448\n",
      "Epoch 1184/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.1194 - val_loss: 3615.0618\n",
      "Epoch 1185/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.6991 - val_loss: 3608.8333\n",
      "Epoch 1186/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.9866 - val_loss: 3637.1917\n",
      "Epoch 1187/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.6702 - val_loss: 2989.4453\n",
      "Epoch 1188/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.5098 - val_loss: 3281.7104\n",
      "Epoch 1189/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.9769 - val_loss: 3276.9766\n",
      "Epoch 1190/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 84.9262 - val_loss: 3519.1638\n",
      "Epoch 1191/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.9121 - val_loss: 3269.2917\n",
      "Epoch 1192/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.9482 - val_loss: 3085.2849\n",
      "Epoch 1193/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.4767 - val_loss: 3443.7812\n",
      "Epoch 1194/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.4768 - val_loss: 3329.9792\n",
      "Epoch 1195/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.6899 - val_loss: 3120.0566\n",
      "Epoch 1196/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.9379 - val_loss: 3541.3804\n",
      "Epoch 1197/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.8032 - val_loss: 3188.9907\n",
      "Epoch 1198/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.2025 - val_loss: 3377.4319\n",
      "Epoch 1199/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.0424 - val_loss: 3268.3828\n",
      "Epoch 1200/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.1548 - val_loss: 3111.4104\n",
      "Epoch 1201/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.5526 - val_loss: 3228.8025\n",
      "Epoch 1202/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.5264 - val_loss: 3050.9321\n",
      "Epoch 1203/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.8127 - val_loss: 3098.4541\n",
      "Epoch 1204/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.3909 - val_loss: 2802.0098\n",
      "Epoch 1205/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.4130 - val_loss: 2879.2668\n",
      "Epoch 1206/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.6985 - val_loss: 3372.5020\n",
      "Epoch 1207/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.5605 - val_loss: 3218.9382\n",
      "Epoch 1208/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8094 - val_loss: 3371.9011\n",
      "Epoch 1209/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.8030 - val_loss: 3387.0198\n",
      "Epoch 1210/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.9853 - val_loss: 3482.0952\n",
      "Epoch 1211/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.7336 - val_loss: 3425.8472\n",
      "Epoch 1212/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.2027 - val_loss: 3070.1758\n",
      "Epoch 1213/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.7519 - val_loss: 3411.3499\n",
      "Epoch 1214/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.2207 - val_loss: 3426.6848\n",
      "Epoch 1215/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.1966 - val_loss: 3528.6426\n",
      "Epoch 1216/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 92.2009 - val_loss: 3542.2195\n",
      "Epoch 1217/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.6573 - val_loss: 3821.3418\n",
      "Epoch 1218/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.2290 - val_loss: 4031.4875\n",
      "Epoch 1219/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.8955 - val_loss: 3778.9192\n",
      "Epoch 1220/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.2030 - val_loss: 4062.4495\n",
      "Epoch 1221/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.0909 - val_loss: 3242.4941\n",
      "Epoch 1222/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.9332 - val_loss: 2961.0974\n",
      "Epoch 1223/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.8374 - val_loss: 3847.7454\n",
      "Epoch 1224/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.4469 - val_loss: 3128.3455\n",
      "Epoch 1225/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.4244 - val_loss: 4053.9121\n",
      "Epoch 1226/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.5437 - val_loss: 3498.0161\n",
      "Epoch 1227/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.7681 - val_loss: 3569.0515\n",
      "Epoch 1228/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.0803 - val_loss: 4319.0913\n",
      "Epoch 1229/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1586 - val_loss: 2782.6902\n",
      "Epoch 1230/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.7267 - val_loss: 2910.6021\n",
      "Epoch 1231/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.9587 - val_loss: 3408.9966\n",
      "Epoch 1232/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.2848 - val_loss: 3529.1667\n",
      "Epoch 1233/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.3134 - val_loss: 3193.2537\n",
      "Epoch 1234/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 96.0555 - val_loss: 3088.9268\n",
      "Epoch 1235/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.8277 - val_loss: 3303.0137\n",
      "Epoch 1236/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.1679 - val_loss: 3336.8418\n",
      "Epoch 1237/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.5738 - val_loss: 3641.8616\n",
      "Epoch 1238/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.5302 - val_loss: 3513.1985\n",
      "Epoch 1239/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.1384 - val_loss: 3643.4673\n",
      "Epoch 1240/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.1274 - val_loss: 3839.2092\n",
      "Epoch 1241/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.6028 - val_loss: 4085.5605\n",
      "Epoch 1242/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.5004 - val_loss: 4245.1060\n",
      "Epoch 1243/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.6558 - val_loss: 3766.4407\n",
      "Epoch 1244/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.5042 - val_loss: 4180.6650\n",
      "Epoch 1245/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.7089 - val_loss: 3951.5488\n",
      "Epoch 1246/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.8333 - val_loss: 4042.0234\n",
      "Epoch 1247/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.2861 - val_loss: 3783.4668\n",
      "Epoch 1248/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.3399 - val_loss: 3267.5432\n",
      "Epoch 1249/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.3438 - val_loss: 3460.7605\n",
      "Epoch 1250/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.9498 - val_loss: 3656.4519\n",
      "Epoch 1251/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.8343 - val_loss: 3856.0354\n",
      "Epoch 1252/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.7457 - val_loss: 3964.0874\n",
      "Epoch 1253/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.9977 - val_loss: 4083.5010\n",
      "Epoch 1254/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 86.2369 - val_loss: 3729.0100\n",
      "Epoch 1255/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.0723 - val_loss: 3716.2456\n",
      "Epoch 1256/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.6440 - val_loss: 3612.5212\n",
      "Epoch 1257/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.5961 - val_loss: 3833.2268\n",
      "Epoch 1258/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.5061 - val_loss: 4062.3025\n",
      "Epoch 1259/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.6585 - val_loss: 3915.2500\n",
      "Epoch 1260/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.0730 - val_loss: 3491.6719\n",
      "Epoch 1261/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 89.2137 - val_loss: 3692.1230\n",
      "Epoch 1262/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 85.7129 - val_loss: 3684.4626\n",
      "Epoch 1263/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 86.6948 - val_loss: 3543.1672\n",
      "Epoch 1264/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 85.5716 - val_loss: 3709.2349\n",
      "Epoch 1265/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.6222 - val_loss: 3531.7327\n",
      "Epoch 1266/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.7754 - val_loss: 3157.3838\n",
      "Epoch 1267/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.9177 - val_loss: 3526.5178\n",
      "Epoch 1268/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.6470 - val_loss: 3621.5173\n",
      "Epoch 1269/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.6381 - val_loss: 3532.2324\n",
      "Epoch 1270/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.2470 - val_loss: 3458.2031\n",
      "Epoch 1271/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.9875 - val_loss: 3410.9351\n",
      "Epoch 1272/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.4263 - val_loss: 3485.6155\n",
      "Epoch 1273/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.0783 - val_loss: 3242.5547\n",
      "Epoch 1274/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 87.8648 - val_loss: 3291.9060\n",
      "Epoch 1275/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.7054 - val_loss: 3601.7866\n",
      "Epoch 1276/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.1118 - val_loss: 3804.3428\n",
      "Epoch 1277/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.5824 - val_loss: 3620.0000\n",
      "Epoch 1278/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.1069 - val_loss: 3029.4775\n",
      "Epoch 1279/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.6030 - val_loss: 3540.3865\n",
      "Epoch 1280/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.6928 - val_loss: 3072.3848\n",
      "Epoch 1281/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.0657 - val_loss: 3479.6775\n",
      "Epoch 1282/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 81.4625 - val_loss: 3191.3926\n",
      "Epoch 1283/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.4417 - val_loss: 3374.1333\n",
      "Epoch 1284/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 81.9927 - val_loss: 3870.7307\n",
      "Epoch 1285/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.6706 - val_loss: 3692.0273\n",
      "Epoch 1286/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 86.8636 - val_loss: 3418.3848\n",
      "Epoch 1287/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 82.8427 - val_loss: 3415.1758\n",
      "Epoch 1288/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.5455 - val_loss: 3368.3865\n",
      "Epoch 1289/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.9824 - val_loss: 3449.7288\n",
      "Epoch 1290/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.3674 - val_loss: 3137.4910\n",
      "Epoch 1291/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.8594 - val_loss: 3499.7776\n",
      "Epoch 1292/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.6073 - val_loss: 3437.1895\n",
      "Epoch 1293/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.8046 - val_loss: 3337.6423\n",
      "Epoch 1294/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.4232 - val_loss: 3462.7466\n",
      "Epoch 1295/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.7626 - val_loss: 3870.9089\n",
      "Epoch 1296/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 106.6212 - val_loss: 3666.4316\n",
      "Epoch 1297/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.7045 - val_loss: 3646.0767\n",
      "Epoch 1298/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.3338 - val_loss: 3524.2229\n",
      "Epoch 1299/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.5559 - val_loss: 3540.6467\n",
      "Epoch 1300/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.6523 - val_loss: 3401.1848\n",
      "Epoch 1301/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.6238 - val_loss: 4116.5386\n",
      "Epoch 1302/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.3203 - val_loss: 3232.1279\n",
      "Epoch 1303/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.6416 - val_loss: 3231.3979\n",
      "Epoch 1304/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.4956 - val_loss: 3217.6096\n",
      "Epoch 1305/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.2249 - val_loss: 3381.2988\n",
      "Epoch 1306/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.5743 - val_loss: 3684.0398\n",
      "Epoch 1307/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.0034 - val_loss: 3211.7659\n",
      "Epoch 1308/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.4726 - val_loss: 2998.4194\n",
      "Epoch 1309/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 92.1752 - val_loss: 3035.7515\n",
      "Epoch 1310/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.6603 - val_loss: 3355.5176\n",
      "Epoch 1311/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.9865 - val_loss: 3453.7842\n",
      "Epoch 1312/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.1614 - val_loss: 3423.4521\n",
      "Epoch 1313/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.9317 - val_loss: 3121.5020\n",
      "Epoch 1314/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.8725 - val_loss: 3001.3677\n",
      "Epoch 1315/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.9270 - val_loss: 2983.2605\n",
      "Epoch 1316/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.4789 - val_loss: 2758.4453\n",
      "Epoch 1317/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 85.4660 - val_loss: 2891.1658\n",
      "Epoch 1318/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.7339 - val_loss: 2573.8516\n",
      "Epoch 1319/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.9441 - val_loss: 2742.5608\n",
      "Epoch 1320/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 82.3450 - val_loss: 2796.0237\n",
      "Epoch 1321/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 83.8966 - val_loss: 3168.7383\n",
      "Epoch 1322/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.9396 - val_loss: 3192.6692\n",
      "Epoch 1323/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.5818 - val_loss: 3241.1248\n",
      "Epoch 1324/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.8339 - val_loss: 3410.3496\n",
      "Epoch 1325/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.0704 - val_loss: 3323.7004\n",
      "Epoch 1326/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.9979 - val_loss: 3292.6648\n",
      "Epoch 1327/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.4681 - val_loss: 3701.1641\n",
      "Epoch 1328/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.0103 - val_loss: 3296.2671\n",
      "Epoch 1329/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.5015 - val_loss: 3582.3872\n",
      "Epoch 1330/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.9101 - val_loss: 4188.7437\n",
      "Epoch 1331/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.4130 - val_loss: 4073.7510\n",
      "Epoch 1332/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.2260 - val_loss: 3644.0164\n",
      "Epoch 1333/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.7530 - val_loss: 3522.6013\n",
      "Epoch 1334/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 87.8280 - val_loss: 3545.4658\n",
      "Epoch 1335/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.8806 - val_loss: 3748.6587\n",
      "Epoch 1336/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.0823 - val_loss: 3803.2654\n",
      "Epoch 1337/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 87.3266 - val_loss: 3632.2493\n",
      "Epoch 1338/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 86.2726 - val_loss: 3697.5808\n",
      "Epoch 1339/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 85.3604 - val_loss: 3652.0176\n",
      "Epoch 1340/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.3859 - val_loss: 3964.5098\n",
      "Epoch 1341/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.4072 - val_loss: 4176.3652\n",
      "Epoch 1342/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.9137 - val_loss: 3816.1387\n",
      "Epoch 1343/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1609.1708 - val_loss: 3620.6423\n",
      "Epoch 1344/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 554.8213 - val_loss: 2531.5615\n",
      "Epoch 1345/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 129.3093 - val_loss: 3020.4214\n",
      "Epoch 1346/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.8385 - val_loss: 3112.4363\n",
      "Epoch 1347/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8835 - val_loss: 2934.4089\n",
      "Epoch 1348/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 105.8549 - val_loss: 3404.8196\n",
      "Epoch 1349/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 116.4870 - val_loss: 3768.4446\n",
      "Epoch 1350/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.9065 - val_loss: 3208.3599\n",
      "Epoch 1351/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.2818 - val_loss: 3810.6079\n",
      "Epoch 1352/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.5707 - val_loss: 3820.9517\n",
      "Epoch 1353/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.1314 - val_loss: 3589.8960\n",
      "Epoch 1354/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 89.2255 - val_loss: 3633.3464\n",
      "Epoch 1355/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.9888 - val_loss: 2931.7783\n",
      "Epoch 1356/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.5377 - val_loss: 3570.7676\n",
      "Epoch 1357/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.5819 - val_loss: 3453.0425\n",
      "Epoch 1358/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.8159 - val_loss: 4034.1584\n",
      "Epoch 1359/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.9615 - val_loss: 3295.9932\n",
      "Epoch 1360/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.5976 - val_loss: 3194.4788\n",
      "Epoch 1361/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 129.0582 - val_loss: 3563.7932\n",
      "Epoch 1362/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.1493 - val_loss: 3767.3542\n",
      "Epoch 1363/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.5621 - val_loss: 3606.1790\n",
      "Epoch 1364/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.0047 - val_loss: 3293.1167\n",
      "Epoch 1365/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.9676 - val_loss: 3810.6465\n",
      "Epoch 1366/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.9954 - val_loss: 3372.2334\n",
      "Epoch 1367/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.2806 - val_loss: 3366.6106\n",
      "Epoch 1368/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 105.9556 - val_loss: 2720.2734\n",
      "Epoch 1369/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 112.9027 - val_loss: 2994.7708\n",
      "Epoch 1370/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.0623 - val_loss: 3308.1699\n",
      "Epoch 1371/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 132.5160 - val_loss: 4152.2412\n",
      "Epoch 1372/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 156.5961 - val_loss: 2632.3857\n",
      "Epoch 1373/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.5984 - val_loss: 2985.9395\n",
      "Epoch 1374/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.0429 - val_loss: 3581.6333\n",
      "Epoch 1375/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.7798 - val_loss: 3449.9580\n",
      "Epoch 1376/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.4617 - val_loss: 2916.1543\n",
      "Epoch 1377/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 94.2181 - val_loss: 3213.1885\n",
      "Epoch 1378/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 92.6994 - val_loss: 3285.1804\n",
      "Epoch 1379/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.7121 - val_loss: 3522.2329\n",
      "Epoch 1380/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.2931 - val_loss: 3753.6907\n",
      "Epoch 1381/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 114.0450 - val_loss: 3034.5088\n",
      "Epoch 1382/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 113.7127 - val_loss: 3191.5750\n",
      "Epoch 1383/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.2363 - val_loss: 3230.2190\n",
      "Epoch 1384/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.8046 - val_loss: 2701.2715\n",
      "Epoch 1385/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.2189 - val_loss: 3184.3171\n",
      "Epoch 1386/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.4932 - val_loss: 2978.0161\n",
      "Epoch 1387/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 99.8317 - val_loss: 2851.0898\n",
      "Epoch 1388/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.6019 - val_loss: 2974.3374\n",
      "Epoch 1389/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.0543 - val_loss: 3538.9656\n",
      "Epoch 1390/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 112.0362 - val_loss: 3126.6709\n",
      "Epoch 1391/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.2267 - val_loss: 2712.0242\n",
      "Epoch 1392/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.8158 - val_loss: 3710.3289\n",
      "Epoch 1393/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.5672 - val_loss: 2868.0981\n",
      "Epoch 1394/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.2524 - val_loss: 2805.9324\n",
      "Epoch 1395/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 103.0400 - val_loss: 3478.6165\n",
      "Epoch 1396/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 100.9688 - val_loss: 3157.3188\n",
      "Epoch 1397/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.0049 - val_loss: 2870.1187\n",
      "Epoch 1398/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 108.0571 - val_loss: 3297.1262\n",
      "Epoch 1399/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.3119 - val_loss: 2370.9346\n",
      "Epoch 1400/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.7733 - val_loss: 2372.5129\n",
      "Epoch 1401/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.6656 - val_loss: 2433.3718\n",
      "Epoch 1402/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.9131 - val_loss: 2526.8301\n",
      "Epoch 1403/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.0639 - val_loss: 2343.4768\n",
      "Epoch 1404/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.8275 - val_loss: 3233.2937\n",
      "Epoch 1405/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 97.9850 - val_loss: 2126.3728\n",
      "Epoch 1406/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.1745 - val_loss: 3102.9041\n",
      "Epoch 1407/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 105.1111 - val_loss: 3377.1743\n",
      "Epoch 1408/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.5776 - val_loss: 3549.2090\n",
      "Epoch 1409/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.0914 - val_loss: 4153.0054\n",
      "Epoch 1410/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.1313 - val_loss: 4278.6606\n",
      "Epoch 1411/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.8731 - val_loss: 3671.4443\n",
      "Epoch 1412/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9224 - val_loss: 4622.7979\n",
      "Epoch 1413/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.7803 - val_loss: 4017.1038\n",
      "Epoch 1414/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.6985 - val_loss: 3937.6230\n",
      "Epoch 1415/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 119.9143 - val_loss: 3509.6025\n",
      "Epoch 1416/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9340 - val_loss: 4352.1196\n",
      "Epoch 1417/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.7943 - val_loss: 4188.3906\n",
      "Epoch 1418/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.2808 - val_loss: 4400.1030\n",
      "Epoch 1419/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.4858 - val_loss: 4109.7588\n",
      "Epoch 1420/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.1203 - val_loss: 4292.6865\n",
      "Epoch 1421/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.3915 - val_loss: 4393.0605\n",
      "Epoch 1422/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.3922 - val_loss: 3652.4729\n",
      "Epoch 1423/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8962 - val_loss: 4035.2656\n",
      "Epoch 1424/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.5405 - val_loss: 4124.0767\n",
      "Epoch 1425/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 92.7042 - val_loss: 3693.6975\n",
      "Epoch 1426/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.8276 - val_loss: 3828.6611\n",
      "Epoch 1427/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 100.0731 - val_loss: 3970.2620\n",
      "Epoch 1428/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.9357 - val_loss: 4039.3010\n",
      "Epoch 1429/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.4051 - val_loss: 4112.4102\n",
      "Epoch 1430/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.4063 - val_loss: 4135.3477\n",
      "Epoch 1431/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 110.0266 - val_loss: 4062.1401\n",
      "Epoch 1432/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.1332 - val_loss: 3780.2061\n",
      "Epoch 1433/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 108.7527 - val_loss: 3299.3276\n",
      "Epoch 1434/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 112.1397 - val_loss: 3651.5239\n",
      "Epoch 1435/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.6415 - val_loss: 4079.3691\n",
      "Epoch 1436/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.4922 - val_loss: 4271.6465\n",
      "Epoch 1437/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.7762 - val_loss: 3750.9602\n",
      "Epoch 1438/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.7738 - val_loss: 3951.2202\n",
      "Epoch 1439/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.2709 - val_loss: 4565.1875\n",
      "Epoch 1440/10000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 108.4017 - val_loss: 4755.7222\n",
      "Epoch 1441/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 106.9364 - val_loss: 3893.4590\n",
      "Epoch 1442/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.2183 - val_loss: 4361.4932\n",
      "Epoch 1443/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.4589 - val_loss: 4558.2324\n",
      "Epoch 1444/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 113.5499 - val_loss: 4477.1040\n",
      "Epoch 1445/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.4906 - val_loss: 3992.4438\n",
      "Epoch 1446/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.7661 - val_loss: 4070.6025\n",
      "Epoch 1447/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.0314 - val_loss: 3904.7334\n",
      "Epoch 1448/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.2050 - val_loss: 3697.8269\n",
      "Epoch 1449/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 104.6660 - val_loss: 4022.5220\n",
      "Epoch 1450/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.6644 - val_loss: 4477.1187\n",
      "Epoch 1451/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 120.4977 - val_loss: 3765.8203\n",
      "Epoch 1452/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.3850 - val_loss: 3454.8247\n",
      "Epoch 1453/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.4674 - val_loss: 3243.7732\n",
      "Epoch 1454/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.0291 - val_loss: 3495.6685\n",
      "Epoch 1455/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.1434 - val_loss: 2855.4512\n",
      "Epoch 1456/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 127.3833 - val_loss: 3460.3113\n",
      "Epoch 1457/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.4835 - val_loss: 4213.9502\n",
      "Epoch 1458/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.5865 - val_loss: 4133.0220\n",
      "Epoch 1459/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.5916 - val_loss: 4011.1787\n",
      "Epoch 1460/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 112.9337 - val_loss: 3484.4558\n",
      "Epoch 1461/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.0572 - val_loss: 3740.1924\n",
      "Epoch 1462/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.7535 - val_loss: 3366.1631\n",
      "Epoch 1463/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.0964 - val_loss: 3619.7798\n",
      "Epoch 1464/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 112.4960 - val_loss: 4221.1792\n",
      "Epoch 1465/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 109.7771 - val_loss: 3346.3464\n",
      "Epoch 1466/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.7108 - val_loss: 3633.3794\n",
      "Epoch 1467/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.5047 - val_loss: 3766.6641\n",
      "Epoch 1468/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.7820 - val_loss: 3572.9717\n",
      "Epoch 1469/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.3118 - val_loss: 3448.4316\n",
      "Epoch 1470/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.6667 - val_loss: 3152.4595\n",
      "Epoch 1471/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 113.8464 - val_loss: 3227.2063\n",
      "Epoch 1472/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.1884 - val_loss: 3596.6272\n",
      "Epoch 1473/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.5375 - val_loss: 3942.7637\n",
      "Epoch 1474/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.9260 - val_loss: 3462.7949\n",
      "Epoch 1475/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 88.9905 - val_loss: 3614.4038\n",
      "Epoch 1476/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9854 - val_loss: 3588.0493\n",
      "Epoch 1477/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.4018 - val_loss: 4183.0542\n",
      "Epoch 1478/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9110 - val_loss: 3299.6646\n",
      "Epoch 1479/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1833 - val_loss: 3504.3545\n",
      "Epoch 1480/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.2120 - val_loss: 3878.8567\n",
      "Epoch 1481/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.6714 - val_loss: 3179.1277\n",
      "Epoch 1482/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.3771 - val_loss: 3141.6423\n",
      "Epoch 1483/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.8138 - val_loss: 4179.3994\n",
      "Epoch 1484/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 121.4846 - val_loss: 3812.8428\n",
      "Epoch 1485/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.8350 - val_loss: 3403.3845\n",
      "Epoch 1486/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 107.6159 - val_loss: 3204.0442\n",
      "Epoch 1487/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.7655 - val_loss: 3362.3967\n",
      "Epoch 1488/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.6235 - val_loss: 2816.5540\n",
      "Epoch 1489/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 106.3804 - val_loss: 3092.3420\n",
      "Epoch 1490/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.1133 - val_loss: 3445.3977\n",
      "Epoch 1491/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.9674 - val_loss: 3669.9265\n",
      "Epoch 1492/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.1476 - val_loss: 3279.9028\n",
      "Epoch 1493/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.5221 - val_loss: 3533.2957\n",
      "Epoch 1494/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.1637 - val_loss: 3027.0005\n",
      "Epoch 1495/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.1938 - val_loss: 3406.3303\n",
      "Epoch 1496/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.3506 - val_loss: 3076.5691\n",
      "Epoch 1497/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.7958 - val_loss: 3601.6006\n",
      "Epoch 1498/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.0002 - val_loss: 3574.2356\n",
      "Epoch 1499/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.7966 - val_loss: 3420.4304\n",
      "Epoch 1500/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9073 - val_loss: 4210.6177\n",
      "Epoch 1501/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 101.3602 - val_loss: 3628.2974\n",
      "Epoch 1502/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.8390 - val_loss: 4305.7573\n",
      "Epoch 1503/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.7619 - val_loss: 3942.5364\n",
      "Epoch 1504/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.0094 - val_loss: 4238.8247\n",
      "Epoch 1505/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 116.7018 - val_loss: 3908.6067\n",
      "Epoch 1506/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.1996 - val_loss: 3778.4551\n",
      "Epoch 1507/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.1636 - val_loss: 3123.8450\n",
      "Epoch 1508/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.8109 - val_loss: 4580.8413\n",
      "Epoch 1509/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.2190 - val_loss: 4244.5938\n",
      "Epoch 1510/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.9066 - val_loss: 4171.3447\n",
      "Epoch 1511/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.2629 - val_loss: 4227.6992\n",
      "Epoch 1512/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 105.5168 - val_loss: 4079.0469\n",
      "Epoch 1513/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.9750 - val_loss: 3699.3184\n",
      "Epoch 1514/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.1660 - val_loss: 4033.4797\n",
      "Epoch 1515/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.0988 - val_loss: 3697.1531\n",
      "Epoch 1516/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.7966 - val_loss: 3150.0781\n",
      "Epoch 1517/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.9571 - val_loss: 3485.9690\n",
      "Epoch 1518/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.6780 - val_loss: 3581.9604\n",
      "Epoch 1519/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.2200 - val_loss: 3845.5305\n",
      "Epoch 1520/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.3007 - val_loss: 4098.9863\n",
      "Epoch 1521/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.3408 - val_loss: 3391.4827\n",
      "Epoch 1522/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9936 - val_loss: 3725.4160\n",
      "Epoch 1523/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.4327 - val_loss: 3526.8386\n",
      "Epoch 1524/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.5514 - val_loss: 3853.9270\n",
      "Epoch 1525/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.9082 - val_loss: 3933.7642\n",
      "Epoch 1526/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.1340 - val_loss: 3284.3411\n",
      "Epoch 1527/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.0914 - val_loss: 3681.0432\n",
      "Epoch 1528/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.9684 - val_loss: 3809.2256\n",
      "Epoch 1529/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.4470 - val_loss: 3473.6807\n",
      "Epoch 1530/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.5501 - val_loss: 3340.3826\n",
      "Epoch 1531/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1724 - val_loss: 3315.3086\n",
      "Epoch 1532/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 113.2475 - val_loss: 3494.7119\n",
      "Epoch 1533/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.1888 - val_loss: 3016.9043\n",
      "Epoch 1534/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.5526 - val_loss: 3620.4561\n",
      "Epoch 1535/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1159 - val_loss: 3710.7104\n",
      "Epoch 1536/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9572 - val_loss: 3632.1077\n",
      "Epoch 1537/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.9607 - val_loss: 4447.6133\n",
      "Epoch 1538/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 177.4934 - val_loss: 229.6756\n",
      "Epoch 1539/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 747.6758 - val_loss: 3897.9995\n",
      "Epoch 1540/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 119.9495 - val_loss: 3199.0940\n",
      "Epoch 1541/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.9026 - val_loss: 3544.3438\n",
      "Epoch 1542/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 113.8077 - val_loss: 3916.0312\n",
      "Epoch 1543/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.2976 - val_loss: 2531.8542\n",
      "Epoch 1544/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.5656 - val_loss: 3320.8965\n",
      "Epoch 1545/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.2486 - val_loss: 2628.3494\n",
      "Epoch 1546/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 105.9229 - val_loss: 2546.1089\n",
      "Epoch 1547/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.0125 - val_loss: 3085.2954\n",
      "Epoch 1548/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.1830 - val_loss: 2764.8469\n",
      "Epoch 1549/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9585 - val_loss: 2727.9470\n",
      "Epoch 1550/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.8149 - val_loss: 3253.2092\n",
      "Epoch 1551/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8171 - val_loss: 3316.6096\n",
      "Epoch 1552/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 93.3880 - val_loss: 3501.8677\n",
      "Epoch 1553/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.8087 - val_loss: 3728.8354\n",
      "Epoch 1554/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1765 - val_loss: 3112.2793\n",
      "Epoch 1555/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.5279 - val_loss: 3359.2197\n",
      "Epoch 1556/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.3932 - val_loss: 3493.3105\n",
      "Epoch 1557/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.9369 - val_loss: 3727.0176\n",
      "Epoch 1558/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.5777 - val_loss: 3586.6484\n",
      "Epoch 1559/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.4900 - val_loss: 3351.0293\n",
      "Epoch 1560/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.8774 - val_loss: 3467.3652\n",
      "Epoch 1561/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.9781 - val_loss: 3432.5781\n",
      "Epoch 1562/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.2729 - val_loss: 3254.2090\n",
      "Epoch 1563/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1539 - val_loss: 3156.7188\n",
      "Epoch 1564/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.5110 - val_loss: 3194.0881\n",
      "Epoch 1565/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.2412 - val_loss: 3506.4944\n",
      "Epoch 1566/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.6683 - val_loss: 3469.9526\n",
      "Epoch 1567/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.5720 - val_loss: 2931.7925\n",
      "Epoch 1568/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.2721 - val_loss: 2949.3735\n",
      "Epoch 1569/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.2653 - val_loss: 3341.6880\n",
      "Epoch 1570/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 122.7651 - val_loss: 3684.8708\n",
      "Epoch 1571/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 128.1855 - val_loss: 3473.2593\n",
      "Epoch 1572/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 114.2210 - val_loss: 2893.8352\n",
      "Epoch 1573/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.9260 - val_loss: 3331.9814\n",
      "Epoch 1574/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 119.2306 - val_loss: 3336.3538\n",
      "Epoch 1575/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 118.1057 - val_loss: 3346.4651\n",
      "Epoch 1576/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 108.6589 - val_loss: 3435.1094\n",
      "Epoch 1577/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.3868 - val_loss: 3528.9448\n",
      "Epoch 1578/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.6800 - val_loss: 3425.8181\n",
      "Epoch 1579/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.0111 - val_loss: 3393.9104\n",
      "Epoch 1580/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.4099 - val_loss: 3815.6621\n",
      "Epoch 1581/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 135.1808 - val_loss: 2988.0740\n",
      "Epoch 1582/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 105.3631 - val_loss: 3457.2832\n",
      "Epoch 1583/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.2435 - val_loss: 3238.1365\n",
      "Epoch 1584/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.8283 - val_loss: 2949.5991\n",
      "Epoch 1585/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.0015 - val_loss: 3114.4148\n",
      "Epoch 1586/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.2486 - val_loss: 3176.8943\n",
      "Epoch 1587/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.2068 - val_loss: 3036.0068\n",
      "Epoch 1588/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.5387 - val_loss: 3198.3455\n",
      "Epoch 1589/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.9160 - val_loss: 2815.6699\n",
      "Epoch 1590/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.4817 - val_loss: 3340.3870\n",
      "Epoch 1591/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.4488 - val_loss: 3402.7986\n",
      "Epoch 1592/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.6525 - val_loss: 3681.3989\n",
      "Epoch 1593/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.2977 - val_loss: 4537.9043\n",
      "Epoch 1594/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 114.5593 - val_loss: 3159.5999\n",
      "Epoch 1595/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.0293 - val_loss: 4221.1680\n",
      "Epoch 1596/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.4828 - val_loss: 3516.3623\n",
      "Epoch 1597/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.2094 - val_loss: 3500.3345\n",
      "Epoch 1598/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.0000 - val_loss: 2805.7749\n",
      "Epoch 1599/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.0388 - val_loss: 2792.8647\n",
      "Epoch 1600/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8140 - val_loss: 3174.5825\n",
      "Epoch 1601/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.6748 - val_loss: 2967.5425\n",
      "Epoch 1602/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9882 - val_loss: 3023.1829\n",
      "Epoch 1603/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.2035 - val_loss: 3087.3296\n",
      "Epoch 1604/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.4405 - val_loss: 3233.6680\n",
      "Epoch 1605/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.2905 - val_loss: 3657.8494\n",
      "Epoch 1606/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.7578 - val_loss: 3244.9443\n",
      "Epoch 1607/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.6527 - val_loss: 4086.6328\n",
      "Epoch 1608/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.6645 - val_loss: 3478.2078\n",
      "Epoch 1609/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.7839 - val_loss: 3433.0002\n",
      "Epoch 1610/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.5163 - val_loss: 3804.1213\n",
      "Epoch 1611/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.2178 - val_loss: 3501.8379\n",
      "Epoch 1612/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.6528 - val_loss: 3526.9619\n",
      "Epoch 1613/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.4124 - val_loss: 3829.2832\n",
      "Epoch 1614/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 95.7075 - val_loss: 3299.0618\n",
      "Epoch 1615/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.7617 - val_loss: 3707.2507\n",
      "Epoch 1616/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.0213 - val_loss: 3086.6562\n",
      "Epoch 1617/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.1295 - val_loss: 3383.2737\n",
      "Epoch 1618/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.4990 - val_loss: 3489.6047\n",
      "Epoch 1619/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.9312 - val_loss: 3264.0010\n",
      "Epoch 1620/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.8928 - val_loss: 3484.6804\n",
      "Epoch 1621/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.5313 - val_loss: 3830.8125\n",
      "Epoch 1622/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.5850 - val_loss: 3840.3718\n",
      "Epoch 1623/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.9113 - val_loss: 4343.9238\n",
      "Epoch 1624/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.5561 - val_loss: 3917.0859\n",
      "Epoch 1625/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.6200 - val_loss: 3896.0916\n",
      "Epoch 1626/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.9495 - val_loss: 3745.8843\n",
      "Epoch 1627/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.1461 - val_loss: 3753.5605\n",
      "Epoch 1628/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.9914 - val_loss: 3632.7119\n",
      "Epoch 1629/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 93.1476 - val_loss: 3297.3862\n",
      "Epoch 1630/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.3772 - val_loss: 3492.9624\n",
      "Epoch 1631/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.3172 - val_loss: 3293.7734\n",
      "Epoch 1632/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.9631 - val_loss: 3769.2944\n",
      "Epoch 1633/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.6304 - val_loss: 3652.6848\n",
      "Epoch 1634/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.0667 - val_loss: 2959.3418\n",
      "Epoch 1635/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8275 - val_loss: 3853.4463\n",
      "Epoch 1636/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.6672 - val_loss: 3351.9219\n",
      "Epoch 1637/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 103.2920 - val_loss: 2451.3984\n",
      "Epoch 1638/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.5595 - val_loss: 3792.9573\n",
      "Epoch 1639/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 105.2406 - val_loss: 3236.3379\n",
      "Epoch 1640/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.7599 - val_loss: 3386.4629\n",
      "Epoch 1641/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.9590 - val_loss: 3719.4775\n",
      "Epoch 1642/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.2793 - val_loss: 3380.3489\n",
      "Epoch 1643/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.1215 - val_loss: 3721.2937\n",
      "Epoch 1644/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.1355 - val_loss: 3966.7715\n",
      "Epoch 1645/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.7451 - val_loss: 3308.6682\n",
      "Epoch 1646/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1643 - val_loss: 2830.1125\n",
      "Epoch 1647/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.7602 - val_loss: 3304.1980\n",
      "Epoch 1648/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.4405 - val_loss: 3536.6709\n",
      "Epoch 1649/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.9978 - val_loss: 3051.7195\n",
      "Epoch 1650/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.2751 - val_loss: 3684.0161\n",
      "Epoch 1651/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.6599 - val_loss: 3164.2817\n",
      "Epoch 1652/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.2076 - val_loss: 3892.4900\n",
      "Epoch 1653/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.4370 - val_loss: 2913.2224\n",
      "Epoch 1654/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.8697 - val_loss: 3592.0471\n",
      "Epoch 1655/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 127.9545 - val_loss: 3738.6379\n",
      "Epoch 1656/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.7473 - val_loss: 3413.2932\n",
      "Epoch 1657/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.0048 - val_loss: 3448.0198\n",
      "Epoch 1658/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.5152 - val_loss: 3222.8110\n",
      "Epoch 1659/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.2184 - val_loss: 3762.7246\n",
      "Epoch 1660/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.2893 - val_loss: 3488.0278\n",
      "Epoch 1661/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.1405 - val_loss: 3317.1663\n",
      "Epoch 1662/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.6893 - val_loss: 2931.9465\n",
      "Epoch 1663/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.0949 - val_loss: 3406.1978\n",
      "Epoch 1664/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.5829 - val_loss: 3370.1455\n",
      "Epoch 1665/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.4943 - val_loss: 3283.9370\n",
      "Epoch 1666/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.3446 - val_loss: 3218.0364\n",
      "Epoch 1667/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.8090 - val_loss: 3030.3745\n",
      "Epoch 1668/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.1208 - val_loss: 3278.8022\n",
      "Epoch 1669/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.3345 - val_loss: 3090.0422\n",
      "Epoch 1670/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.4201 - val_loss: 3169.7610\n",
      "Epoch 1671/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1462 - val_loss: 3144.4045\n",
      "Epoch 1672/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.2132 - val_loss: 3517.9526\n",
      "Epoch 1673/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.1413 - val_loss: 3373.7747\n",
      "Epoch 1674/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.6286 - val_loss: 2999.3948\n",
      "Epoch 1675/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.9559 - val_loss: 3435.6208\n",
      "Epoch 1676/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.9995 - val_loss: 3474.3796\n",
      "Epoch 1677/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.5344 - val_loss: 3074.9670\n",
      "Epoch 1678/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.7965 - val_loss: 3282.6472\n",
      "Epoch 1679/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 88.3274 - val_loss: 3230.9910\n",
      "Epoch 1680/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.9626 - val_loss: 3745.9099\n",
      "Epoch 1681/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.1478 - val_loss: 3654.2141\n",
      "Epoch 1682/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 84.3924 - val_loss: 2998.6372\n",
      "Epoch 1683/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.4678 - val_loss: 2904.2927\n",
      "Epoch 1684/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.5777 - val_loss: 2998.2725\n",
      "Epoch 1685/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.2176 - val_loss: 3367.5886\n",
      "Epoch 1686/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.6253 - val_loss: 3847.1367\n",
      "Epoch 1687/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.2236 - val_loss: 3368.6672\n",
      "Epoch 1688/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.4422 - val_loss: 3087.9473\n",
      "Epoch 1689/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.1332 - val_loss: 3251.6113\n",
      "Epoch 1690/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.8019 - val_loss: 3028.1926\n",
      "Epoch 1691/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.2802 - val_loss: 3150.1270\n",
      "Epoch 1692/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.4417 - val_loss: 3077.8176\n",
      "Epoch 1693/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.4659 - val_loss: 3536.4136\n",
      "Epoch 1694/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 89.3302 - val_loss: 3061.0598\n",
      "Epoch 1695/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.9487 - val_loss: 3293.3306\n",
      "Epoch 1696/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.1245 - val_loss: 3429.9854\n",
      "Epoch 1697/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.7393 - val_loss: 3242.2805\n",
      "Epoch 1698/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 86.0851 - val_loss: 3569.7153\n",
      "Epoch 1699/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.2241 - val_loss: 3149.8416\n",
      "Epoch 1700/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.7656 - val_loss: 3003.7188\n",
      "Epoch 1701/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.3681 - val_loss: 3153.0071\n",
      "Epoch 1702/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.1917 - val_loss: 2900.2554\n",
      "Epoch 1703/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.0212 - val_loss: 3334.6284\n",
      "Epoch 1704/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.7711 - val_loss: 2825.2566\n",
      "Epoch 1705/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.8072 - val_loss: 3424.2324\n",
      "Epoch 1706/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 84.1566 - val_loss: 3163.0293\n",
      "Epoch 1707/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.0450 - val_loss: 3160.3716\n",
      "Epoch 1708/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.9483 - val_loss: 3154.7651\n",
      "Epoch 1709/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.8142 - val_loss: 3313.9219\n",
      "Epoch 1710/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 84.7777 - val_loss: 2790.8958\n",
      "Epoch 1711/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 86.4242 - val_loss: 3454.0874\n",
      "Epoch 1712/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 82.8658 - val_loss: 3105.3318\n",
      "Epoch 1713/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.9187 - val_loss: 2821.3755\n",
      "Epoch 1714/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.6482 - val_loss: 3219.4885\n",
      "Epoch 1715/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.1158 - val_loss: 2939.5166\n",
      "Epoch 1716/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.3488 - val_loss: 3180.3870\n",
      "Epoch 1717/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.6771 - val_loss: 3052.7598\n",
      "Epoch 1718/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.9220 - val_loss: 2999.4629\n",
      "Epoch 1719/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.2564 - val_loss: 3137.6733\n",
      "Epoch 1720/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.2280 - val_loss: 2153.1157\n",
      "Epoch 1721/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 116.2174 - val_loss: 2785.7742\n",
      "Epoch 1722/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.6461 - val_loss: 2589.7129\n",
      "Epoch 1723/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.2711 - val_loss: 2714.3474\n",
      "Epoch 1724/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.2087 - val_loss: 2533.4656\n",
      "Epoch 1725/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.4662 - val_loss: 2563.0623\n",
      "Epoch 1726/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.1457 - val_loss: 2338.2317\n",
      "Epoch 1727/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.7083 - val_loss: 2531.3433\n",
      "Epoch 1728/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.6720 - val_loss: 2449.1812\n",
      "Epoch 1729/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.7268 - val_loss: 2209.2249\n",
      "Epoch 1730/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.2085 - val_loss: 2146.9026\n",
      "Epoch 1731/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.0530 - val_loss: 2354.6741\n",
      "Epoch 1732/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.3539 - val_loss: 2311.3401\n",
      "Epoch 1733/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.7384 - val_loss: 2395.2766\n",
      "Epoch 1734/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.8594 - val_loss: 2567.8340\n",
      "Epoch 1735/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.1076 - val_loss: 2613.6802\n",
      "Epoch 1736/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.9007 - val_loss: 2517.8647\n",
      "Epoch 1737/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.2569 - val_loss: 2570.6614\n",
      "Epoch 1738/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.9350 - val_loss: 2662.6348\n",
      "Epoch 1739/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.9246 - val_loss: 2598.1465\n",
      "Epoch 1740/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.7434 - val_loss: 2520.8188\n",
      "Epoch 1741/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.4318 - val_loss: 2405.6914\n",
      "Epoch 1742/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.8186 - val_loss: 2647.3208\n",
      "Epoch 1743/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 85.2692 - val_loss: 2632.4617\n",
      "Epoch 1744/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.8745 - val_loss: 2693.2229\n",
      "Epoch 1745/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.8080 - val_loss: 2645.9460\n",
      "Epoch 1746/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.1122 - val_loss: 2608.3457\n",
      "Epoch 1747/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.4088 - val_loss: 2479.9963\n",
      "Epoch 1748/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.9646 - val_loss: 3000.4824\n",
      "Epoch 1749/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.8287 - val_loss: 2958.9231\n",
      "Epoch 1750/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.5457 - val_loss: 2557.4258\n",
      "Epoch 1751/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.4297 - val_loss: 2643.8875\n",
      "Epoch 1752/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1478 - val_loss: 2682.5042\n",
      "Epoch 1753/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.6313 - val_loss: 2669.2292\n",
      "Epoch 1754/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.4986 - val_loss: 2647.2856\n",
      "Epoch 1755/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.8698 - val_loss: 2826.6680\n",
      "Epoch 1756/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.7148 - val_loss: 2832.1370\n",
      "Epoch 1757/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.1978 - val_loss: 2307.3760\n",
      "Epoch 1758/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.0839 - val_loss: 2932.6047\n",
      "Epoch 1759/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.6395 - val_loss: 3226.8848\n",
      "Epoch 1760/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.8329 - val_loss: 2238.1436\n",
      "Epoch 1761/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.5095 - val_loss: 2443.2476\n",
      "Epoch 1762/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.7239 - val_loss: 2287.4883\n",
      "Epoch 1763/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.3904 - val_loss: 2497.9771\n",
      "Epoch 1764/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.2692 - val_loss: 2429.0781\n",
      "Epoch 1765/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.4587 - val_loss: 2808.0513\n",
      "Epoch 1766/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.0842 - val_loss: 2406.8210\n",
      "Epoch 1767/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.1965 - val_loss: 2966.1348\n",
      "Epoch 1768/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.7993 - val_loss: 3095.8679\n",
      "Epoch 1769/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.1845 - val_loss: 2896.4338\n",
      "Epoch 1770/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 104.7799 - val_loss: 2852.6895\n",
      "Epoch 1771/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.6108 - val_loss: 2888.8989\n",
      "Epoch 1772/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 104.4476 - val_loss: 2786.7400\n",
      "Epoch 1773/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 104.3665 - val_loss: 2972.7234\n",
      "Epoch 1774/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.5021 - val_loss: 2925.4692\n",
      "Epoch 1775/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.5405 - val_loss: 2713.0422\n",
      "Epoch 1776/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 94.4835 - val_loss: 2756.7839\n",
      "Epoch 1777/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.7423 - val_loss: 2727.0901\n",
      "Epoch 1778/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.5596 - val_loss: 2774.4626\n",
      "Epoch 1779/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.1329 - val_loss: 2768.1973\n",
      "Epoch 1780/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.2974 - val_loss: 2739.8892\n",
      "Epoch 1781/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.0008 - val_loss: 2292.3650\n",
      "Epoch 1782/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.9840 - val_loss: 2745.2432\n",
      "Epoch 1783/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 108.0649 - val_loss: 2560.0959\n",
      "Epoch 1784/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.9343 - val_loss: 2629.6863\n",
      "Epoch 1785/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.8708 - val_loss: 2342.2844\n",
      "Epoch 1786/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.7266 - val_loss: 2491.5681\n",
      "Epoch 1787/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 92.9974 - val_loss: 2500.2083\n",
      "Epoch 1788/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.0029 - val_loss: 2755.8035\n",
      "Epoch 1789/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8855 - val_loss: 3061.4805\n",
      "Epoch 1790/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 119.8750 - val_loss: 3360.0325\n",
      "Epoch 1791/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.8025 - val_loss: 3519.5381\n",
      "Epoch 1792/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 116.4722 - val_loss: 3148.8857\n",
      "Epoch 1793/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.0052 - val_loss: 3253.8318\n",
      "Epoch 1794/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 108.0259 - val_loss: 3567.8818\n",
      "Epoch 1795/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 113.1706 - val_loss: 3628.9661\n",
      "Epoch 1796/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.0592 - val_loss: 3279.8726\n",
      "Epoch 1797/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.3988 - val_loss: 3525.4951\n",
      "Epoch 1798/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.4455 - val_loss: 3535.4377\n",
      "Epoch 1799/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 112.8138 - val_loss: 3889.2766\n",
      "Epoch 1800/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.6709 - val_loss: 3571.5283\n",
      "Epoch 1801/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 103.9117 - val_loss: 4053.9734\n",
      "Epoch 1802/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.7148 - val_loss: 3271.3677\n",
      "Epoch 1803/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.6207 - val_loss: 3525.2915\n",
      "Epoch 1804/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.7808 - val_loss: 3628.9790\n",
      "Epoch 1805/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.0965 - val_loss: 3656.8159\n",
      "Epoch 1806/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.3956 - val_loss: 4063.0718\n",
      "Epoch 1807/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.1951 - val_loss: 2990.1794\n",
      "Epoch 1808/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.4496 - val_loss: 3088.7424\n",
      "Epoch 1809/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.3247 - val_loss: 3146.1035\n",
      "Epoch 1810/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.7441 - val_loss: 3468.4067\n",
      "Epoch 1811/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.9807 - val_loss: 3627.7454\n",
      "Epoch 1812/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 91.9194 - val_loss: 3369.9543\n",
      "Epoch 1813/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.8093 - val_loss: 3451.0020\n",
      "Epoch 1814/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1288 - val_loss: 3277.9961\n",
      "Epoch 1815/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.0907 - val_loss: 3170.6809\n",
      "Epoch 1816/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.0146 - val_loss: 3826.6841\n",
      "Epoch 1817/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.3101 - val_loss: 3554.0647\n",
      "Epoch 1818/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.2793 - val_loss: 3586.7922\n",
      "Epoch 1819/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.6413 - val_loss: 3826.6582\n",
      "Epoch 1820/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.7896 - val_loss: 3749.3301\n",
      "Epoch 1821/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.4382 - val_loss: 3362.7156\n",
      "Epoch 1822/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.3067 - val_loss: 4022.2307\n",
      "Epoch 1823/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.5173 - val_loss: 3272.7954\n",
      "Epoch 1824/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.6929 - val_loss: 3633.6023\n",
      "Epoch 1825/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.5526 - val_loss: 3486.6335\n",
      "Epoch 1826/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.2075 - val_loss: 3315.1084\n",
      "Epoch 1827/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.7016 - val_loss: 3619.0645\n",
      "Epoch 1828/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.6485 - val_loss: 3452.4075\n",
      "Epoch 1829/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.4625 - val_loss: 3469.0464\n",
      "Epoch 1830/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.4266 - val_loss: 3309.3860\n",
      "Epoch 1831/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.9757 - val_loss: 3686.0691\n",
      "Epoch 1832/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.0254 - val_loss: 3411.2329\n",
      "Epoch 1833/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.9744 - val_loss: 3543.9019\n",
      "Epoch 1834/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.4837 - val_loss: 3900.7683\n",
      "Epoch 1835/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.7423 - val_loss: 3512.7205\n",
      "Epoch 1836/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.6172 - val_loss: 3400.2634\n",
      "Epoch 1837/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.5738 - val_loss: 3628.9402\n",
      "Epoch 1838/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.4033 - val_loss: 3477.7466\n",
      "Epoch 1839/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 113.2110 - val_loss: 3833.9692\n",
      "Epoch 1840/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.2197 - val_loss: 3448.2356\n",
      "Epoch 1841/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.2287 - val_loss: 3713.5520\n",
      "Epoch 1842/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 103.1596 - val_loss: 3327.0903\n",
      "Epoch 1843/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9836 - val_loss: 3083.6304\n",
      "Epoch 1844/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.6791 - val_loss: 3305.6995\n",
      "Epoch 1845/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.0379 - val_loss: 3334.7383\n",
      "Epoch 1846/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 92.0256 - val_loss: 3350.4907\n",
      "Epoch 1847/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.9885 - val_loss: 4028.1975\n",
      "Epoch 1848/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.7398 - val_loss: 3500.9292\n",
      "Epoch 1849/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.0998 - val_loss: 3605.1030\n",
      "Epoch 1850/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.4098 - val_loss: 3193.2556\n",
      "Epoch 1851/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.3659 - val_loss: 3565.8896\n",
      "Epoch 1852/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.4620 - val_loss: 3052.1799\n",
      "Epoch 1853/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 127.4424 - val_loss: 3927.1348\n",
      "Epoch 1854/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.4132 - val_loss: 3472.8633\n",
      "Epoch 1855/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.4992 - val_loss: 3524.1121\n",
      "Epoch 1856/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.0415 - val_loss: 3418.0471\n",
      "Epoch 1857/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.8084 - val_loss: 3764.6890\n",
      "Epoch 1858/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.1697 - val_loss: 3242.9666\n",
      "Epoch 1859/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.1000 - val_loss: 3285.2092\n",
      "Epoch 1860/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 95.5244 - val_loss: 3337.2666\n",
      "Epoch 1861/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.6815 - val_loss: 3651.4744\n",
      "Epoch 1862/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 107.2639 - val_loss: 3288.8193\n",
      "Epoch 1863/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.8922 - val_loss: 3086.2114\n",
      "Epoch 1864/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.4062 - val_loss: 3211.5742\n",
      "Epoch 1865/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.9998 - val_loss: 3207.2366\n",
      "Epoch 1866/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.1031 - val_loss: 3119.3210\n",
      "Epoch 1867/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.2032 - val_loss: 3197.8115\n",
      "Epoch 1868/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.7644 - val_loss: 3552.8347\n",
      "Epoch 1869/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.6024 - val_loss: 3176.1289\n",
      "Epoch 1870/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94.5456 - val_loss: 3073.7349\n",
      "Epoch 1871/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.2543 - val_loss: 3410.4268\n",
      "Epoch 1872/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.4045 - val_loss: 3340.6504\n",
      "Epoch 1873/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.1748 - val_loss: 3378.8887\n",
      "Epoch 1874/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.0651 - val_loss: 3596.9512\n",
      "Epoch 1875/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.4518 - val_loss: 3195.3838\n",
      "Epoch 1876/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 90.2017 - val_loss: 3425.6697\n",
      "Epoch 1877/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.3518 - val_loss: 3376.7939\n",
      "Epoch 1878/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.5699 - val_loss: 3730.1191\n",
      "Epoch 1879/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 107.6323 - val_loss: 3756.0159\n",
      "Epoch 1880/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.7805 - val_loss: 4044.7192\n",
      "Epoch 1881/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.9600 - val_loss: 3392.7678\n",
      "Epoch 1882/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.4990 - val_loss: 3395.5105\n",
      "Epoch 1883/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.7220 - val_loss: 3502.3774\n",
      "Epoch 1884/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.2743 - val_loss: 3586.6582\n",
      "Epoch 1885/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.0672 - val_loss: 3673.4553\n",
      "Epoch 1886/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.7895 - val_loss: 3156.0374\n",
      "Epoch 1887/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.5567 - val_loss: 3328.5911\n",
      "Epoch 1888/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.8032 - val_loss: 3642.8271\n",
      "Epoch 1889/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 96.1361 - val_loss: 3293.4331\n",
      "Epoch 1890/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.0893 - val_loss: 3312.4944\n",
      "Epoch 1891/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.9595 - val_loss: 3310.1348\n",
      "Epoch 1892/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 101.5209 - val_loss: 3004.0891\n",
      "Epoch 1893/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.9451 - val_loss: 3294.1897\n",
      "Epoch 1894/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.3810 - val_loss: 3484.3113\n",
      "Epoch 1895/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 103.7987 - val_loss: 3375.7415\n",
      "Epoch 1896/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.8885 - val_loss: 3272.3704\n",
      "Epoch 1897/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.5384 - val_loss: 3585.4531\n",
      "Epoch 1898/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 110.2644 - val_loss: 3660.1765\n",
      "Epoch 1899/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 107.0630 - val_loss: 3608.4316\n",
      "Epoch 1900/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 116.5711 - val_loss: 3489.4922\n",
      "Epoch 1901/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 105.3420 - val_loss: 3428.5229\n",
      "Epoch 1902/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.0685 - val_loss: 3831.6396\n",
      "Epoch 1903/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.8721 - val_loss: 3377.9399\n",
      "Epoch 1904/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.6602 - val_loss: 3071.3684\n",
      "Epoch 1905/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 114.5993 - val_loss: 3305.3884\n",
      "Epoch 1906/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 93.6176 - val_loss: 3162.3438\n",
      "Epoch 1907/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.5112 - val_loss: 3768.9565\n",
      "Epoch 1908/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.4059 - val_loss: 3331.6111\n",
      "Epoch 1909/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 90.3196 - val_loss: 3022.7996\n",
      "Epoch 1910/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.4549 - val_loss: 3193.8066\n",
      "Epoch 1911/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 95.5075 - val_loss: 3007.2942\n",
      "Epoch 1912/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.4705 - val_loss: 3267.0190\n",
      "Epoch 1913/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 121.3202 - val_loss: 3265.7991\n",
      "Epoch 1914/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.2149 - val_loss: 3189.2627\n",
      "Epoch 1915/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 113.3940 - val_loss: 3306.3704\n",
      "Epoch 1916/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 119.2855 - val_loss: 3018.9753\n",
      "Epoch 1917/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 111.8277 - val_loss: 3459.0398\n",
      "Epoch 1918/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.1640 - val_loss: 3101.7510\n",
      "Epoch 1919/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.4040 - val_loss: 3239.7048\n",
      "Epoch 1920/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.6093 - val_loss: 2870.2639\n",
      "Epoch 1921/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 110.7451 - val_loss: 3297.4807\n",
      "Epoch 1922/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.5725 - val_loss: 4139.7686\n",
      "Epoch 1923/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 113.4568 - val_loss: 4347.0527\n",
      "Epoch 1924/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 140.7430 - val_loss: 3372.6802\n",
      "Epoch 1925/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95.9645 - val_loss: 3163.8501\n",
      "Epoch 1926/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.0677 - val_loss: 2888.5859\n",
      "Epoch 1927/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.2040 - val_loss: 3015.5532\n",
      "Epoch 1928/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.2807 - val_loss: 2717.2766\n",
      "Epoch 1929/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.9835 - val_loss: 2629.5601\n",
      "Epoch 1930/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8159 - val_loss: 2517.7046\n",
      "Epoch 1931/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.2264 - val_loss: 2795.0674\n",
      "Epoch 1932/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.2120 - val_loss: 2685.7444\n",
      "Epoch 1933/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.6443 - val_loss: 2930.1562\n",
      "Epoch 1934/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.9616 - val_loss: 2831.1934\n",
      "Epoch 1935/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.6861 - val_loss: 2934.1638\n",
      "Epoch 1936/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 99.6117 - val_loss: 2981.6655\n",
      "Epoch 1937/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 89.2112 - val_loss: 2815.6426\n",
      "Epoch 1938/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 82.4156 - val_loss: 3060.7104\n",
      "Epoch 1939/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.8070 - val_loss: 3086.0161\n",
      "Epoch 1940/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.7452 - val_loss: 3211.3997\n",
      "Epoch 1941/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.9325 - val_loss: 3136.5000\n",
      "Epoch 1942/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8059 - val_loss: 2988.0413\n",
      "Epoch 1943/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 114.0226 - val_loss: 3263.2883\n",
      "Epoch 1944/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 118.8189 - val_loss: 3182.6926\n",
      "Epoch 1945/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 123.3176 - val_loss: 3516.4595\n",
      "Epoch 1946/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.3690 - val_loss: 3041.0249\n",
      "Epoch 1947/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.9633 - val_loss: 3295.8127\n",
      "Epoch 1948/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 117.3430 - val_loss: 3421.9055\n",
      "Epoch 1949/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.9436 - val_loss: 3315.2974\n",
      "Epoch 1950/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9968 - val_loss: 3533.3567\n",
      "Epoch 1951/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.7560 - val_loss: 3408.0400\n",
      "Epoch 1952/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.5966 - val_loss: 3416.2498\n",
      "Epoch 1953/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.6203 - val_loss: 3654.7988\n",
      "Epoch 1954/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.0122 - val_loss: 3235.2366\n",
      "Epoch 1955/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 104.3079 - val_loss: 3344.6121\n",
      "Epoch 1956/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.4592 - val_loss: 3250.8665\n",
      "Epoch 1957/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.5479 - val_loss: 3152.6389\n",
      "Epoch 1958/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.1713 - val_loss: 3649.4163\n",
      "Epoch 1959/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.8459 - val_loss: 3621.5225\n",
      "Epoch 1960/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.4588 - val_loss: 3524.9861\n",
      "Epoch 1961/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.1778 - val_loss: 3206.0510\n",
      "Epoch 1962/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.2404 - val_loss: 3074.2725\n",
      "Epoch 1963/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 114.0574 - val_loss: 3494.9951\n",
      "Epoch 1964/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.6961 - val_loss: 4057.8208\n",
      "Epoch 1965/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 104.7742 - val_loss: 3957.4126\n",
      "Epoch 1966/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 104.0019 - val_loss: 3232.7791\n",
      "Epoch 1967/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 113.3954 - val_loss: 3033.8281\n",
      "Epoch 1968/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.8633 - val_loss: 3742.4248\n",
      "Epoch 1969/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.7234 - val_loss: 4176.0361\n",
      "Epoch 1970/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.1828 - val_loss: 3436.8552\n",
      "Epoch 1971/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.6445 - val_loss: 3875.8088\n",
      "Epoch 1972/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 121.7549 - val_loss: 3787.5728\n",
      "Epoch 1973/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.1476 - val_loss: 3463.3521\n",
      "Epoch 1974/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 111.1311 - val_loss: 4170.9385\n",
      "Epoch 1975/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.3813 - val_loss: 3750.6106\n",
      "Epoch 1976/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.3624 - val_loss: 3494.2163\n",
      "Epoch 1977/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 103.2674 - val_loss: 4098.0063\n",
      "Epoch 1978/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.4722 - val_loss: 3713.3142\n",
      "Epoch 1979/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.9025 - val_loss: 3361.0059\n",
      "Epoch 1980/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 108.3434 - val_loss: 3951.9431\n",
      "Epoch 1981/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 100.9259 - val_loss: 4205.4263\n",
      "Epoch 1982/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 154.8989 - val_loss: 2949.3367\n",
      "Epoch 1983/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 117.4321 - val_loss: 3619.0100\n",
      "Epoch 1984/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 128.9336 - val_loss: 3147.5969\n",
      "Epoch 1985/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.8019 - val_loss: 3543.0059\n",
      "Epoch 1986/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.0245 - val_loss: 3208.3740\n",
      "Epoch 1987/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 102.4376 - val_loss: 4101.5552\n",
      "Epoch 1988/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.0102 - val_loss: 3772.6436\n",
      "Epoch 1989/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.7537 - val_loss: 3925.5068\n",
      "Epoch 1990/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.8854 - val_loss: 4863.3506\n",
      "Epoch 1991/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 124.2331 - val_loss: 4019.6963\n",
      "Epoch 1992/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 139.7271 - val_loss: 4096.8115\n",
      "Epoch 1993/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 140.0618 - val_loss: 4025.7676\n",
      "Epoch 1994/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.7206 - val_loss: 3807.7629\n",
      "Epoch 1995/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.2537 - val_loss: 3787.3589\n",
      "Epoch 1996/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.1530 - val_loss: 4544.3481\n",
      "Epoch 1997/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.2164 - val_loss: 3853.9255\n",
      "Epoch 1998/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.9766 - val_loss: 4228.8062\n",
      "Epoch 1999/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 119.9669 - val_loss: 3890.5349\n",
      "Epoch 2000/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.2384 - val_loss: 3593.1653\n",
      "Epoch 2001/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.8629 - val_loss: 3806.2322\n",
      "Epoch 2002/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 115.7487 - val_loss: 3598.8145\n",
      "Epoch 2003/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.6316 - val_loss: 3692.3379\n",
      "Epoch 2004/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.5679 - val_loss: 3879.1038\n",
      "Epoch 2005/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.2144 - val_loss: 3389.4619\n",
      "Epoch 2006/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.5077 - val_loss: 3439.2522\n",
      "Epoch 2007/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.4160 - val_loss: 3003.7051\n",
      "Epoch 2008/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.1822 - val_loss: 3599.4668\n",
      "Epoch 2009/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.8832 - val_loss: 3236.8660\n",
      "Epoch 2010/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.4739 - val_loss: 2991.9275\n",
      "Epoch 2011/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 98.6764 - val_loss: 3031.0037\n",
      "Epoch 2012/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 97.3967 - val_loss: 3154.4595\n",
      "Epoch 2013/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 89.7552 - val_loss: 3023.1130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2014/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.7933 - val_loss: 3292.1121\n",
      "Epoch 2015/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 97.8227 - val_loss: 3017.6448\n",
      "Epoch 2016/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 103.3157 - val_loss: 3603.9136\n",
      "Epoch 2017/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.6744 - val_loss: 3269.6282\n",
      "Epoch 2018/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.6627 - val_loss: 3005.4636\n",
      "Epoch 2019/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.4623 - val_loss: 3038.5583\n",
      "Epoch 2020/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.6087 - val_loss: 3136.2942\n",
      "Epoch 2021/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.7410 - val_loss: 2754.2693\n",
      "Epoch 2022/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 90.5432 - val_loss: 2940.3293\n",
      "Epoch 2023/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.6283 - val_loss: 3334.4854\n",
      "Epoch 2024/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.9492 - val_loss: 3228.9375\n",
      "Epoch 2025/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.7032 - val_loss: 2872.8774\n",
      "Epoch 2026/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.8273 - val_loss: 2947.6716\n",
      "Epoch 2027/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.0257 - val_loss: 3681.2588\n",
      "Epoch 2028/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.7287 - val_loss: 2858.2007\n",
      "Epoch 2029/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.7167 - val_loss: 3091.2334\n",
      "Epoch 2030/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 99.2861 - val_loss: 3364.9058\n",
      "Epoch 2031/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 93.8405 - val_loss: 3127.6113\n",
      "Epoch 2032/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.2116 - val_loss: 3461.0286\n",
      "Epoch 2033/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 105.2757 - val_loss: 3015.4565\n",
      "Epoch 2034/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.9702 - val_loss: 2855.6433\n",
      "Epoch 2035/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.9359 - val_loss: 3131.0986\n",
      "Epoch 2036/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.4221 - val_loss: 3206.6470\n",
      "Epoch 2037/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.2650 - val_loss: 3367.6479\n",
      "Epoch 2038/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 75.2177Restoring model weights from the end of the best epoch: 1538.\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 98.8204 - val_loss: 3546.9619\n",
      "Epoch 2038: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>32.639999</td>\n",
       "      <td>32.19994</td>\n",
       "      <td>31.464287</td>\n",
       "      <td>30.929655</td>\n",
       "      <td>29.465794</td>\n",
       "      <td>28.594357</td>\n",
       "      <td>28.273865</td>\n",
       "      <td>27.558643</td>\n",
       "      <td>27.338331</td>\n",
       "      <td>26.696087</td>\n",
       "      <td>26.185539</td>\n",
       "      <td>25.414291</td>\n",
       "      <td>25.501762</td>\n",
       "      <td>25.354351</td>\n",
       "      <td>25.181099</td>\n",
       "      <td>25.126312</td>\n",
       "      <td>25.101665</td>\n",
       "      <td>25.119028</td>\n",
       "      <td>25.1117</td>\n",
       "      <td>25.110744</td>\n",
       "      <td>25.122297</td>\n",
       "      <td>25.127419</td>\n",
       "      <td>25.132656</td>\n",
       "      <td>25.168053</td>\n",
       "      <td>25.164726</td>\n",
       "      <td>25.206028</td>\n",
       "      <td>25.289688</td>\n",
       "      <td>25.424046</td>\n",
       "      <td>25.729954</td>\n",
       "      <td>27.051828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>64.862</td>\n",
       "      <td>49.885</td>\n",
       "      <td>53.13</td>\n",
       "      <td>57.796</td>\n",
       "      <td>47.026</td>\n",
       "      <td>74.919</td>\n",
       "      <td>34.733</td>\n",
       "      <td>15.022</td>\n",
       "      <td>20.879</td>\n",
       "      <td>36.409</td>\n",
       "      <td>22.277</td>\n",
       "      <td>20.529</td>\n",
       "      <td>37.061</td>\n",
       "      <td>23.387</td>\n",
       "      <td>38.399</td>\n",
       "      <td>39.652</td>\n",
       "      <td>40.204</td>\n",
       "      <td>21.625</td>\n",
       "      <td>42.731</td>\n",
       "      <td>36.026</td>\n",
       "      <td>34.609</td>\n",
       "      <td>40.787</td>\n",
       "      <td>39.823</td>\n",
       "      <td>39.957</td>\n",
       "      <td>52.048</td>\n",
       "      <td>53.567</td>\n",
       "      <td>46.239</td>\n",
       "      <td>51.066</td>\n",
       "      <td>51.684</td>\n",
       "      <td>44.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>32.222</td>\n",
       "      <td>17.685059</td>\n",
       "      <td>21.665714</td>\n",
       "      <td>26.866346</td>\n",
       "      <td>17.560207</td>\n",
       "      <td>46.324642</td>\n",
       "      <td>6.459137</td>\n",
       "      <td>12.536643</td>\n",
       "      <td>6.459332</td>\n",
       "      <td>9.712914</td>\n",
       "      <td>3.908539</td>\n",
       "      <td>4.885292</td>\n",
       "      <td>11.559238</td>\n",
       "      <td>1.967352</td>\n",
       "      <td>13.217899</td>\n",
       "      <td>14.525688</td>\n",
       "      <td>15.102333</td>\n",
       "      <td>3.494028</td>\n",
       "      <td>17.619299</td>\n",
       "      <td>10.915257</td>\n",
       "      <td>9.486704</td>\n",
       "      <td>15.65958</td>\n",
       "      <td>14.690346</td>\n",
       "      <td>14.788948</td>\n",
       "      <td>26.883274</td>\n",
       "      <td>28.360973</td>\n",
       "      <td>20.94931</td>\n",
       "      <td>25.641956</td>\n",
       "      <td>25.954044</td>\n",
       "      <td>17.855173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1          2          3          4          5   \\\n",
       "Month         Month-1    Month-2    Month-3    Month-4    Month-5    Month-6   \n",
       "Prediction  32.639999   32.19994  31.464287  30.929655  29.465794  28.594357   \n",
       "Target         64.862     49.885      53.13     57.796     47.026     74.919   \n",
       "Error          32.222  17.685059  21.665714  26.866346  17.560207  46.324642   \n",
       "\n",
       "                   6          7          8          9          10         11  \\\n",
       "Month         Month-7    Month-8    Month-9   Month-10   Month-11   Month-12   \n",
       "Prediction  28.273865  27.558643  27.338331  26.696087  26.185539  25.414291   \n",
       "Target         34.733     15.022     20.879     36.409     22.277     20.529   \n",
       "Error        6.459137  12.536643   6.459332   9.712914   3.908539   4.885292   \n",
       "\n",
       "                   12         13         14         15         16         17  \\\n",
       "Month        Month-13   Month-14   Month-15   Month-16   Month-17   Month-18   \n",
       "Prediction  25.501762  25.354351  25.181099  25.126312  25.101665  25.119028   \n",
       "Target         37.061     23.387     38.399     39.652     40.204     21.625   \n",
       "Error       11.559238   1.967352  13.217899  14.525688  15.102333   3.494028   \n",
       "\n",
       "                   18         19         20         21         22         23  \\\n",
       "Month        Month-19   Month-20   Month-21   Month-22   Month-23   Month-24   \n",
       "Prediction    25.1117  25.110744  25.122297  25.127419  25.132656  25.168053   \n",
       "Target         42.731     36.026     34.609     40.787     39.823     39.957   \n",
       "Error       17.619299  10.915257   9.486704   15.65958  14.690346  14.788948   \n",
       "\n",
       "                   24         25         26         27         28         29  \n",
       "Month        Month-25   Month-26   Month-27   Month-28   Month-29   Month-30  \n",
       "Prediction  25.164726  25.206028  25.289688  25.424046  25.729954  27.051828  \n",
       "Target         52.048     53.567     46.239     51.066     51.684     44.907  \n",
       "Error       26.883274  28.360973   20.94931  25.641956  25.954044  17.855173  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.498573"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.37942818"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Ano-0: |Prediction[[346.7608]] - Target[497.4669999999999]| =  Error: [[150.7062]]; MAPE:[[0.30294713]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Ano-0: |Prediction[[302.1571]] - Target[434.26099999999997]| =  Error: [[132.10388]]; MAPE:[[0.3042039]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Ano-5: |Prediction[[153.86627]] - Target[299.511]| =  Error: [[145.64471]]; MAPE:[[0.48627502]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[150.7062]], dtype=float32),\n",
       " array([[132.10388]], dtype=float32),\n",
       " array([[145.64471]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "142.81827"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.36447534"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
