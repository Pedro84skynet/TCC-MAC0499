{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Alagoas - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Alagoas - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Fluxo Mensal (Milhões de reais)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Alagoas - value</th>\n",
       "      <th>Alagoas - Desemprego</th>\n",
       "      <th>Alagoas - Produção de Cimento (t)</th>\n",
       "      <th>Alagoas - PIB - Estadual</th>\n",
       "      <th>Alagoas - PIB - Construção Civil</th>\n",
       "      <th>Alagoas - PIB - Per Capita</th>\n",
       "      <th>Alagoas - PIB - Preços de Mercado</th>\n",
       "      <th>Alagoas - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.635160</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>-5331.049150</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>0.294434</td>\n",
       "      <td>8.765721</td>\n",
       "      <td>30.779440</td>\n",
       "      <td>2.590528e+07</td>\n",
       "      <td>1.303625e+06</td>\n",
       "      <td>7.576443</td>\n",
       "      <td>2.359888e+07</td>\n",
       "      <td>30.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.635571</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>-5318.079644</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>0.296211</td>\n",
       "      <td>8.760196</td>\n",
       "      <td>30.599132</td>\n",
       "      <td>2.593685e+07</td>\n",
       "      <td>1.305020e+06</td>\n",
       "      <td>7.578654</td>\n",
       "      <td>2.360861e+07</td>\n",
       "      <td>27.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.635982</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>-5436.417870</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>0.297521</td>\n",
       "      <td>8.754671</td>\n",
       "      <td>30.545910</td>\n",
       "      <td>2.596843e+07</td>\n",
       "      <td>1.306414e+06</td>\n",
       "      <td>7.580866</td>\n",
       "      <td>2.361833e+07</td>\n",
       "      <td>26.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.636393</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>-5707.015274</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>0.298766</td>\n",
       "      <td>8.749145</td>\n",
       "      <td>30.377624</td>\n",
       "      <td>2.600000e+07</td>\n",
       "      <td>1.307809e+06</td>\n",
       "      <td>7.583078</td>\n",
       "      <td>2.362806e+07</td>\n",
       "      <td>25.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.636804</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>-5599.317941</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>0.299945</td>\n",
       "      <td>8.743620</td>\n",
       "      <td>30.464900</td>\n",
       "      <td>2.603157e+07</td>\n",
       "      <td>1.309203e+06</td>\n",
       "      <td>7.585289</td>\n",
       "      <td>2.363779e+07</td>\n",
       "      <td>25.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.556360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.501314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.609100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.584366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.538488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.688196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Alagoas - IDH  \\\n",
       "0           1.0       0.635160   \n",
       "1           2.0       0.635571   \n",
       "2           3.0       0.635982   \n",
       "3           4.0       0.636393   \n",
       "4           5.0       0.636804   \n",
       "..          ...            ...   \n",
       "235         8.0            NaN   \n",
       "236         9.0            NaN   \n",
       "237        10.0            NaN   \n",
       "238        11.0            NaN   \n",
       "239        12.0            NaN   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "      NFSP - Fluxo Mensal (Milhões de reais)  Taxa Selic (%)    IGP-DI  \\\n",
       "0                               -5331.049150        1.639718  1.036534   \n",
       "1                               -5318.079644        1.378899  0.993449   \n",
       "2                               -5436.417870        1.924317  0.973020   \n",
       "3                               -5707.015274        1.331174  0.940489   \n",
       "4                               -5599.317941        1.736072  0.917493   \n",
       "..                                       ...             ...       ...   \n",
       "235                                      NaN             NaN       NaN   \n",
       "236                                      NaN             NaN       NaN   \n",
       "237                                      NaN             NaN       NaN   \n",
       "238                                      NaN             NaN       NaN   \n",
       "239                                      NaN             NaN       NaN   \n",
       "\n",
       "        População  Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0    1.772069e+08                            7.330309e+06   0.969649   \n",
       "1    1.773884e+08                            7.335910e+06   0.950783   \n",
       "2    1.775699e+08                            7.341511e+06   0.938332   \n",
       "3    1.777514e+08                            7.347112e+06   0.926401   \n",
       "4    1.779329e+08                            7.352713e+06   0.951683   \n",
       "..            ...                                     ...        ...   \n",
       "235           NaN                                     NaN        NaN   \n",
       "236           NaN                                     NaN        NaN   \n",
       "237           NaN                                     NaN        NaN   \n",
       "238           NaN                                     NaN        NaN   \n",
       "239           NaN                                     NaN        NaN   \n",
       "\n",
       "     Alagoas - value  Alagoas - Desemprego  Alagoas - Produção de Cimento (t)  \\\n",
       "0           0.294434              8.765721                          30.779440   \n",
       "1           0.296211              8.760196                          30.599132   \n",
       "2           0.297521              8.754671                          30.545910   \n",
       "3           0.298766              8.749145                          30.377624   \n",
       "4           0.299945              8.743620                          30.464900   \n",
       "..               ...                   ...                                ...   \n",
       "235         0.587645                   NaN                          24.556360   \n",
       "236         0.587084                   NaN                          24.501314   \n",
       "237         0.585891                   NaN                          24.609100   \n",
       "238         0.584366                   NaN                          24.538488   \n",
       "239         0.582450                   NaN                          24.688196   \n",
       "\n",
       "     Alagoas - PIB - Estadual  Alagoas - PIB - Construção Civil  \\\n",
       "0                2.590528e+07                      1.303625e+06   \n",
       "1                2.593685e+07                      1.305020e+06   \n",
       "2                2.596843e+07                      1.306414e+06   \n",
       "3                2.600000e+07                      1.307809e+06   \n",
       "4                2.603157e+07                      1.309203e+06   \n",
       "..                        ...                               ...   \n",
       "235                       NaN                               NaN   \n",
       "236                       NaN                               NaN   \n",
       "237                       NaN                               NaN   \n",
       "238                       NaN                               NaN   \n",
       "239                       NaN                               NaN   \n",
       "\n",
       "     Alagoas - PIB - Per Capita  Alagoas - PIB - Preços de Mercado  \\\n",
       "0                      7.576443                       2.359888e+07   \n",
       "1                      7.578654                       2.360861e+07   \n",
       "2                      7.580866                       2.361833e+07   \n",
       "3                      7.583078                       2.362806e+07   \n",
       "4                      7.585289                       2.363779e+07   \n",
       "..                          ...                                ...   \n",
       "235                         NaN                                NaN   \n",
       "236                         NaN                                NaN   \n",
       "237                         NaN                                NaN   \n",
       "238                         NaN                                NaN   \n",
       "239                         NaN                                NaN   \n",
       "\n",
       "     Alagoas - Consumo de Cimento (t)  \n",
       "0                              30.109  \n",
       "1                              27.684  \n",
       "2                              26.534  \n",
       "3                              25.109  \n",
       "4                              25.171  \n",
       "..                                ...  \n",
       "235                            46.546  \n",
       "236                            47.781  \n",
       "237                            51.171  \n",
       "238                            49.126  \n",
       "239                            49.126  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_AL.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop(['NFSP - Porcentagem do PIB (%)'], axis=1)\n",
    "data['Unnamed: 0'] = data['Unnamed: 0'].str[5:].astype(float)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Alagoas - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Fluxo Mensal (Milhões de reais)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Alagoas - value</th>\n",
       "      <th>Alagoas - Desemprego</th>\n",
       "      <th>Alagoas - Produção de Cimento (t)</th>\n",
       "      <th>Alagoas - PIB - Estadual</th>\n",
       "      <th>Alagoas - PIB - Construção Civil</th>\n",
       "      <th>Alagoas - PIB - Per Capita</th>\n",
       "      <th>Alagoas - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.593255</td>\n",
       "      <td>-2.106195</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>0.364808</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.400856</td>\n",
       "      <td>-0.877266</td>\n",
       "      <td>-0.885888</td>\n",
       "      <td>-1.644358</td>\n",
       "      <td>-1.297696</td>\n",
       "      <td>-1.913990</td>\n",
       "      <td>-1.857572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.303572</td>\n",
       "      <td>-2.072296</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>0.368956</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.374741</td>\n",
       "      <td>-0.879298</td>\n",
       "      <td>-0.900149</td>\n",
       "      <td>-1.627544</td>\n",
       "      <td>-1.242142</td>\n",
       "      <td>-1.888746</td>\n",
       "      <td>-1.832102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.013890</td>\n",
       "      <td>-2.038397</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>0.331110</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.355481</td>\n",
       "      <td>-0.881330</td>\n",
       "      <td>-0.904358</td>\n",
       "      <td>-1.610731</td>\n",
       "      <td>-1.186588</td>\n",
       "      <td>-1.863502</td>\n",
       "      <td>-1.806633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.724207</td>\n",
       "      <td>-2.004498</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>0.244570</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.337169</td>\n",
       "      <td>-0.883362</td>\n",
       "      <td>-0.917668</td>\n",
       "      <td>-1.593917</td>\n",
       "      <td>-1.131034</td>\n",
       "      <td>-1.838257</td>\n",
       "      <td>-1.781163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>-1.970599</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>0.279013</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.319844</td>\n",
       "      <td>-0.885394</td>\n",
       "      <td>-0.910766</td>\n",
       "      <td>-1.577104</td>\n",
       "      <td>-1.075480</td>\n",
       "      <td>-1.813013</td>\n",
       "      <td>-1.755694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.434524</td>\n",
       "      <td>1.358381</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>2.953658</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>0.990315</td>\n",
       "      <td>1.043483</td>\n",
       "      <td>-1.575976</td>\n",
       "      <td>1.179374</td>\n",
       "      <td>-1.254203</td>\n",
       "      <td>1.153065</td>\n",
       "      <td>1.054229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.724207</td>\n",
       "      <td>1.351367</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>3.351323</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.000562</td>\n",
       "      <td>1.037328</td>\n",
       "      <td>-1.527002</td>\n",
       "      <td>1.172432</td>\n",
       "      <td>-1.239868</td>\n",
       "      <td>1.147901</td>\n",
       "      <td>1.048854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.013890</td>\n",
       "      <td>1.344353</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>3.404908</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.011398</td>\n",
       "      <td>1.031173</td>\n",
       "      <td>-1.472984</td>\n",
       "      <td>1.165489</td>\n",
       "      <td>-1.225534</td>\n",
       "      <td>1.142737</td>\n",
       "      <td>1.043480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.303572</td>\n",
       "      <td>1.337339</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>3.671303</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.028853</td>\n",
       "      <td>1.025017</td>\n",
       "      <td>-1.478716</td>\n",
       "      <td>1.158547</td>\n",
       "      <td>-1.211200</td>\n",
       "      <td>1.137574</td>\n",
       "      <td>1.038106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.593255</td>\n",
       "      <td>1.330325</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>4.051551</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.046955</td>\n",
       "      <td>1.018862</td>\n",
       "      <td>-1.460202</td>\n",
       "      <td>1.151604</td>\n",
       "      <td>-1.196865</td>\n",
       "      <td>1.132410</td>\n",
       "      <td>1.032732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Alagoas - IDH  \\\n",
       "0     -1.593255      -2.106195   \n",
       "1     -1.303572      -2.072296   \n",
       "2     -1.013890      -2.038397   \n",
       "3     -0.724207      -2.004498   \n",
       "4     -0.434524      -1.970599   \n",
       "..          ...            ...   \n",
       "187    0.434524       1.358381   \n",
       "188    0.724207       1.351367   \n",
       "189    1.013890       1.344353   \n",
       "190    1.303572       1.337339   \n",
       "191    1.593255       1.330325   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "      NFSP - Fluxo Mensal (Milhões de reais)  Taxa Selic (%)    IGP-DI  \\\n",
       "0                                   0.364808        2.052494  3.890153   \n",
       "1                                   0.368956        1.242280  3.551840   \n",
       "2                                   0.331110        2.936580  3.391423   \n",
       "3                                   0.244570        1.094024  3.135979   \n",
       "4                                   0.279013        2.351810  2.955412   \n",
       "..                                       ...             ...       ...   \n",
       "187                                 2.953658       -1.281958  0.589021   \n",
       "188                                 3.351323       -1.358588  1.043728   \n",
       "189                                 3.404908       -1.511565  1.387010   \n",
       "190                                 3.671303       -1.421708  1.815728   \n",
       "191                                 4.051551       -1.593676  2.181106   \n",
       "\n",
       "     População  Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0    -2.042341                               -2.389042   3.122582   \n",
       "1    -2.014760                               -2.352139   2.970356   \n",
       "2    -1.987179                               -2.315236   2.869895   \n",
       "3    -1.959598                               -2.278333   2.773628   \n",
       "4    -1.932017                               -2.241431   2.977624   \n",
       "..         ...                                     ...        ...   \n",
       "187   1.365911                                0.389193  -1.749976   \n",
       "188   1.376610                                0.370392  -1.593005   \n",
       "189   1.387308                                0.351592  -1.351489   \n",
       "190   1.398006                                0.332791  -1.198492   \n",
       "191   1.408704                                0.313991  -1.100894   \n",
       "\n",
       "     Alagoas - value  Alagoas - Desemprego  Alagoas - Produção de Cimento (t)  \\\n",
       "0          -1.400856             -0.877266                          -0.885888   \n",
       "1          -1.374741             -0.879298                          -0.900149   \n",
       "2          -1.355481             -0.881330                          -0.904358   \n",
       "3          -1.337169             -0.883362                          -0.917668   \n",
       "4          -1.319844             -0.885394                          -0.910766   \n",
       "..               ...                   ...                                ...   \n",
       "187         0.990315              1.043483                          -1.575976   \n",
       "188         1.000562              1.037328                          -1.527002   \n",
       "189         1.011398              1.031173                          -1.472984   \n",
       "190         1.028853              1.025017                          -1.478716   \n",
       "191         1.046955              1.018862                          -1.460202   \n",
       "\n",
       "     Alagoas - PIB - Estadual  Alagoas - PIB - Construção Civil  \\\n",
       "0                   -1.644358                         -1.297696   \n",
       "1                   -1.627544                         -1.242142   \n",
       "2                   -1.610731                         -1.186588   \n",
       "3                   -1.593917                         -1.131034   \n",
       "4                   -1.577104                         -1.075480   \n",
       "..                        ...                               ...   \n",
       "187                  1.179374                         -1.254203   \n",
       "188                  1.172432                         -1.239868   \n",
       "189                  1.165489                         -1.225534   \n",
       "190                  1.158547                         -1.211200   \n",
       "191                  1.151604                         -1.196865   \n",
       "\n",
       "     Alagoas - PIB - Per Capita  Alagoas - PIB - Preços de Mercado  \n",
       "0                     -1.913990                          -1.857572  \n",
       "1                     -1.888746                          -1.832102  \n",
       "2                     -1.863502                          -1.806633  \n",
       "3                     -1.838257                          -1.781163  \n",
       "4                     -1.813013                          -1.755694  \n",
       "..                          ...                                ...  \n",
       "187                    1.153065                           1.054229  \n",
       "188                    1.147901                           1.048854  \n",
       "189                    1.142737                           1.043480  \n",
       "190                    1.137574                           1.038106  \n",
       "191                    1.132410                           1.032732  \n",
       "\n",
       "[192 rows x 16 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,0:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      24.166\n",
       "1      21.774\n",
       "2      28.228\n",
       "3      25.525\n",
       "4      26.207\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Alagoas - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Alagoas - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Fluxo Mensal (Milhões de reais)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Alagoas - value</th>\n",
       "      <th>Alagoas - Desemprego</th>\n",
       "      <th>Alagoas - Produção de Cimento (t)</th>\n",
       "      <th>Alagoas - PIB - Estadual</th>\n",
       "      <th>Alagoas - PIB - Construção Civil</th>\n",
       "      <th>Alagoas - PIB - Per Capita</th>\n",
       "      <th>Alagoas - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.593255</td>\n",
       "      <td>-2.106195</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>0.364808</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.400856</td>\n",
       "      <td>-0.877266</td>\n",
       "      <td>-0.885888</td>\n",
       "      <td>-1.644358</td>\n",
       "      <td>-1.297696</td>\n",
       "      <td>-1.913990</td>\n",
       "      <td>-1.857572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.303572</td>\n",
       "      <td>-2.072296</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>0.368956</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.374741</td>\n",
       "      <td>-0.879298</td>\n",
       "      <td>-0.900149</td>\n",
       "      <td>-1.627544</td>\n",
       "      <td>-1.242142</td>\n",
       "      <td>-1.888746</td>\n",
       "      <td>-1.832102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.013890</td>\n",
       "      <td>-2.038397</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>0.331110</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.355481</td>\n",
       "      <td>-0.881330</td>\n",
       "      <td>-0.904358</td>\n",
       "      <td>-1.610731</td>\n",
       "      <td>-1.186588</td>\n",
       "      <td>-1.863502</td>\n",
       "      <td>-1.806633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.724207</td>\n",
       "      <td>-2.004498</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>0.244570</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.337169</td>\n",
       "      <td>-0.883362</td>\n",
       "      <td>-0.917668</td>\n",
       "      <td>-1.593917</td>\n",
       "      <td>-1.131034</td>\n",
       "      <td>-1.838257</td>\n",
       "      <td>-1.781163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>-1.970599</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>0.279013</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.319844</td>\n",
       "      <td>-0.885394</td>\n",
       "      <td>-0.910766</td>\n",
       "      <td>-1.577104</td>\n",
       "      <td>-1.075480</td>\n",
       "      <td>-1.813013</td>\n",
       "      <td>-1.755694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-1.303572</td>\n",
       "      <td>1.429306</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>1.216560</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>1.348585</td>\n",
       "      <td>1.320458</td>\n",
       "      <td>-0.588269</td>\n",
       "      <td>1.217771</td>\n",
       "      <td>-1.179058</td>\n",
       "      <td>1.109023</td>\n",
       "      <td>1.141942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-1.013890</td>\n",
       "      <td>1.428089</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>1.155373</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>1.330705</td>\n",
       "      <td>1.307307</td>\n",
       "      <td>-0.687207</td>\n",
       "      <td>1.221600</td>\n",
       "      <td>-1.195069</td>\n",
       "      <td>1.116989</td>\n",
       "      <td>1.144540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.724207</td>\n",
       "      <td>1.426872</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>1.056140</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>1.311609</td>\n",
       "      <td>1.294156</td>\n",
       "      <td>-0.785508</td>\n",
       "      <td>1.225429</td>\n",
       "      <td>-1.211080</td>\n",
       "      <td>1.124956</td>\n",
       "      <td>1.147138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>1.425655</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>1.147619</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>1.291203</td>\n",
       "      <td>1.281004</td>\n",
       "      <td>-0.883126</td>\n",
       "      <td>1.229259</td>\n",
       "      <td>-1.227092</td>\n",
       "      <td>1.132922</td>\n",
       "      <td>1.149736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.144841</td>\n",
       "      <td>1.424437</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>1.118091</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>1.269639</td>\n",
       "      <td>1.267853</td>\n",
       "      <td>-0.980024</td>\n",
       "      <td>1.233088</td>\n",
       "      <td>-1.243103</td>\n",
       "      <td>1.140888</td>\n",
       "      <td>1.152334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Alagoas - IDH  \\\n",
       "0     -1.593255      -2.106195   \n",
       "1     -1.303572      -2.072296   \n",
       "2     -1.013890      -2.038397   \n",
       "3     -0.724207      -2.004498   \n",
       "4     -0.434524      -1.970599   \n",
       "..          ...            ...   \n",
       "157   -1.303572       1.429306   \n",
       "158   -1.013890       1.428089   \n",
       "159   -0.724207       1.426872   \n",
       "160   -0.434524       1.425655   \n",
       "161   -0.144841       1.424437   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "      NFSP - Fluxo Mensal (Milhões de reais)  Taxa Selic (%)    IGP-DI  \\\n",
       "0                                   0.364808        2.052494  3.890153   \n",
       "1                                   0.368956        1.242280  3.551840   \n",
       "2                                   0.331110        2.936580  3.391423   \n",
       "3                                   0.244570        1.094024  3.135979   \n",
       "4                                   0.279013        2.351810  2.955412   \n",
       "..                                       ...             ...       ...   \n",
       "157                                 1.216560        0.059280 -1.233012   \n",
       "158                                 1.155373        0.222389 -1.299304   \n",
       "159                                 1.056140        0.191929 -1.248662   \n",
       "160                                 1.147619        0.385687 -1.068274   \n",
       "161                                 1.118091        0.712055 -1.035336   \n",
       "\n",
       "     População  Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0    -2.042341                               -2.389042   3.122582   \n",
       "1    -2.014760                               -2.352139   2.970356   \n",
       "2    -1.987179                               -2.315236   2.869895   \n",
       "3    -1.959598                               -2.278333   2.773628   \n",
       "4    -1.932017                               -2.241431   2.977624   \n",
       "..         ...                                     ...        ...   \n",
       "157   1.031384                                0.819304  -0.883659   \n",
       "158   1.042716                                0.808136  -0.950771   \n",
       "159   1.054049                                0.796969  -1.028465   \n",
       "160   1.065381                                0.785801  -1.103668   \n",
       "161   1.076713                                0.774634  -0.978419   \n",
       "\n",
       "     Alagoas - value  Alagoas - Desemprego  Alagoas - Produção de Cimento (t)  \\\n",
       "0          -1.400856             -0.877266                          -0.885888   \n",
       "1          -1.374741             -0.879298                          -0.900149   \n",
       "2          -1.355481             -0.881330                          -0.904358   \n",
       "3          -1.337169             -0.883362                          -0.917668   \n",
       "4          -1.319844             -0.885394                          -0.910766   \n",
       "..               ...                   ...                                ...   \n",
       "157         1.348585              1.320458                          -0.588269   \n",
       "158         1.330705              1.307307                          -0.687207   \n",
       "159         1.311609              1.294156                          -0.785508   \n",
       "160         1.291203              1.281004                          -0.883126   \n",
       "161         1.269639              1.267853                          -0.980024   \n",
       "\n",
       "     Alagoas - PIB - Estadual  Alagoas - PIB - Construção Civil  \\\n",
       "0                   -1.644358                         -1.297696   \n",
       "1                   -1.627544                         -1.242142   \n",
       "2                   -1.610731                         -1.186588   \n",
       "3                   -1.593917                         -1.131034   \n",
       "4                   -1.577104                         -1.075480   \n",
       "..                        ...                               ...   \n",
       "157                  1.217771                         -1.179058   \n",
       "158                  1.221600                         -1.195069   \n",
       "159                  1.225429                         -1.211080   \n",
       "160                  1.229259                         -1.227092   \n",
       "161                  1.233088                         -1.243103   \n",
       "\n",
       "     Alagoas - PIB - Per Capita  Alagoas - PIB - Preços de Mercado  \n",
       "0                     -1.913990                          -1.857572  \n",
       "1                     -1.888746                          -1.832102  \n",
       "2                     -1.863502                          -1.806633  \n",
       "3                     -1.838257                          -1.781163  \n",
       "4                     -1.813013                          -1.755694  \n",
       "..                          ...                                ...  \n",
       "157                    1.109023                           1.141942  \n",
       "158                    1.116989                           1.144540  \n",
       "159                    1.124956                           1.147138  \n",
       "160                    1.132922                           1.149736  \n",
       "161                    1.140888                           1.152334  \n",
       "\n",
       "[162 rows x 16 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      24.166\n",
       "1      21.774\n",
       "2      28.228\n",
       "3      25.525\n",
       "4      26.207\n",
       "        ...  \n",
       "157    32.321\n",
       "158    41.937\n",
       "159    31.982\n",
       "160    28.499\n",
       "161    22.626\n",
       "Name: Alagoas - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Alagoas - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Fluxo Mensal (Milhões de reais)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Alagoas - value</th>\n",
       "      <th>Alagoas - Desemprego</th>\n",
       "      <th>Alagoas - Produção de Cimento (t)</th>\n",
       "      <th>Alagoas - PIB - Estadual</th>\n",
       "      <th>Alagoas - PIB - Construção Civil</th>\n",
       "      <th>Alagoas - PIB - Per Capita</th>\n",
       "      <th>Alagoas - PIB - Preços de Mercado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.144841</td>\n",
       "      <td>1.423220</td>\n",
       "      <td>-0.601510</td>\n",
       "      <td>1.044342</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>1.247022</td>\n",
       "      <td>1.254702</td>\n",
       "      <td>-1.076156</td>\n",
       "      <td>1.236917</td>\n",
       "      <td>-1.259114</td>\n",
       "      <td>1.148855</td>\n",
       "      <td>1.154932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.434524</td>\n",
       "      <td>1.422003</td>\n",
       "      <td>-0.786068</td>\n",
       "      <td>1.062406</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>1.223337</td>\n",
       "      <td>1.241551</td>\n",
       "      <td>-1.171477</td>\n",
       "      <td>1.240746</td>\n",
       "      <td>-1.275126</td>\n",
       "      <td>1.156821</td>\n",
       "      <td>1.157530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.724207</td>\n",
       "      <td>1.420786</td>\n",
       "      <td>-0.830387</td>\n",
       "      <td>0.969885</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>1.204693</td>\n",
       "      <td>1.228399</td>\n",
       "      <td>-1.265945</td>\n",
       "      <td>1.244576</td>\n",
       "      <td>-1.291137</td>\n",
       "      <td>1.164788</td>\n",
       "      <td>1.160128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.013890</td>\n",
       "      <td>1.419568</td>\n",
       "      <td>-0.801089</td>\n",
       "      <td>0.801374</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>1.185204</td>\n",
       "      <td>1.215248</td>\n",
       "      <td>-1.336584</td>\n",
       "      <td>1.248405</td>\n",
       "      <td>-1.307148</td>\n",
       "      <td>1.172754</td>\n",
       "      <td>1.162726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.303572</td>\n",
       "      <td>1.418351</td>\n",
       "      <td>-0.959917</td>\n",
       "      <td>1.125021</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>1.170986</td>\n",
       "      <td>1.202097</td>\n",
       "      <td>-1.406157</td>\n",
       "      <td>1.252234</td>\n",
       "      <td>-1.323160</td>\n",
       "      <td>1.180720</td>\n",
       "      <td>1.165324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.593255</td>\n",
       "      <td>1.417134</td>\n",
       "      <td>-1.022309</td>\n",
       "      <td>1.148821</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>1.156220</td>\n",
       "      <td>1.188946</td>\n",
       "      <td>-1.475508</td>\n",
       "      <td>1.256063</td>\n",
       "      <td>-1.339171</td>\n",
       "      <td>1.188687</td>\n",
       "      <td>1.167922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-1.593255</td>\n",
       "      <td>1.415917</td>\n",
       "      <td>-1.074401</td>\n",
       "      <td>0.446496</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>1.140972</td>\n",
       "      <td>1.175794</td>\n",
       "      <td>-1.532489</td>\n",
       "      <td>1.259893</td>\n",
       "      <td>-1.355182</td>\n",
       "      <td>1.196653</td>\n",
       "      <td>1.170520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-1.303572</td>\n",
       "      <td>1.415213</td>\n",
       "      <td>-1.119597</td>\n",
       "      <td>0.726189</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>1.128313</td>\n",
       "      <td>1.168359</td>\n",
       "      <td>-1.592879</td>\n",
       "      <td>1.257232</td>\n",
       "      <td>-1.355129</td>\n",
       "      <td>1.196033</td>\n",
       "      <td>1.163964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-1.013890</td>\n",
       "      <td>1.414510</td>\n",
       "      <td>-1.078648</td>\n",
       "      <td>0.597090</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>1.115315</td>\n",
       "      <td>1.160924</td>\n",
       "      <td>-1.642238</td>\n",
       "      <td>1.254572</td>\n",
       "      <td>-1.355076</td>\n",
       "      <td>1.195413</td>\n",
       "      <td>1.157408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-0.724207</td>\n",
       "      <td>1.413807</td>\n",
       "      <td>-1.055426</td>\n",
       "      <td>0.457269</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>1.101989</td>\n",
       "      <td>1.153488</td>\n",
       "      <td>-1.707022</td>\n",
       "      <td>1.251912</td>\n",
       "      <td>-1.355023</td>\n",
       "      <td>1.194793</td>\n",
       "      <td>1.150852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>1.413104</td>\n",
       "      <td>-1.101053</td>\n",
       "      <td>0.580506</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>1.085291</td>\n",
       "      <td>1.146053</td>\n",
       "      <td>-1.758290</td>\n",
       "      <td>1.249252</td>\n",
       "      <td>-1.354969</td>\n",
       "      <td>1.194173</td>\n",
       "      <td>1.144296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-0.144841</td>\n",
       "      <td>1.412400</td>\n",
       "      <td>-1.211370</td>\n",
       "      <td>0.448805</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>1.077419</td>\n",
       "      <td>1.138618</td>\n",
       "      <td>-1.813774</td>\n",
       "      <td>1.246592</td>\n",
       "      <td>-1.354916</td>\n",
       "      <td>1.193553</td>\n",
       "      <td>1.137740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.144841</td>\n",
       "      <td>1.411697</td>\n",
       "      <td>-1.157198</td>\n",
       "      <td>0.280234</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>1.069582</td>\n",
       "      <td>1.131182</td>\n",
       "      <td>-1.831058</td>\n",
       "      <td>1.243931</td>\n",
       "      <td>-1.354863</td>\n",
       "      <td>1.192933</td>\n",
       "      <td>1.131184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.434524</td>\n",
       "      <td>1.410994</td>\n",
       "      <td>-1.223444</td>\n",
       "      <td>0.220168</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>1.061809</td>\n",
       "      <td>1.123747</td>\n",
       "      <td>-1.829288</td>\n",
       "      <td>1.241271</td>\n",
       "      <td>-1.354810</td>\n",
       "      <td>1.192312</td>\n",
       "      <td>1.124628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.724207</td>\n",
       "      <td>1.410291</td>\n",
       "      <td>-1.311519</td>\n",
       "      <td>0.150317</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>1.054127</td>\n",
       "      <td>1.116312</td>\n",
       "      <td>-1.821040</td>\n",
       "      <td>1.238611</td>\n",
       "      <td>-1.354756</td>\n",
       "      <td>1.191692</td>\n",
       "      <td>1.118072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.013890</td>\n",
       "      <td>1.409588</td>\n",
       "      <td>-1.362602</td>\n",
       "      <td>0.005393</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>1.046558</td>\n",
       "      <td>1.108876</td>\n",
       "      <td>-1.800522</td>\n",
       "      <td>1.235951</td>\n",
       "      <td>-1.354703</td>\n",
       "      <td>1.191072</td>\n",
       "      <td>1.111516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.303572</td>\n",
       "      <td>1.408884</td>\n",
       "      <td>-1.380125</td>\n",
       "      <td>0.073096</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>1.039132</td>\n",
       "      <td>1.101441</td>\n",
       "      <td>-1.788556</td>\n",
       "      <td>1.233291</td>\n",
       "      <td>-1.354650</td>\n",
       "      <td>1.190452</td>\n",
       "      <td>1.104960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.593255</td>\n",
       "      <td>1.408181</td>\n",
       "      <td>-1.219296</td>\n",
       "      <td>0.179950</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>1.031875</td>\n",
       "      <td>1.094005</td>\n",
       "      <td>-1.778062</td>\n",
       "      <td>1.230631</td>\n",
       "      <td>-1.354596</td>\n",
       "      <td>1.189832</td>\n",
       "      <td>1.098404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-1.593255</td>\n",
       "      <td>1.407478</td>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.331118</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>1.024757</td>\n",
       "      <td>1.086570</td>\n",
       "      <td>-1.760641</td>\n",
       "      <td>1.227970</td>\n",
       "      <td>-1.354543</td>\n",
       "      <td>1.189212</td>\n",
       "      <td>1.091848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-1.303572</td>\n",
       "      <td>1.400464</td>\n",
       "      <td>-1.336476</td>\n",
       "      <td>0.033946</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>1.017808</td>\n",
       "      <td>1.080415</td>\n",
       "      <td>-1.739308</td>\n",
       "      <td>1.221028</td>\n",
       "      <td>-1.340209</td>\n",
       "      <td>1.184048</td>\n",
       "      <td>1.086474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-1.013890</td>\n",
       "      <td>1.393450</td>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>1.011057</td>\n",
       "      <td>1.074260</td>\n",
       "      <td>-1.733027</td>\n",
       "      <td>1.214086</td>\n",
       "      <td>-1.325874</td>\n",
       "      <td>1.178884</td>\n",
       "      <td>1.081100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-0.724207</td>\n",
       "      <td>1.386436</td>\n",
       "      <td>-1.526021</td>\n",
       "      <td>0.320093</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>1.004534</td>\n",
       "      <td>1.068104</td>\n",
       "      <td>-1.725873</td>\n",
       "      <td>1.207143</td>\n",
       "      <td>-1.311540</td>\n",
       "      <td>1.173721</td>\n",
       "      <td>1.075726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-0.434524</td>\n",
       "      <td>1.379422</td>\n",
       "      <td>-1.681806</td>\n",
       "      <td>0.894923</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>0.998267</td>\n",
       "      <td>1.061949</td>\n",
       "      <td>-1.715028</td>\n",
       "      <td>1.200201</td>\n",
       "      <td>-1.297206</td>\n",
       "      <td>1.168557</td>\n",
       "      <td>1.070351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-0.144841</td>\n",
       "      <td>1.372408</td>\n",
       "      <td>-1.735167</td>\n",
       "      <td>1.830399</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>0.992289</td>\n",
       "      <td>1.055794</td>\n",
       "      <td>-1.684268</td>\n",
       "      <td>1.193259</td>\n",
       "      <td>-1.282871</td>\n",
       "      <td>1.163393</td>\n",
       "      <td>1.064977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.144841</td>\n",
       "      <td>1.365394</td>\n",
       "      <td>-1.962315</td>\n",
       "      <td>2.287258</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>0.986628</td>\n",
       "      <td>1.049638</td>\n",
       "      <td>-1.635177</td>\n",
       "      <td>1.186316</td>\n",
       "      <td>-1.268537</td>\n",
       "      <td>1.158229</td>\n",
       "      <td>1.059603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.434524</td>\n",
       "      <td>1.358381</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>2.953658</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>0.990315</td>\n",
       "      <td>1.043483</td>\n",
       "      <td>-1.575976</td>\n",
       "      <td>1.179374</td>\n",
       "      <td>-1.254203</td>\n",
       "      <td>1.153065</td>\n",
       "      <td>1.054229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.724207</td>\n",
       "      <td>1.351367</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>3.351323</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.000562</td>\n",
       "      <td>1.037328</td>\n",
       "      <td>-1.527002</td>\n",
       "      <td>1.172432</td>\n",
       "      <td>-1.239868</td>\n",
       "      <td>1.147901</td>\n",
       "      <td>1.048854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.013890</td>\n",
       "      <td>1.344353</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>3.404908</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.011398</td>\n",
       "      <td>1.031173</td>\n",
       "      <td>-1.472984</td>\n",
       "      <td>1.165489</td>\n",
       "      <td>-1.225534</td>\n",
       "      <td>1.142737</td>\n",
       "      <td>1.043480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.303572</td>\n",
       "      <td>1.337339</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>3.671303</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.028853</td>\n",
       "      <td>1.025017</td>\n",
       "      <td>-1.478716</td>\n",
       "      <td>1.158547</td>\n",
       "      <td>-1.211200</td>\n",
       "      <td>1.137574</td>\n",
       "      <td>1.038106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.593255</td>\n",
       "      <td>1.330325</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>4.051551</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.046955</td>\n",
       "      <td>1.018862</td>\n",
       "      <td>-1.460202</td>\n",
       "      <td>1.151604</td>\n",
       "      <td>-1.196865</td>\n",
       "      <td>1.132410</td>\n",
       "      <td>1.032732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Alagoas - IDH  \\\n",
       "162    0.144841       1.423220   \n",
       "163    0.434524       1.422003   \n",
       "164    0.724207       1.420786   \n",
       "165    1.013890       1.419568   \n",
       "166    1.303572       1.418351   \n",
       "167    1.593255       1.417134   \n",
       "168   -1.593255       1.415917   \n",
       "169   -1.303572       1.415213   \n",
       "170   -1.013890       1.414510   \n",
       "171   -0.724207       1.413807   \n",
       "172   -0.434524       1.413104   \n",
       "173   -0.144841       1.412400   \n",
       "174    0.144841       1.411697   \n",
       "175    0.434524       1.410994   \n",
       "176    0.724207       1.410291   \n",
       "177    1.013890       1.409588   \n",
       "178    1.303572       1.408884   \n",
       "179    1.593255       1.408181   \n",
       "180   -1.593255       1.407478   \n",
       "181   -1.303572       1.400464   \n",
       "182   -1.013890       1.393450   \n",
       "183   -0.724207       1.386436   \n",
       "184   -0.434524       1.379422   \n",
       "185   -0.144841       1.372408   \n",
       "186    0.144841       1.365394   \n",
       "187    0.434524       1.358381   \n",
       "188    0.724207       1.351367   \n",
       "189    1.013890       1.344353   \n",
       "190    1.303572       1.337339   \n",
       "191    1.593255       1.330325   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162                                         -0.601510   \n",
       "163                                         -0.786068   \n",
       "164                                         -0.830387   \n",
       "165                                         -0.801089   \n",
       "166                                         -0.959917   \n",
       "167                                         -1.022309   \n",
       "168                                         -1.074401   \n",
       "169                                         -1.119597   \n",
       "170                                         -1.078648   \n",
       "171                                         -1.055426   \n",
       "172                                         -1.101053   \n",
       "173                                         -1.211370   \n",
       "174                                         -1.157198   \n",
       "175                                         -1.223444   \n",
       "176                                         -1.311519   \n",
       "177                                         -1.362602   \n",
       "178                                         -1.380125   \n",
       "179                                         -1.219296   \n",
       "180                                         -1.300284   \n",
       "181                                         -1.336476   \n",
       "182                                         -1.415774   \n",
       "183                                         -1.526021   \n",
       "184                                         -1.681806   \n",
       "185                                         -1.735167   \n",
       "186                                         -1.962315   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "      NFSP - Fluxo Mensal (Milhões de reais)  Taxa Selic (%)    IGP-DI  \\\n",
       "162                                 1.044342        0.157879 -1.255326   \n",
       "163                                 1.062406        0.548855 -1.118679   \n",
       "164                                 0.969885        0.385685 -0.936336   \n",
       "165                                 0.801374        0.420965 -0.931790   \n",
       "166                                 1.125021        0.548870 -1.168522   \n",
       "167                                 1.148821        0.222499 -1.285611   \n",
       "168                                 0.446496       -0.614754 -1.446316   \n",
       "169                                 0.726189       -0.478229 -1.357832   \n",
       "170                                 0.597090       -0.393157 -1.235682   \n",
       "171                                 0.457269       -0.557552 -1.065340   \n",
       "172                                 0.580506       -1.033381 -0.826250   \n",
       "173                                 0.448805        0.310838 -0.657967   \n",
       "174                                 0.280234       -1.062966 -0.512365   \n",
       "175                                 0.220168       -1.347961 -0.546480   \n",
       "176                                 0.150317       -0.609120 -0.504812   \n",
       "177                                 0.005393       -0.215312 -0.515805   \n",
       "178                                 0.073096        0.222485 -0.391158   \n",
       "179                                 0.179950       -1.266605 -0.230121   \n",
       "180                                -0.331118       -1.588002 -0.318758   \n",
       "181                                 0.033946       -1.226154 -0.396427   \n",
       "182                                -0.002800       -1.358090 -0.140581   \n",
       "183                                 0.320093       -1.395002 -0.198662   \n",
       "184                                 0.894923       -1.430606 -0.154798   \n",
       "185                                 1.830399       -1.511562 -0.142566   \n",
       "186                                 2.287258       -1.433584  0.013469   \n",
       "187                                 2.953658       -1.281958  0.589021   \n",
       "188                                 3.351323       -1.358588  1.043728   \n",
       "189                                 3.404908       -1.511565  1.387010   \n",
       "190                                 3.671303       -1.421708  1.815728   \n",
       "191                                 4.051551       -1.593676  2.181106   \n",
       "\n",
       "     População  Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "162   1.088045                                0.763466  -1.213929   \n",
       "163   1.099377                                0.752299  -1.292173   \n",
       "164   1.110709                                0.741131  -1.324219   \n",
       "165   1.122042                                0.729964  -1.344446   \n",
       "166   1.133374                                0.718796  -1.381638   \n",
       "167   1.144706                                0.707629  -1.411208   \n",
       "168   1.156038                                0.696461  -1.412953   \n",
       "169   1.167287                                0.681823  -1.491464   \n",
       "170   1.178536                                0.667184  -1.573805   \n",
       "171   1.189784                                0.652545  -1.564950   \n",
       "172   1.201033                                0.637906  -1.581584   \n",
       "173   1.212282                                0.623268  -1.565976   \n",
       "174   1.223531                                0.608629  -1.648556   \n",
       "175   1.234780                                0.593990  -1.650049   \n",
       "176   1.246029                                0.579351  -1.653957   \n",
       "177   1.257277                                0.564713  -1.652572   \n",
       "178   1.268526                                0.550074  -1.715349   \n",
       "179   1.279775                                0.535435  -1.750917   \n",
       "180   1.291024                                0.520796  -1.718448   \n",
       "181   1.301722                                0.501996  -1.733426   \n",
       "182   1.312420                                0.483195  -1.729362   \n",
       "183   1.323118                                0.464395  -1.748544   \n",
       "184   1.333817                                0.445594  -1.778060   \n",
       "185   1.344515                                0.426794  -1.773710   \n",
       "186   1.355213                                0.407993  -1.757007   \n",
       "187   1.365911                                0.389193  -1.749976   \n",
       "188   1.376610                                0.370392  -1.593005   \n",
       "189   1.387308                                0.351592  -1.351489   \n",
       "190   1.398006                                0.332791  -1.198492   \n",
       "191   1.408704                                0.313991  -1.100894   \n",
       "\n",
       "     Alagoas - value  Alagoas - Desemprego  Alagoas - Produção de Cimento (t)  \\\n",
       "162         1.247022              1.254702                          -1.076156   \n",
       "163         1.223337              1.241551                          -1.171477   \n",
       "164         1.204693              1.228399                          -1.265945   \n",
       "165         1.185204              1.215248                          -1.336584   \n",
       "166         1.170986              1.202097                          -1.406157   \n",
       "167         1.156220              1.188946                          -1.475508   \n",
       "168         1.140972              1.175794                          -1.532489   \n",
       "169         1.128313              1.168359                          -1.592879   \n",
       "170         1.115315              1.160924                          -1.642238   \n",
       "171         1.101989              1.153488                          -1.707022   \n",
       "172         1.085291              1.146053                          -1.758290   \n",
       "173         1.077419              1.138618                          -1.813774   \n",
       "174         1.069582              1.131182                          -1.831058   \n",
       "175         1.061809              1.123747                          -1.829288   \n",
       "176         1.054127              1.116312                          -1.821040   \n",
       "177         1.046558              1.108876                          -1.800522   \n",
       "178         1.039132              1.101441                          -1.788556   \n",
       "179         1.031875              1.094005                          -1.778062   \n",
       "180         1.024757              1.086570                          -1.760641   \n",
       "181         1.017808              1.080415                          -1.739308   \n",
       "182         1.011057              1.074260                          -1.733027   \n",
       "183         1.004534              1.068104                          -1.725873   \n",
       "184         0.998267              1.061949                          -1.715028   \n",
       "185         0.992289              1.055794                          -1.684268   \n",
       "186         0.986628              1.049638                          -1.635177   \n",
       "187         0.990315              1.043483                          -1.575976   \n",
       "188         1.000562              1.037328                          -1.527002   \n",
       "189         1.011398              1.031173                          -1.472984   \n",
       "190         1.028853              1.025017                          -1.478716   \n",
       "191         1.046955              1.018862                          -1.460202   \n",
       "\n",
       "     Alagoas - PIB - Estadual  Alagoas - PIB - Construção Civil  \\\n",
       "162                  1.236917                         -1.259114   \n",
       "163                  1.240746                         -1.275126   \n",
       "164                  1.244576                         -1.291137   \n",
       "165                  1.248405                         -1.307148   \n",
       "166                  1.252234                         -1.323160   \n",
       "167                  1.256063                         -1.339171   \n",
       "168                  1.259893                         -1.355182   \n",
       "169                  1.257232                         -1.355129   \n",
       "170                  1.254572                         -1.355076   \n",
       "171                  1.251912                         -1.355023   \n",
       "172                  1.249252                         -1.354969   \n",
       "173                  1.246592                         -1.354916   \n",
       "174                  1.243931                         -1.354863   \n",
       "175                  1.241271                         -1.354810   \n",
       "176                  1.238611                         -1.354756   \n",
       "177                  1.235951                         -1.354703   \n",
       "178                  1.233291                         -1.354650   \n",
       "179                  1.230631                         -1.354596   \n",
       "180                  1.227970                         -1.354543   \n",
       "181                  1.221028                         -1.340209   \n",
       "182                  1.214086                         -1.325874   \n",
       "183                  1.207143                         -1.311540   \n",
       "184                  1.200201                         -1.297206   \n",
       "185                  1.193259                         -1.282871   \n",
       "186                  1.186316                         -1.268537   \n",
       "187                  1.179374                         -1.254203   \n",
       "188                  1.172432                         -1.239868   \n",
       "189                  1.165489                         -1.225534   \n",
       "190                  1.158547                         -1.211200   \n",
       "191                  1.151604                         -1.196865   \n",
       "\n",
       "     Alagoas - PIB - Per Capita  Alagoas - PIB - Preços de Mercado  \n",
       "162                    1.148855                           1.154932  \n",
       "163                    1.156821                           1.157530  \n",
       "164                    1.164788                           1.160128  \n",
       "165                    1.172754                           1.162726  \n",
       "166                    1.180720                           1.165324  \n",
       "167                    1.188687                           1.167922  \n",
       "168                    1.196653                           1.170520  \n",
       "169                    1.196033                           1.163964  \n",
       "170                    1.195413                           1.157408  \n",
       "171                    1.194793                           1.150852  \n",
       "172                    1.194173                           1.144296  \n",
       "173                    1.193553                           1.137740  \n",
       "174                    1.192933                           1.131184  \n",
       "175                    1.192312                           1.124628  \n",
       "176                    1.191692                           1.118072  \n",
       "177                    1.191072                           1.111516  \n",
       "178                    1.190452                           1.104960  \n",
       "179                    1.189832                           1.098404  \n",
       "180                    1.189212                           1.091848  \n",
       "181                    1.184048                           1.086474  \n",
       "182                    1.178884                           1.081100  \n",
       "183                    1.173721                           1.075726  \n",
       "184                    1.168557                           1.070351  \n",
       "185                    1.163393                           1.064977  \n",
       "186                    1.158229                           1.059603  \n",
       "187                    1.153065                           1.054229  \n",
       "188                    1.147901                           1.048854  \n",
       "189                    1.142737                           1.043480  \n",
       "190                    1.137574                           1.038106  \n",
       "191                    1.132410                           1.032732  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    21.340\n",
       "163    26.848\n",
       "164    28.074\n",
       "165    29.941\n",
       "166    28.977\n",
       "167    31.580\n",
       "168    29.991\n",
       "169    26.820\n",
       "170    29.446\n",
       "171    27.666\n",
       "172    22.013\n",
       "173    28.025\n",
       "174    25.648\n",
       "175    31.782\n",
       "176    27.768\n",
       "177    33.073\n",
       "178    30.389\n",
       "179    27.657\n",
       "180    32.388\n",
       "181    30.378\n",
       "182    30.641\n",
       "183    32.337\n",
       "184    36.405\n",
       "185    22.499\n",
       "186    27.961\n",
       "187    32.378\n",
       "188    32.582\n",
       "189    42.703\n",
       "190    38.584\n",
       "191    36.503\n",
       "Name: Alagoas - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor//2):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "#     train, train_val = validation_splitter(train_input, 6)\n",
    "#     target,target_val = validation_splitter(train_target, 6)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train_input, \n",
    "                        train_target, \n",
    "                        epochs=10000,\n",
    "#                         validation_data=(train_val,target_val),\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[276696894, 2014889265, 372569930, 2677425768, 1919255007, 1911378343, 2485568703, 217687616, 43295332, 3998873420, 3563295006, 3367150844, 256132084, 2691593933, 1992719647, 1480873956, 2148446215, 4239312448, 2461111171, 3682730183, 2977149366, 1766794138, 172313718, 1546819712, 3006489405]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 767.68212890625\n",
      "winner_seed: 276696894\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 787.0926513671875\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 2554.7939453125\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 1716.1842041015625\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 584.2723388671875\n",
      "winner_seed: 1919255007\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 1471.868408203125\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 192.3546142578125\n",
      "winner_seed: 2485568703\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 1043.40478515625\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 1732.8548583984375\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 1156.3336181640625\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 1683.42626953125\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 26.92952537536621\n",
      "winner_seed: 3367150844\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 1680.59716796875\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 1387.6890869140625\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 1090.370361328125\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 1718.358154296875\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 1472.8311767578125\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 840.9121704101562\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 1404.60205078125\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 1342.3726806640625\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 797.53955078125\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 1178.4737548828125\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 996.5379028320312\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 1965.03857421875\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 1072.30078125\n",
      "\n",
      "\n",
      "final_seed: 3367150844\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 1s 26ms/step - loss: 2160.5251 - val_loss: 966.0403\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1885.2291 - val_loss: 800.0574\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1914.3767 - val_loss: 3696.5188\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1949.6500 - val_loss: 582.2033\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1777.3407 - val_loss: 1540.2070\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1607.2922 - val_loss: 1658.3398\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1532.3418 - val_loss: 560.2144\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1441.5433 - val_loss: 620.0351\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1285.3163 - val_loss: 501.8520\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1202.7129 - val_loss: 1468.4214\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1182.8329 - val_loss: 1018.0640\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1096.2909 - val_loss: 475.3123\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1007.5853 - val_loss: 141.6132\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1016.9372 - val_loss: 1440.4954\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 967.0309 - val_loss: 1481.3353\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 908.0969 - val_loss: 175.8371\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 885.7759 - val_loss: 180.0196\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 750.8488 - val_loss: 274.4560\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 712.7983 - val_loss: 113.3477\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 632.6182 - val_loss: 369.3274\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 539.9281 - val_loss: 297.5963\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 441.2811 - val_loss: 23.1320\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 266.6296 - val_loss: 18.6497\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.4331 - val_loss: 115.7752\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 193.1023 - val_loss: 395.7635\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 179.2869 - val_loss: 76.7926\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 34.0951 - val_loss: 29.0409\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.5958 - val_loss: 62.3576\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 35.3155 - val_loss: 37.6068\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.2693 - val_loss: 32.1435\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 29.6206 - val_loss: 45.0703\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.8234 - val_loss: 24.2228\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 27.3160 - val_loss: 31.9675\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 26.4405 - val_loss: 30.8708\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 27.5052 - val_loss: 71.9155\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.8659 - val_loss: 27.0925\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.1247 - val_loss: 29.2231\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 38.4925 - val_loss: 34.5963\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 27.3235 - val_loss: 33.6690\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 29.7425 - val_loss: 44.9279\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.6701 - val_loss: 37.9044\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.3467 - val_loss: 45.8240\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.0814 - val_loss: 69.6261\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.2431 - val_loss: 33.2418\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.5046 - val_loss: 37.7326\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.1377 - val_loss: 39.2940\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.0957 - val_loss: 32.4855\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.3370 - val_loss: 27.6930\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 25.9725 - val_loss: 34.9806\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.9460 - val_loss: 30.9924\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.8107 - val_loss: 44.4215\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.8648 - val_loss: 27.1330\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.9198 - val_loss: 30.7467\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.1470 - val_loss: 31.9910\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.4655 - val_loss: 30.8141\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.9257 - val_loss: 26.3531\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.2423 - val_loss: 30.6548\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.8156 - val_loss: 31.5080\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.3811 - val_loss: 29.9370\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.5392 - val_loss: 28.6668\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.5027 - val_loss: 36.9222\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.3816 - val_loss: 43.9660\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 27.5815 - val_loss: 34.3592\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.0129 - val_loss: 40.2696\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 25.8426 - val_loss: 41.4285\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.8289 - val_loss: 36.5165\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.1027 - val_loss: 34.9968\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.4528 - val_loss: 29.9752\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.7739 - val_loss: 34.1840\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.4248 - val_loss: 29.1404\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.3894 - val_loss: 31.9948\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.2374 - val_loss: 30.9486\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.8339 - val_loss: 38.0461\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.0776 - val_loss: 34.1097\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.8228 - val_loss: 28.8057\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.4704 - val_loss: 34.7738\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.8525 - val_loss: 46.0030\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.9327 - val_loss: 33.1743\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.9663 - val_loss: 36.1666\n",
      "Epoch 80/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 27.6202 - val_loss: 43.5069\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.0942 - val_loss: 42.0681\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.6258 - val_loss: 35.8479\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.6340 - val_loss: 34.0327\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.7438 - val_loss: 35.1052\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.1398 - val_loss: 37.1021\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.1073 - val_loss: 34.0886\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6320 - val_loss: 31.5799\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.1567 - val_loss: 31.9929\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.3922 - val_loss: 35.1198\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0279 - val_loss: 35.0068\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 25.6332 - val_loss: 34.7746\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.5857 - val_loss: 39.2855\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.1254 - val_loss: 36.0476\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.8943 - val_loss: 33.9272\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.8392 - val_loss: 29.5549\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.7283 - val_loss: 28.6057\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.3545 - val_loss: 38.4979\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3508 - val_loss: 32.3340\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.3968 - val_loss: 32.8662\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.4768 - val_loss: 34.1546\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.9282 - val_loss: 31.4397\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7026 - val_loss: 35.0065\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.6080 - val_loss: 36.9761\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.9135 - val_loss: 32.8130\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.8567 - val_loss: 33.7906\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.0898 - val_loss: 38.5012\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.4789 - val_loss: 41.9732\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.7799 - val_loss: 36.7874\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.4210 - val_loss: 38.0610\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.1406 - val_loss: 35.4073\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.8641 - val_loss: 39.9690\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4451 - val_loss: 44.6022\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.5323 - val_loss: 40.3982\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.7457 - val_loss: 32.9775\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.2836 - val_loss: 33.7346\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.8072 - val_loss: 34.7473\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.3870 - val_loss: 33.8790\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.9557 - val_loss: 38.1172\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.5502 - val_loss: 30.7557\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.8722 - val_loss: 31.0823\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.1339 - val_loss: 35.5810\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.3589 - val_loss: 40.9022\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.9713 - val_loss: 53.5841\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.4854 - val_loss: 36.8543\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.8979 - val_loss: 27.7277\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6031 - val_loss: 37.2308\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.7539 - val_loss: 36.5740\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6398 - val_loss: 31.0624\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4188 - val_loss: 47.3007\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.0532 - val_loss: 27.2806\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.5389 - val_loss: 35.6946\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.4250 - val_loss: 26.5672\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 23.6937 - val_loss: 37.1056\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 26.7945 - val_loss: 37.8247\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.7310 - val_loss: 34.6564\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.8437 - val_loss: 40.5174\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.6474 - val_loss: 33.2424\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.9932 - val_loss: 37.9867\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.2109 - val_loss: 32.3457\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.5564 - val_loss: 34.9893\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.9657 - val_loss: 28.3105\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 25.4119 - val_loss: 33.9299\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.2751 - val_loss: 37.1945\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.0683 - val_loss: 68.1124\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 29.2903 - val_loss: 43.0025\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.4601 - val_loss: 30.7327\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 25.1043 - val_loss: 36.9501\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.9867 - val_loss: 40.1749\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.4092 - val_loss: 35.9003\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.7471 - val_loss: 41.6439\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6539 - val_loss: 41.0584\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7872 - val_loss: 37.1706\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.4367 - val_loss: 32.5023\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.1038 - val_loss: 32.8282\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6748 - val_loss: 44.1548\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7107 - val_loss: 42.4038\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.9212 - val_loss: 42.0163\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.3185 - val_loss: 34.6054\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.0945 - val_loss: 31.2078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.3227 - val_loss: 38.2421\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6779 - val_loss: 35.5881\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.2097 - val_loss: 33.8579\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4817 - val_loss: 33.8033\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2561 - val_loss: 28.9213\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6027 - val_loss: 29.7859\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.5319 - val_loss: 27.5515\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7432 - val_loss: 29.9130\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.1251 - val_loss: 38.7150\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2917 - val_loss: 35.6568\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.6746 - val_loss: 33.7571\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.8167 - val_loss: 34.0392\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.2389 - val_loss: 29.9350\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.1642 - val_loss: 40.6319\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.8735 - val_loss: 30.4947\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.7059 - val_loss: 37.5249\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.4464 - val_loss: 36.1088\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.4645 - val_loss: 45.1659\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.8888 - val_loss: 30.1160\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.8345 - val_loss: 42.0756\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 30.8058 - val_loss: 33.6176\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.0161 - val_loss: 30.3462\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.8074 - val_loss: 26.1175\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.9478 - val_loss: 33.5750\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.2704 - val_loss: 33.0273\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.0846 - val_loss: 29.9977\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.1594 - val_loss: 29.1787\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.9857 - val_loss: 40.7309\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.3594 - val_loss: 33.6359\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.4936 - val_loss: 31.5999\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.6626 - val_loss: 46.3125\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.2604 - val_loss: 42.8083\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.7027 - val_loss: 34.1655\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.4460 - val_loss: 32.2122\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.2453 - val_loss: 30.9741\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.4879 - val_loss: 28.7957\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.8968 - val_loss: 30.6012\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8339 - val_loss: 26.7391\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.8447 - val_loss: 38.2418\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.1758 - val_loss: 33.7914\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.2266 - val_loss: 29.7961\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.6285 - val_loss: 30.2891\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.6707 - val_loss: 28.4495\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3011 - val_loss: 30.0839\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6039 - val_loss: 26.9286\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.4997 - val_loss: 27.4173\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.3459 - val_loss: 25.0397\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.6341 - val_loss: 26.9130\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.8234 - val_loss: 44.4643\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4711 - val_loss: 28.6668\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.0366 - val_loss: 34.2801\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.9316 - val_loss: 32.3024\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.1725 - val_loss: 28.0508\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5739 - val_loss: 31.9848\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.1304 - val_loss: 29.3513\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9146 - val_loss: 26.6161\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.2261 - val_loss: 35.3675\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.7716 - val_loss: 28.0527\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7715 - val_loss: 28.4093\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9478 - val_loss: 26.0651\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1923 - val_loss: 31.5580\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2651 - val_loss: 43.7396\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.1341 - val_loss: 25.8085\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4669 - val_loss: 28.5214\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.5793 - val_loss: 44.2454\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7832 - val_loss: 29.8353\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0401 - val_loss: 33.4691\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.4677 - val_loss: 27.8722\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1711 - val_loss: 29.5680\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.3174 - val_loss: 28.7291\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 27.5563 - val_loss: 59.2266\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 24.3320 - val_loss: 42.0052\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.2738 - val_loss: 48.0491\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 27.3665 - val_loss: 28.0872\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 20.5584 - val_loss: 27.7900\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.1018 - val_loss: 41.0417\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.8738 - val_loss: 36.5560\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.7010 - val_loss: 29.5332\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.1730 - val_loss: 32.1842\n",
      "Epoch 239/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3869 - val_loss: 32.6103\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5779 - val_loss: 39.1323\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1023 - val_loss: 35.4748\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.7442 - val_loss: 28.8393\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0493 - val_loss: 28.1407\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.4929 - val_loss: 35.4423\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.5930 - val_loss: 28.6513\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3804 - val_loss: 30.7446\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2144 - val_loss: 46.4002\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5690 - val_loss: 28.9432\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.3624 - val_loss: 37.4721\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4613 - val_loss: 28.8325\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.1030 - val_loss: 28.9094\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9112 - val_loss: 29.0689\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0299 - val_loss: 31.9645\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3932 - val_loss: 30.7727\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.4011 - val_loss: 28.3072\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.5619 - val_loss: 27.0322\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1880 - val_loss: 28.1425\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6545 - val_loss: 27.9544\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2921 - val_loss: 26.2060\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9883 - val_loss: 30.1211\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3333 - val_loss: 27.0254\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.5597 - val_loss: 36.0100\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.4770 - val_loss: 33.4570\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.6310 - val_loss: 49.6602\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7854 - val_loss: 28.0883\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1400 - val_loss: 29.6166\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3659 - val_loss: 34.4844\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.6910 - val_loss: 42.6310\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.6676 - val_loss: 35.9651\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.8975 - val_loss: 40.1851\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0110 - val_loss: 37.0375\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.1154 - val_loss: 29.7288\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7643 - val_loss: 29.2721\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0964 - val_loss: 33.5919\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3054 - val_loss: 32.0535\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4967 - val_loss: 33.7066\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6883 - val_loss: 29.4260\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7063 - val_loss: 30.7361\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.0048 - val_loss: 30.0264\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.8890 - val_loss: 30.4871\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4391 - val_loss: 33.4227\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2295 - val_loss: 37.6184\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.8032 - val_loss: 42.1398\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7948 - val_loss: 35.3850\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4156 - val_loss: 34.8060\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.5247 - val_loss: 51.6088\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3444 - val_loss: 31.4995\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.2579 - val_loss: 32.5693\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.2729 - val_loss: 34.3242\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8846 - val_loss: 28.8255\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.5991 - val_loss: 32.0249\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0908 - val_loss: 32.5157\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.5896 - val_loss: 39.1103\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.1893 - val_loss: 38.0573\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.0648 - val_loss: 41.3243\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3337 - val_loss: 44.2005\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1168 - val_loss: 37.7463\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.0717 - val_loss: 29.8443\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0011 - val_loss: 35.9480\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.8113 - val_loss: 30.7867\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.1779 - val_loss: 33.2429\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1669 - val_loss: 28.1232\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.2566 - val_loss: 25.2733\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9436 - val_loss: 28.0562\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7478 - val_loss: 24.9362\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.9963 - val_loss: 31.7076\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.0995 - val_loss: 36.2821\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6746 - val_loss: 33.3705\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0627 - val_loss: 31.7330\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.0838 - val_loss: 29.8440\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4240 - val_loss: 32.8468\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3773 - val_loss: 29.9587\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4269 - val_loss: 33.0736\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9407 - val_loss: 29.8351\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6525 - val_loss: 34.2531\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4671 - val_loss: 31.8201\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.8943 - val_loss: 52.0647\n",
      "Epoch 318/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 19.8984 - val_loss: 43.0063\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4037 - val_loss: 36.1003\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.7701 - val_loss: 45.6797\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5462 - val_loss: 37.2906\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.1771 - val_loss: 49.8198\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9359 - val_loss: 37.3133\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5870 - val_loss: 30.0907\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.5342 - val_loss: 31.8139\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.3476 - val_loss: 32.0887\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.9936 - val_loss: 32.6458\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.5720 - val_loss: 26.7540\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.6192 - val_loss: 33.1181\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.1018 - val_loss: 31.7202\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.6998 - val_loss: 31.2712\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.8938 - val_loss: 27.9054\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6601 - val_loss: 38.8065\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9792 - val_loss: 44.9433\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.6508 - val_loss: 38.6953\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.5996 - val_loss: 31.3626\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.6226 - val_loss: 37.3049\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1579 - val_loss: 39.6851\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.8709 - val_loss: 39.8218\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 18.8445 - val_loss: 37.2085\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.4988 - val_loss: 41.4139\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.4127 - val_loss: 36.3099\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.2159 - val_loss: 35.5781\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6611 - val_loss: 32.5208\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.5839 - val_loss: 36.1081\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6437 - val_loss: 40.2168\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4309 - val_loss: 31.8051\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7513 - val_loss: 30.1068\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9181 - val_loss: 34.0929\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.5610 - val_loss: 30.0498\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1887 - val_loss: 34.9862\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3589 - val_loss: 34.3543\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1327 - val_loss: 36.2246\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6906 - val_loss: 28.3884\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8421 - val_loss: 29.3284\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.3741 - val_loss: 36.1154\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9565 - val_loss: 32.9066\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7626 - val_loss: 32.5993\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7303 - val_loss: 35.1459\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8821 - val_loss: 37.4205\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1290 - val_loss: 37.9288\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.2451 - val_loss: 37.8007\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9556 - val_loss: 29.8087\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2804 - val_loss: 40.3015\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3609 - val_loss: 31.3440\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.3306 - val_loss: 29.1679\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9482 - val_loss: 27.4161\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3175 - val_loss: 29.1548\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1442 - val_loss: 32.5284\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.4668 - val_loss: 38.0194\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.0664 - val_loss: 51.0995\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3320 - val_loss: 32.3579\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.7184 - val_loss: 39.0570\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0679 - val_loss: 32.2533\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9965 - val_loss: 30.6884\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4111 - val_loss: 34.6249\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5167 - val_loss: 39.6817\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7685 - val_loss: 30.8820\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8395 - val_loss: 31.7193\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1956 - val_loss: 29.4617\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.9587 - val_loss: 29.5006\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.1743 - val_loss: 35.2261\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.9767 - val_loss: 30.7735\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3833 - val_loss: 28.5465\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9636 - val_loss: 33.0816\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1127 - val_loss: 28.1184\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5437 - val_loss: 31.3490\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9064 - val_loss: 34.9987\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9132 - val_loss: 31.0594\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.7181 - val_loss: 26.4089\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3050 - val_loss: 27.8001\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.4030 - val_loss: 38.4352\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.7137 - val_loss: 32.2095\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.5594 - val_loss: 34.5101\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0546 - val_loss: 45.8642\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.3040 - val_loss: 31.3214\n",
      "Epoch 397/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 18.4218 - val_loss: 38.8459\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.2908 - val_loss: 30.2514\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9743 - val_loss: 33.5951\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4573 - val_loss: 30.6165\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7092 - val_loss: 30.0466\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.0585 - val_loss: 38.0932\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.7308 - val_loss: 34.9590\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9805 - val_loss: 32.1859\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.7884 - val_loss: 31.0198\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.4832 - val_loss: 28.9821\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.4428 - val_loss: 38.1141\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9526 - val_loss: 28.8600\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.5860 - val_loss: 31.4882\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7584 - val_loss: 29.3904\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.8824 - val_loss: 41.0463\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.8160 - val_loss: 31.4415\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.4731 - val_loss: 36.0570\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5685 - val_loss: 26.9522\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2103 - val_loss: 29.1622\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9563 - val_loss: 48.5322\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9276 - val_loss: 34.2582\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5128 - val_loss: 30.7709\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.8104 - val_loss: 31.8007\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.7746 - val_loss: 81.6406\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.2304 - val_loss: 33.2692\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.6452 - val_loss: 35.0102\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.0720 - val_loss: 35.5156\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.2663 - val_loss: 45.7482\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.3007 - val_loss: 35.9419\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9345 - val_loss: 37.8967\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.8174 - val_loss: 21.2305\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.4911 - val_loss: 38.6451\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9096 - val_loss: 34.7286\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3034 - val_loss: 44.6539\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.4008 - val_loss: 35.5965\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9224 - val_loss: 36.2175\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7263 - val_loss: 31.1851\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3255 - val_loss: 44.6832\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.2622 - val_loss: 33.0362\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.6078 - val_loss: 34.1660\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1851 - val_loss: 28.5846\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4802 - val_loss: 35.6472\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.0217 - val_loss: 32.2955\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.8521 - val_loss: 34.4218\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9745 - val_loss: 32.8004\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.9668 - val_loss: 36.9076\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.7541 - val_loss: 38.8573\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5195 - val_loss: 32.0287\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.0024 - val_loss: 33.7381\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7341 - val_loss: 47.6217\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3038 - val_loss: 34.8718\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.0580 - val_loss: 32.3225\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3808 - val_loss: 37.3740\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9422 - val_loss: 39.2220\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9691 - val_loss: 39.3566\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1918 - val_loss: 45.0002\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.2689 - val_loss: 41.5414\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.4900 - val_loss: 36.2326\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1242 - val_loss: 37.1747\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8866 - val_loss: 37.7256\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8161 - val_loss: 34.1439\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.1594 - val_loss: 33.8513\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.6159 - val_loss: 33.3159\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.8714 - val_loss: 34.5584\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 17.5920 - val_loss: 32.4507\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 17.1963 - val_loss: 31.8524\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.4043 - val_loss: 33.7749\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5173 - val_loss: 38.6807\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.2262 - val_loss: 35.3927\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.2390 - val_loss: 35.5261\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9419 - val_loss: 35.0172\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.8327 - val_loss: 35.2040\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5972 - val_loss: 30.1841\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.7459 - val_loss: 31.5587\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.4536 - val_loss: 31.2116\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.0722 - val_loss: 37.5144\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 16.2436 - val_loss: 32.4878\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.2641 - val_loss: 30.6340\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5971 - val_loss: 31.4490\n",
      "Epoch 476/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 18.2388 - val_loss: 32.6519\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1678 - val_loss: 35.8303\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1552 - val_loss: 31.4513\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.4378 - val_loss: 29.3440\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.8572 - val_loss: 28.0982\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5048 - val_loss: 43.9829\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7419 - val_loss: 30.0466\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.5659 - val_loss: 37.7024\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7415 - val_loss: 33.1005\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.4374 - val_loss: 37.8374\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1470 - val_loss: 33.2266\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.2155 - val_loss: 37.0990\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.5202 - val_loss: 36.5484\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.9910 - val_loss: 29.8578\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.2672 - val_loss: 30.0967\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.2878 - val_loss: 26.6767\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7059 - val_loss: 29.7050\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4004 - val_loss: 30.9242\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.7691 - val_loss: 25.8744\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.6529 - val_loss: 30.0187\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0574 - val_loss: 28.9553\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4727 - val_loss: 29.8167\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1283 - val_loss: 29.9256\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1280 - val_loss: 25.3259\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.2982 - val_loss: 33.4077\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 16.8220 - val_loss: 31.5337\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.3214 - val_loss: 34.5267\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.6504 - val_loss: 36.6675\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.8378 - val_loss: 30.6586\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9324 - val_loss: 31.5894\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.1996 - val_loss: 32.7397\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.1813 - val_loss: 32.4374\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5712 - val_loss: 39.9723\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 15.4700 - val_loss: 30.4049\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2494 - val_loss: 33.5743\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5699 - val_loss: 33.2468\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.1475 - val_loss: 33.4883\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.3393 - val_loss: 30.1110\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.0895 - val_loss: 42.7774\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.0098 - val_loss: 36.2266\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.0191 - val_loss: 33.7781\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.7518 - val_loss: 44.3932\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9139 - val_loss: 40.7465\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.7836 - val_loss: 32.3112\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.6011 - val_loss: 37.5079\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.8499 - val_loss: 37.5116\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 16.1513 - val_loss: 28.4900\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 15.8276 - val_loss: 27.1933\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1847 - val_loss: 30.9796\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.4034 - val_loss: 36.9433\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.2726 - val_loss: 31.7768\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2276 - val_loss: 28.0477\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.4156 - val_loss: 31.7430\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.2798 - val_loss: 38.1755\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.2870 - val_loss: 31.7280\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.4095 - val_loss: 31.6543\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.2359 - val_loss: 31.1326\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.0789 - val_loss: 27.5414\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.1436 - val_loss: 33.8586\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.8925 - val_loss: 36.2990\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4192 - val_loss: 30.2818\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.8141 - val_loss: 28.4081\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.8828 - val_loss: 30.3137\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.8364 - val_loss: 28.5711\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.1902 - val_loss: 29.3717\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.0623 - val_loss: 29.4237\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5515 - val_loss: 37.4697\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5938 - val_loss: 40.5024\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2426 - val_loss: 30.1569\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.3870 - val_loss: 31.2404\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.6243 - val_loss: 35.9852\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.0547 - val_loss: 27.8936\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3538 - val_loss: 32.1739\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.1172 - val_loss: 29.4590\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9152 - val_loss: 41.4236\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2827 - val_loss: 30.0125\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.0151 - val_loss: 34.7374\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5241 - val_loss: 31.1598\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.1929 - val_loss: 37.8942\n",
      "Epoch 555/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 16.5374 - val_loss: 37.0744\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9443 - val_loss: 33.3995\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.7223 - val_loss: 36.2008\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8114 - val_loss: 34.5448\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9808 - val_loss: 33.1460\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.4929 - val_loss: 30.3673\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5573 - val_loss: 34.9694\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.6419 - val_loss: 30.7075\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.0008 - val_loss: 36.5050\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.2102 - val_loss: 37.7546\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.6668 - val_loss: 32.4317\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.2004 - val_loss: 31.7808\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.2206 - val_loss: 29.6584\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.3612 - val_loss: 31.6116\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.5837 - val_loss: 35.2462\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2085 - val_loss: 31.6887\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.3360 - val_loss: 44.1975\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.4651 - val_loss: 30.5460\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.8928 - val_loss: 33.9474\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9138 - val_loss: 30.3015\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9851 - val_loss: 37.2099\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.8496 - val_loss: 41.2950\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.5165 - val_loss: 30.7409\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.0349 - val_loss: 35.8484\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4653 - val_loss: 32.9426\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9913 - val_loss: 31.5308\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.1567 - val_loss: 41.6081\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4291 - val_loss: 30.8534\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.0152 - val_loss: 30.8510\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8651 - val_loss: 31.6657\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9327 - val_loss: 28.9899\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.8705 - val_loss: 44.2301\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9014 - val_loss: 31.7849\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9300 - val_loss: 34.4231\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.6762 - val_loss: 46.9650\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.7418 - val_loss: 36.0988\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.0085 - val_loss: 31.1091\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2255 - val_loss: 28.8723\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4575 - val_loss: 30.8398\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8391 - val_loss: 31.8028\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5559 - val_loss: 28.3311\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9269 - val_loss: 29.5654\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.8430 - val_loss: 28.9950\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8501 - val_loss: 29.4345\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.5506 - val_loss: 29.5971\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.7027 - val_loss: 29.2777\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4369 - val_loss: 29.8937\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.5261 - val_loss: 37.4823\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3741 - val_loss: 38.5742\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4460 - val_loss: 33.2441\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4131 - val_loss: 39.5438\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.5574 - val_loss: 36.0323\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9779 - val_loss: 30.0847\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.8224 - val_loss: 38.4555\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5041 - val_loss: 31.6786\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7095 - val_loss: 33.3706\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4506 - val_loss: 33.3367\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.6397 - val_loss: 30.9272\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9016 - val_loss: 32.8404\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.3430 - val_loss: 34.2589\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9141 - val_loss: 34.5065\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2779 - val_loss: 33.8568\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.5561 - val_loss: 31.5594\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9319 - val_loss: 31.1669\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2541 - val_loss: 37.4570\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7520 - val_loss: 35.0894\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.3627 - val_loss: 30.1111\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.3427 - val_loss: 30.5643\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.5882 - val_loss: 30.4516\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.3703 - val_loss: 34.1360\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.8856 - val_loss: 37.3318\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.7382 - val_loss: 32.4559\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.2736 - val_loss: 42.8071\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.3063 - val_loss: 31.4079\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9352 - val_loss: 35.0216\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9256 - val_loss: 32.1267\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9516 - val_loss: 38.5301\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.0508 - val_loss: 36.1037\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.2838 - val_loss: 32.9186\n",
      "Epoch 634/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4498 - val_loss: 31.3222\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9368 - val_loss: 31.8823\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.5774 - val_loss: 31.3016\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7957 - val_loss: 36.7440\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4566 - val_loss: 30.8211\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4266 - val_loss: 39.2726\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.1147 - val_loss: 28.9961\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4441 - val_loss: 41.4246\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1363 - val_loss: 33.2300\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4521 - val_loss: 31.2899\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.3509 - val_loss: 28.3398\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.2638 - val_loss: 34.1677\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.0420 - val_loss: 36.8508\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.3998 - val_loss: 36.0553\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.3291 - val_loss: 28.0391\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3214 - val_loss: 39.6167\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7092 - val_loss: 43.0633\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.2768 - val_loss: 33.0979\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9871 - val_loss: 36.4252\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.4234 - val_loss: 32.3548\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.1174 - val_loss: 37.1191\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.3527 - val_loss: 35.2051\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.6535 - val_loss: 31.8407\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.0453 - val_loss: 40.6086\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9563 - val_loss: 35.9880\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.5435 - val_loss: 36.9170\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2153 - val_loss: 32.1625\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5970 - val_loss: 34.6989\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.2560 - val_loss: 29.7217\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.0365 - val_loss: 31.8986\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8225 - val_loss: 34.1608\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.7755 - val_loss: 35.1613\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.5094 - val_loss: 30.1238\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6817 - val_loss: 32.7727\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.4851 - val_loss: 31.5699\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8562 - val_loss: 34.9439\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5412 - val_loss: 33.0335\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.2761 - val_loss: 39.2530\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.2151 - val_loss: 31.5539\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.4146 - val_loss: 30.5447\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.6772 - val_loss: 38.1684\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.8596 - val_loss: 34.3715\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6584 - val_loss: 35.1592\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.3208 - val_loss: 32.5972\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.1454 - val_loss: 32.2159\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.5688 - val_loss: 38.3175\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0191 - val_loss: 34.0104\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.8592 - val_loss: 32.4162\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9460 - val_loss: 34.0769\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6834 - val_loss: 39.7587\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.1965 - val_loss: 32.1711\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.1295 - val_loss: 32.7370\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9631 - val_loss: 34.9691\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.8224 - val_loss: 48.2334\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.6117 - val_loss: 31.7178\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8325 - val_loss: 34.9823\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5200 - val_loss: 30.7249\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.6637 - val_loss: 30.9615\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.7949 - val_loss: 36.7535\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4831 - val_loss: 40.6242\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4500 - val_loss: 33.2102\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.3597 - val_loss: 36.9960\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.0004 - val_loss: 37.2997\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5153 - val_loss: 31.1597\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.6113 - val_loss: 36.4777\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0827 - val_loss: 32.4259\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2435 - val_loss: 30.7465\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.1484 - val_loss: 34.1353\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4856 - val_loss: 30.9567\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8606 - val_loss: 32.6372\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8754 - val_loss: 34.1259\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.9832 - val_loss: 34.9544\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8253 - val_loss: 37.2211\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8528 - val_loss: 38.9952\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2786 - val_loss: 33.0805\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4317 - val_loss: 34.3855\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9548 - val_loss: 33.2051\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.1783 - val_loss: 28.4533\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8435 - val_loss: 36.7401\n",
      "Epoch 713/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4084 - val_loss: 36.8769\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4957 - val_loss: 29.5009\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.3680 - val_loss: 32.3937\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4897 - val_loss: 37.1305\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8218 - val_loss: 28.8053\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.8405 - val_loss: 37.4373\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7737 - val_loss: 36.6749\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9655 - val_loss: 36.0785\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.3152 - val_loss: 36.0920\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9919 - val_loss: 37.6793\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.3989 - val_loss: 36.4908\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9938 - val_loss: 38.8866\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5092 - val_loss: 30.7357\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8544 - val_loss: 32.2575\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4107 - val_loss: 29.8603\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.6161 - val_loss: 34.7632\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7405 - val_loss: 36.9542\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5329 - val_loss: 30.6419\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.3744 - val_loss: 34.9225\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.0145 - val_loss: 32.0572\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.6047 - val_loss: 31.8299\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6451 - val_loss: 32.9919\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.6264 - val_loss: 30.6849\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.3678 - val_loss: 35.8960\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.7197 - val_loss: 32.6946\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.1635 - val_loss: 30.0933\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.8626 - val_loss: 29.1882\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.7366 - val_loss: 33.6034\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.6090 - val_loss: 33.6533\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9563 - val_loss: 39.7510\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3226 - val_loss: 35.0134\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3620 - val_loss: 31.1911\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.1699 - val_loss: 30.7562\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.1273 - val_loss: 29.9392\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4901 - val_loss: 29.4453\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7931 - val_loss: 38.2187\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.7939 - val_loss: 38.0522\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.1406 - val_loss: 39.7524\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2183 - val_loss: 40.0583\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2411 - val_loss: 31.7384\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4161 - val_loss: 35.4321\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2503 - val_loss: 36.6129\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4118 - val_loss: 35.8834\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.0774 - val_loss: 34.1593\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8820 - val_loss: 34.5171\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.6941 - val_loss: 35.3219\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.0927 - val_loss: 36.3763\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.0019 - val_loss: 34.1252\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5439 - val_loss: 32.2067\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.6795 - val_loss: 32.5467\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4427 - val_loss: 32.9647\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.5647 - val_loss: 32.3521\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.1990 - val_loss: 33.0069\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1505 - val_loss: 35.9252\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8026 - val_loss: 33.5733\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.0706 - val_loss: 37.6880\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9250 - val_loss: 34.7220\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.6849 - val_loss: 37.3929\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9727 - val_loss: 32.6772\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4135 - val_loss: 38.8859\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5183 - val_loss: 30.4905\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9453 - val_loss: 43.2163\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8177 - val_loss: 33.8378\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4003 - val_loss: 30.7968\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9962 - val_loss: 30.9674\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8711 - val_loss: 31.6195\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.7850 - val_loss: 39.6594\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2383 - val_loss: 34.1354\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9061 - val_loss: 34.0345\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.5173 - val_loss: 40.2866\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8071 - val_loss: 35.4911\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2576 - val_loss: 32.1919\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4624 - val_loss: 34.0833\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.1851 - val_loss: 35.4315\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9339 - val_loss: 33.2452\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.1444 - val_loss: 32.1956\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.0073 - val_loss: 30.5411\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3771 - val_loss: 33.6862\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9519 - val_loss: 32.7339\n",
      "Epoch 792/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9792 - val_loss: 58.0512\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2458 - val_loss: 45.1881\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.0777 - val_loss: 44.2814\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.3482 - val_loss: 33.1887\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8142 - val_loss: 33.6313\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.7737 - val_loss: 35.3917\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.7046 - val_loss: 34.6681\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.1319 - val_loss: 31.6589\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.2842 - val_loss: 35.7590\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4392 - val_loss: 36.6523\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7048 - val_loss: 45.7396\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7519 - val_loss: 34.7192\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14.2812 - val_loss: 36.8395\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.7949 - val_loss: 33.4686\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.1650 - val_loss: 34.9772\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.2356 - val_loss: 31.5087\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9773 - val_loss: 36.7762\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.8008 - val_loss: 33.7779\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6881 - val_loss: 33.0865\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3944 - val_loss: 30.4230\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4155 - val_loss: 36.2977\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4661 - val_loss: 34.7623\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.7127 - val_loss: 33.4550\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.1725 - val_loss: 33.6639\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9233 - val_loss: 31.8668\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4322 - val_loss: 37.3124\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3948 - val_loss: 37.3335\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3972 - val_loss: 29.6641\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4054 - val_loss: 39.1099\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.1489 - val_loss: 31.0464\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4732 - val_loss: 32.8104\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8557 - val_loss: 28.6952\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3275 - val_loss: 34.3258\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.5250 - val_loss: 36.1471\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.8444 - val_loss: 29.6338\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4735 - val_loss: 31.2769\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.9840 - val_loss: 34.9781\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8394 - val_loss: 33.0596\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8574 - val_loss: 34.7119\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8298 - val_loss: 32.7586\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.0148 - val_loss: 35.2240\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4513 - val_loss: 35.6385\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.9210 - val_loss: 37.7302\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8985 - val_loss: 29.4120\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.1653 - val_loss: 35.2572\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.5984 - val_loss: 36.2186\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4000 - val_loss: 33.2700\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3432 - val_loss: 30.6187\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5382 - val_loss: 35.2763\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.0449 - val_loss: 38.3364\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14.7810 - val_loss: 26.9295\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.6147 - val_loss: 29.6482\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.3055 - val_loss: 32.1701\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.3617 - val_loss: 45.1250\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.3218 - val_loss: 30.1288\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8624 - val_loss: 36.8607\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.3181 - val_loss: 34.2259\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8097 - val_loss: 32.1036\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4142 - val_loss: 32.4119\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5643 - val_loss: 33.9408\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6529 - val_loss: 34.2875\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5586 - val_loss: 43.6348\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.0795 - val_loss: 31.5546\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12.8965 - val_loss: 37.8478\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4941 - val_loss: 32.2082\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5912 - val_loss: 39.0037\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3312 - val_loss: 34.0938\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.2245 - val_loss: 34.1430\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4898 - val_loss: 36.2851\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4719 - val_loss: 33.1912\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.1689 - val_loss: 34.9247\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8035 - val_loss: 47.1913\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6856 - val_loss: 32.5594\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14.4634 - val_loss: 40.4071\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.5421 - val_loss: 30.0853\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.3327 - val_loss: 31.8512\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.2470 - val_loss: 30.9705\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.0562 - val_loss: 43.3734\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2861 - val_loss: 43.3248\n",
      "Epoch 871/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 13.3577 - val_loss: 59.4836\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.2683 - val_loss: 41.0272\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5392 - val_loss: 37.7652\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4256 - val_loss: 31.1933\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.3685 - val_loss: 31.7528\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14.2768 - val_loss: 39.4805\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.5081 - val_loss: 45.2751\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.3811 - val_loss: 36.3057\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3752 - val_loss: 35.3601\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.7412 - val_loss: 34.2964\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.9170 - val_loss: 32.1684\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1560 - val_loss: 39.9831\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.5739 - val_loss: 45.0501\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.0023 - val_loss: 32.3850\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3850 - val_loss: 34.1352\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3758 - val_loss: 30.8581\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.6694 - val_loss: 37.3508\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6350 - val_loss: 36.8974\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4414 - val_loss: 37.2117\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12.7116 - val_loss: 31.5786\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.5738 - val_loss: 33.0901\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.9051 - val_loss: 34.8337\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.6325 - val_loss: 35.1991\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.7307 - val_loss: 50.1348\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4198 - val_loss: 32.4064\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.7524 - val_loss: 30.7190\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2776 - val_loss: 40.5347\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.2632 - val_loss: 30.8494\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8910 - val_loss: 33.6753\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8826 - val_loss: 28.9624\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1709 - val_loss: 28.9455\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8327 - val_loss: 39.7204\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8105 - val_loss: 34.9071\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.6367 - val_loss: 32.3055\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4404 - val_loss: 35.6219\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4133 - val_loss: 42.8099\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.7926 - val_loss: 47.2823\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4922 - val_loss: 36.7597\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.0222 - val_loss: 46.1243\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.7808 - val_loss: 46.9857\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.3601 - val_loss: 32.1263\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1385 - val_loss: 42.0780\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3684 - val_loss: 39.7240\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6435 - val_loss: 45.6658\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4818 - val_loss: 45.5953\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4548 - val_loss: 32.6259\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.2620 - val_loss: 39.0327\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8054 - val_loss: 56.7722\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6666 - val_loss: 40.4100\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.5309 - val_loss: 35.3536\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.9527 - val_loss: 41.5738\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4757 - val_loss: 37.3315\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.1313 - val_loss: 37.5423\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.1823 - val_loss: 30.3083\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1150 - val_loss: 27.7990\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.7513 - val_loss: 33.9613\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.3813 - val_loss: 39.8809\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6903 - val_loss: 32.8324\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1852 - val_loss: 31.5237\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.1337 - val_loss: 32.2864\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.0211 - val_loss: 37.2580\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.7519 - val_loss: 40.0934\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2376 - val_loss: 45.6335\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.5460 - val_loss: 47.5792\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.2737 - val_loss: 28.9633\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.5559 - val_loss: 44.2653\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8132 - val_loss: 32.4693\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4929 - val_loss: 39.9462\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3617 - val_loss: 36.7294\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.2455 - val_loss: 60.3228\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.0969 - val_loss: 35.2750\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.2771 - val_loss: 49.2458\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.5080 - val_loss: 39.3543\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.9745 - val_loss: 37.5880\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9032 - val_loss: 34.5527\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.2103 - val_loss: 35.6369\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3745 - val_loss: 32.1142\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.5949 - val_loss: 32.1591\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1922 - val_loss: 32.4366\n",
      "Epoch 950/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 11.9837 - val_loss: 36.0888\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.8174 - val_loss: 52.9515\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.7975 - val_loss: 34.8704\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.6518 - val_loss: 54.9135\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1523 - val_loss: 40.1852\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4376 - val_loss: 35.4770\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14.2072 - val_loss: 48.3078\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8324 - val_loss: 35.2149\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4197 - val_loss: 36.6208\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4484 - val_loss: 44.3403\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.2036 - val_loss: 34.7744\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.9097 - val_loss: 38.5092\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4771 - val_loss: 38.0113\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3438 - val_loss: 42.7990\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.0173 - val_loss: 37.4186\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3476 - val_loss: 48.5872\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4461 - val_loss: 30.5252\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.4251 - val_loss: 53.2892\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.2517 - val_loss: 42.5800\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.3725 - val_loss: 41.7668\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.2447 - val_loss: 44.9950\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4393 - val_loss: 39.5785\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.7894 - val_loss: 47.4229\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.7396 - val_loss: 38.6010\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.6876 - val_loss: 38.0847\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.2101 - val_loss: 37.8573\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.3034 - val_loss: 36.0107\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.5683 - val_loss: 35.6000\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4267 - val_loss: 42.9248\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.4092 - val_loss: 45.7592\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.5048 - val_loss: 34.6792\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3318 - val_loss: 45.1276\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.9128 - val_loss: 44.2446\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.3802 - val_loss: 57.3635\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.6243 - val_loss: 50.7022\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12.1941 - val_loss: 43.5790\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.9073 - val_loss: 42.3383\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3710 - val_loss: 39.4755\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.9176 - val_loss: 45.6167\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.0364 - val_loss: 45.0865\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.6946 - val_loss: 40.7543\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.0105 - val_loss: 43.1346\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.7899 - val_loss: 38.6312\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.9730 - val_loss: 36.1709\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.6532 - val_loss: 38.2975\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.9542 - val_loss: 34.5596\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.3945 - val_loss: 42.9747\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.0775 - val_loss: 42.6086\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.3429 - val_loss: 37.0505\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.2875 - val_loss: 43.8695\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.0682 - val_loss: 41.3986\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11.2085 - val_loss: 38.6453\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1224 - val_loss: 42.6690\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.7971 - val_loss: 38.1897\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1857 - val_loss: 42.3522\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8942 - val_loss: 38.1506\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.4699 - val_loss: 42.4456\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.7407 - val_loss: 44.6610\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.0635 - val_loss: 48.1401\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11.8425 - val_loss: 40.1774\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.8707 - val_loss: 34.8477\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8350 - val_loss: 43.2303\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4285 - val_loss: 49.2357\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.4742 - val_loss: 43.1108\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.3739 - val_loss: 62.5462\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.2170 - val_loss: 43.8369\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.9554 - val_loss: 60.0982\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1729 - val_loss: 45.7954\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8576 - val_loss: 42.7813\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.6282 - val_loss: 62.4904\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.7552 - val_loss: 41.6989\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8112 - val_loss: 45.9836\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.9629 - val_loss: 47.7699\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1624 - val_loss: 64.1778\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.2972 - val_loss: 54.6444\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11.8020 - val_loss: 43.6956\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.6519 - val_loss: 46.6268\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11.5742 - val_loss: 37.8703\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1640 - val_loss: 39.1190\n",
      "Epoch 1029/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 12.3645 - val_loss: 38.4567\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8568 - val_loss: 45.7148\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.4478 - val_loss: 45.0768\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.0843 - val_loss: 37.7155\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4827 - val_loss: 43.9320\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.4418 - val_loss: 38.2197\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.5483 - val_loss: 47.4809\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.3927 - val_loss: 44.4387\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.9713 - val_loss: 48.2355\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.2891 - val_loss: 41.5093\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.1273 - val_loss: 44.5301\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5123 - val_loss: 48.2780\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.7505 - val_loss: 46.5175\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.6193 - val_loss: 37.2397\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.5347 - val_loss: 52.9401\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.2814 - val_loss: 46.3114\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3617 - val_loss: 40.8891\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.2454 - val_loss: 46.6223\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.9988 - val_loss: 51.8147\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.8122 - val_loss: 32.7250\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11.3471 - val_loss: 45.3755\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11.7342 - val_loss: 52.7150\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.9900 - val_loss: 66.4299\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.4972 - val_loss: 53.1050\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.8391 - val_loss: 42.4416\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4458 - val_loss: 49.4042\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.7486 - val_loss: 44.0355\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.7233 - val_loss: 39.9142\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4673 - val_loss: 46.3092\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.7261 - val_loss: 49.5068\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.5249 - val_loss: 52.4962\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9619 - val_loss: 54.1409\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.9031 - val_loss: 44.6247\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.1259 - val_loss: 55.1011\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.5233 - val_loss: 51.3053\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.1679 - val_loss: 55.6327\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.3806 - val_loss: 49.0903\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.3933 - val_loss: 47.4394\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.9628 - val_loss: 50.0006\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11.8390 - val_loss: 52.1154\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.2172 - val_loss: 44.9632\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.1520 - val_loss: 49.3456\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.5706 - val_loss: 43.6163\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.7342 - val_loss: 53.6147\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.5402 - val_loss: 44.8478\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.1425 - val_loss: 43.9505\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.5393 - val_loss: 48.8722\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.2004 - val_loss: 52.1473\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7894 - val_loss: 54.0354\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.2194 - val_loss: 53.8458\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.0342 - val_loss: 43.6714\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.9824 - val_loss: 56.1447\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.5061 - val_loss: 49.5276\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.9265 - val_loss: 52.0131\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9788 - val_loss: 54.6507\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.5871 - val_loss: 62.6554\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12.5994 - val_loss: 50.6528\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.4753 - val_loss: 42.0463\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.2814 - val_loss: 45.2869\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.8769 - val_loss: 50.0593\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.9428 - val_loss: 51.6047\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.6136 - val_loss: 47.6991\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.1874 - val_loss: 61.0992\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.9163 - val_loss: 43.3208\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.4010 - val_loss: 57.7679\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.4711 - val_loss: 49.2965\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.4118 - val_loss: 47.1124\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.9850 - val_loss: 49.1237\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.9283 - val_loss: 52.4953\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9123 - val_loss: 46.5009\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.2020 - val_loss: 43.4526\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9969 - val_loss: 51.8881\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.2198 - val_loss: 47.2867\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.7668 - val_loss: 45.6350\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.8632 - val_loss: 51.5455\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.1250 - val_loss: 49.6116\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.4730 - val_loss: 45.2906\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6105 - val_loss: 49.7125\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.9932 - val_loss: 49.0317\n",
      "Epoch 1108/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1145 - val_loss: 46.2033\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.8296 - val_loss: 48.6383\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.4243 - val_loss: 41.2875\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.5904 - val_loss: 44.6231\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.0886 - val_loss: 51.5055\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.7687 - val_loss: 43.9396\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.4321 - val_loss: 53.0482\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9545 - val_loss: 45.1691\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6993 - val_loss: 47.4031\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6092 - val_loss: 44.6587\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.6241 - val_loss: 46.9135\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1143 - val_loss: 39.5766\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1150 - val_loss: 46.8937\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.0514 - val_loss: 42.3092\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.0098 - val_loss: 51.5239\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.8970 - val_loss: 48.6754\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.3272 - val_loss: 44.6518\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5115 - val_loss: 40.3893\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.4212 - val_loss: 54.3741\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5985 - val_loss: 45.7795\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.3900 - val_loss: 51.0255\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.7768 - val_loss: 45.4506\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.6081 - val_loss: 46.4619\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.4305 - val_loss: 46.9449\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.5769 - val_loss: 52.1366\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.6921 - val_loss: 47.0331\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.2880 - val_loss: 46.6105\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.4763 - val_loss: 50.3250\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6105 - val_loss: 47.0620\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6724 - val_loss: 48.0188\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.9798 - val_loss: 52.8797\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.3425 - val_loss: 55.5894\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6514 - val_loss: 49.2156\n",
      "Epoch 1141/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8424 - val_loss: 55.4644\n",
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.7817 - val_loss: 45.3609\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6705 - val_loss: 43.4009\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.2720 - val_loss: 50.4893\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.8672 - val_loss: 47.1314\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.6928 - val_loss: 50.4335\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5793 - val_loss: 50.2218\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1480 - val_loss: 51.9977\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.3153 - val_loss: 46.7679\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.7956 - val_loss: 49.8246\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.4645 - val_loss: 56.7965\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.2945 - val_loss: 53.4393\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.3152 - val_loss: 48.5356\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.9832 - val_loss: 49.0010\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5933 - val_loss: 49.7358\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.8891 - val_loss: 57.8441\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.7142 - val_loss: 49.4191\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.9790 - val_loss: 56.8635\n",
      "Epoch 1159/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.3473 - val_loss: 62.7938\n",
      "Epoch 1160/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.6904 - val_loss: 54.7988\n",
      "Epoch 1161/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.6632 - val_loss: 56.9013\n",
      "Epoch 1162/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.6503 - val_loss: 58.4942\n",
      "Epoch 1163/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.3093 - val_loss: 56.3900\n",
      "Epoch 1164/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.3539 - val_loss: 62.7267\n",
      "Epoch 1165/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.3828 - val_loss: 51.2206\n",
      "Epoch 1166/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.5948 - val_loss: 54.2506\n",
      "Epoch 1167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.3172 - val_loss: 49.5982\n",
      "Epoch 1168/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.4955 - val_loss: 57.7223\n",
      "Epoch 1169/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5489 - val_loss: 52.2554\n",
      "Epoch 1170/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.7523 - val_loss: 45.8593\n",
      "Epoch 1171/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.0068 - val_loss: 49.5592\n",
      "Epoch 1172/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.1449 - val_loss: 49.0458\n",
      "Epoch 1173/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.2878 - val_loss: 50.5534\n",
      "Epoch 1174/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.9947 - val_loss: 49.7530\n",
      "Epoch 1175/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.4870 - val_loss: 53.2337\n",
      "Epoch 1176/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.7112 - val_loss: 60.3028\n",
      "Epoch 1177/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.0905 - val_loss: 47.6282\n",
      "Epoch 1178/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5109 - val_loss: 55.3057\n",
      "Epoch 1179/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7990 - val_loss: 54.7128\n",
      "Epoch 1180/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6082 - val_loss: 55.2572\n",
      "Epoch 1181/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.3952 - val_loss: 61.4754\n",
      "Epoch 1182/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.2210 - val_loss: 45.3920\n",
      "Epoch 1183/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5416 - val_loss: 53.6946\n",
      "Epoch 1184/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.4234 - val_loss: 57.0202\n",
      "Epoch 1185/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1777 - val_loss: 50.5670\n",
      "Epoch 1186/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.3526 - val_loss: 57.5246\n",
      "Epoch 1187/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 8.9401 - val_loss: 57.2324\n",
      "Epoch 1188/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.5649 - val_loss: 44.3685\n",
      "Epoch 1189/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.2015 - val_loss: 55.1736\n",
      "Epoch 1190/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.8200 - val_loss: 55.0418\n",
      "Epoch 1191/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.6164 - val_loss: 48.5350\n",
      "Epoch 1192/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.8392 - val_loss: 54.4326\n",
      "Epoch 1193/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.8234 - val_loss: 54.2729\n",
      "Epoch 1194/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.0325 - val_loss: 52.2374\n",
      "Epoch 1195/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.4366 - val_loss: 55.2501\n",
      "Epoch 1196/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9821 - val_loss: 50.1821\n",
      "Epoch 1197/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.9226 - val_loss: 67.7383\n",
      "Epoch 1198/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.9683 - val_loss: 57.1054\n",
      "Epoch 1199/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1427 - val_loss: 52.0712\n",
      "Epoch 1200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.2837 - val_loss: 50.5152\n",
      "Epoch 1201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5912 - val_loss: 52.2769\n",
      "Epoch 1202/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9900 - val_loss: 61.2433\n",
      "Epoch 1203/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.3668 - val_loss: 54.7543\n",
      "Epoch 1204/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.1589 - val_loss: 54.7802\n",
      "Epoch 1205/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.2138 - val_loss: 45.6385\n",
      "Epoch 1206/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.0850 - val_loss: 48.7141\n",
      "Epoch 1207/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2325 - val_loss: 57.6679\n",
      "Epoch 1208/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.8869 - val_loss: 52.5544\n",
      "Epoch 1209/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6676 - val_loss: 56.7290\n",
      "Epoch 1210/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7552 - val_loss: 51.6641\n",
      "Epoch 1211/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.7015 - val_loss: 52.3469\n",
      "Epoch 1212/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.0479 - val_loss: 55.7137\n",
      "Epoch 1213/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.1131 - val_loss: 52.1459\n",
      "Epoch 1214/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5026 - val_loss: 51.3948\n",
      "Epoch 1215/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8973 - val_loss: 61.8797\n",
      "Epoch 1216/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2997 - val_loss: 59.7748\n",
      "Epoch 1217/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9642 - val_loss: 63.4784\n",
      "Epoch 1218/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11.1290 - val_loss: 62.6515\n",
      "Epoch 1219/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.0799 - val_loss: 56.0477\n",
      "Epoch 1220/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.2796 - val_loss: 51.1286\n",
      "Epoch 1221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.0204 - val_loss: 64.2104\n",
      "Epoch 1222/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.1809 - val_loss: 55.4393\n",
      "Epoch 1223/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8630 - val_loss: 58.0270\n",
      "Epoch 1224/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.3815 - val_loss: 60.1249\n",
      "Epoch 1225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.2533 - val_loss: 61.8596\n",
      "Epoch 1226/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.4852 - val_loss: 53.8030\n",
      "Epoch 1227/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.9101 - val_loss: 62.2447\n",
      "Epoch 1228/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.3861 - val_loss: 51.8058\n",
      "Epoch 1229/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9195 - val_loss: 55.2890\n",
      "Epoch 1230/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.9136 - val_loss: 55.1047\n",
      "Epoch 1231/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.1285 - val_loss: 55.0337\n",
      "Epoch 1232/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.0659 - val_loss: 62.4146\n",
      "Epoch 1233/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2259 - val_loss: 81.6836\n",
      "Epoch 1234/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1952 - val_loss: 62.0397\n",
      "Epoch 1235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.7765 - val_loss: 49.1236\n",
      "Epoch 1236/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.8741 - val_loss: 63.5857\n",
      "Epoch 1237/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5889 - val_loss: 59.6672\n",
      "Epoch 1238/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.5661 - val_loss: 52.5075\n",
      "Epoch 1239/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7336 - val_loss: 51.9245\n",
      "Epoch 1240/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8747 - val_loss: 54.6894\n",
      "Epoch 1241/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.7729 - val_loss: 50.3139\n",
      "Epoch 1242/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.7468 - val_loss: 64.0180\n",
      "Epoch 1243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6201 - val_loss: 59.8597\n",
      "Epoch 1244/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.0117 - val_loss: 53.5216\n",
      "Epoch 1245/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5470 - val_loss: 54.2049\n",
      "Epoch 1246/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6118 - val_loss: 51.4907\n",
      "Epoch 1247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8052 - val_loss: 58.4807\n",
      "Epoch 1248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.7119 - val_loss: 55.4582\n",
      "Epoch 1249/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8059 - val_loss: 49.5258\n",
      "Epoch 1250/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6279 - val_loss: 46.2193\n",
      "Epoch 1251/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8669 - val_loss: 56.0616\n",
      "Epoch 1252/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.4381 - val_loss: 58.6819\n",
      "Epoch 1253/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1667 - val_loss: 53.2496\n",
      "Epoch 1254/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6223 - val_loss: 54.9480\n",
      "Epoch 1255/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.9285 - val_loss: 51.9781\n",
      "Epoch 1256/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.8399 - val_loss: 52.8236\n",
      "Epoch 1257/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9651 - val_loss: 54.2682\n",
      "Epoch 1258/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.4786 - val_loss: 55.7890\n",
      "Epoch 1259/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6098 - val_loss: 50.3019\n",
      "Epoch 1260/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8277 - val_loss: 58.4347\n",
      "Epoch 1261/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6103 - val_loss: 50.6975\n",
      "Epoch 1262/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.2053 - val_loss: 51.6576\n",
      "Epoch 1263/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6819 - val_loss: 61.7762\n",
      "Epoch 1264/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6046 - val_loss: 50.9574\n",
      "Epoch 1265/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5057 - val_loss: 63.0503\n",
      "Epoch 1266/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2683 - val_loss: 59.0172\n",
      "Epoch 1267/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.3082 - val_loss: 48.9166\n",
      "Epoch 1268/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.1211 - val_loss: 62.6254\n",
      "Epoch 1269/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2593 - val_loss: 59.4994\n",
      "Epoch 1270/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.8432 - val_loss: 50.8547\n",
      "Epoch 1271/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.9450 - val_loss: 54.4274\n",
      "Epoch 1272/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.2281 - val_loss: 56.5371\n",
      "Epoch 1273/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7751 - val_loss: 50.8791\n",
      "Epoch 1274/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8726 - val_loss: 57.6260\n",
      "Epoch 1275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8995 - val_loss: 53.1891\n",
      "Epoch 1276/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9313 - val_loss: 53.3016\n",
      "Epoch 1277/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.1784 - val_loss: 45.5986\n",
      "Epoch 1278/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.1050 - val_loss: 48.4167\n",
      "Epoch 1279/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.3438 - val_loss: 48.6074\n",
      "Epoch 1280/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.4052 - val_loss: 49.5202\n",
      "Epoch 1281/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.8115 - val_loss: 54.9866\n",
      "Epoch 1282/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11.1377 - val_loss: 63.9420\n",
      "Epoch 1283/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8767 - val_loss: 59.4269\n",
      "Epoch 1284/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.4004 - val_loss: 55.8346\n",
      "Epoch 1285/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5145 - val_loss: 57.5069\n",
      "Epoch 1286/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8835 - val_loss: 54.0910\n",
      "Epoch 1287/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9106 - val_loss: 57.7957\n",
      "Epoch 1288/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7246 - val_loss: 61.4116\n",
      "Epoch 1289/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1777 - val_loss: 49.5985\n",
      "Epoch 1290/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.4734 - val_loss: 54.7402\n",
      "Epoch 1291/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6067 - val_loss: 51.5388\n",
      "Epoch 1292/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2335 - val_loss: 53.5868\n",
      "Epoch 1293/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.8913 - val_loss: 61.9980\n",
      "Epoch 1294/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.0460 - val_loss: 55.1448\n",
      "Epoch 1295/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.5552 - val_loss: 52.2097\n",
      "Epoch 1296/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9650 - val_loss: 52.3356\n",
      "Epoch 1297/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6673 - val_loss: 64.7984\n",
      "Epoch 1298/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.4345 - val_loss: 55.2011\n",
      "Epoch 1299/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7444 - val_loss: 50.9356\n",
      "Epoch 1300/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2738 - val_loss: 60.8311\n",
      "Epoch 1301/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5817 - val_loss: 51.2157\n",
      "Epoch 1302/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.7927 - val_loss: 44.5744\n",
      "Epoch 1303/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.9168 - val_loss: 49.0606\n",
      "Epoch 1304/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.3077 - val_loss: 60.7201\n",
      "Epoch 1305/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5200 - val_loss: 58.5636\n",
      "Epoch 1306/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.8533 - val_loss: 48.4648\n",
      "Epoch 1307/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1459 - val_loss: 62.6481\n",
      "Epoch 1308/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.3965 - val_loss: 52.6976\n",
      "Epoch 1309/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11.5470 - val_loss: 45.6701\n",
      "Epoch 1310/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.4901 - val_loss: 47.7716\n",
      "Epoch 1311/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7039 - val_loss: 55.9754\n",
      "Epoch 1312/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6902 - val_loss: 43.9379\n",
      "Epoch 1313/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9347 - val_loss: 53.9001\n",
      "Epoch 1314/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.8634 - val_loss: 60.7231\n",
      "Epoch 1315/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7613 - val_loss: 70.1669\n",
      "Epoch 1316/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.1260 - val_loss: 55.7978\n",
      "Epoch 1317/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.3047 - val_loss: 59.6598\n",
      "Epoch 1318/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.8134 - val_loss: 56.3756\n",
      "Epoch 1319/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.3477 - val_loss: 58.8495\n",
      "Epoch 1320/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2551 - val_loss: 59.9836\n",
      "Epoch 1321/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.5620 - val_loss: 55.0788\n",
      "Epoch 1322/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 11.0234 - val_loss: 48.6208\n",
      "Epoch 1323/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.1411 - val_loss: 65.9894\n",
      "Epoch 1324/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.4029 - val_loss: 57.9994\n",
      "Epoch 1325/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.8587 - val_loss: 54.1094\n",
      "Epoch 1326/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7292 - val_loss: 69.8250\n",
      "Epoch 1327/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.9189 - val_loss: 59.6830\n",
      "Epoch 1328/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.2898 - val_loss: 70.1003\n",
      "Epoch 1329/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6732 - val_loss: 49.9509\n",
      "Epoch 1330/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.3268 - val_loss: 56.7927\n",
      "Epoch 1331/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1447 - val_loss: 57.8478\n",
      "Epoch 1332/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.1299 - val_loss: 51.4944\n",
      "Epoch 1333/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.6374 - val_loss: 47.0442\n",
      "Epoch 1334/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7476 - val_loss: 55.2753\n",
      "Epoch 1335/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2168 - val_loss: 51.3353\n",
      "Epoch 1336/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.7222 - val_loss: 56.0853\n",
      "Epoch 1337/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.0476 - val_loss: 66.5271\n",
      "Epoch 1338/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.6046 - val_loss: 64.2531\n",
      "Epoch 1339/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.9046 - val_loss: 52.1876\n",
      "Epoch 1340/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.9384 - val_loss: 63.1481\n",
      "Epoch 1341/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.7189 - val_loss: 51.7858\n",
      "Epoch 1342/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.9907Restoring model weights from the end of the best epoch: 842.\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 8.4873 - val_loss: 53.2780\n",
      "Epoch 1342: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09914e58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>31.604759</td>\n",
       "      <td>30.968718</td>\n",
       "      <td>30.79285</td>\n",
       "      <td>30.783115</td>\n",
       "      <td>30.775574</td>\n",
       "      <td>30.753244</td>\n",
       "      <td>30.778139</td>\n",
       "      <td>30.77615</td>\n",
       "      <td>30.777201</td>\n",
       "      <td>30.777308</td>\n",
       "      <td>30.775316</td>\n",
       "      <td>30.778269</td>\n",
       "      <td>30.775528</td>\n",
       "      <td>30.772388</td>\n",
       "      <td>30.775427</td>\n",
       "      <td>30.775833</td>\n",
       "      <td>30.775751</td>\n",
       "      <td>28.633604</td>\n",
       "      <td>30.779169</td>\n",
       "      <td>30.776634</td>\n",
       "      <td>30.77688</td>\n",
       "      <td>30.774754</td>\n",
       "      <td>24.819443</td>\n",
       "      <td>22.558033</td>\n",
       "      <td>22.479984</td>\n",
       "      <td>22.459362</td>\n",
       "      <td>22.452263</td>\n",
       "      <td>22.450525</td>\n",
       "      <td>22.44672</td>\n",
       "      <td>22.443668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>21.34</td>\n",
       "      <td>26.848</td>\n",
       "      <td>28.074</td>\n",
       "      <td>29.941</td>\n",
       "      <td>28.977</td>\n",
       "      <td>31.58</td>\n",
       "      <td>29.991</td>\n",
       "      <td>26.82</td>\n",
       "      <td>29.446</td>\n",
       "      <td>27.666</td>\n",
       "      <td>22.013</td>\n",
       "      <td>28.025</td>\n",
       "      <td>25.648</td>\n",
       "      <td>31.782</td>\n",
       "      <td>27.768</td>\n",
       "      <td>33.073</td>\n",
       "      <td>30.389</td>\n",
       "      <td>27.657</td>\n",
       "      <td>32.388</td>\n",
       "      <td>30.378</td>\n",
       "      <td>30.641</td>\n",
       "      <td>32.337</td>\n",
       "      <td>36.405</td>\n",
       "      <td>22.499</td>\n",
       "      <td>27.961</td>\n",
       "      <td>32.378</td>\n",
       "      <td>32.582</td>\n",
       "      <td>42.703</td>\n",
       "      <td>38.584</td>\n",
       "      <td>36.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>10.264759</td>\n",
       "      <td>4.120718</td>\n",
       "      <td>2.718851</td>\n",
       "      <td>0.842115</td>\n",
       "      <td>1.798574</td>\n",
       "      <td>0.826756</td>\n",
       "      <td>0.78714</td>\n",
       "      <td>3.95615</td>\n",
       "      <td>1.331202</td>\n",
       "      <td>3.111307</td>\n",
       "      <td>8.762316</td>\n",
       "      <td>2.753269</td>\n",
       "      <td>5.127527</td>\n",
       "      <td>1.009611</td>\n",
       "      <td>3.007427</td>\n",
       "      <td>2.297169</td>\n",
       "      <td>0.386751</td>\n",
       "      <td>0.976604</td>\n",
       "      <td>1.608831</td>\n",
       "      <td>0.398634</td>\n",
       "      <td>0.13588</td>\n",
       "      <td>1.562248</td>\n",
       "      <td>11.585556</td>\n",
       "      <td>0.059032</td>\n",
       "      <td>5.481016</td>\n",
       "      <td>9.918636</td>\n",
       "      <td>10.129738</td>\n",
       "      <td>20.252474</td>\n",
       "      <td>16.13728</td>\n",
       "      <td>14.05933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1         2          3          4          5   \\\n",
       "Month         Month-1    Month-2   Month-3    Month-4    Month-5    Month-6   \n",
       "Prediction  31.604759  30.968718  30.79285  30.783115  30.775574  30.753244   \n",
       "Target          21.34     26.848    28.074     29.941     28.977      31.58   \n",
       "Error       10.264759   4.120718  2.718851   0.842115   1.798574   0.826756   \n",
       "\n",
       "                   6         7          8          9          10         11  \\\n",
       "Month         Month-7   Month-8    Month-9   Month-10   Month-11   Month-12   \n",
       "Prediction  30.778139  30.77615  30.777201  30.777308  30.775316  30.778269   \n",
       "Target         29.991     26.82     29.446     27.666     22.013     28.025   \n",
       "Error         0.78714   3.95615   1.331202   3.111307   8.762316   2.753269   \n",
       "\n",
       "                   12         13         14         15         16         17  \\\n",
       "Month        Month-13   Month-14   Month-15   Month-16   Month-17   Month-18   \n",
       "Prediction  30.775528  30.772388  30.775427  30.775833  30.775751  28.633604   \n",
       "Target         25.648     31.782     27.768     33.073     30.389     27.657   \n",
       "Error        5.127527   1.009611   3.007427   2.297169   0.386751   0.976604   \n",
       "\n",
       "                   18         19        20         21         22         23  \\\n",
       "Month        Month-19   Month-20  Month-21   Month-22   Month-23   Month-24   \n",
       "Prediction  30.779169  30.776634  30.77688  30.774754  24.819443  22.558033   \n",
       "Target         32.388     30.378    30.641     32.337     36.405     22.499   \n",
       "Error        1.608831   0.398634   0.13588   1.562248  11.585556   0.059032   \n",
       "\n",
       "                   24         25         26         27        28         29  \n",
       "Month        Month-25   Month-26   Month-27   Month-28  Month-29   Month-30  \n",
       "Prediction  22.479984  22.459362  22.452263  22.450525  22.44672  22.443668  \n",
       "Target         27.961     32.378     32.582     42.703    38.584     36.503  \n",
       "Error        5.481016   9.918636  10.129738  20.252474  16.13728   14.05933  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.846896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.15534142"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[370.34067]] - Target[330.72099999999995]| =  Error: [[39.61966]]; MAPE:[[0.11979783]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[352.99347]] - Target[360.96500000000003]| =  Error: [[7.971527]]; MAPE:[[0.02208393]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-5: |Prediction[[134.73251]] - Target[210.711]| =  Error: [[75.978485]]; MAPE:[[0.3605815]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[39.61966]], dtype=float32),\n",
       " array([[7.971527]], dtype=float32),\n",
       " array([[75.978485]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "41.18989"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.16748774"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
