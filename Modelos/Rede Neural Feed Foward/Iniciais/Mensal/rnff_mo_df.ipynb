{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Distrito Federal - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Distrito Federal - value</th>\n",
       "      <th>Distrito Federal - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Distrito Federal - IDH</th>\n",
       "      <th>Distrito Federal - PIB - Estadual</th>\n",
       "      <th>Distrito Federal - PIB - Construção Civil</th>\n",
       "      <th>Distrito Federal - PIB - Per Capita</th>\n",
       "      <th>Distrito Federal - PIB - Preços de Mercado</th>\n",
       "      <th>Distrito Federal - Produção de Cimento (t)</th>\n",
       "      <th>Distrito Federal - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.254227</td>\n",
       "      <td>8.293882</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>0.826971</td>\n",
       "      <td>1.184017e+08</td>\n",
       "      <td>3.570616e+06</td>\n",
       "      <td>43.639430</td>\n",
       "      <td>1.092465e+08</td>\n",
       "      <td>156.625720</td>\n",
       "      <td>50.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.252655</td>\n",
       "      <td>8.287887</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>0.827063</td>\n",
       "      <td>1.185511e+08</td>\n",
       "      <td>3.573184e+06</td>\n",
       "      <td>43.651300</td>\n",
       "      <td>1.093025e+08</td>\n",
       "      <td>157.678528</td>\n",
       "      <td>48.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.250972</td>\n",
       "      <td>8.281892</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>0.827155</td>\n",
       "      <td>1.187006e+08</td>\n",
       "      <td>3.575752e+06</td>\n",
       "      <td>43.663170</td>\n",
       "      <td>1.093585e+08</td>\n",
       "      <td>159.190268</td>\n",
       "      <td>49.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.249179</td>\n",
       "      <td>8.275896</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>0.827247</td>\n",
       "      <td>1.188500e+08</td>\n",
       "      <td>3.578320e+06</td>\n",
       "      <td>43.675041</td>\n",
       "      <td>1.094145e+08</td>\n",
       "      <td>160.688376</td>\n",
       "      <td>48.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.247070</td>\n",
       "      <td>8.269901</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>0.827340</td>\n",
       "      <td>1.189994e+08</td>\n",
       "      <td>3.580889e+06</td>\n",
       "      <td>43.686911</td>\n",
       "      <td>1.094705e+08</td>\n",
       "      <td>162.847410</td>\n",
       "      <td>51.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>0.529279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.077918</td>\n",
       "      <td>77.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>0.527896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.545664</td>\n",
       "      <td>64.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>0.526069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.265413</td>\n",
       "      <td>72.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>0.523943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.486640</td>\n",
       "      <td>59.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>0.521081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.931980</td>\n",
       "      <td>59.598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Distrito Federal - value  Distrito Federal - Desemprego  \\\n",
       "0       2003-1                  0.254227                       8.293882   \n",
       "1       2003-2                  0.252655                       8.287887   \n",
       "2       2003-3                  0.250972                       8.281892   \n",
       "3       2003-4                  0.249179                       8.275896   \n",
       "4       2003-5                  0.247070                       8.269901   \n",
       "..         ...                       ...                            ...   \n",
       "235     2022-8                  0.529279                            NaN   \n",
       "236     2022-9                  0.527896                            NaN   \n",
       "237    2022-10                  0.526069                            NaN   \n",
       "238    2022-11                  0.523943                            NaN   \n",
       "239    2022-12                  0.521081                            NaN   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     Distrito Federal - IDH  Distrito Federal - PIB - Estadual  \\\n",
       "0                  0.826971                       1.184017e+08   \n",
       "1                  0.827063                       1.185511e+08   \n",
       "2                  0.827155                       1.187006e+08   \n",
       "3                  0.827247                       1.188500e+08   \n",
       "4                  0.827340                       1.189994e+08   \n",
       "..                      ...                                ...   \n",
       "235                     NaN                                NaN   \n",
       "236                     NaN                                NaN   \n",
       "237                     NaN                                NaN   \n",
       "238                     NaN                                NaN   \n",
       "239                     NaN                                NaN   \n",
       "\n",
       "     Distrito Federal - PIB - Construção Civil  \\\n",
       "0                                 3.570616e+06   \n",
       "1                                 3.573184e+06   \n",
       "2                                 3.575752e+06   \n",
       "3                                 3.578320e+06   \n",
       "4                                 3.580889e+06   \n",
       "..                                         ...   \n",
       "235                                        NaN   \n",
       "236                                        NaN   \n",
       "237                                        NaN   \n",
       "238                                        NaN   \n",
       "239                                        NaN   \n",
       "\n",
       "     Distrito Federal - PIB - Per Capita  \\\n",
       "0                              43.639430   \n",
       "1                              43.651300   \n",
       "2                              43.663170   \n",
       "3                              43.675041   \n",
       "4                              43.686911   \n",
       "..                                   ...   \n",
       "235                                  NaN   \n",
       "236                                  NaN   \n",
       "237                                  NaN   \n",
       "238                                  NaN   \n",
       "239                                  NaN   \n",
       "\n",
       "     Distrito Federal - PIB - Preços de Mercado  \\\n",
       "0                                  1.092465e+08   \n",
       "1                                  1.093025e+08   \n",
       "2                                  1.093585e+08   \n",
       "3                                  1.094145e+08   \n",
       "4                                  1.094705e+08   \n",
       "..                                          ...   \n",
       "235                                         NaN   \n",
       "236                                         NaN   \n",
       "237                                         NaN   \n",
       "238                                         NaN   \n",
       "239                                         NaN   \n",
       "\n",
       "     Distrito Federal - Produção de Cimento (t)  \\\n",
       "0                                    156.625720   \n",
       "1                                    157.678528   \n",
       "2                                    159.190268   \n",
       "3                                    160.688376   \n",
       "4                                    162.847410   \n",
       "..                                          ...   \n",
       "235                                  250.077918   \n",
       "236                                  248.545664   \n",
       "237                                  248.265413   \n",
       "238                                  247.486640   \n",
       "239                                  247.931980   \n",
       "\n",
       "     Distrito Federal - Consumo de Cimento (t)  \n",
       "0                                       50.047  \n",
       "1                                       48.110  \n",
       "2                                       49.006  \n",
       "3                                       48.445  \n",
       "4                                       51.436  \n",
       "..                                         ...  \n",
       "235                                     77.448  \n",
       "236                                     64.321  \n",
       "237                                     72.839  \n",
       "238                                     59.598  \n",
       "239                                     59.598  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_DF.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distrito Federal - value</th>\n",
       "      <th>Distrito Federal - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Distrito Federal - IDH</th>\n",
       "      <th>Distrito Federal - PIB - Estadual</th>\n",
       "      <th>Distrito Federal - PIB - Construção Civil</th>\n",
       "      <th>Distrito Federal - PIB - Per Capita</th>\n",
       "      <th>Distrito Federal - PIB - Preços de Mercado</th>\n",
       "      <th>Distrito Federal - Produção de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.765895</td>\n",
       "      <td>-0.830412</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-2.593530</td>\n",
       "      <td>-1.693822</td>\n",
       "      <td>0.396337</td>\n",
       "      <td>-2.171734</td>\n",
       "      <td>-2.205731</td>\n",
       "      <td>-1.931775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.800114</td>\n",
       "      <td>-0.833674</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-2.541888</td>\n",
       "      <td>-1.674984</td>\n",
       "      <td>0.431282</td>\n",
       "      <td>-2.081307</td>\n",
       "      <td>-2.163694</td>\n",
       "      <td>-1.908347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.836745</td>\n",
       "      <td>-0.836936</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-2.490246</td>\n",
       "      <td>-1.656145</td>\n",
       "      <td>0.466227</td>\n",
       "      <td>-1.990880</td>\n",
       "      <td>-2.121657</td>\n",
       "      <td>-1.874707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.875764</td>\n",
       "      <td>-0.840198</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-2.438604</td>\n",
       "      <td>-1.637307</td>\n",
       "      <td>0.501171</td>\n",
       "      <td>-1.900453</td>\n",
       "      <td>-2.079620</td>\n",
       "      <td>-1.841370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.921678</td>\n",
       "      <td>-0.843461</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-2.386962</td>\n",
       "      <td>-1.618468</td>\n",
       "      <td>0.536116</td>\n",
       "      <td>-1.810026</td>\n",
       "      <td>-2.037583</td>\n",
       "      <td>-1.793327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.298634</td>\n",
       "      <td>1.198041</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>0.236110</td>\n",
       "      <td>1.116166</td>\n",
       "      <td>-1.071950</td>\n",
       "      <td>-1.286229</td>\n",
       "      <td>0.817896</td>\n",
       "      <td>-0.512069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.354774</td>\n",
       "      <td>1.198255</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>0.183845</td>\n",
       "      <td>1.104850</td>\n",
       "      <td>-1.047047</td>\n",
       "      <td>-1.328476</td>\n",
       "      <td>0.799100</td>\n",
       "      <td>-0.500824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.401307</td>\n",
       "      <td>1.198470</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>0.131580</td>\n",
       "      <td>1.093534</td>\n",
       "      <td>-1.022144</td>\n",
       "      <td>-1.370723</td>\n",
       "      <td>0.780305</td>\n",
       "      <td>-0.491677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.460103</td>\n",
       "      <td>1.198684</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>0.079315</td>\n",
       "      <td>1.082218</td>\n",
       "      <td>-0.997242</td>\n",
       "      <td>-1.412970</td>\n",
       "      <td>0.761510</td>\n",
       "      <td>-0.481495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.513867</td>\n",
       "      <td>1.198898</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>0.027050</td>\n",
       "      <td>1.070902</td>\n",
       "      <td>-0.972339</td>\n",
       "      <td>-1.455217</td>\n",
       "      <td>0.742715</td>\n",
       "      <td>-0.478094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Distrito Federal - value  Distrito Federal - Desemprego  \\\n",
       "0                   -0.765895                      -0.830412   \n",
       "1                   -0.800114                      -0.833674   \n",
       "2                   -0.836745                      -0.836936   \n",
       "3                   -0.875764                      -0.840198   \n",
       "4                   -0.921678                      -0.843461   \n",
       "..                        ...                            ...   \n",
       "187                  1.298634                       1.198041   \n",
       "188                  1.354774                       1.198255   \n",
       "189                  1.401307                       1.198470   \n",
       "190                  1.460103                       1.198684   \n",
       "191                  1.513867                       1.198898   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Distrito Federal - IDH  Distrito Federal - PIB - Estadual  \\\n",
       "0                 -2.593530                          -1.693822   \n",
       "1                 -2.541888                          -1.674984   \n",
       "2                 -2.490246                          -1.656145   \n",
       "3                 -2.438604                          -1.637307   \n",
       "4                 -2.386962                          -1.618468   \n",
       "..                      ...                                ...   \n",
       "187                0.236110                           1.116166   \n",
       "188                0.183845                           1.104850   \n",
       "189                0.131580                           1.093534   \n",
       "190                0.079315                           1.082218   \n",
       "191                0.027050                           1.070902   \n",
       "\n",
       "     Distrito Federal - PIB - Construção Civil  \\\n",
       "0                                     0.396337   \n",
       "1                                     0.431282   \n",
       "2                                     0.466227   \n",
       "3                                     0.501171   \n",
       "4                                     0.536116   \n",
       "..                                         ...   \n",
       "187                                  -1.071950   \n",
       "188                                  -1.047047   \n",
       "189                                  -1.022144   \n",
       "190                                  -0.997242   \n",
       "191                                  -0.972339   \n",
       "\n",
       "     Distrito Federal - PIB - Per Capita  \\\n",
       "0                              -2.171734   \n",
       "1                              -2.081307   \n",
       "2                              -1.990880   \n",
       "3                              -1.900453   \n",
       "4                              -1.810026   \n",
       "..                                   ...   \n",
       "187                            -1.286229   \n",
       "188                            -1.328476   \n",
       "189                            -1.370723   \n",
       "190                            -1.412970   \n",
       "191                            -1.455217   \n",
       "\n",
       "     Distrito Federal - PIB - Preços de Mercado  \\\n",
       "0                                     -2.205731   \n",
       "1                                     -2.163694   \n",
       "2                                     -2.121657   \n",
       "3                                     -2.079620   \n",
       "4                                     -2.037583   \n",
       "..                                          ...   \n",
       "187                                    0.817896   \n",
       "188                                    0.799100   \n",
       "189                                    0.780305   \n",
       "190                                    0.761510   \n",
       "191                                    0.742715   \n",
       "\n",
       "     Distrito Federal - Produção de Cimento (t)  \n",
       "0                                     -1.931775  \n",
       "1                                     -1.908347  \n",
       "2                                     -1.874707  \n",
       "3                                     -1.841370  \n",
       "4                                     -1.793327  \n",
       "..                                          ...  \n",
       "187                                   -0.512069  \n",
       "188                                   -0.500824  \n",
       "189                                   -0.491677  \n",
       "190                                   -0.481495  \n",
       "191                                   -0.478094  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      46.442\n",
       "1      43.234\n",
       "2      54.587\n",
       "3      59.228\n",
       "4      63.997\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Distrito Federal - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distrito Federal - value</th>\n",
       "      <th>Distrito Federal - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Distrito Federal - IDH</th>\n",
       "      <th>Distrito Federal - PIB - Estadual</th>\n",
       "      <th>Distrito Federal - PIB - Construção Civil</th>\n",
       "      <th>Distrito Federal - PIB - Per Capita</th>\n",
       "      <th>Distrito Federal - PIB - Preços de Mercado</th>\n",
       "      <th>Distrito Federal - Produção de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.765895</td>\n",
       "      <td>-0.830412</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-2.593530</td>\n",
       "      <td>-1.693822</td>\n",
       "      <td>0.396337</td>\n",
       "      <td>-2.171734</td>\n",
       "      <td>-2.205731</td>\n",
       "      <td>-1.931775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.800114</td>\n",
       "      <td>-0.833674</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-2.541888</td>\n",
       "      <td>-1.674984</td>\n",
       "      <td>0.431282</td>\n",
       "      <td>-2.081307</td>\n",
       "      <td>-2.163694</td>\n",
       "      <td>-1.908347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.836745</td>\n",
       "      <td>-0.836936</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-2.490246</td>\n",
       "      <td>-1.656145</td>\n",
       "      <td>0.466227</td>\n",
       "      <td>-1.990880</td>\n",
       "      <td>-2.121657</td>\n",
       "      <td>-1.874707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.875764</td>\n",
       "      <td>-0.840198</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-2.438604</td>\n",
       "      <td>-1.637307</td>\n",
       "      <td>0.501171</td>\n",
       "      <td>-1.900453</td>\n",
       "      <td>-2.079620</td>\n",
       "      <td>-1.841370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.921678</td>\n",
       "      <td>-0.843461</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-2.386962</td>\n",
       "      <td>-1.618468</td>\n",
       "      <td>0.536116</td>\n",
       "      <td>-1.810026</td>\n",
       "      <td>-2.037583</td>\n",
       "      <td>-1.793327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.937260</td>\n",
       "      <td>1.309227</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>1.616226</td>\n",
       "      <td>1.235244</td>\n",
       "      <td>-1.506889</td>\n",
       "      <td>-0.747477</td>\n",
       "      <td>1.174551</td>\n",
       "      <td>0.131039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.925760</td>\n",
       "      <td>1.302282</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>1.563561</td>\n",
       "      <td>1.236423</td>\n",
       "      <td>-1.511843</td>\n",
       "      <td>-0.763990</td>\n",
       "      <td>1.168128</td>\n",
       "      <td>0.077457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.912813</td>\n",
       "      <td>1.295337</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>1.510895</td>\n",
       "      <td>1.237602</td>\n",
       "      <td>-1.516798</td>\n",
       "      <td>-0.780503</td>\n",
       "      <td>1.161706</td>\n",
       "      <td>0.032090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.906620</td>\n",
       "      <td>1.288392</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>1.458230</td>\n",
       "      <td>1.238780</td>\n",
       "      <td>-1.521752</td>\n",
       "      <td>-0.797016</td>\n",
       "      <td>1.155283</td>\n",
       "      <td>-0.032489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.901772</td>\n",
       "      <td>1.281447</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>1.405564</td>\n",
       "      <td>1.239959</td>\n",
       "      <td>-1.526706</td>\n",
       "      <td>-0.813529</td>\n",
       "      <td>1.148860</td>\n",
       "      <td>-0.058248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Distrito Federal - value  Distrito Federal - Desemprego  \\\n",
       "0                   -0.765895                      -0.830412   \n",
       "1                   -0.800114                      -0.833674   \n",
       "2                   -0.836745                      -0.836936   \n",
       "3                   -0.875764                      -0.840198   \n",
       "4                   -0.921678                      -0.843461   \n",
       "..                        ...                            ...   \n",
       "157                  0.937260                       1.309227   \n",
       "158                  0.925760                       1.302282   \n",
       "159                  0.912813                       1.295337   \n",
       "160                  0.906620                       1.288392   \n",
       "161                  0.901772                       1.281447   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     Distrito Federal - IDH  Distrito Federal - PIB - Estadual  \\\n",
       "0                 -2.593530                          -1.693822   \n",
       "1                 -2.541888                          -1.674984   \n",
       "2                 -2.490246                          -1.656145   \n",
       "3                 -2.438604                          -1.637307   \n",
       "4                 -2.386962                          -1.618468   \n",
       "..                      ...                                ...   \n",
       "157                1.616226                           1.235244   \n",
       "158                1.563561                           1.236423   \n",
       "159                1.510895                           1.237602   \n",
       "160                1.458230                           1.238780   \n",
       "161                1.405564                           1.239959   \n",
       "\n",
       "     Distrito Federal - PIB - Construção Civil  \\\n",
       "0                                     0.396337   \n",
       "1                                     0.431282   \n",
       "2                                     0.466227   \n",
       "3                                     0.501171   \n",
       "4                                     0.536116   \n",
       "..                                         ...   \n",
       "157                                  -1.506889   \n",
       "158                                  -1.511843   \n",
       "159                                  -1.516798   \n",
       "160                                  -1.521752   \n",
       "161                                  -1.526706   \n",
       "\n",
       "     Distrito Federal - PIB - Per Capita  \\\n",
       "0                              -2.171734   \n",
       "1                              -2.081307   \n",
       "2                              -1.990880   \n",
       "3                              -1.900453   \n",
       "4                              -1.810026   \n",
       "..                                   ...   \n",
       "157                            -0.747477   \n",
       "158                            -0.763990   \n",
       "159                            -0.780503   \n",
       "160                            -0.797016   \n",
       "161                            -0.813529   \n",
       "\n",
       "     Distrito Federal - PIB - Preços de Mercado  \\\n",
       "0                                     -2.205731   \n",
       "1                                     -2.163694   \n",
       "2                                     -2.121657   \n",
       "3                                     -2.079620   \n",
       "4                                     -2.037583   \n",
       "..                                          ...   \n",
       "157                                    1.174551   \n",
       "158                                    1.168128   \n",
       "159                                    1.161706   \n",
       "160                                    1.155283   \n",
       "161                                    1.148860   \n",
       "\n",
       "     Distrito Federal - Produção de Cimento (t)  \n",
       "0                                     -1.931775  \n",
       "1                                     -1.908347  \n",
       "2                                     -1.874707  \n",
       "3                                     -1.841370  \n",
       "4                                     -1.793327  \n",
       "..                                          ...  \n",
       "157                                    0.131039  \n",
       "158                                    0.077457  \n",
       "159                                    0.032090  \n",
       "160                                   -0.032489  \n",
       "161                                   -0.058248  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      46.442\n",
       "1      43.234\n",
       "2      54.587\n",
       "3      59.228\n",
       "4      63.997\n",
       "        ...  \n",
       "157    35.599\n",
       "158    49.981\n",
       "159    39.881\n",
       "160    48.598\n",
       "161    49.942\n",
       "Name: Distrito Federal - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distrito Federal - value</th>\n",
       "      <th>Distrito Federal - Desemprego</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Distrito Federal - IDH</th>\n",
       "      <th>Distrito Federal - PIB - Estadual</th>\n",
       "      <th>Distrito Federal - PIB - Construção Civil</th>\n",
       "      <th>Distrito Federal - PIB - Per Capita</th>\n",
       "      <th>Distrito Federal - PIB - Preços de Mercado</th>\n",
       "      <th>Distrito Federal - Produção de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.902328</td>\n",
       "      <td>1.274502</td>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>1.352899</td>\n",
       "      <td>1.241137</td>\n",
       "      <td>-1.531661</td>\n",
       "      <td>-0.830042</td>\n",
       "      <td>1.142438</td>\n",
       "      <td>-0.088054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.902814</td>\n",
       "      <td>1.267557</td>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>1.300233</td>\n",
       "      <td>1.242316</td>\n",
       "      <td>-1.536615</td>\n",
       "      <td>-0.846555</td>\n",
       "      <td>1.136015</td>\n",
       "      <td>-0.105352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.907317</td>\n",
       "      <td>1.260612</td>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>1.247568</td>\n",
       "      <td>1.243494</td>\n",
       "      <td>-1.541569</td>\n",
       "      <td>-0.863068</td>\n",
       "      <td>1.129592</td>\n",
       "      <td>-0.117887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.914492</td>\n",
       "      <td>1.253668</td>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>1.194903</td>\n",
       "      <td>1.244673</td>\n",
       "      <td>-1.546523</td>\n",
       "      <td>-0.879581</td>\n",
       "      <td>1.123170</td>\n",
       "      <td>-0.134394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.915160</td>\n",
       "      <td>1.246723</td>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>1.142237</td>\n",
       "      <td>1.245851</td>\n",
       "      <td>-1.551478</td>\n",
       "      <td>-0.896095</td>\n",
       "      <td>1.116747</td>\n",
       "      <td>-0.163790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.914118</td>\n",
       "      <td>1.239778</td>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>1.089572</td>\n",
       "      <td>1.247030</td>\n",
       "      <td>-1.556432</td>\n",
       "      <td>-0.912608</td>\n",
       "      <td>1.110324</td>\n",
       "      <td>-0.197707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.913548</td>\n",
       "      <td>1.232833</td>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>1.036906</td>\n",
       "      <td>1.248208</td>\n",
       "      <td>-1.561386</td>\n",
       "      <td>-0.929121</td>\n",
       "      <td>1.103902</td>\n",
       "      <td>-0.234373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.922162</td>\n",
       "      <td>1.229808</td>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>1.000661</td>\n",
       "      <td>1.243806</td>\n",
       "      <td>-1.535126</td>\n",
       "      <td>-0.934236</td>\n",
       "      <td>1.091032</td>\n",
       "      <td>-0.271993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.931366</td>\n",
       "      <td>1.226784</td>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>0.964416</td>\n",
       "      <td>1.239403</td>\n",
       "      <td>-1.508866</td>\n",
       "      <td>-0.939351</td>\n",
       "      <td>1.078162</td>\n",
       "      <td>-0.289415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.942855</td>\n",
       "      <td>1.223760</td>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>0.928171</td>\n",
       "      <td>1.235001</td>\n",
       "      <td>-1.482607</td>\n",
       "      <td>-0.944465</td>\n",
       "      <td>1.065292</td>\n",
       "      <td>-0.315182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.950015</td>\n",
       "      <td>1.220736</td>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>0.891926</td>\n",
       "      <td>1.230598</td>\n",
       "      <td>-1.456347</td>\n",
       "      <td>-0.949580</td>\n",
       "      <td>1.052422</td>\n",
       "      <td>-0.313632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.955517</td>\n",
       "      <td>1.217711</td>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>0.855681</td>\n",
       "      <td>1.226195</td>\n",
       "      <td>-1.430087</td>\n",
       "      <td>-0.954695</td>\n",
       "      <td>1.039552</td>\n",
       "      <td>-0.333588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.968236</td>\n",
       "      <td>1.214687</td>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>0.819435</td>\n",
       "      <td>1.221793</td>\n",
       "      <td>-1.403827</td>\n",
       "      <td>-0.959810</td>\n",
       "      <td>1.026682</td>\n",
       "      <td>-0.343725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.987364</td>\n",
       "      <td>1.211663</td>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>0.783190</td>\n",
       "      <td>1.217390</td>\n",
       "      <td>-1.377567</td>\n",
       "      <td>-0.964925</td>\n",
       "      <td>1.013812</td>\n",
       "      <td>-0.360793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.004660</td>\n",
       "      <td>1.208639</td>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>0.746945</td>\n",
       "      <td>1.212988</td>\n",
       "      <td>-1.351307</td>\n",
       "      <td>-0.970040</td>\n",
       "      <td>1.000942</td>\n",
       "      <td>-0.395540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.019373</td>\n",
       "      <td>1.205614</td>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>0.710700</td>\n",
       "      <td>1.208585</td>\n",
       "      <td>-1.325047</td>\n",
       "      <td>-0.975155</td>\n",
       "      <td>0.988072</td>\n",
       "      <td>-0.425571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.047436</td>\n",
       "      <td>1.202590</td>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>0.674455</td>\n",
       "      <td>1.204183</td>\n",
       "      <td>-1.298787</td>\n",
       "      <td>-0.980270</td>\n",
       "      <td>0.975202</td>\n",
       "      <td>-0.461232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.069016</td>\n",
       "      <td>1.199566</td>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>0.638210</td>\n",
       "      <td>1.199780</td>\n",
       "      <td>-1.272527</td>\n",
       "      <td>-0.985385</td>\n",
       "      <td>0.962332</td>\n",
       "      <td>-0.496888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.089751</td>\n",
       "      <td>1.196542</td>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>0.601965</td>\n",
       "      <td>1.195377</td>\n",
       "      <td>-1.246267</td>\n",
       "      <td>-0.990500</td>\n",
       "      <td>0.949462</td>\n",
       "      <td>-0.519429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.125880</td>\n",
       "      <td>1.196756</td>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>0.549700</td>\n",
       "      <td>1.184062</td>\n",
       "      <td>-1.221365</td>\n",
       "      <td>-1.032747</td>\n",
       "      <td>0.930667</td>\n",
       "      <td>-0.552790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.154427</td>\n",
       "      <td>1.196970</td>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>0.497435</td>\n",
       "      <td>1.172746</td>\n",
       "      <td>-1.196462</td>\n",
       "      <td>-1.074994</td>\n",
       "      <td>0.911872</td>\n",
       "      <td>-0.574011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.179526</td>\n",
       "      <td>1.197184</td>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>0.445170</td>\n",
       "      <td>1.161430</td>\n",
       "      <td>-1.171560</td>\n",
       "      <td>-1.117241</td>\n",
       "      <td>0.893077</td>\n",
       "      <td>-0.594627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.206735</td>\n",
       "      <td>1.197399</td>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>0.392905</td>\n",
       "      <td>1.150114</td>\n",
       "      <td>-1.146657</td>\n",
       "      <td>-1.159488</td>\n",
       "      <td>0.874281</td>\n",
       "      <td>-0.595647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.222632</td>\n",
       "      <td>1.197613</td>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>0.340640</td>\n",
       "      <td>1.138798</td>\n",
       "      <td>-1.121755</td>\n",
       "      <td>-1.201735</td>\n",
       "      <td>0.855486</td>\n",
       "      <td>-0.561738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.254055</td>\n",
       "      <td>1.197827</td>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>0.288375</td>\n",
       "      <td>1.127482</td>\n",
       "      <td>-1.096852</td>\n",
       "      <td>-1.243982</td>\n",
       "      <td>0.836691</td>\n",
       "      <td>-0.543989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.298634</td>\n",
       "      <td>1.198041</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>0.236110</td>\n",
       "      <td>1.116166</td>\n",
       "      <td>-1.071950</td>\n",
       "      <td>-1.286229</td>\n",
       "      <td>0.817896</td>\n",
       "      <td>-0.512069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.354774</td>\n",
       "      <td>1.198255</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>0.183845</td>\n",
       "      <td>1.104850</td>\n",
       "      <td>-1.047047</td>\n",
       "      <td>-1.328476</td>\n",
       "      <td>0.799100</td>\n",
       "      <td>-0.500824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.401307</td>\n",
       "      <td>1.198470</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>0.131580</td>\n",
       "      <td>1.093534</td>\n",
       "      <td>-1.022144</td>\n",
       "      <td>-1.370723</td>\n",
       "      <td>0.780305</td>\n",
       "      <td>-0.491677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.460103</td>\n",
       "      <td>1.198684</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>0.079315</td>\n",
       "      <td>1.082218</td>\n",
       "      <td>-0.997242</td>\n",
       "      <td>-1.412970</td>\n",
       "      <td>0.761510</td>\n",
       "      <td>-0.481495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.513867</td>\n",
       "      <td>1.198898</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>0.027050</td>\n",
       "      <td>1.070902</td>\n",
       "      <td>-0.972339</td>\n",
       "      <td>-1.455217</td>\n",
       "      <td>0.742715</td>\n",
       "      <td>-0.478094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Distrito Federal - value  Distrito Federal - Desemprego  \\\n",
       "162                  0.902328                       1.274502   \n",
       "163                  0.902814                       1.267557   \n",
       "164                  0.907317                       1.260612   \n",
       "165                  0.914492                       1.253668   \n",
       "166                  0.915160                       1.246723   \n",
       "167                  0.914118                       1.239778   \n",
       "168                  0.913548                       1.232833   \n",
       "169                  0.922162                       1.229808   \n",
       "170                  0.931366                       1.226784   \n",
       "171                  0.942855                       1.223760   \n",
       "172                  0.950015                       1.220736   \n",
       "173                  0.955517                       1.217711   \n",
       "174                  0.968236                       1.214687   \n",
       "175                  0.987364                       1.211663   \n",
       "176                  1.004660                       1.208639   \n",
       "177                  1.019373                       1.205614   \n",
       "178                  1.047436                       1.202590   \n",
       "179                  1.069016                       1.199566   \n",
       "180                  1.089751                       1.196542   \n",
       "181                  1.125880                       1.196756   \n",
       "182                  1.154427                       1.196970   \n",
       "183                  1.179526                       1.197184   \n",
       "184                  1.206735                       1.197399   \n",
       "185                  1.222632                       1.197613   \n",
       "186                  1.254055                       1.197827   \n",
       "187                  1.298634                       1.198041   \n",
       "188                  1.354774                       1.198255   \n",
       "189                  1.401307                       1.198470   \n",
       "190                  1.460103                       1.198684   \n",
       "191                  1.513867                       1.198898   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162                                         -0.601510   \n",
       "163                                         -0.786068   \n",
       "164                                         -0.830387   \n",
       "165                                         -0.801089   \n",
       "166                                         -0.959917   \n",
       "167                                         -1.022309   \n",
       "168                                         -1.074401   \n",
       "169                                         -1.119597   \n",
       "170                                         -1.078648   \n",
       "171                                         -1.055426   \n",
       "172                                         -1.101053   \n",
       "173                                         -1.211370   \n",
       "174                                         -1.157198   \n",
       "175                                         -1.223444   \n",
       "176                                         -1.311519   \n",
       "177                                         -1.362602   \n",
       "178                                         -1.380125   \n",
       "179                                         -1.219296   \n",
       "180                                         -1.300284   \n",
       "181                                         -1.336476   \n",
       "182                                         -1.415774   \n",
       "183                                         -1.526021   \n",
       "184                                         -1.681806   \n",
       "185                                         -1.735167   \n",
       "186                                         -1.962315   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "162                                0.763466  -1.213929   \n",
       "163                                0.752299  -1.292173   \n",
       "164                                0.741131  -1.324219   \n",
       "165                                0.729964  -1.344446   \n",
       "166                                0.718796  -1.381638   \n",
       "167                                0.707629  -1.411208   \n",
       "168                                0.696461  -1.412953   \n",
       "169                                0.681823  -1.491464   \n",
       "170                                0.667184  -1.573805   \n",
       "171                                0.652545  -1.564950   \n",
       "172                                0.637906  -1.581584   \n",
       "173                                0.623268  -1.565976   \n",
       "174                                0.608629  -1.648556   \n",
       "175                                0.593990  -1.650049   \n",
       "176                                0.579351  -1.653957   \n",
       "177                                0.564713  -1.652572   \n",
       "178                                0.550074  -1.715349   \n",
       "179                                0.535435  -1.750917   \n",
       "180                                0.520796  -1.718448   \n",
       "181                                0.501996  -1.733426   \n",
       "182                                0.483195  -1.729362   \n",
       "183                                0.464395  -1.748544   \n",
       "184                                0.445594  -1.778060   \n",
       "185                                0.426794  -1.773710   \n",
       "186                                0.407993  -1.757007   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Distrito Federal - IDH  Distrito Federal - PIB - Estadual  \\\n",
       "162                1.352899                           1.241137   \n",
       "163                1.300233                           1.242316   \n",
       "164                1.247568                           1.243494   \n",
       "165                1.194903                           1.244673   \n",
       "166                1.142237                           1.245851   \n",
       "167                1.089572                           1.247030   \n",
       "168                1.036906                           1.248208   \n",
       "169                1.000661                           1.243806   \n",
       "170                0.964416                           1.239403   \n",
       "171                0.928171                           1.235001   \n",
       "172                0.891926                           1.230598   \n",
       "173                0.855681                           1.226195   \n",
       "174                0.819435                           1.221793   \n",
       "175                0.783190                           1.217390   \n",
       "176                0.746945                           1.212988   \n",
       "177                0.710700                           1.208585   \n",
       "178                0.674455                           1.204183   \n",
       "179                0.638210                           1.199780   \n",
       "180                0.601965                           1.195377   \n",
       "181                0.549700                           1.184062   \n",
       "182                0.497435                           1.172746   \n",
       "183                0.445170                           1.161430   \n",
       "184                0.392905                           1.150114   \n",
       "185                0.340640                           1.138798   \n",
       "186                0.288375                           1.127482   \n",
       "187                0.236110                           1.116166   \n",
       "188                0.183845                           1.104850   \n",
       "189                0.131580                           1.093534   \n",
       "190                0.079315                           1.082218   \n",
       "191                0.027050                           1.070902   \n",
       "\n",
       "     Distrito Federal - PIB - Construção Civil  \\\n",
       "162                                  -1.531661   \n",
       "163                                  -1.536615   \n",
       "164                                  -1.541569   \n",
       "165                                  -1.546523   \n",
       "166                                  -1.551478   \n",
       "167                                  -1.556432   \n",
       "168                                  -1.561386   \n",
       "169                                  -1.535126   \n",
       "170                                  -1.508866   \n",
       "171                                  -1.482607   \n",
       "172                                  -1.456347   \n",
       "173                                  -1.430087   \n",
       "174                                  -1.403827   \n",
       "175                                  -1.377567   \n",
       "176                                  -1.351307   \n",
       "177                                  -1.325047   \n",
       "178                                  -1.298787   \n",
       "179                                  -1.272527   \n",
       "180                                  -1.246267   \n",
       "181                                  -1.221365   \n",
       "182                                  -1.196462   \n",
       "183                                  -1.171560   \n",
       "184                                  -1.146657   \n",
       "185                                  -1.121755   \n",
       "186                                  -1.096852   \n",
       "187                                  -1.071950   \n",
       "188                                  -1.047047   \n",
       "189                                  -1.022144   \n",
       "190                                  -0.997242   \n",
       "191                                  -0.972339   \n",
       "\n",
       "     Distrito Federal - PIB - Per Capita  \\\n",
       "162                            -0.830042   \n",
       "163                            -0.846555   \n",
       "164                            -0.863068   \n",
       "165                            -0.879581   \n",
       "166                            -0.896095   \n",
       "167                            -0.912608   \n",
       "168                            -0.929121   \n",
       "169                            -0.934236   \n",
       "170                            -0.939351   \n",
       "171                            -0.944465   \n",
       "172                            -0.949580   \n",
       "173                            -0.954695   \n",
       "174                            -0.959810   \n",
       "175                            -0.964925   \n",
       "176                            -0.970040   \n",
       "177                            -0.975155   \n",
       "178                            -0.980270   \n",
       "179                            -0.985385   \n",
       "180                            -0.990500   \n",
       "181                            -1.032747   \n",
       "182                            -1.074994   \n",
       "183                            -1.117241   \n",
       "184                            -1.159488   \n",
       "185                            -1.201735   \n",
       "186                            -1.243982   \n",
       "187                            -1.286229   \n",
       "188                            -1.328476   \n",
       "189                            -1.370723   \n",
       "190                            -1.412970   \n",
       "191                            -1.455217   \n",
       "\n",
       "     Distrito Federal - PIB - Preços de Mercado  \\\n",
       "162                                    1.142438   \n",
       "163                                    1.136015   \n",
       "164                                    1.129592   \n",
       "165                                    1.123170   \n",
       "166                                    1.116747   \n",
       "167                                    1.110324   \n",
       "168                                    1.103902   \n",
       "169                                    1.091032   \n",
       "170                                    1.078162   \n",
       "171                                    1.065292   \n",
       "172                                    1.052422   \n",
       "173                                    1.039552   \n",
       "174                                    1.026682   \n",
       "175                                    1.013812   \n",
       "176                                    1.000942   \n",
       "177                                    0.988072   \n",
       "178                                    0.975202   \n",
       "179                                    0.962332   \n",
       "180                                    0.949462   \n",
       "181                                    0.930667   \n",
       "182                                    0.911872   \n",
       "183                                    0.893077   \n",
       "184                                    0.874281   \n",
       "185                                    0.855486   \n",
       "186                                    0.836691   \n",
       "187                                    0.817896   \n",
       "188                                    0.799100   \n",
       "189                                    0.780305   \n",
       "190                                    0.761510   \n",
       "191                                    0.742715   \n",
       "\n",
       "     Distrito Federal - Produção de Cimento (t)  \n",
       "162                                   -0.088054  \n",
       "163                                   -0.105352  \n",
       "164                                   -0.117887  \n",
       "165                                   -0.134394  \n",
       "166                                   -0.163790  \n",
       "167                                   -0.197707  \n",
       "168                                   -0.234373  \n",
       "169                                   -0.271993  \n",
       "170                                   -0.289415  \n",
       "171                                   -0.315182  \n",
       "172                                   -0.313632  \n",
       "173                                   -0.333588  \n",
       "174                                   -0.343725  \n",
       "175                                   -0.360793  \n",
       "176                                   -0.395540  \n",
       "177                                   -0.425571  \n",
       "178                                   -0.461232  \n",
       "179                                   -0.496888  \n",
       "180                                   -0.519429  \n",
       "181                                   -0.552790  \n",
       "182                                   -0.574011  \n",
       "183                                   -0.594627  \n",
       "184                                   -0.595647  \n",
       "185                                   -0.561738  \n",
       "186                                   -0.543989  \n",
       "187                                   -0.512069  \n",
       "188                                   -0.500824  \n",
       "189                                   -0.491677  \n",
       "190                                   -0.481495  \n",
       "191                                   -0.478094  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    53.235\n",
       "163    59.290\n",
       "164    54.875\n",
       "165    57.520\n",
       "166    49.573\n",
       "167    40.698\n",
       "168    47.195\n",
       "169    43.527\n",
       "170    45.488\n",
       "171    44.960\n",
       "172    36.721\n",
       "173    54.463\n",
       "174    51.462\n",
       "175    58.854\n",
       "176    53.940\n",
       "177    51.514\n",
       "178    42.635\n",
       "179    40.371\n",
       "180    48.990\n",
       "181    44.726\n",
       "182    44.491\n",
       "183    43.901\n",
       "184    55.019\n",
       "185    50.942\n",
       "186    63.992\n",
       "187    64.127\n",
       "188    60.822\n",
       "189    65.182\n",
       "190    51.282\n",
       "191    43.554\n",
       "Name: Distrito Federal - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    train, train_val = validation_splitter(train_input, 6)\n",
    "    target,target_val = validation_splitter(train_target, 6)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train_input, \n",
    "                        train_target, \n",
    "                        epochs=10000,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[879734783, 3465453232, 1629244912, 375501388, 1585315282, 3678478761, 3739960358, 3420587644, 1727912013, 2179788616, 502870164, 3584597009, 1742210170, 2008537515, 3690316247, 3505218498, 2486856343, 1149087968, 573820605, 3919907720, 3417328661, 2341142796, 1896535414, 3392300536, 108364276]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 1916.2340087890625\n",
      "winner_seed: 879734783\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 3336.59375\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 669.0719604492188\n",
      "winner_seed: 1629244912\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 6100.04052734375\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 4138.48388671875\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 75.11467742919922\n",
      "winner_seed: 3678478761\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 3457.427001953125\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 3352.271240234375\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 4470.2333984375\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 1786.462646484375\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 3625.160400390625\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 484.7122497558594\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 3876.67919921875\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 2230.158203125\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 503.802490234375\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 2705.949951171875\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 6660.0986328125\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 3014.6337890625\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 5404.65625\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 1594.3626708984375\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 2489.541015625\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 1432.35888671875\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 4420.056640625\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 3287.345703125\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 3998.84375\n",
      "\n",
      "\n",
      "final_seed: 3678478761\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 1s 27ms/step - loss: 7659.2300 - val_loss: 2178.2686\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6861.9121 - val_loss: 886.5637\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5732.6172 - val_loss: 20.1030\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5109.7192 - val_loss: 2308.0940\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5069.8345 - val_loss: 1292.2512\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4381.4321 - val_loss: 45.4358\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4281.3330 - val_loss: 48.6539\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3059.1467 - val_loss: 216.1776\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2198.4846 - val_loss: 264.5623\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1736.4313 - val_loss: 3357.5627\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1083.7008 - val_loss: 942.3229\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 244.4364 - val_loss: 1496.6981\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 202.3828 - val_loss: 1434.0977\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 208.9125 - val_loss: 1593.5939\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 189.5133 - val_loss: 1570.7645\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 184.0277 - val_loss: 1391.5834\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 194.6940 - val_loss: 1629.9253\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 178.0404 - val_loss: 1712.5111\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 187.7962 - val_loss: 1379.6572\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 199.6724 - val_loss: 1455.7863\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 191.0824 - val_loss: 1484.1849\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 191.9500 - val_loss: 1620.5359\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 192.2108 - val_loss: 1488.6854\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 188.6301 - val_loss: 1517.5890\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 180.4789 - val_loss: 1795.5780\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 198.0779 - val_loss: 1288.9473\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 194.0315 - val_loss: 1627.8003\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 190.8351 - val_loss: 1708.9526\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 190.4830 - val_loss: 1578.1842\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 190.0500 - val_loss: 1728.8962\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 198.0568 - val_loss: 1624.1084\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 183.9431 - val_loss: 1553.5535\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 185.9068 - val_loss: 1378.5439\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 190.6860 - val_loss: 1487.6870\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 181.3444 - val_loss: 1182.4984\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 187.5413 - val_loss: 1303.0848\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 181.7456 - val_loss: 1489.9215\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 179.1861 - val_loss: 1386.1987\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 185.2828 - val_loss: 1650.8643\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 164.6450 - val_loss: 1331.0260\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 166.3535 - val_loss: 1316.8914\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 175.7543 - val_loss: 1284.0996\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 186.8715 - val_loss: 1883.1541\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 193.4729 - val_loss: 1428.7380\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 175.7641 - val_loss: 1589.4575\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 170.3657 - val_loss: 1307.4928\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 151.9117 - val_loss: 1309.5144\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 167.3306 - val_loss: 1296.8458\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 167.6038 - val_loss: 1267.6729\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 174.1918 - val_loss: 1256.6615\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 169.5905 - val_loss: 1422.8077\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 165.2583 - val_loss: 1404.9502\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160.1387 - val_loss: 1422.4034\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 153.3485 - val_loss: 1324.7639\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 143.1051 - val_loss: 1204.7333\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 150.3174 - val_loss: 1342.2357\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 159.6848 - val_loss: 1808.3508\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 175.2599 - val_loss: 1407.4814\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 210.4168 - val_loss: 1516.3640\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 190.2808 - val_loss: 1889.9999\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 177.3196 - val_loss: 1603.5623\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 174.8212 - val_loss: 1404.4241\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 158.7716 - val_loss: 1399.3956\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 185.5668 - val_loss: 1661.4841\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 188.8766 - val_loss: 1540.1963\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 193.5436 - val_loss: 1816.1519\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 179.8336 - val_loss: 1633.5648\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 192.2219 - val_loss: 1677.1891\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 170.4675 - val_loss: 1623.4852\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 157.9908 - val_loss: 1321.6512\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 155.8301 - val_loss: 1478.8435\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 164.9789 - val_loss: 1588.8838\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 194.6517 - val_loss: 1360.8525\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160.6075 - val_loss: 1469.6351\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 156.6737 - val_loss: 1503.9742\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 161.9496 - val_loss: 1483.1711\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 153.9122 - val_loss: 1531.6420\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 153.4977 - val_loss: 1365.0310\n",
      "Epoch 79/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 142.2085 - val_loss: 1469.6660\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 145.1811 - val_loss: 1200.7773\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160.4624 - val_loss: 1349.2264\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 155.1261 - val_loss: 1519.3068\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 161.3419 - val_loss: 1299.4008\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 156.6958 - val_loss: 1371.1373\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 152.6587 - val_loss: 1269.8807\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 136.1352 - val_loss: 1181.9546\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 139.3244 - val_loss: 1399.5055\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 179.9029 - val_loss: 1367.6924\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 182.1664 - val_loss: 1299.5752\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 183.3098 - val_loss: 1321.0293\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 174.1577 - val_loss: 1868.4292\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 189.7475 - val_loss: 1854.3013\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 205.0123 - val_loss: 1561.7314\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 188.8799 - val_loss: 1605.0349\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 187.3353 - val_loss: 1625.3219\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 188.6024 - val_loss: 1608.5729\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 186.7850 - val_loss: 1750.1866\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 188.9952 - val_loss: 1726.1229\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 185.4290 - val_loss: 1662.5985\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 185.0496 - val_loss: 1552.5726\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 184.9284 - val_loss: 1770.1980\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 191.2833 - val_loss: 1651.9780\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 195.0311 - val_loss: 1533.3096\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 208.1616 - val_loss: 1694.2144\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 185.9212 - val_loss: 1694.5044\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 196.4237 - val_loss: 2205.1841\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 202.0665 - val_loss: 1074.5529\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 169.4275 - val_loss: 1118.3955\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 171.2330 - val_loss: 1104.5114\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 170.6978 - val_loss: 1087.6899\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 172.0461 - val_loss: 1062.9825\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 170.4075 - val_loss: 1089.0537\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 176.9910 - val_loss: 1348.8518\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 194.2728 - val_loss: 1149.7467\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 184.8370 - val_loss: 1218.7482\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 188.8302 - val_loss: 1173.9054\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 183.1597 - val_loss: 1182.1672\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 181.5714 - val_loss: 1141.9971\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 173.3242 - val_loss: 1166.0994\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 172.5752 - val_loss: 1178.2284\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 169.0133 - val_loss: 1357.9362\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 183.5509 - val_loss: 1379.6967\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 202.1112 - val_loss: 1445.5961\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 191.6770 - val_loss: 1256.1211\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 192.8631 - val_loss: 1285.8816\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 205.7504 - val_loss: 1275.8588\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 186.7734 - val_loss: 1279.2369\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 190.4183 - val_loss: 1188.3391\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 182.2407 - val_loss: 1241.1787\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 182.6435 - val_loss: 1201.4132\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 181.2820 - val_loss: 1046.1725\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 180.9693 - val_loss: 1023.5532\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 181.1439 - val_loss: 1425.9695\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 203.2318 - val_loss: 1196.4424\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 186.9047 - val_loss: 1188.0541\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 179.5959 - val_loss: 1118.4984\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 192.4984 - val_loss: 1293.4011\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 186.9411 - val_loss: 1196.7258\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 191.7191 - val_loss: 1522.2714\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 202.6922 - val_loss: 1261.2778\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 184.6014 - val_loss: 1308.0696\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 185.4526 - val_loss: 1076.2667\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 183.1407 - val_loss: 1153.9326\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 178.1233 - val_loss: 1265.6427\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 186.7405 - val_loss: 1254.4214\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 210.0991 - val_loss: 1648.4799\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 188.3329 - val_loss: 1462.1083\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 179.9574 - val_loss: 1689.3917\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 203.2673 - val_loss: 1580.8341\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 186.2570 - val_loss: 1653.8765\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 196.4832 - val_loss: 1313.2502\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 178.9656 - val_loss: 1528.5605\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 187.3229 - val_loss: 1405.4076\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 181.6858 - val_loss: 1536.1147\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 189.5101 - val_loss: 1464.6113\n",
      "Epoch 156/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 195.7474 - val_loss: 1328.2399\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 190.5031 - val_loss: 1569.2994\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 189.9672 - val_loss: 1342.7117\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 179.7842 - val_loss: 1432.1437\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 195.7169 - val_loss: 1363.6985\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 181.0934 - val_loss: 1287.0641\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 182.4359 - val_loss: 1360.0018\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 190.1799 - val_loss: 985.7468\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 196.8712 - val_loss: 1744.8494\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 180.7466 - val_loss: 1569.5415\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 195.7986 - val_loss: 1674.1420\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 179.4916 - val_loss: 1672.2089\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 183.4682 - val_loss: 1490.7140\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 188.3641 - val_loss: 1684.2664\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 184.8113 - val_loss: 1572.8254\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 180.9822 - val_loss: 1637.7371\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 184.3340 - val_loss: 1841.5675\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 199.2142 - val_loss: 1626.8063\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 195.2625 - val_loss: 1784.3004\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 203.8626 - val_loss: 1566.1434\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 190.8252 - val_loss: 1518.8147\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 188.3352 - val_loss: 1470.4575\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 208.3873 - val_loss: 1517.2496\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 217.2990 - val_loss: 1517.1313\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 185.5433 - val_loss: 1530.3912\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 185.3561 - val_loss: 1475.3469\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 189.4764 - val_loss: 1533.0408\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 188.5389 - val_loss: 1521.9489\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 192.6695 - val_loss: 1505.0815\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 199.7319 - val_loss: 1583.8589\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 187.2422 - val_loss: 1540.7142\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 189.3274 - val_loss: 1423.9840\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 189.8017 - val_loss: 1495.2255\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 186.8961 - val_loss: 1323.7635\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 180.9328 - val_loss: 1308.0786\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 190.0887 - val_loss: 1475.8127\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 181.8217 - val_loss: 1677.7939\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 196.7127 - val_loss: 1557.2311\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 186.5202 - val_loss: 1840.3313\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 207.5632 - val_loss: 1538.5082\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 186.3598 - val_loss: 1522.0806\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 188.7578 - val_loss: 1791.8723\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 196.3442 - val_loss: 1683.0792\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 174.9609 - val_loss: 1464.4219\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 183.6709 - val_loss: 1499.3745\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 199.6642 - val_loss: 1526.6208\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 177.8972 - val_loss: 1514.0016\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 193.7223 - val_loss: 1634.5376\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 181.2927 - val_loss: 1542.3301\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 174.5071 - val_loss: 1530.2217\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 178.6487 - val_loss: 1474.8469\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 180.2127 - val_loss: 1474.6613\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 178.9924 - val_loss: 1589.1478\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 181.3815 - val_loss: 1397.0294\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 181.6714 - val_loss: 1356.3666\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 186.5647 - val_loss: 1493.7631\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 186.0405 - val_loss: 1450.9774\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 179.2012 - val_loss: 1710.2576\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 203.1702 - val_loss: 1431.1315\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 192.9848 - val_loss: 1339.5577\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 181.5705 - val_loss: 1349.0271\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 181.6246 - val_loss: 1683.8573\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 192.5289 - val_loss: 1837.4286\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 183.3623 - val_loss: 1645.0406\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 176.3624 - val_loss: 1649.7778\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 181.4150 - val_loss: 1629.4055\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 189.7330 - val_loss: 1694.5994\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 185.6730 - val_loss: 1703.1223\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 187.5566 - val_loss: 1591.2255\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 180.0346 - val_loss: 1644.0615\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 174.9555 - val_loss: 1495.9208\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 187.0793 - val_loss: 1811.8247\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 186.7514 - val_loss: 1667.8414\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 183.9359 - val_loss: 1446.0751\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 188.7341 - val_loss: 1578.1787\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 185.7290 - val_loss: 1809.4718\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 185.2573 - val_loss: 2011.1183\n",
      "Epoch 233/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 204.5300 - val_loss: 1614.3384\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 186.3676 - val_loss: 1747.0363\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 184.2350 - val_loss: 1702.5094\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 173.2427 - val_loss: 1429.6003\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 173.7255 - val_loss: 1501.4092\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 178.7115 - val_loss: 1797.7407\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 180.9014 - val_loss: 1451.6255\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 177.7552 - val_loss: 1732.5878\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 176.3184 - val_loss: 1446.8206\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 184.0997 - val_loss: 1358.4154\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 193.4935 - val_loss: 1379.7793\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 176.3696 - val_loss: 1688.5438\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 176.1104 - val_loss: 1681.1969\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 172.9006 - val_loss: 1663.3134\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 178.6408 - val_loss: 1784.4907\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 176.8996 - val_loss: 1643.9120\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 177.8852 - val_loss: 1661.2240\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 182.0366 - val_loss: 1739.1644\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 178.5840 - val_loss: 1786.3857\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 180.4417 - val_loss: 1626.7418\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 172.9034 - val_loss: 1903.1995\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 188.7363 - val_loss: 1911.2990\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 176.3369 - val_loss: 1723.5587\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 184.5008 - val_loss: 1419.9731\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 188.8167 - val_loss: 1639.8633\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 175.0774 - val_loss: 1546.6613\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 180.8556 - val_loss: 1518.9507\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 190.4139 - val_loss: 1645.3998\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 174.1697 - val_loss: 1578.0835\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 180.7158 - val_loss: 1553.9026\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 188.1871 - val_loss: 1598.2296\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 173.4612 - val_loss: 1008.4921\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 158.1597 - val_loss: 1343.6625\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 180.0344 - val_loss: 1182.1384\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 167.2466 - val_loss: 1207.4318\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 155.9095 - val_loss: 980.6125\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 114.8923 - val_loss: 989.9930\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 131.3811 - val_loss: 1438.5511\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 136.2657 - val_loss: 1324.8669\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 136.1389 - val_loss: 1046.0598\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.9754 - val_loss: 1105.1732\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 119.7778 - val_loss: 1141.5221\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 126.4677 - val_loss: 1155.3379\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.3065 - val_loss: 916.7496\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 121.2698 - val_loss: 1311.0037\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 163.4248 - val_loss: 1112.9961\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 121.7985 - val_loss: 1286.5902\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 115.1950 - val_loss: 1147.3019\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 112.7496 - val_loss: 888.1151\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 114.8246 - val_loss: 820.8615\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 125.4751 - val_loss: 1266.5813\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 160.6929 - val_loss: 1807.2766\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 165.1706 - val_loss: 1804.9631\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 144.3959 - val_loss: 1652.7869\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 177.6147 - val_loss: 1591.1702\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 143.4165 - val_loss: 1548.5265\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 141.8588 - val_loss: 1584.1351\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 140.0098 - val_loss: 1879.2533\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 148.4627 - val_loss: 1594.8939\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 143.4528 - val_loss: 1455.9106\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 135.9380 - val_loss: 1439.4136\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.2136 - val_loss: 1404.3649\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 118.5746 - val_loss: 1581.3989\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 126.3799 - val_loss: 1579.9806\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 125.5168 - val_loss: 1449.7440\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 129.9563 - val_loss: 1524.0217\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 121.2591 - val_loss: 1287.7374\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 112.9943 - val_loss: 1435.9648\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 114.0732 - val_loss: 1321.8931\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 134.8231 - val_loss: 1424.4666\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 122.5350 - val_loss: 1436.8195\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 115.8552 - val_loss: 1233.3372\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 165.3656 - val_loss: 1060.5070\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 118.7132 - val_loss: 1196.2271\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 121.4863 - val_loss: 1366.9479\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 127.3936 - val_loss: 902.9350\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 128.7743 - val_loss: 932.8624\n",
      "Epoch 310/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 117.9344 - val_loss: 902.9748\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 121.4611 - val_loss: 682.7228\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 126.7157 - val_loss: 873.8668\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 132.1918 - val_loss: 1292.0049\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.4205 - val_loss: 1109.7976\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 115.3297 - val_loss: 828.1711\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 120.0857 - val_loss: 1046.5300\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.4129 - val_loss: 1082.7234\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 122.9880 - val_loss: 1525.8176\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 129.5696 - val_loss: 1312.5764\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 125.7261 - val_loss: 1261.0686\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 118.8423 - val_loss: 1036.5205\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 131.4088 - val_loss: 973.9678\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 122.7775 - val_loss: 1661.7155\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 127.3259 - val_loss: 906.1569\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 113.2916 - val_loss: 1234.2875\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.5059 - val_loss: 894.0972\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.7258 - val_loss: 977.4056\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.3221 - val_loss: 940.6964\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.2182 - val_loss: 947.2274\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.6283 - val_loss: 1308.2227\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.0017 - val_loss: 1188.5537\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.3973 - val_loss: 846.2939\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 128.1063 - val_loss: 1199.4669\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 130.2670 - val_loss: 1457.9679\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.4835 - val_loss: 1282.6528\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 113.3313 - val_loss: 1412.4402\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.6460 - val_loss: 1248.5632\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.3976 - val_loss: 1260.0409\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 132.8424 - val_loss: 1248.0616\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 113.9005 - val_loss: 1220.2966\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.9828 - val_loss: 1437.4343\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 122.0800 - val_loss: 1171.3302\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 140.0010 - val_loss: 1309.5127\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 133.1029 - val_loss: 1376.9521\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 133.1959 - val_loss: 994.0807\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.7197 - val_loss: 854.1622\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 136.8437 - val_loss: 1403.9440\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 165.5905 - val_loss: 1499.5499\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 141.1028 - val_loss: 1489.2227\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 129.2140 - val_loss: 798.5356\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 161.0419 - val_loss: 1645.5734\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 116.3331 - val_loss: 1752.0461\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.4273 - val_loss: 1596.8521\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 125.0909 - val_loss: 1495.3467\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 121.5179 - val_loss: 1385.1586\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 130.9697 - val_loss: 1557.1827\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 121.5947 - val_loss: 1127.6433\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 111.1325 - val_loss: 1477.5182\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 123.8004 - val_loss: 1404.0096\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 126.3762 - val_loss: 2092.7620\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.9815 - val_loss: 1776.3250\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 120.0536 - val_loss: 1557.2170\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.4381 - val_loss: 1632.1031\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.8547 - val_loss: 1331.9032\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.2364 - val_loss: 1393.1970\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 118.2149 - val_loss: 1685.3831\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.7121 - val_loss: 1571.1198\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 112.9930 - val_loss: 1568.1001\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 100.5619 - val_loss: 1437.3668\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.1032 - val_loss: 1906.2731\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 117.1509 - val_loss: 1817.4811\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.5782 - val_loss: 1145.0829\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 127.2785 - val_loss: 1275.9347\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.6204 - val_loss: 1028.8235\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 116.7954 - val_loss: 1055.8989\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.5097 - val_loss: 1363.8386\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.8840 - val_loss: 1146.8608\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.4238 - val_loss: 1621.5398\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.8999 - val_loss: 905.5497\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.7033 - val_loss: 1289.3313\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.6870 - val_loss: 1568.2039\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.4320 - val_loss: 983.6198\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 109.6550 - val_loss: 1304.3796\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.3179 - val_loss: 1875.3948\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 132.5962 - val_loss: 1333.1432\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.6327 - val_loss: 1494.6569\n",
      "Epoch 387/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 104.1142 - val_loss: 1303.6123\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.8187 - val_loss: 1317.4669\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.8781 - val_loss: 1991.1338\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.8111 - val_loss: 1460.1025\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 115.3130 - val_loss: 1520.9166\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.1228 - val_loss: 1704.3237\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.7946 - val_loss: 1553.0498\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.9964 - val_loss: 1077.0087\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.4207 - val_loss: 1526.6390\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 134.3719 - val_loss: 1607.6276\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.4023 - val_loss: 1460.4064\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 112.7210 - val_loss: 1369.3560\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.0510 - val_loss: 1640.3018\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.7424 - val_loss: 2133.3748\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.4221 - val_loss: 1786.2302\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.2645 - val_loss: 1648.8383\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 132.3848 - val_loss: 1767.5388\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 132.7378 - val_loss: 1510.8418\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 125.6715 - val_loss: 1401.0507\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.5856 - val_loss: 1710.3866\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.0952 - val_loss: 1393.6838\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.3715 - val_loss: 1432.3757\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.0472 - val_loss: 1678.5630\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.7434 - val_loss: 1600.7888\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.5715 - val_loss: 1557.2950\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.0288 - val_loss: 1817.1669\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.6188 - val_loss: 1374.3289\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.1718 - val_loss: 1487.6455\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.3472 - val_loss: 1915.3917\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 112.5027 - val_loss: 1551.2465\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.0190 - val_loss: 1633.5861\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.7058 - val_loss: 1432.9423\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.9982 - val_loss: 1689.1577\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.8187 - val_loss: 1586.7334\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.1119 - val_loss: 1771.3790\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.4399 - val_loss: 1646.9427\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.8565 - val_loss: 1519.5242\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 128.0529 - val_loss: 1576.8214\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.6867 - val_loss: 1632.2087\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.2711 - val_loss: 1881.0889\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 121.2138 - val_loss: 1679.8820\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 116.5363 - val_loss: 1710.8104\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.9593 - val_loss: 1898.0831\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.5524 - val_loss: 1659.5525\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.1338 - val_loss: 1012.5237\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 112.4518 - val_loss: 358.5478\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 360.5424 - val_loss: 2219.4299\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 156.1513 - val_loss: 1054.9575\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 122.4051 - val_loss: 1095.8199\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 125.0529 - val_loss: 874.3467\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.7347 - val_loss: 994.2773\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.3024 - val_loss: 955.3225\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.7679 - val_loss: 805.6430\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.0747 - val_loss: 983.4634\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.8454 - val_loss: 852.6888\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.4031 - val_loss: 950.3892\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.3486 - val_loss: 730.7670\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.9873 - val_loss: 692.1107\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.9840 - val_loss: 979.8851\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.3609 - val_loss: 697.9375\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.2611 - val_loss: 887.4099\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.0564 - val_loss: 823.4584\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 115.6989 - val_loss: 829.0462\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.6590 - val_loss: 985.7817\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.8049 - val_loss: 1102.8878\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.3792 - val_loss: 862.2475\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.2560 - val_loss: 949.0393\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.5516 - val_loss: 875.6265\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 115.1928 - val_loss: 937.9592\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 121.9314 - val_loss: 1022.6410\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.2073 - val_loss: 495.6805\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 151.6203 - val_loss: 1261.8695\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.5020 - val_loss: 1139.2454\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.3761 - val_loss: 1824.4382\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 112.8485 - val_loss: 1525.0052\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.3847 - val_loss: 1550.3137\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.1851 - val_loss: 1225.3622\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.9870 - val_loss: 1493.9324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 115.9162 - val_loss: 1627.6750\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.1507 - val_loss: 1215.1774\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.3737 - val_loss: 1796.2552\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.5389 - val_loss: 954.9131\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 111.6991 - val_loss: 1039.4607\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.2589 - val_loss: 1268.1071\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.5374 - val_loss: 1701.9772\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.7040 - val_loss: 1260.9644\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.0116 - val_loss: 1442.3129\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.7479 - val_loss: 1365.5190\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.9109 - val_loss: 1409.4956\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.5581 - val_loss: 1301.8828\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.5929 - val_loss: 1133.6122\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.0674 - val_loss: 1238.7661\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.2335 - val_loss: 1401.2738\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.9789 - val_loss: 1281.7897\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.6641 - val_loss: 1518.3545\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.0598 - val_loss: 1571.5021\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.5932 - val_loss: 1325.6482\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 118.8682 - val_loss: 608.2513\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 117.2065 - val_loss: 1549.5851\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.9451 - val_loss: 1629.9150\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.1801 - val_loss: 1460.7472\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.2048 - val_loss: 1327.4374\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.2672 - val_loss: 1420.8123\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.8199 - val_loss: 1563.5051\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.9909 - val_loss: 1357.9648\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.5995 - val_loss: 1151.6516\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.8745 - val_loss: 1193.0282\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.8887 - val_loss: 1353.4092\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.4925 - val_loss: 1216.4242\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.1897 - val_loss: 1101.5288\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.7329 - val_loss: 1306.1097\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.6695 - val_loss: 1349.0604\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.0685 - val_loss: 1298.2075\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.9105 - val_loss: 1370.2965\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 97.0636 - val_loss: 1221.9026\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.8773 - val_loss: 1509.8397\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.4865 - val_loss: 1334.6713\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.0521 - val_loss: 1161.5592\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.4944 - val_loss: 1387.9111\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.7016 - val_loss: 1282.3235\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 103.9343 - val_loss: 1034.6500\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.5511 - val_loss: 1620.5107\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 111.0949 - val_loss: 1281.9202\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.7900 - val_loss: 1395.5629\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.6287 - val_loss: 1379.5422\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.2604 - val_loss: 1273.8484\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 111.8507 - val_loss: 1345.0559\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.8889 - val_loss: 1744.8079\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.5975 - val_loss: 1614.0138\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.8704 - val_loss: 1669.4287\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.5908 - val_loss: 1666.6443\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.2058 - val_loss: 1439.0231\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.1891 - val_loss: 1482.7144\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.2230 - val_loss: 1457.3098\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.7175 - val_loss: 1527.1223\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.9814 - val_loss: 1572.6844\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.0581 - val_loss: 1409.8691\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.2410 - val_loss: 1574.1458\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.2268 - val_loss: 1603.2363\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.6029 - val_loss: 1363.5088\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.7903 - val_loss: 1300.0491\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 118.0754 - val_loss: 1659.0416\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.2218 - val_loss: 1464.8474\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.3783 - val_loss: 1444.6182\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.4202 - val_loss: 1586.8448\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.8121 - val_loss: 1369.2784\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.2916 - val_loss: 1393.6946\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.7159 - val_loss: 1556.2996\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.4326 - val_loss: 1507.3311\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.0580 - val_loss: 1493.8114\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.8240 - val_loss: 1523.6089\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.7405 - val_loss: 1329.4462\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.8768 - val_loss: 1392.8896\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.2732 - val_loss: 1352.1586\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.5173 - val_loss: 1384.7903\n",
      "Epoch 542/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 95.5967 - val_loss: 1447.8599\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.6384 - val_loss: 1338.9872\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.1178 - val_loss: 1520.1208\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.1261 - val_loss: 1527.0472\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.5151 - val_loss: 1478.4089\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.4722 - val_loss: 1544.6317\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.1610 - val_loss: 1527.1575\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.1104 - val_loss: 1225.9548\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.0575 - val_loss: 1231.4659\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.5191 - val_loss: 1335.3801\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.6973 - val_loss: 1366.6626\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.1610 - val_loss: 1276.6012\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.1926 - val_loss: 1443.8446\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.5505 - val_loss: 1346.3287\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.1098 - val_loss: 1119.4216\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.8410 - val_loss: 1422.5894\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.6063 - val_loss: 1223.5022\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.3891 - val_loss: 1581.7646\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.9143 - val_loss: 1343.6239\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.5452 - val_loss: 1755.4137\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.0448 - val_loss: 1353.4971\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.1720 - val_loss: 1685.8154\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.0662 - val_loss: 1481.5278\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.1825 - val_loss: 1333.7682\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.7367 - val_loss: 2236.0024\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 122.5432 - val_loss: 1478.6282\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 113.4041 - val_loss: 1416.0955\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.2950 - val_loss: 1251.1382\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.5085 - val_loss: 1353.0703\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.8980 - val_loss: 1293.6025\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 115.2035 - val_loss: 1376.1630\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.8490 - val_loss: 1442.5601\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.0487 - val_loss: 1492.2648\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.2472 - val_loss: 1383.0162\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.7534 - val_loss: 1681.2087\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.9007 - val_loss: 1550.4756\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.0408 - val_loss: 1597.3763\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.5648 - val_loss: 1600.5387\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.9559 - val_loss: 1701.6396\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.2651 - val_loss: 1812.8099\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.9666 - val_loss: 1608.2941\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.1296 - val_loss: 1688.6794\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.7523 - val_loss: 1407.2994\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.6013 - val_loss: 1263.9364\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.3949 - val_loss: 1657.6080\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.4647 - val_loss: 1665.4856\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.5368 - val_loss: 1828.4734\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.2515 - val_loss: 1589.9158\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.3725 - val_loss: 1537.3917\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.4467 - val_loss: 1581.4658\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.9105 - val_loss: 1532.3741\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.3295 - val_loss: 1525.5706\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.0268 - val_loss: 1642.3531\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.5643 - val_loss: 1742.4061\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.8955 - val_loss: 1369.2208\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.6827 - val_loss: 1789.0288\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.2570 - val_loss: 1641.9852\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.9994 - val_loss: 1477.5958\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.8898 - val_loss: 1804.9166\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.9380 - val_loss: 1479.7629\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.3194 - val_loss: 1541.0519\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.3643 - val_loss: 1994.2737\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.0734 - val_loss: 1756.6229\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.0090 - val_loss: 1757.1204\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.4826 - val_loss: 1885.4924\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 124.2072 - val_loss: 1700.7328\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.8661 - val_loss: 1488.8875\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.4574 - val_loss: 1485.9059\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.9350 - val_loss: 2099.2705\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.2776 - val_loss: 1522.8192\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.3928 - val_loss: 1803.8754\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.7597 - val_loss: 1655.2705\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.9133 - val_loss: 1342.9668\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.8553 - val_loss: 1493.4727\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.5324 - val_loss: 1446.6884\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.9914 - val_loss: 1805.1670\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.3185 - val_loss: 1724.3728\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.0954 - val_loss: 1888.7136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.2366 - val_loss: 1713.6611\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.8147 - val_loss: 1478.6266\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.9604 - val_loss: 1718.4020\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.9520 - val_loss: 1540.4814\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.3196 - val_loss: 1554.0365\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.7656 - val_loss: 1627.9026\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.5984 - val_loss: 1234.5729\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.1290 - val_loss: 1373.8552\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.4812 - val_loss: 1773.3796\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.2522 - val_loss: 1804.7463\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.2288 - val_loss: 1435.2480\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.5287 - val_loss: 1459.6653\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.9305 - val_loss: 1577.4513\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.7923 - val_loss: 1492.6201\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.7190 - val_loss: 1643.2595\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.6142 - val_loss: 1563.3875\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.9687 - val_loss: 1369.0811\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.5377 - val_loss: 1676.5145\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.2097 - val_loss: 1604.4353\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.1027 - val_loss: 1673.7153\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.5416 - val_loss: 1525.8115\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.2904 - val_loss: 1602.0013\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.8065 - val_loss: 1569.8063\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.2463 - val_loss: 1937.0795\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.6239 - val_loss: 1626.1378\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.1796 - val_loss: 1566.9847\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.0750 - val_loss: 1613.8480\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.7347 - val_loss: 1815.3726\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.9872 - val_loss: 1693.0155\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.8152 - val_loss: 1489.7216\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.7634 - val_loss: 1520.2645\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.9585 - val_loss: 1787.6332\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.4821 - val_loss: 1592.2705\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.3314 - val_loss: 1719.4061\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.8831 - val_loss: 1559.8782\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.4733 - val_loss: 1802.8661\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.7224 - val_loss: 1633.7587\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.3352 - val_loss: 1676.2048\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.2563 - val_loss: 1730.6799\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.7346 - val_loss: 1430.7366\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.4165 - val_loss: 1500.0403\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.7655 - val_loss: 1585.4180\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.6117 - val_loss: 2442.2559\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.3993 - val_loss: 1663.9365\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.2857 - val_loss: 1721.8044\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.1429 - val_loss: 1635.9097\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.1916 - val_loss: 1743.3346\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 76.6149 - val_loss: 1586.0863\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.3093 - val_loss: 1716.4037\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.8410 - val_loss: 1798.2206\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.7699 - val_loss: 1804.4185\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.6937 - val_loss: 1756.7371\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.0693 - val_loss: 1784.8723\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.8381 - val_loss: 1681.5062\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.8590 - val_loss: 1660.9972\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.2071 - val_loss: 1768.1864\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.8817 - val_loss: 1636.5653\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.9410 - val_loss: 1711.3738\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.2609 - val_loss: 1710.4590\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.1512 - val_loss: 1653.1151\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.8435 - val_loss: 1552.0583\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.9627 - val_loss: 1535.2277\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.0241 - val_loss: 1502.9458\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.9295 - val_loss: 1493.3008\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.5241 - val_loss: 1320.0967\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.6165 - val_loss: 1730.6035\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.3196 - val_loss: 1442.9791\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.3772 - val_loss: 1584.6274\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.0780 - val_loss: 1524.6567\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.7512 - val_loss: 1466.4384\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.9276 - val_loss: 1646.7938\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.0601 - val_loss: 1401.3776\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.9099 - val_loss: 1476.0547\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.1692 - val_loss: 1278.2821\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.6007 - val_loss: 2081.0376\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.6281 - val_loss: 1497.9080\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.1099 - val_loss: 1625.8655\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.6197 - val_loss: 1602.5958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.5211 - val_loss: 1427.9854\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.1753 - val_loss: 1624.2396\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.7172 - val_loss: 1543.1082\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.9475 - val_loss: 1674.8795\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.5742 - val_loss: 1527.5769\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.1720 - val_loss: 1520.5928\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.5836 - val_loss: 1850.6787\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.2079 - val_loss: 1449.7009\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.8135 - val_loss: 1551.7614\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.1037 - val_loss: 1536.9335\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.0694 - val_loss: 1503.9579\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.0898 - val_loss: 1700.6465\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.2779 - val_loss: 1659.2407\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.4064 - val_loss: 1476.0935\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.1981 - val_loss: 1447.7059\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.1910 - val_loss: 1624.5258\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.1827 - val_loss: 1507.3031\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.2793 - val_loss: 1387.8660\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.3467 - val_loss: 1310.6279\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.9052 - val_loss: 1335.6731\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.4996 - val_loss: 1382.9622\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.2883 - val_loss: 1569.5287\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.1345 - val_loss: 1395.3733\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.0314 - val_loss: 1823.9004\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.7905 - val_loss: 1573.7832\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.7292 - val_loss: 1467.4528\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.0847 - val_loss: 1223.4526\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.9081 - val_loss: 1315.4475\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.1032 - val_loss: 1114.1030\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.6271 - val_loss: 1503.6117\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.0490 - val_loss: 1327.4844\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.8908 - val_loss: 1721.5886\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.2827 - val_loss: 1531.8984\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.7268 - val_loss: 1307.4698\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.3110 - val_loss: 1529.1613\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.0320 - val_loss: 1634.2806\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.4799 - val_loss: 1677.1237\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.4428 - val_loss: 1466.0493\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.6025 - val_loss: 1539.0712\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 76.1858 - val_loss: 1602.8145\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.1692 - val_loss: 1417.6128\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.4670 - val_loss: 1543.2372\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.1983 - val_loss: 1505.9919\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.6283 - val_loss: 1506.0406\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.6743 - val_loss: 1362.0167\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.2562 - val_loss: 1717.1451\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.3480 - val_loss: 1548.5029\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.9973 - val_loss: 1249.0615\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.6265 - val_loss: 1468.6045\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.0358 - val_loss: 1357.7985\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.7950 - val_loss: 2042.0398\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.9251 - val_loss: 1438.9418\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.1180 - val_loss: 1647.5892\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.7931 - val_loss: 1365.1505\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.9300 - val_loss: 1295.5823\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 132.1035 - val_loss: 1576.9576\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.1740 - val_loss: 1850.5848\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.8140 - val_loss: 1859.6967\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.6059 - val_loss: 1468.1241\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 113.8976 - val_loss: 1686.8824\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.6122 - val_loss: 1100.3802\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 113.2034 - val_loss: 1843.8235\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.6511 - val_loss: 1422.9133\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.2077 - val_loss: 1486.5338\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.3083 - val_loss: 1511.4192\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.2048 - val_loss: 1789.5276\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.3057 - val_loss: 1562.6370\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.3782 - val_loss: 1653.0305\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.1452 - val_loss: 1710.1356\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.1339 - val_loss: 1558.8496\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.6652 - val_loss: 1096.8029\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.7236 - val_loss: 1534.6368\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.0891 - val_loss: 1438.8772\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.3786 - val_loss: 1449.5724\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.6265 - val_loss: 1463.8282\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.5261 - val_loss: 1548.2969\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.6065 - val_loss: 1739.2034\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.8069 - val_loss: 1118.2528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 140.6675 - val_loss: 1126.0791\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 340.3761 - val_loss: 961.5707\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 161.3839 - val_loss: 1390.3602\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 124.1231 - val_loss: 1863.8492\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.9435 - val_loss: 1675.3396\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.1830 - val_loss: 1552.7317\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.6573 - val_loss: 1415.0520\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.1181 - val_loss: 1365.5409\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.0613 - val_loss: 1408.2246\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.4002 - val_loss: 1083.3271\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.7122 - val_loss: 1390.7863\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.6430 - val_loss: 1598.1953\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.9357 - val_loss: 1403.7720\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.6701 - val_loss: 1431.1576\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.1909 - val_loss: 1537.1455\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 129.8590 - val_loss: 1662.1831\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.3723 - val_loss: 1575.6719\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.8989 - val_loss: 1400.5364\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.9795 - val_loss: 1609.1119\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.8031 - val_loss: 1368.8436\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.8062 - val_loss: 1472.9794\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.9814 - val_loss: 1188.3408\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.9671 - val_loss: 1452.0433\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.2448 - val_loss: 1312.5122\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.3895 - val_loss: 1361.0941\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.0889 - val_loss: 1362.9932\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.4260 - val_loss: 1959.8573\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.4335 - val_loss: 1780.1942\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.5053 - val_loss: 2192.5886\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.1242 - val_loss: 1676.6498\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78.4579 - val_loss: 1864.0232\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.4790 - val_loss: 1372.6997\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.2594 - val_loss: 991.1414\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.6753 - val_loss: 1436.8771\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.3171 - val_loss: 1333.3398\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 76.4910 - val_loss: 1187.5135\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.7659 - val_loss: 1108.2765\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.6908 - val_loss: 1360.1107\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.9274 - val_loss: 1350.2178\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 127.3251 - val_loss: 1446.4976\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 119.8454 - val_loss: 1292.7202\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.5315 - val_loss: 1463.1912\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.4904 - val_loss: 1233.1639\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 111.8013 - val_loss: 1593.3877\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.3690 - val_loss: 1314.2850\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.6142 - val_loss: 1426.4919\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.1590 - val_loss: 1098.9366\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.3176 - val_loss: 1048.8367\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.3062 - val_loss: 1152.5081\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.9147 - val_loss: 1447.0692\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.2454 - val_loss: 1240.2122\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.3265 - val_loss: 1221.7581\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 123.7306 - val_loss: 1437.3405\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 116.4252 - val_loss: 1592.6620\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.7835 - val_loss: 1114.4043\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.7062 - val_loss: 1317.5474\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.9141 - val_loss: 1319.6591\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.7365 - val_loss: 1220.7545\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.6817 - val_loss: 1226.4524\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.5072 - val_loss: 1400.6060\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 111.1313 - val_loss: 1335.6953\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.0240 - val_loss: 1115.3876\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 113.9469 - val_loss: 1404.1116\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 115.1212 - val_loss: 1250.6750\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.6535 - val_loss: 1056.2517\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 116.3294 - val_loss: 1254.9951\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.6028 - val_loss: 1173.9696\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.8843 - val_loss: 1215.7014\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.7946 - val_loss: 1600.2994\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.0316 - val_loss: 1240.2974\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.0610 - val_loss: 1277.8575\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.1906 - val_loss: 1223.7528\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.6268 - val_loss: 1368.5461\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.7802 - val_loss: 1004.2221\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.9626 - val_loss: 1315.7457\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.7857 - val_loss: 1721.8427\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.5794 - val_loss: 1441.8942\n",
      "Epoch 853/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 90.1507 - val_loss: 1372.6113\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.7197 - val_loss: 1571.7694\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.9744 - val_loss: 1450.8208\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.6519 - val_loss: 1342.1729\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.2130 - val_loss: 1325.5398\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.6637 - val_loss: 1598.2606\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.7796 - val_loss: 1369.4713\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.7198 - val_loss: 1405.4855\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.9228 - val_loss: 1588.8025\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.1915 - val_loss: 1542.5465\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78.5987 - val_loss: 1415.3566\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.0797 - val_loss: 1379.2003\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.8041 - val_loss: 1282.2943\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.6161 - val_loss: 1796.9899\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.9770 - val_loss: 1622.0042\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.7880 - val_loss: 1214.3899\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.4171 - val_loss: 1370.4193\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.2722 - val_loss: 1397.3121\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.1594 - val_loss: 1468.3447\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.0428 - val_loss: 1550.2430\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.3434 - val_loss: 1324.4272\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.4721 - val_loss: 1752.2198\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.6360 - val_loss: 1695.6865\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.9919 - val_loss: 1497.9048\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.7991 - val_loss: 1542.1143\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.8557 - val_loss: 1577.5168\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.7388 - val_loss: 1467.9244\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.7108 - val_loss: 1616.1523\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.9735 - val_loss: 1664.2402\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.7044 - val_loss: 1153.3256\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.9088 - val_loss: 1495.2894\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.7276 - val_loss: 1265.6099\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.7080 - val_loss: 1349.0886\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.8213 - val_loss: 1620.2780\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.7380 - val_loss: 1537.3848\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.9419 - val_loss: 1433.2756\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.3550 - val_loss: 1464.1620\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.1029 - val_loss: 1524.0974\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.3682 - val_loss: 1271.1708\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.1849 - val_loss: 1565.7433\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.3275 - val_loss: 1401.8555\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.6088 - val_loss: 1551.5928\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.6830 - val_loss: 1610.9496\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.6293 - val_loss: 1680.0068\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.6130 - val_loss: 1387.5453\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.5004 - val_loss: 1582.4641\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.4030 - val_loss: 1426.0319\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.3205 - val_loss: 1564.3374\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.8173 - val_loss: 1723.8403\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.8447 - val_loss: 1608.3917\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.4328 - val_loss: 1516.9156\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.7069 - val_loss: 1649.4899\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.2208 - val_loss: 1514.9310\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.8592 - val_loss: 1446.0537\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.6192 - val_loss: 1372.6760\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.3891 - val_loss: 1533.8591\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.5470 - val_loss: 1400.6895\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.7063 - val_loss: 1351.5601\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.5071 - val_loss: 1534.6421\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.1335 - val_loss: 1479.9933\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.0901 - val_loss: 1231.0107\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.7118 - val_loss: 1687.2493\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.6399 - val_loss: 1590.7711\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.0114 - val_loss: 1384.8469\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.1443 - val_loss: 1221.2572\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.4081 - val_loss: 1486.2174\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.4117 - val_loss: 1493.2126\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.0700 - val_loss: 1368.3417\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.6394 - val_loss: 1351.8466\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.4062 - val_loss: 1289.1602\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.8487 - val_loss: 1660.1299\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.5683 - val_loss: 1435.4431\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.8297 - val_loss: 1206.3538\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.3252 - val_loss: 1525.9584\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.7685 - val_loss: 1411.5432\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.6416 - val_loss: 1233.4065\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 75.1723 - val_loss: 1509.3989\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 72.8551 - val_loss: 1457.3245\n",
      "Epoch 931/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 73.1460 - val_loss: 1394.2135\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.6860 - val_loss: 1362.0973\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.0737 - val_loss: 1441.1963\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.3106 - val_loss: 1352.8456\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.9409 - val_loss: 1637.6998\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.2685 - val_loss: 1242.9348\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.7281 - val_loss: 924.4102\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 122.4066 - val_loss: 1523.7032\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.3912 - val_loss: 1403.9606\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.0998 - val_loss: 1463.1565\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.0945 - val_loss: 1385.6917\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.1993 - val_loss: 1515.5603\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.0394 - val_loss: 1332.1298\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.7736 - val_loss: 1495.8959\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 75.9943 - val_loss: 1479.7045\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.3412 - val_loss: 1578.2092\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.5909 - val_loss: 1660.3339\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.9044 - val_loss: 1587.2871\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.3113 - val_loss: 1590.5331\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.7546 - val_loss: 1317.6412\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.6894 - val_loss: 2127.3354\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.3786 - val_loss: 1698.8436\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.8717 - val_loss: 1313.7377\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.7876 - val_loss: 1271.0809\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.5527 - val_loss: 1612.4137\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.9873 - val_loss: 1391.3113\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.5867 - val_loss: 1593.8420\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.4136 - val_loss: 1526.2234\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.4803 - val_loss: 1422.9794\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.2027 - val_loss: 1435.9836\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.5082 - val_loss: 1411.3582\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.7876 - val_loss: 1647.8971\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 78.3500 - val_loss: 1167.8311\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.3181 - val_loss: 1183.2373\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.9047 - val_loss: 1493.7979\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.7068 - val_loss: 1725.2657\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.8306 - val_loss: 1672.1689\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.1454 - val_loss: 1617.5829\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.7876 - val_loss: 1266.3613\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.2887 - val_loss: 1636.8174\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.2963 - val_loss: 1687.5729\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.7581 - val_loss: 1630.5267\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.0006 - val_loss: 1479.4727\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.6010 - val_loss: 1449.5396\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.6781 - val_loss: 1478.8849\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.7897 - val_loss: 1339.5540\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.6203 - val_loss: 1396.7352\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.8335 - val_loss: 1489.9521\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.7603 - val_loss: 1375.0016\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.6544 - val_loss: 1429.9160\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.5833 - val_loss: 1255.1278\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.3011 - val_loss: 1153.2107\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.7519 - val_loss: 1395.9265\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.5400 - val_loss: 1511.9196\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 78.7562 - val_loss: 1326.7842\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.4292 - val_loss: 1551.7014\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.9395 - val_loss: 1475.2615\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.5864 - val_loss: 1562.2738\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.8630 - val_loss: 1455.0302\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.8754 - val_loss: 1531.7170\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.6660 - val_loss: 1362.1034\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.0345 - val_loss: 1543.7670\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.9765 - val_loss: 1574.7056\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.8963 - val_loss: 1385.4476\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.0786 - val_loss: 1690.7175\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.4922 - val_loss: 1517.3602\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.2594 - val_loss: 1257.0892\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.2432 - val_loss: 1306.7914\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 111.4432 - val_loss: 1431.7151\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.7542 - val_loss: 1374.1090\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.2173 - val_loss: 1707.5793\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.1249 - val_loss: 1732.9124\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.9317 - val_loss: 1513.0129\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.8219 - val_loss: 2069.4534\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.4991 - val_loss: 1239.5585\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.6294 - val_loss: 1169.0386\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.3537 - val_loss: 1417.5620\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.0785 - val_loss: 1476.8556\n",
      "Epoch 1009/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 81.2150 - val_loss: 1586.5256\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.7026 - val_loss: 1539.8892\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.0668 - val_loss: 1235.3484\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.9676 - val_loss: 1613.8627\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.8801 - val_loss: 1508.9764\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.4217 - val_loss: 1446.4961\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.9904 - val_loss: 1520.4989\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.4726 - val_loss: 1261.4045\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.5904 - val_loss: 1782.1599\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.4541 - val_loss: 1743.4277\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.9735 - val_loss: 1448.0168\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.4300 - val_loss: 1448.2213\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.0353 - val_loss: 1418.1311\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.0807 - val_loss: 1363.9417\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.1479 - val_loss: 1648.1597\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.9831 - val_loss: 1390.1831\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.4960 - val_loss: 1539.8652\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 75.4862 - val_loss: 1575.6147\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 75.3803 - val_loss: 1256.7858\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.4944 - val_loss: 1686.2887\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.7483 - val_loss: 1617.9878\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 123.0005 - val_loss: 1511.0035\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.1265 - val_loss: 1679.2283\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.7346 - val_loss: 1370.2845\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.8544 - val_loss: 1510.6073\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 112.0636 - val_loss: 1654.2363\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.6480 - val_loss: 1631.4420\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.7272 - val_loss: 1397.1678\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.2469 - val_loss: 1438.5779\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.1113 - val_loss: 1604.9752\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.8116 - val_loss: 1502.5262\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.5333 - val_loss: 1399.8755\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.7516 - val_loss: 1527.4586\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.6053 - val_loss: 1328.3247\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.3850 - val_loss: 1293.0085\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.9687 - val_loss: 1400.5032\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.1394 - val_loss: 1604.1067\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.7369 - val_loss: 1422.4636\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.9257 - val_loss: 1606.9135\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.7319 - val_loss: 1210.7758\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.0980 - val_loss: 1497.4984\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.1717 - val_loss: 1497.9958\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.2190 - val_loss: 1363.5521\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 141.9464 - val_loss: 1310.0415\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 252.0336 - val_loss: 1251.3837\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 141.9966 - val_loss: 1361.1995\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.1476 - val_loss: 1225.2252\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.6517 - val_loss: 1324.2068\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.1285 - val_loss: 1503.1464\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.7874 - val_loss: 1544.0294\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.1081 - val_loss: 1557.1553\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.8503 - val_loss: 1444.2415\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.6293 - val_loss: 1346.3445\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.0510 - val_loss: 1111.1729\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 130.7236 - val_loss: 1355.1644\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.5885 - val_loss: 1327.3993\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.1760 - val_loss: 1513.7913\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.8698 - val_loss: 1398.4541\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.8347 - val_loss: 1053.3340\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.6328 - val_loss: 1326.3489\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.2053 - val_loss: 1385.0776\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.2571 - val_loss: 1287.7562\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.9896 - val_loss: 1417.2238\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.2028 - val_loss: 1241.1599\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.7408 - val_loss: 1642.3923\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.2035 - val_loss: 1267.0618\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 117.8243 - val_loss: 903.3926\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 131.9812 - val_loss: 1362.2217\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.5979 - val_loss: 1464.6798\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.4027 - val_loss: 1258.5864\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.3602 - val_loss: 1363.1500\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.1352 - val_loss: 1562.6016\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.3490 - val_loss: 1286.6482\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.0994 - val_loss: 1432.4371\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.7874 - val_loss: 1400.9906\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.0746 - val_loss: 1402.3323\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.5057 - val_loss: 1171.1084\n",
      "Epoch 1086/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 103.5141 - val_loss: 1203.8805\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.3218 - val_loss: 1327.6288\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.4220 - val_loss: 1276.0731\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.6001 - val_loss: 1527.0497\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.1215 - val_loss: 1245.2516\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.3938 - val_loss: 1498.8126\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.6036 - val_loss: 1466.8979\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.2970 - val_loss: 1258.1025\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.3875 - val_loss: 1421.5537\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.6069 - val_loss: 1460.0742\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.7129 - val_loss: 1381.1007\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.0293 - val_loss: 1355.2709\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.6902 - val_loss: 1413.8641\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.6499 - val_loss: 1461.9919\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.3944 - val_loss: 1334.1165\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.1144 - val_loss: 1414.2610\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 102.7204 - val_loss: 1535.2020\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.1452 - val_loss: 1669.9598\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 217.1017 - val_loss: 75.1147\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 229.1103 - val_loss: 1118.1006\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.2408 - val_loss: 1432.1028\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.2400 - val_loss: 1357.4695\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.4378 - val_loss: 1286.9796\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.5586 - val_loss: 953.5730\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.0652 - val_loss: 1145.7863\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.9208 - val_loss: 1199.2827\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.8151 - val_loss: 1087.8029\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.4112 - val_loss: 1139.2643\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.1307 - val_loss: 882.1620\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.2082 - val_loss: 1395.9713\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 122.8532 - val_loss: 1303.0479\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.1623 - val_loss: 1345.2588\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.2198 - val_loss: 1150.6335\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.1000 - val_loss: 1269.9150\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.7010 - val_loss: 1488.4662\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.3498 - val_loss: 1267.8567\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.2739 - val_loss: 1343.7290\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.0506 - val_loss: 1236.5145\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.6251 - val_loss: 1043.5476\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 121.4807 - val_loss: 1414.4601\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 121.0441 - val_loss: 1280.1161\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.8827 - val_loss: 1315.7390\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.0337 - val_loss: 1281.3258\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 111.3600 - val_loss: 1363.2571\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.9502 - val_loss: 1084.9443\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.3211 - val_loss: 1119.4358\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.8890 - val_loss: 1168.5023\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.9241 - val_loss: 1511.1387\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.8232 - val_loss: 1267.1439\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.7716 - val_loss: 1113.1578\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.7930 - val_loss: 1328.3120\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.0407 - val_loss: 1283.9902\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.4568 - val_loss: 928.5198\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.8283 - val_loss: 1168.6348\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.1207 - val_loss: 1081.2367\n",
      "Epoch 1141/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.4968 - val_loss: 1006.4452\n",
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.9667 - val_loss: 1163.4432\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.5356 - val_loss: 1116.1851\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.9807 - val_loss: 1306.7842\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.1249 - val_loss: 1068.6698\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.4471 - val_loss: 1179.5118\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.1912 - val_loss: 1023.4780\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.6049 - val_loss: 1499.0548\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.9107 - val_loss: 1550.0470\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.4114 - val_loss: 1459.3337\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.5440 - val_loss: 1447.6632\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.8003 - val_loss: 1500.9883\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.8092 - val_loss: 1537.0815\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.7181 - val_loss: 1486.7209\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.0752 - val_loss: 1418.8695\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.7507 - val_loss: 1361.2964\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.0261 - val_loss: 1360.1990\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.9885 - val_loss: 1278.0275\n",
      "Epoch 1159/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.6617 - val_loss: 1262.3287\n",
      "Epoch 1160/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.5121 - val_loss: 1170.4292\n",
      "Epoch 1161/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.6921 - val_loss: 1217.0028\n",
      "Epoch 1162/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.6223 - val_loss: 1283.0029\n",
      "Epoch 1163/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 95.8535 - val_loss: 1275.0792\n",
      "Epoch 1164/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.1238 - val_loss: 1346.1627\n",
      "Epoch 1165/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 111.8471 - val_loss: 1592.9514\n",
      "Epoch 1166/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 273.0345 - val_loss: 797.9413\n",
      "Epoch 1167/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.1230 - val_loss: 1437.5481\n",
      "Epoch 1168/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 116.4385 - val_loss: 1227.7905\n",
      "Epoch 1169/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.7211 - val_loss: 1092.9413\n",
      "Epoch 1170/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.0998 - val_loss: 1043.4032\n",
      "Epoch 1171/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 111.6384 - val_loss: 1039.9966\n",
      "Epoch 1172/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.1768 - val_loss: 1042.7238\n",
      "Epoch 1173/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.1760 - val_loss: 1100.0391\n",
      "Epoch 1174/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 95.2960 - val_loss: 996.0620\n",
      "Epoch 1175/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.4696 - val_loss: 1075.5615\n",
      "Epoch 1176/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.2254 - val_loss: 1100.1403\n",
      "Epoch 1177/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.4193 - val_loss: 1000.7159\n",
      "Epoch 1178/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.9324 - val_loss: 1122.8557\n",
      "Epoch 1179/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.5362 - val_loss: 1293.0459\n",
      "Epoch 1180/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.7104 - val_loss: 1022.0795\n",
      "Epoch 1181/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.8082 - val_loss: 865.0513\n",
      "Epoch 1182/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.0982 - val_loss: 1024.7126\n",
      "Epoch 1183/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.5463 - val_loss: 878.4985\n",
      "Epoch 1184/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.7558 - val_loss: 717.8596\n",
      "Epoch 1185/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.7976 - val_loss: 1039.9884\n",
      "Epoch 1186/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 113.0701 - val_loss: 1313.3512\n",
      "Epoch 1187/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.4353 - val_loss: 1431.6807\n",
      "Epoch 1188/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.8594 - val_loss: 1162.0931\n",
      "Epoch 1189/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.6626 - val_loss: 987.3447\n",
      "Epoch 1190/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.0817 - val_loss: 943.6573\n",
      "Epoch 1191/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.9456 - val_loss: 923.5806\n",
      "Epoch 1192/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.9398 - val_loss: 1072.8293\n",
      "Epoch 1193/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.8213 - val_loss: 868.3088\n",
      "Epoch 1194/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.8454 - val_loss: 522.1641\n",
      "Epoch 1195/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.7408 - val_loss: 954.2932\n",
      "Epoch 1196/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.5047 - val_loss: 994.7590\n",
      "Epoch 1197/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.8848 - val_loss: 847.0718\n",
      "Epoch 1198/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.8812 - val_loss: 1011.6058\n",
      "Epoch 1199/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.9537 - val_loss: 1014.0043\n",
      "Epoch 1200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.6035 - val_loss: 995.1835\n",
      "Epoch 1201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.3765 - val_loss: 977.1388\n",
      "Epoch 1202/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.8593 - val_loss: 888.9151\n",
      "Epoch 1203/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.5040 - val_loss: 1151.6580\n",
      "Epoch 1204/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.3571 - val_loss: 1011.6156\n",
      "Epoch 1205/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.3751 - val_loss: 995.2861\n",
      "Epoch 1206/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.5067 - val_loss: 1042.6713\n",
      "Epoch 1207/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.4109 - val_loss: 1284.9347\n",
      "Epoch 1208/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.3723 - val_loss: 1158.5748\n",
      "Epoch 1209/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.6216 - val_loss: 994.9202\n",
      "Epoch 1210/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.9008 - val_loss: 1095.4153\n",
      "Epoch 1211/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.7071 - val_loss: 1032.4849\n",
      "Epoch 1212/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.2865 - val_loss: 1229.6711\n",
      "Epoch 1213/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.6227 - val_loss: 1219.7168\n",
      "Epoch 1214/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.2578 - val_loss: 998.1444\n",
      "Epoch 1215/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.0702 - val_loss: 1144.0280\n",
      "Epoch 1216/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.7747 - val_loss: 1052.7841\n",
      "Epoch 1217/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.5470 - val_loss: 1117.5701\n",
      "Epoch 1218/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.6250 - val_loss: 855.0298\n",
      "Epoch 1219/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.1417 - val_loss: 1134.9463\n",
      "Epoch 1220/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.9726 - val_loss: 933.6033\n",
      "Epoch 1221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.7447 - val_loss: 1126.5829\n",
      "Epoch 1222/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.8167 - val_loss: 1168.2057\n",
      "Epoch 1223/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.7654 - val_loss: 906.4418\n",
      "Epoch 1224/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.9820 - val_loss: 953.2769\n",
      "Epoch 1225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.2315 - val_loss: 1410.3286\n",
      "Epoch 1226/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.2649 - val_loss: 944.6047\n",
      "Epoch 1227/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.4667 - val_loss: 1094.2390\n",
      "Epoch 1228/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.6463 - val_loss: 1223.1449\n",
      "Epoch 1229/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.1784 - val_loss: 918.6937\n",
      "Epoch 1230/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.9950 - val_loss: 1158.8383\n",
      "Epoch 1231/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.3703 - val_loss: 1050.3920\n",
      "Epoch 1232/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.7917 - val_loss: 898.6459\n",
      "Epoch 1233/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.0604 - val_loss: 481.9667\n",
      "Epoch 1234/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 136.7560 - val_loss: 1043.2295\n",
      "Epoch 1235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.3939 - val_loss: 1292.7128\n",
      "Epoch 1236/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.8177 - val_loss: 1170.8893\n",
      "Epoch 1237/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.5753 - val_loss: 1163.8062\n",
      "Epoch 1238/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.7765 - val_loss: 1161.7114\n",
      "Epoch 1239/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.7746 - val_loss: 1018.8534\n",
      "Epoch 1240/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 98.4018 - val_loss: 1054.4489\n",
      "Epoch 1241/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.5631 - val_loss: 1156.1173\n",
      "Epoch 1242/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.6203 - val_loss: 1235.5966\n",
      "Epoch 1243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.8997 - val_loss: 1232.7080\n",
      "Epoch 1244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.4823 - val_loss: 1009.6275\n",
      "Epoch 1245/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.4925 - val_loss: 1168.4265\n",
      "Epoch 1246/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.3600 - val_loss: 964.8827\n",
      "Epoch 1247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 115.2776 - val_loss: 1184.9141\n",
      "Epoch 1248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.7134 - val_loss: 1159.5833\n",
      "Epoch 1249/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.6785 - val_loss: 942.4741\n",
      "Epoch 1250/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.5109 - val_loss: 1129.5674\n",
      "Epoch 1251/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.6941 - val_loss: 1363.2672\n",
      "Epoch 1252/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.9313 - val_loss: 1241.5066\n",
      "Epoch 1253/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.3059 - val_loss: 1048.2000\n",
      "Epoch 1254/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.6837 - val_loss: 1057.6317\n",
      "Epoch 1255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.7674 - val_loss: 1131.3221\n",
      "Epoch 1256/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.7427 - val_loss: 843.5084\n",
      "Epoch 1257/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.6408 - val_loss: 912.5048\n",
      "Epoch 1258/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.0452 - val_loss: 1144.3217\n",
      "Epoch 1259/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.2604 - val_loss: 1085.3749\n",
      "Epoch 1260/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.8938 - val_loss: 1128.2017\n",
      "Epoch 1261/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.7490 - val_loss: 1074.7443\n",
      "Epoch 1262/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.4146 - val_loss: 1118.1212\n",
      "Epoch 1263/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.2446 - val_loss: 1098.9849\n",
      "Epoch 1264/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78.4449 - val_loss: 741.1800\n",
      "Epoch 1265/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.9853 - val_loss: 867.5161\n",
      "Epoch 1266/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.5729 - val_loss: 1297.0780\n",
      "Epoch 1267/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.0417 - val_loss: 954.4383\n",
      "Epoch 1268/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.4073 - val_loss: 1088.8250\n",
      "Epoch 1269/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.0240 - val_loss: 1231.6552\n",
      "Epoch 1270/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.0116 - val_loss: 1315.1007\n",
      "Epoch 1271/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.9051 - val_loss: 943.4449\n",
      "Epoch 1272/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.8779 - val_loss: 1134.6013\n",
      "Epoch 1273/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.0688 - val_loss: 1059.4807\n",
      "Epoch 1274/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.6568 - val_loss: 1045.8676\n",
      "Epoch 1275/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.9807 - val_loss: 1122.1332\n",
      "Epoch 1276/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.1819 - val_loss: 1130.7302\n",
      "Epoch 1277/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.4456 - val_loss: 1194.3594\n",
      "Epoch 1278/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.7276 - val_loss: 1344.8767\n",
      "Epoch 1279/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.9226 - val_loss: 1321.4406\n",
      "Epoch 1280/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.1703 - val_loss: 1091.3716\n",
      "Epoch 1281/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.1929 - val_loss: 1222.8741\n",
      "Epoch 1282/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.3511 - val_loss: 1206.8422\n",
      "Epoch 1283/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.6043 - val_loss: 1271.2433\n",
      "Epoch 1284/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.0852 - val_loss: 1061.3645\n",
      "Epoch 1285/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.4404 - val_loss: 1210.8877\n",
      "Epoch 1286/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.7676 - val_loss: 1120.1804\n",
      "Epoch 1287/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.9106 - val_loss: 1210.7776\n",
      "Epoch 1288/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.2598 - val_loss: 1212.4609\n",
      "Epoch 1289/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.1642 - val_loss: 1081.2189\n",
      "Epoch 1290/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.5290 - val_loss: 850.2589\n",
      "Epoch 1291/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.6626 - val_loss: 768.8459\n",
      "Epoch 1292/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 116.0180 - val_loss: 1260.0763\n",
      "Epoch 1293/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.3016 - val_loss: 1113.3384\n",
      "Epoch 1294/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.7002 - val_loss: 900.3110\n",
      "Epoch 1295/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.9496 - val_loss: 899.9545\n",
      "Epoch 1296/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.9813 - val_loss: 883.0995\n",
      "Epoch 1297/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.8547 - val_loss: 971.8713\n",
      "Epoch 1298/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.6879 - val_loss: 738.2620\n",
      "Epoch 1299/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.6732 - val_loss: 748.9724\n",
      "Epoch 1300/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.2238 - val_loss: 857.8027\n",
      "Epoch 1301/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.7257 - val_loss: 1117.5940\n",
      "Epoch 1302/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.6911 - val_loss: 716.2612\n",
      "Epoch 1303/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.1962 - val_loss: 1193.0917\n",
      "Epoch 1304/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.9464 - val_loss: 814.9003\n",
      "Epoch 1305/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.7032 - val_loss: 977.6171\n",
      "Epoch 1306/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.5734 - val_loss: 817.2028\n",
      "Epoch 1307/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.7269 - val_loss: 886.7789\n",
      "Epoch 1308/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.0869 - val_loss: 1035.1276\n",
      "Epoch 1309/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.9428 - val_loss: 795.4138\n",
      "Epoch 1310/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.4141 - val_loss: 823.9445\n",
      "Epoch 1311/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.8580 - val_loss: 895.5142\n",
      "Epoch 1312/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78.2809 - val_loss: 661.7055\n",
      "Epoch 1313/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.5231 - val_loss: 800.6600\n",
      "Epoch 1314/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.8042 - val_loss: 1059.5729\n",
      "Epoch 1315/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.0406 - val_loss: 1064.4268\n",
      "Epoch 1316/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.3045 - val_loss: 856.0573\n",
      "Epoch 1317/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 95.7877 - val_loss: 726.4137\n",
      "Epoch 1318/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 122.1149 - val_loss: 920.8687\n",
      "Epoch 1319/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.9065 - val_loss: 768.0355\n",
      "Epoch 1320/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.6276 - val_loss: 718.8338\n",
      "Epoch 1321/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.8962 - val_loss: 713.6875\n",
      "Epoch 1322/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.3961 - val_loss: 874.5467\n",
      "Epoch 1323/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 125.7652 - val_loss: 936.6619\n",
      "Epoch 1324/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 149.2570 - val_loss: 512.2734\n",
      "Epoch 1325/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.9167 - val_loss: 951.2847\n",
      "Epoch 1326/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.8038 - val_loss: 815.4354\n",
      "Epoch 1327/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.1215 - val_loss: 953.1271\n",
      "Epoch 1328/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.7513 - val_loss: 704.7820\n",
      "Epoch 1329/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.4855 - val_loss: 862.4288\n",
      "Epoch 1330/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.0140 - val_loss: 758.0396\n",
      "Epoch 1331/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.7969 - val_loss: 953.3647\n",
      "Epoch 1332/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.3455 - val_loss: 828.4259\n",
      "Epoch 1333/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.3246 - val_loss: 714.2448\n",
      "Epoch 1334/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.9171 - val_loss: 981.0258\n",
      "Epoch 1335/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.9304 - val_loss: 844.1524\n",
      "Epoch 1336/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.0310 - val_loss: 997.5770\n",
      "Epoch 1337/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.0339 - val_loss: 1050.8680\n",
      "Epoch 1338/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 133.0877 - val_loss: 1242.6498\n",
      "Epoch 1339/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 191.4959 - val_loss: 342.5179\n",
      "Epoch 1340/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 183.3554 - val_loss: 154.9104\n",
      "Epoch 1341/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 170.3510 - val_loss: 652.9000\n",
      "Epoch 1342/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 141.8836 - val_loss: 596.0063\n",
      "Epoch 1343/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 154.6956 - val_loss: 665.6899\n",
      "Epoch 1344/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 124.5357 - val_loss: 631.8302\n",
      "Epoch 1345/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.7006 - val_loss: 660.0092\n",
      "Epoch 1346/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.1173 - val_loss: 521.6852\n",
      "Epoch 1347/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.5637 - val_loss: 952.3227\n",
      "Epoch 1348/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.4442 - val_loss: 864.8333\n",
      "Epoch 1349/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.8728 - val_loss: 844.7133\n",
      "Epoch 1350/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 112.7241 - val_loss: 844.8721\n",
      "Epoch 1351/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.1668 - val_loss: 820.4722\n",
      "Epoch 1352/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.2302 - val_loss: 738.3912\n",
      "Epoch 1353/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.8688 - val_loss: 671.7901\n",
      "Epoch 1354/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.9167 - val_loss: 803.2344\n",
      "Epoch 1355/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.4310 - val_loss: 1013.8619\n",
      "Epoch 1356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.1678 - val_loss: 899.0953\n",
      "Epoch 1357/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.1025 - val_loss: 786.2365\n",
      "Epoch 1358/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.7630 - val_loss: 668.1960\n",
      "Epoch 1359/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.8366 - val_loss: 826.1668\n",
      "Epoch 1360/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.5780 - val_loss: 909.7567\n",
      "Epoch 1361/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.5926 - val_loss: 831.9455\n",
      "Epoch 1362/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.7078 - val_loss: 741.5114\n",
      "Epoch 1363/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.8593 - val_loss: 771.2490\n",
      "Epoch 1364/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.8251 - val_loss: 875.0078\n",
      "Epoch 1365/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.5584 - val_loss: 847.5635\n",
      "Epoch 1366/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 134.0305 - val_loss: 816.9916\n",
      "Epoch 1367/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.3576 - val_loss: 1062.0378\n",
      "Epoch 1368/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 128.9580 - val_loss: 779.9641\n",
      "Epoch 1369/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.2175 - val_loss: 301.6980\n",
      "Epoch 1370/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 199.3966 - val_loss: 1784.3767\n",
      "Epoch 1371/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 167.9440 - val_loss: 731.6697\n",
      "Epoch 1372/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.9385 - val_loss: 605.7559\n",
      "Epoch 1373/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 140.2740 - val_loss: 461.8520\n",
      "Epoch 1374/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.8767 - val_loss: 287.9670\n",
      "Epoch 1375/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.3619 - val_loss: 736.8535\n",
      "Epoch 1376/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.4416 - val_loss: 739.8215\n",
      "Epoch 1377/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.3458 - val_loss: 615.8950\n",
      "Epoch 1378/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.7453 - val_loss: 588.9837\n",
      "Epoch 1379/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.3768 - val_loss: 907.9409\n",
      "Epoch 1380/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.6944 - val_loss: 656.4869\n",
      "Epoch 1381/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.6850 - val_loss: 645.2448\n",
      "Epoch 1382/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.7458 - val_loss: 848.9913\n",
      "Epoch 1383/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 115.8599 - val_loss: 626.7524\n",
      "Epoch 1384/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.5675 - val_loss: 634.9491\n",
      "Epoch 1385/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.0966 - val_loss: 845.0012\n",
      "Epoch 1386/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.5051 - val_loss: 757.9203\n",
      "Epoch 1387/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.5410 - val_loss: 968.0181\n",
      "Epoch 1388/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.7572 - val_loss: 820.1622\n",
      "Epoch 1389/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.3071 - val_loss: 755.0224\n",
      "Epoch 1390/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.2091 - val_loss: 892.1752\n",
      "Epoch 1391/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.8236 - val_loss: 668.1294\n",
      "Epoch 1392/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 114.4336 - val_loss: 917.1324\n",
      "Epoch 1393/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.0121 - val_loss: 606.1498\n",
      "Epoch 1394/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 99.8595 - val_loss: 769.1856\n",
      "Epoch 1395/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.6349 - val_loss: 775.5244\n",
      "Epoch 1396/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 118.9334 - val_loss: 884.4700\n",
      "Epoch 1397/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 96.1584 - val_loss: 778.4645\n",
      "Epoch 1398/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.0768 - val_loss: 719.0807\n",
      "Epoch 1399/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.6988 - val_loss: 846.8459\n",
      "Epoch 1400/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 115.3686 - val_loss: 563.5644\n",
      "Epoch 1401/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.8798 - val_loss: 705.4351\n",
      "Epoch 1402/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.1491 - val_loss: 974.5199\n",
      "Epoch 1403/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 127.7204 - val_loss: 808.1332\n",
      "Epoch 1404/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.7447 - val_loss: 619.6729\n",
      "Epoch 1405/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.2563 - val_loss: 609.9302\n",
      "Epoch 1406/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.5517 - val_loss: 441.4625\n",
      "Epoch 1407/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.9881 - val_loss: 727.6340\n",
      "Epoch 1408/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.9908 - val_loss: 712.4769\n",
      "Epoch 1409/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.4352 - val_loss: 480.3677\n",
      "Epoch 1410/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.4354 - val_loss: 814.8922\n",
      "Epoch 1411/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.0195 - val_loss: 765.0111\n",
      "Epoch 1412/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.4516 - val_loss: 710.5499\n",
      "Epoch 1413/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 112.2799 - val_loss: 617.0029\n",
      "Epoch 1414/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.5369 - val_loss: 919.4917\n",
      "Epoch 1415/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.7342 - val_loss: 791.9919\n",
      "Epoch 1416/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.8163 - val_loss: 672.3708\n",
      "Epoch 1417/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.4890 - val_loss: 802.8940\n",
      "Epoch 1418/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.3064 - val_loss: 737.1235\n",
      "Epoch 1419/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.4187 - val_loss: 699.2846\n",
      "Epoch 1420/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.7886 - val_loss: 681.5535\n",
      "Epoch 1421/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.5456 - val_loss: 710.6415\n",
      "Epoch 1422/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.7238 - val_loss: 671.1138\n",
      "Epoch 1423/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.6404 - val_loss: 676.6650\n",
      "Epoch 1424/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.1554 - val_loss: 765.4149\n",
      "Epoch 1425/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.6059 - val_loss: 816.0931\n",
      "Epoch 1426/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.6266 - val_loss: 714.5120\n",
      "Epoch 1427/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.2282 - val_loss: 731.6724\n",
      "Epoch 1428/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.0304 - val_loss: 611.3306\n",
      "Epoch 1429/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.1303 - val_loss: 601.0423\n",
      "Epoch 1430/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.9498 - val_loss: 750.7847\n",
      "Epoch 1431/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 112.4473 - val_loss: 709.8726\n",
      "Epoch 1432/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.3800 - val_loss: 721.3508\n",
      "Epoch 1433/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 106.6306 - val_loss: 664.1915\n",
      "Epoch 1434/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.3739 - val_loss: 672.7601\n",
      "Epoch 1435/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.0176 - val_loss: 686.3198\n",
      "Epoch 1436/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 123.5894 - val_loss: 749.4044\n",
      "Epoch 1437/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.8679 - val_loss: 644.2856\n",
      "Epoch 1438/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.6304 - val_loss: 662.0657\n",
      "Epoch 1439/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.2376 - val_loss: 729.5229\n",
      "Epoch 1440/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.8129 - val_loss: 700.4656\n",
      "Epoch 1441/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.7281 - val_loss: 634.8630\n",
      "Epoch 1442/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.2556 - val_loss: 624.1064\n",
      "Epoch 1443/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.5112 - val_loss: 660.8635\n",
      "Epoch 1444/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.2730 - val_loss: 662.5662\n",
      "Epoch 1445/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.4059 - val_loss: 679.8190\n",
      "Epoch 1446/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.0855 - val_loss: 704.6901\n",
      "Epoch 1447/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.1075 - val_loss: 295.5533\n",
      "Epoch 1448/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.0312 - val_loss: 692.9253\n",
      "Epoch 1449/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.9164 - val_loss: 735.9518\n",
      "Epoch 1450/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 88.3082 - val_loss: 746.2761\n",
      "Epoch 1451/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.7146 - val_loss: 628.6771\n",
      "Epoch 1452/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.9056 - val_loss: 538.0923\n",
      "Epoch 1453/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.3056 - val_loss: 499.7425\n",
      "Epoch 1454/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.4281 - val_loss: 534.6441\n",
      "Epoch 1455/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 95.9222 - val_loss: 634.0482\n",
      "Epoch 1456/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.5403 - val_loss: 657.0298\n",
      "Epoch 1457/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.7920 - val_loss: 649.2249\n",
      "Epoch 1458/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.9917 - val_loss: 700.6785\n",
      "Epoch 1459/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.2203 - val_loss: 804.8183\n",
      "Epoch 1460/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.3108 - val_loss: 791.5833\n",
      "Epoch 1461/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 98.2576 - val_loss: 701.2730\n",
      "Epoch 1462/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.9838 - val_loss: 778.4228\n",
      "Epoch 1463/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.8088 - val_loss: 596.7328\n",
      "Epoch 1464/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.1954 - val_loss: 630.5975\n",
      "Epoch 1465/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.0526 - val_loss: 875.1766\n",
      "Epoch 1466/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.2417 - val_loss: 629.3866\n",
      "Epoch 1467/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.1986 - val_loss: 651.3916\n",
      "Epoch 1468/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.0084 - val_loss: 611.9333\n",
      "Epoch 1469/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.9039 - val_loss: 623.1320\n",
      "Epoch 1470/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.8981 - val_loss: 651.1440\n",
      "Epoch 1471/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.6688 - val_loss: 709.1230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1472/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101.3384 - val_loss: 689.4987\n",
      "Epoch 1473/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.2829 - val_loss: 607.4863\n",
      "Epoch 1474/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.5547 - val_loss: 527.0098\n",
      "Epoch 1475/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.0100 - val_loss: 629.0407\n",
      "Epoch 1476/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.2792 - val_loss: 683.0461\n",
      "Epoch 1477/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.7997 - val_loss: 515.6087\n",
      "Epoch 1478/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.8998 - val_loss: 604.8318\n",
      "Epoch 1479/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.6251 - val_loss: 676.1104\n",
      "Epoch 1480/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.7273 - val_loss: 636.0974\n",
      "Epoch 1481/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.6708 - val_loss: 667.3218\n",
      "Epoch 1482/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.6059 - val_loss: 574.8080\n",
      "Epoch 1483/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.2564 - val_loss: 749.9697\n",
      "Epoch 1484/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.1610 - val_loss: 625.0616\n",
      "Epoch 1485/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.4037 - val_loss: 544.9191\n",
      "Epoch 1486/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.3694 - val_loss: 504.3174\n",
      "Epoch 1487/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.1171 - val_loss: 740.9289\n",
      "Epoch 1488/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.5972 - val_loss: 737.1362\n",
      "Epoch 1489/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.4855 - val_loss: 560.4927\n",
      "Epoch 1490/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.3011 - val_loss: 536.0309\n",
      "Epoch 1491/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.7369 - val_loss: 678.4109\n",
      "Epoch 1492/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.8845 - val_loss: 613.1512\n",
      "Epoch 1493/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.9533 - val_loss: 565.4870\n",
      "Epoch 1494/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.3933 - val_loss: 578.8268\n",
      "Epoch 1495/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 78.7810 - val_loss: 473.9261\n",
      "Epoch 1496/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.4621 - val_loss: 692.0826\n",
      "Epoch 1497/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.8783 - val_loss: 595.7415\n",
      "Epoch 1498/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.3121 - val_loss: 517.1039\n",
      "Epoch 1499/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.6945 - val_loss: 524.2939\n",
      "Epoch 1500/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.9216 - val_loss: 507.0936\n",
      "Epoch 1501/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.8945 - val_loss: 611.2153\n",
      "Epoch 1502/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.0282 - val_loss: 510.0307\n",
      "Epoch 1503/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 78.8904 - val_loss: 471.9382\n",
      "Epoch 1504/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.4689 - val_loss: 603.9726\n",
      "Epoch 1505/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.4457 - val_loss: 512.2543\n",
      "Epoch 1506/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.2788 - val_loss: 597.7356\n",
      "Epoch 1507/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.3994 - val_loss: 590.3926\n",
      "Epoch 1508/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.7425 - val_loss: 656.5557\n",
      "Epoch 1509/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.7280 - val_loss: 587.5308\n",
      "Epoch 1510/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.1772 - val_loss: 610.5226\n",
      "Epoch 1511/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.2879 - val_loss: 679.8681\n",
      "Epoch 1512/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 89.4546 - val_loss: 495.4416\n",
      "Epoch 1513/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 85.6822 - val_loss: 659.9980\n",
      "Epoch 1514/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 74.3890 - val_loss: 689.5836\n",
      "Epoch 1515/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.5836 - val_loss: 546.1940\n",
      "Epoch 1516/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 77.7351 - val_loss: 663.1518\n",
      "Epoch 1517/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.7535 - val_loss: 589.9337\n",
      "Epoch 1518/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.7742 - val_loss: 595.1398\n",
      "Epoch 1519/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.1822 - val_loss: 579.5445\n",
      "Epoch 1520/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.1242 - val_loss: 682.0095\n",
      "Epoch 1521/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.9707 - val_loss: 574.9468\n",
      "Epoch 1522/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.7032 - val_loss: 650.6756\n",
      "Epoch 1523/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 76.9870 - val_loss: 798.4189\n",
      "Epoch 1524/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.5877 - val_loss: 688.8047\n",
      "Epoch 1525/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.7286 - val_loss: 849.7289\n",
      "Epoch 1526/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.4289 - val_loss: 742.3450\n",
      "Epoch 1527/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.2921 - val_loss: 718.3969\n",
      "Epoch 1528/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.9949 - val_loss: 707.3066\n",
      "Epoch 1529/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78.7942 - val_loss: 598.7170\n",
      "Epoch 1530/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.6170 - val_loss: 594.5873\n",
      "Epoch 1531/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.1250 - val_loss: 781.3606\n",
      "Epoch 1532/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.2963 - val_loss: 669.8718\n",
      "Epoch 1533/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 84.3086 - val_loss: 450.6110\n",
      "Epoch 1534/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.7952 - val_loss: 803.8412\n",
      "Epoch 1535/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.5035 - val_loss: 620.1328\n",
      "Epoch 1536/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.4861 - val_loss: 632.3374\n",
      "Epoch 1537/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.1062 - val_loss: 696.2160\n",
      "Epoch 1538/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.6562 - val_loss: 745.0934\n",
      "Epoch 1539/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.8630 - val_loss: 659.8985\n",
      "Epoch 1540/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.7779 - val_loss: 684.0209\n",
      "Epoch 1541/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.3363 - val_loss: 752.4988\n",
      "Epoch 1542/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.0471 - val_loss: 714.5781\n",
      "Epoch 1543/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.5074 - val_loss: 719.4630\n",
      "Epoch 1544/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 78.0633 - val_loss: 561.7940\n",
      "Epoch 1545/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.5355 - val_loss: 580.1702\n",
      "Epoch 1546/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.6523 - val_loss: 544.4152\n",
      "Epoch 1547/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.5684 - val_loss: 719.9878\n",
      "Epoch 1548/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.9506 - val_loss: 730.1097\n",
      "Epoch 1549/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.6188 - val_loss: 563.1860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1550/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.5454 - val_loss: 723.6198\n",
      "Epoch 1551/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.8867 - val_loss: 706.6091\n",
      "Epoch 1552/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.3716 - val_loss: 416.7684\n",
      "Epoch 1553/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.2281 - val_loss: 558.3892\n",
      "Epoch 1554/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.0844 - val_loss: 862.8246\n",
      "Epoch 1555/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.1352 - val_loss: 670.3320\n",
      "Epoch 1556/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.2701 - val_loss: 677.6365\n",
      "Epoch 1557/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.3792 - val_loss: 742.5878\n",
      "Epoch 1558/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.2591 - val_loss: 686.8889\n",
      "Epoch 1559/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 88.5239 - val_loss: 651.6855\n",
      "Epoch 1560/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.5357 - val_loss: 605.8348\n",
      "Epoch 1561/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.7791 - val_loss: 722.1655\n",
      "Epoch 1562/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 94.0872 - val_loss: 675.7631\n",
      "Epoch 1563/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.1662 - val_loss: 659.4540\n",
      "Epoch 1564/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.4148 - val_loss: 585.5898\n",
      "Epoch 1565/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.4230 - val_loss: 517.4786\n",
      "Epoch 1566/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.4530 - val_loss: 641.8857\n",
      "Epoch 1567/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.5974 - val_loss: 614.8586\n",
      "Epoch 1568/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.0842 - val_loss: 605.3087\n",
      "Epoch 1569/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.8639 - val_loss: 617.8489\n",
      "Epoch 1570/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.1014 - val_loss: 655.8349\n",
      "Epoch 1571/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 91.5504 - val_loss: 558.3386\n",
      "Epoch 1572/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.5203 - val_loss: 711.1167\n",
      "Epoch 1573/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 92.0580 - val_loss: 679.0256\n",
      "Epoch 1574/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.2702 - val_loss: 552.4279\n",
      "Epoch 1575/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.1351 - val_loss: 590.3813\n",
      "Epoch 1576/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.8933 - val_loss: 608.6182\n",
      "Epoch 1577/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78.6074 - val_loss: 614.5531\n",
      "Epoch 1578/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.9716 - val_loss: 531.1788\n",
      "Epoch 1579/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.0669 - val_loss: 593.0043\n",
      "Epoch 1580/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.4086 - val_loss: 527.3237\n",
      "Epoch 1581/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.3168 - val_loss: 610.3614\n",
      "Epoch 1582/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.7474 - val_loss: 580.7289\n",
      "Epoch 1583/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90.4022 - val_loss: 690.1587\n",
      "Epoch 1584/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.1116 - val_loss: 608.8990\n",
      "Epoch 1585/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 76.8223 - val_loss: 584.6131\n",
      "Epoch 1586/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 93.1739 - val_loss: 560.4968\n",
      "Epoch 1587/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78.2704 - val_loss: 597.7687\n",
      "Epoch 1588/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.4604 - val_loss: 663.4056\n",
      "Epoch 1589/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 87.4290 - val_loss: 676.9229\n",
      "Epoch 1590/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.5547 - val_loss: 598.2156\n",
      "Epoch 1591/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.1298 - val_loss: 714.3306\n",
      "Epoch 1592/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.1715 - val_loss: 611.9426\n",
      "Epoch 1593/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.3135 - val_loss: 628.1057\n",
      "Epoch 1594/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.7626 - val_loss: 578.6163\n",
      "Epoch 1595/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.8666 - val_loss: 684.6964\n",
      "Epoch 1596/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.2456 - val_loss: 467.0963\n",
      "Epoch 1597/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.3838 - val_loss: 571.7266\n",
      "Epoch 1598/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.6515 - val_loss: 640.0285\n",
      "Epoch 1599/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.1901 - val_loss: 625.3878\n",
      "Epoch 1600/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 80.9206 - val_loss: 559.8638\n",
      "Epoch 1601/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 82.7291 - val_loss: 640.0769\n",
      "Epoch 1602/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 78.4437 - val_loss: 538.5873\n",
      "Epoch 1603/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 81.2998 - val_loss: 639.8630\n",
      "Epoch 1604/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 44.6180Restoring model weights from the end of the best epoch: 1104.\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 77.2044 - val_loss: 593.6147\n",
      "Epoch 1604: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>30.988646</td>\n",
       "      <td>30.32295</td>\n",
       "      <td>29.478382</td>\n",
       "      <td>29.357288</td>\n",
       "      <td>29.070728</td>\n",
       "      <td>28.560095</td>\n",
       "      <td>28.073397</td>\n",
       "      <td>27.984396</td>\n",
       "      <td>27.941139</td>\n",
       "      <td>27.884312</td>\n",
       "      <td>27.74082</td>\n",
       "      <td>27.864117</td>\n",
       "      <td>27.601357</td>\n",
       "      <td>27.564171</td>\n",
       "      <td>27.571186</td>\n",
       "      <td>27.599739</td>\n",
       "      <td>27.59071</td>\n",
       "      <td>27.430355</td>\n",
       "      <td>27.42297</td>\n",
       "      <td>27.421303</td>\n",
       "      <td>27.345831</td>\n",
       "      <td>27.334015</td>\n",
       "      <td>27.313591</td>\n",
       "      <td>27.30817</td>\n",
       "      <td>27.282593</td>\n",
       "      <td>27.19289</td>\n",
       "      <td>27.139351</td>\n",
       "      <td>27.033293</td>\n",
       "      <td>26.876877</td>\n",
       "      <td>1.686638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>53.235</td>\n",
       "      <td>59.29</td>\n",
       "      <td>54.875</td>\n",
       "      <td>57.52</td>\n",
       "      <td>49.573</td>\n",
       "      <td>40.698</td>\n",
       "      <td>47.195</td>\n",
       "      <td>43.527</td>\n",
       "      <td>45.488</td>\n",
       "      <td>44.96</td>\n",
       "      <td>36.721</td>\n",
       "      <td>54.463</td>\n",
       "      <td>51.462</td>\n",
       "      <td>58.854</td>\n",
       "      <td>53.94</td>\n",
       "      <td>51.514</td>\n",
       "      <td>42.635</td>\n",
       "      <td>40.371</td>\n",
       "      <td>48.99</td>\n",
       "      <td>44.726</td>\n",
       "      <td>44.491</td>\n",
       "      <td>43.901</td>\n",
       "      <td>55.019</td>\n",
       "      <td>50.942</td>\n",
       "      <td>63.992</td>\n",
       "      <td>64.127</td>\n",
       "      <td>60.822</td>\n",
       "      <td>65.182</td>\n",
       "      <td>51.282</td>\n",
       "      <td>43.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>22.246355</td>\n",
       "      <td>28.967051</td>\n",
       "      <td>25.396618</td>\n",
       "      <td>28.162712</td>\n",
       "      <td>20.502274</td>\n",
       "      <td>12.137907</td>\n",
       "      <td>19.121603</td>\n",
       "      <td>15.542604</td>\n",
       "      <td>17.54686</td>\n",
       "      <td>17.075687</td>\n",
       "      <td>8.980181</td>\n",
       "      <td>26.598885</td>\n",
       "      <td>23.860645</td>\n",
       "      <td>31.289829</td>\n",
       "      <td>26.368813</td>\n",
       "      <td>23.914261</td>\n",
       "      <td>15.044289</td>\n",
       "      <td>12.940643</td>\n",
       "      <td>21.567032</td>\n",
       "      <td>17.304699</td>\n",
       "      <td>17.14517</td>\n",
       "      <td>16.566986</td>\n",
       "      <td>27.70541</td>\n",
       "      <td>23.633831</td>\n",
       "      <td>36.709408</td>\n",
       "      <td>36.934109</td>\n",
       "      <td>33.682648</td>\n",
       "      <td>38.148705</td>\n",
       "      <td>24.405125</td>\n",
       "      <td>41.867363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1          2          3          4          5   \\\n",
       "Month         Month-1    Month-2    Month-3    Month-4    Month-5    Month-6   \n",
       "Prediction  30.988646   30.32295  29.478382  29.357288  29.070728  28.560095   \n",
       "Target         53.235      59.29     54.875      57.52     49.573     40.698   \n",
       "Error       22.246355  28.967051  25.396618  28.162712  20.502274  12.137907   \n",
       "\n",
       "                   6          7          8          9         10         11  \\\n",
       "Month         Month-7    Month-8    Month-9   Month-10  Month-11   Month-12   \n",
       "Prediction  28.073397  27.984396  27.941139  27.884312  27.74082  27.864117   \n",
       "Target         47.195     43.527     45.488      44.96    36.721     54.463   \n",
       "Error       19.121603  15.542604   17.54686  17.075687  8.980181  26.598885   \n",
       "\n",
       "                   12         13         14         15         16         17  \\\n",
       "Month        Month-13   Month-14   Month-15   Month-16   Month-17   Month-18   \n",
       "Prediction  27.601357  27.564171  27.571186  27.599739   27.59071  27.430355   \n",
       "Target         51.462     58.854      53.94     51.514     42.635     40.371   \n",
       "Error       23.860645  31.289829  26.368813  23.914261  15.044289  12.940643   \n",
       "\n",
       "                   18         19         20         21         22         23  \\\n",
       "Month        Month-19   Month-20   Month-21   Month-22   Month-23   Month-24   \n",
       "Prediction   27.42297  27.421303  27.345831  27.334015  27.313591   27.30817   \n",
       "Target          48.99     44.726     44.491     43.901     55.019     50.942   \n",
       "Error       21.567032  17.304699   17.14517  16.566986   27.70541  23.633831   \n",
       "\n",
       "                   24         25         26         27         28         29  \n",
       "Month        Month-25   Month-26   Month-27   Month-28   Month-29   Month-30  \n",
       "Prediction  27.282593   27.19289  27.139351  27.033293  26.876877   1.686638  \n",
       "Target         63.992     64.127     60.822     65.182     51.282     43.554  \n",
       "Error       36.709408  36.934109  33.682648  38.148705  24.405125  41.867363  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.712257"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.45788085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[345.26624]] - Target[587.5449999999998]| =  Error: [[242.27875]]; MAPE:[[0.41235778]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Ano-0: |Prediction[[329.5034]] - Target[586.845]| =  Error: [[257.34158]]; MAPE:[[0.43851715]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Ano-5: |Prediction[[137.21164]] - Target[348.95899999999995]| =  Error: [[211.74738]]; MAPE:[[0.6067973]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[242.27875]], dtype=float32),\n",
       " array([[257.34158]], dtype=float32),\n",
       " array([[211.74738]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "237.12256"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.48589072"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
