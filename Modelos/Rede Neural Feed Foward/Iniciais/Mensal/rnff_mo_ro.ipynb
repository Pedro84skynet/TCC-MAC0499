{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Rondônia - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rondônia - Produção de Cimento (t)</th>\n",
       "      <th>Rondônia - IDH</th>\n",
       "      <th>Rondônia - PIB - Estadual</th>\n",
       "      <th>Rondônia - PIB - Construção Civil</th>\n",
       "      <th>Rondônia - PIB - Per Capita</th>\n",
       "      <th>Rondônia - PIB - Preços de Mercado</th>\n",
       "      <th>Rondônia - Desemprego</th>\n",
       "      <th>Rondônia - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>4.987000</td>\n",
       "      <td>0.688843</td>\n",
       "      <td>2.068350e+07</td>\n",
       "      <td>1.587672e+06</td>\n",
       "      <td>11.468162</td>\n",
       "      <td>1.828350e+07</td>\n",
       "      <td>8.226062</td>\n",
       "      <td>13.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>4.987000</td>\n",
       "      <td>0.689031</td>\n",
       "      <td>2.071062e+07</td>\n",
       "      <td>1.589518e+06</td>\n",
       "      <td>11.472453</td>\n",
       "      <td>1.829323e+07</td>\n",
       "      <td>8.219943</td>\n",
       "      <td>10.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>4.987000</td>\n",
       "      <td>0.689218</td>\n",
       "      <td>2.073774e+07</td>\n",
       "      <td>1.591364e+06</td>\n",
       "      <td>11.476744</td>\n",
       "      <td>1.830296e+07</td>\n",
       "      <td>8.213823</td>\n",
       "      <td>13.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>4.987000</td>\n",
       "      <td>0.689405</td>\n",
       "      <td>2.076486e+07</td>\n",
       "      <td>1.593210e+06</td>\n",
       "      <td>11.481034</td>\n",
       "      <td>1.831268e+07</td>\n",
       "      <td>8.207703</td>\n",
       "      <td>11.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>4.987000</td>\n",
       "      <td>0.689592</td>\n",
       "      <td>2.079198e+07</td>\n",
       "      <td>1.595056e+06</td>\n",
       "      <td>11.485325</td>\n",
       "      <td>1.832241e+07</td>\n",
       "      <td>8.201584</td>\n",
       "      <td>14.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.931530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.812259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.687985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.551024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.555289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0       2003-1                                          0.724032   \n",
       "1       2003-2                                          0.690297   \n",
       "2       2003-3                                          0.669681   \n",
       "3       2003-4                                          0.660494   \n",
       "4       2003-5                                          0.648337   \n",
       "..         ...                                               ...   \n",
       "235     2022-8                                               NaN   \n",
       "236     2022-9                                               NaN   \n",
       "237    2022-10                                               NaN   \n",
       "238    2022-11                                               NaN   \n",
       "239    2022-12                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     Rondônia - Produção de Cimento (t)  Rondônia - IDH  \\\n",
       "0                              4.987000        0.688843   \n",
       "1                              4.987000        0.689031   \n",
       "2                              4.987000        0.689218   \n",
       "3                              4.987000        0.689405   \n",
       "4                              4.987000        0.689592   \n",
       "..                                  ...             ...   \n",
       "235                           20.931530             NaN   \n",
       "236                           20.812259             NaN   \n",
       "237                           20.687985             NaN   \n",
       "238                           20.551024             NaN   \n",
       "239                           20.555289             NaN   \n",
       "\n",
       "     Rondônia - PIB - Estadual  Rondônia - PIB - Construção Civil  \\\n",
       "0                 2.068350e+07                       1.587672e+06   \n",
       "1                 2.071062e+07                       1.589518e+06   \n",
       "2                 2.073774e+07                       1.591364e+06   \n",
       "3                 2.076486e+07                       1.593210e+06   \n",
       "4                 2.079198e+07                       1.595056e+06   \n",
       "..                         ...                                ...   \n",
       "235                        NaN                                NaN   \n",
       "236                        NaN                                NaN   \n",
       "237                        NaN                                NaN   \n",
       "238                        NaN                                NaN   \n",
       "239                        NaN                                NaN   \n",
       "\n",
       "     Rondônia - PIB - Per Capita  Rondônia - PIB - Preços de Mercado  \\\n",
       "0                      11.468162                        1.828350e+07   \n",
       "1                      11.472453                        1.829323e+07   \n",
       "2                      11.476744                        1.830296e+07   \n",
       "3                      11.481034                        1.831268e+07   \n",
       "4                      11.485325                        1.832241e+07   \n",
       "..                           ...                                 ...   \n",
       "235                          NaN                                 NaN   \n",
       "236                          NaN                                 NaN   \n",
       "237                          NaN                                 NaN   \n",
       "238                          NaN                                 NaN   \n",
       "239                          NaN                                 NaN   \n",
       "\n",
       "     Rondônia - Desemprego  Rondônia - Consumo de Cimento (t)  \n",
       "0                 8.226062                             13.867  \n",
       "1                 8.219943                             10.777  \n",
       "2                 8.213823                             13.888  \n",
       "3                 8.207703                             11.859  \n",
       "4                 8.201584                             14.431  \n",
       "..                     ...                                ...  \n",
       "235                    NaN                             49.066  \n",
       "236                    NaN                             49.850  \n",
       "237                    NaN                             43.733  \n",
       "238                    NaN                             40.078  \n",
       "239                    NaN                             40.078  \n",
       "\n",
       "[240 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_RO.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rondônia - Produção de Cimento (t)</th>\n",
       "      <th>Rondônia - IDH</th>\n",
       "      <th>Rondônia - PIB - Estadual</th>\n",
       "      <th>Rondônia - PIB - Construção Civil</th>\n",
       "      <th>Rondônia - PIB - Per Capita</th>\n",
       "      <th>Rondônia - PIB - Preços de Mercado</th>\n",
       "      <th>Rondônia - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.115226</td>\n",
       "      <td>-1.859790</td>\n",
       "      <td>-1.684237</td>\n",
       "      <td>0.358666</td>\n",
       "      <td>-2.401614</td>\n",
       "      <td>-1.935575</td>\n",
       "      <td>1.247042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.115226</td>\n",
       "      <td>-1.835964</td>\n",
       "      <td>-1.666360</td>\n",
       "      <td>0.383576</td>\n",
       "      <td>-2.358981</td>\n",
       "      <td>-1.906624</td>\n",
       "      <td>1.233793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.115226</td>\n",
       "      <td>-1.812139</td>\n",
       "      <td>-1.648484</td>\n",
       "      <td>0.408485</td>\n",
       "      <td>-2.316347</td>\n",
       "      <td>-1.877673</td>\n",
       "      <td>1.220544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.115226</td>\n",
       "      <td>-1.788313</td>\n",
       "      <td>-1.630607</td>\n",
       "      <td>0.433395</td>\n",
       "      <td>-2.273714</td>\n",
       "      <td>-1.848722</td>\n",
       "      <td>1.207295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.115226</td>\n",
       "      <td>-1.764487</td>\n",
       "      <td>-1.612730</td>\n",
       "      <td>0.458305</td>\n",
       "      <td>-2.231081</td>\n",
       "      <td>-1.819771</td>\n",
       "      <td>1.194046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-0.247503</td>\n",
       "      <td>1.280168</td>\n",
       "      <td>1.167829</td>\n",
       "      <td>-1.179294</td>\n",
       "      <td>1.068920</td>\n",
       "      <td>1.031159</td>\n",
       "      <td>-1.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>-0.239967</td>\n",
       "      <td>1.265078</td>\n",
       "      <td>1.159325</td>\n",
       "      <td>-1.160375</td>\n",
       "      <td>1.051588</td>\n",
       "      <td>1.020921</td>\n",
       "      <td>-1.291394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>-0.218298</td>\n",
       "      <td>1.249987</td>\n",
       "      <td>1.150821</td>\n",
       "      <td>-1.141456</td>\n",
       "      <td>1.034256</td>\n",
       "      <td>1.010683</td>\n",
       "      <td>-1.318081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-0.219108</td>\n",
       "      <td>1.234897</td>\n",
       "      <td>1.142317</td>\n",
       "      <td>-1.122538</td>\n",
       "      <td>1.016924</td>\n",
       "      <td>1.000446</td>\n",
       "      <td>-1.344769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-0.217594</td>\n",
       "      <td>1.219807</td>\n",
       "      <td>1.133813</td>\n",
       "      <td>-1.103619</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.990208</td>\n",
       "      <td>-1.371457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Rondônia - Produção de Cimento (t)  Rondônia - IDH  \\\n",
       "0                             -1.115226       -1.859790   \n",
       "1                             -1.115226       -1.835964   \n",
       "2                             -1.115226       -1.812139   \n",
       "3                             -1.115226       -1.788313   \n",
       "4                             -1.115226       -1.764487   \n",
       "..                                  ...             ...   \n",
       "187                           -0.247503        1.280168   \n",
       "188                           -0.239967        1.265078   \n",
       "189                           -0.218298        1.249987   \n",
       "190                           -0.219108        1.234897   \n",
       "191                           -0.217594        1.219807   \n",
       "\n",
       "     Rondônia - PIB - Estadual  Rondônia - PIB - Construção Civil  \\\n",
       "0                    -1.684237                           0.358666   \n",
       "1                    -1.666360                           0.383576   \n",
       "2                    -1.648484                           0.408485   \n",
       "3                    -1.630607                           0.433395   \n",
       "4                    -1.612730                           0.458305   \n",
       "..                         ...                                ...   \n",
       "187                   1.167829                          -1.179294   \n",
       "188                   1.159325                          -1.160375   \n",
       "189                   1.150821                          -1.141456   \n",
       "190                   1.142317                          -1.122538   \n",
       "191                   1.133813                          -1.103619   \n",
       "\n",
       "     Rondônia - PIB - Per Capita  Rondônia - PIB - Preços de Mercado  \\\n",
       "0                      -2.401614                           -1.935575   \n",
       "1                      -2.358981                           -1.906624   \n",
       "2                      -2.316347                           -1.877673   \n",
       "3                      -2.273714                           -1.848722   \n",
       "4                      -2.231081                           -1.819771   \n",
       "..                           ...                                 ...   \n",
       "187                     1.068920                            1.031159   \n",
       "188                     1.051588                            1.020921   \n",
       "189                     1.034256                            1.010683   \n",
       "190                     1.016924                            1.000446   \n",
       "191                     0.999592                            0.990208   \n",
       "\n",
       "     Rondônia - Desemprego  \n",
       "0                 1.247042  \n",
       "1                 1.233793  \n",
       "2                 1.220544  \n",
       "3                 1.207295  \n",
       "4                 1.194046  \n",
       "..                     ...  \n",
       "187              -1.264706  \n",
       "188              -1.291394  \n",
       "189              -1.318081  \n",
       "190              -1.344769  \n",
       "191              -1.371457  \n",
       "\n",
       "[192 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      13.420\n",
       "1      11.302\n",
       "2      16.993\n",
       "3      16.214\n",
       "4      15.406\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Rondônia - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rondônia - Produção de Cimento (t)</th>\n",
       "      <th>Rondônia - IDH</th>\n",
       "      <th>Rondônia - PIB - Estadual</th>\n",
       "      <th>Rondônia - PIB - Construção Civil</th>\n",
       "      <th>Rondônia - PIB - Per Capita</th>\n",
       "      <th>Rondônia - PIB - Preços de Mercado</th>\n",
       "      <th>Rondônia - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.115226</td>\n",
       "      <td>-1.859790</td>\n",
       "      <td>-1.684237</td>\n",
       "      <td>0.358666</td>\n",
       "      <td>-2.401614</td>\n",
       "      <td>-1.935575</td>\n",
       "      <td>1.247042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.115226</td>\n",
       "      <td>-1.835964</td>\n",
       "      <td>-1.666360</td>\n",
       "      <td>0.383576</td>\n",
       "      <td>-2.358981</td>\n",
       "      <td>-1.906624</td>\n",
       "      <td>1.233793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.115226</td>\n",
       "      <td>-1.812139</td>\n",
       "      <td>-1.648484</td>\n",
       "      <td>0.408485</td>\n",
       "      <td>-2.316347</td>\n",
       "      <td>-1.877673</td>\n",
       "      <td>1.220544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.115226</td>\n",
       "      <td>-1.788313</td>\n",
       "      <td>-1.630607</td>\n",
       "      <td>0.433395</td>\n",
       "      <td>-2.273714</td>\n",
       "      <td>-1.848722</td>\n",
       "      <td>1.207295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.115226</td>\n",
       "      <td>-1.764487</td>\n",
       "      <td>-1.612730</td>\n",
       "      <td>0.458305</td>\n",
       "      <td>-2.231081</td>\n",
       "      <td>-1.819771</td>\n",
       "      <td>1.194046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>-0.087019</td>\n",
       "      <td>1.457304</td>\n",
       "      <td>1.215933</td>\n",
       "      <td>-1.493457</td>\n",
       "      <td>1.031936</td>\n",
       "      <td>1.145432</td>\n",
       "      <td>-0.079052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>-0.105967</td>\n",
       "      <td>1.457217</td>\n",
       "      <td>1.221174</td>\n",
       "      <td>-1.488264</td>\n",
       "      <td>1.051337</td>\n",
       "      <td>1.152213</td>\n",
       "      <td>-0.144286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>-0.124493</td>\n",
       "      <td>1.457130</td>\n",
       "      <td>1.226414</td>\n",
       "      <td>-1.483070</td>\n",
       "      <td>1.070737</td>\n",
       "      <td>1.158994</td>\n",
       "      <td>-0.209519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>-0.140092</td>\n",
       "      <td>1.457044</td>\n",
       "      <td>1.231655</td>\n",
       "      <td>-1.477877</td>\n",
       "      <td>1.090137</td>\n",
       "      <td>1.165775</td>\n",
       "      <td>-0.274753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>-0.146549</td>\n",
       "      <td>1.456957</td>\n",
       "      <td>1.236895</td>\n",
       "      <td>-1.472684</td>\n",
       "      <td>1.109538</td>\n",
       "      <td>1.172556</td>\n",
       "      <td>-0.339986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     Rondônia - Produção de Cimento (t)  Rondônia - IDH  \\\n",
       "0                             -1.115226       -1.859790   \n",
       "1                             -1.115226       -1.835964   \n",
       "2                             -1.115226       -1.812139   \n",
       "3                             -1.115226       -1.788313   \n",
       "4                             -1.115226       -1.764487   \n",
       "..                                  ...             ...   \n",
       "157                           -0.087019        1.457304   \n",
       "158                           -0.105967        1.457217   \n",
       "159                           -0.124493        1.457130   \n",
       "160                           -0.140092        1.457044   \n",
       "161                           -0.146549        1.456957   \n",
       "\n",
       "     Rondônia - PIB - Estadual  Rondônia - PIB - Construção Civil  \\\n",
       "0                    -1.684237                           0.358666   \n",
       "1                    -1.666360                           0.383576   \n",
       "2                    -1.648484                           0.408485   \n",
       "3                    -1.630607                           0.433395   \n",
       "4                    -1.612730                           0.458305   \n",
       "..                         ...                                ...   \n",
       "157                   1.215933                          -1.493457   \n",
       "158                   1.221174                          -1.488264   \n",
       "159                   1.226414                          -1.483070   \n",
       "160                   1.231655                          -1.477877   \n",
       "161                   1.236895                          -1.472684   \n",
       "\n",
       "     Rondônia - PIB - Per Capita  Rondônia - PIB - Preços de Mercado  \\\n",
       "0                      -2.401614                           -1.935575   \n",
       "1                      -2.358981                           -1.906624   \n",
       "2                      -2.316347                           -1.877673   \n",
       "3                      -2.273714                           -1.848722   \n",
       "4                      -2.231081                           -1.819771   \n",
       "..                           ...                                 ...   \n",
       "157                     1.031936                            1.145432   \n",
       "158                     1.051337                            1.152213   \n",
       "159                     1.070737                            1.158994   \n",
       "160                     1.090137                            1.165775   \n",
       "161                     1.109538                            1.172556   \n",
       "\n",
       "     Rondônia - Desemprego  \n",
       "0                 1.247042  \n",
       "1                 1.233793  \n",
       "2                 1.220544  \n",
       "3                 1.207295  \n",
       "4                 1.194046  \n",
       "..                     ...  \n",
       "157              -0.079052  \n",
       "158              -0.144286  \n",
       "159              -0.209519  \n",
       "160              -0.274753  \n",
       "161              -0.339986  \n",
       "\n",
       "[162 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      13.420\n",
       "1      11.302\n",
       "2      16.993\n",
       "3      16.214\n",
       "4      15.406\n",
       "        ...  \n",
       "157    29.662\n",
       "158    31.408\n",
       "159    29.484\n",
       "160    33.601\n",
       "161    36.905\n",
       "Name: Rondônia - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rondônia - Produção de Cimento (t)</th>\n",
       "      <th>Rondônia - IDH</th>\n",
       "      <th>Rondônia - PIB - Estadual</th>\n",
       "      <th>Rondônia - PIB - Construção Civil</th>\n",
       "      <th>Rondônia - PIB - Per Capita</th>\n",
       "      <th>Rondônia - PIB - Preços de Mercado</th>\n",
       "      <th>Rondônia - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>-0.154026</td>\n",
       "      <td>1.456870</td>\n",
       "      <td>1.242136</td>\n",
       "      <td>-1.467490</td>\n",
       "      <td>1.128938</td>\n",
       "      <td>1.179337</td>\n",
       "      <td>-0.405220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>-0.149437</td>\n",
       "      <td>1.456783</td>\n",
       "      <td>1.247376</td>\n",
       "      <td>-1.462297</td>\n",
       "      <td>1.148338</td>\n",
       "      <td>1.186118</td>\n",
       "      <td>-0.470454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>-0.146620</td>\n",
       "      <td>1.456697</td>\n",
       "      <td>1.252617</td>\n",
       "      <td>-1.457104</td>\n",
       "      <td>1.167739</td>\n",
       "      <td>1.192899</td>\n",
       "      <td>-0.535687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>-0.144720</td>\n",
       "      <td>1.456610</td>\n",
       "      <td>1.257857</td>\n",
       "      <td>-1.451910</td>\n",
       "      <td>1.187139</td>\n",
       "      <td>1.199680</td>\n",
       "      <td>-0.600921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>-0.149294</td>\n",
       "      <td>1.456523</td>\n",
       "      <td>1.263098</td>\n",
       "      <td>-1.446717</td>\n",
       "      <td>1.206539</td>\n",
       "      <td>1.206461</td>\n",
       "      <td>-0.666154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>-0.152432</td>\n",
       "      <td>1.456436</td>\n",
       "      <td>1.268338</td>\n",
       "      <td>-1.441524</td>\n",
       "      <td>1.225940</td>\n",
       "      <td>1.213242</td>\n",
       "      <td>-0.731388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>-0.156135</td>\n",
       "      <td>1.456350</td>\n",
       "      <td>1.273579</td>\n",
       "      <td>-1.436331</td>\n",
       "      <td>1.245340</td>\n",
       "      <td>1.220023</td>\n",
       "      <td>-0.796621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>-0.163427</td>\n",
       "      <td>1.450470</td>\n",
       "      <td>1.269727</td>\n",
       "      <td>-1.425947</td>\n",
       "      <td>1.240749</td>\n",
       "      <td>1.210256</td>\n",
       "      <td>-0.820061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>-0.171276</td>\n",
       "      <td>1.444591</td>\n",
       "      <td>1.265875</td>\n",
       "      <td>-1.415563</td>\n",
       "      <td>1.236157</td>\n",
       "      <td>1.200489</td>\n",
       "      <td>-0.843500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>-0.183620</td>\n",
       "      <td>1.438712</td>\n",
       "      <td>1.262023</td>\n",
       "      <td>-1.405179</td>\n",
       "      <td>1.231566</td>\n",
       "      <td>1.190723</td>\n",
       "      <td>-0.866939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>-0.188694</td>\n",
       "      <td>1.432833</td>\n",
       "      <td>1.258172</td>\n",
       "      <td>-1.394795</td>\n",
       "      <td>1.226975</td>\n",
       "      <td>1.180956</td>\n",
       "      <td>-0.890378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>-0.198901</td>\n",
       "      <td>1.426954</td>\n",
       "      <td>1.254320</td>\n",
       "      <td>-1.384411</td>\n",
       "      <td>1.222383</td>\n",
       "      <td>1.171189</td>\n",
       "      <td>-0.913817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>-0.201539</td>\n",
       "      <td>1.421075</td>\n",
       "      <td>1.250468</td>\n",
       "      <td>-1.374027</td>\n",
       "      <td>1.217792</td>\n",
       "      <td>1.161422</td>\n",
       "      <td>-0.937256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>-0.205942</td>\n",
       "      <td>1.415196</td>\n",
       "      <td>1.246616</td>\n",
       "      <td>-1.363643</td>\n",
       "      <td>1.213201</td>\n",
       "      <td>1.151656</td>\n",
       "      <td>-0.960696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>-0.213972</td>\n",
       "      <td>1.409317</td>\n",
       "      <td>1.242764</td>\n",
       "      <td>-1.353259</td>\n",
       "      <td>1.208609</td>\n",
       "      <td>1.141889</td>\n",
       "      <td>-0.984135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>-0.223641</td>\n",
       "      <td>1.403437</td>\n",
       "      <td>1.238913</td>\n",
       "      <td>-1.342876</td>\n",
       "      <td>1.204018</td>\n",
       "      <td>1.132122</td>\n",
       "      <td>-1.007574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>-0.237196</td>\n",
       "      <td>1.397558</td>\n",
       "      <td>1.235061</td>\n",
       "      <td>-1.332492</td>\n",
       "      <td>1.199427</td>\n",
       "      <td>1.122355</td>\n",
       "      <td>-1.031013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>-0.250600</td>\n",
       "      <td>1.391679</td>\n",
       "      <td>1.231209</td>\n",
       "      <td>-1.322108</td>\n",
       "      <td>1.194835</td>\n",
       "      <td>1.112589</td>\n",
       "      <td>-1.054452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>-0.261565</td>\n",
       "      <td>1.385800</td>\n",
       "      <td>1.227357</td>\n",
       "      <td>-1.311724</td>\n",
       "      <td>1.190244</td>\n",
       "      <td>1.102822</td>\n",
       "      <td>-1.077892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>-0.270324</td>\n",
       "      <td>1.370710</td>\n",
       "      <td>1.218853</td>\n",
       "      <td>-1.292805</td>\n",
       "      <td>1.172912</td>\n",
       "      <td>1.092584</td>\n",
       "      <td>-1.104579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>-0.282208</td>\n",
       "      <td>1.355619</td>\n",
       "      <td>1.210349</td>\n",
       "      <td>-1.273887</td>\n",
       "      <td>1.155580</td>\n",
       "      <td>1.082347</td>\n",
       "      <td>-1.131267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>-0.287448</td>\n",
       "      <td>1.340529</td>\n",
       "      <td>1.201845</td>\n",
       "      <td>-1.254968</td>\n",
       "      <td>1.138248</td>\n",
       "      <td>1.072109</td>\n",
       "      <td>-1.157955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>-0.287429</td>\n",
       "      <td>1.325439</td>\n",
       "      <td>1.193341</td>\n",
       "      <td>-1.236049</td>\n",
       "      <td>1.120916</td>\n",
       "      <td>1.061871</td>\n",
       "      <td>-1.184643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>-0.287653</td>\n",
       "      <td>1.310349</td>\n",
       "      <td>1.184837</td>\n",
       "      <td>-1.217131</td>\n",
       "      <td>1.103584</td>\n",
       "      <td>1.051634</td>\n",
       "      <td>-1.211330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>-0.270817</td>\n",
       "      <td>1.295258</td>\n",
       "      <td>1.176333</td>\n",
       "      <td>-1.198212</td>\n",
       "      <td>1.086252</td>\n",
       "      <td>1.041396</td>\n",
       "      <td>-1.238018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-0.247503</td>\n",
       "      <td>1.280168</td>\n",
       "      <td>1.167829</td>\n",
       "      <td>-1.179294</td>\n",
       "      <td>1.068920</td>\n",
       "      <td>1.031159</td>\n",
       "      <td>-1.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>-0.239967</td>\n",
       "      <td>1.265078</td>\n",
       "      <td>1.159325</td>\n",
       "      <td>-1.160375</td>\n",
       "      <td>1.051588</td>\n",
       "      <td>1.020921</td>\n",
       "      <td>-1.291394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>-0.218298</td>\n",
       "      <td>1.249987</td>\n",
       "      <td>1.150821</td>\n",
       "      <td>-1.141456</td>\n",
       "      <td>1.034256</td>\n",
       "      <td>1.010683</td>\n",
       "      <td>-1.318081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-0.219108</td>\n",
       "      <td>1.234897</td>\n",
       "      <td>1.142317</td>\n",
       "      <td>-1.122538</td>\n",
       "      <td>1.016924</td>\n",
       "      <td>1.000446</td>\n",
       "      <td>-1.344769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-0.217594</td>\n",
       "      <td>1.219807</td>\n",
       "      <td>1.133813</td>\n",
       "      <td>-1.103619</td>\n",
       "      <td>0.999592</td>\n",
       "      <td>0.990208</td>\n",
       "      <td>-1.371457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162                                         -0.601510   \n",
       "163                                         -0.786068   \n",
       "164                                         -0.830387   \n",
       "165                                         -0.801089   \n",
       "166                                         -0.959917   \n",
       "167                                         -1.022309   \n",
       "168                                         -1.074401   \n",
       "169                                         -1.119597   \n",
       "170                                         -1.078648   \n",
       "171                                         -1.055426   \n",
       "172                                         -1.101053   \n",
       "173                                         -1.211370   \n",
       "174                                         -1.157198   \n",
       "175                                         -1.223444   \n",
       "176                                         -1.311519   \n",
       "177                                         -1.362602   \n",
       "178                                         -1.380125   \n",
       "179                                         -1.219296   \n",
       "180                                         -1.300284   \n",
       "181                                         -1.336476   \n",
       "182                                         -1.415774   \n",
       "183                                         -1.526021   \n",
       "184                                         -1.681806   \n",
       "185                                         -1.735167   \n",
       "186                                         -1.962315   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "162                                0.763466  -1.213929   \n",
       "163                                0.752299  -1.292173   \n",
       "164                                0.741131  -1.324219   \n",
       "165                                0.729964  -1.344446   \n",
       "166                                0.718796  -1.381638   \n",
       "167                                0.707629  -1.411208   \n",
       "168                                0.696461  -1.412953   \n",
       "169                                0.681823  -1.491464   \n",
       "170                                0.667184  -1.573805   \n",
       "171                                0.652545  -1.564950   \n",
       "172                                0.637906  -1.581584   \n",
       "173                                0.623268  -1.565976   \n",
       "174                                0.608629  -1.648556   \n",
       "175                                0.593990  -1.650049   \n",
       "176                                0.579351  -1.653957   \n",
       "177                                0.564713  -1.652572   \n",
       "178                                0.550074  -1.715349   \n",
       "179                                0.535435  -1.750917   \n",
       "180                                0.520796  -1.718448   \n",
       "181                                0.501996  -1.733426   \n",
       "182                                0.483195  -1.729362   \n",
       "183                                0.464395  -1.748544   \n",
       "184                                0.445594  -1.778060   \n",
       "185                                0.426794  -1.773710   \n",
       "186                                0.407993  -1.757007   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Rondônia - Produção de Cimento (t)  Rondônia - IDH  \\\n",
       "162                           -0.154026        1.456870   \n",
       "163                           -0.149437        1.456783   \n",
       "164                           -0.146620        1.456697   \n",
       "165                           -0.144720        1.456610   \n",
       "166                           -0.149294        1.456523   \n",
       "167                           -0.152432        1.456436   \n",
       "168                           -0.156135        1.456350   \n",
       "169                           -0.163427        1.450470   \n",
       "170                           -0.171276        1.444591   \n",
       "171                           -0.183620        1.438712   \n",
       "172                           -0.188694        1.432833   \n",
       "173                           -0.198901        1.426954   \n",
       "174                           -0.201539        1.421075   \n",
       "175                           -0.205942        1.415196   \n",
       "176                           -0.213972        1.409317   \n",
       "177                           -0.223641        1.403437   \n",
       "178                           -0.237196        1.397558   \n",
       "179                           -0.250600        1.391679   \n",
       "180                           -0.261565        1.385800   \n",
       "181                           -0.270324        1.370710   \n",
       "182                           -0.282208        1.355619   \n",
       "183                           -0.287448        1.340529   \n",
       "184                           -0.287429        1.325439   \n",
       "185                           -0.287653        1.310349   \n",
       "186                           -0.270817        1.295258   \n",
       "187                           -0.247503        1.280168   \n",
       "188                           -0.239967        1.265078   \n",
       "189                           -0.218298        1.249987   \n",
       "190                           -0.219108        1.234897   \n",
       "191                           -0.217594        1.219807   \n",
       "\n",
       "     Rondônia - PIB - Estadual  Rondônia - PIB - Construção Civil  \\\n",
       "162                   1.242136                          -1.467490   \n",
       "163                   1.247376                          -1.462297   \n",
       "164                   1.252617                          -1.457104   \n",
       "165                   1.257857                          -1.451910   \n",
       "166                   1.263098                          -1.446717   \n",
       "167                   1.268338                          -1.441524   \n",
       "168                   1.273579                          -1.436331   \n",
       "169                   1.269727                          -1.425947   \n",
       "170                   1.265875                          -1.415563   \n",
       "171                   1.262023                          -1.405179   \n",
       "172                   1.258172                          -1.394795   \n",
       "173                   1.254320                          -1.384411   \n",
       "174                   1.250468                          -1.374027   \n",
       "175                   1.246616                          -1.363643   \n",
       "176                   1.242764                          -1.353259   \n",
       "177                   1.238913                          -1.342876   \n",
       "178                   1.235061                          -1.332492   \n",
       "179                   1.231209                          -1.322108   \n",
       "180                   1.227357                          -1.311724   \n",
       "181                   1.218853                          -1.292805   \n",
       "182                   1.210349                          -1.273887   \n",
       "183                   1.201845                          -1.254968   \n",
       "184                   1.193341                          -1.236049   \n",
       "185                   1.184837                          -1.217131   \n",
       "186                   1.176333                          -1.198212   \n",
       "187                   1.167829                          -1.179294   \n",
       "188                   1.159325                          -1.160375   \n",
       "189                   1.150821                          -1.141456   \n",
       "190                   1.142317                          -1.122538   \n",
       "191                   1.133813                          -1.103619   \n",
       "\n",
       "     Rondônia - PIB - Per Capita  Rondônia - PIB - Preços de Mercado  \\\n",
       "162                     1.128938                            1.179337   \n",
       "163                     1.148338                            1.186118   \n",
       "164                     1.167739                            1.192899   \n",
       "165                     1.187139                            1.199680   \n",
       "166                     1.206539                            1.206461   \n",
       "167                     1.225940                            1.213242   \n",
       "168                     1.245340                            1.220023   \n",
       "169                     1.240749                            1.210256   \n",
       "170                     1.236157                            1.200489   \n",
       "171                     1.231566                            1.190723   \n",
       "172                     1.226975                            1.180956   \n",
       "173                     1.222383                            1.171189   \n",
       "174                     1.217792                            1.161422   \n",
       "175                     1.213201                            1.151656   \n",
       "176                     1.208609                            1.141889   \n",
       "177                     1.204018                            1.132122   \n",
       "178                     1.199427                            1.122355   \n",
       "179                     1.194835                            1.112589   \n",
       "180                     1.190244                            1.102822   \n",
       "181                     1.172912                            1.092584   \n",
       "182                     1.155580                            1.082347   \n",
       "183                     1.138248                            1.072109   \n",
       "184                     1.120916                            1.061871   \n",
       "185                     1.103584                            1.051634   \n",
       "186                     1.086252                            1.041396   \n",
       "187                     1.068920                            1.031159   \n",
       "188                     1.051588                            1.020921   \n",
       "189                     1.034256                            1.010683   \n",
       "190                     1.016924                            1.000446   \n",
       "191                     0.999592                            0.990208   \n",
       "\n",
       "     Rondônia - Desemprego  \n",
       "162              -0.405220  \n",
       "163              -0.470454  \n",
       "164              -0.535687  \n",
       "165              -0.600921  \n",
       "166              -0.666154  \n",
       "167              -0.731388  \n",
       "168              -0.796621  \n",
       "169              -0.820061  \n",
       "170              -0.843500  \n",
       "171              -0.866939  \n",
       "172              -0.890378  \n",
       "173              -0.913817  \n",
       "174              -0.937256  \n",
       "175              -0.960696  \n",
       "176              -0.984135  \n",
       "177              -1.007574  \n",
       "178              -1.031013  \n",
       "179              -1.054452  \n",
       "180              -1.077892  \n",
       "181              -1.104579  \n",
       "182              -1.131267  \n",
       "183              -1.157955  \n",
       "184              -1.184643  \n",
       "185              -1.211330  \n",
       "186              -1.238018  \n",
       "187              -1.264706  \n",
       "188              -1.291394  \n",
       "189              -1.318081  \n",
       "190              -1.344769  \n",
       "191              -1.371457  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    36.094\n",
       "163    42.556\n",
       "164    41.193\n",
       "165    37.053\n",
       "166    33.527\n",
       "167    25.616\n",
       "168    25.221\n",
       "169    23.321\n",
       "170    23.927\n",
       "171    24.561\n",
       "172    20.135\n",
       "173    34.837\n",
       "174    34.338\n",
       "175    39.293\n",
       "176    41.610\n",
       "177    43.544\n",
       "178    35.658\n",
       "179    29.693\n",
       "180    32.559\n",
       "181    24.910\n",
       "182    28.713\n",
       "183    32.660\n",
       "184    31.635\n",
       "185    35.142\n",
       "186    36.419\n",
       "187    40.300\n",
       "188    35.493\n",
       "189    38.489\n",
       "190    35.591\n",
       "191    27.530\n",
       "Name: Rondônia - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    train, train_val = validation_splitter(train_input, 7)\n",
    "    target,target_val = validation_splitter(train_target, 7)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val, target_val),\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3692409180, 3905937919, 1989302893, 3197138803, 3724492508, 4063532661, 2308781494, 560018080, 3600029169, 3374916127, 3545162816, 4006485376, 956356329, 3598626078, 3502146001, 283245043, 3160433072, 2194300826, 3603401983, 1835417221, 1739912908, 2483070836, 896320941, 3451515146, 901747655]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 82.48979949951172\n",
      "winner_seed: 3692409180\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 66.40487670898438\n",
      "winner_seed: 3905937919\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 80.51290893554688\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 65.96240997314453\n",
      "winner_seed: 3197138803\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 79.22322082519531\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 57.249412536621094\n",
      "winner_seed: 4063532661\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 77.23082733154297\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 75.75936889648438\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 78.587890625\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 79.9114761352539\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 78.30537414550781\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 78.91677856445312\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 78.10243225097656\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 78.46881103515625\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 64.65641784667969\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 78.57685089111328\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 80.09632110595703\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 77.5087661743164\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 69.87353515625\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 79.3698959350586\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 77.32390594482422\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 78.80577087402344\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 64.39447021484375\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 79.1493911743164\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 80.41447448730469\n",
      "\n",
      "\n",
      "final_seed: 4063532661\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 1s 27ms/step - loss: 1573.9688 - val_loss: 2828.5171\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2876.3296 - val_loss: 1504.3385\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1589.5327 - val_loss: 1257.7579\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1405.7231 - val_loss: 580.9241\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 677.8060 - val_loss: 279.7362\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 251.6516 - val_loss: 413.4127\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 295.1518 - val_loss: 282.8040\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 233.4630 - val_loss: 297.8383\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 241.3016 - val_loss: 268.1328\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 199.1637 - val_loss: 216.5828\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 193.3131 - val_loss: 246.1344\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 165.3122 - val_loss: 227.5991\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 153.4349 - val_loss: 192.3881\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 143.5856 - val_loss: 115.5307\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 79.1152 - val_loss: 186.7406\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.7177 - val_loss: 103.6366\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.8773 - val_loss: 118.7960\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.3324 - val_loss: 133.6520\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.6557 - val_loss: 111.8415\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.3887 - val_loss: 109.7014\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.0707 - val_loss: 114.1099\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 94.8345 - val_loss: 98.3042\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 86.8759 - val_loss: 119.5966\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 77.8656 - val_loss: 126.3521\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.1308 - val_loss: 107.8196\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.6309 - val_loss: 116.9047\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 96.6778 - val_loss: 110.2762\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.8607 - val_loss: 144.1253\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.8177 - val_loss: 103.5557\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 72.9876 - val_loss: 181.7545\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 329.2924 - val_loss: 126.3788\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 88.0004 - val_loss: 101.1524\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.6889 - val_loss: 106.4160\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.3538 - val_loss: 115.2441\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.4753 - val_loss: 123.7705\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.6947 - val_loss: 116.3665\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.9806 - val_loss: 120.5164\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.6364 - val_loss: 126.3682\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 76.2181 - val_loss: 108.2331\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 69.1811 - val_loss: 124.4670\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.7180 - val_loss: 97.7938\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.1587 - val_loss: 110.9907\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 118.8899 - val_loss: 127.4369\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 77.4081 - val_loss: 99.6694\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 77.3753 - val_loss: 103.5327\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 65.6658 - val_loss: 130.4738\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 77.4106 - val_loss: 133.6611\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.7942 - val_loss: 103.4096\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 71.3305 - val_loss: 96.4026\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 79.4211 - val_loss: 92.2752\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.4140 - val_loss: 89.7081\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.4373 - val_loss: 95.5063\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.0201 - val_loss: 93.8574\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.4589 - val_loss: 106.3822\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 67.6941 - val_loss: 127.6749\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 75.4420 - val_loss: 112.6879\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.9022 - val_loss: 99.4840\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.8303 - val_loss: 109.6826\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.5102 - val_loss: 122.1646\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 84.2687 - val_loss: 114.8553\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 76.5073 - val_loss: 109.7132\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.0827 - val_loss: 106.6232\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.7870 - val_loss: 122.0205\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.1242 - val_loss: 98.9768\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.0520 - val_loss: 95.5244\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.3204 - val_loss: 111.8867\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.7007 - val_loss: 96.5030\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75.7258 - val_loss: 93.6492\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 81.9180 - val_loss: 117.6485\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.5183 - val_loss: 105.0035\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.6428 - val_loss: 91.9408\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.4695 - val_loss: 104.7825\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.8010 - val_loss: 167.3540\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 88.8093 - val_loss: 97.3183\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.2946 - val_loss: 92.8647\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.8932 - val_loss: 95.7104\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.6399 - val_loss: 110.8221\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 61.7930 - val_loss: 98.5030\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.3638 - val_loss: 105.2724\n",
      "Epoch 80/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 66.7737 - val_loss: 96.9353\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.7384 - val_loss: 155.9387\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.0271 - val_loss: 107.5237\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 65.5732 - val_loss: 91.4639\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.6219 - val_loss: 95.6501\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.9104 - val_loss: 138.1589\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 79.6749 - val_loss: 108.4855\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.9144 - val_loss: 101.3825\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.8807 - val_loss: 117.8369\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 71.1855 - val_loss: 102.2856\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.2979 - val_loss: 105.5699\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.5302 - val_loss: 95.6391\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.7955 - val_loss: 104.6321\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.5689 - val_loss: 106.6682\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.1687 - val_loss: 95.5663\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.8111 - val_loss: 100.8047\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.8223 - val_loss: 100.6112\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 154.6337 - val_loss: 161.5022\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 92.6795 - val_loss: 91.8278\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.9577 - val_loss: 115.9667\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.0373 - val_loss: 106.3599\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.4921 - val_loss: 90.4370\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.8274 - val_loss: 85.6727\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.7482 - val_loss: 103.1809\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.4548 - val_loss: 127.5166\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.5691 - val_loss: 95.6259\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.0710 - val_loss: 102.3297\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.1059 - val_loss: 105.3538\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.5346 - val_loss: 106.3497\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.4055 - val_loss: 112.1431\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.3059 - val_loss: 92.2639\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.8689 - val_loss: 86.0999\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.0153 - val_loss: 102.1119\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.4496 - val_loss: 93.6658\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.0396 - val_loss: 94.8204\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.7676 - val_loss: 92.7207\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.6949 - val_loss: 98.7328\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.0009 - val_loss: 92.7888\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.9344 - val_loss: 106.2216\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.1684 - val_loss: 96.3780\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.6588 - val_loss: 97.4374\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.7087 - val_loss: 103.7934\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.5674 - val_loss: 103.4543\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.9687 - val_loss: 105.2115\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.6517 - val_loss: 108.2336\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.4943 - val_loss: 95.9608\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.9904 - val_loss: 94.2852\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.9324 - val_loss: 110.2008\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.0743 - val_loss: 110.6311\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.9899 - val_loss: 118.1792\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.0180 - val_loss: 96.1865\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.3551 - val_loss: 91.0906\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 67.8956 - val_loss: 96.2909\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.2973 - val_loss: 107.3570\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.9533 - val_loss: 106.0162\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.8246 - val_loss: 108.7997\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.6230 - val_loss: 96.9739\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.3840 - val_loss: 111.4206\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.3838 - val_loss: 98.9349\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 59.7301 - val_loss: 107.9989\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.8809 - val_loss: 98.3425\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.8644 - val_loss: 108.3961\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.9559 - val_loss: 102.8123\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 70.7275 - val_loss: 98.4872\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.5540 - val_loss: 98.6552\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.7304 - val_loss: 105.4798\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.5419 - val_loss: 115.2222\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.4712 - val_loss: 99.2064\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.0718 - val_loss: 95.4093\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.8792 - val_loss: 103.9569\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.2147 - val_loss: 107.8255\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.8373 - val_loss: 98.6937\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.7954 - val_loss: 106.0456\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.7856 - val_loss: 94.2516\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 53.4510 - val_loss: 99.3216\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.0927 - val_loss: 99.4202\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.0935 - val_loss: 98.4750\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.3989 - val_loss: 94.2798\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.6168 - val_loss: 113.2874\n",
      "Epoch 159/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 50.2391 - val_loss: 96.7932\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.1639 - val_loss: 95.3901\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.1707 - val_loss: 99.0603\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.6297 - val_loss: 104.7408\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.8778 - val_loss: 108.6546\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.9241 - val_loss: 100.3735\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.2080 - val_loss: 91.9602\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.3053 - val_loss: 98.4127\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.3158 - val_loss: 99.2846\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.7845 - val_loss: 99.4942\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.0810 - val_loss: 96.3246\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.3789 - val_loss: 94.8785\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.4046 - val_loss: 96.9684\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.9260 - val_loss: 97.6469\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.7631 - val_loss: 123.1971\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.4080 - val_loss: 113.2214\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.1110 - val_loss: 107.3546\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 72.1072 - val_loss: 103.9224\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.3997 - val_loss: 97.5599\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.7404 - val_loss: 95.4739\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 73.3576 - val_loss: 101.0195\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.1198 - val_loss: 105.6160\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 65.8929 - val_loss: 98.4306\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.8236 - val_loss: 103.5531\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.6846 - val_loss: 102.7076\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 61.6837 - val_loss: 101.7683\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.9051 - val_loss: 103.0878\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.4188 - val_loss: 115.1635\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.2442 - val_loss: 97.0477\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.5870 - val_loss: 92.4136\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.5654 - val_loss: 102.8939\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.1426 - val_loss: 100.1014\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 56.2440 - val_loss: 120.9169\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.9237 - val_loss: 113.8233\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.0913 - val_loss: 113.6382\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.6914 - val_loss: 98.6029\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.2745 - val_loss: 95.8257\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.6286 - val_loss: 94.4710\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.2059 - val_loss: 108.8139\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.8419 - val_loss: 102.0661\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.8064 - val_loss: 97.0797\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.4038 - val_loss: 95.7919\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.9406 - val_loss: 88.8152\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.5446 - val_loss: 92.5361\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.9141 - val_loss: 95.9185\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.4323 - val_loss: 103.1353\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 63.3254 - val_loss: 106.6126\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.1070 - val_loss: 93.7046\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.4221 - val_loss: 91.0577\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.9973 - val_loss: 96.1387\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.7927 - val_loss: 98.9213\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.1180 - val_loss: 102.6939\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.1847 - val_loss: 94.3629\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.6292 - val_loss: 102.4777\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.3028 - val_loss: 102.5284\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.6213 - val_loss: 90.3972\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.1226 - val_loss: 94.9672\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.4323 - val_loss: 97.6497\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.3431 - val_loss: 89.4282\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.7224 - val_loss: 100.2571\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.8018 - val_loss: 93.1893\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.2735 - val_loss: 94.3152\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.5072 - val_loss: 99.3806\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.9354 - val_loss: 117.1142\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.0668 - val_loss: 110.6998\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 71.4311 - val_loss: 112.5606\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.5629 - val_loss: 93.5985\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.0029 - val_loss: 100.8611\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.1049 - val_loss: 93.1733\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.2666 - val_loss: 105.2395\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.4721 - val_loss: 96.7861\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.8207 - val_loss: 93.3365\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.2889 - val_loss: 93.8723\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.8376 - val_loss: 92.2234\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 51.5276 - val_loss: 89.6678\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.8266 - val_loss: 87.2335\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.7729 - val_loss: 104.7371\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.2032 - val_loss: 109.6868\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.5663 - val_loss: 95.5457\n",
      "Epoch 238/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 55.3589 - val_loss: 90.3871\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.9782 - val_loss: 99.1266\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.8081 - val_loss: 90.4639\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.3386 - val_loss: 95.6565\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.4873 - val_loss: 100.7994\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 89.7535 - val_loss: 110.5694\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.7296 - val_loss: 109.7730\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.6900 - val_loss: 104.2459\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.4384 - val_loss: 90.9807\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.2084 - val_loss: 101.4871\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.2067 - val_loss: 99.8522\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.7012 - val_loss: 102.5354\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.3524 - val_loss: 93.0183\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.2798 - val_loss: 102.1029\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.2504 - val_loss: 154.3363\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.2128 - val_loss: 167.6306\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 78.5262 - val_loss: 110.8149\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.1766 - val_loss: 91.1021\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.3226 - val_loss: 108.7186\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.2592 - val_loss: 104.0742\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.7047 - val_loss: 109.7438\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.6691 - val_loss: 109.9431\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.4907 - val_loss: 106.6561\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.7696 - val_loss: 99.1646\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 64.4366 - val_loss: 98.6754\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.5268 - val_loss: 95.7430\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.4819 - val_loss: 97.2779\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.1066 - val_loss: 99.8957\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.8750 - val_loss: 102.4955\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.8434 - val_loss: 100.2580\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.4060 - val_loss: 109.0012\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.7478 - val_loss: 94.4053\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.5404 - val_loss: 93.7468\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.8404 - val_loss: 94.6943\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 55.7865 - val_loss: 99.1690\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.8358 - val_loss: 101.1050\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.9297 - val_loss: 104.5175\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.3336 - val_loss: 85.5224\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.3066 - val_loss: 103.2719\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.0773 - val_loss: 79.8147\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.7445 - val_loss: 87.9361\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.7941 - val_loss: 83.6075\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.0067 - val_loss: 96.1190\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.6717 - val_loss: 84.2220\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.5152 - val_loss: 87.2639\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.4998 - val_loss: 83.3731\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.9492 - val_loss: 95.6258\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.8575 - val_loss: 138.0559\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.2888 - val_loss: 95.0509\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.1097 - val_loss: 97.3238\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.2212 - val_loss: 141.4318\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.5003 - val_loss: 93.1124\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.5213 - val_loss: 111.8033\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.9812 - val_loss: 81.9661\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.8258 - val_loss: 81.2161\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.4387 - val_loss: 83.7545\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.4332 - val_loss: 94.1545\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.1410 - val_loss: 90.9135\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.0629 - val_loss: 128.0109\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 80.8114 - val_loss: 98.2869\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.4959 - val_loss: 72.7878\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.8922 - val_loss: 75.0425\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.5803 - val_loss: 75.3812\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.5482 - val_loss: 78.6703\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.8459 - val_loss: 89.6151\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.7815 - val_loss: 79.5311\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.7722 - val_loss: 83.5361\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.5730 - val_loss: 78.7583\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.5425 - val_loss: 74.0191\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.0946 - val_loss: 84.6666\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.5062 - val_loss: 83.3544\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.4127 - val_loss: 73.5196\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.6403 - val_loss: 76.3646\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.8827 - val_loss: 95.0131\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.0535 - val_loss: 80.0326\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.2192 - val_loss: 94.6827\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.0244 - val_loss: 89.2636\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.6455 - val_loss: 81.4615\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.0559 - val_loss: 78.9618\n",
      "Epoch 317/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 51.4223 - val_loss: 86.1877\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.8821 - val_loss: 76.7199\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.0032 - val_loss: 71.9220\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 63.9804 - val_loss: 90.0635\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.1160 - val_loss: 89.0750\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.5885 - val_loss: 95.4942\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 51.6821 - val_loss: 104.9714\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.5271 - val_loss: 83.3180\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.6527 - val_loss: 84.9390\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.1105 - val_loss: 81.8097\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.0917 - val_loss: 73.9415\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.8695 - val_loss: 72.2828\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.9118 - val_loss: 75.4803\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.0754 - val_loss: 87.0688\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.1622 - val_loss: 72.4017\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.0315 - val_loss: 94.6874\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.3964 - val_loss: 76.3919\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 61.2669 - val_loss: 93.4292\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.9848 - val_loss: 87.5836\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.0342 - val_loss: 86.4271\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.1848 - val_loss: 88.9615\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.2542 - val_loss: 84.0113\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.2113 - val_loss: 87.2001\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.2611 - val_loss: 88.0822\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.6501 - val_loss: 98.3309\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.9509 - val_loss: 86.1010\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.3462 - val_loss: 88.0488\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.4576 - val_loss: 91.0794\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.2108 - val_loss: 88.0849\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 62.8957 - val_loss: 85.1479\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.2450 - val_loss: 94.9201\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.9579 - val_loss: 92.9466\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.6756 - val_loss: 88.3527\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.6229 - val_loss: 91.9018\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.7316 - val_loss: 93.4241\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.0215 - val_loss: 78.7369\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.5418 - val_loss: 91.4053\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.5348 - val_loss: 95.6908\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.6324 - val_loss: 85.1519\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.6045 - val_loss: 81.7750\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 54.3165 - val_loss: 127.2714\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 65.1549 - val_loss: 94.5139\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.6587 - val_loss: 92.3491\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.5117 - val_loss: 87.7053\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.0200 - val_loss: 100.0779\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.4933 - val_loss: 84.3781\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.3054 - val_loss: 77.9869\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.2286 - val_loss: 78.9514\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.4386 - val_loss: 86.7819\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.4630 - val_loss: 89.5897\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.5257 - val_loss: 87.0168\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.6845 - val_loss: 81.5640\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.1742 - val_loss: 119.3231\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 74.1406 - val_loss: 103.8185\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.5681 - val_loss: 109.3867\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.1187 - val_loss: 92.7088\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.8437 - val_loss: 96.9380\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 51.5003 - val_loss: 102.6324\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.2851 - val_loss: 90.5004\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.9376 - val_loss: 85.9910\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.2618 - val_loss: 84.2552\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 52.7288 - val_loss: 98.5075\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.5953 - val_loss: 94.2773\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.7903 - val_loss: 151.2102\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82.8688 - val_loss: 113.7568\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 66.4411 - val_loss: 99.4341\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.6081 - val_loss: 94.6779\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.2179 - val_loss: 101.4566\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58.2824 - val_loss: 94.9496\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.7889 - val_loss: 104.4433\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 63.1747 - val_loss: 95.1011\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.9954 - val_loss: 89.2082\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.2315 - val_loss: 87.2741\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.0845 - val_loss: 90.6761\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.8818 - val_loss: 87.7602\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.2291 - val_loss: 84.2993\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.6494 - val_loss: 92.1114\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.8376 - val_loss: 86.1224\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.7585 - val_loss: 97.1365\n",
      "Epoch 396/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 56.5963 - val_loss: 95.7169\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.3855 - val_loss: 89.1937\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.9778 - val_loss: 92.6851\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.6954 - val_loss: 84.1917\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.7575 - val_loss: 92.2255\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.6924 - val_loss: 91.9053\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.2496 - val_loss: 85.5017\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.7730 - val_loss: 84.4207\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.1824 - val_loss: 86.5455\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.6364 - val_loss: 93.8165\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.6509 - val_loss: 87.6339\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.1168 - val_loss: 107.6865\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.5854 - val_loss: 95.0421\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.9435 - val_loss: 80.5984\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.2150 - val_loss: 83.3602\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 52.3903 - val_loss: 86.8520\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.5994 - val_loss: 87.7087\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.8126 - val_loss: 89.1101\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.3927 - val_loss: 88.6436\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.2072 - val_loss: 78.1894\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.3800 - val_loss: 86.4830\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.7046 - val_loss: 88.3214\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 52.8907 - val_loss: 92.9306\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 52.3772 - val_loss: 89.4627\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.9907 - val_loss: 102.2142\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 54.3672 - val_loss: 94.2461\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.2300 - val_loss: 100.3537\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.2857 - val_loss: 102.2660\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.8581 - val_loss: 98.0703\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.0148 - val_loss: 88.7387\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.3203 - val_loss: 100.1195\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.7428 - val_loss: 100.5007\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.9755 - val_loss: 96.3605\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.7241 - val_loss: 80.1035\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 57.8739 - val_loss: 88.1046\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.9935 - val_loss: 119.1904\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.9086 - val_loss: 82.5367\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.4859 - val_loss: 91.7712\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.1710 - val_loss: 87.0960\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.4237 - val_loss: 88.7646\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.8983 - val_loss: 79.0915\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.0390 - val_loss: 141.2847\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.6173 - val_loss: 122.0069\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.0903 - val_loss: 86.4035\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.2811 - val_loss: 100.5016\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.3255 - val_loss: 86.6569\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.3227 - val_loss: 87.4929\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.8921 - val_loss: 81.8807\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.0172 - val_loss: 79.9486\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.9672 - val_loss: 129.8183\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.0392 - val_loss: 86.9935\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.8712 - val_loss: 94.2013\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.0931 - val_loss: 89.1180\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.2277 - val_loss: 87.8360\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.7309 - val_loss: 83.4155\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.5656 - val_loss: 85.3234\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.1601 - val_loss: 79.6916\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.1015 - val_loss: 81.7979\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.0894 - val_loss: 83.3171\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.2980 - val_loss: 76.3791\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.5596 - val_loss: 84.2400\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.6458 - val_loss: 70.9342\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.4301 - val_loss: 78.6466\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.4274 - val_loss: 72.7449\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.2945 - val_loss: 68.9365\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.0970 - val_loss: 78.6020\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.4432 - val_loss: 77.3796\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.2648 - val_loss: 93.5573\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.2171 - val_loss: 95.8264\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.4908 - val_loss: 99.6625\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.2650 - val_loss: 108.0292\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.0323 - val_loss: 97.0873\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.2227 - val_loss: 97.7166\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.2093 - val_loss: 88.7462\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.0557 - val_loss: 90.8318\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.3087 - val_loss: 99.1342\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.5478 - val_loss: 112.4630\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.7689 - val_loss: 99.8925\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.4524 - val_loss: 119.3655\n",
      "Epoch 475/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 51.7138 - val_loss: 107.4955\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.5624 - val_loss: 116.8932\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.0011 - val_loss: 96.3834\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.4339 - val_loss: 117.1020\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 55.4755 - val_loss: 104.2213\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.2833 - val_loss: 109.1626\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.2220 - val_loss: 111.1377\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.6426 - val_loss: 118.2352\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.3558 - val_loss: 90.9608\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.9987 - val_loss: 112.8308\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 53.8166 - val_loss: 131.0414\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 68.1861 - val_loss: 124.6984\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.7721 - val_loss: 120.0247\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.5140 - val_loss: 101.9900\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.5109 - val_loss: 97.4421\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.5318 - val_loss: 111.3124\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.1799 - val_loss: 108.2264\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.8785 - val_loss: 111.0703\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.4679 - val_loss: 100.3489\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.3171 - val_loss: 98.5906\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.4388 - val_loss: 99.4033\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.8454 - val_loss: 119.8669\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 52.5922 - val_loss: 136.5364\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.7205 - val_loss: 102.0700\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.5168 - val_loss: 98.6781\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 60.9432 - val_loss: 81.6465\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 54.9663 - val_loss: 109.7846\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 62.6925 - val_loss: 107.0088\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 62.9531 - val_loss: 105.8602\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 57.6734 - val_loss: 104.0205\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.8947 - val_loss: 118.9817\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.7853 - val_loss: 115.1867\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.1108 - val_loss: 112.9923\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.2456 - val_loss: 117.8858\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 50.5479 - val_loss: 97.4842\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.5276 - val_loss: 98.0696\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.0381 - val_loss: 100.8919\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 50.9686 - val_loss: 90.6977\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.0561 - val_loss: 99.4031\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.2169 - val_loss: 100.2021\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.5839 - val_loss: 99.3561\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.5144 - val_loss: 112.6245\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.9833 - val_loss: 111.9782\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.9624 - val_loss: 116.2407\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.7327 - val_loss: 129.8154\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.5051 - val_loss: 112.0541\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 56.4916 - val_loss: 106.8831\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.9619 - val_loss: 100.4455\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 52.5048 - val_loss: 87.5303\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 50.5064 - val_loss: 90.3701\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.3361 - val_loss: 96.1285\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.5817 - val_loss: 92.2123\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 53.8849 - val_loss: 78.5980\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.5624 - val_loss: 79.1169\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.0055 - val_loss: 106.4471\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 50.9768 - val_loss: 73.5645\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.0153 - val_loss: 86.8078\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.2470 - val_loss: 89.7509\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.2274 - val_loss: 84.1318\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.4084 - val_loss: 118.9105\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.2423 - val_loss: 111.1606\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.3876 - val_loss: 117.1974\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.3101 - val_loss: 109.8598\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.8435 - val_loss: 108.8959\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.0983 - val_loss: 85.0811\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 60.9746 - val_loss: 72.2543\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 55.9205 - val_loss: 67.7062\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.1798 - val_loss: 69.3529\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 51.4109 - val_loss: 59.2367\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.0252 - val_loss: 64.5392\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 52.3143 - val_loss: 64.1700\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.7582 - val_loss: 73.9476\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 48.3006 - val_loss: 75.4345\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.7446 - val_loss: 69.2338\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.5133 - val_loss: 76.8495\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.7562 - val_loss: 81.6940\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.2748 - val_loss: 96.0043\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.3660 - val_loss: 97.6214\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.7608 - val_loss: 86.8184\n",
      "Epoch 554/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 50.3316 - val_loss: 93.3622\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.8762 - val_loss: 108.1228\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.6569 - val_loss: 78.0058\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.7189 - val_loss: 98.6124\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.6823 - val_loss: 104.2941\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.7881 - val_loss: 93.7865\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.1432 - val_loss: 109.6096\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.8191 - val_loss: 122.5681\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.0315 - val_loss: 116.2734\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.6302 - val_loss: 124.8994\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.5035 - val_loss: 120.6387\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.3034 - val_loss: 114.4816\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.6546 - val_loss: 98.5767\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.3597 - val_loss: 83.5010\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.8742 - val_loss: 85.9111\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.0461 - val_loss: 85.1576\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.1564 - val_loss: 94.7697\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.0175 - val_loss: 90.2336\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.6249 - val_loss: 83.5811\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.0834 - val_loss: 89.9422\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.4125 - val_loss: 95.2184\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.5074 - val_loss: 64.5824\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.9132 - val_loss: 69.4292\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.0999 - val_loss: 83.9938\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.4263 - val_loss: 81.2172\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 48.4486 - val_loss: 86.9898\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 49.7224 - val_loss: 74.2743\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.6323 - val_loss: 87.0336\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.5449 - val_loss: 92.1859\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.5234 - val_loss: 94.0441\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.5827 - val_loss: 78.8245\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.2528 - val_loss: 95.3778\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.6524 - val_loss: 99.4064\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.2012 - val_loss: 102.0264\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.3703 - val_loss: 93.3928\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.3768 - val_loss: 92.1702\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.9715 - val_loss: 92.8012\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.6827 - val_loss: 88.1658\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.6555 - val_loss: 106.7935\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.4748 - val_loss: 100.2031\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.3502 - val_loss: 128.8976\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.0359 - val_loss: 96.2877\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.0229 - val_loss: 98.0558\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.3210 - val_loss: 92.3904\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.3319 - val_loss: 97.3893\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.8358 - val_loss: 112.9623\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.2323 - val_loss: 97.3431\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.2138 - val_loss: 95.7363\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.4021 - val_loss: 99.9791\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.0467 - val_loss: 76.2577\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.3878 - val_loss: 86.6481\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.1776 - val_loss: 71.1089\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.5621 - val_loss: 82.7449\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.4380 - val_loss: 85.6343\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.8845 - val_loss: 72.8449\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.6718 - val_loss: 84.3654\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.7408 - val_loss: 91.8288\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.4166 - val_loss: 80.4336\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.9122 - val_loss: 78.6822\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.8208 - val_loss: 77.6652\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.4374 - val_loss: 71.6079\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.6166 - val_loss: 72.4487\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.3215 - val_loss: 85.0544\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.8311 - val_loss: 93.5423\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.4247 - val_loss: 90.4095\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.3928 - val_loss: 95.4651\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.3157 - val_loss: 121.9341\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 64.9995 - val_loss: 95.9722\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.2549 - val_loss: 81.9559\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.6498 - val_loss: 72.7771\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.3441 - val_loss: 92.1110\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.7031 - val_loss: 70.3777\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.3554 - val_loss: 67.9383\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 50.6805 - val_loss: 82.4782\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.6336 - val_loss: 86.9707\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.0488 - val_loss: 87.7758\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.4667 - val_loss: 92.4175\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.9928 - val_loss: 65.9376\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 57.9770 - val_loss: 84.8072\n",
      "Epoch 633/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 46.7299 - val_loss: 57.2494\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.8931 - val_loss: 59.8379\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.8259 - val_loss: 70.6832\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.2182 - val_loss: 68.8474\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.2016 - val_loss: 72.0748\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 47.9674 - val_loss: 75.8532\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.8169 - val_loss: 79.3841\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 45.3857 - val_loss: 73.8108\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.8803 - val_loss: 71.7744\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.5494 - val_loss: 104.4922\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.3429 - val_loss: 110.7195\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.9123 - val_loss: 101.1322\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.1394 - val_loss: 84.3914\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.6421 - val_loss: 77.9973\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.3668 - val_loss: 72.0250\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.7910 - val_loss: 64.4044\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.3424 - val_loss: 71.4335\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.4038 - val_loss: 93.7316\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.1965 - val_loss: 69.5275\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.8688 - val_loss: 70.8138\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.0441 - val_loss: 79.1483\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.8645 - val_loss: 76.5957\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.8078 - val_loss: 95.1159\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.0026 - val_loss: 79.1038\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.2937 - val_loss: 89.3078\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.0054 - val_loss: 94.0593\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.1948 - val_loss: 83.4690\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.4153 - val_loss: 109.7572\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.4188 - val_loss: 99.3384\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.1285 - val_loss: 86.7832\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.6513 - val_loss: 85.9864\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.4489 - val_loss: 80.2628\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.3658 - val_loss: 85.1308\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.3743 - val_loss: 78.9300\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.6056 - val_loss: 72.3079\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.7270 - val_loss: 76.7969\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.6692 - val_loss: 76.4054\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.5864 - val_loss: 77.1395\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.3544 - val_loss: 85.9511\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.2177 - val_loss: 77.2432\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.8137 - val_loss: 81.0980\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.4243 - val_loss: 97.7282\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.6885 - val_loss: 91.6102\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.1445 - val_loss: 85.6203\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.2509 - val_loss: 96.4103\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.0650 - val_loss: 89.2837\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.1222 - val_loss: 84.2012\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.2951 - val_loss: 87.7242\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.8254 - val_loss: 80.8071\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.9945 - val_loss: 103.6449\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.9372 - val_loss: 81.1138\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.6246 - val_loss: 97.7529\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.8713 - val_loss: 89.8270\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.9447 - val_loss: 68.3491\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 42.9434 - val_loss: 83.0829\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.3496 - val_loss: 107.3194\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.0465 - val_loss: 80.8180\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.2100 - val_loss: 105.2767\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 50.3502 - val_loss: 118.1974\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.3687 - val_loss: 106.3070\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.9333 - val_loss: 105.6125\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.4874 - val_loss: 107.4005\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.1952 - val_loss: 88.7245\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.7837 - val_loss: 88.7107\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.8610 - val_loss: 94.3013\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.3029 - val_loss: 121.7745\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.3235 - val_loss: 136.8438\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.3811 - val_loss: 118.7024\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 59.3904 - val_loss: 90.0089\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.4508 - val_loss: 97.5355\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.9919 - val_loss: 91.7362\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.2981 - val_loss: 78.5514\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.5719 - val_loss: 85.9716\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.7605 - val_loss: 97.1130\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.8636 - val_loss: 85.6381\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.4788 - val_loss: 83.3490\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.0025 - val_loss: 77.3824\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.9047 - val_loss: 72.1374\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.7344 - val_loss: 89.1084\n",
      "Epoch 712/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 47.3100 - val_loss: 99.4444\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.1513 - val_loss: 86.0449\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.2603 - val_loss: 91.1443\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.3075 - val_loss: 112.9058\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.0086 - val_loss: 115.2924\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.1456 - val_loss: 91.8717\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.0206 - val_loss: 106.2132\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.7028 - val_loss: 84.0309\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.1274 - val_loss: 95.2214\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.0882 - val_loss: 81.2355\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.5633 - val_loss: 93.2003\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.8741 - val_loss: 88.0534\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.5944 - val_loss: 85.3667\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.0560 - val_loss: 88.2306\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.6063 - val_loss: 92.3485\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.4704 - val_loss: 107.0725\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.7030 - val_loss: 102.8223\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.9993 - val_loss: 93.6419\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.2670 - val_loss: 123.7531\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.9854 - val_loss: 90.1474\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.9915 - val_loss: 87.0075\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.1222 - val_loss: 82.9231\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.8496 - val_loss: 82.2335\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.7700 - val_loss: 90.5184\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.0319 - val_loss: 84.5339\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.0256 - val_loss: 89.5010\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 56.3351 - val_loss: 76.5087\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.5325 - val_loss: 75.8293\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 49.9414 - val_loss: 81.1061\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.5630 - val_loss: 86.5228\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.7741 - val_loss: 89.6428\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.8807 - val_loss: 96.9354\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.6155 - val_loss: 94.3920\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.1063 - val_loss: 99.3322\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.6332 - val_loss: 99.8162\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.3058 - val_loss: 77.3071\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.8164 - val_loss: 77.5966\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.9647 - val_loss: 99.0355\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.6628 - val_loss: 96.7089\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.5103 - val_loss: 102.9265\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.8705 - val_loss: 101.1483\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.5643 - val_loss: 93.4307\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 49.7643 - val_loss: 93.9914\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 44.9638 - val_loss: 98.3208\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 53.2320 - val_loss: 96.4268\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.9352 - val_loss: 93.1855\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.0576 - val_loss: 103.4469\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.4214 - val_loss: 109.0512\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.3178 - val_loss: 112.0667\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.2009 - val_loss: 125.8071\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.0850 - val_loss: 116.5307\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 45.4105 - val_loss: 115.4978\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.6905 - val_loss: 114.8088\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.2188 - val_loss: 114.7975\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.5864 - val_loss: 115.9474\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.9483 - val_loss: 115.5857\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.7115 - val_loss: 114.5889\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.6979 - val_loss: 92.6034\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.7173 - val_loss: 102.5308\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.0499 - val_loss: 127.7026\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.8554 - val_loss: 119.2980\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.1228 - val_loss: 116.8509\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.3652 - val_loss: 118.5506\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.3299 - val_loss: 109.7894\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.4510 - val_loss: 108.0315\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.0611 - val_loss: 116.4738\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.4724 - val_loss: 104.1769\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.0278 - val_loss: 108.7603\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.5568 - val_loss: 112.4455\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.0640 - val_loss: 111.6724\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.6109 - val_loss: 103.9197\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 47.0505 - val_loss: 111.3478\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 130.8293 - val_loss: 145.0881\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 67.6059 - val_loss: 94.0124\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.2082 - val_loss: 91.0223\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.8433 - val_loss: 95.8599\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.7178 - val_loss: 93.5980\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.1903 - val_loss: 90.3939\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.4442 - val_loss: 125.5075\n",
      "Epoch 791/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 56.2580 - val_loss: 75.0517\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.6546 - val_loss: 129.4844\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.2442 - val_loss: 106.2105\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.8055 - val_loss: 81.0438\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.2905 - val_loss: 112.0969\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 60.2125 - val_loss: 91.1581\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.2527 - val_loss: 85.0657\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.8888 - val_loss: 76.1329\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.1686 - val_loss: 82.3112\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.2766 - val_loss: 72.8679\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.3494 - val_loss: 76.7876\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.8956 - val_loss: 77.3591\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.8243 - val_loss: 75.9223\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 51.9784 - val_loss: 103.7375\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 52.6833 - val_loss: 82.8929\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.7388 - val_loss: 95.1329\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.2089 - val_loss: 86.8839\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.3958 - val_loss: 127.3181\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 45.2524 - val_loss: 79.8437\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.7775 - val_loss: 90.6528\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.1984 - val_loss: 94.3578\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.6947 - val_loss: 102.9762\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.0552 - val_loss: 89.4999\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.2780 - val_loss: 88.9414\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.6466 - val_loss: 91.9639\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.9485 - val_loss: 89.0128\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.0141 - val_loss: 96.9216\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.7336 - val_loss: 83.1713\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.9886 - val_loss: 85.8412\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.0794 - val_loss: 73.0073\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.9975 - val_loss: 74.3656\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.3942 - val_loss: 84.6565\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.0768 - val_loss: 83.8098\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.6562 - val_loss: 91.7606\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.9587 - val_loss: 86.3864\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.5789 - val_loss: 88.3144\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.7012 - val_loss: 75.5477\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.6721 - val_loss: 88.5901\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.4740 - val_loss: 89.1594\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.9905 - val_loss: 80.5053\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.0537 - val_loss: 85.3887\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.1383 - val_loss: 88.4334\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.2536 - val_loss: 67.3802\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.5799 - val_loss: 92.3208\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.8375 - val_loss: 83.1008\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.5020 - val_loss: 94.3148\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.6047 - val_loss: 100.0798\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.4808 - val_loss: 99.3391\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.6896 - val_loss: 103.5698\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.8848 - val_loss: 102.5425\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.1067 - val_loss: 98.9372\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.4913 - val_loss: 99.3590\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.7725 - val_loss: 116.6437\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 62.4229 - val_loss: 109.3127\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.5534 - val_loss: 101.6308\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.5212 - val_loss: 99.3251\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.7196 - val_loss: 88.1267\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.8784 - val_loss: 85.5183\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.6833 - val_loss: 88.5350\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.2598 - val_loss: 123.1718\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.1176 - val_loss: 96.8955\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.6105 - val_loss: 78.1705\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.5431 - val_loss: 96.0094\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.5566 - val_loss: 83.8427\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.6243 - val_loss: 83.1417\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.3589 - val_loss: 94.0551\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.4508 - val_loss: 109.1071\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.6813 - val_loss: 92.3538\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.9274 - val_loss: 98.6517\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.8868 - val_loss: 92.4810\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.6762 - val_loss: 84.1788\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.5311 - val_loss: 83.0793\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.3744 - val_loss: 82.5289\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.0443 - val_loss: 84.1405\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.7713 - val_loss: 99.1942\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.8865 - val_loss: 87.2441\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.7030 - val_loss: 88.3567\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.6939 - val_loss: 94.3812\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.3189 - val_loss: 94.3761\n",
      "Epoch 870/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 51.4493 - val_loss: 108.8523\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.4855 - val_loss: 110.9717\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.3542 - val_loss: 85.8467\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.7584 - val_loss: 83.3899\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 55.9063 - val_loss: 87.6257\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.8514 - val_loss: 79.9276\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 51.4897 - val_loss: 85.9157\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 47.3262 - val_loss: 85.0020\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.2143 - val_loss: 123.2765\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.5679 - val_loss: 71.6971\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.7625 - val_loss: 83.6895\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.0583 - val_loss: 83.3304\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.4008 - val_loss: 78.4842\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.3252 - val_loss: 92.8923\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.8918 - val_loss: 78.2397\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.8620 - val_loss: 80.3218\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.9687 - val_loss: 79.4881\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.6454 - val_loss: 71.1572\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.7702 - val_loss: 73.6878\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.5770 - val_loss: 71.3735\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.6208 - val_loss: 78.9179\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.2556 - val_loss: 75.8824\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.4159 - val_loss: 77.8158\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.5675 - val_loss: 77.4356\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.4470 - val_loss: 74.3852\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.1092 - val_loss: 78.5325\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.5691 - val_loss: 73.7117\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.8162 - val_loss: 79.1769\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.8919 - val_loss: 86.2705\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.9483 - val_loss: 75.4039\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.0132 - val_loss: 75.2814\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.8460 - val_loss: 74.8780\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.3309 - val_loss: 94.6507\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.2796 - val_loss: 79.7705\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.6069 - val_loss: 89.1989\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.6910 - val_loss: 94.7284\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 47.9609 - val_loss: 95.3614\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.7101 - val_loss: 85.1611\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.5551 - val_loss: 98.3873\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.3555 - val_loss: 97.7744\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.9924 - val_loss: 89.3531\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.0021 - val_loss: 87.8860\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.0941 - val_loss: 91.5429\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 38.3216 - val_loss: 89.5317\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 40.8387 - val_loss: 86.5704\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 38.9977 - val_loss: 77.7266\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 38.2663 - val_loss: 75.5093\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 41.5461 - val_loss: 94.7814\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.0283 - val_loss: 82.1472\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.6740 - val_loss: 82.8076\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.8208 - val_loss: 83.5977\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.4445 - val_loss: 90.8011\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.4048 - val_loss: 91.5797\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.8116 - val_loss: 85.1039\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.4526 - val_loss: 74.8512\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.8300 - val_loss: 97.6243\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.7501 - val_loss: 94.5812\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.3386 - val_loss: 87.4922\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.6242 - val_loss: 75.3719\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.1112 - val_loss: 85.4522\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.1302 - val_loss: 84.5576\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.3535 - val_loss: 79.2493\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.4189 - val_loss: 89.0326\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.2704 - val_loss: 97.6628\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.2114 - val_loss: 83.3061\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.3398 - val_loss: 87.0645\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.7286 - val_loss: 83.1453\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.0115 - val_loss: 83.5285\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.3241 - val_loss: 81.3791\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.9992 - val_loss: 77.0175\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.5814 - val_loss: 74.2254\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.3499 - val_loss: 104.5336\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.0301 - val_loss: 100.5849\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.0652 - val_loss: 103.1939\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.0674 - val_loss: 97.7131\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.5086 - val_loss: 94.8575\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.3474 - val_loss: 95.0186\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.5790 - val_loss: 89.7697\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.0479 - val_loss: 96.7489\n",
      "Epoch 949/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 44.5576 - val_loss: 90.7014\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.2484 - val_loss: 89.1992\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.4228 - val_loss: 100.3694\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.8047 - val_loss: 90.9069\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.6692 - val_loss: 103.7689\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 43.5416 - val_loss: 93.1486\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.9520 - val_loss: 93.9493\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.3931 - val_loss: 110.5351\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.8952 - val_loss: 252.9694\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 83.8738 - val_loss: 95.6885\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.8191 - val_loss: 87.7953\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.1585 - val_loss: 91.7210\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.6458 - val_loss: 116.4726\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.8996 - val_loss: 103.5429\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.9288 - val_loss: 93.7623\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.8862 - val_loss: 118.8518\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.4150 - val_loss: 96.7638\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.9132 - val_loss: 111.0461\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.8399 - val_loss: 162.8811\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 57.3598 - val_loss: 107.5833\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 54.9098 - val_loss: 110.8634\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.3736 - val_loss: 103.0549\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.0177 - val_loss: 89.3959\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.7645 - val_loss: 96.7814\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.4717 - val_loss: 109.6490\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.2265 - val_loss: 97.0316\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.0510 - val_loss: 115.1381\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.0114 - val_loss: 105.3064\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.2668 - val_loss: 98.3031\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.9124 - val_loss: 95.9839\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.9019 - val_loss: 111.4197\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.1885 - val_loss: 90.3890\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.7601 - val_loss: 108.4513\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.7125 - val_loss: 95.6682\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.9956 - val_loss: 95.6521\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.6136 - val_loss: 96.8854\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.9518 - val_loss: 98.1412\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.7049 - val_loss: 98.0596\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.2849 - val_loss: 104.4330\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.4443 - val_loss: 103.1254\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.6467 - val_loss: 99.8251\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.1752 - val_loss: 107.3419\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.3459 - val_loss: 104.2379\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 43.4738 - val_loss: 105.8405\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.3175 - val_loss: 110.0462\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.6699 - val_loss: 109.7619\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.9895 - val_loss: 106.8527\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.0004 - val_loss: 99.3903\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.2039 - val_loss: 105.3878\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.7992 - val_loss: 106.4867\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.3069 - val_loss: 104.4048\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.3868 - val_loss: 105.3715\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.8175 - val_loss: 116.9709\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.5209 - val_loss: 115.5444\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.4370 - val_loss: 178.6035\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.2389 - val_loss: 121.9249\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.4714 - val_loss: 290.2950\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.6149 - val_loss: 101.3716\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.7139 - val_loss: 92.9078\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.3089 - val_loss: 93.9551\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.0288 - val_loss: 107.1506\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.3376 - val_loss: 95.8212\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.4488 - val_loss: 89.8049\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.9725 - val_loss: 91.5290\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.0027 - val_loss: 82.1569\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.3254 - val_loss: 121.7908\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 69.8850 - val_loss: 102.7237\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 44.9742 - val_loss: 92.7878\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.5043 - val_loss: 84.7961\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.6429 - val_loss: 92.4347\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.0373 - val_loss: 90.7415\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.4193 - val_loss: 94.0021\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.6587 - val_loss: 89.7799\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.5730 - val_loss: 92.1590\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.2611 - val_loss: 90.8757\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.4603 - val_loss: 102.1767\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.9867 - val_loss: 102.3665\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.6526 - val_loss: 92.6104\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.6219 - val_loss: 100.0183\n",
      "Epoch 1028/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 43.8501 - val_loss: 102.8230\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.9084 - val_loss: 101.6067\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.3797 - val_loss: 99.4598\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.5508 - val_loss: 105.3263\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 48.0644 - val_loss: 94.3879\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.1944 - val_loss: 106.2512\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.3823 - val_loss: 98.4959\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.1410 - val_loss: 138.5345\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 65.0904 - val_loss: 108.1313\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.9585 - val_loss: 127.9835\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 53.9617 - val_loss: 124.3953\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 72.2112 - val_loss: 174.5477\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 61.5327 - val_loss: 117.1368\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.9406 - val_loss: 117.0962\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.8855 - val_loss: 120.4202\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.1242 - val_loss: 111.2374\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.5793 - val_loss: 96.1865\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.7995 - val_loss: 114.7390\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 52.7686 - val_loss: 94.4238\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.5656 - val_loss: 106.7050\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.4999 - val_loss: 112.0089\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.0549 - val_loss: 108.3844\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.1357 - val_loss: 113.4863\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.6934 - val_loss: 102.9770\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.7710 - val_loss: 111.3780\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.2038 - val_loss: 106.5237\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.5304 - val_loss: 106.4199\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.3912 - val_loss: 99.1073\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.0310 - val_loss: 103.7288\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.8517 - val_loss: 109.2252\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.1059 - val_loss: 107.3613\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.0536 - val_loss: 99.6216\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 51.4962 - val_loss: 92.1753\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.4441 - val_loss: 103.0343\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.0956 - val_loss: 107.3820\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.0502 - val_loss: 110.2092\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.7660 - val_loss: 100.6424\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 48.5228 - val_loss: 114.4336\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.7776 - val_loss: 106.9229\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 40.9865 - val_loss: 98.6290\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.2923 - val_loss: 99.6189\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.0546 - val_loss: 98.9364\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.0565 - val_loss: 106.0277\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.0313 - val_loss: 102.9839\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.2267 - val_loss: 110.6479\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.8182 - val_loss: 110.7400\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.2837 - val_loss: 91.1440\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.8544 - val_loss: 111.8747\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.7494 - val_loss: 101.9660\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 46.8608 - val_loss: 105.8829\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.9993 - val_loss: 100.9497\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.9408 - val_loss: 109.3781\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.0545 - val_loss: 112.9015\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 46.9639 - val_loss: 108.3886\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.5627 - val_loss: 110.9977\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.4507 - val_loss: 106.2388\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.3859 - val_loss: 102.5299\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.9408 - val_loss: 102.0884\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.1878 - val_loss: 95.8801\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.9413 - val_loss: 126.7873\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.6910 - val_loss: 127.9690\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 49.4991 - val_loss: 103.2485\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.4869 - val_loss: 104.1045\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.8036 - val_loss: 130.3522\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.9362 - val_loss: 110.0182\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.4104 - val_loss: 102.7131\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 43.0783 - val_loss: 92.2930\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.8663 - val_loss: 102.5996\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 50.9002 - val_loss: 93.6791\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 43.7407 - val_loss: 93.1700\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 44.0481 - val_loss: 98.3602\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.9562 - val_loss: 90.0454\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 48.5639 - val_loss: 97.4847\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.7006 - val_loss: 102.0046\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.0947 - val_loss: 89.9364\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.0488 - val_loss: 99.2392\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.3858 - val_loss: 94.1434\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.9574 - val_loss: 93.5430\n",
      "Epoch 1106/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 44.8923 - val_loss: 154.4591\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.1632 - val_loss: 112.1601\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.4199 - val_loss: 103.0529\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.3460 - val_loss: 98.5906\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.1373 - val_loss: 98.3456\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.3777 - val_loss: 95.5670\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.8435 - val_loss: 110.1075\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.2216 - val_loss: 99.3980\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.0633 - val_loss: 117.3526\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.5577 - val_loss: 98.7952\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.0493 - val_loss: 105.0312\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.7560 - val_loss: 97.4286\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.8852 - val_loss: 99.2501\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 48.8563 - val_loss: 102.1792\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.3112 - val_loss: 92.6308\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 42.6766 - val_loss: 84.7577\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.0602 - val_loss: 99.0149\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.6399 - val_loss: 92.9676\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 51.5386 - val_loss: 98.5695\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 43.2731 - val_loss: 94.5078\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.8410 - val_loss: 102.9390\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 50.6689 - val_loss: 102.1814\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 47.7525 - val_loss: 102.4179\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.6052 - val_loss: 106.5118\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 45.1322 - val_loss: 109.0309\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 46.5213 - val_loss: 102.8823\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 49.0977 - val_loss: 96.9928\n",
      "Epoch 1133/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 37.3632Restoring model weights from the end of the best epoch: 633.\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 46.0516 - val_loss: 101.1835\n",
      "Epoch 1133: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>32.634468</td>\n",
       "      <td>32.64061</td>\n",
       "      <td>32.6464</td>\n",
       "      <td>32.646896</td>\n",
       "      <td>32.632683</td>\n",
       "      <td>32.618053</td>\n",
       "      <td>32.563469</td>\n",
       "      <td>32.576427</td>\n",
       "      <td>32.592197</td>\n",
       "      <td>32.607864</td>\n",
       "      <td>32.619854</td>\n",
       "      <td>32.645134</td>\n",
       "      <td>32.64209</td>\n",
       "      <td>32.635658</td>\n",
       "      <td>32.641808</td>\n",
       "      <td>32.642918</td>\n",
       "      <td>32.64967</td>\n",
       "      <td>32.656185</td>\n",
       "      <td>32.64912</td>\n",
       "      <td>32.641441</td>\n",
       "      <td>32.66254</td>\n",
       "      <td>32.656422</td>\n",
       "      <td>32.658279</td>\n",
       "      <td>32.662872</td>\n",
       "      <td>32.678341</td>\n",
       "      <td>32.788136</td>\n",
       "      <td>36.389069</td>\n",
       "      <td>39.116642</td>\n",
       "      <td>48.726105</td>\n",
       "      <td>48.732502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>36.094</td>\n",
       "      <td>42.556</td>\n",
       "      <td>41.193</td>\n",
       "      <td>37.053</td>\n",
       "      <td>33.527</td>\n",
       "      <td>25.616</td>\n",
       "      <td>25.221</td>\n",
       "      <td>23.321</td>\n",
       "      <td>23.927</td>\n",
       "      <td>24.561</td>\n",
       "      <td>20.135</td>\n",
       "      <td>34.837</td>\n",
       "      <td>34.338</td>\n",
       "      <td>39.293</td>\n",
       "      <td>41.61</td>\n",
       "      <td>43.544</td>\n",
       "      <td>35.658</td>\n",
       "      <td>29.693</td>\n",
       "      <td>32.559</td>\n",
       "      <td>24.91</td>\n",
       "      <td>28.713</td>\n",
       "      <td>32.66</td>\n",
       "      <td>31.635</td>\n",
       "      <td>35.142</td>\n",
       "      <td>36.419</td>\n",
       "      <td>40.3</td>\n",
       "      <td>35.493</td>\n",
       "      <td>38.489</td>\n",
       "      <td>35.591</td>\n",
       "      <td>27.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>3.459534</td>\n",
       "      <td>9.91539</td>\n",
       "      <td>8.5466</td>\n",
       "      <td>4.406105</td>\n",
       "      <td>0.894318</td>\n",
       "      <td>7.002054</td>\n",
       "      <td>7.342468</td>\n",
       "      <td>9.255428</td>\n",
       "      <td>8.665197</td>\n",
       "      <td>8.046864</td>\n",
       "      <td>12.484854</td>\n",
       "      <td>2.191868</td>\n",
       "      <td>1.695911</td>\n",
       "      <td>6.657341</td>\n",
       "      <td>8.968193</td>\n",
       "      <td>10.901081</td>\n",
       "      <td>3.008331</td>\n",
       "      <td>2.963184</td>\n",
       "      <td>0.090122</td>\n",
       "      <td>7.731441</td>\n",
       "      <td>3.949541</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>1.023279</td>\n",
       "      <td>2.479126</td>\n",
       "      <td>3.740658</td>\n",
       "      <td>7.511864</td>\n",
       "      <td>0.896069</td>\n",
       "      <td>0.627644</td>\n",
       "      <td>13.135105</td>\n",
       "      <td>21.202501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1        2          3          4          5   \\\n",
       "Month         Month-1   Month-2  Month-3    Month-4    Month-5    Month-6   \n",
       "Prediction  32.634468  32.64061  32.6464  32.646896  32.632683  32.618053   \n",
       "Target         36.094    42.556   41.193     37.053     33.527     25.616   \n",
       "Error        3.459534   9.91539   8.5466   4.406105   0.894318   7.002054   \n",
       "\n",
       "                   6          7          8          9          10         11  \\\n",
       "Month         Month-7    Month-8    Month-9   Month-10   Month-11   Month-12   \n",
       "Prediction  32.563469  32.576427  32.592197  32.607864  32.619854  32.645134   \n",
       "Target         25.221     23.321     23.927     24.561     20.135     34.837   \n",
       "Error        7.342468   9.255428   8.665197   8.046864  12.484854   2.191868   \n",
       "\n",
       "                  12         13         14         15        16         17  \\\n",
       "Month       Month-13   Month-14   Month-15   Month-16  Month-17   Month-18   \n",
       "Prediction  32.64209  32.635658  32.641808  32.642918  32.64967  32.656185   \n",
       "Target        34.338     39.293      41.61     43.544    35.658     29.693   \n",
       "Error       1.695911   6.657341   8.968193  10.901081  3.008331   2.963184   \n",
       "\n",
       "                  18         19        20         21         22         23  \\\n",
       "Month       Month-19   Month-20  Month-21   Month-22   Month-23   Month-24   \n",
       "Prediction  32.64912  32.641441  32.66254  32.656422  32.658279  32.662872   \n",
       "Target        32.559      24.91    28.713      32.66     31.635     35.142   \n",
       "Error       0.090122   7.731441  3.949541   0.003578   1.023279   2.479126   \n",
       "\n",
       "                   24         25         26         27         28         29  \n",
       "Month        Month-25   Month-26   Month-27   Month-28   Month-29   Month-30  \n",
       "Prediction  32.678341  32.788136  36.389069  39.116642  48.726105  48.732502  \n",
       "Target         36.419       40.3     35.493     38.489     35.591      27.53  \n",
       "Error        3.740658   7.511864   0.896069   0.627644  13.135105  21.202501  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.9598546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.19694792"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Ano-0: |Prediction[[391.42404]] - Target[368.041]| =  Error: [[23.383057]]; MAPE:[[0.06353384]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Ano-0: |Prediction[[391.79904]] - Target[409.75500000000005]| =  Error: [[17.955963]]; MAPE:[[0.04382122]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Ano-5: |Prediction[[238.43079]] - Target[213.822]| =  Error: [[24.60878]]; MAPE:[[0.11509003]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[23.383057]], dtype=float32),\n",
       " array([[17.955963]], dtype=float32),\n",
       " array([[24.60878]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "21.9826"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.074148364"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
