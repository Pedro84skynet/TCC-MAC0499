{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Rio Grande Do Norte - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rio Grande do Norte - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rio Grande Do Norte - Produção de Cimento (t)</th>\n",
       "      <th>Rio Grande do Norte - PIB - Estadual</th>\n",
       "      <th>Rio Grande do Norte - PIB - Construção Civil</th>\n",
       "      <th>Rio Grande do Norte - PIB - Per Capita</th>\n",
       "      <th>Rio Grande do Norte - PIB - Preços de Mercado</th>\n",
       "      <th>Rio Grande do Norte - Desemprego</th>\n",
       "      <th>Rio Grande Do Norte - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.689488</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>27.698760</td>\n",
       "      <td>3.164847e+07</td>\n",
       "      <td>1.998664e+06</td>\n",
       "      <td>9.097985</td>\n",
       "      <td>2.879532e+07</td>\n",
       "      <td>8.294170</td>\n",
       "      <td>36.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.689892</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>27.407645</td>\n",
       "      <td>3.168897e+07</td>\n",
       "      <td>2.001107e+06</td>\n",
       "      <td>9.101271</td>\n",
       "      <td>2.881033e+07</td>\n",
       "      <td>8.288224</td>\n",
       "      <td>34.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>27.377422</td>\n",
       "      <td>3.172947e+07</td>\n",
       "      <td>2.003550e+06</td>\n",
       "      <td>9.104557</td>\n",
       "      <td>2.882535e+07</td>\n",
       "      <td>8.282278</td>\n",
       "      <td>30.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.690702</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>27.542280</td>\n",
       "      <td>3.176997e+07</td>\n",
       "      <td>2.005994e+06</td>\n",
       "      <td>9.107843</td>\n",
       "      <td>2.884036e+07</td>\n",
       "      <td>8.276332</td>\n",
       "      <td>31.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.691107</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>27.944900</td>\n",
       "      <td>3.181046e+07</td>\n",
       "      <td>2.008437e+06</td>\n",
       "      <td>9.111128</td>\n",
       "      <td>2.885538e+07</td>\n",
       "      <td>8.270387</td>\n",
       "      <td>33.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.557326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.910014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.800783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.752983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.559717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Rio Grande do Norte - IDH  \\\n",
       "0       2003-1                   0.689488   \n",
       "1       2003-2                   0.689892   \n",
       "2       2003-3                   0.690297   \n",
       "3       2003-4                   0.690702   \n",
       "4       2003-5                   0.691107   \n",
       "..         ...                        ...   \n",
       "235     2022-8                        NaN   \n",
       "236     2022-9                        NaN   \n",
       "237    2022-10                        NaN   \n",
       "238    2022-11                        NaN   \n",
       "239    2022-12                        NaN   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            0.724032   \n",
       "1                                            0.690297   \n",
       "2                                            0.669681   \n",
       "3                                            0.660494   \n",
       "4                                            0.648337   \n",
       "..                                                ...   \n",
       "235                                               NaN   \n",
       "236                                               NaN   \n",
       "237                                               NaN   \n",
       "238                                               NaN   \n",
       "239                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     Rio Grande Do Norte - Produção de Cimento (t)  \\\n",
       "0                                        27.698760   \n",
       "1                                        27.407645   \n",
       "2                                        27.377422   \n",
       "3                                        27.542280   \n",
       "4                                        27.944900   \n",
       "..                                             ...   \n",
       "235                                      95.557326   \n",
       "236                                      94.910014   \n",
       "237                                      94.800783   \n",
       "238                                      94.752983   \n",
       "239                                      94.559717   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Estadual  \\\n",
       "0                            3.164847e+07   \n",
       "1                            3.168897e+07   \n",
       "2                            3.172947e+07   \n",
       "3                            3.176997e+07   \n",
       "4                            3.181046e+07   \n",
       "..                                    ...   \n",
       "235                                   NaN   \n",
       "236                                   NaN   \n",
       "237                                   NaN   \n",
       "238                                   NaN   \n",
       "239                                   NaN   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Construção Civil  \\\n",
       "0                                    1.998664e+06   \n",
       "1                                    2.001107e+06   \n",
       "2                                    2.003550e+06   \n",
       "3                                    2.005994e+06   \n",
       "4                                    2.008437e+06   \n",
       "..                                            ...   \n",
       "235                                           NaN   \n",
       "236                                           NaN   \n",
       "237                                           NaN   \n",
       "238                                           NaN   \n",
       "239                                           NaN   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Per Capita  \\\n",
       "0                                  9.097985   \n",
       "1                                  9.101271   \n",
       "2                                  9.104557   \n",
       "3                                  9.107843   \n",
       "4                                  9.111128   \n",
       "..                                      ...   \n",
       "235                                     NaN   \n",
       "236                                     NaN   \n",
       "237                                     NaN   \n",
       "238                                     NaN   \n",
       "239                                     NaN   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Preços de Mercado  \\\n",
       "0                                     2.879532e+07   \n",
       "1                                     2.881033e+07   \n",
       "2                                     2.882535e+07   \n",
       "3                                     2.884036e+07   \n",
       "4                                     2.885538e+07   \n",
       "..                                             ...   \n",
       "235                                            NaN   \n",
       "236                                            NaN   \n",
       "237                                            NaN   \n",
       "238                                            NaN   \n",
       "239                                            NaN   \n",
       "\n",
       "     Rio Grande do Norte - Desemprego  \\\n",
       "0                            8.294170   \n",
       "1                            8.288224   \n",
       "2                            8.282278   \n",
       "3                            8.276332   \n",
       "4                            8.270387   \n",
       "..                                ...   \n",
       "235                               NaN   \n",
       "236                               NaN   \n",
       "237                               NaN   \n",
       "238                               NaN   \n",
       "239                               NaN   \n",
       "\n",
       "     Rio Grande Do Norte - Consumo de Cimento (t)  \n",
       "0                                          36.825  \n",
       "1                                          34.088  \n",
       "2                                          30.150  \n",
       "3                                          31.224  \n",
       "4                                          33.606  \n",
       "..                                            ...  \n",
       "235                                        83.890  \n",
       "236                                        83.438  \n",
       "237                                        80.005  \n",
       "238                                        75.441  \n",
       "239                                        75.441  \n",
       "\n",
       "[240 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_RN.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data = data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rio Grande do Norte - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rio Grande Do Norte - Produção de Cimento (t)</th>\n",
       "      <th>Rio Grande do Norte - PIB - Estadual</th>\n",
       "      <th>Rio Grande do Norte - PIB - Construção Civil</th>\n",
       "      <th>Rio Grande do Norte - PIB - Per Capita</th>\n",
       "      <th>Rio Grande do Norte - PIB - Preços de Mercado</th>\n",
       "      <th>Rio Grande do Norte - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.184058</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.183161</td>\n",
       "      <td>-1.731345</td>\n",
       "      <td>-0.778207</td>\n",
       "      <td>-2.784513</td>\n",
       "      <td>-2.193066</td>\n",
       "      <td>-0.876481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.147573</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.192364</td>\n",
       "      <td>-1.711183</td>\n",
       "      <td>-0.728728</td>\n",
       "      <td>-2.703361</td>\n",
       "      <td>-2.146603</td>\n",
       "      <td>-0.878896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.111089</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.193319</td>\n",
       "      <td>-1.691021</td>\n",
       "      <td>-0.679248</td>\n",
       "      <td>-2.622210</td>\n",
       "      <td>-2.100140</td>\n",
       "      <td>-0.881311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.074605</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.188108</td>\n",
       "      <td>-1.670859</td>\n",
       "      <td>-0.629768</td>\n",
       "      <td>-2.541059</td>\n",
       "      <td>-2.053677</td>\n",
       "      <td>-0.883727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.038120</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.175380</td>\n",
       "      <td>-1.650697</td>\n",
       "      <td>-0.580289</td>\n",
       "      <td>-2.459908</td>\n",
       "      <td>-2.007214</td>\n",
       "      <td>-0.886142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.321156</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>0.389536</td>\n",
       "      <td>1.102751</td>\n",
       "      <td>-1.573216</td>\n",
       "      <td>0.457957</td>\n",
       "      <td>0.775635</td>\n",
       "      <td>1.052347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.314269</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>0.398528</td>\n",
       "      <td>1.092237</td>\n",
       "      <td>-1.561825</td>\n",
       "      <td>0.427807</td>\n",
       "      <td>0.759230</td>\n",
       "      <td>1.051753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.307381</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>0.414978</td>\n",
       "      <td>1.081724</td>\n",
       "      <td>-1.550435</td>\n",
       "      <td>0.397658</td>\n",
       "      <td>0.742826</td>\n",
       "      <td>1.051160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.300494</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>0.429834</td>\n",
       "      <td>1.071210</td>\n",
       "      <td>-1.539044</td>\n",
       "      <td>0.367509</td>\n",
       "      <td>0.726421</td>\n",
       "      <td>1.050566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.293607</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>0.437373</td>\n",
       "      <td>1.060696</td>\n",
       "      <td>-1.527653</td>\n",
       "      <td>0.337359</td>\n",
       "      <td>0.710017</td>\n",
       "      <td>1.049972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rio Grande do Norte - IDH  \\\n",
       "0                    -2.184058   \n",
       "1                    -2.147573   \n",
       "2                    -2.111089   \n",
       "3                    -2.074605   \n",
       "4                    -2.038120   \n",
       "..                         ...   \n",
       "187                   1.321156   \n",
       "188                   1.314269   \n",
       "189                   1.307381   \n",
       "190                   1.300494   \n",
       "191                   1.293607   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Rio Grande Do Norte - Produção de Cimento (t)  \\\n",
       "0                                        -1.183161   \n",
       "1                                        -1.192364   \n",
       "2                                        -1.193319   \n",
       "3                                        -1.188108   \n",
       "4                                        -1.175380   \n",
       "..                                             ...   \n",
       "187                                       0.389536   \n",
       "188                                       0.398528   \n",
       "189                                       0.414978   \n",
       "190                                       0.429834   \n",
       "191                                       0.437373   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Estadual  \\\n",
       "0                               -1.731345   \n",
       "1                               -1.711183   \n",
       "2                               -1.691021   \n",
       "3                               -1.670859   \n",
       "4                               -1.650697   \n",
       "..                                    ...   \n",
       "187                              1.102751   \n",
       "188                              1.092237   \n",
       "189                              1.081724   \n",
       "190                              1.071210   \n",
       "191                              1.060696   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Construção Civil  \\\n",
       "0                                       -0.778207   \n",
       "1                                       -0.728728   \n",
       "2                                       -0.679248   \n",
       "3                                       -0.629768   \n",
       "4                                       -0.580289   \n",
       "..                                            ...   \n",
       "187                                     -1.573216   \n",
       "188                                     -1.561825   \n",
       "189                                     -1.550435   \n",
       "190                                     -1.539044   \n",
       "191                                     -1.527653   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Per Capita  \\\n",
       "0                                 -2.784513   \n",
       "1                                 -2.703361   \n",
       "2                                 -2.622210   \n",
       "3                                 -2.541059   \n",
       "4                                 -2.459908   \n",
       "..                                      ...   \n",
       "187                                0.457957   \n",
       "188                                0.427807   \n",
       "189                                0.397658   \n",
       "190                                0.367509   \n",
       "191                                0.337359   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Preços de Mercado  \\\n",
       "0                                        -2.193066   \n",
       "1                                        -2.146603   \n",
       "2                                        -2.100140   \n",
       "3                                        -2.053677   \n",
       "4                                        -2.007214   \n",
       "..                                             ...   \n",
       "187                                       0.775635   \n",
       "188                                       0.759230   \n",
       "189                                       0.742826   \n",
       "190                                       0.726421   \n",
       "191                                       0.710017   \n",
       "\n",
       "     Rio Grande do Norte - Desemprego  \n",
       "0                           -0.876481  \n",
       "1                           -0.878896  \n",
       "2                           -0.881311  \n",
       "3                           -0.883727  \n",
       "4                           -0.886142  \n",
       "..                                ...  \n",
       "187                          1.052347  \n",
       "188                          1.051753  \n",
       "189                          1.051160  \n",
       "190                          1.050566  \n",
       "191                          1.049972  \n",
       "\n",
       "[192 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      32.845\n",
       "1      26.809\n",
       "2      34.465\n",
       "3      30.563\n",
       "4      32.574\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Rio Grande Do Norte - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rio Grande do Norte - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rio Grande Do Norte - Produção de Cimento (t)</th>\n",
       "      <th>Rio Grande do Norte - PIB - Estadual</th>\n",
       "      <th>Rio Grande do Norte - PIB - Construção Civil</th>\n",
       "      <th>Rio Grande do Norte - PIB - Per Capita</th>\n",
       "      <th>Rio Grande do Norte - PIB - Preços de Mercado</th>\n",
       "      <th>Rio Grande do Norte - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.184058</td>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.183161</td>\n",
       "      <td>-1.731345</td>\n",
       "      <td>-0.778207</td>\n",
       "      <td>-2.784513</td>\n",
       "      <td>-2.193066</td>\n",
       "      <td>-0.876481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.147573</td>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.192364</td>\n",
       "      <td>-1.711183</td>\n",
       "      <td>-0.728728</td>\n",
       "      <td>-2.703361</td>\n",
       "      <td>-2.146603</td>\n",
       "      <td>-0.878896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.111089</td>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.193319</td>\n",
       "      <td>-1.691021</td>\n",
       "      <td>-0.679248</td>\n",
       "      <td>-2.622210</td>\n",
       "      <td>-2.100140</td>\n",
       "      <td>-0.881311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.074605</td>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.188108</td>\n",
       "      <td>-1.670859</td>\n",
       "      <td>-0.629768</td>\n",
       "      <td>-2.541059</td>\n",
       "      <td>-2.053677</td>\n",
       "      <td>-0.883727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.038120</td>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.175380</td>\n",
       "      <td>-1.650697</td>\n",
       "      <td>-0.580289</td>\n",
       "      <td>-2.459908</td>\n",
       "      <td>-2.007214</td>\n",
       "      <td>-0.886142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.384282</td>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>1.046207</td>\n",
       "      <td>1.183768</td>\n",
       "      <td>-1.442416</td>\n",
       "      <td>0.625176</td>\n",
       "      <td>0.985411</td>\n",
       "      <td>1.213189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.382302</td>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>1.000373</td>\n",
       "      <td>1.187707</td>\n",
       "      <td>-1.461501</td>\n",
       "      <td>0.642268</td>\n",
       "      <td>0.990347</td>\n",
       "      <td>1.201976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.380323</td>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>0.957199</td>\n",
       "      <td>1.191647</td>\n",
       "      <td>-1.480587</td>\n",
       "      <td>0.659360</td>\n",
       "      <td>0.995283</td>\n",
       "      <td>1.190764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.378343</td>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>0.908410</td>\n",
       "      <td>1.195587</td>\n",
       "      <td>-1.499673</td>\n",
       "      <td>0.676453</td>\n",
       "      <td>1.000219</td>\n",
       "      <td>1.179551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.376364</td>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>0.876941</td>\n",
       "      <td>1.199527</td>\n",
       "      <td>-1.518759</td>\n",
       "      <td>0.693545</td>\n",
       "      <td>1.005155</td>\n",
       "      <td>1.168339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rio Grande do Norte - IDH  \\\n",
       "0                    -2.184058   \n",
       "1                    -2.147573   \n",
       "2                    -2.111089   \n",
       "3                    -2.074605   \n",
       "4                    -2.038120   \n",
       "..                         ...   \n",
       "157                   1.384282   \n",
       "158                   1.382302   \n",
       "159                   1.380323   \n",
       "160                   1.378343   \n",
       "161                   1.376364   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     Rio Grande Do Norte - Produção de Cimento (t)  \\\n",
       "0                                        -1.183161   \n",
       "1                                        -1.192364   \n",
       "2                                        -1.193319   \n",
       "3                                        -1.188108   \n",
       "4                                        -1.175380   \n",
       "..                                             ...   \n",
       "157                                       1.046207   \n",
       "158                                       1.000373   \n",
       "159                                       0.957199   \n",
       "160                                       0.908410   \n",
       "161                                       0.876941   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Estadual  \\\n",
       "0                               -1.731345   \n",
       "1                               -1.711183   \n",
       "2                               -1.691021   \n",
       "3                               -1.670859   \n",
       "4                               -1.650697   \n",
       "..                                    ...   \n",
       "157                              1.183768   \n",
       "158                              1.187707   \n",
       "159                              1.191647   \n",
       "160                              1.195587   \n",
       "161                              1.199527   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Construção Civil  \\\n",
       "0                                       -0.778207   \n",
       "1                                       -0.728728   \n",
       "2                                       -0.679248   \n",
       "3                                       -0.629768   \n",
       "4                                       -0.580289   \n",
       "..                                            ...   \n",
       "157                                     -1.442416   \n",
       "158                                     -1.461501   \n",
       "159                                     -1.480587   \n",
       "160                                     -1.499673   \n",
       "161                                     -1.518759   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Per Capita  \\\n",
       "0                                 -2.784513   \n",
       "1                                 -2.703361   \n",
       "2                                 -2.622210   \n",
       "3                                 -2.541059   \n",
       "4                                 -2.459908   \n",
       "..                                      ...   \n",
       "157                                0.625176   \n",
       "158                                0.642268   \n",
       "159                                0.659360   \n",
       "160                                0.676453   \n",
       "161                                0.693545   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Preços de Mercado  \\\n",
       "0                                        -2.193066   \n",
       "1                                        -2.146603   \n",
       "2                                        -2.100140   \n",
       "3                                        -2.053677   \n",
       "4                                        -2.007214   \n",
       "..                                             ...   \n",
       "157                                       0.985411   \n",
       "158                                       0.990347   \n",
       "159                                       0.995283   \n",
       "160                                       1.000219   \n",
       "161                                       1.005155   \n",
       "\n",
       "     Rio Grande do Norte - Desemprego  \n",
       "0                           -0.876481  \n",
       "1                           -0.878896  \n",
       "2                           -0.881311  \n",
       "3                           -0.883727  \n",
       "4                           -0.886142  \n",
       "..                                ...  \n",
       "157                          1.213189  \n",
       "158                          1.201976  \n",
       "159                          1.190764  \n",
       "160                          1.179551  \n",
       "161                          1.168339  \n",
       "\n",
       "[162 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      32.845\n",
       "1      26.809\n",
       "2      34.465\n",
       "3      30.563\n",
       "4      32.574\n",
       "        ...  \n",
       "157    52.722\n",
       "158    63.109\n",
       "159    49.356\n",
       "160    55.725\n",
       "161    50.796\n",
       "Name: Rio Grande Do Norte - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rio Grande do Norte - IDH</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Rio Grande Do Norte - Produção de Cimento (t)</th>\n",
       "      <th>Rio Grande do Norte - PIB - Estadual</th>\n",
       "      <th>Rio Grande do Norte - PIB - Construção Civil</th>\n",
       "      <th>Rio Grande do Norte - PIB - Per Capita</th>\n",
       "      <th>Rio Grande do Norte - PIB - Preços de Mercado</th>\n",
       "      <th>Rio Grande do Norte - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.374384</td>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>0.848293</td>\n",
       "      <td>1.203467</td>\n",
       "      <td>-1.537845</td>\n",
       "      <td>0.710637</td>\n",
       "      <td>1.010091</td>\n",
       "      <td>1.157126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1.372404</td>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>0.824099</td>\n",
       "      <td>1.207407</td>\n",
       "      <td>-1.556931</td>\n",
       "      <td>0.727729</td>\n",
       "      <td>1.015027</td>\n",
       "      <td>1.145914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1.370425</td>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>0.799099</td>\n",
       "      <td>1.211347</td>\n",
       "      <td>-1.576017</td>\n",
       "      <td>0.744821</td>\n",
       "      <td>1.019963</td>\n",
       "      <td>1.134701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.368445</td>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>0.777768</td>\n",
       "      <td>1.215287</td>\n",
       "      <td>-1.595102</td>\n",
       "      <td>0.761913</td>\n",
       "      <td>1.024899</td>\n",
       "      <td>1.123489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1.366466</td>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>0.760884</td>\n",
       "      <td>1.219226</td>\n",
       "      <td>-1.614188</td>\n",
       "      <td>0.779005</td>\n",
       "      <td>1.029835</td>\n",
       "      <td>1.112277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.364486</td>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>0.735834</td>\n",
       "      <td>1.223166</td>\n",
       "      <td>-1.633274</td>\n",
       "      <td>0.796097</td>\n",
       "      <td>1.034770</td>\n",
       "      <td>1.101064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.362506</td>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>0.707114</td>\n",
       "      <td>1.227106</td>\n",
       "      <td>-1.652360</td>\n",
       "      <td>0.813189</td>\n",
       "      <td>1.039706</td>\n",
       "      <td>1.089852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.363078</td>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>0.679884</td>\n",
       "      <td>1.222876</td>\n",
       "      <td>-1.652409</td>\n",
       "      <td>0.801173</td>\n",
       "      <td>1.027270</td>\n",
       "      <td>1.087072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1.363650</td>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>0.645700</td>\n",
       "      <td>1.218646</td>\n",
       "      <td>-1.652458</td>\n",
       "      <td>0.789158</td>\n",
       "      <td>1.014833</td>\n",
       "      <td>1.084293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.364221</td>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>0.600550</td>\n",
       "      <td>1.214416</td>\n",
       "      <td>-1.652508</td>\n",
       "      <td>0.777142</td>\n",
       "      <td>1.002396</td>\n",
       "      <td>1.081514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.364793</td>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>0.571033</td>\n",
       "      <td>1.210186</td>\n",
       "      <td>-1.652557</td>\n",
       "      <td>0.765127</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>1.078735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.365365</td>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>0.530241</td>\n",
       "      <td>1.205956</td>\n",
       "      <td>-1.652606</td>\n",
       "      <td>0.753111</td>\n",
       "      <td>0.977523</td>\n",
       "      <td>1.075956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.365936</td>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>0.502564</td>\n",
       "      <td>1.201726</td>\n",
       "      <td>-1.652655</td>\n",
       "      <td>0.741096</td>\n",
       "      <td>0.965086</td>\n",
       "      <td>1.073177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.366508</td>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>0.474533</td>\n",
       "      <td>1.197496</td>\n",
       "      <td>-1.652705</td>\n",
       "      <td>0.729080</td>\n",
       "      <td>0.952649</td>\n",
       "      <td>1.070398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.367080</td>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>0.450230</td>\n",
       "      <td>1.193266</td>\n",
       "      <td>-1.652754</td>\n",
       "      <td>0.717065</td>\n",
       "      <td>0.940213</td>\n",
       "      <td>1.067619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.367651</td>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>0.429435</td>\n",
       "      <td>1.189036</td>\n",
       "      <td>-1.652803</td>\n",
       "      <td>0.705049</td>\n",
       "      <td>0.927776</td>\n",
       "      <td>1.064840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.368223</td>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>0.411155</td>\n",
       "      <td>1.184806</td>\n",
       "      <td>-1.652853</td>\n",
       "      <td>0.693033</td>\n",
       "      <td>0.915339</td>\n",
       "      <td>1.062060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.368795</td>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>0.394670</td>\n",
       "      <td>1.180576</td>\n",
       "      <td>-1.652902</td>\n",
       "      <td>0.681018</td>\n",
       "      <td>0.902902</td>\n",
       "      <td>1.059281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.369366</td>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>0.382559</td>\n",
       "      <td>1.176346</td>\n",
       "      <td>-1.652951</td>\n",
       "      <td>0.669002</td>\n",
       "      <td>0.890466</td>\n",
       "      <td>1.056502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.362479</td>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>0.372358</td>\n",
       "      <td>1.165833</td>\n",
       "      <td>-1.641560</td>\n",
       "      <td>0.638853</td>\n",
       "      <td>0.874061</td>\n",
       "      <td>1.055909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.355592</td>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>0.363682</td>\n",
       "      <td>1.155319</td>\n",
       "      <td>-1.630170</td>\n",
       "      <td>0.608704</td>\n",
       "      <td>0.857657</td>\n",
       "      <td>1.055315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.348705</td>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>0.353036</td>\n",
       "      <td>1.144805</td>\n",
       "      <td>-1.618779</td>\n",
       "      <td>0.578554</td>\n",
       "      <td>0.841252</td>\n",
       "      <td>1.054721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.341817</td>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>0.350432</td>\n",
       "      <td>1.134292</td>\n",
       "      <td>-1.607388</td>\n",
       "      <td>0.548405</td>\n",
       "      <td>0.824848</td>\n",
       "      <td>1.054128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.334930</td>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>0.370695</td>\n",
       "      <td>1.123778</td>\n",
       "      <td>-1.595997</td>\n",
       "      <td>0.518256</td>\n",
       "      <td>0.808443</td>\n",
       "      <td>1.053534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.328043</td>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>0.378946</td>\n",
       "      <td>1.113264</td>\n",
       "      <td>-1.584607</td>\n",
       "      <td>0.488106</td>\n",
       "      <td>0.792039</td>\n",
       "      <td>1.052940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.321156</td>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>0.389536</td>\n",
       "      <td>1.102751</td>\n",
       "      <td>-1.573216</td>\n",
       "      <td>0.457957</td>\n",
       "      <td>0.775635</td>\n",
       "      <td>1.052347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.314269</td>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>0.398528</td>\n",
       "      <td>1.092237</td>\n",
       "      <td>-1.561825</td>\n",
       "      <td>0.427807</td>\n",
       "      <td>0.759230</td>\n",
       "      <td>1.051753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.307381</td>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>0.414978</td>\n",
       "      <td>1.081724</td>\n",
       "      <td>-1.550435</td>\n",
       "      <td>0.397658</td>\n",
       "      <td>0.742826</td>\n",
       "      <td>1.051160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.300494</td>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>0.429834</td>\n",
       "      <td>1.071210</td>\n",
       "      <td>-1.539044</td>\n",
       "      <td>0.367509</td>\n",
       "      <td>0.726421</td>\n",
       "      <td>1.050566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.293607</td>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>0.437373</td>\n",
       "      <td>1.060696</td>\n",
       "      <td>-1.527653</td>\n",
       "      <td>0.337359</td>\n",
       "      <td>0.710017</td>\n",
       "      <td>1.049972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rio Grande do Norte - IDH  \\\n",
       "162                   1.374384   \n",
       "163                   1.372404   \n",
       "164                   1.370425   \n",
       "165                   1.368445   \n",
       "166                   1.366466   \n",
       "167                   1.364486   \n",
       "168                   1.362506   \n",
       "169                   1.363078   \n",
       "170                   1.363650   \n",
       "171                   1.364221   \n",
       "172                   1.364793   \n",
       "173                   1.365365   \n",
       "174                   1.365936   \n",
       "175                   1.366508   \n",
       "176                   1.367080   \n",
       "177                   1.367651   \n",
       "178                   1.368223   \n",
       "179                   1.368795   \n",
       "180                   1.369366   \n",
       "181                   1.362479   \n",
       "182                   1.355592   \n",
       "183                   1.348705   \n",
       "184                   1.341817   \n",
       "185                   1.334930   \n",
       "186                   1.328043   \n",
       "187                   1.321156   \n",
       "188                   1.314269   \n",
       "189                   1.307381   \n",
       "190                   1.300494   \n",
       "191                   1.293607   \n",
       "\n",
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162                                         -0.601510   \n",
       "163                                         -0.786068   \n",
       "164                                         -0.830387   \n",
       "165                                         -0.801089   \n",
       "166                                         -0.959917   \n",
       "167                                         -1.022309   \n",
       "168                                         -1.074401   \n",
       "169                                         -1.119597   \n",
       "170                                         -1.078648   \n",
       "171                                         -1.055426   \n",
       "172                                         -1.101053   \n",
       "173                                         -1.211370   \n",
       "174                                         -1.157198   \n",
       "175                                         -1.223444   \n",
       "176                                         -1.311519   \n",
       "177                                         -1.362602   \n",
       "178                                         -1.380125   \n",
       "179                                         -1.219296   \n",
       "180                                         -1.300284   \n",
       "181                                         -1.336476   \n",
       "182                                         -1.415774   \n",
       "183                                         -1.526021   \n",
       "184                                         -1.681806   \n",
       "185                                         -1.735167   \n",
       "186                                         -1.962315   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "162                                0.763466  -1.213929   \n",
       "163                                0.752299  -1.292173   \n",
       "164                                0.741131  -1.324219   \n",
       "165                                0.729964  -1.344446   \n",
       "166                                0.718796  -1.381638   \n",
       "167                                0.707629  -1.411208   \n",
       "168                                0.696461  -1.412953   \n",
       "169                                0.681823  -1.491464   \n",
       "170                                0.667184  -1.573805   \n",
       "171                                0.652545  -1.564950   \n",
       "172                                0.637906  -1.581584   \n",
       "173                                0.623268  -1.565976   \n",
       "174                                0.608629  -1.648556   \n",
       "175                                0.593990  -1.650049   \n",
       "176                                0.579351  -1.653957   \n",
       "177                                0.564713  -1.652572   \n",
       "178                                0.550074  -1.715349   \n",
       "179                                0.535435  -1.750917   \n",
       "180                                0.520796  -1.718448   \n",
       "181                                0.501996  -1.733426   \n",
       "182                                0.483195  -1.729362   \n",
       "183                                0.464395  -1.748544   \n",
       "184                                0.445594  -1.778060   \n",
       "185                                0.426794  -1.773710   \n",
       "186                                0.407993  -1.757007   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     Rio Grande Do Norte - Produção de Cimento (t)  \\\n",
       "162                                       0.848293   \n",
       "163                                       0.824099   \n",
       "164                                       0.799099   \n",
       "165                                       0.777768   \n",
       "166                                       0.760884   \n",
       "167                                       0.735834   \n",
       "168                                       0.707114   \n",
       "169                                       0.679884   \n",
       "170                                       0.645700   \n",
       "171                                       0.600550   \n",
       "172                                       0.571033   \n",
       "173                                       0.530241   \n",
       "174                                       0.502564   \n",
       "175                                       0.474533   \n",
       "176                                       0.450230   \n",
       "177                                       0.429435   \n",
       "178                                       0.411155   \n",
       "179                                       0.394670   \n",
       "180                                       0.382559   \n",
       "181                                       0.372358   \n",
       "182                                       0.363682   \n",
       "183                                       0.353036   \n",
       "184                                       0.350432   \n",
       "185                                       0.370695   \n",
       "186                                       0.378946   \n",
       "187                                       0.389536   \n",
       "188                                       0.398528   \n",
       "189                                       0.414978   \n",
       "190                                       0.429834   \n",
       "191                                       0.437373   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Estadual  \\\n",
       "162                              1.203467   \n",
       "163                              1.207407   \n",
       "164                              1.211347   \n",
       "165                              1.215287   \n",
       "166                              1.219226   \n",
       "167                              1.223166   \n",
       "168                              1.227106   \n",
       "169                              1.222876   \n",
       "170                              1.218646   \n",
       "171                              1.214416   \n",
       "172                              1.210186   \n",
       "173                              1.205956   \n",
       "174                              1.201726   \n",
       "175                              1.197496   \n",
       "176                              1.193266   \n",
       "177                              1.189036   \n",
       "178                              1.184806   \n",
       "179                              1.180576   \n",
       "180                              1.176346   \n",
       "181                              1.165833   \n",
       "182                              1.155319   \n",
       "183                              1.144805   \n",
       "184                              1.134292   \n",
       "185                              1.123778   \n",
       "186                              1.113264   \n",
       "187                              1.102751   \n",
       "188                              1.092237   \n",
       "189                              1.081724   \n",
       "190                              1.071210   \n",
       "191                              1.060696   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Construção Civil  \\\n",
       "162                                     -1.537845   \n",
       "163                                     -1.556931   \n",
       "164                                     -1.576017   \n",
       "165                                     -1.595102   \n",
       "166                                     -1.614188   \n",
       "167                                     -1.633274   \n",
       "168                                     -1.652360   \n",
       "169                                     -1.652409   \n",
       "170                                     -1.652458   \n",
       "171                                     -1.652508   \n",
       "172                                     -1.652557   \n",
       "173                                     -1.652606   \n",
       "174                                     -1.652655   \n",
       "175                                     -1.652705   \n",
       "176                                     -1.652754   \n",
       "177                                     -1.652803   \n",
       "178                                     -1.652853   \n",
       "179                                     -1.652902   \n",
       "180                                     -1.652951   \n",
       "181                                     -1.641560   \n",
       "182                                     -1.630170   \n",
       "183                                     -1.618779   \n",
       "184                                     -1.607388   \n",
       "185                                     -1.595997   \n",
       "186                                     -1.584607   \n",
       "187                                     -1.573216   \n",
       "188                                     -1.561825   \n",
       "189                                     -1.550435   \n",
       "190                                     -1.539044   \n",
       "191                                     -1.527653   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Per Capita  \\\n",
       "162                                0.710637   \n",
       "163                                0.727729   \n",
       "164                                0.744821   \n",
       "165                                0.761913   \n",
       "166                                0.779005   \n",
       "167                                0.796097   \n",
       "168                                0.813189   \n",
       "169                                0.801173   \n",
       "170                                0.789158   \n",
       "171                                0.777142   \n",
       "172                                0.765127   \n",
       "173                                0.753111   \n",
       "174                                0.741096   \n",
       "175                                0.729080   \n",
       "176                                0.717065   \n",
       "177                                0.705049   \n",
       "178                                0.693033   \n",
       "179                                0.681018   \n",
       "180                                0.669002   \n",
       "181                                0.638853   \n",
       "182                                0.608704   \n",
       "183                                0.578554   \n",
       "184                                0.548405   \n",
       "185                                0.518256   \n",
       "186                                0.488106   \n",
       "187                                0.457957   \n",
       "188                                0.427807   \n",
       "189                                0.397658   \n",
       "190                                0.367509   \n",
       "191                                0.337359   \n",
       "\n",
       "     Rio Grande do Norte - PIB - Preços de Mercado  \\\n",
       "162                                       1.010091   \n",
       "163                                       1.015027   \n",
       "164                                       1.019963   \n",
       "165                                       1.024899   \n",
       "166                                       1.029835   \n",
       "167                                       1.034770   \n",
       "168                                       1.039706   \n",
       "169                                       1.027270   \n",
       "170                                       1.014833   \n",
       "171                                       1.002396   \n",
       "172                                       0.989959   \n",
       "173                                       0.977523   \n",
       "174                                       0.965086   \n",
       "175                                       0.952649   \n",
       "176                                       0.940213   \n",
       "177                                       0.927776   \n",
       "178                                       0.915339   \n",
       "179                                       0.902902   \n",
       "180                                       0.890466   \n",
       "181                                       0.874061   \n",
       "182                                       0.857657   \n",
       "183                                       0.841252   \n",
       "184                                       0.824848   \n",
       "185                                       0.808443   \n",
       "186                                       0.792039   \n",
       "187                                       0.775635   \n",
       "188                                       0.759230   \n",
       "189                                       0.742826   \n",
       "190                                       0.726421   \n",
       "191                                       0.710017   \n",
       "\n",
       "     Rio Grande do Norte - Desemprego  \n",
       "162                          1.157126  \n",
       "163                          1.145914  \n",
       "164                          1.134701  \n",
       "165                          1.123489  \n",
       "166                          1.112277  \n",
       "167                          1.101064  \n",
       "168                          1.089852  \n",
       "169                          1.087072  \n",
       "170                          1.084293  \n",
       "171                          1.081514  \n",
       "172                          1.078735  \n",
       "173                          1.075956  \n",
       "174                          1.073177  \n",
       "175                          1.070398  \n",
       "176                          1.067619  \n",
       "177                          1.064840  \n",
       "178                          1.062060  \n",
       "179                          1.059281  \n",
       "180                          1.056502  \n",
       "181                          1.055909  \n",
       "182                          1.055315  \n",
       "183                          1.054721  \n",
       "184                          1.054128  \n",
       "185                          1.053534  \n",
       "186                          1.052940  \n",
       "187                          1.052347  \n",
       "188                          1.051753  \n",
       "189                          1.051160  \n",
       "190                          1.050566  \n",
       "191                          1.049972  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    48.750\n",
       "163    59.738\n",
       "164    60.303\n",
       "165    51.009\n",
       "166    48.874\n",
       "167    48.506\n",
       "168    42.721\n",
       "169    32.801\n",
       "170    37.638\n",
       "171    37.358\n",
       "172    31.339\n",
       "173    45.311\n",
       "174    42.085\n",
       "175    48.520\n",
       "176    41.365\n",
       "177    43.813\n",
       "178    43.816\n",
       "179    38.245\n",
       "180    46.081\n",
       "181    38.703\n",
       "182    36.037\n",
       "183    38.430\n",
       "184    44.471\n",
       "185    37.884\n",
       "186    51.585\n",
       "187    54.306\n",
       "188    52.511\n",
       "189    59.472\n",
       "190    54.022\n",
       "191    49.791\n",
       "Name: Rio Grande Do Norte - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    train, train_val = validation_splitter(train_input, 8)\n",
    "    target,target_val = validation_splitter(train_target, 8)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val, target_val),\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1915252632, 3219293133, 3285064327, 462069691, 2282234682, 418808632, 935154646, 184270058, 553343776, 2964421840, 4233998320, 1966993840, 2441000978, 2076917689, 3099940549, 103510955, 1425340031, 2539920630, 240577878, 1546965392, 1316517200, 2328839478, 1280919727, 315834237, 911295073]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 20.079696655273438\n",
      "winner_seed: 1915252632\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 20.630374908447266\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 18.650821685791016\n",
      "winner_seed: 3285064327\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 15.470341682434082\n",
      "winner_seed: 462069691\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 15.458224296569824\n",
      "winner_seed: 2282234682\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 15.547518730163574\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 16.271448135375977\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 14.114107131958008\n",
      "winner_seed: 184270058\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 61.326148986816406\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 13.25575065612793\n",
      "winner_seed: 2964421840\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 13.988677978515625\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 15.282443046569824\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 18.84673500061035\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 16.404287338256836\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 64.15779113769531\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 14.651199340820312\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 18.538610458374023\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 17.555641174316406\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 17.158222198486328\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 16.167621612548828\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 15.100787162780762\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 14.118532180786133\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 18.022502899169922\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 63.47306442260742\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 16.47935676574707\n",
      "\n",
      "\n",
      "final_seed: 2964421840\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3733.3223 - val_loss: 3518.5591\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3102.3816 - val_loss: 2566.7329\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2870.5706 - val_loss: 472.2202\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2395.6458 - val_loss: 164.3064\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 194.8172 - val_loss: 75.0036\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 71.7318 - val_loss: 47.8899\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 53.6750 - val_loss: 49.0841\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 47.4989 - val_loss: 88.9597\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 56.9861 - val_loss: 45.0438\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 51.7410 - val_loss: 35.8127\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 43.3468 - val_loss: 50.2285\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 48.9493 - val_loss: 45.2628\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 47.0578 - val_loss: 110.1345\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 65.3444 - val_loss: 40.9959\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 49.9188 - val_loss: 53.2624\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 44.4157 - val_loss: 98.5769\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 49.0052 - val_loss: 37.8799\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 46.8265 - val_loss: 45.0265\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 42.6014 - val_loss: 45.7485\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 42.6058 - val_loss: 42.7674\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 41.4841 - val_loss: 61.7678\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 41.9914 - val_loss: 45.3858\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 40.1529 - val_loss: 57.9879\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 39.2276 - val_loss: 98.8957\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 54.6876 - val_loss: 44.6983\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 40.3195 - val_loss: 58.9057\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 39.2731 - val_loss: 47.3254\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 39.5521 - val_loss: 59.2618\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 37.6125 - val_loss: 36.5381\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 37.0380 - val_loss: 39.6634\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 39.9467 - val_loss: 41.1938\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 38.1673 - val_loss: 41.9572\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 38.1191 - val_loss: 43.7899\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 37.5304 - val_loss: 55.6568\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 33.5600 - val_loss: 44.8285\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 32.6738 - val_loss: 33.8818\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 37.7315 - val_loss: 41.3481\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 36.7847 - val_loss: 42.3558\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 32.6346 - val_loss: 87.4254\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 37.0628 - val_loss: 66.7889\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 37.5262 - val_loss: 43.8631\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 34.1186 - val_loss: 31.6254\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.8592 - val_loss: 53.0331\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 32.6948 - val_loss: 48.9644\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 49.0117 - val_loss: 53.6044\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 35.6742 - val_loss: 51.6934\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 35.2255 - val_loss: 62.8364\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 35.3318 - val_loss: 42.0331\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 34.3281 - val_loss: 36.2159\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 33.6751 - val_loss: 64.1545\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 34.1668 - val_loss: 48.4201\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 33.8115 - val_loss: 51.1625\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 42.9761 - val_loss: 56.7403\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 32.8540 - val_loss: 42.1203\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.7208 - val_loss: 41.5474\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.5007 - val_loss: 35.5803\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.2755 - val_loss: 33.3039\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.2044 - val_loss: 46.9049\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.5380 - val_loss: 40.6005\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.6277 - val_loss: 60.0814\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.1619 - val_loss: 40.4978\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.4321 - val_loss: 36.5530\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.7591 - val_loss: 48.6891\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.3105 - val_loss: 47.6389\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 34.5137 - val_loss: 87.1176\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 36.6791 - val_loss: 30.0983\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 36.3487 - val_loss: 36.3047\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 32.1818 - val_loss: 34.8428\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.0799 - val_loss: 47.6380\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 33.0560 - val_loss: 36.9116\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 32.1580 - val_loss: 33.7880\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.2935 - val_loss: 38.0638\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.2498 - val_loss: 53.1591\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.8472 - val_loss: 41.1537\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.8192 - val_loss: 36.9301\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.9222 - val_loss: 35.9401\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 32.8652 - val_loss: 37.6943\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.0121 - val_loss: 39.3022\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.1913 - val_loss: 24.4506\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.0589 - val_loss: 34.3048\n",
      "Epoch 81/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 30.9553 - val_loss: 37.9672\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.0897 - val_loss: 32.8980\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.9472 - val_loss: 41.2586\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.5076 - val_loss: 29.7438\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.6915 - val_loss: 39.3659\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.7912 - val_loss: 26.7785\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.0115 - val_loss: 57.9322\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 34.4597 - val_loss: 29.4391\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 34.4791 - val_loss: 47.8388\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 33.2040 - val_loss: 25.2185\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.1274 - val_loss: 65.2160\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 34.5981 - val_loss: 60.4647\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 32.2642 - val_loss: 30.9768\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.2803 - val_loss: 72.2857\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 42.1087 - val_loss: 41.3416\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 34.9069 - val_loss: 46.3899\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.9138 - val_loss: 27.7997\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.0225 - val_loss: 28.3316\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.3778 - val_loss: 31.3398\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.1542 - val_loss: 40.8022\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.6244 - val_loss: 28.9754\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.5247 - val_loss: 32.7647\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.3137 - val_loss: 30.0277\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.3648 - val_loss: 39.0774\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.5108 - val_loss: 32.4793\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.1152 - val_loss: 26.8376\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.2295 - val_loss: 29.6041\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.7005 - val_loss: 28.8966\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.7558 - val_loss: 51.3544\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 34.2371 - val_loss: 37.0444\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.8055 - val_loss: 35.0373\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.4319 - val_loss: 28.9841\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.1056 - val_loss: 40.2475\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.5105 - val_loss: 28.8391\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.9582 - val_loss: 30.0648\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.4900 - val_loss: 43.9710\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.5417 - val_loss: 23.0853\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.0795 - val_loss: 50.8707\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.7908 - val_loss: 35.8004\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.0242 - val_loss: 26.6413\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.9082 - val_loss: 42.8785\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.3385 - val_loss: 28.7609\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.1853 - val_loss: 49.8040\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 35.4331 - val_loss: 24.1764\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.8715 - val_loss: 33.4716\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.4925 - val_loss: 33.2706\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.1930 - val_loss: 35.1422\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.5414 - val_loss: 35.5988\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.1203 - val_loss: 28.2836\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.1610 - val_loss: 28.0256\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.0972 - val_loss: 25.2321\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.6475 - val_loss: 41.7682\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.6916 - val_loss: 32.8364\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.6746 - val_loss: 54.3684\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.5328 - val_loss: 30.9083\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.8354 - val_loss: 20.2261\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.9564 - val_loss: 38.4090\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.3641 - val_loss: 28.0295\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.6211 - val_loss: 46.3557\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.1650 - val_loss: 44.1799\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.1872 - val_loss: 60.8941\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 33.3120 - val_loss: 45.4265\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.8749 - val_loss: 37.6176\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.6891 - val_loss: 61.0288\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.2629 - val_loss: 38.9317\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.8974 - val_loss: 42.3411\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.0203 - val_loss: 31.8569\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.7062 - val_loss: 35.7358\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.3242 - val_loss: 33.3076\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.3316 - val_loss: 35.2243\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.8051 - val_loss: 29.6548\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.8017 - val_loss: 37.0512\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.0230 - val_loss: 41.4368\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.2162 - val_loss: 36.7830\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.0670 - val_loss: 30.2900\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.0917 - val_loss: 32.7539\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 436.7934 - val_loss: 58.7110\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 41.2875 - val_loss: 56.3904\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.8163 - val_loss: 34.8379\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 33.3867 - val_loss: 48.6298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.7627 - val_loss: 43.1920\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.5027 - val_loss: 34.7795\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.7532 - val_loss: 35.9709\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.7314 - val_loss: 48.2101\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 32.9259 - val_loss: 37.5144\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.2027 - val_loss: 36.4754\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.6799 - val_loss: 42.0627\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 31.0715 - val_loss: 33.3981\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.2359 - val_loss: 32.1019\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.2435 - val_loss: 31.2497\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.8809 - val_loss: 35.9304\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.9776 - val_loss: 43.6095\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.8946 - val_loss: 53.7487\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.5877 - val_loss: 27.3458\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 34.4529 - val_loss: 57.0608\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.1967 - val_loss: 53.2398\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.8330 - val_loss: 26.1984\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.3001 - val_loss: 21.9043\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.9107 - val_loss: 23.0658\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.0233 - val_loss: 41.9863\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.4087 - val_loss: 42.4423\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.4004 - val_loss: 22.3018\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.8753 - val_loss: 32.4101\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.2406 - val_loss: 44.3797\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.2671 - val_loss: 37.8180\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4401 - val_loss: 41.2275\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.3907 - val_loss: 47.4726\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.9736 - val_loss: 34.4008\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.4314 - val_loss: 25.3218\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.2804 - val_loss: 40.4659\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.3389 - val_loss: 33.9024\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.0203 - val_loss: 39.6399\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.9171 - val_loss: 49.6034\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.2087 - val_loss: 35.1794\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.2615 - val_loss: 36.6361\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.4287 - val_loss: 46.6474\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.5292 - val_loss: 43.9838\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.8698 - val_loss: 29.0002\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.1935 - val_loss: 26.0308\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.1853 - val_loss: 27.4933\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.9001 - val_loss: 44.5127\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.8080 - val_loss: 46.6102\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.0775 - val_loss: 24.3866\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.6225 - val_loss: 34.4577\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.4247 - val_loss: 21.2695\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.7544 - val_loss: 24.4622\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.5998 - val_loss: 34.7693\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.2200 - val_loss: 26.7612\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.5506 - val_loss: 23.9765\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.4845 - val_loss: 30.3898\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.8124 - val_loss: 31.7444\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.6879 - val_loss: 24.3348\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.6600 - val_loss: 25.2853\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.7675 - val_loss: 47.3151\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.9694 - val_loss: 28.8898\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.6425 - val_loss: 29.4484\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.0023 - val_loss: 40.5362\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.7512 - val_loss: 40.6211\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.7732 - val_loss: 27.0836\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.0772 - val_loss: 27.6585\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.2665 - val_loss: 29.0657\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.9318 - val_loss: 36.0466\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.4238 - val_loss: 31.8170\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.3572 - val_loss: 43.1523\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.4578 - val_loss: 30.5453\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.5710 - val_loss: 32.4261\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.3727 - val_loss: 43.2114\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.3194 - val_loss: 49.9847\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.2848 - val_loss: 62.2531\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.9631 - val_loss: 27.5068\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.5699 - val_loss: 41.9194\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.6668 - val_loss: 27.4404\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.8277 - val_loss: 32.5957\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.3565 - val_loss: 49.0065\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.7407 - val_loss: 45.9313\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.4065 - val_loss: 38.1860\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.7145 - val_loss: 38.4037\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.8544 - val_loss: 29.2330\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.9704 - val_loss: 34.3232\n",
      "Epoch 240/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 25.8746 - val_loss: 46.0185\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.5821 - val_loss: 39.1435\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.5417 - val_loss: 27.0233\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.2347 - val_loss: 25.2009\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.7894 - val_loss: 36.1856\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.9562 - val_loss: 39.9470\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.6973 - val_loss: 42.3468\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.2315 - val_loss: 26.2950\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 31.7468 - val_loss: 31.5635\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.8926 - val_loss: 40.0012\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.4172 - val_loss: 39.2506\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.8034 - val_loss: 24.4496\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.4644 - val_loss: 29.6439\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6825 - val_loss: 35.2360\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.2032 - val_loss: 48.3153\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.2130 - val_loss: 42.2885\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.6863 - val_loss: 35.8824\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.5630 - val_loss: 36.5237\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.0284 - val_loss: 32.8489\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0716 - val_loss: 39.3754\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.5992 - val_loss: 57.4487\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.3173 - val_loss: 29.6623\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.9715 - val_loss: 32.9476\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4331 - val_loss: 26.0608\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.1486 - val_loss: 38.7299\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.0189 - val_loss: 25.5463\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1635 - val_loss: 36.6456\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.4520 - val_loss: 42.1836\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.6800 - val_loss: 43.6814\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.2010 - val_loss: 28.9094\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.8593 - val_loss: 31.3310\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.4473 - val_loss: 38.0908\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.6593 - val_loss: 40.3473\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.8204 - val_loss: 28.5648\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.7075 - val_loss: 26.0845\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.9152 - val_loss: 26.8101\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.2281 - val_loss: 22.5127\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.5396 - val_loss: 28.0705\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.9657 - val_loss: 25.6988\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.1319 - val_loss: 26.6710\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.1837 - val_loss: 21.8830\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.3046 - val_loss: 25.2878\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.0874 - val_loss: 22.4100\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.1761 - val_loss: 23.3717\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.1755 - val_loss: 22.2877\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.6152 - val_loss: 31.7786\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.1081 - val_loss: 31.3733\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.4903 - val_loss: 22.0494\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.5136 - val_loss: 31.9575\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.5405 - val_loss: 36.3387\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.4611 - val_loss: 34.6529\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.3378 - val_loss: 20.4117\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.0425 - val_loss: 55.8529\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.0843 - val_loss: 26.2517\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.2546 - val_loss: 24.0157\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.0617 - val_loss: 36.4738\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.0098 - val_loss: 28.0496\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.8876 - val_loss: 30.0081\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.8195 - val_loss: 23.8317\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.0037 - val_loss: 26.7383\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.0968 - val_loss: 32.8836\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.5636 - val_loss: 33.2380\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.1610 - val_loss: 26.6624\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.1479 - val_loss: 60.2062\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.2138 - val_loss: 30.1132\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.5192 - val_loss: 21.0669\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.2288 - val_loss: 27.9692\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.3219 - val_loss: 41.6270\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.1237 - val_loss: 39.8564\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.6791 - val_loss: 42.2505\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 37.0602 - val_loss: 52.6858\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.7904 - val_loss: 29.1765\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.8635 - val_loss: 45.0395\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 66.9168 - val_loss: 23.5229\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.2971 - val_loss: 38.0114\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.7403 - val_loss: 35.4977\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.1979 - val_loss: 27.3170\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.1053 - val_loss: 25.3895\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.5704 - val_loss: 23.6711\n",
      "Epoch 319/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 22.7850 - val_loss: 22.1702\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.6263 - val_loss: 23.6501\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.6974 - val_loss: 34.2867\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.4719 - val_loss: 31.3273\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.2425 - val_loss: 24.8050\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.4888 - val_loss: 36.3215\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.8529 - val_loss: 34.8729\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.0976 - val_loss: 31.4468\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.5414 - val_loss: 25.0284\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.5853 - val_loss: 24.3692\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.6100 - val_loss: 25.9283\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.4480 - val_loss: 18.5673\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.8809 - val_loss: 37.9067\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.4632 - val_loss: 33.3831\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.9801 - val_loss: 18.1944\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.7484 - val_loss: 25.5114\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.2919 - val_loss: 28.2381\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.6227 - val_loss: 36.4922\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.3181 - val_loss: 25.8467\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.2113 - val_loss: 42.8863\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.9625 - val_loss: 33.8142\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.0497 - val_loss: 32.7430\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.9163 - val_loss: 30.6430\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.9223 - val_loss: 36.7019\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.8106 - val_loss: 40.6076\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.5872 - val_loss: 46.3162\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.6640 - val_loss: 39.5579\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.3587 - val_loss: 29.7804\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.0799 - val_loss: 22.5956\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.4041 - val_loss: 25.6818\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.3330 - val_loss: 26.5048\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.4306 - val_loss: 29.2392\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.6815 - val_loss: 26.9384\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.1782 - val_loss: 28.1641\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7534 - val_loss: 30.7497\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.7560 - val_loss: 22.7813\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.7627 - val_loss: 39.7370\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.6132 - val_loss: 18.4374\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.7687 - val_loss: 29.5967\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3365 - val_loss: 17.8570\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.3470 - val_loss: 26.0648\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.4871 - val_loss: 21.8259\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.5048 - val_loss: 22.4270\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8355 - val_loss: 23.8021\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.5579 - val_loss: 50.2856\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.4459 - val_loss: 43.2262\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.3876 - val_loss: 20.5588\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.2664 - val_loss: 30.1733\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.6265 - val_loss: 23.4540\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.8195 - val_loss: 17.5691\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.1927 - val_loss: 22.6855\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.4588 - val_loss: 24.2578\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.8623 - val_loss: 30.0129\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.3365 - val_loss: 32.8808\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.7743 - val_loss: 21.0633\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.1355 - val_loss: 25.4512\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9028 - val_loss: 39.7621\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7395 - val_loss: 32.4447\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.5778 - val_loss: 40.5430\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.5991 - val_loss: 38.4846\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.9615 - val_loss: 32.2442\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6370 - val_loss: 23.4842\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.2285 - val_loss: 36.0621\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.7951 - val_loss: 38.9722\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.5159 - val_loss: 28.1776\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.0170 - val_loss: 21.8748\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.1295 - val_loss: 52.5579\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.3420 - val_loss: 33.8868\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.8549 - val_loss: 37.5842\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.8737 - val_loss: 41.5344\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.2426 - val_loss: 35.3786\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.6123 - val_loss: 31.8937\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.6756 - val_loss: 35.3784\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.8820 - val_loss: 24.6399\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.3050 - val_loss: 30.6875\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.6680 - val_loss: 29.5441\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0310 - val_loss: 33.7689\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.1226 - val_loss: 26.9496\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.9684 - val_loss: 38.0734\n",
      "Epoch 398/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 20.2862 - val_loss: 28.3653\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.0356 - val_loss: 23.6987\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1210 - val_loss: 24.5647\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3979 - val_loss: 21.1605\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1189 - val_loss: 33.6126\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.8986 - val_loss: 22.6960\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.8905 - val_loss: 26.0696\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.9673 - val_loss: 31.0213\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.3829 - val_loss: 21.5228\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.6638 - val_loss: 22.6121\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.6078 - val_loss: 29.2334\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.0044 - val_loss: 35.8758\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.0941 - val_loss: 32.7913\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.8236 - val_loss: 45.5383\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.7151 - val_loss: 47.0268\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.0822 - val_loss: 20.0863\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.2642 - val_loss: 31.4845\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.1288 - val_loss: 39.8920\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.0428 - val_loss: 27.7593\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.1534 - val_loss: 26.4697\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.1597 - val_loss: 27.3784\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.6231 - val_loss: 18.6672\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.1519 - val_loss: 54.2667\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 41.8651 - val_loss: 759.1918\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 208.7356 - val_loss: 60.1135\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 49.6149 - val_loss: 31.0269\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.2967 - val_loss: 34.6735\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.0368 - val_loss: 30.4645\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.7836 - val_loss: 40.4426\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.1235 - val_loss: 29.6919\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.0963 - val_loss: 33.4722\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.4140 - val_loss: 32.6737\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.5562 - val_loss: 30.0643\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.2964 - val_loss: 25.3150\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.9860 - val_loss: 31.6619\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.9959 - val_loss: 24.4316\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.7144 - val_loss: 46.8818\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.5007 - val_loss: 36.6527\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.6307 - val_loss: 55.9775\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 34.5795 - val_loss: 30.4336\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.6015 - val_loss: 24.7536\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.4452 - val_loss: 31.8026\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.2253 - val_loss: 50.9227\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.1096 - val_loss: 36.3167\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.5314 - val_loss: 37.9319\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.0562 - val_loss: 23.1406\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.3668 - val_loss: 30.3079\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.7985 - val_loss: 41.9696\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.7596 - val_loss: 23.1133\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.1278 - val_loss: 22.5127\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.0794 - val_loss: 19.0307\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.3802 - val_loss: 31.9866\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.4451 - val_loss: 45.5867\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.6371 - val_loss: 26.4042\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.9270 - val_loss: 35.3014\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.2828 - val_loss: 40.7019\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.0172 - val_loss: 31.9898\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.3734 - val_loss: 39.7362\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.0948 - val_loss: 59.9394\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 48.2929 - val_loss: 59.7504\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 38.7622 - val_loss: 26.1014\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 31.5513 - val_loss: 33.5146\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.5760 - val_loss: 47.2131\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 29.9507 - val_loss: 32.4249\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.3297 - val_loss: 41.4220\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.5189 - val_loss: 36.5513\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.8444 - val_loss: 33.2782\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.9227 - val_loss: 39.2867\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.1073 - val_loss: 45.8190\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.5940 - val_loss: 28.9249\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.4097 - val_loss: 29.6628\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 27.8397 - val_loss: 29.4907\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.3183 - val_loss: 83.0052\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 39.3719 - val_loss: 30.5445\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 33.8485 - val_loss: 33.4398\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.3874 - val_loss: 39.5555\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.2412 - val_loss: 46.1443\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.5830 - val_loss: 32.5423\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.8549 - val_loss: 24.8745\n",
      "Epoch 477/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 25.9756 - val_loss: 31.9045\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.8803 - val_loss: 33.1789\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.4303 - val_loss: 33.6598\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.3467 - val_loss: 28.3376\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.2676 - val_loss: 29.5349\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.4399 - val_loss: 35.7681\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.8546 - val_loss: 30.6626\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.8775 - val_loss: 18.5337\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.8246 - val_loss: 35.2856\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.3731 - val_loss: 36.3767\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.4146 - val_loss: 23.7621\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.2237 - val_loss: 25.7321\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.0715 - val_loss: 45.8212\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.4601 - val_loss: 29.0599\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.4695 - val_loss: 31.0106\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.2941 - val_loss: 37.4806\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.1750 - val_loss: 33.0782\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.3072 - val_loss: 22.8001\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.4137 - val_loss: 23.2144\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.2469 - val_loss: 24.2284\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.5519 - val_loss: 36.5068\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.0354 - val_loss: 29.2865\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.2131 - val_loss: 19.1789\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.5763 - val_loss: 58.2295\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 28.3025 - val_loss: 32.5167\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4375 - val_loss: 31.1114\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7586 - val_loss: 36.4873\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.8716 - val_loss: 21.7586\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.9475 - val_loss: 29.8713\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.7564 - val_loss: 26.4976\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.4539 - val_loss: 32.3181\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.1882 - val_loss: 24.4245\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.9893 - val_loss: 19.8378\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.7472 - val_loss: 40.4080\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.9709 - val_loss: 25.0802\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9919 - val_loss: 31.2355\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.1577 - val_loss: 28.5439\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.0445 - val_loss: 24.9226\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.8513 - val_loss: 27.1391\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.9099 - val_loss: 20.4083\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.3671 - val_loss: 22.6115\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5495 - val_loss: 26.3415\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.0309 - val_loss: 50.1490\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.0213 - val_loss: 38.9946\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.9828 - val_loss: 31.5895\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.5996 - val_loss: 35.3737\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.8028 - val_loss: 38.2253\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.4901 - val_loss: 37.2985\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.0877 - val_loss: 27.4089\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.3099 - val_loss: 25.7848\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.2527 - val_loss: 26.6771\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.9490 - val_loss: 25.2876\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.8500 - val_loss: 30.8917\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.0736 - val_loss: 34.3825\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.0657 - val_loss: 52.4760\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.3878 - val_loss: 24.7192\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.2166 - val_loss: 29.5084\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.9083 - val_loss: 36.0671\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.5555 - val_loss: 36.4992\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.0278 - val_loss: 21.8056\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9314 - val_loss: 28.7694\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3686 - val_loss: 20.4282\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.8127 - val_loss: 22.4069\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.5665 - val_loss: 37.1848\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6028 - val_loss: 20.9920\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.5706 - val_loss: 25.8510\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.9396 - val_loss: 39.3518\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.1543 - val_loss: 29.5464\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.7846 - val_loss: 44.7711\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.9288 - val_loss: 20.6907\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.6970 - val_loss: 31.2207\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8883 - val_loss: 27.7589\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3449 - val_loss: 28.2436\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2181 - val_loss: 31.0405\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.3595 - val_loss: 22.7381\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6183 - val_loss: 21.4034\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.4583 - val_loss: 24.7874\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.1522 - val_loss: 22.8292\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.4722 - val_loss: 33.2383\n",
      "Epoch 556/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 20.8000 - val_loss: 36.5625\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.0052 - val_loss: 51.4541\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 30.4803 - val_loss: 33.9559\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.4543 - val_loss: 33.4781\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.1536 - val_loss: 21.5395\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5934 - val_loss: 27.3170\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.8742 - val_loss: 46.4179\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.1078 - val_loss: 39.0396\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.4357 - val_loss: 28.9156\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.9183 - val_loss: 35.5454\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9129 - val_loss: 30.8586\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.0710 - val_loss: 31.9265\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.2983 - val_loss: 26.6093\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1983 - val_loss: 32.5580\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.4922 - val_loss: 24.4114\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.5836 - val_loss: 29.7282\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8833 - val_loss: 22.6372\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.7285 - val_loss: 31.8337\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7540 - val_loss: 19.8282\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.2792 - val_loss: 27.4612\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1236 - val_loss: 26.4551\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.5259 - val_loss: 26.0223\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7558 - val_loss: 27.6035\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.5278 - val_loss: 38.9860\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5636 - val_loss: 28.9971\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 16.8568 - val_loss: 17.1815\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1983 - val_loss: 26.6250\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3987 - val_loss: 25.5296\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.8375 - val_loss: 21.6486\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.6037 - val_loss: 44.5068\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.9061 - val_loss: 37.9476\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2303 - val_loss: 24.3486\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9340 - val_loss: 40.1711\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.7220 - val_loss: 32.1125\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.8474 - val_loss: 26.3752\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8620 - val_loss: 23.3041\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5981 - val_loss: 25.8388\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5082 - val_loss: 31.9432\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3127 - val_loss: 40.3549\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 26.8690 - val_loss: 26.3851\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0201 - val_loss: 22.6174\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2543 - val_loss: 22.4794\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3456 - val_loss: 30.3035\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2108 - val_loss: 25.9146\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1108 - val_loss: 26.6145\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5908 - val_loss: 30.0183\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.0205 - val_loss: 19.5053\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1838 - val_loss: 42.8331\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.3420 - val_loss: 30.3687\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.0063 - val_loss: 32.7121\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.2470 - val_loss: 29.1256\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.2109 - val_loss: 50.6261\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.2170 - val_loss: 31.4208\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.7451 - val_loss: 18.3275\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1935 - val_loss: 19.3562\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1800 - val_loss: 32.3054\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.7867 - val_loss: 31.0284\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3542 - val_loss: 28.4837\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.3150 - val_loss: 17.6550\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5435 - val_loss: 23.8728\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9862 - val_loss: 31.6690\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9862 - val_loss: 23.6348\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.4507 - val_loss: 50.4328\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.2367 - val_loss: 20.5844\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3129 - val_loss: 20.2807\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.2062 - val_loss: 26.5015\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8737 - val_loss: 74.3685\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 36.3773 - val_loss: 24.6022\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.6212 - val_loss: 40.4972\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.6218 - val_loss: 27.1575\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.8805 - val_loss: 37.3153\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6215 - val_loss: 24.7349\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.4530 - val_loss: 29.2974\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.3335 - val_loss: 44.6225\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3494 - val_loss: 24.2899\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0282 - val_loss: 37.2494\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6843 - val_loss: 33.6278\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9335 - val_loss: 24.1459\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3768 - val_loss: 29.1382\n",
      "Epoch 635/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0251 - val_loss: 34.0129\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8752 - val_loss: 45.8410\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.4942 - val_loss: 26.4478\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0838 - val_loss: 22.5505\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3098 - val_loss: 56.4009\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4483 - val_loss: 32.8337\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.9843 - val_loss: 28.9733\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7429 - val_loss: 29.7706\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3339 - val_loss: 22.3531\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.7377 - val_loss: 27.6915\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.6526 - val_loss: 34.5933\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0299 - val_loss: 37.6866\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7394 - val_loss: 28.5404\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3615 - val_loss: 40.7028\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.2355 - val_loss: 52.4571\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.0199 - val_loss: 28.0077\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3900 - val_loss: 38.5594\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1403 - val_loss: 24.2152\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7749 - val_loss: 33.5416\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.6500 - val_loss: 23.7829\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1150 - val_loss: 22.5264\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7832 - val_loss: 27.5126\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3642 - val_loss: 23.8878\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0991 - val_loss: 27.1906\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7815 - val_loss: 16.3330\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.6370 - val_loss: 18.9961\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.4326 - val_loss: 25.2570\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3753 - val_loss: 24.0136\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.9252 - val_loss: 25.1013\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6580 - val_loss: 18.4129\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.5036 - val_loss: 17.0487\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9421 - val_loss: 23.4645\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6197 - val_loss: 32.2080\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6779 - val_loss: 33.7693\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6283 - val_loss: 23.2124\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.2238 - val_loss: 15.8728\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2262 - val_loss: 24.8626\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.0113 - val_loss: 16.3313\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.9002 - val_loss: 29.8546\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3192 - val_loss: 22.3091\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.8729 - val_loss: 38.8376\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.1057 - val_loss: 32.3383\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8051 - val_loss: 34.9661\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.2676 - val_loss: 23.3040\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.4905 - val_loss: 25.1769\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8491 - val_loss: 23.1808\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0606 - val_loss: 22.1749\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2699 - val_loss: 31.4924\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.8373 - val_loss: 33.3323\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1561 - val_loss: 20.4645\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7149 - val_loss: 19.3353\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.4525 - val_loss: 17.8134\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.4735 - val_loss: 19.0131\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.0771 - val_loss: 15.8619\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.8146 - val_loss: 19.7260\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3901 - val_loss: 31.1141\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.3856 - val_loss: 33.1419\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.3521 - val_loss: 18.0937\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.2464 - val_loss: 33.1804\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7973 - val_loss: 33.6387\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3712 - val_loss: 32.6904\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3261 - val_loss: 26.4130\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.8187 - val_loss: 34.5320\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9817 - val_loss: 22.1190\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9382 - val_loss: 29.7411\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8506 - val_loss: 24.0697\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9215 - val_loss: 16.8598\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.8450 - val_loss: 21.2972\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.9132 - val_loss: 44.3295\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.7520 - val_loss: 23.3119\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7434 - val_loss: 25.9913\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.4110 - val_loss: 25.2289\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.6446 - val_loss: 28.5476\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.5740 - val_loss: 28.0366\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.8407 - val_loss: 33.6815\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.8709 - val_loss: 27.6994\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.7125 - val_loss: 50.0770\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.4306 - val_loss: 23.3734\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.5776 - val_loss: 29.4283\n",
      "Epoch 714/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 19.2631 - val_loss: 28.9642\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0700 - val_loss: 22.0576\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.2555 - val_loss: 36.6582\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9854 - val_loss: 20.0339\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7726 - val_loss: 49.5076\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.0083 - val_loss: 27.3196\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.7549 - val_loss: 24.5938\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7021 - val_loss: 27.6482\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.5964 - val_loss: 27.8930\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.7409 - val_loss: 35.2556\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5537 - val_loss: 26.5646\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.2856 - val_loss: 20.7269\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.7966 - val_loss: 29.5087\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5519 - val_loss: 25.7621\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.0937 - val_loss: 29.6073\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.8098 - val_loss: 27.6527\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2809 - val_loss: 39.1127\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8659 - val_loss: 30.9897\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.0674 - val_loss: 25.1977\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3392 - val_loss: 48.4366\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.5524 - val_loss: 22.3198\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.6999 - val_loss: 19.1306\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.3521 - val_loss: 26.7484\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4100 - val_loss: 22.2418\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4930 - val_loss: 27.4842\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3678 - val_loss: 36.7543\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1022 - val_loss: 20.2451\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8331 - val_loss: 27.3102\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3709 - val_loss: 25.8993\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.2408 - val_loss: 23.2908\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.2431 - val_loss: 23.3825\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6881 - val_loss: 30.2716\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9511 - val_loss: 21.6357\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.6901 - val_loss: 37.2559\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5530 - val_loss: 29.6422\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1491 - val_loss: 20.8280\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1845 - val_loss: 29.1619\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7930 - val_loss: 19.8830\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0925 - val_loss: 37.4717\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.7244 - val_loss: 33.9891\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3567 - val_loss: 29.1947\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3649 - val_loss: 21.5029\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.7621 - val_loss: 20.3242\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.4311 - val_loss: 23.3025\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2798 - val_loss: 21.6401\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3175 - val_loss: 32.7298\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5079 - val_loss: 32.4344\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.2847 - val_loss: 28.1395\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.6827 - val_loss: 31.3829\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.4360 - val_loss: 37.0923\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.2434 - val_loss: 27.7970\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.0446 - val_loss: 34.4612\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1531 - val_loss: 25.4083\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9829 - val_loss: 30.1197\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7865 - val_loss: 39.3735\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 25.5015 - val_loss: 22.4642\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.4325 - val_loss: 21.7998\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6377 - val_loss: 22.9407\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.1101 - val_loss: 23.4116\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.8848 - val_loss: 31.4348\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7234 - val_loss: 33.2673\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.1898 - val_loss: 25.7870\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.5119 - val_loss: 27.8861\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7115 - val_loss: 26.3473\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7022 - val_loss: 26.7132\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3134 - val_loss: 34.4321\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1491 - val_loss: 35.6508\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8801 - val_loss: 30.2912\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4791 - val_loss: 32.6138\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6425 - val_loss: 30.1238\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3455 - val_loss: 39.9173\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.8254 - val_loss: 22.0500\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7371 - val_loss: 41.8206\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.2428 - val_loss: 31.9006\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5595 - val_loss: 24.4910\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6346 - val_loss: 30.3707\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6300 - val_loss: 24.0027\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4958 - val_loss: 30.7247\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7401 - val_loss: 21.8706\n",
      "Epoch 793/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5680 - val_loss: 47.2275\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.4156 - val_loss: 18.4580\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.1456 - val_loss: 23.4642\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1951 - val_loss: 20.5094\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.5640 - val_loss: 21.6532\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7224 - val_loss: 26.9416\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0951 - val_loss: 20.8711\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4269 - val_loss: 31.8310\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9391 - val_loss: 24.0364\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3879 - val_loss: 19.0563\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1565 - val_loss: 22.2048\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1944 - val_loss: 24.2976\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8652 - val_loss: 24.8897\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.8523 - val_loss: 28.7299\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.5156 - val_loss: 22.7970\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.5706 - val_loss: 26.9617\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.0345 - val_loss: 29.3700\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.6970 - val_loss: 26.0935\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.4372 - val_loss: 29.2535\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3275 - val_loss: 38.5150\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.5964 - val_loss: 27.4289\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.9105 - val_loss: 21.9654\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.6930 - val_loss: 22.1187\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.6650 - val_loss: 31.0000\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.9157 - val_loss: 24.6615\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2616 - val_loss: 28.0502\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4435 - val_loss: 65.6731\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.6441 - val_loss: 30.2939\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.5548 - val_loss: 43.1041\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4926 - val_loss: 22.7689\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.6232 - val_loss: 29.8961\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9782 - val_loss: 25.8208\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1241 - val_loss: 28.5265\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4180 - val_loss: 20.9243\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.0423 - val_loss: 24.0956\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0818 - val_loss: 18.9824\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0677 - val_loss: 20.2667\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9289 - val_loss: 31.3279\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.8314 - val_loss: 28.7979\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9461 - val_loss: 22.4069\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.4897 - val_loss: 24.0244\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7732 - val_loss: 25.1978\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6092 - val_loss: 20.7554\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4083 - val_loss: 20.8818\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2031 - val_loss: 25.2332\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0027 - val_loss: 18.7322\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1667 - val_loss: 22.0320\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.5426 - val_loss: 28.1319\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8492 - val_loss: 20.8562\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.5951 - val_loss: 25.2407\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6092 - val_loss: 20.8461\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3832 - val_loss: 28.1563\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9224 - val_loss: 25.9319\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2238 - val_loss: 24.3202\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5383 - val_loss: 20.7842\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1973 - val_loss: 31.5927\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.5213 - val_loss: 39.8308\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.2992 - val_loss: 20.7802\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.4795 - val_loss: 21.5120\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2087 - val_loss: 26.2076\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.8868 - val_loss: 40.9098\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9931 - val_loss: 19.0534\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5332 - val_loss: 44.0177\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3062 - val_loss: 27.9088\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6833 - val_loss: 18.9037\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.0663 - val_loss: 27.3394\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24.0232 - val_loss: 32.2313\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.7419 - val_loss: 21.4680\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2995 - val_loss: 30.9029\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.1357 - val_loss: 29.3626\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.5697 - val_loss: 32.6062\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.0619 - val_loss: 25.3494\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.2480 - val_loss: 28.1866\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.8999 - val_loss: 25.2684\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6913 - val_loss: 21.5405\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7971 - val_loss: 30.9185\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6212 - val_loss: 18.1199\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6253 - val_loss: 25.1751\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6628 - val_loss: 28.8052\n",
      "Epoch 872/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3161 - val_loss: 19.6216\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6257 - val_loss: 31.7664\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7887 - val_loss: 29.5952\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7153 - val_loss: 32.0631\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6795 - val_loss: 33.0590\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.7988 - val_loss: 27.6216\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1541 - val_loss: 28.2335\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9747 - val_loss: 17.1146\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5829 - val_loss: 27.5530\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3365 - val_loss: 20.2924\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1075 - val_loss: 16.6610\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3540 - val_loss: 18.4116\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0852 - val_loss: 20.5615\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1725 - val_loss: 24.1324\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9752 - val_loss: 17.9782\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1531 - val_loss: 25.1610\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9252 - val_loss: 26.6069\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6391 - val_loss: 30.1965\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.2628 - val_loss: 20.2496\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5733 - val_loss: 30.8120\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1471 - val_loss: 28.8922\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0499 - val_loss: 37.5374\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2870 - val_loss: 25.9932\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5829 - val_loss: 21.9460\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5037 - val_loss: 17.8636\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9714 - val_loss: 31.4035\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9460 - val_loss: 29.3944\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.6198 - val_loss: 49.8414\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7861 - val_loss: 18.5597\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6402 - val_loss: 21.8354\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7290 - val_loss: 19.1574\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.6658 - val_loss: 20.6105\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.1495 - val_loss: 18.2629\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3276 - val_loss: 21.0683\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9938 - val_loss: 23.3290\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.8641 - val_loss: 19.3831\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5807 - val_loss: 24.0304\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7768 - val_loss: 20.4180\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.0431 - val_loss: 23.7584\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4396 - val_loss: 24.8471\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7549 - val_loss: 20.0501\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.0637 - val_loss: 17.8271\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.7818 - val_loss: 16.2846\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9365 - val_loss: 16.0567\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9734 - val_loss: 33.3262\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.0771 - val_loss: 26.7079\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.3398 - val_loss: 51.1438\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.2786 - val_loss: 22.2207\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6027 - val_loss: 23.2216\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0941 - val_loss: 31.6121\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9414 - val_loss: 25.5013\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7803 - val_loss: 32.7748\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9547 - val_loss: 18.3284\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6181 - val_loss: 25.8942\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8517 - val_loss: 21.2896\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2466 - val_loss: 27.7307\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6688 - val_loss: 20.2544\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9347 - val_loss: 26.0977\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.2821 - val_loss: 33.8088\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7246 - val_loss: 25.3546\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.4587 - val_loss: 23.6388\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.8642 - val_loss: 37.8609\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.8473 - val_loss: 33.6466\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.4681 - val_loss: 19.9737\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5312 - val_loss: 23.4341\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1030 - val_loss: 41.2334\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.5237 - val_loss: 36.0271\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4068 - val_loss: 27.5066\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6089 - val_loss: 29.9583\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4678 - val_loss: 31.5117\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.9512 - val_loss: 29.8454\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5661 - val_loss: 26.0528\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1204 - val_loss: 19.1285\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.0393 - val_loss: 38.2563\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2553 - val_loss: 21.2377\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6016 - val_loss: 20.2380\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4155 - val_loss: 24.1207\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5915 - val_loss: 27.0541\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.0813 - val_loss: 35.4999\n",
      "Epoch 951/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9274 - val_loss: 17.2590\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.2827 - val_loss: 24.8500\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3033 - val_loss: 20.8436\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2839 - val_loss: 20.2355\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9127 - val_loss: 17.9189\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.8531 - val_loss: 23.2980\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0091 - val_loss: 34.4089\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1242 - val_loss: 23.9187\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3496 - val_loss: 24.5092\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1865 - val_loss: 21.7894\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1793 - val_loss: 20.9232\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4297 - val_loss: 21.8967\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3615 - val_loss: 22.0588\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3443 - val_loss: 29.0407\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9370 - val_loss: 33.7684\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1295 - val_loss: 25.7316\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2732 - val_loss: 25.5733\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7695 - val_loss: 25.4353\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3664 - val_loss: 17.9815\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0746 - val_loss: 24.3197\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2954 - val_loss: 25.3138\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6452 - val_loss: 23.2204\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8982 - val_loss: 47.1684\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8519 - val_loss: 25.7156\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5649 - val_loss: 19.0558\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3450 - val_loss: 19.6404\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.3017 - val_loss: 18.4425\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8244 - val_loss: 20.1935\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5959 - val_loss: 32.6852\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.8179 - val_loss: 26.4991\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6547 - val_loss: 15.7860\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0516 - val_loss: 24.3304\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1531 - val_loss: 20.1540\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1077 - val_loss: 19.6384\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1699 - val_loss: 22.0904\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7182 - val_loss: 23.8868\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.4415 - val_loss: 22.6347\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.9542 - val_loss: 20.7280\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4824 - val_loss: 30.9036\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7839 - val_loss: 20.5803\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.8520 - val_loss: 20.1261\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9782 - val_loss: 24.4011\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1639 - val_loss: 29.5880\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1194 - val_loss: 19.2795\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2532 - val_loss: 22.6979\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8950 - val_loss: 25.2090\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1806 - val_loss: 19.7193\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7364 - val_loss: 17.5591\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7958 - val_loss: 21.3151\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9954 - val_loss: 19.6685\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9797 - val_loss: 23.3462\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2285 - val_loss: 21.8383\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5394 - val_loss: 24.7375\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7581 - val_loss: 22.3822\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7183 - val_loss: 26.8459\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2384 - val_loss: 17.7637\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.8511 - val_loss: 20.7393\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8399 - val_loss: 21.9609\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9140 - val_loss: 26.7232\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.7101 - val_loss: 28.7670\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3166 - val_loss: 32.4609\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7075 - val_loss: 21.1463\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9386 - val_loss: 23.1313\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3490 - val_loss: 24.4394\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.6503 - val_loss: 23.1727\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3490 - val_loss: 15.8192\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1537 - val_loss: 23.9869\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3057 - val_loss: 16.6207\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4791 - val_loss: 20.5666\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6982 - val_loss: 22.8440\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.0215 - val_loss: 15.6862\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7472 - val_loss: 19.3007\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6419 - val_loss: 24.1600\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7236 - val_loss: 28.0889\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1651 - val_loss: 25.6324\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.8171 - val_loss: 31.1271\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9559 - val_loss: 17.8630\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.4614 - val_loss: 35.5416\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5939 - val_loss: 19.0219\n",
      "Epoch 1030/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2594 - val_loss: 20.0020\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6130 - val_loss: 19.8491\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3700 - val_loss: 22.1809\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.6431 - val_loss: 42.9747\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.5697 - val_loss: 32.0675\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.4942 - val_loss: 19.0796\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9482 - val_loss: 28.4836\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0315 - val_loss: 29.8479\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8385 - val_loss: 16.3275\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7452 - val_loss: 35.0843\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0319 - val_loss: 17.9813\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1232 - val_loss: 20.8168\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1508 - val_loss: 44.7163\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2305 - val_loss: 26.0388\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2590 - val_loss: 17.1873\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5587 - val_loss: 23.3133\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1228 - val_loss: 37.6650\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9130 - val_loss: 20.7506\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9316 - val_loss: 29.3862\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1831 - val_loss: 33.9340\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3014 - val_loss: 21.6258\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2295 - val_loss: 20.5429\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9536 - val_loss: 20.1955\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2720 - val_loss: 28.1216\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6758 - val_loss: 20.4018\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6607 - val_loss: 23.2105\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4348 - val_loss: 22.2195\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7965 - val_loss: 32.7070\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9197 - val_loss: 29.5633\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3699 - val_loss: 19.1962\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9172 - val_loss: 18.9303\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2666 - val_loss: 19.5518\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4367 - val_loss: 20.1423\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8307 - val_loss: 21.5231\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7321 - val_loss: 20.6089\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9287 - val_loss: 16.2263\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5820 - val_loss: 20.5054\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2827 - val_loss: 26.2154\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1641 - val_loss: 23.4280\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8079 - val_loss: 22.5138\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0913 - val_loss: 38.9991\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2953 - val_loss: 28.3102\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.6098 - val_loss: 22.1718\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3018 - val_loss: 23.9928\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.8141 - val_loss: 19.8510\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5484 - val_loss: 38.5047\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1710 - val_loss: 26.3407\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.6846 - val_loss: 22.8512\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6956 - val_loss: 17.7442\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2215 - val_loss: 19.5067\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9276 - val_loss: 26.9785\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9776 - val_loss: 15.6983\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1878 - val_loss: 28.3626\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4210 - val_loss: 20.9905\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8176 - val_loss: 18.7488\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6571 - val_loss: 25.9803\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1973 - val_loss: 24.2996\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9270 - val_loss: 19.6463\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5454 - val_loss: 23.3216\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.8560 - val_loss: 19.2422\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0252 - val_loss: 23.6667\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7659 - val_loss: 30.8103\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1675 - val_loss: 23.5331\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1930 - val_loss: 18.9625\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2187 - val_loss: 25.2764\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2930 - val_loss: 19.9579\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4288 - val_loss: 27.7267\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1804 - val_loss: 18.2099\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3157 - val_loss: 29.1754\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8890 - val_loss: 17.4194\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2267 - val_loss: 19.2884\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7334 - val_loss: 19.6496\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1745 - val_loss: 23.0715\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.6681 - val_loss: 26.7587\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1811 - val_loss: 37.8179\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.4947 - val_loss: 22.2106\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1260 - val_loss: 20.6314\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1586 - val_loss: 21.3172\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7444 - val_loss: 25.9421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0845 - val_loss: 27.4149\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2180 - val_loss: 31.4240\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1124 - val_loss: 27.8816\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.6530 - val_loss: 24.6041\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6108 - val_loss: 22.9003\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9376 - val_loss: 17.9520\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.1374 - val_loss: 33.1174\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.9907 - val_loss: 26.0856\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7634 - val_loss: 19.1125\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9746 - val_loss: 25.9427\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3029 - val_loss: 27.4526\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.5958 - val_loss: 21.9757\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.6153 - val_loss: 24.7994\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8779 - val_loss: 27.3317\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5319 - val_loss: 19.8047\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9589 - val_loss: 23.8999\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2600 - val_loss: 26.4206\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5222 - val_loss: 33.6614\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5141 - val_loss: 27.7541\n",
      "Epoch 1128/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2147 - val_loss: 27.3847\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5931 - val_loss: 23.9929\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7867 - val_loss: 30.3500\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7600 - val_loss: 21.5427\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8238 - val_loss: 24.3776\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7049 - val_loss: 27.2007\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3592 - val_loss: 20.8576\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2977 - val_loss: 17.2498\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2900 - val_loss: 23.0489\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.0339 - val_loss: 26.4622\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2394 - val_loss: 31.5317\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.5134 - val_loss: 16.9994\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4937 - val_loss: 30.7824\n",
      "Epoch 1141/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.8346 - val_loss: 17.7653\n",
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.7865 - val_loss: 26.0529\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.1627 - val_loss: 17.0265\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.2563 - val_loss: 24.3545\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7510 - val_loss: 22.9326\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4533 - val_loss: 21.9329\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2938 - val_loss: 33.4290\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8539 - val_loss: 34.8778\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.6895 - val_loss: 30.2616\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.8421 - val_loss: 35.1982\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.3109 - val_loss: 17.8766\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4382 - val_loss: 39.8639\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8518 - val_loss: 37.3672\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.8496 - val_loss: 32.3779\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.6733 - val_loss: 29.7345\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1634 - val_loss: 24.9340\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3709 - val_loss: 27.9436\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.4079 - val_loss: 42.3315\n",
      "Epoch 1159/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1001 - val_loss: 23.0607\n",
      "Epoch 1160/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3630 - val_loss: 32.9634\n",
      "Epoch 1161/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9677 - val_loss: 17.3651\n",
      "Epoch 1162/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0709 - val_loss: 20.5407\n",
      "Epoch 1163/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4076 - val_loss: 15.9464\n",
      "Epoch 1164/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3986 - val_loss: 24.8913\n",
      "Epoch 1165/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7299 - val_loss: 18.6992\n",
      "Epoch 1166/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8505 - val_loss: 30.3487\n",
      "Epoch 1167/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9025 - val_loss: 26.9772\n",
      "Epoch 1168/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3010 - val_loss: 30.0143\n",
      "Epoch 1169/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.6599 - val_loss: 18.0641\n",
      "Epoch 1170/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.2959 - val_loss: 20.3353\n",
      "Epoch 1171/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.9722 - val_loss: 25.9257\n",
      "Epoch 1172/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6492 - val_loss: 22.8872\n",
      "Epoch 1173/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9570 - val_loss: 23.3309\n",
      "Epoch 1174/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7796 - val_loss: 35.3136\n",
      "Epoch 1175/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0426 - val_loss: 27.5451\n",
      "Epoch 1176/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4745 - val_loss: 21.0694\n",
      "Epoch 1177/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0939 - val_loss: 27.4245\n",
      "Epoch 1178/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5740 - val_loss: 24.3542\n",
      "Epoch 1179/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6979 - val_loss: 28.7435\n",
      "Epoch 1180/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5934 - val_loss: 25.7523\n",
      "Epoch 1181/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9522 - val_loss: 29.4149\n",
      "Epoch 1182/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7056 - val_loss: 52.3764\n",
      "Epoch 1183/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4893 - val_loss: 31.4603\n",
      "Epoch 1184/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7516 - val_loss: 29.2734\n",
      "Epoch 1185/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4408 - val_loss: 20.5854\n",
      "Epoch 1186/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4339 - val_loss: 34.1371\n",
      "Epoch 1187/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4506 - val_loss: 28.2791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1188/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9983 - val_loss: 27.4083\n",
      "Epoch 1189/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.7396 - val_loss: 31.5641\n",
      "Epoch 1190/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.1644 - val_loss: 41.2945\n",
      "Epoch 1191/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.3999 - val_loss: 17.0929\n",
      "Epoch 1192/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.7814 - val_loss: 23.1804\n",
      "Epoch 1193/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5107 - val_loss: 24.8853\n",
      "Epoch 1194/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2486 - val_loss: 20.8077\n",
      "Epoch 1195/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.6550 - val_loss: 20.4245\n",
      "Epoch 1196/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1743 - val_loss: 31.6039\n",
      "Epoch 1197/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4875 - val_loss: 28.7718\n",
      "Epoch 1198/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.4835 - val_loss: 19.5426\n",
      "Epoch 1199/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2887 - val_loss: 22.0421\n",
      "Epoch 1200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.8711 - val_loss: 21.4550\n",
      "Epoch 1201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7306 - val_loss: 27.6088\n",
      "Epoch 1202/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8126 - val_loss: 25.9618\n",
      "Epoch 1203/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1585 - val_loss: 27.6608\n",
      "Epoch 1204/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2159 - val_loss: 20.6053\n",
      "Epoch 1205/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6761 - val_loss: 20.5018\n",
      "Epoch 1206/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7860 - val_loss: 21.1251\n",
      "Epoch 1207/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8097 - val_loss: 25.0138\n",
      "Epoch 1208/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1111 - val_loss: 23.7098\n",
      "Epoch 1209/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5962 - val_loss: 20.8226\n",
      "Epoch 1210/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3064 - val_loss: 20.9945\n",
      "Epoch 1211/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6054 - val_loss: 18.5526\n",
      "Epoch 1212/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9243 - val_loss: 25.9603\n",
      "Epoch 1213/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.5248 - val_loss: 29.6909\n",
      "Epoch 1214/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3926 - val_loss: 24.7894\n",
      "Epoch 1215/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8457 - val_loss: 20.0396\n",
      "Epoch 1216/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4174 - val_loss: 35.6351\n",
      "Epoch 1217/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6930 - val_loss: 21.3203\n",
      "Epoch 1218/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9863 - val_loss: 23.4985\n",
      "Epoch 1219/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8959 - val_loss: 24.6933\n",
      "Epoch 1220/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.2408 - val_loss: 36.7839\n",
      "Epoch 1221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2644 - val_loss: 34.5921\n",
      "Epoch 1222/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.2676 - val_loss: 21.2106\n",
      "Epoch 1223/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.2401 - val_loss: 18.2652\n",
      "Epoch 1224/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.2250 - val_loss: 29.0822\n",
      "Epoch 1225/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3081 - val_loss: 37.6605\n",
      "Epoch 1226/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1600 - val_loss: 27.8492\n",
      "Epoch 1227/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.0146 - val_loss: 21.0769\n",
      "Epoch 1228/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 16.0104 - val_loss: 14.8008\n",
      "Epoch 1229/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2149 - val_loss: 21.1464\n",
      "Epoch 1230/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9313 - val_loss: 16.9887\n",
      "Epoch 1231/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9110 - val_loss: 18.3122\n",
      "Epoch 1232/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9402 - val_loss: 39.0534\n",
      "Epoch 1233/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9851 - val_loss: 27.0421\n",
      "Epoch 1234/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6417 - val_loss: 27.2109\n",
      "Epoch 1235/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7829 - val_loss: 24.1887\n",
      "Epoch 1236/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.0766 - val_loss: 26.9164\n",
      "Epoch 1237/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.1745 - val_loss: 14.8749\n",
      "Epoch 1238/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1789 - val_loss: 22.9961\n",
      "Epoch 1239/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2601 - val_loss: 16.3892\n",
      "Epoch 1240/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.8696 - val_loss: 19.6424\n",
      "Epoch 1241/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1535 - val_loss: 15.7894\n",
      "Epoch 1242/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.0993 - val_loss: 21.5894\n",
      "Epoch 1243/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1242 - val_loss: 30.5016\n",
      "Epoch 1244/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7236 - val_loss: 19.4896\n",
      "Epoch 1245/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.5582 - val_loss: 21.8645\n",
      "Epoch 1246/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3178 - val_loss: 20.5424\n",
      "Epoch 1247/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5316 - val_loss: 27.5559\n",
      "Epoch 1248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8235 - val_loss: 29.4102\n",
      "Epoch 1249/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5221 - val_loss: 18.4350\n",
      "Epoch 1250/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9466 - val_loss: 29.7232\n",
      "Epoch 1251/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0341 - val_loss: 47.6066\n",
      "Epoch 1252/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 22.8202 - val_loss: 23.9192\n",
      "Epoch 1253/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3283 - val_loss: 17.1311\n",
      "Epoch 1254/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3957 - val_loss: 19.9416\n",
      "Epoch 1255/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0719 - val_loss: 44.0971\n",
      "Epoch 1256/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.3366 - val_loss: 20.2391\n",
      "Epoch 1257/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9501 - val_loss: 16.7384\n",
      "Epoch 1258/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5739 - val_loss: 26.1135\n",
      "Epoch 1259/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0198 - val_loss: 19.4220\n",
      "Epoch 1260/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4612 - val_loss: 32.6789\n",
      "Epoch 1261/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5735 - val_loss: 19.1318\n",
      "Epoch 1262/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2383 - val_loss: 19.4898\n",
      "Epoch 1263/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6357 - val_loss: 20.1030\n",
      "Epoch 1264/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1994 - val_loss: 32.2541\n",
      "Epoch 1265/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9768 - val_loss: 31.8679\n",
      "Epoch 1266/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.2138 - val_loss: 31.5425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1267/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8450 - val_loss: 51.3543\n",
      "Epoch 1268/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5506 - val_loss: 25.8943\n",
      "Epoch 1269/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1828 - val_loss: 29.7918\n",
      "Epoch 1270/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5328 - val_loss: 18.2866\n",
      "Epoch 1271/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4969 - val_loss: 17.6794\n",
      "Epoch 1272/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8607 - val_loss: 30.5071\n",
      "Epoch 1273/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6038 - val_loss: 15.4950\n",
      "Epoch 1274/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3332 - val_loss: 15.8398\n",
      "Epoch 1275/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.8230 - val_loss: 17.0625\n",
      "Epoch 1276/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6508 - val_loss: 22.7946\n",
      "Epoch 1277/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9229 - val_loss: 24.4546\n",
      "Epoch 1278/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7450 - val_loss: 26.8622\n",
      "Epoch 1279/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7457 - val_loss: 24.9290\n",
      "Epoch 1280/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9705 - val_loss: 17.6682\n",
      "Epoch 1281/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6591 - val_loss: 34.9506\n",
      "Epoch 1282/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4570 - val_loss: 36.0443\n",
      "Epoch 1283/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5060 - val_loss: 32.0598\n",
      "Epoch 1284/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.0942 - val_loss: 31.2424\n",
      "Epoch 1285/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0514 - val_loss: 22.0760\n",
      "Epoch 1286/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4211 - val_loss: 30.5063\n",
      "Epoch 1287/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6921 - val_loss: 16.8558\n",
      "Epoch 1288/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5556 - val_loss: 22.0713\n",
      "Epoch 1289/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3578 - val_loss: 24.4518\n",
      "Epoch 1290/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7497 - val_loss: 22.0582\n",
      "Epoch 1291/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2576 - val_loss: 22.1072\n",
      "Epoch 1292/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7785 - val_loss: 20.8082\n",
      "Epoch 1293/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.3573 - val_loss: 13.2558\n",
      "Epoch 1294/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4776 - val_loss: 15.2374\n",
      "Epoch 1295/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3851 - val_loss: 23.3235\n",
      "Epoch 1296/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9312 - val_loss: 17.8313\n",
      "Epoch 1297/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6257 - val_loss: 18.2588\n",
      "Epoch 1298/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9197 - val_loss: 19.9868\n",
      "Epoch 1299/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8688 - val_loss: 27.4678\n",
      "Epoch 1300/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4943 - val_loss: 23.7418\n",
      "Epoch 1301/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8209 - val_loss: 28.6942\n",
      "Epoch 1302/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8290 - val_loss: 24.9638\n",
      "Epoch 1303/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4090 - val_loss: 20.7836\n",
      "Epoch 1304/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5156 - val_loss: 26.3039\n",
      "Epoch 1305/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7904 - val_loss: 21.8060\n",
      "Epoch 1306/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3115 - val_loss: 22.6459\n",
      "Epoch 1307/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3730 - val_loss: 15.3571\n",
      "Epoch 1308/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7382 - val_loss: 28.2060\n",
      "Epoch 1309/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1495 - val_loss: 25.4847\n",
      "Epoch 1310/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.2028 - val_loss: 17.5561\n",
      "Epoch 1311/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.8183 - val_loss: 21.4412\n",
      "Epoch 1312/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2253 - val_loss: 29.0860\n",
      "Epoch 1313/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9962 - val_loss: 18.4630\n",
      "Epoch 1314/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6725 - val_loss: 22.8337\n",
      "Epoch 1315/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6699 - val_loss: 19.2840\n",
      "Epoch 1316/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6060 - val_loss: 27.8664\n",
      "Epoch 1317/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5537 - val_loss: 21.1306\n",
      "Epoch 1318/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.6086 - val_loss: 19.5932\n",
      "Epoch 1319/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5180 - val_loss: 21.8858\n",
      "Epoch 1320/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4673 - val_loss: 34.8399\n",
      "Epoch 1321/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5426 - val_loss: 29.3555\n",
      "Epoch 1322/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1476 - val_loss: 28.2291\n",
      "Epoch 1323/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.6906 - val_loss: 31.9671\n",
      "Epoch 1324/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.0614 - val_loss: 21.9223\n",
      "Epoch 1325/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7516 - val_loss: 23.3919\n",
      "Epoch 1326/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.0689 - val_loss: 26.6629\n",
      "Epoch 1327/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2062 - val_loss: 16.4269\n",
      "Epoch 1328/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5904 - val_loss: 26.0404\n",
      "Epoch 1329/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3976 - val_loss: 29.7599\n",
      "Epoch 1330/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2567 - val_loss: 26.8479\n",
      "Epoch 1331/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4645 - val_loss: 26.2884\n",
      "Epoch 1332/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.8074 - val_loss: 28.8653\n",
      "Epoch 1333/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.9915 - val_loss: 43.5197\n",
      "Epoch 1334/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9450 - val_loss: 20.7712\n",
      "Epoch 1335/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8989 - val_loss: 18.8166\n",
      "Epoch 1336/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1889 - val_loss: 20.4237\n",
      "Epoch 1337/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7162 - val_loss: 23.0494\n",
      "Epoch 1338/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6675 - val_loss: 25.1863\n",
      "Epoch 1339/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3124 - val_loss: 23.5513\n",
      "Epoch 1340/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6945 - val_loss: 15.7183\n",
      "Epoch 1341/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2127 - val_loss: 17.5398\n",
      "Epoch 1342/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.7097 - val_loss: 21.1032\n",
      "Epoch 1343/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4492 - val_loss: 21.3261\n",
      "Epoch 1344/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2599 - val_loss: 27.6319\n",
      "Epoch 1345/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7035 - val_loss: 37.7491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1346/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5468 - val_loss: 27.7483\n",
      "Epoch 1347/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7856 - val_loss: 18.9746\n",
      "Epoch 1348/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0633 - val_loss: 21.1949\n",
      "Epoch 1349/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6419 - val_loss: 17.8643\n",
      "Epoch 1350/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4630 - val_loss: 22.9678\n",
      "Epoch 1351/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1951 - val_loss: 30.4803\n",
      "Epoch 1352/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4334 - val_loss: 29.3208\n",
      "Epoch 1353/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9742 - val_loss: 38.4294\n",
      "Epoch 1354/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.6587 - val_loss: 25.9604\n",
      "Epoch 1355/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7695 - val_loss: 17.5952\n",
      "Epoch 1356/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.6598 - val_loss: 31.4726\n",
      "Epoch 1357/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4394 - val_loss: 26.4853\n",
      "Epoch 1358/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2868 - val_loss: 31.8530\n",
      "Epoch 1359/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8589 - val_loss: 23.8953\n",
      "Epoch 1360/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6024 - val_loss: 24.6009\n",
      "Epoch 1361/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0592 - val_loss: 26.2923\n",
      "Epoch 1362/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1009 - val_loss: 36.3242\n",
      "Epoch 1363/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4670 - val_loss: 41.5075\n",
      "Epoch 1364/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4048 - val_loss: 19.3618\n",
      "Epoch 1365/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.3526 - val_loss: 26.8690\n",
      "Epoch 1366/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 81.3727 - val_loss: 314.2766\n",
      "Epoch 1367/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 139.6775 - val_loss: 68.5755\n",
      "Epoch 1368/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 51.2192 - val_loss: 69.2097\n",
      "Epoch 1369/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 42.7930 - val_loss: 49.5722\n",
      "Epoch 1370/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.7322 - val_loss: 24.6898\n",
      "Epoch 1371/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1983 - val_loss: 19.9907\n",
      "Epoch 1372/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.4879 - val_loss: 32.9025\n",
      "Epoch 1373/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8681 - val_loss: 30.9650\n",
      "Epoch 1374/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7969 - val_loss: 15.8930\n",
      "Epoch 1375/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3091 - val_loss: 19.4916\n",
      "Epoch 1376/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9515 - val_loss: 34.8847\n",
      "Epoch 1377/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3484 - val_loss: 33.1641\n",
      "Epoch 1378/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4807 - val_loss: 17.6483\n",
      "Epoch 1379/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5143 - val_loss: 17.7738\n",
      "Epoch 1380/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4705 - val_loss: 19.3503\n",
      "Epoch 1381/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8572 - val_loss: 17.5087\n",
      "Epoch 1382/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9305 - val_loss: 21.6102\n",
      "Epoch 1383/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9520 - val_loss: 28.1801\n",
      "Epoch 1384/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3657 - val_loss: 36.6373\n",
      "Epoch 1385/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.6565 - val_loss: 46.3645\n",
      "Epoch 1386/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.6949 - val_loss: 36.0250\n",
      "Epoch 1387/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21.0594 - val_loss: 31.7439\n",
      "Epoch 1388/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1864 - val_loss: 25.3010\n",
      "Epoch 1389/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5181 - val_loss: 27.4313\n",
      "Epoch 1390/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.7568 - val_loss: 39.0978\n",
      "Epoch 1391/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.8437 - val_loss: 16.7009\n",
      "Epoch 1392/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9940 - val_loss: 27.8892\n",
      "Epoch 1393/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.2374 - val_loss: 25.5646\n",
      "Epoch 1394/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2695 - val_loss: 19.9193\n",
      "Epoch 1395/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1208 - val_loss: 27.9948\n",
      "Epoch 1396/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.3619 - val_loss: 21.7256\n",
      "Epoch 1397/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.6468 - val_loss: 31.9065\n",
      "Epoch 1398/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.5890 - val_loss: 24.7490\n",
      "Epoch 1399/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6835 - val_loss: 37.1429\n",
      "Epoch 1400/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.5563 - val_loss: 31.9062\n",
      "Epoch 1401/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5328 - val_loss: 18.6314\n",
      "Epoch 1402/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7597 - val_loss: 25.8026\n",
      "Epoch 1403/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.9801 - val_loss: 20.7145\n",
      "Epoch 1404/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5299 - val_loss: 24.0444\n",
      "Epoch 1405/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2245 - val_loss: 32.6640\n",
      "Epoch 1406/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.9338 - val_loss: 29.9936\n",
      "Epoch 1407/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3506 - val_loss: 17.4264\n",
      "Epoch 1408/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.2753 - val_loss: 28.6275\n",
      "Epoch 1409/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3180 - val_loss: 38.0903\n",
      "Epoch 1410/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0335 - val_loss: 26.8455\n",
      "Epoch 1411/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9511 - val_loss: 25.4752\n",
      "Epoch 1412/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5492 - val_loss: 41.0885\n",
      "Epoch 1413/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6323 - val_loss: 18.8501\n",
      "Epoch 1414/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4539 - val_loss: 22.1295\n",
      "Epoch 1415/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1902 - val_loss: 18.9849\n",
      "Epoch 1416/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2544 - val_loss: 27.7781\n",
      "Epoch 1417/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9041 - val_loss: 30.3676\n",
      "Epoch 1418/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.0061 - val_loss: 33.8208\n",
      "Epoch 1419/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23.3979 - val_loss: 16.2036\n",
      "Epoch 1420/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1615 - val_loss: 19.0385\n",
      "Epoch 1421/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3298 - val_loss: 23.6905\n",
      "Epoch 1422/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2241 - val_loss: 22.8867\n",
      "Epoch 1423/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.2328 - val_loss: 21.2045\n",
      "Epoch 1424/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3203 - val_loss: 17.8902\n",
      "Epoch 1425/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0191 - val_loss: 23.1287\n",
      "Epoch 1426/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.6427 - val_loss: 29.0706\n",
      "Epoch 1427/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5213 - val_loss: 28.6476\n",
      "Epoch 1428/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6109 - val_loss: 18.9977\n",
      "Epoch 1429/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7255 - val_loss: 24.2008\n",
      "Epoch 1430/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7974 - val_loss: 20.0289\n",
      "Epoch 1431/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.3348 - val_loss: 17.1385\n",
      "Epoch 1432/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2217 - val_loss: 30.1191\n",
      "Epoch 1433/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.0151 - val_loss: 18.7227\n",
      "Epoch 1434/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0080 - val_loss: 17.7619\n",
      "Epoch 1435/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5177 - val_loss: 22.7421\n",
      "Epoch 1436/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.2206 - val_loss: 21.4767\n",
      "Epoch 1437/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.8105 - val_loss: 23.5263\n",
      "Epoch 1438/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7092 - val_loss: 27.0958\n",
      "Epoch 1439/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5768 - val_loss: 43.9173\n",
      "Epoch 1440/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7771 - val_loss: 23.5007\n",
      "Epoch 1441/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9379 - val_loss: 25.9249\n",
      "Epoch 1442/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1447 - val_loss: 38.2431\n",
      "Epoch 1443/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6963 - val_loss: 22.9384\n",
      "Epoch 1444/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4582 - val_loss: 24.9179\n",
      "Epoch 1445/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.1681 - val_loss: 17.3655\n",
      "Epoch 1446/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1212 - val_loss: 21.8522\n",
      "Epoch 1447/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7234 - val_loss: 23.4124\n",
      "Epoch 1448/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5339 - val_loss: 25.4228\n",
      "Epoch 1449/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.1265 - val_loss: 23.6466\n",
      "Epoch 1450/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.6011 - val_loss: 20.4297\n",
      "Epoch 1451/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6799 - val_loss: 25.4786\n",
      "Epoch 1452/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5523 - val_loss: 18.5485\n",
      "Epoch 1453/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0873 - val_loss: 27.9471\n",
      "Epoch 1454/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1600 - val_loss: 28.8728\n",
      "Epoch 1455/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5433 - val_loss: 20.7159\n",
      "Epoch 1456/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0774 - val_loss: 27.9877\n",
      "Epoch 1457/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5099 - val_loss: 24.9478\n",
      "Epoch 1458/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.1606 - val_loss: 28.4375\n",
      "Epoch 1459/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5212 - val_loss: 18.4151\n",
      "Epoch 1460/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.0482 - val_loss: 24.6357\n",
      "Epoch 1461/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5188 - val_loss: 16.7705\n",
      "Epoch 1462/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4478 - val_loss: 20.5141\n",
      "Epoch 1463/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8792 - val_loss: 31.1366\n",
      "Epoch 1464/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3244 - val_loss: 26.5185\n",
      "Epoch 1465/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1314 - val_loss: 25.1467\n",
      "Epoch 1466/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5424 - val_loss: 24.8908\n",
      "Epoch 1467/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5503 - val_loss: 22.9125\n",
      "Epoch 1468/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4082 - val_loss: 24.4867\n",
      "Epoch 1469/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5425 - val_loss: 24.3814\n",
      "Epoch 1470/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3696 - val_loss: 24.0086\n",
      "Epoch 1471/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3261 - val_loss: 36.4640\n",
      "Epoch 1472/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1783 - val_loss: 24.6288\n",
      "Epoch 1473/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.0115 - val_loss: 23.1854\n",
      "Epoch 1474/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.2023 - val_loss: 23.8291\n",
      "Epoch 1475/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3305 - val_loss: 22.6189\n",
      "Epoch 1476/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5296 - val_loss: 27.2901\n",
      "Epoch 1477/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.8559 - val_loss: 27.0558\n",
      "Epoch 1478/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4463 - val_loss: 32.7754\n",
      "Epoch 1479/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5869 - val_loss: 15.4190\n",
      "Epoch 1480/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4975 - val_loss: 29.0417\n",
      "Epoch 1481/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3379 - val_loss: 18.5153\n",
      "Epoch 1482/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6433 - val_loss: 18.0522\n",
      "Epoch 1483/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1140 - val_loss: 22.2187\n",
      "Epoch 1484/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4036 - val_loss: 20.5929\n",
      "Epoch 1485/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9534 - val_loss: 28.6393\n",
      "Epoch 1486/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.1212 - val_loss: 16.4698\n",
      "Epoch 1487/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4784 - val_loss: 31.2682\n",
      "Epoch 1488/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.4339 - val_loss: 30.2671\n",
      "Epoch 1489/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0910 - val_loss: 37.1621\n",
      "Epoch 1490/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5749 - val_loss: 28.3379\n",
      "Epoch 1491/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6883 - val_loss: 24.1466\n",
      "Epoch 1492/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.0940 - val_loss: 25.6592\n",
      "Epoch 1493/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2385 - val_loss: 20.6577\n",
      "Epoch 1494/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1270 - val_loss: 20.2699\n",
      "Epoch 1495/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.6256 - val_loss: 22.6245\n",
      "Epoch 1496/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4013 - val_loss: 30.7086\n",
      "Epoch 1497/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9814 - val_loss: 26.5074\n",
      "Epoch 1498/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4364 - val_loss: 32.4180\n",
      "Epoch 1499/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5146 - val_loss: 25.4134\n",
      "Epoch 1500/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.3567 - val_loss: 28.8648\n",
      "Epoch 1501/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.0826 - val_loss: 25.4092\n",
      "Epoch 1502/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2165 - val_loss: 34.3116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1503/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5423 - val_loss: 29.4313\n",
      "Epoch 1504/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6200 - val_loss: 25.4312\n",
      "Epoch 1505/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.2019 - val_loss: 19.6020\n",
      "Epoch 1506/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4947 - val_loss: 16.3695\n",
      "Epoch 1507/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5076 - val_loss: 19.9065\n",
      "Epoch 1508/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6215 - val_loss: 25.2238\n",
      "Epoch 1509/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.3673 - val_loss: 17.0450\n",
      "Epoch 1510/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6897 - val_loss: 44.9311\n",
      "Epoch 1511/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6002 - val_loss: 33.7650\n",
      "Epoch 1512/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4195 - val_loss: 19.5358\n",
      "Epoch 1513/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.2981 - val_loss: 18.9865\n",
      "Epoch 1514/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8809 - val_loss: 30.0277\n",
      "Epoch 1515/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5067 - val_loss: 25.1155\n",
      "Epoch 1516/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.3101 - val_loss: 36.4525\n",
      "Epoch 1517/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7695 - val_loss: 27.5195\n",
      "Epoch 1518/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3648 - val_loss: 21.4399\n",
      "Epoch 1519/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4015 - val_loss: 18.2825\n",
      "Epoch 1520/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.6032 - val_loss: 22.4120\n",
      "Epoch 1521/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.8244 - val_loss: 24.2461\n",
      "Epoch 1522/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4393 - val_loss: 19.5971\n",
      "Epoch 1523/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.0690 - val_loss: 27.2242\n",
      "Epoch 1524/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6362 - val_loss: 23.5760\n",
      "Epoch 1525/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5093 - val_loss: 18.3054\n",
      "Epoch 1526/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.1122 - val_loss: 17.9630\n",
      "Epoch 1527/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.8936 - val_loss: 42.1466\n",
      "Epoch 1528/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4655 - val_loss: 33.0832\n",
      "Epoch 1529/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2898 - val_loss: 27.3248\n",
      "Epoch 1530/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.6167 - val_loss: 17.4544\n",
      "Epoch 1531/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.2162 - val_loss: 21.6587\n",
      "Epoch 1532/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9963 - val_loss: 23.0795\n",
      "Epoch 1533/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.1277 - val_loss: 18.7932\n",
      "Epoch 1534/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.1604 - val_loss: 18.6966\n",
      "Epoch 1535/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9259 - val_loss: 19.1068\n",
      "Epoch 1536/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6251 - val_loss: 19.4369\n",
      "Epoch 1537/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6566 - val_loss: 19.7824\n",
      "Epoch 1538/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6943 - val_loss: 15.6020\n",
      "Epoch 1539/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4009 - val_loss: 31.6598\n",
      "Epoch 1540/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5057 - val_loss: 16.6447\n",
      "Epoch 1541/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.4050 - val_loss: 25.2202\n",
      "Epoch 1542/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.0229 - val_loss: 28.3830\n",
      "Epoch 1543/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1146 - val_loss: 23.1542\n",
      "Epoch 1544/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.9053 - val_loss: 22.6555\n",
      "Epoch 1545/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0119 - val_loss: 24.0225\n",
      "Epoch 1546/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.0939 - val_loss: 23.0291\n",
      "Epoch 1547/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.0012 - val_loss: 24.8379\n",
      "Epoch 1548/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5638 - val_loss: 18.0480\n",
      "Epoch 1549/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2931 - val_loss: 22.9541\n",
      "Epoch 1550/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9864 - val_loss: 29.6781\n",
      "Epoch 1551/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.2438 - val_loss: 21.1787\n",
      "Epoch 1552/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3880 - val_loss: 27.0566\n",
      "Epoch 1553/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6444 - val_loss: 19.0935\n",
      "Epoch 1554/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9187 - val_loss: 32.6484\n",
      "Epoch 1555/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4060 - val_loss: 23.4568\n",
      "Epoch 1556/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4801 - val_loss: 21.4284\n",
      "Epoch 1557/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.2763 - val_loss: 30.5344\n",
      "Epoch 1558/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.3618 - val_loss: 31.8440\n",
      "Epoch 1559/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.1191 - val_loss: 28.3254\n",
      "Epoch 1560/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5466 - val_loss: 28.8571\n",
      "Epoch 1561/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4609 - val_loss: 28.8244\n",
      "Epoch 1562/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2723 - val_loss: 25.0785\n",
      "Epoch 1563/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.8214 - val_loss: 21.0531\n",
      "Epoch 1564/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5794 - val_loss: 31.3405\n",
      "Epoch 1565/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0964 - val_loss: 22.9031\n",
      "Epoch 1566/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4862 - val_loss: 17.9749\n",
      "Epoch 1567/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.1727 - val_loss: 30.8244\n",
      "Epoch 1568/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5100 - val_loss: 23.1867\n",
      "Epoch 1569/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7733 - val_loss: 24.8570\n",
      "Epoch 1570/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.0679 - val_loss: 15.6121\n",
      "Epoch 1571/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2160 - val_loss: 18.5000\n",
      "Epoch 1572/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5760 - val_loss: 26.7938\n",
      "Epoch 1573/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0513 - val_loss: 27.2898\n",
      "Epoch 1574/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4202 - val_loss: 31.8808\n",
      "Epoch 1575/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8178 - val_loss: 18.6237\n",
      "Epoch 1576/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6028 - val_loss: 33.1693\n",
      "Epoch 1577/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4217 - val_loss: 28.0995\n",
      "Epoch 1578/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.6842 - val_loss: 21.6918\n",
      "Epoch 1579/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5089 - val_loss: 24.5820\n",
      "Epoch 1580/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2868 - val_loss: 33.9776\n",
      "Epoch 1581/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3348 - val_loss: 29.1537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1582/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2007 - val_loss: 21.7515\n",
      "Epoch 1583/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.4819 - val_loss: 28.8383\n",
      "Epoch 1584/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7499 - val_loss: 22.0111\n",
      "Epoch 1585/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6006 - val_loss: 22.6883\n",
      "Epoch 1586/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0317 - val_loss: 31.2965\n",
      "Epoch 1587/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4221 - val_loss: 33.7556\n",
      "Epoch 1588/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.6636 - val_loss: 19.7836\n",
      "Epoch 1589/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5070 - val_loss: 20.5390\n",
      "Epoch 1590/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.0286 - val_loss: 31.7380\n",
      "Epoch 1591/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.8083 - val_loss: 20.6408\n",
      "Epoch 1592/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.3359 - val_loss: 32.6853\n",
      "Epoch 1593/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3396 - val_loss: 17.8167\n",
      "Epoch 1594/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.2382 - val_loss: 20.8070\n",
      "Epoch 1595/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2864 - val_loss: 21.8267\n",
      "Epoch 1596/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.2444 - val_loss: 24.9695\n",
      "Epoch 1597/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.8856 - val_loss: 22.3152\n",
      "Epoch 1598/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.4514 - val_loss: 28.0620\n",
      "Epoch 1599/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1877 - val_loss: 19.3498\n",
      "Epoch 1600/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6075 - val_loss: 25.2054\n",
      "Epoch 1601/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4720 - val_loss: 43.6154\n",
      "Epoch 1602/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5173 - val_loss: 36.9080\n",
      "Epoch 1603/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4422 - val_loss: 36.3507\n",
      "Epoch 1604/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5271 - val_loss: 19.4846\n",
      "Epoch 1605/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8530 - val_loss: 31.0380\n",
      "Epoch 1606/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.5767 - val_loss: 19.4181\n",
      "Epoch 1607/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4721 - val_loss: 22.6853\n",
      "Epoch 1608/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.1787 - val_loss: 23.5573\n",
      "Epoch 1609/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.0988 - val_loss: 25.1720\n",
      "Epoch 1610/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.5215 - val_loss: 28.0749\n",
      "Epoch 1611/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.6536 - val_loss: 27.3548\n",
      "Epoch 1612/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6101 - val_loss: 24.1564\n",
      "Epoch 1613/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.2716 - val_loss: 24.7531\n",
      "Epoch 1614/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5802 - val_loss: 20.0689\n",
      "Epoch 1615/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.2862 - val_loss: 31.0421\n",
      "Epoch 1616/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.7215 - val_loss: 23.9830\n",
      "Epoch 1617/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.1678 - val_loss: 23.5760\n",
      "Epoch 1618/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.7712 - val_loss: 24.0964\n",
      "Epoch 1619/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7855 - val_loss: 28.3483\n",
      "Epoch 1620/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5692 - val_loss: 16.8786\n",
      "Epoch 1621/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5879 - val_loss: 32.4977\n",
      "Epoch 1622/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4637 - val_loss: 25.5277\n",
      "Epoch 1623/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.0523 - val_loss: 23.9632\n",
      "Epoch 1624/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0971 - val_loss: 21.1706\n",
      "Epoch 1625/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.2993 - val_loss: 23.9063\n",
      "Epoch 1626/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0495 - val_loss: 25.7810\n",
      "Epoch 1627/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4810 - val_loss: 34.0714\n",
      "Epoch 1628/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1907 - val_loss: 20.5312\n",
      "Epoch 1629/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4814 - val_loss: 29.1522\n",
      "Epoch 1630/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7113 - val_loss: 27.8545\n",
      "Epoch 1631/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4837 - val_loss: 28.2963\n",
      "Epoch 1632/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7364 - val_loss: 32.5659\n",
      "Epoch 1633/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.7976 - val_loss: 23.7259\n",
      "Epoch 1634/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5558 - val_loss: 47.7021\n",
      "Epoch 1635/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.4413 - val_loss: 22.6687\n",
      "Epoch 1636/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1065 - val_loss: 22.3058\n",
      "Epoch 1637/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9513 - val_loss: 26.7641\n",
      "Epoch 1638/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1209 - val_loss: 31.2336\n",
      "Epoch 1639/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2876 - val_loss: 36.1322\n",
      "Epoch 1640/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5091 - val_loss: 39.4360\n",
      "Epoch 1641/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.2013 - val_loss: 22.3224\n",
      "Epoch 1642/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1318 - val_loss: 18.1355\n",
      "Epoch 1643/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7936 - val_loss: 20.6173\n",
      "Epoch 1644/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0343 - val_loss: 25.0839\n",
      "Epoch 1645/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7379 - val_loss: 26.9356\n",
      "Epoch 1646/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5129 - val_loss: 25.1802\n",
      "Epoch 1647/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4895 - val_loss: 26.5422\n",
      "Epoch 1648/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.9063 - val_loss: 21.0925\n",
      "Epoch 1649/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3743 - val_loss: 44.0874\n",
      "Epoch 1650/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8849 - val_loss: 22.1269\n",
      "Epoch 1651/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4544 - val_loss: 24.8309\n",
      "Epoch 1652/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7375 - val_loss: 31.8672\n",
      "Epoch 1653/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3084 - val_loss: 23.5919\n",
      "Epoch 1654/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.2058 - val_loss: 21.6227\n",
      "Epoch 1655/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6803 - val_loss: 25.2735\n",
      "Epoch 1656/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4004 - val_loss: 30.0742\n",
      "Epoch 1657/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1756 - val_loss: 24.1119\n",
      "Epoch 1658/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6751 - val_loss: 33.3495\n",
      "Epoch 1659/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4509 - val_loss: 24.5576\n",
      "Epoch 1660/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7159 - val_loss: 20.9770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1661/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.2085 - val_loss: 26.6595\n",
      "Epoch 1662/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.8864 - val_loss: 35.7633\n",
      "Epoch 1663/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9559 - val_loss: 28.9872\n",
      "Epoch 1664/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7503 - val_loss: 23.3382\n",
      "Epoch 1665/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8472 - val_loss: 39.8022\n",
      "Epoch 1666/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6892 - val_loss: 35.7481\n",
      "Epoch 1667/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.8515 - val_loss: 31.5780\n",
      "Epoch 1668/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3783 - val_loss: 29.9803\n",
      "Epoch 1669/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6413 - val_loss: 36.7599\n",
      "Epoch 1670/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5747 - val_loss: 23.4113\n",
      "Epoch 1671/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.0090 - val_loss: 20.8065\n",
      "Epoch 1672/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2473 - val_loss: 17.6651\n",
      "Epoch 1673/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.8155 - val_loss: 24.5185\n",
      "Epoch 1674/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6049 - val_loss: 23.1915\n",
      "Epoch 1675/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6726 - val_loss: 20.6188\n",
      "Epoch 1676/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7911 - val_loss: 21.1915\n",
      "Epoch 1677/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1708 - val_loss: 22.5196\n",
      "Epoch 1678/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.0125 - val_loss: 19.2587\n",
      "Epoch 1679/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0675 - val_loss: 28.7258\n",
      "Epoch 1680/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.3885 - val_loss: 25.5685\n",
      "Epoch 1681/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9408 - val_loss: 37.5034\n",
      "Epoch 1682/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.5033 - val_loss: 24.2169\n",
      "Epoch 1683/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9021 - val_loss: 23.1777\n",
      "Epoch 1684/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8841 - val_loss: 23.1096\n",
      "Epoch 1685/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8672 - val_loss: 18.3811\n",
      "Epoch 1686/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4016 - val_loss: 21.8457\n",
      "Epoch 1687/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.1331 - val_loss: 28.3867\n",
      "Epoch 1688/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.9364 - val_loss: 22.1668\n",
      "Epoch 1689/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4895 - val_loss: 24.4412\n",
      "Epoch 1690/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7629 - val_loss: 23.3300\n",
      "Epoch 1691/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8898 - val_loss: 28.9457\n",
      "Epoch 1692/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.2965 - val_loss: 18.1300\n",
      "Epoch 1693/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7556 - val_loss: 24.7736\n",
      "Epoch 1694/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0708 - val_loss: 21.7721\n",
      "Epoch 1695/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.2309 - val_loss: 40.0238\n",
      "Epoch 1696/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.0049 - val_loss: 24.3688\n",
      "Epoch 1697/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7909 - val_loss: 26.6888\n",
      "Epoch 1698/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8709 - val_loss: 28.8031\n",
      "Epoch 1699/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.1775 - val_loss: 19.4063\n",
      "Epoch 1700/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7528 - val_loss: 28.6710\n",
      "Epoch 1701/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4349 - val_loss: 33.5633\n",
      "Epoch 1702/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.3085 - val_loss: 19.0711\n",
      "Epoch 1703/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9461 - val_loss: 34.9496\n",
      "Epoch 1704/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.1664 - val_loss: 27.1429\n",
      "Epoch 1705/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2116 - val_loss: 33.3267\n",
      "Epoch 1706/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.5249 - val_loss: 27.6240\n",
      "Epoch 1707/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5702 - val_loss: 31.1835\n",
      "Epoch 1708/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.5682 - val_loss: 40.0517\n",
      "Epoch 1709/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8554 - val_loss: 20.0362\n",
      "Epoch 1710/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6698 - val_loss: 19.7136\n",
      "Epoch 1711/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.0651 - val_loss: 23.2904\n",
      "Epoch 1712/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1052 - val_loss: 21.5292\n",
      "Epoch 1713/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7798 - val_loss: 27.5553\n",
      "Epoch 1714/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.7404 - val_loss: 24.4565\n",
      "Epoch 1715/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4497 - val_loss: 30.8200\n",
      "Epoch 1716/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.8101 - val_loss: 22.1537\n",
      "Epoch 1717/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1671 - val_loss: 21.3971\n",
      "Epoch 1718/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.1453 - val_loss: 17.2477\n",
      "Epoch 1719/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.8346 - val_loss: 24.9616\n",
      "Epoch 1720/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.2793 - val_loss: 22.7515\n",
      "Epoch 1721/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.3710 - val_loss: 35.9041\n",
      "Epoch 1722/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 20.9519 - val_loss: 20.6677\n",
      "Epoch 1723/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6568 - val_loss: 17.8223\n",
      "Epoch 1724/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.2862 - val_loss: 19.6407\n",
      "Epoch 1725/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3927 - val_loss: 18.8255\n",
      "Epoch 1726/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6403 - val_loss: 20.2156\n",
      "Epoch 1727/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9914 - val_loss: 25.1615\n",
      "Epoch 1728/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.1395 - val_loss: 21.3449\n",
      "Epoch 1729/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2925 - val_loss: 29.2514\n",
      "Epoch 1730/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.1311 - val_loss: 19.5944\n",
      "Epoch 1731/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7605 - val_loss: 25.1623\n",
      "Epoch 1732/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6875 - val_loss: 20.1415\n",
      "Epoch 1733/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.6392 - val_loss: 23.4488\n",
      "Epoch 1734/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.7899 - val_loss: 27.3400\n",
      "Epoch 1735/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7073 - val_loss: 25.8158\n",
      "Epoch 1736/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.0684 - val_loss: 21.5041\n",
      "Epoch 1737/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.7391 - val_loss: 21.6022\n",
      "Epoch 1738/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.8117 - val_loss: 20.5340\n",
      "Epoch 1739/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 19.7545 - val_loss: 33.4913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1740/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.6884 - val_loss: 41.2001\n",
      "Epoch 1741/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.3355 - val_loss: 22.7491\n",
      "Epoch 1742/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7359 - val_loss: 25.5799\n",
      "Epoch 1743/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.1549 - val_loss: 21.5034\n",
      "Epoch 1744/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.1689 - val_loss: 33.1838\n",
      "Epoch 1745/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3604 - val_loss: 31.9607\n",
      "Epoch 1746/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.4162 - val_loss: 23.6560\n",
      "Epoch 1747/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.8125 - val_loss: 28.9845\n",
      "Epoch 1748/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.9516 - val_loss: 36.2552\n",
      "Epoch 1749/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.6458 - val_loss: 30.7085\n",
      "Epoch 1750/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1289 - val_loss: 30.5352\n",
      "Epoch 1751/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.8989 - val_loss: 23.4479\n",
      "Epoch 1752/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.3180 - val_loss: 27.1371\n",
      "Epoch 1753/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.8703 - val_loss: 29.6653\n",
      "Epoch 1754/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 17.8657 - val_loss: 28.5367\n",
      "Epoch 1755/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4145 - val_loss: 19.0981\n",
      "Epoch 1756/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3175 - val_loss: 23.1024\n",
      "Epoch 1757/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.2666 - val_loss: 30.5236\n",
      "Epoch 1758/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.0374 - val_loss: 18.1384\n",
      "Epoch 1759/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.4674 - val_loss: 16.9489\n",
      "Epoch 1760/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8402 - val_loss: 18.8467\n",
      "Epoch 1761/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.7717 - val_loss: 21.1928\n",
      "Epoch 1762/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.4258 - val_loss: 20.6910\n",
      "Epoch 1763/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7543 - val_loss: 20.8917\n",
      "Epoch 1764/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9494 - val_loss: 19.5373\n",
      "Epoch 1765/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.3780 - val_loss: 38.2490\n",
      "Epoch 1766/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.1659 - val_loss: 20.4833\n",
      "Epoch 1767/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.4713 - val_loss: 19.0471\n",
      "Epoch 1768/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2403 - val_loss: 31.2566\n",
      "Epoch 1769/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.1955 - val_loss: 18.6564\n",
      "Epoch 1770/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8277 - val_loss: 28.1811\n",
      "Epoch 1771/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.9834 - val_loss: 26.2914\n",
      "Epoch 1772/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.5831 - val_loss: 27.9282\n",
      "Epoch 1773/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.8383 - val_loss: 23.8147\n",
      "Epoch 1774/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5910 - val_loss: 16.0298\n",
      "Epoch 1775/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4178 - val_loss: 19.8518\n",
      "Epoch 1776/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.7512 - val_loss: 18.6038\n",
      "Epoch 1777/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.3679 - val_loss: 31.8584\n",
      "Epoch 1778/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4674 - val_loss: 39.5877\n",
      "Epoch 1779/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.7610 - val_loss: 29.8018\n",
      "Epoch 1780/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.0450 - val_loss: 27.2272\n",
      "Epoch 1781/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.7721 - val_loss: 19.5693\n",
      "Epoch 1782/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3153 - val_loss: 20.5644\n",
      "Epoch 1783/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6868 - val_loss: 22.1009\n",
      "Epoch 1784/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.9177 - val_loss: 29.1558\n",
      "Epoch 1785/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3002 - val_loss: 22.5550\n",
      "Epoch 1786/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.4810 - val_loss: 24.6512\n",
      "Epoch 1787/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.6644 - val_loss: 21.7277\n",
      "Epoch 1788/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 15.2639 - val_loss: 26.3833\n",
      "Epoch 1789/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.9000 - val_loss: 27.4597\n",
      "Epoch 1790/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.4223 - val_loss: 16.8666\n",
      "Epoch 1791/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.3731 - val_loss: 33.8029\n",
      "Epoch 1792/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.4027 - val_loss: 28.0464\n",
      "Epoch 1793/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1061Restoring model weights from the end of the best epoch: 1293.\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.0807 - val_loss: 24.9337\n",
      "Epoch 1793: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>53.553566</td>\n",
       "      <td>53.553543</td>\n",
       "      <td>53.553467</td>\n",
       "      <td>53.553482</td>\n",
       "      <td>53.552773</td>\n",
       "      <td>53.525467</td>\n",
       "      <td>11.442562</td>\n",
       "      <td>11.63927</td>\n",
       "      <td>21.789314</td>\n",
       "      <td>22.958199</td>\n",
       "      <td>4.008727</td>\n",
       "      <td>53.446518</td>\n",
       "      <td>3.484991</td>\n",
       "      <td>-8.091105</td>\n",
       "      <td>3.965674</td>\n",
       "      <td>12.857436</td>\n",
       "      <td>38.846252</td>\n",
       "      <td>-7.578867</td>\n",
       "      <td>-8.538363</td>\n",
       "      <td>-8.513203</td>\n",
       "      <td>-8.532068</td>\n",
       "      <td>-8.568899</td>\n",
       "      <td>-8.668713</td>\n",
       "      <td>-8.765547</td>\n",
       "      <td>-8.992937</td>\n",
       "      <td>-8.776243</td>\n",
       "      <td>-8.533916</td>\n",
       "      <td>-2.51832</td>\n",
       "      <td>48.971687</td>\n",
       "      <td>53.552322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>48.75</td>\n",
       "      <td>59.738</td>\n",
       "      <td>60.303</td>\n",
       "      <td>51.009</td>\n",
       "      <td>48.874</td>\n",
       "      <td>48.506</td>\n",
       "      <td>42.721</td>\n",
       "      <td>32.801</td>\n",
       "      <td>37.638</td>\n",
       "      <td>37.358</td>\n",
       "      <td>31.339</td>\n",
       "      <td>45.311</td>\n",
       "      <td>42.085</td>\n",
       "      <td>48.52</td>\n",
       "      <td>41.365</td>\n",
       "      <td>43.813</td>\n",
       "      <td>43.816</td>\n",
       "      <td>38.245</td>\n",
       "      <td>46.081</td>\n",
       "      <td>38.703</td>\n",
       "      <td>36.037</td>\n",
       "      <td>38.43</td>\n",
       "      <td>44.471</td>\n",
       "      <td>37.884</td>\n",
       "      <td>51.585</td>\n",
       "      <td>54.306</td>\n",
       "      <td>52.511</td>\n",
       "      <td>59.472</td>\n",
       "      <td>54.022</td>\n",
       "      <td>49.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>4.803566</td>\n",
       "      <td>6.184456</td>\n",
       "      <td>6.749535</td>\n",
       "      <td>2.544483</td>\n",
       "      <td>4.678772</td>\n",
       "      <td>5.019466</td>\n",
       "      <td>31.278439</td>\n",
       "      <td>21.161728</td>\n",
       "      <td>15.848686</td>\n",
       "      <td>14.399803</td>\n",
       "      <td>27.330273</td>\n",
       "      <td>8.135517</td>\n",
       "      <td>38.60001</td>\n",
       "      <td>56.611107</td>\n",
       "      <td>37.399326</td>\n",
       "      <td>30.955563</td>\n",
       "      <td>4.969749</td>\n",
       "      <td>45.823868</td>\n",
       "      <td>54.619362</td>\n",
       "      <td>47.216202</td>\n",
       "      <td>44.569069</td>\n",
       "      <td>46.998901</td>\n",
       "      <td>53.139713</td>\n",
       "      <td>46.649544</td>\n",
       "      <td>60.577934</td>\n",
       "      <td>63.082245</td>\n",
       "      <td>61.044918</td>\n",
       "      <td>61.990318</td>\n",
       "      <td>5.050312</td>\n",
       "      <td>3.761322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1          2          3          4          5   \\\n",
       "Month         Month-1    Month-2    Month-3    Month-4    Month-5    Month-6   \n",
       "Prediction  53.553566  53.553543  53.553467  53.553482  53.552773  53.525467   \n",
       "Target          48.75     59.738     60.303     51.009     48.874     48.506   \n",
       "Error        4.803566   6.184456   6.749535   2.544483   4.678772   5.019466   \n",
       "\n",
       "                   6          7          8          9          10         11  \\\n",
       "Month         Month-7    Month-8    Month-9   Month-10   Month-11   Month-12   \n",
       "Prediction  11.442562   11.63927  21.789314  22.958199   4.008727  53.446518   \n",
       "Target         42.721     32.801     37.638     37.358     31.339     45.311   \n",
       "Error       31.278439  21.161728  15.848686  14.399803  27.330273   8.135517   \n",
       "\n",
       "                  12         13         14         15         16         17  \\\n",
       "Month       Month-13   Month-14   Month-15   Month-16   Month-17   Month-18   \n",
       "Prediction  3.484991  -8.091105   3.965674  12.857436  38.846252  -7.578867   \n",
       "Target        42.085      48.52     41.365     43.813     43.816     38.245   \n",
       "Error       38.60001  56.611107  37.399326  30.955563   4.969749  45.823868   \n",
       "\n",
       "                   18         19         20         21         22         23  \\\n",
       "Month        Month-19   Month-20   Month-21   Month-22   Month-23   Month-24   \n",
       "Prediction  -8.538363  -8.513203  -8.532068  -8.568899  -8.668713  -8.765547   \n",
       "Target         46.081     38.703     36.037      38.43     44.471     37.884   \n",
       "Error       54.619362  47.216202  44.569069  46.998901  53.139713  46.649544   \n",
       "\n",
       "                   24         25         26         27         28         29  \n",
       "Month        Month-25   Month-26   Month-27   Month-28   Month-29   Month-30  \n",
       "Prediction  -8.992937  -8.776243  -8.533916   -2.51832  48.971687  53.552322  \n",
       "Target         51.585     54.306     52.511     59.472     54.022     49.791  \n",
       "Error       60.577934  63.082245  61.044918  61.990318   5.050312   3.761322  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.373137"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6935299"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[446.5769]] - Target[544.3480000000001]| =  Error: [[97.77112]]; MAPE:[[0.17961141]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[-8.102407]] - Target[499.45000000000005]| =  Error: [[507.55243]]; MAPE:[[1.0162227]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-5: |Prediction[[73.70259]] - Target[321.687]| =  Error: [[247.98442]]; MAPE:[[0.77088726]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[97.77112]], dtype=float32),\n",
       " array([[507.55243]], dtype=float32),\n",
       " array([[247.98442]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "284.436"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6555738"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
