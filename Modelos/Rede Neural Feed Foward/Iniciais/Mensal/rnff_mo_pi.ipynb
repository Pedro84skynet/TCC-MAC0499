{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Piauí - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Piauí - IDH</th>\n",
       "      <th>Piauí - Produção de Cimento (t)</th>\n",
       "      <th>Piauí - PIB - Estadual</th>\n",
       "      <th>Piauí - PIB - Construção Civil</th>\n",
       "      <th>Piauí - PIB - Per Capita</th>\n",
       "      <th>Piauí - PIB - Preços de Mercado</th>\n",
       "      <th>Piauí - Desemprego</th>\n",
       "      <th>Piauí - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>0.649218</td>\n",
       "      <td>24.669760</td>\n",
       "      <td>2.136063e+07</td>\n",
       "      <td>1.358044e+06</td>\n",
       "      <td>6.061141</td>\n",
       "      <td>1.868149e+07</td>\n",
       "      <td>8.192266</td>\n",
       "      <td>21.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>0.649661</td>\n",
       "      <td>25.167145</td>\n",
       "      <td>2.139102e+07</td>\n",
       "      <td>1.359835e+06</td>\n",
       "      <td>6.065065</td>\n",
       "      <td>1.869506e+07</td>\n",
       "      <td>8.186156</td>\n",
       "      <td>15.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>0.650104</td>\n",
       "      <td>25.520404</td>\n",
       "      <td>2.142142e+07</td>\n",
       "      <td>1.361626e+06</td>\n",
       "      <td>6.068988</td>\n",
       "      <td>1.870864e+07</td>\n",
       "      <td>8.180046</td>\n",
       "      <td>16.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>0.650548</td>\n",
       "      <td>25.519725</td>\n",
       "      <td>2.145181e+07</td>\n",
       "      <td>1.363417e+06</td>\n",
       "      <td>6.072912</td>\n",
       "      <td>1.872222e+07</td>\n",
       "      <td>8.173937</td>\n",
       "      <td>14.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>0.650991</td>\n",
       "      <td>25.929312</td>\n",
       "      <td>2.148221e+07</td>\n",
       "      <td>1.365208e+06</td>\n",
       "      <td>6.076835</td>\n",
       "      <td>1.873580e+07</td>\n",
       "      <td>8.167827</td>\n",
       "      <td>17.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.957215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.965575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.977734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.994123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.015266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0       2003-1                                          0.724032   \n",
       "1       2003-2                                          0.690297   \n",
       "2       2003-3                                          0.669681   \n",
       "3       2003-4                                          0.660494   \n",
       "4       2003-5                                          0.648337   \n",
       "..         ...                                               ...   \n",
       "235     2022-8                                               NaN   \n",
       "236     2022-9                                               NaN   \n",
       "237    2022-10                                               NaN   \n",
       "238    2022-11                                               NaN   \n",
       "239    2022-12                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Piauí - IDH  \\\n",
       "0                              7.330309e+06   0.969649     0.649218   \n",
       "1                              7.335910e+06   0.950783     0.649661   \n",
       "2                              7.341511e+06   0.938332     0.650104   \n",
       "3                              7.347112e+06   0.926401     0.650548   \n",
       "4                              7.352713e+06   0.951683     0.650991   \n",
       "..                                      ...        ...          ...   \n",
       "235                                     NaN        NaN          NaN   \n",
       "236                                     NaN        NaN          NaN   \n",
       "237                                     NaN        NaN          NaN   \n",
       "238                                     NaN        NaN          NaN   \n",
       "239                                     NaN        NaN          NaN   \n",
       "\n",
       "     Piauí - Produção de Cimento (t)  Piauí - PIB - Estadual  \\\n",
       "0                          24.669760            2.136063e+07   \n",
       "1                          25.167145            2.139102e+07   \n",
       "2                          25.520404            2.142142e+07   \n",
       "3                          25.519725            2.145181e+07   \n",
       "4                          25.929312            2.148221e+07   \n",
       "..                               ...                     ...   \n",
       "235                        12.957215                     NaN   \n",
       "236                        12.965575                     NaN   \n",
       "237                        12.977734                     NaN   \n",
       "238                        12.994123                     NaN   \n",
       "239                        13.015266                     NaN   \n",
       "\n",
       "     Piauí - PIB - Construção Civil  Piauí - PIB - Per Capita  \\\n",
       "0                      1.358044e+06                  6.061141   \n",
       "1                      1.359835e+06                  6.065065   \n",
       "2                      1.361626e+06                  6.068988   \n",
       "3                      1.363417e+06                  6.072912   \n",
       "4                      1.365208e+06                  6.076835   \n",
       "..                              ...                       ...   \n",
       "235                             NaN                       NaN   \n",
       "236                             NaN                       NaN   \n",
       "237                             NaN                       NaN   \n",
       "238                             NaN                       NaN   \n",
       "239                             NaN                       NaN   \n",
       "\n",
       "     Piauí - PIB - Preços de Mercado  Piauí - Desemprego  \\\n",
       "0                       1.868149e+07            8.192266   \n",
       "1                       1.869506e+07            8.186156   \n",
       "2                       1.870864e+07            8.180046   \n",
       "3                       1.872222e+07            8.173937   \n",
       "4                       1.873580e+07            8.167827   \n",
       "..                               ...                 ...   \n",
       "235                              NaN                 NaN   \n",
       "236                              NaN                 NaN   \n",
       "237                              NaN                 NaN   \n",
       "238                              NaN                 NaN   \n",
       "239                              NaN                 NaN   \n",
       "\n",
       "     Piauí - Consumo de Cimento (t)  \n",
       "0                            21.844  \n",
       "1                            15.814  \n",
       "2                            16.067  \n",
       "3                            14.938  \n",
       "4                            17.765  \n",
       "..                              ...  \n",
       "235                          77.776  \n",
       "236                          72.377  \n",
       "237                          71.791  \n",
       "238                          71.015  \n",
       "239                          71.015  \n",
       "\n",
       "[240 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_PI.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Piauí - IDH</th>\n",
       "      <th>Piauí - Produção de Cimento (t)</th>\n",
       "      <th>Piauí - PIB - Estadual</th>\n",
       "      <th>Piauí - PIB - Construção Civil</th>\n",
       "      <th>Piauí - PIB - Per Capita</th>\n",
       "      <th>Piauí - PIB - Preços de Mercado</th>\n",
       "      <th>Piauí - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-2.255392</td>\n",
       "      <td>-1.240720</td>\n",
       "      <td>-1.669677</td>\n",
       "      <td>-2.498915</td>\n",
       "      <td>-2.014630</td>\n",
       "      <td>-1.966414</td>\n",
       "      <td>-0.747080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-2.215344</td>\n",
       "      <td>-1.193299</td>\n",
       "      <td>-1.652630</td>\n",
       "      <td>-2.431501</td>\n",
       "      <td>-1.986722</td>\n",
       "      <td>-1.939126</td>\n",
       "      <td>-0.751564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-2.175296</td>\n",
       "      <td>-1.159620</td>\n",
       "      <td>-1.635584</td>\n",
       "      <td>-2.364087</td>\n",
       "      <td>-1.958813</td>\n",
       "      <td>-1.911838</td>\n",
       "      <td>-0.756047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-2.135248</td>\n",
       "      <td>-1.159684</td>\n",
       "      <td>-1.618537</td>\n",
       "      <td>-2.296673</td>\n",
       "      <td>-1.930905</td>\n",
       "      <td>-1.884550</td>\n",
       "      <td>-0.760531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-2.095200</td>\n",
       "      <td>-1.120635</td>\n",
       "      <td>-1.601491</td>\n",
       "      <td>-2.229259</td>\n",
       "      <td>-1.902997</td>\n",
       "      <td>-1.857261</td>\n",
       "      <td>-0.765014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.336332</td>\n",
       "      <td>-1.934378</td>\n",
       "      <td>1.184371</td>\n",
       "      <td>0.511529</td>\n",
       "      <td>1.001536</td>\n",
       "      <td>1.022413</td>\n",
       "      <td>1.331534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.329819</td>\n",
       "      <td>-1.960422</td>\n",
       "      <td>1.174437</td>\n",
       "      <td>0.526506</td>\n",
       "      <td>0.987984</td>\n",
       "      <td>1.008864</td>\n",
       "      <td>1.330230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.323306</td>\n",
       "      <td>-1.985417</td>\n",
       "      <td>1.164504</td>\n",
       "      <td>0.541484</td>\n",
       "      <td>0.974431</td>\n",
       "      <td>0.995315</td>\n",
       "      <td>1.328926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.316792</td>\n",
       "      <td>-2.009327</td>\n",
       "      <td>1.154570</td>\n",
       "      <td>0.556461</td>\n",
       "      <td>0.960879</td>\n",
       "      <td>0.981765</td>\n",
       "      <td>1.327622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.310279</td>\n",
       "      <td>-2.032113</td>\n",
       "      <td>1.144637</td>\n",
       "      <td>0.571438</td>\n",
       "      <td>0.947326</td>\n",
       "      <td>0.968216</td>\n",
       "      <td>1.326318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Piauí - IDH  \\\n",
       "0                                 -2.389042   3.122582    -2.255392   \n",
       "1                                 -2.352139   2.970356    -2.215344   \n",
       "2                                 -2.315236   2.869895    -2.175296   \n",
       "3                                 -2.278333   2.773628    -2.135248   \n",
       "4                                 -2.241431   2.977624    -2.095200   \n",
       "..                                      ...        ...          ...   \n",
       "187                                0.389193  -1.749976     1.336332   \n",
       "188                                0.370392  -1.593005     1.329819   \n",
       "189                                0.351592  -1.351489     1.323306   \n",
       "190                                0.332791  -1.198492     1.316792   \n",
       "191                                0.313991  -1.100894     1.310279   \n",
       "\n",
       "     Piauí - Produção de Cimento (t)  Piauí - PIB - Estadual  \\\n",
       "0                          -1.240720               -1.669677   \n",
       "1                          -1.193299               -1.652630   \n",
       "2                          -1.159620               -1.635584   \n",
       "3                          -1.159684               -1.618537   \n",
       "4                          -1.120635               -1.601491   \n",
       "..                               ...                     ...   \n",
       "187                        -1.934378                1.184371   \n",
       "188                        -1.960422                1.174437   \n",
       "189                        -1.985417                1.164504   \n",
       "190                        -2.009327                1.154570   \n",
       "191                        -2.032113                1.144637   \n",
       "\n",
       "     Piauí - PIB - Construção Civil  Piauí - PIB - Per Capita  \\\n",
       "0                         -2.498915                 -2.014630   \n",
       "1                         -2.431501                 -1.986722   \n",
       "2                         -2.364087                 -1.958813   \n",
       "3                         -2.296673                 -1.930905   \n",
       "4                         -2.229259                 -1.902997   \n",
       "..                              ...                       ...   \n",
       "187                        0.511529                  1.001536   \n",
       "188                        0.526506                  0.987984   \n",
       "189                        0.541484                  0.974431   \n",
       "190                        0.556461                  0.960879   \n",
       "191                        0.571438                  0.947326   \n",
       "\n",
       "     Piauí - PIB - Preços de Mercado  Piauí - Desemprego  \n",
       "0                          -1.966414           -0.747080  \n",
       "1                          -1.939126           -0.751564  \n",
       "2                          -1.911838           -0.756047  \n",
       "3                          -1.884550           -0.760531  \n",
       "4                          -1.857261           -0.765014  \n",
       "..                               ...                 ...  \n",
       "187                         1.022413            1.331534  \n",
       "188                         1.008864            1.330230  \n",
       "189                         0.995315            1.328926  \n",
       "190                         0.981765            1.327622  \n",
       "191                         0.968216            1.326318  \n",
       "\n",
       "[192 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      18.413\n",
       "1      16.605\n",
       "2      22.084\n",
       "3      22.445\n",
       "4      23.323\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Piauí - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Piauí - IDH</th>\n",
       "      <th>Piauí - Produção de Cimento (t)</th>\n",
       "      <th>Piauí - PIB - Estadual</th>\n",
       "      <th>Piauí - PIB - Construção Civil</th>\n",
       "      <th>Piauí - PIB - Per Capita</th>\n",
       "      <th>Piauí - PIB - Preços de Mercado</th>\n",
       "      <th>Piauí - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-2.255392</td>\n",
       "      <td>-1.240720</td>\n",
       "      <td>-1.669677</td>\n",
       "      <td>-2.498915</td>\n",
       "      <td>-2.014630</td>\n",
       "      <td>-1.966414</td>\n",
       "      <td>-0.747080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-2.215344</td>\n",
       "      <td>-1.193299</td>\n",
       "      <td>-1.652630</td>\n",
       "      <td>-2.431501</td>\n",
       "      <td>-1.986722</td>\n",
       "      <td>-1.939126</td>\n",
       "      <td>-0.751564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-2.175296</td>\n",
       "      <td>-1.159620</td>\n",
       "      <td>-1.635584</td>\n",
       "      <td>-2.364087</td>\n",
       "      <td>-1.958813</td>\n",
       "      <td>-1.911838</td>\n",
       "      <td>-0.756047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-2.135248</td>\n",
       "      <td>-1.159684</td>\n",
       "      <td>-1.618537</td>\n",
       "      <td>-2.296673</td>\n",
       "      <td>-1.930905</td>\n",
       "      <td>-1.884550</td>\n",
       "      <td>-0.760531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-2.095200</td>\n",
       "      <td>-1.120635</td>\n",
       "      <td>-1.601491</td>\n",
       "      <td>-2.229259</td>\n",
       "      <td>-1.902997</td>\n",
       "      <td>-1.857261</td>\n",
       "      <td>-0.765014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>1.382405</td>\n",
       "      <td>-0.210180</td>\n",
       "      <td>1.192759</td>\n",
       "      <td>0.339852</td>\n",
       "      <td>1.041980</td>\n",
       "      <td>1.070621</td>\n",
       "      <td>1.460989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>1.385453</td>\n",
       "      <td>-0.282985</td>\n",
       "      <td>1.199072</td>\n",
       "      <td>0.340094</td>\n",
       "      <td>1.049362</td>\n",
       "      <td>1.077532</td>\n",
       "      <td>1.459107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>1.388501</td>\n",
       "      <td>-0.356527</td>\n",
       "      <td>1.205385</td>\n",
       "      <td>0.340336</td>\n",
       "      <td>1.056744</td>\n",
       "      <td>1.084444</td>\n",
       "      <td>1.457225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>1.391549</td>\n",
       "      <td>-0.430817</td>\n",
       "      <td>1.211698</td>\n",
       "      <td>0.340578</td>\n",
       "      <td>1.064126</td>\n",
       "      <td>1.091356</td>\n",
       "      <td>1.455343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>1.394598</td>\n",
       "      <td>-0.505868</td>\n",
       "      <td>1.218011</td>\n",
       "      <td>0.340819</td>\n",
       "      <td>1.071508</td>\n",
       "      <td>1.098268</td>\n",
       "      <td>1.453462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Piauí - IDH  \\\n",
       "0                                 -2.389042   3.122582    -2.255392   \n",
       "1                                 -2.352139   2.970356    -2.215344   \n",
       "2                                 -2.315236   2.869895    -2.175296   \n",
       "3                                 -2.278333   2.773628    -2.135248   \n",
       "4                                 -2.241431   2.977624    -2.095200   \n",
       "..                                      ...        ...          ...   \n",
       "157                                0.819304  -0.883659     1.382405   \n",
       "158                                0.808136  -0.950771     1.385453   \n",
       "159                                0.796969  -1.028465     1.388501   \n",
       "160                                0.785801  -1.103668     1.391549   \n",
       "161                                0.774634  -0.978419     1.394598   \n",
       "\n",
       "     Piauí - Produção de Cimento (t)  Piauí - PIB - Estadual  \\\n",
       "0                          -1.240720               -1.669677   \n",
       "1                          -1.193299               -1.652630   \n",
       "2                          -1.159620               -1.635584   \n",
       "3                          -1.159684               -1.618537   \n",
       "4                          -1.120635               -1.601491   \n",
       "..                               ...                     ...   \n",
       "157                        -0.210180                1.192759   \n",
       "158                        -0.282985                1.199072   \n",
       "159                        -0.356527                1.205385   \n",
       "160                        -0.430817                1.211698   \n",
       "161                        -0.505868                1.218011   \n",
       "\n",
       "     Piauí - PIB - Construção Civil  Piauí - PIB - Per Capita  \\\n",
       "0                         -2.498915                 -2.014630   \n",
       "1                         -2.431501                 -1.986722   \n",
       "2                         -2.364087                 -1.958813   \n",
       "3                         -2.296673                 -1.930905   \n",
       "4                         -2.229259                 -1.902997   \n",
       "..                              ...                       ...   \n",
       "157                        0.339852                  1.041980   \n",
       "158                        0.340094                  1.049362   \n",
       "159                        0.340336                  1.056744   \n",
       "160                        0.340578                  1.064126   \n",
       "161                        0.340819                  1.071508   \n",
       "\n",
       "     Piauí - PIB - Preços de Mercado  Piauí - Desemprego  \n",
       "0                          -1.966414           -0.747080  \n",
       "1                          -1.939126           -0.751564  \n",
       "2                          -1.911838           -0.756047  \n",
       "3                          -1.884550           -0.760531  \n",
       "4                          -1.857261           -0.765014  \n",
       "..                               ...                 ...  \n",
       "157                         1.070621            1.460989  \n",
       "158                         1.077532            1.459107  \n",
       "159                         1.084444            1.457225  \n",
       "160                         1.091356            1.455343  \n",
       "161                         1.098268            1.453462  \n",
       "\n",
       "[162 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      18.413\n",
       "1      16.605\n",
       "2      22.084\n",
       "3      22.445\n",
       "4      23.323\n",
       "        ...  \n",
       "157    54.656\n",
       "158    69.984\n",
       "159    58.643\n",
       "160    72.337\n",
       "161    70.968\n",
       "Name: Piauí - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Piauí - IDH</th>\n",
       "      <th>Piauí - Produção de Cimento (t)</th>\n",
       "      <th>Piauí - PIB - Estadual</th>\n",
       "      <th>Piauí - PIB - Construção Civil</th>\n",
       "      <th>Piauí - PIB - Per Capita</th>\n",
       "      <th>Piauí - PIB - Preços de Mercado</th>\n",
       "      <th>Piauí - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>1.397646</td>\n",
       "      <td>-0.581677</td>\n",
       "      <td>1.224324</td>\n",
       "      <td>0.341061</td>\n",
       "      <td>1.078891</td>\n",
       "      <td>1.105179</td>\n",
       "      <td>1.451580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>1.400694</td>\n",
       "      <td>-0.658262</td>\n",
       "      <td>1.230638</td>\n",
       "      <td>0.341303</td>\n",
       "      <td>1.086273</td>\n",
       "      <td>1.112091</td>\n",
       "      <td>1.449698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>1.403742</td>\n",
       "      <td>-0.735635</td>\n",
       "      <td>1.236951</td>\n",
       "      <td>0.341545</td>\n",
       "      <td>1.093655</td>\n",
       "      <td>1.119003</td>\n",
       "      <td>1.447816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>1.406790</td>\n",
       "      <td>-0.813815</td>\n",
       "      <td>1.243264</td>\n",
       "      <td>0.341787</td>\n",
       "      <td>1.101037</td>\n",
       "      <td>1.125915</td>\n",
       "      <td>1.445934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>1.409838</td>\n",
       "      <td>-0.892819</td>\n",
       "      <td>1.249577</td>\n",
       "      <td>0.342029</td>\n",
       "      <td>1.108419</td>\n",
       "      <td>1.132826</td>\n",
       "      <td>1.444052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>1.412886</td>\n",
       "      <td>-0.972668</td>\n",
       "      <td>1.255890</td>\n",
       "      <td>0.342271</td>\n",
       "      <td>1.115801</td>\n",
       "      <td>1.139738</td>\n",
       "      <td>1.442171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>1.415934</td>\n",
       "      <td>-1.053381</td>\n",
       "      <td>1.262203</td>\n",
       "      <td>0.342513</td>\n",
       "      <td>1.123183</td>\n",
       "      <td>1.146650</td>\n",
       "      <td>1.440289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>1.413100</td>\n",
       "      <td>-1.134978</td>\n",
       "      <td>1.261512</td>\n",
       "      <td>0.347861</td>\n",
       "      <td>1.120952</td>\n",
       "      <td>1.144201</td>\n",
       "      <td>1.431987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>1.410266</td>\n",
       "      <td>-1.212485</td>\n",
       "      <td>1.260820</td>\n",
       "      <td>0.353209</td>\n",
       "      <td>1.118720</td>\n",
       "      <td>1.141751</td>\n",
       "      <td>1.423685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>1.407432</td>\n",
       "      <td>-1.291035</td>\n",
       "      <td>1.260129</td>\n",
       "      <td>0.358557</td>\n",
       "      <td>1.116488</td>\n",
       "      <td>1.139302</td>\n",
       "      <td>1.415383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>1.404598</td>\n",
       "      <td>-1.354649</td>\n",
       "      <td>1.259438</td>\n",
       "      <td>0.363905</td>\n",
       "      <td>1.114257</td>\n",
       "      <td>1.136853</td>\n",
       "      <td>1.407080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>1.401764</td>\n",
       "      <td>-1.410693</td>\n",
       "      <td>1.258746</td>\n",
       "      <td>0.369253</td>\n",
       "      <td>1.112025</td>\n",
       "      <td>1.134404</td>\n",
       "      <td>1.398778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>1.398930</td>\n",
       "      <td>-1.464176</td>\n",
       "      <td>1.258055</td>\n",
       "      <td>0.374601</td>\n",
       "      <td>1.109793</td>\n",
       "      <td>1.131955</td>\n",
       "      <td>1.390476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>1.396096</td>\n",
       "      <td>-1.517651</td>\n",
       "      <td>1.257363</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>1.107562</td>\n",
       "      <td>1.129505</td>\n",
       "      <td>1.382174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>1.393262</td>\n",
       "      <td>-1.568450</td>\n",
       "      <td>1.256672</td>\n",
       "      <td>0.385297</td>\n",
       "      <td>1.105330</td>\n",
       "      <td>1.127056</td>\n",
       "      <td>1.373872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>1.390428</td>\n",
       "      <td>-1.611131</td>\n",
       "      <td>1.255980</td>\n",
       "      <td>0.390645</td>\n",
       "      <td>1.103098</td>\n",
       "      <td>1.124607</td>\n",
       "      <td>1.365570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>1.387594</td>\n",
       "      <td>-1.653372</td>\n",
       "      <td>1.255289</td>\n",
       "      <td>0.395993</td>\n",
       "      <td>1.100867</td>\n",
       "      <td>1.122158</td>\n",
       "      <td>1.357268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>1.384760</td>\n",
       "      <td>-1.692491</td>\n",
       "      <td>1.254597</td>\n",
       "      <td>0.401341</td>\n",
       "      <td>1.098635</td>\n",
       "      <td>1.119709</td>\n",
       "      <td>1.348966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>1.381926</td>\n",
       "      <td>-1.725704</td>\n",
       "      <td>1.253906</td>\n",
       "      <td>0.406689</td>\n",
       "      <td>1.096403</td>\n",
       "      <td>1.117259</td>\n",
       "      <td>1.340664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>1.375413</td>\n",
       "      <td>-1.758110</td>\n",
       "      <td>1.243972</td>\n",
       "      <td>0.421666</td>\n",
       "      <td>1.082851</td>\n",
       "      <td>1.103710</td>\n",
       "      <td>1.339360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>1.368900</td>\n",
       "      <td>-1.789700</td>\n",
       "      <td>1.234039</td>\n",
       "      <td>0.436643</td>\n",
       "      <td>1.069298</td>\n",
       "      <td>1.090161</td>\n",
       "      <td>1.338055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>1.362386</td>\n",
       "      <td>-1.820450</td>\n",
       "      <td>1.224105</td>\n",
       "      <td>0.451620</td>\n",
       "      <td>1.055746</td>\n",
       "      <td>1.076611</td>\n",
       "      <td>1.336751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>1.355873</td>\n",
       "      <td>-1.850326</td>\n",
       "      <td>1.214172</td>\n",
       "      <td>0.466598</td>\n",
       "      <td>1.042194</td>\n",
       "      <td>1.063062</td>\n",
       "      <td>1.335447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>1.349359</td>\n",
       "      <td>-1.879295</td>\n",
       "      <td>1.204238</td>\n",
       "      <td>0.481575</td>\n",
       "      <td>1.028641</td>\n",
       "      <td>1.049512</td>\n",
       "      <td>1.334143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>1.342846</td>\n",
       "      <td>-1.907324</td>\n",
       "      <td>1.194304</td>\n",
       "      <td>0.496552</td>\n",
       "      <td>1.015089</td>\n",
       "      <td>1.035963</td>\n",
       "      <td>1.332839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.336332</td>\n",
       "      <td>-1.934378</td>\n",
       "      <td>1.184371</td>\n",
       "      <td>0.511529</td>\n",
       "      <td>1.001536</td>\n",
       "      <td>1.022413</td>\n",
       "      <td>1.331534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.329819</td>\n",
       "      <td>-1.960422</td>\n",
       "      <td>1.174437</td>\n",
       "      <td>0.526506</td>\n",
       "      <td>0.987984</td>\n",
       "      <td>1.008864</td>\n",
       "      <td>1.330230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.323306</td>\n",
       "      <td>-1.985417</td>\n",
       "      <td>1.164504</td>\n",
       "      <td>0.541484</td>\n",
       "      <td>0.974431</td>\n",
       "      <td>0.995315</td>\n",
       "      <td>1.328926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.316792</td>\n",
       "      <td>-2.009327</td>\n",
       "      <td>1.154570</td>\n",
       "      <td>0.556461</td>\n",
       "      <td>0.960879</td>\n",
       "      <td>0.981765</td>\n",
       "      <td>1.327622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.310279</td>\n",
       "      <td>-2.032113</td>\n",
       "      <td>1.144637</td>\n",
       "      <td>0.571438</td>\n",
       "      <td>0.947326</td>\n",
       "      <td>0.968216</td>\n",
       "      <td>1.326318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162                                         -0.601510   \n",
       "163                                         -0.786068   \n",
       "164                                         -0.830387   \n",
       "165                                         -0.801089   \n",
       "166                                         -0.959917   \n",
       "167                                         -1.022309   \n",
       "168                                         -1.074401   \n",
       "169                                         -1.119597   \n",
       "170                                         -1.078648   \n",
       "171                                         -1.055426   \n",
       "172                                         -1.101053   \n",
       "173                                         -1.211370   \n",
       "174                                         -1.157198   \n",
       "175                                         -1.223444   \n",
       "176                                         -1.311519   \n",
       "177                                         -1.362602   \n",
       "178                                         -1.380125   \n",
       "179                                         -1.219296   \n",
       "180                                         -1.300284   \n",
       "181                                         -1.336476   \n",
       "182                                         -1.415774   \n",
       "183                                         -1.526021   \n",
       "184                                         -1.681806   \n",
       "185                                         -1.735167   \n",
       "186                                         -1.962315   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Piauí - IDH  \\\n",
       "162                                0.763466  -1.213929     1.397646   \n",
       "163                                0.752299  -1.292173     1.400694   \n",
       "164                                0.741131  -1.324219     1.403742   \n",
       "165                                0.729964  -1.344446     1.406790   \n",
       "166                                0.718796  -1.381638     1.409838   \n",
       "167                                0.707629  -1.411208     1.412886   \n",
       "168                                0.696461  -1.412953     1.415934   \n",
       "169                                0.681823  -1.491464     1.413100   \n",
       "170                                0.667184  -1.573805     1.410266   \n",
       "171                                0.652545  -1.564950     1.407432   \n",
       "172                                0.637906  -1.581584     1.404598   \n",
       "173                                0.623268  -1.565976     1.401764   \n",
       "174                                0.608629  -1.648556     1.398930   \n",
       "175                                0.593990  -1.650049     1.396096   \n",
       "176                                0.579351  -1.653957     1.393262   \n",
       "177                                0.564713  -1.652572     1.390428   \n",
       "178                                0.550074  -1.715349     1.387594   \n",
       "179                                0.535435  -1.750917     1.384760   \n",
       "180                                0.520796  -1.718448     1.381926   \n",
       "181                                0.501996  -1.733426     1.375413   \n",
       "182                                0.483195  -1.729362     1.368900   \n",
       "183                                0.464395  -1.748544     1.362386   \n",
       "184                                0.445594  -1.778060     1.355873   \n",
       "185                                0.426794  -1.773710     1.349359   \n",
       "186                                0.407993  -1.757007     1.342846   \n",
       "187                                0.389193  -1.749976     1.336332   \n",
       "188                                0.370392  -1.593005     1.329819   \n",
       "189                                0.351592  -1.351489     1.323306   \n",
       "190                                0.332791  -1.198492     1.316792   \n",
       "191                                0.313991  -1.100894     1.310279   \n",
       "\n",
       "     Piauí - Produção de Cimento (t)  Piauí - PIB - Estadual  \\\n",
       "162                        -0.581677                1.224324   \n",
       "163                        -0.658262                1.230638   \n",
       "164                        -0.735635                1.236951   \n",
       "165                        -0.813815                1.243264   \n",
       "166                        -0.892819                1.249577   \n",
       "167                        -0.972668                1.255890   \n",
       "168                        -1.053381                1.262203   \n",
       "169                        -1.134978                1.261512   \n",
       "170                        -1.212485                1.260820   \n",
       "171                        -1.291035                1.260129   \n",
       "172                        -1.354649                1.259438   \n",
       "173                        -1.410693                1.258746   \n",
       "174                        -1.464176                1.258055   \n",
       "175                        -1.517651                1.257363   \n",
       "176                        -1.568450                1.256672   \n",
       "177                        -1.611131                1.255980   \n",
       "178                        -1.653372                1.255289   \n",
       "179                        -1.692491                1.254597   \n",
       "180                        -1.725704                1.253906   \n",
       "181                        -1.758110                1.243972   \n",
       "182                        -1.789700                1.234039   \n",
       "183                        -1.820450                1.224105   \n",
       "184                        -1.850326                1.214172   \n",
       "185                        -1.879295                1.204238   \n",
       "186                        -1.907324                1.194304   \n",
       "187                        -1.934378                1.184371   \n",
       "188                        -1.960422                1.174437   \n",
       "189                        -1.985417                1.164504   \n",
       "190                        -2.009327                1.154570   \n",
       "191                        -2.032113                1.144637   \n",
       "\n",
       "     Piauí - PIB - Construção Civil  Piauí - PIB - Per Capita  \\\n",
       "162                        0.341061                  1.078891   \n",
       "163                        0.341303                  1.086273   \n",
       "164                        0.341545                  1.093655   \n",
       "165                        0.341787                  1.101037   \n",
       "166                        0.342029                  1.108419   \n",
       "167                        0.342271                  1.115801   \n",
       "168                        0.342513                  1.123183   \n",
       "169                        0.347861                  1.120952   \n",
       "170                        0.353209                  1.118720   \n",
       "171                        0.358557                  1.116488   \n",
       "172                        0.363905                  1.114257   \n",
       "173                        0.369253                  1.112025   \n",
       "174                        0.374601                  1.109793   \n",
       "175                        0.379949                  1.107562   \n",
       "176                        0.385297                  1.105330   \n",
       "177                        0.390645                  1.103098   \n",
       "178                        0.395993                  1.100867   \n",
       "179                        0.401341                  1.098635   \n",
       "180                        0.406689                  1.096403   \n",
       "181                        0.421666                  1.082851   \n",
       "182                        0.436643                  1.069298   \n",
       "183                        0.451620                  1.055746   \n",
       "184                        0.466598                  1.042194   \n",
       "185                        0.481575                  1.028641   \n",
       "186                        0.496552                  1.015089   \n",
       "187                        0.511529                  1.001536   \n",
       "188                        0.526506                  0.987984   \n",
       "189                        0.541484                  0.974431   \n",
       "190                        0.556461                  0.960879   \n",
       "191                        0.571438                  0.947326   \n",
       "\n",
       "     Piauí - PIB - Preços de Mercado  Piauí - Desemprego  \n",
       "162                         1.105179            1.451580  \n",
       "163                         1.112091            1.449698  \n",
       "164                         1.119003            1.447816  \n",
       "165                         1.125915            1.445934  \n",
       "166                         1.132826            1.444052  \n",
       "167                         1.139738            1.442171  \n",
       "168                         1.146650            1.440289  \n",
       "169                         1.144201            1.431987  \n",
       "170                         1.141751            1.423685  \n",
       "171                         1.139302            1.415383  \n",
       "172                         1.136853            1.407080  \n",
       "173                         1.134404            1.398778  \n",
       "174                         1.131955            1.390476  \n",
       "175                         1.129505            1.382174  \n",
       "176                         1.127056            1.373872  \n",
       "177                         1.124607            1.365570  \n",
       "178                         1.122158            1.357268  \n",
       "179                         1.119709            1.348966  \n",
       "180                         1.117259            1.340664  \n",
       "181                         1.103710            1.339360  \n",
       "182                         1.090161            1.338055  \n",
       "183                         1.076611            1.336751  \n",
       "184                         1.063062            1.335447  \n",
       "185                         1.049512            1.334143  \n",
       "186                         1.035963            1.332839  \n",
       "187                         1.022413            1.331534  \n",
       "188                         1.008864            1.330230  \n",
       "189                         0.995315            1.328926  \n",
       "190                         0.981765            1.327622  \n",
       "191                         0.968216            1.326318  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    75.913\n",
       "163    74.774\n",
       "164    72.484\n",
       "165    71.534\n",
       "166    70.320\n",
       "167    67.364\n",
       "168    59.688\n",
       "169    40.259\n",
       "170    41.239\n",
       "171    45.035\n",
       "172    42.477\n",
       "173    57.619\n",
       "174    53.109\n",
       "175    63.141\n",
       "176    55.580\n",
       "177    60.001\n",
       "178    62.767\n",
       "179    45.308\n",
       "180    57.142\n",
       "181    46.283\n",
       "182    43.390\n",
       "183    40.824\n",
       "184    55.063\n",
       "185    56.474\n",
       "186    68.133\n",
       "187    68.642\n",
       "188    64.741\n",
       "189    71.269\n",
       "190    67.631\n",
       "191    62.845\n",
       "Name: Piauí - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    train, train_val = validation_splitter(train_input, 8)\n",
    "    target,target_val = validation_splitter(train_target, 8)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val, target_val),\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4121761216, 3905059143, 2654542077, 2470464604, 187176261, 1689011358, 1962526129, 3163657453, 2562722345, 1984944408, 41051988, 2558800775, 1553869388, 528453202, 988644813, 3967487080, 2643060102, 4025605482, 247896754, 556665803, 1776816470, 761443290, 2177346346, 115890705, 3354919160]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 17.42163848876953\n",
      "winner_seed: 4121761216\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 20.529523849487305\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 23.375125885009766\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 21.93442153930664\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 22.27463150024414\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 17.776607513427734\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 15.633512496948242\n",
      "winner_seed: 1962526129\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 24.277324676513672\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 17.079065322875977\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 20.55915641784668\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 22.40818977355957\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 23.762466430664062\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 23.39225959777832\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 22.41900634765625\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 20.73914337158203\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 21.275760650634766\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 22.340341567993164\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 22.21477699279785\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 19.45464324951172\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 19.310054779052734\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 22.091480255126953\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 21.396915435791016\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 26.20086097717285\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 24.106660842895508\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 23.170284271240234\n",
      "\n",
      "\n",
      "final_seed: 1962526129\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 1s 26ms/step - loss: 2443.0247 - val_loss: 1948.3652\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2028.1067 - val_loss: 2218.2258\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2207.3862 - val_loss: 2763.6919\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2144.8013 - val_loss: 2114.3862\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1475.6202 - val_loss: 401.8625\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 907.5742 - val_loss: 261.1328\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1013.1503 - val_loss: 1438.4813\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1440.5437 - val_loss: 1315.3861\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1286.4066 - val_loss: 1110.7117\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1076.0171 - val_loss: 1459.5702\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1153.0790 - val_loss: 944.1820\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 980.0484 - val_loss: 779.5360\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 900.0092 - val_loss: 621.3983\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 489.0007 - val_loss: 457.9391\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 499.3844 - val_loss: 106.0254\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 133.7770 - val_loss: 107.0184\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 142.4509 - val_loss: 105.5030\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 135.1610 - val_loss: 108.0792\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 137.3329 - val_loss: 106.6492\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 132.5809 - val_loss: 108.4025\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 141.1662 - val_loss: 120.6416\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 135.4853 - val_loss: 105.9538\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 134.3248 - val_loss: 99.5266\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 127.5779 - val_loss: 92.5521\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 124.9276 - val_loss: 138.0469\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 132.8607 - val_loss: 85.2756\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 125.9380 - val_loss: 85.2806\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 124.2524 - val_loss: 103.3825\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 124.6119 - val_loss: 88.3313\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 116.2553 - val_loss: 81.6881\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 112.4347 - val_loss: 95.2178\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 119.3387 - val_loss: 91.0857\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 118.5479 - val_loss: 83.8389\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 116.4695 - val_loss: 105.1800\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 119.4110 - val_loss: 85.7651\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 118.4010 - val_loss: 99.7871\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 118.1758 - val_loss: 107.6240\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 127.8832 - val_loss: 94.9835\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 123.2939 - val_loss: 83.9183\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 115.8810 - val_loss: 84.9403\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.4854 - val_loss: 83.6831\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 116.7427 - val_loss: 98.0287\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 119.2966 - val_loss: 83.0696\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 112.6019 - val_loss: 90.9637\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.7845 - val_loss: 103.0703\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 116.2858 - val_loss: 97.3318\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.6854 - val_loss: 85.3691\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.7493 - val_loss: 90.1711\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.2852 - val_loss: 82.6448\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.9139 - val_loss: 88.4816\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 118.2249 - val_loss: 90.4343\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 118.9278 - val_loss: 85.7151\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.2652 - val_loss: 82.5609\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.7597 - val_loss: 86.0577\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 116.5426 - val_loss: 99.0018\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.7976 - val_loss: 87.6545\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 118.4785 - val_loss: 85.5457\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.1950 - val_loss: 89.5224\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 131.3503 - val_loss: 110.5515\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.7754 - val_loss: 76.2068\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.4185 - val_loss: 85.8519\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.2145 - val_loss: 108.0817\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 118.4873 - val_loss: 92.0479\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.2857 - val_loss: 80.7658\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.0460 - val_loss: 87.0166\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 111.2170 - val_loss: 94.6940\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.7486 - val_loss: 83.2721\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.2170 - val_loss: 83.3285\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.3035 - val_loss: 83.9519\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.4693 - val_loss: 83.8489\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.1690 - val_loss: 83.4947\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.1430 - val_loss: 81.7462\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.2605 - val_loss: 81.8419\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.4021 - val_loss: 93.7373\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.9935 - val_loss: 99.4422\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.2310 - val_loss: 98.9824\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.1827 - val_loss: 99.4219\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 112.8371 - val_loss: 85.0992\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.2369 - val_loss: 84.7372\n",
      "Epoch 80/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 101.3006 - val_loss: 81.4722\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.9620 - val_loss: 81.2988\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.2661 - val_loss: 101.6977\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.1714 - val_loss: 85.6862\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.3868 - val_loss: 82.1080\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.5496 - val_loss: 89.4799\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.2650 - val_loss: 81.6692\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.9098 - val_loss: 91.5014\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.5627 - val_loss: 85.4096\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.1305 - val_loss: 88.4072\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.2007 - val_loss: 85.2392\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.7981 - val_loss: 85.8643\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.7496 - val_loss: 89.1375\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.9207 - val_loss: 81.4737\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.5090 - val_loss: 83.5518\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 107.6530 - val_loss: 107.9108\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 113.2063 - val_loss: 91.3230\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.2425 - val_loss: 74.4294\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 106.6129 - val_loss: 80.2235\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 105.6817 - val_loss: 86.6483\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.6992 - val_loss: 83.1666\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 107.9238 - val_loss: 84.2564\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 104.5480 - val_loss: 81.3806\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 108.9515 - val_loss: 80.8646\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.7901 - val_loss: 87.0823\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.6645 - val_loss: 81.3899\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.6208 - val_loss: 84.9749\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.8408 - val_loss: 88.5915\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.2769 - val_loss: 93.2529\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.8747 - val_loss: 105.6492\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 117.7665 - val_loss: 88.7352\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.3367 - val_loss: 83.4539\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.9537 - val_loss: 88.5647\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.2729 - val_loss: 106.2437\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 114.1732 - val_loss: 82.1571\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.5211 - val_loss: 82.7161\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.8255 - val_loss: 90.8898\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 106.5679 - val_loss: 81.4554\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.8498 - val_loss: 101.9126\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 110.6791 - val_loss: 108.8322\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 108.4346 - val_loss: 81.9301\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.9127 - val_loss: 81.8557\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.2567 - val_loss: 85.7287\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 101.0886 - val_loss: 94.7923\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 126.0340 - val_loss: 80.5985\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.8239 - val_loss: 84.8721\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.0759 - val_loss: 81.1461\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.3312 - val_loss: 85.9142\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.8341 - val_loss: 77.6842\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.1325 - val_loss: 94.6109\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 102.9192 - val_loss: 87.0645\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.7674 - val_loss: 86.5253\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 105.8594 - val_loss: 113.3308\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.0271 - val_loss: 82.3911\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.4260 - val_loss: 82.9098\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.2558 - val_loss: 84.3416\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.5506 - val_loss: 81.7371\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.5355 - val_loss: 81.7923\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.1116 - val_loss: 83.9616\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.4273 - val_loss: 83.9453\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.6670 - val_loss: 83.8716\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.7485 - val_loss: 94.0486\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103.4222 - val_loss: 83.4761\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.3137 - val_loss: 81.8443\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.3144 - val_loss: 85.3985\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 101.2225 - val_loss: 86.1676\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.3440 - val_loss: 133.1927\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 114.8726 - val_loss: 88.7336\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.0130 - val_loss: 89.4415\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.4120 - val_loss: 84.8515\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.1064 - val_loss: 87.6890\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.6500 - val_loss: 82.1432\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.4677 - val_loss: 67.2091\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.5260 - val_loss: 73.6197\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.9137 - val_loss: 69.6379\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 94.2558 - val_loss: 78.0892\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.7638 - val_loss: 74.8743\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.0706 - val_loss: 64.1367\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 71.9215 - val_loss: 51.3677\n",
      "Epoch 159/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 63.0495 - val_loss: 78.1225\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.9994 - val_loss: 63.5058\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 83.7220 - val_loss: 84.3186\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 85.6016 - val_loss: 56.3095\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.0486 - val_loss: 48.8162\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 58.7860 - val_loss: 61.4750\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 65.2662 - val_loss: 45.6730\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 56.4227 - val_loss: 41.2646\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.7178 - val_loss: 41.7734\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53.5873 - val_loss: 45.1230\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 46.6153 - val_loss: 49.2342\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 46.9475 - val_loss: 39.2305\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53.0173 - val_loss: 36.0302\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.4822 - val_loss: 58.6419\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53.5998 - val_loss: 43.9187\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 42.5256 - val_loss: 49.5775\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 60.9799 - val_loss: 36.0825\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.6691 - val_loss: 43.1378\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 50.5188 - val_loss: 32.1731\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 44.9916 - val_loss: 113.8956\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.3701 - val_loss: 47.9613\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.2230 - val_loss: 47.5537\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 48.2955 - val_loss: 36.6179\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 37.6064 - val_loss: 37.0942\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 36.6568 - val_loss: 47.7449\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 36.6659 - val_loss: 40.4411\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 39.4296 - val_loss: 43.4738\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 35.9948 - val_loss: 44.7743\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.0370 - val_loss: 35.7404\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.1049 - val_loss: 45.8531\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 39.4891 - val_loss: 154.4082\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 111.6700 - val_loss: 74.6573\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.1270 - val_loss: 80.9036\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.1259 - val_loss: 64.9415\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.0741 - val_loss: 70.5855\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 75.4958 - val_loss: 90.8450\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.8283 - val_loss: 102.3867\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.2275 - val_loss: 80.6333\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.4248 - val_loss: 81.2841\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.6804 - val_loss: 81.0639\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.6787 - val_loss: 87.5549\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.0223 - val_loss: 81.1734\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 97.0313 - val_loss: 82.7878\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 99.5950 - val_loss: 82.5314\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.9276 - val_loss: 81.8452\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.1323 - val_loss: 83.6775\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.0732 - val_loss: 81.2568\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 99.2218 - val_loss: 82.8024\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.2858 - val_loss: 82.0098\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.4991 - val_loss: 81.5759\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 104.0196 - val_loss: 139.8990\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.3786 - val_loss: 81.9319\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.3765 - val_loss: 91.7018\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.4385 - val_loss: 75.9919\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.1246 - val_loss: 79.7896\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.9390 - val_loss: 75.3093\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 100.4799 - val_loss: 77.1165\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.2989 - val_loss: 81.8869\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.3093 - val_loss: 76.7647\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 102.7235 - val_loss: 84.4477\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 109.2139 - val_loss: 71.1519\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 98.6887 - val_loss: 68.3857\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.8570 - val_loss: 46.7572\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 68.0419 - val_loss: 63.7838\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53.9651 - val_loss: 40.4700\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.4199 - val_loss: 41.3674\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 50.7557 - val_loss: 40.0668\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 50.7819 - val_loss: 80.5164\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.2439 - val_loss: 43.4368\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 41.2240 - val_loss: 43.7469\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.1053 - val_loss: 43.6379\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.9273 - val_loss: 40.6821\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 45.0742 - val_loss: 45.9549\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 48.0233 - val_loss: 54.7457\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 43.8174 - val_loss: 40.9741\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 79.4438 - val_loss: 61.3987\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 96.9475 - val_loss: 58.5044\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.9708 - val_loss: 34.9210\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.3434 - val_loss: 26.7085\n",
      "Epoch 238/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 49.3309 - val_loss: 30.5672\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 47.8003 - val_loss: 18.3162\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 38.1106 - val_loss: 27.4216\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 39.1281 - val_loss: 31.6366\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.2604 - val_loss: 42.8468\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 62.8539 - val_loss: 74.5520\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 65.5873 - val_loss: 38.9109\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 61.6167 - val_loss: 43.5452\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 69.7186 - val_loss: 47.0626\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 65.0922 - val_loss: 35.8856\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.0692 - val_loss: 36.3873\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.1268 - val_loss: 37.1776\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 48.4501 - val_loss: 38.9123\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.2265 - val_loss: 69.6560\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 61.5244 - val_loss: 44.1579\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 60.8189 - val_loss: 69.4698\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 104.4553 - val_loss: 77.6493\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87.9872 - val_loss: 56.9183\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 85.8531 - val_loss: 86.7518\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.4541 - val_loss: 55.3864\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.0934 - val_loss: 54.7502\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 73.8354 - val_loss: 49.6016\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69.1895 - val_loss: 47.1538\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 72.2505 - val_loss: 49.9717\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 66.1709 - val_loss: 45.6419\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 63.0819 - val_loss: 47.8766\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 60.5540 - val_loss: 73.2782\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 100.0549 - val_loss: 67.6674\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 83.9878 - val_loss: 44.3677\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 64.3191 - val_loss: 70.3485\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 93.8199 - val_loss: 71.5215\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.6535 - val_loss: 108.2889\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 89.4497 - val_loss: 62.0031\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 86.1149 - val_loss: 49.8445\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 65.0195 - val_loss: 52.1707\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54.9289 - val_loss: 41.1654\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 53.0144 - val_loss: 36.7056\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.3070 - val_loss: 42.5099\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 410.6098 - val_loss: 612.1578\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 504.8022 - val_loss: 63.9696\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49.0063 - val_loss: 38.7070\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.9178 - val_loss: 37.9030\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37.0046 - val_loss: 39.6227\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 35.0768 - val_loss: 43.0950\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51.0940 - val_loss: 37.4265\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 33.8261 - val_loss: 38.7985\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.9715 - val_loss: 37.6722\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.9361 - val_loss: 42.7376\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 36.1068 - val_loss: 30.4532\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 35.3972 - val_loss: 34.4100\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 34.1534 - val_loss: 38.9704\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 34.3939 - val_loss: 33.7833\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 35.6750 - val_loss: 24.2214\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 34.2634 - val_loss: 34.3911\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 29.8522 - val_loss: 42.6110\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.0373 - val_loss: 39.6372\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 36.7108 - val_loss: 40.7704\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 36.9292 - val_loss: 46.0640\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 37.9068 - val_loss: 42.4769\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 35.8225 - val_loss: 37.4616\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.0828 - val_loss: 36.1738\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 34.8196 - val_loss: 24.8693\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 41.5677 - val_loss: 40.9321\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 29.3985 - val_loss: 35.3758\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.8828 - val_loss: 37.4479\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 34.0472 - val_loss: 38.0219\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 34.9314 - val_loss: 48.3895\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 33.0312 - val_loss: 31.7944\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 38.1031 - val_loss: 35.5398\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.6593 - val_loss: 32.0729\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.1570 - val_loss: 38.1230\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 31.3315 - val_loss: 50.5926\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 34.5857 - val_loss: 23.1127\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 33.2594 - val_loss: 37.2777\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 29.0545 - val_loss: 47.8508\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 36.7339 - val_loss: 65.7562\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 43.2179 - val_loss: 38.6276\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 32.5194 - val_loss: 37.0138\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.7210 - val_loss: 39.2250\n",
      "Epoch 317/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 29.0616 - val_loss: 38.7091\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.1666 - val_loss: 42.0478\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 35.9307 - val_loss: 53.2369\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37.2670 - val_loss: 29.6850\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 36.0695 - val_loss: 37.4984\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 33.5272 - val_loss: 24.1224\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 34.4474 - val_loss: 41.1946\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 33.6999 - val_loss: 35.1372\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 29.8173 - val_loss: 31.0821\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 30.9188 - val_loss: 41.9748\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 33.7458 - val_loss: 31.3380\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.7810 - val_loss: 34.5852\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.8385 - val_loss: 31.6425\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 28.2929 - val_loss: 36.4062\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.5825 - val_loss: 27.6297\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.7729 - val_loss: 34.5513\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 28.9083 - val_loss: 27.5045\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.1006 - val_loss: 30.0818\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 29.9640 - val_loss: 44.1878\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.7119 - val_loss: 28.6615\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 33.9188 - val_loss: 26.6215\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.5460 - val_loss: 34.6486\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 36.6503 - val_loss: 40.3635\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 30.5664 - val_loss: 48.6906\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 30.1731 - val_loss: 36.5624\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.3888 - val_loss: 33.6623\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.7391 - val_loss: 46.3598\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.2876 - val_loss: 32.9395\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.9155 - val_loss: 36.4722\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.1049 - val_loss: 37.1669\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.2021 - val_loss: 35.0204\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.8316 - val_loss: 34.6172\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.9877 - val_loss: 41.0367\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.8792 - val_loss: 36.3215\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.2704 - val_loss: 40.0521\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.8511 - val_loss: 37.5610\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.6934 - val_loss: 29.9884\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.9120 - val_loss: 36.2654\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.7453 - val_loss: 33.0718\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 29.6018 - val_loss: 38.8706\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 29.9899 - val_loss: 37.4601\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.2629 - val_loss: 30.9765\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.3196 - val_loss: 32.1742\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.9796 - val_loss: 18.8258\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 38.1870 - val_loss: 30.3420\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.2861 - val_loss: 38.7321\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.0236 - val_loss: 44.5667\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 29.5585 - val_loss: 38.8850\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.7487 - val_loss: 54.2147\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 34.7691 - val_loss: 50.6351\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.8394 - val_loss: 44.5263\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.4259 - val_loss: 47.8838\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 31.6408 - val_loss: 48.3907\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 29.0700 - val_loss: 31.9964\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.5624 - val_loss: 46.5517\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.7298 - val_loss: 36.1077\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.8556 - val_loss: 41.2450\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.8728 - val_loss: 35.8623\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 25.0096 - val_loss: 41.9094\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.9375 - val_loss: 37.8335\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.9233 - val_loss: 41.4127\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.7473 - val_loss: 125.3152\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 73.8385 - val_loss: 30.3152\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 31.9551 - val_loss: 27.7092\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 29.7531 - val_loss: 39.4117\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.5014 - val_loss: 46.1982\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.6421 - val_loss: 37.9636\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 26.7622 - val_loss: 35.9832\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 27.4222 - val_loss: 36.3210\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 26.7391 - val_loss: 34.1831\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.0817 - val_loss: 33.4865\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 25.4312 - val_loss: 36.9822\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.6557 - val_loss: 40.1063\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 33.2462 - val_loss: 34.7147\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.3748 - val_loss: 41.4004\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 34.4396 - val_loss: 36.4063\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 31.3469 - val_loss: 27.7589\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.0516 - val_loss: 26.7279\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.0829 - val_loss: 25.5304\n",
      "Epoch 396/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 29.1458 - val_loss: 35.6211\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 28.8635 - val_loss: 41.7016\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 29.1238 - val_loss: 40.1779\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.8989 - val_loss: 43.0029\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.3934 - val_loss: 41.6045\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.7078 - val_loss: 33.9699\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.8489 - val_loss: 36.2356\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.4245 - val_loss: 35.7782\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.1138 - val_loss: 41.5993\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.4875 - val_loss: 38.5181\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.5740 - val_loss: 42.9261\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.4094 - val_loss: 44.0519\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.1112 - val_loss: 35.3992\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.7074 - val_loss: 36.7820\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.0161 - val_loss: 37.9044\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.9397 - val_loss: 34.2813\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.2185 - val_loss: 32.2500\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.5854 - val_loss: 33.4892\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 26.5445 - val_loss: 33.8333\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.1512 - val_loss: 42.4077\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.3997 - val_loss: 46.1455\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.8478 - val_loss: 40.1007\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.0226 - val_loss: 47.0228\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.1069 - val_loss: 34.9889\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.7635 - val_loss: 38.2197\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.9385 - val_loss: 33.8020\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.4170 - val_loss: 41.7063\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.4187 - val_loss: 45.2379\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 26.5839 - val_loss: 40.5762\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.8993 - val_loss: 36.6993\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.9668 - val_loss: 42.3989\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.4004 - val_loss: 39.6430\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.7891 - val_loss: 45.5320\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.3203 - val_loss: 33.6606\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.0468 - val_loss: 31.1535\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.3628 - val_loss: 36.6178\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.3474 - val_loss: 36.8372\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.0013 - val_loss: 43.2369\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.4277 - val_loss: 37.3455\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.1355 - val_loss: 21.0289\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.8456 - val_loss: 26.3623\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.2231 - val_loss: 28.8660\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.7360 - val_loss: 26.7129\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.0067 - val_loss: 29.7752\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.2573 - val_loss: 33.9166\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.6356 - val_loss: 31.8755\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6964 - val_loss: 30.8256\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.1211 - val_loss: 33.3192\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5642 - val_loss: 32.9643\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.9964 - val_loss: 37.1895\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.8386 - val_loss: 29.5643\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.5609 - val_loss: 27.7138\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.3080 - val_loss: 36.4397\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4564 - val_loss: 38.5537\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.4574 - val_loss: 30.3045\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.5362 - val_loss: 39.0598\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 29.1371 - val_loss: 27.8645\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3669 - val_loss: 35.7512\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.0567 - val_loss: 29.2510\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.0004 - val_loss: 28.1977\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.1287 - val_loss: 30.4812\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.4771 - val_loss: 40.8231\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 23.5381 - val_loss: 31.0784\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.2800 - val_loss: 28.9838\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.5926 - val_loss: 32.1353\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.9439 - val_loss: 38.6229\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.7113 - val_loss: 26.4570\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.9214 - val_loss: 29.8781\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.5579 - val_loss: 35.8170\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4689 - val_loss: 29.7710\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7120 - val_loss: 33.1708\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.8958 - val_loss: 34.1973\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.6413 - val_loss: 31.4339\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4319 - val_loss: 31.1609\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.1233 - val_loss: 32.5617\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.4612 - val_loss: 30.1047\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.6710 - val_loss: 26.9868\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.7183 - val_loss: 31.2436\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 25.7045 - val_loss: 30.4908\n",
      "Epoch 475/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 25.9353 - val_loss: 33.1087\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.2376 - val_loss: 36.8170\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.8326 - val_loss: 30.6645\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.4194 - val_loss: 32.2724\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.0070 - val_loss: 29.1904\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.9223 - val_loss: 27.8090\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.2400 - val_loss: 28.4938\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.7523 - val_loss: 33.0747\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.0561 - val_loss: 35.2704\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.2894 - val_loss: 35.6752\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.4578 - val_loss: 36.5773\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3719 - val_loss: 33.6858\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.2869 - val_loss: 33.8605\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6760 - val_loss: 37.6121\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.7368 - val_loss: 32.1469\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.9338 - val_loss: 29.2458\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.9163 - val_loss: 31.8050\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.9237 - val_loss: 28.7306\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.6296 - val_loss: 27.8534\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3901 - val_loss: 30.4971\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.3302 - val_loss: 32.1548\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5857 - val_loss: 31.7717\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7477 - val_loss: 32.2625\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4522 - val_loss: 32.6029\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6842 - val_loss: 29.7931\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.9220 - val_loss: 34.0055\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 22.7913 - val_loss: 31.7955\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 20.2373 - val_loss: 31.3582\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 20.0707 - val_loss: 30.5863\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.6026 - val_loss: 29.9664\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3487 - val_loss: 30.4506\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.7535 - val_loss: 31.7966\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 22.5420 - val_loss: 29.9658\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.9174 - val_loss: 33.5445\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4468 - val_loss: 34.0123\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0125 - val_loss: 35.9305\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.0105 - val_loss: 31.1912\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 18.6047 - val_loss: 29.5043\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.5360 - val_loss: 26.4330\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.3307 - val_loss: 30.9762\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.1730 - val_loss: 29.5207\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6008 - val_loss: 40.8945\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.3484 - val_loss: 35.4522\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0892 - val_loss: 27.5053\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3793 - val_loss: 29.0163\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6152 - val_loss: 30.0986\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.4700 - val_loss: 32.1025\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.3001 - val_loss: 45.8572\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.1150 - val_loss: 39.9845\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.5669 - val_loss: 38.4873\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.2045 - val_loss: 32.7111\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.9269 - val_loss: 40.9150\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.2659 - val_loss: 36.7223\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.4098 - val_loss: 37.0671\n",
      "Epoch 529/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.9590 - val_loss: 36.1242\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.8757 - val_loss: 29.8707\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.3237 - val_loss: 31.0568\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.9601 - val_loss: 31.0375\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3836 - val_loss: 44.9569\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.8657 - val_loss: 31.9835\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.7098 - val_loss: 29.5723\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.2594 - val_loss: 28.6837\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.1337 - val_loss: 34.2975\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.1446 - val_loss: 38.8789\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4899 - val_loss: 38.5538\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.6276 - val_loss: 35.4715\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 21.1672 - val_loss: 24.1222\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.5360 - val_loss: 26.2635\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7584 - val_loss: 31.7717\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.6675 - val_loss: 27.8239\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.0363 - val_loss: 28.6204\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.3934 - val_loss: 26.2684\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.1141 - val_loss: 26.0797\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.8501 - val_loss: 39.4605\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.1875 - val_loss: 41.2854\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6459 - val_loss: 44.3263\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.5441 - val_loss: 31.1600\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.6934 - val_loss: 34.6630\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.3641 - val_loss: 29.2491\n",
      "Epoch 554/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3092 - val_loss: 48.3488\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.7249 - val_loss: 41.6143\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.6313 - val_loss: 40.5630\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1729 - val_loss: 39.2501\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.4700 - val_loss: 39.7535\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.5961 - val_loss: 31.0513\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.0784 - val_loss: 33.5520\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.9157 - val_loss: 32.7734\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8737 - val_loss: 33.9035\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.7561 - val_loss: 36.1194\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1086 - val_loss: 40.4378\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0138 - val_loss: 35.0613\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.8775 - val_loss: 42.3503\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0123 - val_loss: 44.8941\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.4171 - val_loss: 37.9250\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0665 - val_loss: 38.6614\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.5123 - val_loss: 36.5563\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3095 - val_loss: 32.7259\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.2730 - val_loss: 33.5802\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.8149 - val_loss: 25.0771\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.8809 - val_loss: 35.3441\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.3317 - val_loss: 38.4550\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.5589 - val_loss: 26.1555\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.1156 - val_loss: 35.5015\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.8881 - val_loss: 31.0058\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6366 - val_loss: 29.4092\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4496 - val_loss: 29.1797\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7397 - val_loss: 27.7628\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4510 - val_loss: 30.0736\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.0313 - val_loss: 30.3510\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.8479 - val_loss: 32.9240\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.9176 - val_loss: 34.1256\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4756 - val_loss: 30.7258\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.9153 - val_loss: 36.2475\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.6699 - val_loss: 36.3619\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.6623 - val_loss: 30.1213\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.5010 - val_loss: 31.5773\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1172 - val_loss: 32.0554\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4685 - val_loss: 32.6213\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.8477 - val_loss: 31.6618\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.4430 - val_loss: 33.3279\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5651 - val_loss: 34.7698\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8378 - val_loss: 37.7150\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9258 - val_loss: 32.2395\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.2147 - val_loss: 30.1944\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.4091 - val_loss: 36.3335\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9650 - val_loss: 35.9805\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6738 - val_loss: 34.7832\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.7153 - val_loss: 36.9301\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.0704 - val_loss: 40.7944\n",
      "Epoch 604/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.8853 - val_loss: 39.8287\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6636 - val_loss: 37.8426\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.5602 - val_loss: 36.5167\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 26.0822 - val_loss: 15.6335\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.6044 - val_loss: 30.4457\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.1438 - val_loss: 33.8475\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.6431 - val_loss: 37.7483\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.2246 - val_loss: 30.8682\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4807 - val_loss: 28.3678\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8259 - val_loss: 29.7564\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2040 - val_loss: 23.5895\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.3229 - val_loss: 25.3895\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2472 - val_loss: 26.5436\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.6945 - val_loss: 31.5908\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.3964 - val_loss: 28.9362\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.4397 - val_loss: 26.9608\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2544 - val_loss: 31.7471\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3896 - val_loss: 37.6097\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.9862 - val_loss: 28.3578\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.8511 - val_loss: 28.1444\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.8861 - val_loss: 29.5620\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.9240 - val_loss: 34.2007\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.3846 - val_loss: 39.0298\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.0825 - val_loss: 29.6974\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.8649 - val_loss: 28.5509\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.2082 - val_loss: 37.3871\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2670 - val_loss: 31.5295\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.9460 - val_loss: 33.1368\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2829 - val_loss: 37.6851\n",
      "Epoch 633/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6074 - val_loss: 36.2604\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3273 - val_loss: 36.2494\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 60.4857 - val_loss: 189.1286\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 73.2969 - val_loss: 39.6296\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 41.0381 - val_loss: 22.7991\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.1796 - val_loss: 24.3302\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 26.9742 - val_loss: 26.1808\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.0565 - val_loss: 25.5629\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 27.2485 - val_loss: 24.5299\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.9901 - val_loss: 25.1062\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.9544 - val_loss: 26.5945\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.3635 - val_loss: 28.1558\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.4544 - val_loss: 35.6707\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.8580 - val_loss: 32.5389\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.9295 - val_loss: 32.9183\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.3653 - val_loss: 58.7778\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.9673 - val_loss: 31.5837\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.8003 - val_loss: 27.4384\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.3954 - val_loss: 25.2249\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.5720 - val_loss: 25.9825\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.0027 - val_loss: 25.7684\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.3507 - val_loss: 38.8382\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.7324 - val_loss: 32.5346\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.7071 - val_loss: 26.6567\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0228 - val_loss: 30.9542\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.9927 - val_loss: 29.1040\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.0685 - val_loss: 29.7849\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.0988 - val_loss: 33.9572\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.5212 - val_loss: 25.1155\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.9530 - val_loss: 28.8119\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.4853 - val_loss: 24.5646\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.6924 - val_loss: 28.2652\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 23.0127 - val_loss: 27.7152\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.4557 - val_loss: 39.1668\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.9396 - val_loss: 33.0373\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.9734 - val_loss: 31.1075\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.5839 - val_loss: 29.7076\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.9795 - val_loss: 24.2938\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.0870 - val_loss: 25.8528\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2749 - val_loss: 27.7926\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8869 - val_loss: 40.3938\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.4667 - val_loss: 26.6539\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.8096 - val_loss: 29.5693\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.8696 - val_loss: 31.3395\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0985 - val_loss: 30.0228\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.2757 - val_loss: 33.1776\n",
      "Epoch 679/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.7198 - val_loss: 32.4135\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.9880 - val_loss: 41.0025\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.8258 - val_loss: 48.5409\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.2539 - val_loss: 32.3998\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.9596 - val_loss: 31.6305\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9182 - val_loss: 33.3089\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0396 - val_loss: 33.3194\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9609 - val_loss: 31.3523\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5401 - val_loss: 31.6259\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.9453 - val_loss: 43.2317\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.1490 - val_loss: 41.4216\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.5740 - val_loss: 35.9484\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.9889 - val_loss: 26.5249\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.5704 - val_loss: 31.2371\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.7490 - val_loss: 27.8998\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3573 - val_loss: 24.0339\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.2968 - val_loss: 26.4073\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4890 - val_loss: 24.1816\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.8925 - val_loss: 27.6405\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.6870 - val_loss: 34.2953\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7429 - val_loss: 33.3301\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9685 - val_loss: 33.1698\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0528 - val_loss: 40.5772\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.6554 - val_loss: 34.1687\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.5787 - val_loss: 30.5374\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.3858 - val_loss: 32.0020\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 30.4182 - val_loss: 32.3840\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.6737 - val_loss: 35.5359\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.5091 - val_loss: 29.7289\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.7443 - val_loss: 33.1000\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.8980 - val_loss: 31.8441\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3061 - val_loss: 35.0978\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.0108 - val_loss: 32.1042\n",
      "Epoch 712/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0342 - val_loss: 33.8390\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4095 - val_loss: 29.8984\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1378 - val_loss: 46.2212\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.1863 - val_loss: 29.4392\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0293 - val_loss: 39.7629\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.5417 - val_loss: 36.6834\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 25.9752 - val_loss: 30.4452\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.1277 - val_loss: 32.3793\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3717 - val_loss: 34.1278\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.0313 - val_loss: 36.1158\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9943 - val_loss: 32.1748\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.5524 - val_loss: 38.4044\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.9856 - val_loss: 39.6501\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.2283 - val_loss: 36.1455\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.7600 - val_loss: 36.6608\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.9225 - val_loss: 31.2510\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.5790 - val_loss: 36.1028\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.8032 - val_loss: 28.2790\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3749 - val_loss: 29.6234\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.8407 - val_loss: 30.7919\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.9874 - val_loss: 31.5155\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.6251 - val_loss: 28.1287\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.3350 - val_loss: 26.3098\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.2120 - val_loss: 29.1662\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6442 - val_loss: 32.9022\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6526 - val_loss: 40.6117\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.7106 - val_loss: 47.0419\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.2080 - val_loss: 25.0448\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3444 - val_loss: 26.8941\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.1853 - val_loss: 27.9059\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.9212 - val_loss: 25.2803\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.5868 - val_loss: 29.6974\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.9203 - val_loss: 36.2799\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.2716 - val_loss: 33.2050\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.9687 - val_loss: 31.9015\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.6930 - val_loss: 27.7092\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2384 - val_loss: 28.2302\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5641 - val_loss: 32.7006\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 31.4598 - val_loss: 28.1865\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 27.4136 - val_loss: 36.3286\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.8797 - val_loss: 42.2005\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0298 - val_loss: 41.3596\n",
      "Epoch 754/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.3625 - val_loss: 33.9153\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4286 - val_loss: 26.7152\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.3985 - val_loss: 27.9718\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5078 - val_loss: 29.0781\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7018 - val_loss: 39.8933\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.0197 - val_loss: 35.5175\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.1159 - val_loss: 35.4087\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7800 - val_loss: 26.2621\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5082 - val_loss: 30.2934\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.8620 - val_loss: 44.7562\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.2868 - val_loss: 30.6159\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.5877 - val_loss: 29.2871\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.9240 - val_loss: 32.3844\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.5412 - val_loss: 38.9199\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.8933 - val_loss: 30.6540\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.1882 - val_loss: 30.4665\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3248 - val_loss: 30.1255\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.1917 - val_loss: 26.6879\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.6430 - val_loss: 36.2662\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.4368 - val_loss: 38.0032\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.2000 - val_loss: 27.3351\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.5995 - val_loss: 28.9915\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.1104 - val_loss: 25.5413\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 29.2295 - val_loss: 40.2608\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 26.0807 - val_loss: 33.5539\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.2069 - val_loss: 36.7776\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.5117 - val_loss: 29.8418\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.1708 - val_loss: 32.7692\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.0161 - val_loss: 37.2674\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.0739 - val_loss: 33.1399\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.4528 - val_loss: 32.0675\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.6427 - val_loss: 28.9105\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3904 - val_loss: 32.9121\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.0268 - val_loss: 28.1106\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.4695 - val_loss: 37.0365\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9944 - val_loss: 30.3058\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.8535 - val_loss: 28.9220\n",
      "Epoch 791/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 18.2791 - val_loss: 34.3462\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.2204 - val_loss: 35.8373\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.2271 - val_loss: 33.9234\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 24.1928 - val_loss: 33.0742\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0584 - val_loss: 26.9747\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4926 - val_loss: 29.8699\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.7789 - val_loss: 30.2591\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.7491 - val_loss: 26.7398\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.9460 - val_loss: 45.7721\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.3880 - val_loss: 37.3476\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.8555 - val_loss: 38.3080\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2105 - val_loss: 37.7979\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.2194 - val_loss: 35.9259\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4466 - val_loss: 29.2489\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.5849 - val_loss: 33.8297\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.5244 - val_loss: 32.4361\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.4153 - val_loss: 33.1147\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.0038 - val_loss: 38.7680\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4759 - val_loss: 44.4810\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.4112 - val_loss: 39.7071\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.4771 - val_loss: 36.1031\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.5388 - val_loss: 31.2727\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6994 - val_loss: 36.3813\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.3897 - val_loss: 33.8249\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.3373 - val_loss: 39.4432\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3030 - val_loss: 37.0742\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9336 - val_loss: 36.2956\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3985 - val_loss: 29.9993\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3362 - val_loss: 37.3816\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0983 - val_loss: 35.3352\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4511 - val_loss: 34.5837\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1589 - val_loss: 31.4686\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3578 - val_loss: 34.7345\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7444 - val_loss: 36.5820\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9880 - val_loss: 29.2012\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.2298 - val_loss: 27.9039\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.8614 - val_loss: 20.6753\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1595 - val_loss: 30.2290\n",
      "Epoch 829/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4480 - val_loss: 29.8325\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0722 - val_loss: 29.6182\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1032 - val_loss: 26.2787\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0765 - val_loss: 26.6941\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2085 - val_loss: 32.5865\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0080 - val_loss: 31.2204\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.8899 - val_loss: 35.9039\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0774 - val_loss: 34.0596\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.9838 - val_loss: 28.6869\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.4971 - val_loss: 33.1422\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4811 - val_loss: 35.8021\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2976 - val_loss: 31.8099\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.0828 - val_loss: 29.8507\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6145 - val_loss: 33.2819\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3729 - val_loss: 33.7054\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0022 - val_loss: 29.5489\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6565 - val_loss: 30.7972\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1722 - val_loss: 29.6618\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9437 - val_loss: 31.1326\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3677 - val_loss: 35.1954\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.5586 - val_loss: 32.5370\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7698 - val_loss: 28.7781\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.8257 - val_loss: 28.7034\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.3347 - val_loss: 29.2857\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.9009 - val_loss: 30.0459\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25.2176 - val_loss: 25.2353\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.5989 - val_loss: 26.3883\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8391 - val_loss: 27.5189\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.9100 - val_loss: 28.9072\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.7092 - val_loss: 27.1408\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7663 - val_loss: 29.3667\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.9950 - val_loss: 28.5492\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.8036 - val_loss: 32.3228\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.1048 - val_loss: 28.7020\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2953 - val_loss: 28.8109\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.5966 - val_loss: 33.4662\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9542 - val_loss: 33.1911\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4152 - val_loss: 29.7299\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.7554 - val_loss: 29.5703\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.7444 - val_loss: 30.9661\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8979 - val_loss: 28.0277\n",
      "Epoch 870/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 17.1421 - val_loss: 33.0462\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.5686 - val_loss: 39.3929\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.2499 - val_loss: 32.2105\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.8472 - val_loss: 28.1878\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.6133 - val_loss: 27.3212\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1119 - val_loss: 26.9051\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.1581 - val_loss: 35.2513\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7488 - val_loss: 28.7526\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.5168 - val_loss: 26.9632\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5566 - val_loss: 23.8239\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.0025 - val_loss: 30.1195\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.6005 - val_loss: 29.6770\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.7938 - val_loss: 36.0048\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0484 - val_loss: 29.2386\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.2455 - val_loss: 34.3823\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.0234 - val_loss: 30.1540\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.0818 - val_loss: 39.2658\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4334 - val_loss: 27.3457\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3412 - val_loss: 30.5580\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8109 - val_loss: 27.1848\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.8312 - val_loss: 28.6135\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2313 - val_loss: 42.9573\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.0939 - val_loss: 26.2162\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9535 - val_loss: 35.1049\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3122 - val_loss: 31.7133\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.7446 - val_loss: 32.1342\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3256 - val_loss: 33.8259\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2032 - val_loss: 29.3721\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1870 - val_loss: 33.5385\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.9356 - val_loss: 30.6765\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7688 - val_loss: 28.8582\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3703 - val_loss: 27.7972\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1711 - val_loss: 28.1939\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.3343 - val_loss: 30.5032\n",
      "Epoch 904/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3131 - val_loss: 27.4986\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1919 - val_loss: 36.8519\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.7935 - val_loss: 26.3009\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3730 - val_loss: 35.0056\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5787 - val_loss: 28.8141\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9747 - val_loss: 28.5788\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0031 - val_loss: 34.3286\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6647 - val_loss: 31.0333\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.3190 - val_loss: 36.3226\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0277 - val_loss: 38.9331\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9663 - val_loss: 32.8208\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5870 - val_loss: 33.9915\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.2870 - val_loss: 33.9988\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.6814 - val_loss: 32.7337\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4392 - val_loss: 35.8845\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1291 - val_loss: 34.3219\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6770 - val_loss: 33.8633\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1824 - val_loss: 35.5384\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16.7852 - val_loss: 36.5897\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1428 - val_loss: 35.5732\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 26.1659 - val_loss: 37.4706\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6095 - val_loss: 35.6845\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.7515 - val_loss: 35.0643\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.8658 - val_loss: 33.2081\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7882 - val_loss: 34.6875\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.5328 - val_loss: 34.8725\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.8273 - val_loss: 33.6208\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1387 - val_loss: 36.0997\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3699 - val_loss: 33.6216\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7330 - val_loss: 44.3948\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.5063 - val_loss: 33.2566\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8951 - val_loss: 27.3501\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3496 - val_loss: 34.3947\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.7431 - val_loss: 31.6840\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7792 - val_loss: 33.7722\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3521 - val_loss: 35.9590\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9617 - val_loss: 32.6871\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.8823 - val_loss: 31.8228\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.8542 - val_loss: 38.1591\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2484 - val_loss: 36.4803\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9145 - val_loss: 38.7186\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.0127 - val_loss: 34.6770\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.4462 - val_loss: 40.0654\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.5772 - val_loss: 31.7140\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 29.3046 - val_loss: 34.9778\n",
      "Epoch 949/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 23.9972 - val_loss: 29.6802\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1669 - val_loss: 36.0422\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5462 - val_loss: 38.3126\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3212 - val_loss: 39.2898\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2045 - val_loss: 37.2986\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.4974 - val_loss: 34.3294\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3873 - val_loss: 32.9200\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.2491 - val_loss: 27.2868\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.9016 - val_loss: 29.3824\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.0638 - val_loss: 32.2405\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.9937 - val_loss: 27.2290\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.6942 - val_loss: 30.5052\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0401 - val_loss: 29.6762\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2922 - val_loss: 37.0088\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.8739 - val_loss: 37.0595\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9665 - val_loss: 37.6162\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.7438 - val_loss: 28.6819\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.0510 - val_loss: 38.6964\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.8661 - val_loss: 34.3615\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.4272 - val_loss: 33.5855\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.0738 - val_loss: 34.1022\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.4704 - val_loss: 33.4771\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3255 - val_loss: 39.4083\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1781 - val_loss: 33.3712\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.3330 - val_loss: 33.3872\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1376 - val_loss: 39.4081\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.3786 - val_loss: 33.8733\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.8695 - val_loss: 30.1976\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.7612 - val_loss: 33.5291\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.6527 - val_loss: 33.5840\n",
      "Epoch 979/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.3199 - val_loss: 23.9132\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.5296 - val_loss: 21.9929\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5272 - val_loss: 28.7060\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.8373 - val_loss: 32.1116\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4649 - val_loss: 32.5989\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3230 - val_loss: 26.1169\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.2053 - val_loss: 28.2436\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3449 - val_loss: 35.6250\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0665 - val_loss: 30.7247\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3421 - val_loss: 37.0905\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.1758 - val_loss: 36.1217\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.0247 - val_loss: 33.5135\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.4692 - val_loss: 33.4169\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4194 - val_loss: 31.5551\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0935 - val_loss: 27.8477\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.2219 - val_loss: 26.9278\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.6992 - val_loss: 36.2643\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5140 - val_loss: 37.7886\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0724 - val_loss: 28.2468\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9569 - val_loss: 24.6954\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.3181 - val_loss: 27.9559\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0262 - val_loss: 32.0615\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.1172 - val_loss: 33.1708\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.3259 - val_loss: 29.9434\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.3778 - val_loss: 29.3107\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.6454 - val_loss: 39.5951\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.5015 - val_loss: 37.1658\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.1642 - val_loss: 44.1553\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4553 - val_loss: 42.8255\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0377 - val_loss: 26.0847\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.0665 - val_loss: 27.9451\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.0059 - val_loss: 41.8191\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.9006 - val_loss: 35.8803\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8826 - val_loss: 30.0619\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.8102 - val_loss: 25.8635\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3878 - val_loss: 25.6517\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.2255 - val_loss: 25.5278\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.7842 - val_loss: 29.8310\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2530 - val_loss: 29.0196\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.4245 - val_loss: 30.8337\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9054 - val_loss: 24.1389\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1126 - val_loss: 31.3038\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8235 - val_loss: 36.6890\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21.6596 - val_loss: 35.2191\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.9365 - val_loss: 33.8630\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.1118 - val_loss: 28.4494\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5346 - val_loss: 28.4776\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22.1119 - val_loss: 31.7749\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.2333 - val_loss: 24.0499\n",
      "Epoch 1028/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4273 - val_loss: 30.5857\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.3119 - val_loss: 31.5404\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.4695 - val_loss: 30.8389\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.2652 - val_loss: 23.5046\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24.0377 - val_loss: 27.1889\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.5365 - val_loss: 33.0482\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 22.4525 - val_loss: 23.9201\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.8477 - val_loss: 23.0192\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.2743 - val_loss: 28.2571\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.5810 - val_loss: 30.3679\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.4788 - val_loss: 26.8943\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.3101 - val_loss: 28.6333\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8906 - val_loss: 26.7363\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1204 - val_loss: 39.0743\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.4751 - val_loss: 38.4949\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.4541 - val_loss: 31.1666\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.8770 - val_loss: 31.5089\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9218 - val_loss: 28.4324\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.8192 - val_loss: 29.2237\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.4127 - val_loss: 27.1638\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.6792 - val_loss: 33.2075\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.6398 - val_loss: 28.6106\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.0097 - val_loss: 29.5634\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1156 - val_loss: 28.8298\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.7137 - val_loss: 24.8682\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 23.6608 - val_loss: 25.9010\n",
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.6303 - val_loss: 27.3635\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.6118 - val_loss: 29.0183\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.1352 - val_loss: 33.1536\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.9225 - val_loss: 30.4229\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.1077 - val_loss: 31.8418\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.9336 - val_loss: 26.0703\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.9045 - val_loss: 31.6862\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.4057 - val_loss: 24.9125\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.7387 - val_loss: 21.5419\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.5746 - val_loss: 21.9923\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.0173 - val_loss: 29.5741\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.5700 - val_loss: 21.9195\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.1540 - val_loss: 25.5818\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.0405 - val_loss: 29.2420\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.8757 - val_loss: 24.8497\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.1884 - val_loss: 26.7460\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 17.4551 - val_loss: 26.5710\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.1830 - val_loss: 27.8112\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.4352 - val_loss: 37.3691\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.5739 - val_loss: 37.0802\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.3086 - val_loss: 34.2721\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 20.1541 - val_loss: 30.1377\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.8879 - val_loss: 22.9455\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.3321 - val_loss: 30.5031\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16.7002 - val_loss: 28.5375\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.4146 - val_loss: 29.1964\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18.0628 - val_loss: 32.5768\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 18.2278 - val_loss: 37.8576\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.3014 - val_loss: 32.8439\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.1971 - val_loss: 25.0368\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19.0330 - val_loss: 23.5692\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.5041 - val_loss: 24.5890\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.2297 - val_loss: 24.9687\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.3784 - val_loss: 29.3928\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.0266 - val_loss: 28.6379\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19.2764 - val_loss: 25.7461\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.3900 - val_loss: 28.3532\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.7562 - val_loss: 29.6662\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.4759 - val_loss: 33.3327\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.5702 - val_loss: 31.3338\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.1682 - val_loss: 30.9072\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.6692 - val_loss: 33.3302\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 17.6076 - val_loss: 33.0020\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17.8624 - val_loss: 31.8062\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.0959 - val_loss: 32.2469\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.8554 - val_loss: 31.7126\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.4915 - val_loss: 30.7197\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.2376 - val_loss: 31.7843\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.8873 - val_loss: 31.1552\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18.9592 - val_loss: 34.2918\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.8926 - val_loss: 26.8776\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.7210 - val_loss: 25.9840\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.7731 - val_loss: 27.9617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1107/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 26.8246Restoring model weights from the end of the best epoch: 607.\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 21.6918 - val_loss: 37.1825\n",
      "Epoch 1107: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>69.253922</td>\n",
       "      <td>69.258904</td>\n",
       "      <td>69.254097</td>\n",
       "      <td>69.250778</td>\n",
       "      <td>69.191338</td>\n",
       "      <td>35.17173</td>\n",
       "      <td>24.148249</td>\n",
       "      <td>24.444172</td>\n",
       "      <td>24.509846</td>\n",
       "      <td>23.805075</td>\n",
       "      <td>22.185478</td>\n",
       "      <td>26.600525</td>\n",
       "      <td>22.201387</td>\n",
       "      <td>22.142048</td>\n",
       "      <td>23.984703</td>\n",
       "      <td>24.678234</td>\n",
       "      <td>26.129097</td>\n",
       "      <td>22.140841</td>\n",
       "      <td>22.132366</td>\n",
       "      <td>22.136606</td>\n",
       "      <td>22.137009</td>\n",
       "      <td>22.135777</td>\n",
       "      <td>22.137989</td>\n",
       "      <td>22.135357</td>\n",
       "      <td>22.164333</td>\n",
       "      <td>24.604904</td>\n",
       "      <td>24.584856</td>\n",
       "      <td>24.458918</td>\n",
       "      <td>24.794937</td>\n",
       "      <td>24.627682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>75.913</td>\n",
       "      <td>74.774</td>\n",
       "      <td>72.484</td>\n",
       "      <td>71.534</td>\n",
       "      <td>70.32</td>\n",
       "      <td>67.364</td>\n",
       "      <td>59.688</td>\n",
       "      <td>40.259</td>\n",
       "      <td>41.239</td>\n",
       "      <td>45.035</td>\n",
       "      <td>42.477</td>\n",
       "      <td>57.619</td>\n",
       "      <td>53.109</td>\n",
       "      <td>63.141</td>\n",
       "      <td>55.58</td>\n",
       "      <td>60.001</td>\n",
       "      <td>62.767</td>\n",
       "      <td>45.308</td>\n",
       "      <td>57.142</td>\n",
       "      <td>46.283</td>\n",
       "      <td>43.39</td>\n",
       "      <td>40.824</td>\n",
       "      <td>55.063</td>\n",
       "      <td>56.474</td>\n",
       "      <td>68.133</td>\n",
       "      <td>68.642</td>\n",
       "      <td>64.741</td>\n",
       "      <td>71.269</td>\n",
       "      <td>67.631</td>\n",
       "      <td>62.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>6.659081</td>\n",
       "      <td>5.515099</td>\n",
       "      <td>3.229904</td>\n",
       "      <td>2.283218</td>\n",
       "      <td>1.128662</td>\n",
       "      <td>32.192268</td>\n",
       "      <td>35.539749</td>\n",
       "      <td>15.814827</td>\n",
       "      <td>16.729153</td>\n",
       "      <td>21.229925</td>\n",
       "      <td>20.291523</td>\n",
       "      <td>31.018475</td>\n",
       "      <td>30.907614</td>\n",
       "      <td>40.998951</td>\n",
       "      <td>31.595299</td>\n",
       "      <td>35.322765</td>\n",
       "      <td>36.637901</td>\n",
       "      <td>23.167158</td>\n",
       "      <td>35.009632</td>\n",
       "      <td>24.146395</td>\n",
       "      <td>21.252991</td>\n",
       "      <td>18.688225</td>\n",
       "      <td>32.925011</td>\n",
       "      <td>34.338642</td>\n",
       "      <td>45.96867</td>\n",
       "      <td>44.037094</td>\n",
       "      <td>40.156143</td>\n",
       "      <td>46.810081</td>\n",
       "      <td>42.83606</td>\n",
       "      <td>38.217319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1          2          3          4          5   \\\n",
       "Month         Month-1    Month-2    Month-3    Month-4    Month-5    Month-6   \n",
       "Prediction  69.253922  69.258904  69.254097  69.250778  69.191338   35.17173   \n",
       "Target         75.913     74.774     72.484     71.534      70.32     67.364   \n",
       "Error        6.659081   5.515099   3.229904   2.283218   1.128662  32.192268   \n",
       "\n",
       "                   6          7          8          9          10         11  \\\n",
       "Month         Month-7    Month-8    Month-9   Month-10   Month-11   Month-12   \n",
       "Prediction  24.148249  24.444172  24.509846  23.805075  22.185478  26.600525   \n",
       "Target         59.688     40.259     41.239     45.035     42.477     57.619   \n",
       "Error       35.539749  15.814827  16.729153  21.229925  20.291523  31.018475   \n",
       "\n",
       "                   12         13         14         15         16         17  \\\n",
       "Month        Month-13   Month-14   Month-15   Month-16   Month-17   Month-18   \n",
       "Prediction  22.201387  22.142048  23.984703  24.678234  26.129097  22.140841   \n",
       "Target         53.109     63.141      55.58     60.001     62.767     45.308   \n",
       "Error       30.907614  40.998951  31.595299  35.322765  36.637901  23.167158   \n",
       "\n",
       "                   18         19         20         21         22         23  \\\n",
       "Month        Month-19   Month-20   Month-21   Month-22   Month-23   Month-24   \n",
       "Prediction  22.132366  22.136606  22.137009  22.135777  22.137989  22.135357   \n",
       "Target         57.142     46.283      43.39     40.824     55.063     56.474   \n",
       "Error       35.009632  24.146395  21.252991  18.688225  32.925011  34.338642   \n",
       "\n",
       "                   24         25         26         27         28         29  \n",
       "Month        Month-25   Month-26   Month-27   Month-28   Month-29   Month-30  \n",
       "Prediction  22.164333  24.604904  24.584856  24.458918  24.794937  24.627682  \n",
       "Target         68.133     68.642     64.741     71.269     67.631     62.845  \n",
       "Error        45.96867  44.037094  40.156143  46.810081   42.83606  38.217319  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.15493"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.47398442"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Ano-0: |Prediction[[527.07416]] - Target[718.706]| =  Error: [[191.63184]]; MAPE:[[0.26663452]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Ano-0: |Prediction[[274.09143]] - Target[639.082]| =  Error: [[364.99054]]; MAPE:[[0.5711169]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Ano-5: |Prediction[[145.23563]] - Target[403.26099999999997]| =  Error: [[258.02536]]; MAPE:[[0.63984704]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[191.63184]], dtype=float32),\n",
       " array([[364.99054]], dtype=float32),\n",
       " array([[258.02536]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "271.54922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.49253282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
