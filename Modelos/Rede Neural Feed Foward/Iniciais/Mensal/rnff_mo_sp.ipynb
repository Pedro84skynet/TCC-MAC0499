{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'São Paulo - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>São Paulo - Produção de Cimento (t)</th>\n",
       "      <th>São Paulo - value</th>\n",
       "      <th>São Paulo - PIB - Estadual</th>\n",
       "      <th>São Paulo - PIB - Construção Civil</th>\n",
       "      <th>São Paulo - PIB - Per Capita</th>\n",
       "      <th>São Paulo - PIB - Preços de Mercado</th>\n",
       "      <th>São Paulo - Desemprego</th>\n",
       "      <th>São Paulo - IDH</th>\n",
       "      <th>São Paulo - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>437.972720</td>\n",
       "      <td>0.314974</td>\n",
       "      <td>1.034903e+09</td>\n",
       "      <td>4.730940e+07</td>\n",
       "      <td>23.895559</td>\n",
       "      <td>9.819129e+08</td>\n",
       "      <td>8.310335</td>\n",
       "      <td>0.812723</td>\n",
       "      <td>782.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>434.363720</td>\n",
       "      <td>0.317328</td>\n",
       "      <td>1.036092e+09</td>\n",
       "      <td>4.732994e+07</td>\n",
       "      <td>23.901472</td>\n",
       "      <td>9.822666e+08</td>\n",
       "      <td>8.304194</td>\n",
       "      <td>0.812838</td>\n",
       "      <td>789.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>433.350868</td>\n",
       "      <td>0.319840</td>\n",
       "      <td>1.037280e+09</td>\n",
       "      <td>4.735047e+07</td>\n",
       "      <td>23.907385</td>\n",
       "      <td>9.826203e+08</td>\n",
       "      <td>8.298053</td>\n",
       "      <td>0.812953</td>\n",
       "      <td>774.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>431.825332</td>\n",
       "      <td>0.322104</td>\n",
       "      <td>1.038469e+09</td>\n",
       "      <td>4.737101e+07</td>\n",
       "      <td>23.913298</td>\n",
       "      <td>9.829741e+08</td>\n",
       "      <td>8.291912</td>\n",
       "      <td>0.813068</td>\n",
       "      <td>782.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>433.287298</td>\n",
       "      <td>0.324320</td>\n",
       "      <td>1.039658e+09</td>\n",
       "      <td>4.739155e+07</td>\n",
       "      <td>23.919210</td>\n",
       "      <td>9.833278e+08</td>\n",
       "      <td>8.285771</td>\n",
       "      <td>0.813183</td>\n",
       "      <td>841.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>515.306495</td>\n",
       "      <td>0.590649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1112.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>514.812591</td>\n",
       "      <td>0.588569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1028.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>514.856452</td>\n",
       "      <td>0.585196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>996.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>515.215930</td>\n",
       "      <td>0.581094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>515.784324</td>\n",
       "      <td>0.576147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024.272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0       2003-1                                          0.724032   \n",
       "1       2003-2                                          0.690297   \n",
       "2       2003-3                                          0.669681   \n",
       "3       2003-4                                          0.660494   \n",
       "4       2003-5                                          0.648337   \n",
       "..         ...                                               ...   \n",
       "235     2022-8                                               NaN   \n",
       "236     2022-9                                               NaN   \n",
       "237    2022-10                                               NaN   \n",
       "238    2022-11                                               NaN   \n",
       "239    2022-12                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                              7.330309e+06   0.969649   \n",
       "1                              7.335910e+06   0.950783   \n",
       "2                              7.341511e+06   0.938332   \n",
       "3                              7.347112e+06   0.926401   \n",
       "4                              7.352713e+06   0.951683   \n",
       "..                                      ...        ...   \n",
       "235                                     NaN        NaN   \n",
       "236                                     NaN        NaN   \n",
       "237                                     NaN        NaN   \n",
       "238                                     NaN        NaN   \n",
       "239                                     NaN        NaN   \n",
       "\n",
       "     São Paulo - Produção de Cimento (t)  São Paulo - value  \\\n",
       "0                             437.972720           0.314974   \n",
       "1                             434.363720           0.317328   \n",
       "2                             433.350868           0.319840   \n",
       "3                             431.825332           0.322104   \n",
       "4                             433.287298           0.324320   \n",
       "..                                   ...                ...   \n",
       "235                           515.306495           0.590649   \n",
       "236                           514.812591           0.588569   \n",
       "237                           514.856452           0.585196   \n",
       "238                           515.215930           0.581094   \n",
       "239                           515.784324           0.576147   \n",
       "\n",
       "     São Paulo - PIB - Estadual  São Paulo - PIB - Construção Civil  \\\n",
       "0                  1.034903e+09                        4.730940e+07   \n",
       "1                  1.036092e+09                        4.732994e+07   \n",
       "2                  1.037280e+09                        4.735047e+07   \n",
       "3                  1.038469e+09                        4.737101e+07   \n",
       "4                  1.039658e+09                        4.739155e+07   \n",
       "..                          ...                                 ...   \n",
       "235                         NaN                                 NaN   \n",
       "236                         NaN                                 NaN   \n",
       "237                         NaN                                 NaN   \n",
       "238                         NaN                                 NaN   \n",
       "239                         NaN                                 NaN   \n",
       "\n",
       "     São Paulo - PIB - Per Capita  São Paulo - PIB - Preços de Mercado  \\\n",
       "0                       23.895559                         9.819129e+08   \n",
       "1                       23.901472                         9.822666e+08   \n",
       "2                       23.907385                         9.826203e+08   \n",
       "3                       23.913298                         9.829741e+08   \n",
       "4                       23.919210                         9.833278e+08   \n",
       "..                            ...                                  ...   \n",
       "235                           NaN                                  NaN   \n",
       "236                           NaN                                  NaN   \n",
       "237                           NaN                                  NaN   \n",
       "238                           NaN                                  NaN   \n",
       "239                           NaN                                  NaN   \n",
       "\n",
       "     São Paulo - Desemprego  São Paulo - IDH  \\\n",
       "0                  8.310335         0.812723   \n",
       "1                  8.304194         0.812838   \n",
       "2                  8.298053         0.812953   \n",
       "3                  8.291912         0.813068   \n",
       "4                  8.285771         0.813183   \n",
       "..                      ...              ...   \n",
       "235                     NaN              NaN   \n",
       "236                     NaN              NaN   \n",
       "237                     NaN              NaN   \n",
       "238                     NaN              NaN   \n",
       "239                     NaN              NaN   \n",
       "\n",
       "     São Paulo - Consumo de Cimento (t)  \n",
       "0                               782.111  \n",
       "1                               789.891  \n",
       "2                               774.309  \n",
       "3                               782.071  \n",
       "4                               841.400  \n",
       "..                                  ...  \n",
       "235                            1112.914  \n",
       "236                            1028.144  \n",
       "237                             996.449  \n",
       "238                            1024.272  \n",
       "239                            1024.272  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_SP.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>São Paulo - Produção de Cimento (t)</th>\n",
       "      <th>São Paulo - value</th>\n",
       "      <th>São Paulo - PIB - Estadual</th>\n",
       "      <th>São Paulo - PIB - Construção Civil</th>\n",
       "      <th>São Paulo - PIB - Per Capita</th>\n",
       "      <th>São Paulo - PIB - Preços de Mercado</th>\n",
       "      <th>São Paulo - Desemprego</th>\n",
       "      <th>São Paulo - IDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.410736</td>\n",
       "      <td>-1.192538</td>\n",
       "      <td>-1.718526</td>\n",
       "      <td>-0.426010</td>\n",
       "      <td>-1.485366</td>\n",
       "      <td>-2.737181</td>\n",
       "      <td>-0.804344</td>\n",
       "      <td>-2.274413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.440931</td>\n",
       "      <td>-1.124056</td>\n",
       "      <td>-1.699080</td>\n",
       "      <td>-0.401643</td>\n",
       "      <td>-1.421647</td>\n",
       "      <td>-2.673768</td>\n",
       "      <td>-0.808200</td>\n",
       "      <td>-2.236038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.449405</td>\n",
       "      <td>-1.050974</td>\n",
       "      <td>-1.679635</td>\n",
       "      <td>-0.377275</td>\n",
       "      <td>-1.357928</td>\n",
       "      <td>-2.610355</td>\n",
       "      <td>-0.812056</td>\n",
       "      <td>-2.197662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.462169</td>\n",
       "      <td>-0.985091</td>\n",
       "      <td>-1.660189</td>\n",
       "      <td>-0.352908</td>\n",
       "      <td>-1.294210</td>\n",
       "      <td>-2.546942</td>\n",
       "      <td>-0.815911</td>\n",
       "      <td>-2.159286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.449937</td>\n",
       "      <td>-0.920633</td>\n",
       "      <td>-1.640744</td>\n",
       "      <td>-0.328540</td>\n",
       "      <td>-1.230491</td>\n",
       "      <td>-2.483529</td>\n",
       "      <td>-0.819767</td>\n",
       "      <td>-2.120910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-1.209684</td>\n",
       "      <td>1.711139</td>\n",
       "      <td>1.107674</td>\n",
       "      <td>-1.587758</td>\n",
       "      <td>-1.453963</td>\n",
       "      <td>0.436685</td>\n",
       "      <td>1.040670</td>\n",
       "      <td>0.784878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>-1.192369</td>\n",
       "      <td>1.711746</td>\n",
       "      <td>1.098119</td>\n",
       "      <td>-1.580975</td>\n",
       "      <td>-1.459558</td>\n",
       "      <td>0.423023</td>\n",
       "      <td>1.034370</td>\n",
       "      <td>0.748669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>-1.178463</td>\n",
       "      <td>1.717654</td>\n",
       "      <td>1.088565</td>\n",
       "      <td>-1.574192</td>\n",
       "      <td>-1.465154</td>\n",
       "      <td>0.409361</td>\n",
       "      <td>1.028069</td>\n",
       "      <td>0.712461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-1.166182</td>\n",
       "      <td>1.729082</td>\n",
       "      <td>1.079010</td>\n",
       "      <td>-1.567409</td>\n",
       "      <td>-1.470749</td>\n",
       "      <td>0.395699</td>\n",
       "      <td>1.021769</td>\n",
       "      <td>0.676253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-1.169926</td>\n",
       "      <td>1.769880</td>\n",
       "      <td>1.069456</td>\n",
       "      <td>-1.560626</td>\n",
       "      <td>-1.476344</td>\n",
       "      <td>0.382038</td>\n",
       "      <td>1.015469</td>\n",
       "      <td>0.640045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     São Paulo - Produção de Cimento (t)  São Paulo - value  \\\n",
       "0                              -1.410736          -1.192538   \n",
       "1                              -1.440931          -1.124056   \n",
       "2                              -1.449405          -1.050974   \n",
       "3                              -1.462169          -0.985091   \n",
       "4                              -1.449937          -0.920633   \n",
       "..                                   ...                ...   \n",
       "187                            -1.209684           1.711139   \n",
       "188                            -1.192369           1.711746   \n",
       "189                            -1.178463           1.717654   \n",
       "190                            -1.166182           1.729082   \n",
       "191                            -1.169926           1.769880   \n",
       "\n",
       "     São Paulo - PIB - Estadual  São Paulo - PIB - Construção Civil  \\\n",
       "0                     -1.718526                           -0.426010   \n",
       "1                     -1.699080                           -0.401643   \n",
       "2                     -1.679635                           -0.377275   \n",
       "3                     -1.660189                           -0.352908   \n",
       "4                     -1.640744                           -0.328540   \n",
       "..                          ...                                 ...   \n",
       "187                    1.107674                           -1.587758   \n",
       "188                    1.098119                           -1.580975   \n",
       "189                    1.088565                           -1.574192   \n",
       "190                    1.079010                           -1.567409   \n",
       "191                    1.069456                           -1.560626   \n",
       "\n",
       "     São Paulo - PIB - Per Capita  São Paulo - PIB - Preços de Mercado  \\\n",
       "0                       -1.485366                            -2.737181   \n",
       "1                       -1.421647                            -2.673768   \n",
       "2                       -1.357928                            -2.610355   \n",
       "3                       -1.294210                            -2.546942   \n",
       "4                       -1.230491                            -2.483529   \n",
       "..                            ...                                  ...   \n",
       "187                     -1.453963                             0.436685   \n",
       "188                     -1.459558                             0.423023   \n",
       "189                     -1.465154                             0.409361   \n",
       "190                     -1.470749                             0.395699   \n",
       "191                     -1.476344                             0.382038   \n",
       "\n",
       "     São Paulo - Desemprego  São Paulo - IDH  \n",
       "0                 -0.804344        -2.274413  \n",
       "1                 -0.808200        -2.236038  \n",
       "2                 -0.812056        -2.197662  \n",
       "3                 -0.815911        -2.159286  \n",
       "4                 -0.819767        -2.120910  \n",
       "..                      ...              ...  \n",
       "187                1.040670         0.784878  \n",
       "188                1.034370         0.748669  \n",
       "189                1.028069         0.712461  \n",
       "190                1.021769         0.676253  \n",
       "191                1.015469         0.640045  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      706.731\n",
       "1      697.361\n",
       "2      859.304\n",
       "3      762.222\n",
       "4      763.920\n",
       "        ...   \n",
       "235        NaN\n",
       "236        NaN\n",
       "237        NaN\n",
       "238        NaN\n",
       "239        NaN\n",
       "Name: São Paulo - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>São Paulo - Produção de Cimento (t)</th>\n",
       "      <th>São Paulo - value</th>\n",
       "      <th>São Paulo - PIB - Estadual</th>\n",
       "      <th>São Paulo - PIB - Construção Civil</th>\n",
       "      <th>São Paulo - PIB - Per Capita</th>\n",
       "      <th>São Paulo - PIB - Preços de Mercado</th>\n",
       "      <th>São Paulo - Desemprego</th>\n",
       "      <th>São Paulo - IDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.410736</td>\n",
       "      <td>-1.192538</td>\n",
       "      <td>-1.718526</td>\n",
       "      <td>-0.426010</td>\n",
       "      <td>-1.485366</td>\n",
       "      <td>-2.737181</td>\n",
       "      <td>-0.804344</td>\n",
       "      <td>-2.274413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-1.440931</td>\n",
       "      <td>-1.124056</td>\n",
       "      <td>-1.699080</td>\n",
       "      <td>-0.401643</td>\n",
       "      <td>-1.421647</td>\n",
       "      <td>-2.673768</td>\n",
       "      <td>-0.808200</td>\n",
       "      <td>-2.236038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-1.449405</td>\n",
       "      <td>-1.050974</td>\n",
       "      <td>-1.679635</td>\n",
       "      <td>-0.377275</td>\n",
       "      <td>-1.357928</td>\n",
       "      <td>-2.610355</td>\n",
       "      <td>-0.812056</td>\n",
       "      <td>-2.197662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-1.462169</td>\n",
       "      <td>-0.985091</td>\n",
       "      <td>-1.660189</td>\n",
       "      <td>-0.352908</td>\n",
       "      <td>-1.294210</td>\n",
       "      <td>-2.546942</td>\n",
       "      <td>-0.815911</td>\n",
       "      <td>-2.159286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-1.449937</td>\n",
       "      <td>-0.920633</td>\n",
       "      <td>-1.640744</td>\n",
       "      <td>-0.328540</td>\n",
       "      <td>-1.230491</td>\n",
       "      <td>-2.483529</td>\n",
       "      <td>-0.819767</td>\n",
       "      <td>-2.120910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>-0.608419</td>\n",
       "      <td>1.023937</td>\n",
       "      <td>1.193677</td>\n",
       "      <td>-1.393041</td>\n",
       "      <td>-1.206846</td>\n",
       "      <td>0.733610</td>\n",
       "      <td>1.413038</td>\n",
       "      <td>1.566441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>-0.653197</td>\n",
       "      <td>1.033712</td>\n",
       "      <td>1.195577</td>\n",
       "      <td>-1.411276</td>\n",
       "      <td>-1.217300</td>\n",
       "      <td>0.727991</td>\n",
       "      <td>1.392752</td>\n",
       "      <td>1.539489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>-0.699576</td>\n",
       "      <td>1.049101</td>\n",
       "      <td>1.197477</td>\n",
       "      <td>-1.429511</td>\n",
       "      <td>-1.227755</td>\n",
       "      <td>0.722372</td>\n",
       "      <td>1.372465</td>\n",
       "      <td>1.512536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>-0.757794</td>\n",
       "      <td>1.059564</td>\n",
       "      <td>1.199378</td>\n",
       "      <td>-1.447746</td>\n",
       "      <td>-1.238210</td>\n",
       "      <td>0.716753</td>\n",
       "      <td>1.352178</td>\n",
       "      <td>1.485583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>-0.785825</td>\n",
       "      <td>1.068338</td>\n",
       "      <td>1.201278</td>\n",
       "      <td>-1.465981</td>\n",
       "      <td>-1.248665</td>\n",
       "      <td>0.711134</td>\n",
       "      <td>1.331891</td>\n",
       "      <td>1.458630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "0                                 -2.389042   3.122582   \n",
       "1                                 -2.352139   2.970356   \n",
       "2                                 -2.315236   2.869895   \n",
       "3                                 -2.278333   2.773628   \n",
       "4                                 -2.241431   2.977624   \n",
       "..                                      ...        ...   \n",
       "157                                0.819304  -0.883659   \n",
       "158                                0.808136  -0.950771   \n",
       "159                                0.796969  -1.028465   \n",
       "160                                0.785801  -1.103668   \n",
       "161                                0.774634  -0.978419   \n",
       "\n",
       "     São Paulo - Produção de Cimento (t)  São Paulo - value  \\\n",
       "0                              -1.410736          -1.192538   \n",
       "1                              -1.440931          -1.124056   \n",
       "2                              -1.449405          -1.050974   \n",
       "3                              -1.462169          -0.985091   \n",
       "4                              -1.449937          -0.920633   \n",
       "..                                   ...                ...   \n",
       "157                            -0.608419           1.023937   \n",
       "158                            -0.653197           1.033712   \n",
       "159                            -0.699576           1.049101   \n",
       "160                            -0.757794           1.059564   \n",
       "161                            -0.785825           1.068338   \n",
       "\n",
       "     São Paulo - PIB - Estadual  São Paulo - PIB - Construção Civil  \\\n",
       "0                     -1.718526                           -0.426010   \n",
       "1                     -1.699080                           -0.401643   \n",
       "2                     -1.679635                           -0.377275   \n",
       "3                     -1.660189                           -0.352908   \n",
       "4                     -1.640744                           -0.328540   \n",
       "..                          ...                                 ...   \n",
       "157                    1.193677                           -1.393041   \n",
       "158                    1.195577                           -1.411276   \n",
       "159                    1.197477                           -1.429511   \n",
       "160                    1.199378                           -1.447746   \n",
       "161                    1.201278                           -1.465981   \n",
       "\n",
       "     São Paulo - PIB - Per Capita  São Paulo - PIB - Preços de Mercado  \\\n",
       "0                       -1.485366                            -2.737181   \n",
       "1                       -1.421647                            -2.673768   \n",
       "2                       -1.357928                            -2.610355   \n",
       "3                       -1.294210                            -2.546942   \n",
       "4                       -1.230491                            -2.483529   \n",
       "..                            ...                                  ...   \n",
       "157                     -1.206846                             0.733610   \n",
       "158                     -1.217300                             0.727991   \n",
       "159                     -1.227755                             0.722372   \n",
       "160                     -1.238210                             0.716753   \n",
       "161                     -1.248665                             0.711134   \n",
       "\n",
       "     São Paulo - Desemprego  São Paulo - IDH  \n",
       "0                 -0.804344        -2.274413  \n",
       "1                 -0.808200        -2.236038  \n",
       "2                 -0.812056        -2.197662  \n",
       "3                 -0.815911        -2.159286  \n",
       "4                 -0.819767        -2.120910  \n",
       "..                      ...              ...  \n",
       "157                1.413038         1.566441  \n",
       "158                1.392752         1.539489  \n",
       "159                1.372465         1.512536  \n",
       "160                1.352178         1.485583  \n",
       "161                1.331891         1.458630  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      706.731\n",
       "1      697.361\n",
       "2      859.304\n",
       "3      762.222\n",
       "4      763.920\n",
       "        ...   \n",
       "157    757.915\n",
       "158    923.634\n",
       "159    756.663\n",
       "160    872.715\n",
       "161    844.988\n",
       "Name: São Paulo - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>São Paulo - Produção de Cimento (t)</th>\n",
       "      <th>São Paulo - value</th>\n",
       "      <th>São Paulo - PIB - Estadual</th>\n",
       "      <th>São Paulo - PIB - Construção Civil</th>\n",
       "      <th>São Paulo - PIB - Per Capita</th>\n",
       "      <th>São Paulo - PIB - Preços de Mercado</th>\n",
       "      <th>São Paulo - Desemprego</th>\n",
       "      <th>São Paulo - IDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>-0.820644</td>\n",
       "      <td>1.082634</td>\n",
       "      <td>1.203179</td>\n",
       "      <td>-1.484216</td>\n",
       "      <td>-1.259120</td>\n",
       "      <td>0.705516</td>\n",
       "      <td>1.311604</td>\n",
       "      <td>1.431678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>-0.853043</td>\n",
       "      <td>1.099539</td>\n",
       "      <td>1.205079</td>\n",
       "      <td>-1.502451</td>\n",
       "      <td>-1.269575</td>\n",
       "      <td>0.699897</td>\n",
       "      <td>1.291318</td>\n",
       "      <td>1.404725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>-0.879813</td>\n",
       "      <td>1.131286</td>\n",
       "      <td>1.206979</td>\n",
       "      <td>-1.520686</td>\n",
       "      <td>-1.280030</td>\n",
       "      <td>0.694278</td>\n",
       "      <td>1.271031</td>\n",
       "      <td>1.377772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>-0.906260</td>\n",
       "      <td>1.157706</td>\n",
       "      <td>1.208880</td>\n",
       "      <td>-1.538921</td>\n",
       "      <td>-1.290484</td>\n",
       "      <td>0.688659</td>\n",
       "      <td>1.250744</td>\n",
       "      <td>1.350819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>-0.932027</td>\n",
       "      <td>1.184668</td>\n",
       "      <td>1.210780</td>\n",
       "      <td>-1.557156</td>\n",
       "      <td>-1.300939</td>\n",
       "      <td>0.683040</td>\n",
       "      <td>1.230457</td>\n",
       "      <td>1.323866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>-0.955450</td>\n",
       "      <td>1.212391</td>\n",
       "      <td>1.212680</td>\n",
       "      <td>-1.575390</td>\n",
       "      <td>-1.311394</td>\n",
       "      <td>0.677421</td>\n",
       "      <td>1.210170</td>\n",
       "      <td>1.296914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>-0.980990</td>\n",
       "      <td>1.240924</td>\n",
       "      <td>1.214581</td>\n",
       "      <td>-1.593625</td>\n",
       "      <td>-1.321849</td>\n",
       "      <td>0.671803</td>\n",
       "      <td>1.189884</td>\n",
       "      <td>1.269961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>-1.007316</td>\n",
       "      <td>1.258259</td>\n",
       "      <td>1.211245</td>\n",
       "      <td>-1.597093</td>\n",
       "      <td>-1.329595</td>\n",
       "      <td>0.660179</td>\n",
       "      <td>1.181124</td>\n",
       "      <td>1.250659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>-1.034034</td>\n",
       "      <td>1.282135</td>\n",
       "      <td>1.207910</td>\n",
       "      <td>-1.600561</td>\n",
       "      <td>-1.337340</td>\n",
       "      <td>0.648555</td>\n",
       "      <td>1.172365</td>\n",
       "      <td>1.231357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>-1.061615</td>\n",
       "      <td>1.306114</td>\n",
       "      <td>1.204574</td>\n",
       "      <td>-1.604029</td>\n",
       "      <td>-1.345086</td>\n",
       "      <td>0.636932</td>\n",
       "      <td>1.163605</td>\n",
       "      <td>1.212054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>-1.080622</td>\n",
       "      <td>1.330829</td>\n",
       "      <td>1.201239</td>\n",
       "      <td>-1.607497</td>\n",
       "      <td>-1.352831</td>\n",
       "      <td>0.625308</td>\n",
       "      <td>1.154846</td>\n",
       "      <td>1.192752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>-1.112059</td>\n",
       "      <td>1.373902</td>\n",
       "      <td>1.197904</td>\n",
       "      <td>-1.610965</td>\n",
       "      <td>-1.360577</td>\n",
       "      <td>0.613684</td>\n",
       "      <td>1.146087</td>\n",
       "      <td>1.173450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>-1.124585</td>\n",
       "      <td>1.418532</td>\n",
       "      <td>1.194568</td>\n",
       "      <td>-1.614433</td>\n",
       "      <td>-1.368323</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>1.137327</td>\n",
       "      <td>1.154148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>-1.143191</td>\n",
       "      <td>1.458861</td>\n",
       "      <td>1.191233</td>\n",
       "      <td>-1.617900</td>\n",
       "      <td>-1.376068</td>\n",
       "      <td>0.590437</td>\n",
       "      <td>1.128568</td>\n",
       "      <td>1.134846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>-1.170809</td>\n",
       "      <td>1.494850</td>\n",
       "      <td>1.187897</td>\n",
       "      <td>-1.621368</td>\n",
       "      <td>-1.383814</td>\n",
       "      <td>0.578813</td>\n",
       "      <td>1.119808</td>\n",
       "      <td>1.115544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>-1.169332</td>\n",
       "      <td>1.527551</td>\n",
       "      <td>1.184562</td>\n",
       "      <td>-1.624836</td>\n",
       "      <td>-1.391560</td>\n",
       "      <td>0.567189</td>\n",
       "      <td>1.111049</td>\n",
       "      <td>1.096241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>-1.183874</td>\n",
       "      <td>1.561820</td>\n",
       "      <td>1.181226</td>\n",
       "      <td>-1.628304</td>\n",
       "      <td>-1.399305</td>\n",
       "      <td>0.555566</td>\n",
       "      <td>1.102289</td>\n",
       "      <td>1.076939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>-1.194903</td>\n",
       "      <td>1.603062</td>\n",
       "      <td>1.177891</td>\n",
       "      <td>-1.631772</td>\n",
       "      <td>-1.407051</td>\n",
       "      <td>0.543942</td>\n",
       "      <td>1.093530</td>\n",
       "      <td>1.057637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>-1.206170</td>\n",
       "      <td>1.645296</td>\n",
       "      <td>1.174555</td>\n",
       "      <td>-1.635240</td>\n",
       "      <td>-1.414796</td>\n",
       "      <td>0.532318</td>\n",
       "      <td>1.084771</td>\n",
       "      <td>1.038335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>-1.209225</td>\n",
       "      <td>1.658285</td>\n",
       "      <td>1.165001</td>\n",
       "      <td>-1.628457</td>\n",
       "      <td>-1.420392</td>\n",
       "      <td>0.518656</td>\n",
       "      <td>1.078470</td>\n",
       "      <td>1.002127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>-1.216799</td>\n",
       "      <td>1.665294</td>\n",
       "      <td>1.155446</td>\n",
       "      <td>-1.621674</td>\n",
       "      <td>-1.425987</td>\n",
       "      <td>0.504995</td>\n",
       "      <td>1.072170</td>\n",
       "      <td>0.965919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>-1.230761</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>1.145892</td>\n",
       "      <td>-1.614891</td>\n",
       "      <td>-1.431582</td>\n",
       "      <td>0.491333</td>\n",
       "      <td>1.065870</td>\n",
       "      <td>0.929710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>-1.235852</td>\n",
       "      <td>1.679025</td>\n",
       "      <td>1.136337</td>\n",
       "      <td>-1.608108</td>\n",
       "      <td>-1.437177</td>\n",
       "      <td>0.477671</td>\n",
       "      <td>1.059570</td>\n",
       "      <td>0.893502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>-1.221731</td>\n",
       "      <td>1.691667</td>\n",
       "      <td>1.126783</td>\n",
       "      <td>-1.601324</td>\n",
       "      <td>-1.442773</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>1.053270</td>\n",
       "      <td>0.857294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>-1.223276</td>\n",
       "      <td>1.704388</td>\n",
       "      <td>1.117228</td>\n",
       "      <td>-1.594541</td>\n",
       "      <td>-1.448368</td>\n",
       "      <td>0.450347</td>\n",
       "      <td>1.046970</td>\n",
       "      <td>0.821086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>-1.209684</td>\n",
       "      <td>1.711139</td>\n",
       "      <td>1.107674</td>\n",
       "      <td>-1.587758</td>\n",
       "      <td>-1.453963</td>\n",
       "      <td>0.436685</td>\n",
       "      <td>1.040670</td>\n",
       "      <td>0.784878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>-1.192369</td>\n",
       "      <td>1.711746</td>\n",
       "      <td>1.098119</td>\n",
       "      <td>-1.580975</td>\n",
       "      <td>-1.459558</td>\n",
       "      <td>0.423023</td>\n",
       "      <td>1.034370</td>\n",
       "      <td>0.748669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>-1.178463</td>\n",
       "      <td>1.717654</td>\n",
       "      <td>1.088565</td>\n",
       "      <td>-1.574192</td>\n",
       "      <td>-1.465154</td>\n",
       "      <td>0.409361</td>\n",
       "      <td>1.028069</td>\n",
       "      <td>0.712461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>-1.166182</td>\n",
       "      <td>1.729082</td>\n",
       "      <td>1.079010</td>\n",
       "      <td>-1.567409</td>\n",
       "      <td>-1.470749</td>\n",
       "      <td>0.395699</td>\n",
       "      <td>1.021769</td>\n",
       "      <td>0.676253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>-1.169926</td>\n",
       "      <td>1.769880</td>\n",
       "      <td>1.069456</td>\n",
       "      <td>-1.560626</td>\n",
       "      <td>-1.476344</td>\n",
       "      <td>0.382038</td>\n",
       "      <td>1.015469</td>\n",
       "      <td>0.640045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162                                         -0.601510   \n",
       "163                                         -0.786068   \n",
       "164                                         -0.830387   \n",
       "165                                         -0.801089   \n",
       "166                                         -0.959917   \n",
       "167                                         -1.022309   \n",
       "168                                         -1.074401   \n",
       "169                                         -1.119597   \n",
       "170                                         -1.078648   \n",
       "171                                         -1.055426   \n",
       "172                                         -1.101053   \n",
       "173                                         -1.211370   \n",
       "174                                         -1.157198   \n",
       "175                                         -1.223444   \n",
       "176                                         -1.311519   \n",
       "177                                         -1.362602   \n",
       "178                                         -1.380125   \n",
       "179                                         -1.219296   \n",
       "180                                         -1.300284   \n",
       "181                                         -1.336476   \n",
       "182                                         -1.415774   \n",
       "183                                         -1.526021   \n",
       "184                                         -1.681806   \n",
       "185                                         -1.735167   \n",
       "186                                         -1.962315   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  \\\n",
       "162                                0.763466  -1.213929   \n",
       "163                                0.752299  -1.292173   \n",
       "164                                0.741131  -1.324219   \n",
       "165                                0.729964  -1.344446   \n",
       "166                                0.718796  -1.381638   \n",
       "167                                0.707629  -1.411208   \n",
       "168                                0.696461  -1.412953   \n",
       "169                                0.681823  -1.491464   \n",
       "170                                0.667184  -1.573805   \n",
       "171                                0.652545  -1.564950   \n",
       "172                                0.637906  -1.581584   \n",
       "173                                0.623268  -1.565976   \n",
       "174                                0.608629  -1.648556   \n",
       "175                                0.593990  -1.650049   \n",
       "176                                0.579351  -1.653957   \n",
       "177                                0.564713  -1.652572   \n",
       "178                                0.550074  -1.715349   \n",
       "179                                0.535435  -1.750917   \n",
       "180                                0.520796  -1.718448   \n",
       "181                                0.501996  -1.733426   \n",
       "182                                0.483195  -1.729362   \n",
       "183                                0.464395  -1.748544   \n",
       "184                                0.445594  -1.778060   \n",
       "185                                0.426794  -1.773710   \n",
       "186                                0.407993  -1.757007   \n",
       "187                                0.389193  -1.749976   \n",
       "188                                0.370392  -1.593005   \n",
       "189                                0.351592  -1.351489   \n",
       "190                                0.332791  -1.198492   \n",
       "191                                0.313991  -1.100894   \n",
       "\n",
       "     São Paulo - Produção de Cimento (t)  São Paulo - value  \\\n",
       "162                            -0.820644           1.082634   \n",
       "163                            -0.853043           1.099539   \n",
       "164                            -0.879813           1.131286   \n",
       "165                            -0.906260           1.157706   \n",
       "166                            -0.932027           1.184668   \n",
       "167                            -0.955450           1.212391   \n",
       "168                            -0.980990           1.240924   \n",
       "169                            -1.007316           1.258259   \n",
       "170                            -1.034034           1.282135   \n",
       "171                            -1.061615           1.306114   \n",
       "172                            -1.080622           1.330829   \n",
       "173                            -1.112059           1.373902   \n",
       "174                            -1.124585           1.418532   \n",
       "175                            -1.143191           1.458861   \n",
       "176                            -1.170809           1.494850   \n",
       "177                            -1.169332           1.527551   \n",
       "178                            -1.183874           1.561820   \n",
       "179                            -1.194903           1.603062   \n",
       "180                            -1.206170           1.645296   \n",
       "181                            -1.209225           1.658285   \n",
       "182                            -1.216799           1.665294   \n",
       "183                            -1.230761           1.672246   \n",
       "184                            -1.235852           1.679025   \n",
       "185                            -1.221731           1.691667   \n",
       "186                            -1.223276           1.704388   \n",
       "187                            -1.209684           1.711139   \n",
       "188                            -1.192369           1.711746   \n",
       "189                            -1.178463           1.717654   \n",
       "190                            -1.166182           1.729082   \n",
       "191                            -1.169926           1.769880   \n",
       "\n",
       "     São Paulo - PIB - Estadual  São Paulo - PIB - Construção Civil  \\\n",
       "162                    1.203179                           -1.484216   \n",
       "163                    1.205079                           -1.502451   \n",
       "164                    1.206979                           -1.520686   \n",
       "165                    1.208880                           -1.538921   \n",
       "166                    1.210780                           -1.557156   \n",
       "167                    1.212680                           -1.575390   \n",
       "168                    1.214581                           -1.593625   \n",
       "169                    1.211245                           -1.597093   \n",
       "170                    1.207910                           -1.600561   \n",
       "171                    1.204574                           -1.604029   \n",
       "172                    1.201239                           -1.607497   \n",
       "173                    1.197904                           -1.610965   \n",
       "174                    1.194568                           -1.614433   \n",
       "175                    1.191233                           -1.617900   \n",
       "176                    1.187897                           -1.621368   \n",
       "177                    1.184562                           -1.624836   \n",
       "178                    1.181226                           -1.628304   \n",
       "179                    1.177891                           -1.631772   \n",
       "180                    1.174555                           -1.635240   \n",
       "181                    1.165001                           -1.628457   \n",
       "182                    1.155446                           -1.621674   \n",
       "183                    1.145892                           -1.614891   \n",
       "184                    1.136337                           -1.608108   \n",
       "185                    1.126783                           -1.601324   \n",
       "186                    1.117228                           -1.594541   \n",
       "187                    1.107674                           -1.587758   \n",
       "188                    1.098119                           -1.580975   \n",
       "189                    1.088565                           -1.574192   \n",
       "190                    1.079010                           -1.567409   \n",
       "191                    1.069456                           -1.560626   \n",
       "\n",
       "     São Paulo - PIB - Per Capita  São Paulo - PIB - Preços de Mercado  \\\n",
       "162                     -1.259120                             0.705516   \n",
       "163                     -1.269575                             0.699897   \n",
       "164                     -1.280030                             0.694278   \n",
       "165                     -1.290484                             0.688659   \n",
       "166                     -1.300939                             0.683040   \n",
       "167                     -1.311394                             0.677421   \n",
       "168                     -1.321849                             0.671803   \n",
       "169                     -1.329595                             0.660179   \n",
       "170                     -1.337340                             0.648555   \n",
       "171                     -1.345086                             0.636932   \n",
       "172                     -1.352831                             0.625308   \n",
       "173                     -1.360577                             0.613684   \n",
       "174                     -1.368323                             0.602060   \n",
       "175                     -1.376068                             0.590437   \n",
       "176                     -1.383814                             0.578813   \n",
       "177                     -1.391560                             0.567189   \n",
       "178                     -1.399305                             0.555566   \n",
       "179                     -1.407051                             0.543942   \n",
       "180                     -1.414796                             0.532318   \n",
       "181                     -1.420392                             0.518656   \n",
       "182                     -1.425987                             0.504995   \n",
       "183                     -1.431582                             0.491333   \n",
       "184                     -1.437177                             0.477671   \n",
       "185                     -1.442773                             0.464009   \n",
       "186                     -1.448368                             0.450347   \n",
       "187                     -1.453963                             0.436685   \n",
       "188                     -1.459558                             0.423023   \n",
       "189                     -1.465154                             0.409361   \n",
       "190                     -1.470749                             0.395699   \n",
       "191                     -1.476344                             0.382038   \n",
       "\n",
       "     São Paulo - Desemprego  São Paulo - IDH  \n",
       "162                1.311604         1.431678  \n",
       "163                1.291318         1.404725  \n",
       "164                1.271031         1.377772  \n",
       "165                1.250744         1.350819  \n",
       "166                1.230457         1.323866  \n",
       "167                1.210170         1.296914  \n",
       "168                1.189884         1.269961  \n",
       "169                1.181124         1.250659  \n",
       "170                1.172365         1.231357  \n",
       "171                1.163605         1.212054  \n",
       "172                1.154846         1.192752  \n",
       "173                1.146087         1.173450  \n",
       "174                1.137327         1.154148  \n",
       "175                1.128568         1.134846  \n",
       "176                1.119808         1.115544  \n",
       "177                1.111049         1.096241  \n",
       "178                1.102289         1.076939  \n",
       "179                1.093530         1.057637  \n",
       "180                1.084771         1.038335  \n",
       "181                1.078470         1.002127  \n",
       "182                1.072170         0.965919  \n",
       "183                1.065870         0.929710  \n",
       "184                1.059570         0.893502  \n",
       "185                1.053270         0.857294  \n",
       "186                1.046970         0.821086  \n",
       "187                1.040670         0.784878  \n",
       "188                1.034370         0.748669  \n",
       "189                1.028069         0.712461  \n",
       "190                1.021769         0.676253  \n",
       "191                1.015469         0.640045  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162     910.653\n",
       "163     937.696\n",
       "164     871.611\n",
       "165     795.853\n",
       "166     804.767\n",
       "167     712.733\n",
       "168     763.665\n",
       "169     727.397\n",
       "170     855.245\n",
       "171     855.042\n",
       "172     648.867\n",
       "173    1003.807\n",
       "174     855.104\n",
       "175     913.329\n",
       "176     849.262\n",
       "177     897.883\n",
       "178     860.059\n",
       "179     771.417\n",
       "180     860.232\n",
       "181     773.607\n",
       "182     790.146\n",
       "183     886.929\n",
       "184     941.600\n",
       "185     817.301\n",
       "186     957.289\n",
       "187     978.990\n",
       "188     906.956\n",
       "189     980.948\n",
       "190     872.046\n",
       "191     692.232\n",
       "Name: São Paulo - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*6 + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    train, train_val = validation_splitter(train_input, 6)\n",
    "    target,target_val = validation_splitter(train_target, 6)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train, \n",
    "                        target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val, target_val),\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3105976222, 2805720170, 3391438123, 2518405116, 642653407, 422945028, 3626258037, 45802468, 2817319329, 3422377802, 681545618, 2932850902, 2633540016, 2079934621, 3688915333, 2121287827, 1773717203, 1380785523, 714949175, 164812638, 3212960564, 3131451633, 2974545041, 4142879747, 2061307042]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 9692.923828125\n",
      "winner_seed: 3105976222\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 11535.814453125\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 9433.6708984375\n",
      "winner_seed: 3391438123\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 10289.236328125\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 10716.6689453125\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 9177.4560546875\n",
      "winner_seed: 422945028\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 10074.7265625\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 9362.6201171875\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 9597.904296875\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 10390.373046875\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 8893.091796875\n",
      "winner_seed: 681545618\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 9617.3984375\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 10819.7763671875\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 9594.7900390625\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 10555.5419921875\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 9511.9619140625\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 8987.7392578125\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 10303.3671875\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 8429.6748046875\n",
      "winner_seed: 714949175\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 9944.39453125\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 8572.2998046875\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n",
      "val_loss: 10370.6962890625\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 11899.44921875\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 11241.517578125\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 9869.224609375\n",
      "\n",
      "\n",
      "final_seed: 714949175\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 1s 24ms/step - loss: 1385850.0000 - val_loss: 933882.3750\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 931419.1250 - val_loss: 703120.3125\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 711080.8750 - val_loss: 550094.5000\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 599960.3750 - val_loss: 611562.8125\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 592906.5625 - val_loss: 443969.2500\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 426762.2500 - val_loss: 412088.8750\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 412756.1250 - val_loss: 305358.9062\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 364358.6875 - val_loss: 304199.4688\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 339644.5312 - val_loss: 317102.1875\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 327629.6875 - val_loss: 577349.5000\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 412218.6250 - val_loss: 284717.4062\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 317004.8750 - val_loss: 252760.2656\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253288.4375 - val_loss: 242812.2188\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 253292.7656 - val_loss: 206676.0312\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 213668.1875 - val_loss: 252157.7969\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 203915.7969 - val_loss: 161875.8594\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 205193.0000 - val_loss: 180583.8594\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 198768.9844 - val_loss: 158654.1406\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 161008.0312 - val_loss: 136326.2344\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 178017.4375 - val_loss: 127266.6328\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 149354.6250 - val_loss: 112221.5469\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 121920.1875 - val_loss: 114941.0547\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 103389.1094 - val_loss: 102273.1641\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111432.0703 - val_loss: 93367.5469\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101546.7734 - val_loss: 83715.7031\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91723.0781 - val_loss: 81001.4062\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 90690.5625 - val_loss: 85614.9922\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 87999.8594 - val_loss: 99838.5000\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 82537.9531 - val_loss: 73304.6562\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 69617.4141 - val_loss: 71236.6797\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77927.5938 - val_loss: 64944.4297\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 75053.1328 - val_loss: 60278.5664\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 66025.0938 - val_loss: 103464.0625\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 74907.5938 - val_loss: 101921.4453\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 70956.5625 - val_loss: 58713.7305\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 58945.9336 - val_loss: 54321.9531\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51369.3086 - val_loss: 43323.6406\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54452.1484 - val_loss: 94521.0078\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 78322.8203 - val_loss: 49188.5039\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 55463.5352 - val_loss: 41237.5977\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 54067.3633 - val_loss: 45288.5273\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 51679.5703 - val_loss: 35682.3203\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44252.5703 - val_loss: 40155.5586\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 49607.4414 - val_loss: 64967.4688\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 59773.9297 - val_loss: 33106.4648\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45414.7812 - val_loss: 40193.0938\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45444.5586 - val_loss: 28972.7598\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 39134.5352 - val_loss: 29943.6719\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37555.5039 - val_loss: 25869.5000\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32993.2812 - val_loss: 35884.5547\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 32839.6719 - val_loss: 41660.4258\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37208.9414 - val_loss: 34204.6562\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 29983.8594 - val_loss: 21988.4766\n",
      "Epoch 54/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 32388.2324 - val_loss: 22714.3242\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 28311.9160 - val_loss: 27844.2676\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 29324.9883 - val_loss: 20511.3105\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 26541.5801 - val_loss: 26349.2266\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 24922.9023 - val_loss: 27645.1426\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23557.5742 - val_loss: 21662.5957\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22949.4043 - val_loss: 24405.6602\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21045.4082 - val_loss: 24836.2129\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19241.3242 - val_loss: 26019.3145\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22132.3926 - val_loss: 25628.4492\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17949.0859 - val_loss: 22950.5918\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22029.3691 - val_loss: 21894.2891\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19755.7148 - val_loss: 32663.4785\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24552.6680 - val_loss: 24198.0918\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21162.7012 - val_loss: 32390.4102\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 22424.2852 - val_loss: 20391.8164\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22544.0117 - val_loss: 16256.3066\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19672.5703 - val_loss: 24520.1094\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18195.0664 - val_loss: 21156.5273\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18672.1328 - val_loss: 14684.0264\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16643.5098 - val_loss: 24237.6621\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16972.0566 - val_loss: 18384.6191\n",
      "Epoch 76/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 15697.1592 - val_loss: 21014.4824\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15450.7314 - val_loss: 13401.9834\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13372.9609 - val_loss: 19068.2148\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13722.1025 - val_loss: 19065.9648\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15266.7744 - val_loss: 20031.9609\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15259.4863 - val_loss: 17372.3535\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16665.1816 - val_loss: 20487.7109\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12848.0820 - val_loss: 21009.5371\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14403.9531 - val_loss: 22832.1367\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13649.1357 - val_loss: 24561.7383\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15182.0938 - val_loss: 12262.4121\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12760.4023 - val_loss: 18057.3652\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12551.1826 - val_loss: 17336.0332\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16622.7383 - val_loss: 25666.4238\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15819.0615 - val_loss: 18849.2031\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13409.5488 - val_loss: 18570.0801\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13253.2979 - val_loss: 18561.1016\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15958.3867 - val_loss: 17088.0566\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11832.6201 - val_loss: 19146.3926\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11379.4746 - val_loss: 14282.0166\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12077.1357 - val_loss: 17469.2773\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11818.2568 - val_loss: 19440.1152\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13612.9600 - val_loss: 18342.7559\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10845.2061 - val_loss: 17209.1484\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11827.9551 - val_loss: 20719.8379\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12633.2480 - val_loss: 13174.5039\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12229.7617 - val_loss: 13293.8623\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13129.3428 - val_loss: 16091.8516\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11620.2217 - val_loss: 13178.4463\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11946.5264 - val_loss: 19587.4766\n",
      "Epoch 106/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14662.0205 - val_loss: 20864.1992\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15640.1221 - val_loss: 17933.4688\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12747.7432 - val_loss: 15877.7734\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12660.3896 - val_loss: 11635.0518\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11503.2441 - val_loss: 13287.0820\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11888.6895 - val_loss: 13654.1025\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10657.3643 - val_loss: 12358.2383\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11134.8447 - val_loss: 20036.8672\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 12005.8926 - val_loss: 16267.1611\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 12121.3643 - val_loss: 14296.0996\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 11913.8555 - val_loss: 16863.4375\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11555.7598 - val_loss: 14901.8838\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10278.0977 - val_loss: 16057.1250\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10418.7783 - val_loss: 16117.0254\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10918.2285 - val_loss: 15742.0439\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11574.1260 - val_loss: 15210.7930\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11999.0127 - val_loss: 20693.1621\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11965.2637 - val_loss: 14723.5254\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11265.1221 - val_loss: 16821.1699\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9957.5146 - val_loss: 14513.2393\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10191.5420 - val_loss: 18087.6973\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9894.5000 - val_loss: 24143.9648\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11950.2090 - val_loss: 18121.2227\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10646.6143 - val_loss: 14460.6475\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9576.5566 - val_loss: 17802.7969\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10536.1816 - val_loss: 16845.2910\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9070.9238 - val_loss: 15535.8398\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9826.6631 - val_loss: 18550.5605\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11332.2588 - val_loss: 13194.6963\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8400.7695 - val_loss: 15587.2676\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8314.2266 - val_loss: 21239.6660\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10673.2295 - val_loss: 25193.2168\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11428.3330 - val_loss: 14321.0293\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9441.9141 - val_loss: 19188.5664\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8518.1348 - val_loss: 14132.6289\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9698.0078 - val_loss: 14861.8662\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9304.4375 - val_loss: 12793.6602\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9721.8877 - val_loss: 14271.3447\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11472.9668 - val_loss: 21929.4668\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10805.0869 - val_loss: 16397.5898\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10054.4092 - val_loss: 16731.8301\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10108.9561 - val_loss: 16644.6992\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10520.7686 - val_loss: 16418.9531\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8785.0020 - val_loss: 15291.7734\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9749.3887 - val_loss: 18363.5605\n",
      "Epoch 151/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 8912.5557 - val_loss: 17489.1992\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11554.2998 - val_loss: 16460.9551\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8923.1582 - val_loss: 14449.6162\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8721.9521 - val_loss: 16672.8145\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11637.2959 - val_loss: 14454.4297\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11727.4248 - val_loss: 20785.7676\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8547.2988 - val_loss: 16267.0264\n",
      "Epoch 158/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9631.4023 - val_loss: 15742.7432\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10383.3115 - val_loss: 15721.4424\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9505.1162 - val_loss: 14242.9873\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9347.4668 - val_loss: 14713.2549\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9061.8965 - val_loss: 14370.6914\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9290.8154 - val_loss: 16242.2568\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8948.5166 - val_loss: 14803.3496\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8877.7178 - val_loss: 15440.9746\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9147.9551 - val_loss: 16137.2061\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9027.5400 - val_loss: 15138.0166\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8248.3896 - val_loss: 13302.3047\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7474.0220 - val_loss: 15748.3818\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7665.3662 - val_loss: 16788.2793\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8897.8506 - val_loss: 13981.3350\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8434.6836 - val_loss: 13385.8711\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8657.8301 - val_loss: 12146.5830\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8880.0889 - val_loss: 12055.1445\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8150.5400 - val_loss: 15037.9287\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9635.3535 - val_loss: 16866.6484\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7469.5034 - val_loss: 14930.3418\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8768.3340 - val_loss: 20369.9258\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10393.9355 - val_loss: 16121.3770\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8427.7842 - val_loss: 17586.5840\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8203.7461 - val_loss: 18855.0762\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8575.9453 - val_loss: 19403.6621\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9631.7285 - val_loss: 19906.8164\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8961.1846 - val_loss: 21612.6426\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9368.9893 - val_loss: 19668.3574\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8123.3203 - val_loss: 14607.3213\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8173.9517 - val_loss: 17114.0898\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9462.1641 - val_loss: 17398.5137\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9016.5947 - val_loss: 14773.3701\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9549.2764 - val_loss: 14410.2139\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8879.8154 - val_loss: 18442.6074\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8530.3643 - val_loss: 14479.7549\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9299.7852 - val_loss: 18192.3086\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8342.2061 - val_loss: 15517.0713\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8093.4424 - val_loss: 15215.8770\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8004.1890 - val_loss: 18801.0332\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8463.7090 - val_loss: 19485.5879\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9237.4316 - val_loss: 16740.3633\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9507.8916 - val_loss: 15299.8291\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9553.1562 - val_loss: 18155.2637\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9164.0303 - val_loss: 16878.1797\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8008.3379 - val_loss: 16777.8105\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8981.9980 - val_loss: 24649.1152\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10699.9014 - val_loss: 16822.0391\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8687.6035 - val_loss: 15045.2666\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9124.9551 - val_loss: 17386.8164\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9459.2832 - val_loss: 19648.7285\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9376.5908 - val_loss: 18569.4648\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9263.2803 - val_loss: 18702.4863\n",
      "Epoch 210/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9935.4648 - val_loss: 14067.7627\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9675.8379 - val_loss: 12706.0947\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8386.5723 - val_loss: 16026.9141\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7877.6704 - val_loss: 15621.7295\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9403.8301 - val_loss: 18831.6543\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10050.2617 - val_loss: 19071.2070\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9697.5938 - val_loss: 23021.8574\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10834.7852 - val_loss: 18441.4980\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9535.2910 - val_loss: 16941.9160\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9246.9004 - val_loss: 16538.8281\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9060.3623 - val_loss: 16010.0742\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8269.1270 - val_loss: 15526.0752\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7992.7646 - val_loss: 16225.7588\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8364.1162 - val_loss: 16949.7500\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9012.4766 - val_loss: 16341.5615\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8416.9521 - val_loss: 22283.7734\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8682.2646 - val_loss: 18800.7891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8697.3486 - val_loss: 15798.2119\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8984.7236 - val_loss: 16710.3262\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8852.8086 - val_loss: 17345.9414\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9002.3545 - val_loss: 16013.8857\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9268.9912 - val_loss: 17071.5547\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7901.8926 - val_loss: 18666.7012\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8278.2090 - val_loss: 17394.6094\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8782.3955 - val_loss: 16725.9004\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9036.8076 - val_loss: 16360.5713\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9623.7119 - val_loss: 22508.0410\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10729.1377 - val_loss: 16736.4961\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11041.4600 - val_loss: 22345.4863\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9841.2471 - val_loss: 16409.1699\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10596.9561 - val_loss: 23591.2363\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10692.5078 - val_loss: 17156.5762\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8251.5244 - val_loss: 20244.1172\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8459.8564 - val_loss: 17759.9902\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8379.7432 - val_loss: 15418.6240\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8034.8521 - val_loss: 18381.1191\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8795.2207 - val_loss: 15190.0352\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8925.7578 - val_loss: 16188.8271\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8593.2529 - val_loss: 18389.9492\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9076.6826 - val_loss: 15029.5488\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8409.4014 - val_loss: 18105.4531\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8298.7539 - val_loss: 19534.3262\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9078.6445 - val_loss: 20699.5977\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10049.8408 - val_loss: 17613.4805\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8552.0596 - val_loss: 18702.5547\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9198.6650 - val_loss: 15796.4932\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8165.4785 - val_loss: 16194.3867\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8603.2822 - val_loss: 15223.2998\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9270.0039 - val_loss: 15010.7266\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8637.4707 - val_loss: 20418.2969\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9355.6768 - val_loss: 13684.9463\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9078.8711 - val_loss: 14560.7988\n",
      "Epoch 262/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8589.3301 - val_loss: 13327.5391\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8177.7192 - val_loss: 17071.4766\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8240.3242 - val_loss: 16604.5449\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8337.1660 - val_loss: 14200.8770\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7444.7529 - val_loss: 16841.0352\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9127.9941 - val_loss: 18757.7852\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9264.9756 - val_loss: 16748.2402\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10694.3301 - val_loss: 15870.7559\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8853.4570 - val_loss: 20572.5762\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9345.4229 - val_loss: 19850.9277\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8798.9395 - val_loss: 18251.0039\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8755.5898 - val_loss: 17576.5449\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10379.6807 - val_loss: 18009.4238\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10743.8252 - val_loss: 24803.8652\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13510.5186 - val_loss: 20437.5859\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10063.9805 - val_loss: 17422.2988\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9425.1104 - val_loss: 15662.2314\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8835.1309 - val_loss: 15809.4561\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9820.5420 - val_loss: 14934.6387\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9231.4873 - val_loss: 17160.0566\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10664.8301 - val_loss: 18588.6758\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10456.3496 - val_loss: 16913.9453\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10118.1523 - val_loss: 14518.7432\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12157.5732 - val_loss: 25102.6582\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10488.5527 - val_loss: 19331.4238\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9585.5342 - val_loss: 15400.2754\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9685.9668 - val_loss: 16468.4160\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9919.8096 - val_loss: 16183.3291\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8926.7471 - val_loss: 17813.4277\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8948.1162 - val_loss: 24111.7090\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10693.4160 - val_loss: 16473.0664\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8314.0459 - val_loss: 15693.0420\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9142.1621 - val_loss: 14775.2744\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9350.7217 - val_loss: 17123.4980\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9312.2051 - val_loss: 20625.5273\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9218.7842 - val_loss: 21551.8496\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9684.7676 - val_loss: 19304.2266\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9343.2744 - val_loss: 21140.9492\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9746.6787 - val_loss: 23414.2871\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9871.6641 - val_loss: 24430.6543\n",
      "Epoch 302/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 9853.8730 - val_loss: 18414.7930\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9422.8135 - val_loss: 19700.4355\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9313.5684 - val_loss: 19502.9277\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9240.2363 - val_loss: 19025.9375\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8870.4404 - val_loss: 20169.7324\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9395.0078 - val_loss: 15268.0400\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9589.7705 - val_loss: 15859.6436\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9128.0400 - val_loss: 14373.4814\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8550.7490 - val_loss: 20078.0039\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9059.4717 - val_loss: 22572.7402\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8809.3311 - val_loss: 18255.0098\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9172.9336 - val_loss: 20206.4043\n",
      "Epoch 314/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9269.1484 - val_loss: 20344.5117\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9082.0820 - val_loss: 19090.4609\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8466.0400 - val_loss: 19256.3867\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7753.2163 - val_loss: 15686.8359\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8530.4170 - val_loss: 20967.8984\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8843.3867 - val_loss: 18720.4395\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8383.1396 - val_loss: 14918.1641\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8923.6582 - val_loss: 13809.7080\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8051.5166 - val_loss: 11170.3359\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7678.8179 - val_loss: 11383.6055\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8319.2490 - val_loss: 10878.6426\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9833.5381 - val_loss: 12293.1484\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9747.9199 - val_loss: 13418.9121\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8604.1426 - val_loss: 13755.8252\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8476.4092 - val_loss: 15006.7109\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8324.0459 - val_loss: 13126.3945\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7163.9561 - val_loss: 14037.8232\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8716.6016 - val_loss: 13934.2197\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9359.7393 - val_loss: 18218.4922\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9266.7627 - val_loss: 16808.9609\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8868.6748 - val_loss: 14632.5449\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8247.1338 - val_loss: 16266.6689\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7639.7222 - val_loss: 15360.9111\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8249.5488 - val_loss: 19248.7969\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9195.4619 - val_loss: 15914.0322\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8757.0625 - val_loss: 16380.0605\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8186.2222 - val_loss: 17610.0996\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9318.1504 - val_loss: 17169.3652\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10285.7168 - val_loss: 16266.4150\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9623.0029 - val_loss: 15466.8574\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13096.3242 - val_loss: 18716.3594\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10346.6328 - val_loss: 16604.8184\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11239.7861 - val_loss: 18223.1855\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10784.8125 - val_loss: 13945.9238\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 11237.3838 - val_loss: 15947.7207\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13058.7461 - val_loss: 18767.6172\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10857.6885 - val_loss: 15847.9414\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9096.9785 - val_loss: 17035.3145\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11770.9277 - val_loss: 21342.9629\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11494.3457 - val_loss: 18070.3223\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10099.9043 - val_loss: 26857.1895\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11194.9180 - val_loss: 13935.3691\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8689.6348 - val_loss: 19843.4902\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8690.0781 - val_loss: 12784.8174\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9395.8311 - val_loss: 14197.3916\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11013.6650 - val_loss: 15340.1875\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9578.4336 - val_loss: 15670.5488\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11904.0186 - val_loss: 20322.0840\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10664.9580 - val_loss: 21359.6250\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10435.1582 - val_loss: 19815.6758\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9866.2100 - val_loss: 20865.2656\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10433.6846 - val_loss: 18453.0840\n",
      "Epoch 366/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8742.4961 - val_loss: 19141.0176\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9665.1855 - val_loss: 14898.8730\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8667.8076 - val_loss: 15884.7168\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9303.6113 - val_loss: 16116.5674\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9206.2305 - val_loss: 17933.2676\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10849.1328 - val_loss: 15423.4834\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8360.0625 - val_loss: 16709.6387\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7458.4590 - val_loss: 17550.2773\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8958.9531 - val_loss: 20867.8125\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9636.4268 - val_loss: 19313.0234\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9597.5215 - val_loss: 17693.0859\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9123.5303 - val_loss: 16237.2959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8924.0186 - val_loss: 14570.2568\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8218.2930 - val_loss: 15251.1104\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8050.6353 - val_loss: 15090.1914\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8843.0449 - val_loss: 16567.9668\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9583.0713 - val_loss: 13484.2480\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9295.9541 - val_loss: 16496.9473\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8277.6689 - val_loss: 14019.8877\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9507.8750 - val_loss: 15983.1895\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7688.9150 - val_loss: 14245.2412\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7372.7974 - val_loss: 18146.7285\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8477.9189 - val_loss: 18064.6035\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9365.2168 - val_loss: 16036.5371\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8682.1367 - val_loss: 14499.1602\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8653.0127 - val_loss: 12939.8213\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9096.6719 - val_loss: 14200.4258\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8678.4121 - val_loss: 15194.1621\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7956.1807 - val_loss: 15505.4727\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9466.3262 - val_loss: 12768.9023\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8566.9395 - val_loss: 14493.5117\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9252.8711 - val_loss: 13216.8135\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8212.9443 - val_loss: 13823.3164\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8255.3691 - val_loss: 19079.3203\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8341.7891 - val_loss: 17196.5508\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9473.7305 - val_loss: 15695.3477\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9163.3018 - val_loss: 12740.2393\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9786.5000 - val_loss: 19382.7227\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9344.7314 - val_loss: 21606.0000\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9101.6611 - val_loss: 15246.0449\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8879.2568 - val_loss: 14010.3545\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7119.9121 - val_loss: 17020.2324\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9418.0684 - val_loss: 15785.3682\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8312.8760 - val_loss: 15121.8008\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8033.7554 - val_loss: 12860.8330\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9733.4531 - val_loss: 18888.8730\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9674.6133 - val_loss: 16952.5391\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9790.1406 - val_loss: 18372.5586\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9284.4297 - val_loss: 16842.6094\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8579.4639 - val_loss: 15066.5645\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8993.6348 - val_loss: 15076.1738\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8551.2998 - val_loss: 17504.8164\n",
      "Epoch 418/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9209.7617 - val_loss: 15338.4189\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8392.9600 - val_loss: 14045.3662\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8847.6650 - val_loss: 18225.1914\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8971.7285 - val_loss: 16547.0000\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9082.0703 - val_loss: 16306.1230\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7390.9614 - val_loss: 18209.8730\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8780.9707 - val_loss: 16590.9570\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8107.6167 - val_loss: 13699.5049\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8075.4639 - val_loss: 17749.5723\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9263.6543 - val_loss: 13773.6133\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8938.2041 - val_loss: 14487.8574\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8867.5146 - val_loss: 13223.0537\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8800.2158 - val_loss: 11884.1494\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8437.3516 - val_loss: 13000.4102\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8414.1406 - val_loss: 14663.8838\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8279.3262 - val_loss: 14719.1816\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9264.9424 - val_loss: 14104.8633\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8454.3350 - val_loss: 13688.5859\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9656.9580 - val_loss: 11924.5264\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10368.9727 - val_loss: 12931.2236\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9286.2236 - val_loss: 10567.0303\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8486.2969 - val_loss: 10852.8105\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8367.0576 - val_loss: 12140.3057\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9149.6172 - val_loss: 12629.0049\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9331.3848 - val_loss: 12474.1250\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7543.9941 - val_loss: 12323.9600\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8001.3770 - val_loss: 14264.1758\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9168.8359 - val_loss: 21569.9336\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8925.3887 - val_loss: 13244.9492\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7845.5493 - val_loss: 19339.1895\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8673.6611 - val_loss: 12265.1943\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7379.7725 - val_loss: 13156.8369\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7214.4927 - val_loss: 14303.0244\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8740.5889 - val_loss: 16765.6133\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9524.6631 - val_loss: 14339.7812\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8144.5054 - val_loss: 14814.8086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8216.3672 - val_loss: 12923.7988\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8537.4551 - val_loss: 14929.3760\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8441.5859 - val_loss: 12742.0684\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8341.8721 - val_loss: 13209.2080\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9833.0801 - val_loss: 15327.0752\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9162.9150 - val_loss: 17874.4922\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9405.7324 - val_loss: 16302.3301\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8271.6631 - val_loss: 17327.6367\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9153.8271 - val_loss: 15454.2168\n",
      "Epoch 463/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9098.3701 - val_loss: 14243.3662\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7584.0859 - val_loss: 14511.1641\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9236.4912 - val_loss: 16594.6484\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10360.6748 - val_loss: 13419.5186\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8675.6787 - val_loss: 13479.4697\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8410.8242 - val_loss: 12340.5430\n",
      "Epoch 469/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9209.3496 - val_loss: 15784.6602\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8914.4971 - val_loss: 14942.0537\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8092.1953 - val_loss: 19305.2988\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9108.3789 - val_loss: 14642.2812\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8689.0117 - val_loss: 14696.8867\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10417.5049 - val_loss: 14634.8711\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8463.2236 - val_loss: 14062.1299\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8827.9668 - val_loss: 13497.8398\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8848.9062 - val_loss: 14625.1016\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8012.9150 - val_loss: 14046.4775\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7905.2798 - val_loss: 14336.3584\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8105.3613 - val_loss: 13437.6602\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8510.0146 - val_loss: 13915.5889\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9190.5430 - val_loss: 14216.3555\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8446.3584 - val_loss: 14264.7500\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9073.4688 - val_loss: 12564.3828\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8282.5176 - val_loss: 13190.4814\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8288.2637 - val_loss: 11839.5371\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8647.1367 - val_loss: 12234.1387\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7458.8525 - val_loss: 14924.3115\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8030.2275 - val_loss: 12884.6855\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9663.0186 - val_loss: 19829.8770\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9853.7080 - val_loss: 12588.8037\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8387.2129 - val_loss: 12682.1357\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8044.5435 - val_loss: 12590.7725\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9741.1875 - val_loss: 19700.4707\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10708.6035 - val_loss: 13465.7666\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9091.1396 - val_loss: 14074.7930\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9154.0312 - val_loss: 14468.0146\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10510.3936 - val_loss: 14572.6025\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8891.3926 - val_loss: 14478.6865\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9216.9209 - val_loss: 19061.7832\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9229.3926 - val_loss: 15834.3320\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9572.0850 - val_loss: 16451.1348\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8928.9922 - val_loss: 16043.9287\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8285.3271 - val_loss: 15395.9375\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9125.2520 - val_loss: 17780.5645\n",
      "Epoch 506/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10029.3379 - val_loss: 15197.4678\n",
      "Epoch 507/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9085.7207 - val_loss: 14263.1455\n",
      "Epoch 508/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8650.4424 - val_loss: 15703.8799\n",
      "Epoch 509/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8625.2725 - val_loss: 14387.1436\n",
      "Epoch 510/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8712.9375 - val_loss: 15345.9453\n",
      "Epoch 511/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8276.8301 - val_loss: 19666.9746\n",
      "Epoch 512/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11958.6758 - val_loss: 16960.7832\n",
      "Epoch 513/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12330.2021 - val_loss: 19431.3203\n",
      "Epoch 514/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12461.1250 - val_loss: 16609.8828\n",
      "Epoch 515/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11108.4180 - val_loss: 26499.3457\n",
      "Epoch 516/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11480.0938 - val_loss: 16455.8594\n",
      "Epoch 517/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8358.0801 - val_loss: 16474.6367\n",
      "Epoch 518/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8578.4932 - val_loss: 19462.2266\n",
      "Epoch 519/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10253.5244 - val_loss: 13666.2012\n",
      "Epoch 520/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9208.5615 - val_loss: 14572.2012\n",
      "Epoch 521/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9357.1699 - val_loss: 15199.8213\n",
      "Epoch 522/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8758.5391 - val_loss: 15807.9424\n",
      "Epoch 523/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8533.1992 - val_loss: 17309.0352\n",
      "Epoch 524/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9131.7412 - val_loss: 17133.1680\n",
      "Epoch 525/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9836.9180 - val_loss: 19392.0156\n",
      "Epoch 526/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9382.9912 - val_loss: 16220.1182\n",
      "Epoch 527/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9379.0332 - val_loss: 17184.2051\n",
      "Epoch 528/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8298.1807 - val_loss: 15292.1367\n",
      "Epoch 529/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 11078.6621 - val_loss: 18805.7520\n",
      "Epoch 530/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11309.4395 - val_loss: 17784.7148\n",
      "Epoch 531/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9550.8770 - val_loss: 18187.0293\n",
      "Epoch 532/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10468.5146 - val_loss: 17851.8652\n",
      "Epoch 533/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9876.4004 - val_loss: 18329.0332\n",
      "Epoch 534/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11370.3711 - val_loss: 16375.4814\n",
      "Epoch 535/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9144.5088 - val_loss: 21937.0039\n",
      "Epoch 536/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10849.7725 - val_loss: 18019.8848\n",
      "Epoch 537/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9006.2461 - val_loss: 16748.6836\n",
      "Epoch 538/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9001.7715 - val_loss: 15352.9795\n",
      "Epoch 539/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9215.5684 - val_loss: 18951.4531\n",
      "Epoch 540/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 10122.9883 - val_loss: 13660.8604\n",
      "Epoch 541/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10561.6533 - val_loss: 31201.2969\n",
      "Epoch 542/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13069.3994 - val_loss: 18712.4863\n",
      "Epoch 543/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10025.1162 - val_loss: 15728.1875\n",
      "Epoch 544/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8926.7373 - val_loss: 15257.1191\n",
      "Epoch 545/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11237.1611 - val_loss: 15522.7041\n",
      "Epoch 546/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9165.0684 - val_loss: 15669.4932\n",
      "Epoch 547/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9571.0596 - val_loss: 13461.5137\n",
      "Epoch 548/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9751.9277 - val_loss: 12034.4131\n",
      "Epoch 549/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8003.0972 - val_loss: 14752.2432\n",
      "Epoch 550/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8927.8320 - val_loss: 12743.4766\n",
      "Epoch 551/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8760.9395 - val_loss: 13271.1621\n",
      "Epoch 552/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9910.1016 - val_loss: 15201.1963\n",
      "Epoch 553/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9261.5273 - val_loss: 11001.4121\n",
      "Epoch 554/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8130.5229 - val_loss: 12517.9873\n",
      "Epoch 555/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9017.8965 - val_loss: 10980.0303\n",
      "Epoch 556/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8717.3809 - val_loss: 11599.7500\n",
      "Epoch 557/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9078.7959 - val_loss: 15651.6318\n",
      "Epoch 558/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8301.2803 - val_loss: 11258.9629\n",
      "Epoch 559/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7967.5566 - val_loss: 10697.1064\n",
      "Epoch 560/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7748.2773 - val_loss: 11930.3047\n",
      "Epoch 561/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8170.3076 - val_loss: 12251.2451\n",
      "Epoch 562/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9582.6514 - val_loss: 16378.9209\n",
      "Epoch 563/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10494.3115 - val_loss: 11783.8936\n",
      "Epoch 564/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7781.7417 - val_loss: 11713.1689\n",
      "Epoch 565/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8650.1885 - val_loss: 12557.0938\n",
      "Epoch 566/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12329.7988 - val_loss: 28184.6582\n",
      "Epoch 567/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16007.2373 - val_loss: 16897.2031\n",
      "Epoch 568/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10681.5947 - val_loss: 14958.3730\n",
      "Epoch 569/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 11182.2803 - val_loss: 15785.0020\n",
      "Epoch 570/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11277.8125 - val_loss: 17706.3770\n",
      "Epoch 571/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10602.2051 - val_loss: 15337.4492\n",
      "Epoch 572/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11087.3398 - val_loss: 13260.6826\n",
      "Epoch 573/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9469.4004 - val_loss: 24367.1738\n",
      "Epoch 574/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13312.2070 - val_loss: 12258.4629\n",
      "Epoch 575/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9341.9150 - val_loss: 15250.2998\n",
      "Epoch 576/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9359.1631 - val_loss: 12861.0537\n",
      "Epoch 577/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8914.0615 - val_loss: 12759.0166\n",
      "Epoch 578/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9102.3223 - val_loss: 19588.8223\n",
      "Epoch 579/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10192.7803 - val_loss: 11979.2207\n",
      "Epoch 580/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8793.6572 - val_loss: 13025.0537\n",
      "Epoch 581/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7971.7778 - val_loss: 11650.0547\n",
      "Epoch 582/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7308.9419 - val_loss: 15506.7256\n",
      "Epoch 583/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10546.6846 - val_loss: 16624.3047\n",
      "Epoch 584/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10705.0254 - val_loss: 15235.8086\n",
      "Epoch 585/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11117.0000 - val_loss: 20050.2832\n",
      "Epoch 586/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13245.3467 - val_loss: 12683.6797\n",
      "Epoch 587/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10086.0303 - val_loss: 13969.3896\n",
      "Epoch 588/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10237.3125 - val_loss: 13477.2051\n",
      "Epoch 589/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9619.1230 - val_loss: 12909.8291\n",
      "Epoch 590/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10720.8086 - val_loss: 15452.9316\n",
      "Epoch 591/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10424.1152 - val_loss: 15535.0205\n",
      "Epoch 592/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10479.3574 - val_loss: 15161.2324\n",
      "Epoch 593/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11532.3457 - val_loss: 15063.8633\n",
      "Epoch 594/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11019.9121 - val_loss: 27729.3418\n",
      "Epoch 595/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13029.5156 - val_loss: 14636.2646\n",
      "Epoch 596/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10526.4551 - val_loss: 16313.2207\n",
      "Epoch 597/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9881.6807 - val_loss: 13492.5947\n",
      "Epoch 598/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9953.0068 - val_loss: 21952.2715\n",
      "Epoch 599/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10764.7979 - val_loss: 12177.4434\n",
      "Epoch 600/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9124.5898 - val_loss: 14166.6836\n",
      "Epoch 601/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8610.4355 - val_loss: 14046.6006\n",
      "Epoch 602/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7611.6528 - val_loss: 25293.7266\n",
      "Epoch 603/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9796.3809 - val_loss: 15366.7451\n",
      "Epoch 604/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 8185.6055 - val_loss: 14545.1123\n",
      "Epoch 605/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9711.1279 - val_loss: 13786.1572\n",
      "Epoch 606/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10299.7119 - val_loss: 14292.1543\n",
      "Epoch 607/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10741.0566 - val_loss: 23547.9785\n",
      "Epoch 608/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11766.0059 - val_loss: 18165.0020\n",
      "Epoch 609/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10101.4404 - val_loss: 23236.8262\n",
      "Epoch 610/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9755.6846 - val_loss: 16446.8516\n",
      "Epoch 611/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10073.3154 - val_loss: 15426.8701\n",
      "Epoch 612/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11361.7109 - val_loss: 18328.6289\n",
      "Epoch 613/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10589.9688 - val_loss: 16444.4453\n",
      "Epoch 614/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13772.3125 - val_loss: 17876.2812\n",
      "Epoch 615/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13528.4971 - val_loss: 14107.9121\n",
      "Epoch 616/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11592.5205 - val_loss: 14155.4834\n",
      "Epoch 617/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10502.8340 - val_loss: 12736.5137\n",
      "Epoch 618/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10812.8066 - val_loss: 16303.4170\n",
      "Epoch 619/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11457.2949 - val_loss: 13182.5830\n",
      "Epoch 620/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11602.7520 - val_loss: 24299.1113\n",
      "Epoch 621/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12581.9873 - val_loss: 14345.6572\n",
      "Epoch 622/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13222.2529 - val_loss: 15466.5371\n",
      "Epoch 623/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12820.3662 - val_loss: 15961.8145\n",
      "Epoch 624/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12924.6504 - val_loss: 13676.7129\n",
      "Epoch 625/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11843.3223 - val_loss: 14206.4814\n",
      "Epoch 626/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11624.0186 - val_loss: 23737.1016\n",
      "Epoch 627/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15057.7393 - val_loss: 15432.5303\n",
      "Epoch 628/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11387.0762 - val_loss: 16040.7744\n",
      "Epoch 629/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10653.6816 - val_loss: 17054.9961\n",
      "Epoch 630/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11984.4736 - val_loss: 18252.7461\n",
      "Epoch 631/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11545.6514 - val_loss: 16166.7500\n",
      "Epoch 632/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11415.2432 - val_loss: 15689.2930\n",
      "Epoch 633/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11544.7129 - val_loss: 17002.3613\n",
      "Epoch 634/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10140.5352 - val_loss: 17436.3711\n",
      "Epoch 635/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10343.3164 - val_loss: 17337.3047\n",
      "Epoch 636/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11347.8770 - val_loss: 15775.5684\n",
      "Epoch 637/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11312.6045 - val_loss: 15335.1748\n",
      "Epoch 638/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9167.0205 - val_loss: 13842.2490\n",
      "Epoch 639/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10175.9795 - val_loss: 12882.6797\n",
      "Epoch 640/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8319.4326 - val_loss: 11337.3730\n",
      "Epoch 641/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10909.4014 - val_loss: 15601.5117\n",
      "Epoch 642/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13254.3750 - val_loss: 18792.8516\n",
      "Epoch 643/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10589.2012 - val_loss: 16617.6484\n",
      "Epoch 644/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11202.1094 - val_loss: 17376.5176\n",
      "Epoch 645/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10946.4219 - val_loss: 16810.1230\n",
      "Epoch 646/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11331.0898 - val_loss: 18163.1738\n",
      "Epoch 647/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11292.9336 - val_loss: 19528.0879\n",
      "Epoch 648/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10586.6338 - val_loss: 18230.2422\n",
      "Epoch 649/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11141.0576 - val_loss: 19067.4336\n",
      "Epoch 650/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10278.0859 - val_loss: 18819.2324\n",
      "Epoch 651/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10720.4717 - val_loss: 22869.2363\n",
      "Epoch 652/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17676.3984 - val_loss: 22767.1211\n",
      "Epoch 653/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17680.0215 - val_loss: 23553.3242\n",
      "Epoch 654/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19420.3418 - val_loss: 22473.4121\n",
      "Epoch 655/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17010.4023 - val_loss: 25888.1738\n",
      "Epoch 656/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18202.7422 - val_loss: 22579.9336\n",
      "Epoch 657/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15399.4521 - val_loss: 26829.5137\n",
      "Epoch 658/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16222.7393 - val_loss: 27050.8145\n",
      "Epoch 659/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12855.2295 - val_loss: 20696.6250\n",
      "Epoch 660/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10946.2549 - val_loss: 18169.5898\n",
      "Epoch 661/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10140.5811 - val_loss: 18877.2207\n",
      "Epoch 662/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9082.0635 - val_loss: 16852.4160\n",
      "Epoch 663/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8953.5352 - val_loss: 19285.5547\n",
      "Epoch 664/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10732.2881 - val_loss: 14475.1621\n",
      "Epoch 665/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9812.8809 - val_loss: 13907.5176\n",
      "Epoch 666/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9574.7246 - val_loss: 14419.0537\n",
      "Epoch 667/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8583.2393 - val_loss: 15860.5381\n",
      "Epoch 668/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9044.0469 - val_loss: 15103.0664\n",
      "Epoch 669/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8293.3369 - val_loss: 14212.7246\n",
      "Epoch 670/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8527.9111 - val_loss: 16696.7988\n",
      "Epoch 671/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9431.4805 - val_loss: 14060.1562\n",
      "Epoch 672/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8363.0508 - val_loss: 13490.6816\n",
      "Epoch 673/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8344.3525 - val_loss: 13963.6562\n",
      "Epoch 674/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9484.7402 - val_loss: 14059.6455\n",
      "Epoch 675/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8806.8018 - val_loss: 17894.8652\n",
      "Epoch 676/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9277.4229 - val_loss: 14722.6367\n",
      "Epoch 677/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8160.9536 - val_loss: 17649.8848\n",
      "Epoch 678/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10947.0459 - val_loss: 14192.7305\n",
      "Epoch 679/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 8110.8232 - val_loss: 25741.6152\n",
      "Epoch 680/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 12692.1543 - val_loss: 14843.9424\n",
      "Epoch 681/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9916.7324 - val_loss: 17644.4316\n",
      "Epoch 682/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9473.7861 - val_loss: 14426.0078\n",
      "Epoch 683/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9780.9922 - val_loss: 16847.2344\n",
      "Epoch 684/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9017.7188 - val_loss: 15243.2061\n",
      "Epoch 685/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8271.5684 - val_loss: 18887.5020\n",
      "Epoch 686/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10867.8086 - val_loss: 16448.7520\n",
      "Epoch 687/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9932.6309 - val_loss: 15009.1455\n",
      "Epoch 688/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8716.6514 - val_loss: 19055.2773\n",
      "Epoch 689/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10258.6504 - val_loss: 16065.1201\n",
      "Epoch 690/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9093.5889 - val_loss: 15561.5693\n",
      "Epoch 691/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8288.3955 - val_loss: 19113.2598\n",
      "Epoch 692/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11066.0850 - val_loss: 15915.9678\n",
      "Epoch 693/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9220.8486 - val_loss: 16382.8359\n",
      "Epoch 694/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9374.0176 - val_loss: 14303.5850\n",
      "Epoch 695/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8645.5391 - val_loss: 15688.8984\n",
      "Epoch 696/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13612.6680 - val_loss: 19721.1719\n",
      "Epoch 697/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14991.6289 - val_loss: 13150.8037\n",
      "Epoch 698/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13070.3135 - val_loss: 13585.6182\n",
      "Epoch 699/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11564.6650 - val_loss: 14359.7061\n",
      "Epoch 700/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12205.4199 - val_loss: 13816.7764\n",
      "Epoch 701/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11330.8203 - val_loss: 15002.2393\n",
      "Epoch 702/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11584.8369 - val_loss: 13680.9883\n",
      "Epoch 703/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11569.4248 - val_loss: 14615.4795\n",
      "Epoch 704/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10558.5645 - val_loss: 12692.3818\n",
      "Epoch 705/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9382.3867 - val_loss: 10922.4795\n",
      "Epoch 706/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9418.0625 - val_loss: 13768.4424\n",
      "Epoch 707/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 13707.3574 - val_loss: 13753.3770\n",
      "Epoch 708/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10735.8545 - val_loss: 12043.5693\n",
      "Epoch 709/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10356.3301 - val_loss: 12573.3311\n",
      "Epoch 710/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12244.3555 - val_loss: 13846.4316\n",
      "Epoch 711/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10711.3652 - val_loss: 19023.6250\n",
      "Epoch 712/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13896.3096 - val_loss: 17432.5996\n",
      "Epoch 713/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13677.7539 - val_loss: 17068.4102\n",
      "Epoch 714/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13182.5352 - val_loss: 16999.3691\n",
      "Epoch 715/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12588.9561 - val_loss: 17011.1914\n",
      "Epoch 716/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12613.5547 - val_loss: 16804.2168\n",
      "Epoch 717/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11997.7666 - val_loss: 15139.3428\n",
      "Epoch 718/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10657.8057 - val_loss: 23810.6758\n",
      "Epoch 719/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14525.0303 - val_loss: 17707.2090\n",
      "Epoch 720/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10116.9590 - val_loss: 12092.1924\n",
      "Epoch 721/10000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 9177.8711 - val_loss: 10628.7061\n",
      "Epoch 722/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10031.8555 - val_loss: 13213.1992\n",
      "Epoch 723/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9634.7949 - val_loss: 18630.8359\n",
      "Epoch 724/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10193.4814 - val_loss: 12910.1670\n",
      "Epoch 725/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8171.8203 - val_loss: 12848.1748\n",
      "Epoch 726/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9032.4043 - val_loss: 13007.2881\n",
      "Epoch 727/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8232.0137 - val_loss: 14410.9121\n",
      "Epoch 728/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8199.5889 - val_loss: 15947.7695\n",
      "Epoch 729/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8848.9697 - val_loss: 11213.3125\n",
      "Epoch 730/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8244.6621 - val_loss: 12918.9492\n",
      "Epoch 731/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8344.5635 - val_loss: 13642.3203\n",
      "Epoch 732/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8323.4297 - val_loss: 12813.7979\n",
      "Epoch 733/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8187.4585 - val_loss: 13600.2305\n",
      "Epoch 734/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8739.1738 - val_loss: 15526.4922\n",
      "Epoch 735/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9724.4541 - val_loss: 13392.2500\n",
      "Epoch 736/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9592.2168 - val_loss: 13294.3887\n",
      "Epoch 737/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9331.4229 - val_loss: 13410.0996\n",
      "Epoch 738/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8280.7305 - val_loss: 15431.7793\n",
      "Epoch 739/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8892.7744 - val_loss: 15673.2617\n",
      "Epoch 740/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9663.6338 - val_loss: 16109.4707\n",
      "Epoch 741/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10363.1436 - val_loss: 13769.1045\n",
      "Epoch 742/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8679.5400 - val_loss: 12371.3262\n",
      "Epoch 743/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9116.8359 - val_loss: 11114.2275\n",
      "Epoch 744/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11196.3330 - val_loss: 12321.3311\n",
      "Epoch 745/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10572.3809 - val_loss: 11974.7412\n",
      "Epoch 746/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12238.0605 - val_loss: 15496.7666\n",
      "Epoch 747/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13182.9473 - val_loss: 12380.5938\n",
      "Epoch 748/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10159.0361 - val_loss: 12886.6562\n",
      "Epoch 749/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11532.0879 - val_loss: 12020.9170\n",
      "Epoch 750/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9222.2100 - val_loss: 13315.8447\n",
      "Epoch 751/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11057.2812 - val_loss: 15800.9209\n",
      "Epoch 752/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11926.5283 - val_loss: 16352.7852\n",
      "Epoch 753/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11279.7451 - val_loss: 16026.8037\n",
      "Epoch 754/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 12803.1055 - val_loss: 15101.0947\n",
      "Epoch 755/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11923.8682 - val_loss: 24391.8203\n",
      "Epoch 756/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19902.8418 - val_loss: 18927.6348\n",
      "Epoch 757/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16517.5312 - val_loss: 13463.2666\n",
      "Epoch 758/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15197.0332 - val_loss: 17489.7090\n",
      "Epoch 759/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14300.4697 - val_loss: 14027.2383\n",
      "Epoch 760/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13926.9004 - val_loss: 15058.2891\n",
      "Epoch 761/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14372.6748 - val_loss: 13622.4873\n",
      "Epoch 762/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12971.5732 - val_loss: 13060.3037\n",
      "Epoch 763/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12340.6982 - val_loss: 14025.9463\n",
      "Epoch 764/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12929.3799 - val_loss: 19184.0410\n",
      "Epoch 765/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13295.1973 - val_loss: 14893.6953\n",
      "Epoch 766/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13009.6318 - val_loss: 16339.5117\n",
      "Epoch 767/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15825.5146 - val_loss: 21690.7207\n",
      "Epoch 768/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18194.6426 - val_loss: 17105.8828\n",
      "Epoch 769/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15123.6348 - val_loss: 18872.1289\n",
      "Epoch 770/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16273.2148 - val_loss: 17607.3203\n",
      "Epoch 771/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15992.8594 - val_loss: 16081.1992\n",
      "Epoch 772/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12286.0557 - val_loss: 18174.9102\n",
      "Epoch 773/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14371.8213 - val_loss: 18530.2734\n",
      "Epoch 774/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14874.8867 - val_loss: 20840.7656\n",
      "Epoch 775/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14912.4600 - val_loss: 12774.8770\n",
      "Epoch 776/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11625.6943 - val_loss: 14214.3691\n",
      "Epoch 777/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11016.2373 - val_loss: 13264.9707\n",
      "Epoch 778/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10095.9277 - val_loss: 13283.8506\n",
      "Epoch 779/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10609.8486 - val_loss: 12914.2451\n",
      "Epoch 780/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9430.1348 - val_loss: 13040.7168\n",
      "Epoch 781/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10403.9980 - val_loss: 14309.6895\n",
      "Epoch 782/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10654.4648 - val_loss: 12908.5732\n",
      "Epoch 783/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9645.4297 - val_loss: 19163.1270\n",
      "Epoch 784/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10198.5664 - val_loss: 12768.6484\n",
      "Epoch 785/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10145.6611 - val_loss: 12312.8232\n",
      "Epoch 786/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10564.7715 - val_loss: 19098.8418\n",
      "Epoch 787/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10894.6152 - val_loss: 15019.1182\n",
      "Epoch 788/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10224.9990 - val_loss: 12994.0430\n",
      "Epoch 789/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10355.5078 - val_loss: 14433.9082\n",
      "Epoch 790/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8749.8252 - val_loss: 14202.3047\n",
      "Epoch 791/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7351.6987 - val_loss: 14514.7725\n",
      "Epoch 792/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8887.2881 - val_loss: 16107.4912\n",
      "Epoch 793/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9067.0195 - val_loss: 19702.0508\n",
      "Epoch 794/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9590.6787 - val_loss: 13028.3525\n",
      "Epoch 795/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8426.4336 - val_loss: 15297.5615\n",
      "Epoch 796/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9135.3594 - val_loss: 16384.6895\n",
      "Epoch 797/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10154.7021 - val_loss: 14734.8574\n",
      "Epoch 798/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8103.5620 - val_loss: 14324.3838\n",
      "Epoch 799/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7870.9536 - val_loss: 16080.8994\n",
      "Epoch 800/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10255.9736 - val_loss: 14935.4082\n",
      "Epoch 801/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8128.5371 - val_loss: 14259.5576\n",
      "Epoch 802/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8511.7725 - val_loss: 16986.3730\n",
      "Epoch 803/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9309.3633 - val_loss: 14849.6162\n",
      "Epoch 804/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7969.5610 - val_loss: 21629.5254\n",
      "Epoch 805/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9343.2510 - val_loss: 14431.2236\n",
      "Epoch 806/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8367.5723 - val_loss: 14978.3994\n",
      "Epoch 807/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8859.5000 - val_loss: 16243.5693\n",
      "Epoch 808/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8102.9399 - val_loss: 15966.6924\n",
      "Epoch 809/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10043.7969 - val_loss: 15760.7852\n",
      "Epoch 810/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8113.3574 - val_loss: 15599.4014\n",
      "Epoch 811/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8481.1914 - val_loss: 14585.6016\n",
      "Epoch 812/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8622.2139 - val_loss: 16702.7480\n",
      "Epoch 813/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8556.4873 - val_loss: 15778.1016\n",
      "Epoch 814/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8017.0908 - val_loss: 16605.7031\n",
      "Epoch 815/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9091.3467 - val_loss: 24825.3398\n",
      "Epoch 816/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9969.7412 - val_loss: 14827.3789\n",
      "Epoch 817/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9698.0020 - val_loss: 14353.8418\n",
      "Epoch 818/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8622.8213 - val_loss: 14810.0332\n",
      "Epoch 819/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8974.6582 - val_loss: 15546.9414\n",
      "Epoch 820/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9346.2012 - val_loss: 19858.7539\n",
      "Epoch 821/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10663.8760 - val_loss: 31745.3008\n",
      "Epoch 822/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12638.8203 - val_loss: 17262.2520\n",
      "Epoch 823/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10461.5293 - val_loss: 15802.0791\n",
      "Epoch 824/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8068.5757 - val_loss: 15123.2520\n",
      "Epoch 825/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8646.5625 - val_loss: 16278.4023\n",
      "Epoch 826/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8942.7031 - val_loss: 18688.2832\n",
      "Epoch 827/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8725.0264 - val_loss: 16416.4141\n",
      "Epoch 828/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8798.4609 - val_loss: 16131.3887\n",
      "Epoch 829/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 8332.2812 - val_loss: 19165.5527\n",
      "Epoch 830/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8199.2109 - val_loss: 20008.5078\n",
      "Epoch 831/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9685.8545 - val_loss: 16016.5049\n",
      "Epoch 832/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9217.3096 - val_loss: 16476.0996\n",
      "Epoch 833/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8332.1064 - val_loss: 16524.0449\n",
      "Epoch 834/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8280.4824 - val_loss: 25606.2168\n",
      "Epoch 835/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11148.9277 - val_loss: 20821.9844\n",
      "Epoch 836/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11970.6436 - val_loss: 18718.6094\n",
      "Epoch 837/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8436.3350 - val_loss: 15167.2266\n",
      "Epoch 838/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8671.0723 - val_loss: 15552.7686\n",
      "Epoch 839/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9340.9199 - val_loss: 17097.9590\n",
      "Epoch 840/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9652.7500 - val_loss: 22036.9355\n",
      "Epoch 841/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12270.9395 - val_loss: 22396.1074\n",
      "Epoch 842/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10124.5000 - val_loss: 19094.1758\n",
      "Epoch 843/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10264.6748 - val_loss: 19483.8887\n",
      "Epoch 844/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10499.2998 - val_loss: 20604.2969\n",
      "Epoch 845/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9857.1729 - val_loss: 19369.1094\n",
      "Epoch 846/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9364.3047 - val_loss: 17464.0742\n",
      "Epoch 847/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9502.7656 - val_loss: 18947.0078\n",
      "Epoch 848/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9691.9404 - val_loss: 18749.9238\n",
      "Epoch 849/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9500.9463 - val_loss: 25280.0547\n",
      "Epoch 850/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11806.9189 - val_loss: 24736.9395\n",
      "Epoch 851/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13084.6338 - val_loss: 22706.3750\n",
      "Epoch 852/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13980.9844 - val_loss: 25947.1035\n",
      "Epoch 853/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12554.0752 - val_loss: 20156.3594\n",
      "Epoch 854/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13512.3037 - val_loss: 21829.5449\n",
      "Epoch 855/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12897.9678 - val_loss: 23317.2402\n",
      "Epoch 856/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12291.4863 - val_loss: 22599.0332\n",
      "Epoch 857/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13563.6729 - val_loss: 18052.5059\n",
      "Epoch 858/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12464.4971 - val_loss: 18136.4336\n",
      "Epoch 859/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12263.9854 - val_loss: 19611.0879\n",
      "Epoch 860/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12142.0020 - val_loss: 17453.1133\n",
      "Epoch 861/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12442.1797 - val_loss: 17997.5137\n",
      "Epoch 862/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12487.0967 - val_loss: 17486.5352\n",
      "Epoch 863/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11523.9697 - val_loss: 14703.4443\n",
      "Epoch 864/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9543.4102 - val_loss: 17613.9980\n",
      "Epoch 865/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9505.9346 - val_loss: 15378.2705\n",
      "Epoch 866/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9837.4551 - val_loss: 25516.0977\n",
      "Epoch 867/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11865.8496 - val_loss: 18251.2109\n",
      "Epoch 868/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8705.7803 - val_loss: 21166.2246\n",
      "Epoch 869/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8701.4053 - val_loss: 18488.2949\n",
      "Epoch 870/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8820.1113 - val_loss: 21570.9395\n",
      "Epoch 871/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10315.6133 - val_loss: 20059.4004\n",
      "Epoch 872/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9607.9062 - val_loss: 20359.1953\n",
      "Epoch 873/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8904.0977 - val_loss: 18131.9980\n",
      "Epoch 874/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9862.2852 - val_loss: 18872.5879\n",
      "Epoch 875/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8709.9922 - val_loss: 23277.1328\n",
      "Epoch 876/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9869.7461 - val_loss: 19256.6855\n",
      "Epoch 877/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9475.8740 - val_loss: 19456.7832\n",
      "Epoch 878/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8491.0410 - val_loss: 18737.8145\n",
      "Epoch 879/10000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 9681.9434 - val_loss: 17727.3730\n",
      "Epoch 880/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9300.8301 - val_loss: 18162.8770\n",
      "Epoch 881/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10609.5566 - val_loss: 25399.9395\n",
      "Epoch 882/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9321.5137 - val_loss: 18481.4395\n",
      "Epoch 883/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8257.7686 - val_loss: 19193.6465\n",
      "Epoch 884/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14224.6709 - val_loss: 30365.1523\n",
      "Epoch 885/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14795.6875 - val_loss: 18665.2012\n",
      "Epoch 886/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13934.5635 - val_loss: 20201.0410\n",
      "Epoch 887/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12101.1816 - val_loss: 17480.5938\n",
      "Epoch 888/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11741.7598 - val_loss: 17577.2793\n",
      "Epoch 889/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12572.6865 - val_loss: 18861.2344\n",
      "Epoch 890/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12213.7393 - val_loss: 16927.9902\n",
      "Epoch 891/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11731.5039 - val_loss: 15138.5537\n",
      "Epoch 892/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11301.3672 - val_loss: 14327.3428\n",
      "Epoch 893/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10677.6533 - val_loss: 15640.4121\n",
      "Epoch 894/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12021.8945 - val_loss: 14633.7666\n",
      "Epoch 895/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10602.1650 - val_loss: 14842.5576\n",
      "Epoch 896/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12000.0186 - val_loss: 19282.6074\n",
      "Epoch 897/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11897.6172 - val_loss: 14925.5020\n",
      "Epoch 898/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10232.7988 - val_loss: 18043.7207\n",
      "Epoch 899/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9885.9912 - val_loss: 15132.8867\n",
      "Epoch 900/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11397.4365 - val_loss: 18554.2637\n",
      "Epoch 901/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12192.2041 - val_loss: 19098.0938\n",
      "Epoch 902/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11382.5332 - val_loss: 22275.2617\n",
      "Epoch 903/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12014.6348 - val_loss: 21266.4648\n",
      "Epoch 904/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 11198.2646 - val_loss: 19812.6953\n",
      "Epoch 905/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11787.7861 - val_loss: 21729.6914\n",
      "Epoch 906/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11739.7021 - val_loss: 19553.0391\n",
      "Epoch 907/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11393.0176 - val_loss: 17178.8262\n",
      "Epoch 908/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9992.1973 - val_loss: 16786.7637\n",
      "Epoch 909/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10757.1113 - val_loss: 23793.9375\n",
      "Epoch 910/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10869.7998 - val_loss: 17515.2207\n",
      "Epoch 911/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9421.1465 - val_loss: 24925.5781\n",
      "Epoch 912/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11337.2588 - val_loss: 19042.0605\n",
      "Epoch 913/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11748.7529 - val_loss: 18615.3086\n",
      "Epoch 914/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11143.4648 - val_loss: 22064.2734\n",
      "Epoch 915/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13311.6172 - val_loss: 22020.3477\n",
      "Epoch 916/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13340.2725 - val_loss: 17348.0234\n",
      "Epoch 917/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10987.2490 - val_loss: 19374.5605\n",
      "Epoch 918/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11444.4199 - val_loss: 17961.5898\n",
      "Epoch 919/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10686.1357 - val_loss: 18201.0020\n",
      "Epoch 920/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10166.6055 - val_loss: 18197.4980\n",
      "Epoch 921/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10891.1514 - val_loss: 22689.4355\n",
      "Epoch 922/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11678.8906 - val_loss: 18989.2461\n",
      "Epoch 923/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10387.1250 - val_loss: 17969.1777\n",
      "Epoch 924/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10461.3564 - val_loss: 17593.4980\n",
      "Epoch 925/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10926.9502 - val_loss: 17897.1152\n",
      "Epoch 926/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11469.8633 - val_loss: 18232.1992\n",
      "Epoch 927/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10283.3418 - val_loss: 23012.1387\n",
      "Epoch 928/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13762.8672 - val_loss: 52726.1211\n",
      "Epoch 929/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19059.2031 - val_loss: 23613.2480\n",
      "Epoch 930/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14744.3926 - val_loss: 21276.6523\n",
      "Epoch 931/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15981.9277 - val_loss: 25821.0137\n",
      "Epoch 932/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14109.7656 - val_loss: 23207.3887\n",
      "Epoch 933/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13185.7979 - val_loss: 21150.3281\n",
      "Epoch 934/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14133.3516 - val_loss: 31524.7285\n",
      "Epoch 935/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18848.7090 - val_loss: 21346.1094\n",
      "Epoch 936/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13643.5273 - val_loss: 23043.7129\n",
      "Epoch 937/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12372.4961 - val_loss: 17724.1719\n",
      "Epoch 938/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9961.0498 - val_loss: 18402.0762\n",
      "Epoch 939/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10418.8984 - val_loss: 17246.9141\n",
      "Epoch 940/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9223.6006 - val_loss: 17268.4219\n",
      "Epoch 941/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9092.6660 - val_loss: 17334.9922\n",
      "Epoch 942/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9832.0986 - val_loss: 17863.5938\n",
      "Epoch 943/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10031.7188 - val_loss: 17503.1172\n",
      "Epoch 944/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12445.0615 - val_loss: 19550.4258\n",
      "Epoch 945/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10618.1504 - val_loss: 28116.9590\n",
      "Epoch 946/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12214.6689 - val_loss: 17039.4609\n",
      "Epoch 947/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10358.6982 - val_loss: 21515.9219\n",
      "Epoch 948/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10576.3477 - val_loss: 25748.5039\n",
      "Epoch 949/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13036.0605 - val_loss: 18978.7793\n",
      "Epoch 950/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9341.3447 - val_loss: 17841.7168\n",
      "Epoch 951/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9566.9316 - val_loss: 21861.5137\n",
      "Epoch 952/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11017.4375 - val_loss: 17844.6719\n",
      "Epoch 953/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9243.1787 - val_loss: 17783.7285\n",
      "Epoch 954/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10839.4541 - val_loss: 19625.0098\n",
      "Epoch 955/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10340.4668 - val_loss: 18440.1035\n",
      "Epoch 956/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9541.6973 - val_loss: 18200.9492\n",
      "Epoch 957/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9735.5947 - val_loss: 20092.6660\n",
      "Epoch 958/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9529.0381 - val_loss: 17819.9414\n",
      "Epoch 959/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9295.7471 - val_loss: 18122.5605\n",
      "Epoch 960/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9453.3301 - val_loss: 18327.1660\n",
      "Epoch 961/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9425.6963 - val_loss: 18830.1152\n",
      "Epoch 962/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9124.6016 - val_loss: 17467.3477\n",
      "Epoch 963/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9407.3740 - val_loss: 19628.1016\n",
      "Epoch 964/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10012.0068 - val_loss: 19344.7988\n",
      "Epoch 965/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9961.1396 - val_loss: 16923.1270\n",
      "Epoch 966/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9813.2100 - val_loss: 16647.2578\n",
      "Epoch 967/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9214.4854 - val_loss: 16274.3564\n",
      "Epoch 968/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9796.1758 - val_loss: 16331.3887\n",
      "Epoch 969/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11037.4082 - val_loss: 14445.1924\n",
      "Epoch 970/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11638.9355 - val_loss: 19101.2598\n",
      "Epoch 971/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12275.7588 - val_loss: 15476.6201\n",
      "Epoch 972/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11317.5264 - val_loss: 15617.3936\n",
      "Epoch 973/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9897.5352 - val_loss: 20363.9746\n",
      "Epoch 974/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10802.0059 - val_loss: 15026.8955\n",
      "Epoch 975/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10572.3213 - val_loss: 15588.2559\n",
      "Epoch 976/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9672.2773 - val_loss: 14981.0674\n",
      "Epoch 977/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8989.5020 - val_loss: 17624.9375\n",
      "Epoch 978/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10918.6797 - val_loss: 14555.1338\n",
      "Epoch 979/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 9522.5684 - val_loss: 24021.2676\n",
      "Epoch 980/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16702.5547 - val_loss: 18202.2793\n",
      "Epoch 981/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 19131.3828 - val_loss: 18324.2988\n",
      "Epoch 982/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 17215.7559 - val_loss: 22373.0332\n",
      "Epoch 983/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17265.0176 - val_loss: 28265.6621\n",
      "Epoch 984/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16906.3105 - val_loss: 25035.1758\n",
      "Epoch 985/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16785.3516 - val_loss: 19601.1973\n",
      "Epoch 986/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15925.2998 - val_loss: 26710.0000\n",
      "Epoch 987/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18056.4043 - val_loss: 21236.1406\n",
      "Epoch 988/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15895.4834 - val_loss: 20600.5137\n",
      "Epoch 989/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14955.9199 - val_loss: 21873.9902\n",
      "Epoch 990/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17207.3652 - val_loss: 19259.9043\n",
      "Epoch 991/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15398.6006 - val_loss: 20902.4023\n",
      "Epoch 992/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15411.2236 - val_loss: 22587.2871\n",
      "Epoch 993/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17996.1152 - val_loss: 29075.5918\n",
      "Epoch 994/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16836.3867 - val_loss: 20290.1875\n",
      "Epoch 995/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15886.3037 - val_loss: 26281.4043\n",
      "Epoch 996/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17489.5488 - val_loss: 25107.9395\n",
      "Epoch 997/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17467.9258 - val_loss: 21035.1660\n",
      "Epoch 998/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 15371.2725 - val_loss: 22178.6523\n",
      "Epoch 999/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13701.6631 - val_loss: 21292.2539\n",
      "Epoch 1000/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16661.7754 - val_loss: 21182.5879\n",
      "Epoch 1001/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17113.8438 - val_loss: 20951.4121\n",
      "Epoch 1002/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15699.4111 - val_loss: 16210.9697\n",
      "Epoch 1003/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12235.5801 - val_loss: 22110.8984\n",
      "Epoch 1004/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16139.4551 - val_loss: 24442.4297\n",
      "Epoch 1005/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16974.0371 - val_loss: 30040.9766\n",
      "Epoch 1006/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17056.4609 - val_loss: 20652.0781\n",
      "Epoch 1007/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16661.9141 - val_loss: 24875.2324\n",
      "Epoch 1008/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17591.0957 - val_loss: 21463.6387\n",
      "Epoch 1009/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16062.0518 - val_loss: 22734.6152\n",
      "Epoch 1010/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16209.5264 - val_loss: 21331.9043\n",
      "Epoch 1011/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 15922.7871 - val_loss: 19347.0957\n",
      "Epoch 1012/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15048.6660 - val_loss: 21305.3340\n",
      "Epoch 1013/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16059.0088 - val_loss: 20027.0742\n",
      "Epoch 1014/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17068.2832 - val_loss: 19154.3027\n",
      "Epoch 1015/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15273.0449 - val_loss: 25034.1641\n",
      "Epoch 1016/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15884.9199 - val_loss: 25125.2422\n",
      "Epoch 1017/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15517.2578 - val_loss: 19431.4922\n",
      "Epoch 1018/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15662.3633 - val_loss: 25688.9766\n",
      "Epoch 1019/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14894.9570 - val_loss: 20791.1348\n",
      "Epoch 1020/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15160.2822 - val_loss: 21346.0645\n",
      "Epoch 1021/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15002.8369 - val_loss: 20912.8418\n",
      "Epoch 1022/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14945.6670 - val_loss: 16110.1064\n",
      "Epoch 1023/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11715.2051 - val_loss: 16430.5781\n",
      "Epoch 1024/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11547.8320 - val_loss: 19422.4492\n",
      "Epoch 1025/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11141.5273 - val_loss: 23501.9121\n",
      "Epoch 1026/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11652.0381 - val_loss: 16949.8984\n",
      "Epoch 1027/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10112.0137 - val_loss: 17549.7051\n",
      "Epoch 1028/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12346.1133 - val_loss: 14832.6455\n",
      "Epoch 1029/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11259.3721 - val_loss: 15225.5947\n",
      "Epoch 1030/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12933.0186 - val_loss: 20909.0781\n",
      "Epoch 1031/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12593.4219 - val_loss: 17924.1777\n",
      "Epoch 1032/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11555.6699 - val_loss: 14398.5605\n",
      "Epoch 1033/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13270.0801 - val_loss: 18851.2891\n",
      "Epoch 1034/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14600.8105 - val_loss: 14571.8633\n",
      "Epoch 1035/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12192.2432 - val_loss: 18458.8477\n",
      "Epoch 1036/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 12817.7422 - val_loss: 16043.3057\n",
      "Epoch 1037/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13784.0430 - val_loss: 13260.6191\n",
      "Epoch 1038/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11676.6875 - val_loss: 13837.8564\n",
      "Epoch 1039/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10974.7891 - val_loss: 18066.3086\n",
      "Epoch 1040/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12259.4912 - val_loss: 17193.8789\n",
      "Epoch 1041/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12310.5059 - val_loss: 17974.9980\n",
      "Epoch 1042/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11890.8564 - val_loss: 15870.4727\n",
      "Epoch 1043/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11351.6855 - val_loss: 13553.7412\n",
      "Epoch 1044/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11596.7500 - val_loss: 12894.8252\n",
      "Epoch 1045/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11401.0625 - val_loss: 13473.5879\n",
      "Epoch 1046/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10594.0088 - val_loss: 13125.2695\n",
      "Epoch 1047/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11416.2070 - val_loss: 13704.4521\n",
      "Epoch 1048/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9811.1416 - val_loss: 14487.3008\n",
      "Epoch 1049/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9652.8320 - val_loss: 14012.6621\n",
      "Epoch 1050/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10642.4766 - val_loss: 13607.7266\n",
      "Epoch 1051/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9708.9453 - val_loss: 17479.6816\n",
      "Epoch 1052/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9806.1641 - val_loss: 16203.0859\n",
      "Epoch 1053/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13048.9609 - val_loss: 17788.2207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1054/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12134.3184 - val_loss: 16781.8809\n",
      "Epoch 1055/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11210.4629 - val_loss: 25817.9727\n",
      "Epoch 1056/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20036.9531 - val_loss: 12571.2686\n",
      "Epoch 1057/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14292.4727 - val_loss: 20806.3906\n",
      "Epoch 1058/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15846.0625 - val_loss: 14992.0352\n",
      "Epoch 1059/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12401.5352 - val_loss: 13197.5381\n",
      "Epoch 1060/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11879.6602 - val_loss: 16680.9102\n",
      "Epoch 1061/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11170.9365 - val_loss: 18579.8418\n",
      "Epoch 1062/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10954.2822 - val_loss: 14764.4883\n",
      "Epoch 1063/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10369.8916 - val_loss: 14457.4629\n",
      "Epoch 1064/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10808.9697 - val_loss: 18704.0078\n",
      "Epoch 1065/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10869.6816 - val_loss: 17298.9414\n",
      "Epoch 1066/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9605.7051 - val_loss: 14437.9609\n",
      "Epoch 1067/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11444.7969 - val_loss: 14533.7129\n",
      "Epoch 1068/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11828.7432 - val_loss: 15788.7754\n",
      "Epoch 1069/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12102.1895 - val_loss: 18401.2383\n",
      "Epoch 1070/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10218.7734 - val_loss: 17440.5645\n",
      "Epoch 1071/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9231.3369 - val_loss: 22897.4238\n",
      "Epoch 1072/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10721.6758 - val_loss: 16566.3008\n",
      "Epoch 1073/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11104.1387 - val_loss: 19650.5898\n",
      "Epoch 1074/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10258.5029 - val_loss: 15373.6553\n",
      "Epoch 1075/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9136.9551 - val_loss: 17402.4629\n",
      "Epoch 1076/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9999.3174 - val_loss: 16559.1758\n",
      "Epoch 1077/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9082.3076 - val_loss: 10633.9141\n",
      "Epoch 1078/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9714.9971 - val_loss: 10168.7363\n",
      "Epoch 1079/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9917.7402 - val_loss: 13241.6084\n",
      "Epoch 1080/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9452.7881 - val_loss: 15465.7500\n",
      "Epoch 1081/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9002.4941 - val_loss: 13807.3447\n",
      "Epoch 1082/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12006.1162 - val_loss: 13172.9355\n",
      "Epoch 1083/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9940.0625 - val_loss: 13322.4814\n",
      "Epoch 1084/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10702.5791 - val_loss: 14438.2871\n",
      "Epoch 1085/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11219.2578 - val_loss: 15083.7275\n",
      "Epoch 1086/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10700.5830 - val_loss: 13980.5420\n",
      "Epoch 1087/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10241.6836 - val_loss: 13053.3184\n",
      "Epoch 1088/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10896.8223 - val_loss: 14242.3682\n",
      "Epoch 1089/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12324.8848 - val_loss: 17324.4727\n",
      "Epoch 1090/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13962.3877 - val_loss: 20059.5605\n",
      "Epoch 1091/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14299.3516 - val_loss: 22151.2539\n",
      "Epoch 1092/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14899.6826 - val_loss: 20135.0781\n",
      "Epoch 1093/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13677.3691 - val_loss: 22975.8828\n",
      "Epoch 1094/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14731.8311 - val_loss: 18957.4082\n",
      "Epoch 1095/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13161.6963 - val_loss: 20924.5781\n",
      "Epoch 1096/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14482.4609 - val_loss: 19401.0938\n",
      "Epoch 1097/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14072.1133 - val_loss: 22081.7227\n",
      "Epoch 1098/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15616.2422 - val_loss: 20393.2656\n",
      "Epoch 1099/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13753.4297 - val_loss: 17882.0625\n",
      "Epoch 1100/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12686.6289 - val_loss: 17881.0000\n",
      "Epoch 1101/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14906.7861 - val_loss: 19006.7969\n",
      "Epoch 1102/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13713.2588 - val_loss: 17838.0352\n",
      "Epoch 1103/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13277.8877 - val_loss: 18530.9395\n",
      "Epoch 1104/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14284.7422 - val_loss: 19341.7148\n",
      "Epoch 1105/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16244.3965 - val_loss: 18622.5781\n",
      "Epoch 1106/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12329.9160 - val_loss: 19556.1777\n",
      "Epoch 1107/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14750.2246 - val_loss: 18669.0293\n",
      "Epoch 1108/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13202.4668 - val_loss: 22458.3516\n",
      "Epoch 1109/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14714.3916 - val_loss: 20494.5000\n",
      "Epoch 1110/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15786.6777 - val_loss: 24581.6094\n",
      "Epoch 1111/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15641.5869 - val_loss: 37106.9297\n",
      "Epoch 1112/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18204.0020 - val_loss: 17917.6895\n",
      "Epoch 1113/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13879.6846 - val_loss: 18900.2109\n",
      "Epoch 1114/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13705.4473 - val_loss: 25013.2402\n",
      "Epoch 1115/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15485.7119 - val_loss: 18232.5039\n",
      "Epoch 1116/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13295.8809 - val_loss: 17250.5469\n",
      "Epoch 1117/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13126.4365 - val_loss: 18093.5254\n",
      "Epoch 1118/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14013.6113 - val_loss: 22805.0020\n",
      "Epoch 1119/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15808.6387 - val_loss: 18048.1211\n",
      "Epoch 1120/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14248.6348 - val_loss: 18086.3105\n",
      "Epoch 1121/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14045.9766 - val_loss: 21158.3906\n",
      "Epoch 1122/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14065.7119 - val_loss: 20232.3105\n",
      "Epoch 1123/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13804.3301 - val_loss: 29188.1973\n",
      "Epoch 1124/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21388.1289 - val_loss: 22234.0391\n",
      "Epoch 1125/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15535.4033 - val_loss: 17920.4785\n",
      "Epoch 1126/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12897.8057 - val_loss: 18314.7754\n",
      "Epoch 1127/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13882.7949 - val_loss: 20097.3301\n",
      "Epoch 1128/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 13760.6357 - val_loss: 18688.9277\n",
      "Epoch 1129/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13794.1348 - val_loss: 24900.4355\n",
      "Epoch 1130/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14164.2148 - val_loss: 17993.8730\n",
      "Epoch 1131/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13907.1592 - val_loss: 17009.0293\n",
      "Epoch 1132/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13948.8018 - val_loss: 18217.1094\n",
      "Epoch 1133/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13978.6797 - val_loss: 18055.1992\n",
      "Epoch 1134/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13693.5664 - val_loss: 22667.9297\n",
      "Epoch 1135/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13093.2695 - val_loss: 21903.3926\n",
      "Epoch 1136/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13350.0566 - val_loss: 19916.0332\n",
      "Epoch 1137/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13914.2891 - val_loss: 21037.0371\n",
      "Epoch 1138/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13021.7031 - val_loss: 22157.7031\n",
      "Epoch 1139/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15798.7559 - val_loss: 16315.2988\n",
      "Epoch 1140/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15472.9629 - val_loss: 16888.7656\n",
      "Epoch 1141/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14238.4932 - val_loss: 26972.4492\n",
      "Epoch 1142/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14142.6611 - val_loss: 17445.9512\n",
      "Epoch 1143/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13662.7412 - val_loss: 17817.8262\n",
      "Epoch 1144/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13537.9443 - val_loss: 19297.1660\n",
      "Epoch 1145/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13187.2686 - val_loss: 17471.0293\n",
      "Epoch 1146/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12301.7695 - val_loss: 15784.0068\n",
      "Epoch 1147/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10138.7930 - val_loss: 15939.3379\n",
      "Epoch 1148/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10267.5049 - val_loss: 15773.1436\n",
      "Epoch 1149/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10911.9453 - val_loss: 16578.7676\n",
      "Epoch 1150/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9512.3623 - val_loss: 15137.6895\n",
      "Epoch 1151/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10092.0322 - val_loss: 17691.1289\n",
      "Epoch 1152/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10410.8838 - val_loss: 16899.2832\n",
      "Epoch 1153/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10788.0938 - val_loss: 15244.5996\n",
      "Epoch 1154/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13094.0439 - val_loss: 15315.6113\n",
      "Epoch 1155/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9807.8770 - val_loss: 23724.2500\n",
      "Epoch 1156/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13252.9092 - val_loss: 16029.8193\n",
      "Epoch 1157/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10857.3662 - val_loss: 18821.7344\n",
      "Epoch 1158/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12528.3975 - val_loss: 18229.1387\n",
      "Epoch 1159/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13169.7520 - val_loss: 16720.4961\n",
      "Epoch 1160/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11575.5762 - val_loss: 18432.3887\n",
      "Epoch 1161/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11036.8037 - val_loss: 18234.2090\n",
      "Epoch 1162/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12083.4951 - val_loss: 16314.8184\n",
      "Epoch 1163/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11938.4590 - val_loss: 19061.5566\n",
      "Epoch 1164/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12025.1074 - val_loss: 19330.8203\n",
      "Epoch 1165/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12932.0820 - val_loss: 18656.3730\n",
      "Epoch 1166/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11352.2051 - val_loss: 16883.5664\n",
      "Epoch 1167/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9731.1611 - val_loss: 16764.0137\n",
      "Epoch 1168/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10320.3555 - val_loss: 17314.0664\n",
      "Epoch 1169/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12028.6348 - val_loss: 18566.2285\n",
      "Epoch 1170/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11170.7764 - val_loss: 15805.3311\n",
      "Epoch 1171/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11184.8506 - val_loss: 27525.6738\n",
      "Epoch 1172/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15671.6836 - val_loss: 17151.1211\n",
      "Epoch 1173/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9864.9150 - val_loss: 17671.4941\n",
      "Epoch 1174/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9649.4268 - val_loss: 15815.8838\n",
      "Epoch 1175/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9720.9053 - val_loss: 16602.8145\n",
      "Epoch 1176/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9966.3613 - val_loss: 44496.7969\n",
      "Epoch 1177/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22593.6543 - val_loss: 8680.2871\n",
      "Epoch 1178/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 16087.5332 - val_loss: 12134.9746\n",
      "Epoch 1179/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16662.3281 - val_loss: 9662.5898\n",
      "Epoch 1180/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12896.0537 - val_loss: 10992.6885\n",
      "Epoch 1181/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11850.1367 - val_loss: 13736.5898\n",
      "Epoch 1182/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13000.6025 - val_loss: 14192.4482\n",
      "Epoch 1183/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17242.0273 - val_loss: 10943.9863\n",
      "Epoch 1184/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15407.5947 - val_loss: 12043.3887\n",
      "Epoch 1185/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 14512.7383 - val_loss: 16819.9785\n",
      "Epoch 1186/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 18161.1328 - val_loss: 8640.4258\n",
      "Epoch 1187/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13799.8232 - val_loss: 10023.9814\n",
      "Epoch 1188/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16678.2676 - val_loss: 8429.6748\n",
      "Epoch 1189/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11084.2314 - val_loss: 12788.7988\n",
      "Epoch 1190/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14258.6055 - val_loss: 17177.3418\n",
      "Epoch 1191/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18195.4316 - val_loss: 9965.0801\n",
      "Epoch 1192/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13426.4736 - val_loss: 11377.3682\n",
      "Epoch 1193/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11946.1299 - val_loss: 13148.6328\n",
      "Epoch 1194/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18779.1816 - val_loss: 20486.3516\n",
      "Epoch 1195/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15308.0342 - val_loss: 19643.4297\n",
      "Epoch 1196/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15049.9707 - val_loss: 19017.0703\n",
      "Epoch 1197/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14611.2090 - val_loss: 19129.2578\n",
      "Epoch 1198/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14617.9980 - val_loss: 19585.9668\n",
      "Epoch 1199/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13894.8555 - val_loss: 12720.8496\n",
      "Epoch 1200/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10661.0029 - val_loss: 12220.9951\n",
      "Epoch 1201/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10137.0195 - val_loss: 11213.7686\n",
      "Epoch 1202/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9542.4072 - val_loss: 14751.2549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1203/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11510.8457 - val_loss: 12518.4609\n",
      "Epoch 1204/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10312.0986 - val_loss: 18577.3574\n",
      "Epoch 1205/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12400.1348 - val_loss: 13449.8447\n",
      "Epoch 1206/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10289.7822 - val_loss: 14686.5674\n",
      "Epoch 1207/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12781.8389 - val_loss: 19668.9785\n",
      "Epoch 1208/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11433.6406 - val_loss: 19097.0547\n",
      "Epoch 1209/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10641.4346 - val_loss: 13327.2383\n",
      "Epoch 1210/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9732.1719 - val_loss: 13853.4482\n",
      "Epoch 1211/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10270.7510 - val_loss: 15553.7412\n",
      "Epoch 1212/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9717.3135 - val_loss: 19557.2227\n",
      "Epoch 1213/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11516.4072 - val_loss: 18966.6992\n",
      "Epoch 1214/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11470.0986 - val_loss: 17801.3203\n",
      "Epoch 1215/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12476.2393 - val_loss: 14637.1826\n",
      "Epoch 1216/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12090.0654 - val_loss: 13134.7568\n",
      "Epoch 1217/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10330.8555 - val_loss: 13068.2637\n",
      "Epoch 1218/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10571.1904 - val_loss: 14866.7510\n",
      "Epoch 1219/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10618.1865 - val_loss: 15568.7041\n",
      "Epoch 1220/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11595.7412 - val_loss: 13648.8633\n",
      "Epoch 1221/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10149.2578 - val_loss: 13893.3037\n",
      "Epoch 1222/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10504.1943 - val_loss: 15577.5391\n",
      "Epoch 1223/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9780.3262 - val_loss: 17455.2012\n",
      "Epoch 1224/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10266.6641 - val_loss: 17422.1484\n",
      "Epoch 1225/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11388.3438 - val_loss: 13848.8047\n",
      "Epoch 1226/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10692.5586 - val_loss: 15796.9932\n",
      "Epoch 1227/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9833.9629 - val_loss: 15592.7109\n",
      "Epoch 1228/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13292.8115 - val_loss: 15541.6250\n",
      "Epoch 1229/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12467.3291 - val_loss: 15074.2803\n",
      "Epoch 1230/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13790.2109 - val_loss: 16366.1133\n",
      "Epoch 1231/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14260.8633 - val_loss: 14581.7139\n",
      "Epoch 1232/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12685.0869 - val_loss: 13528.9248\n",
      "Epoch 1233/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9385.6729 - val_loss: 23519.5898\n",
      "Epoch 1234/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10479.7197 - val_loss: 17693.8887\n",
      "Epoch 1235/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11763.0459 - val_loss: 17221.9297\n",
      "Epoch 1236/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11209.7568 - val_loss: 12785.8184\n",
      "Epoch 1237/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10458.7998 - val_loss: 17084.5332\n",
      "Epoch 1238/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11478.2656 - val_loss: 13518.3037\n",
      "Epoch 1239/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9181.0576 - val_loss: 14521.5234\n",
      "Epoch 1240/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10056.9932 - val_loss: 20780.0215\n",
      "Epoch 1241/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9408.9297 - val_loss: 15134.5547\n",
      "Epoch 1242/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10460.3301 - val_loss: 17175.7793\n",
      "Epoch 1243/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8383.8184 - val_loss: 15355.4922\n",
      "Epoch 1244/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8746.8838 - val_loss: 16010.3975\n",
      "Epoch 1245/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8827.4658 - val_loss: 18122.4238\n",
      "Epoch 1246/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9559.7520 - val_loss: 25621.0410\n",
      "Epoch 1247/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11371.1514 - val_loss: 21400.3008\n",
      "Epoch 1248/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10628.2676 - val_loss: 15659.7881\n",
      "Epoch 1249/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10774.8496 - val_loss: 15756.0068\n",
      "Epoch 1250/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8042.2500 - val_loss: 15577.0264\n",
      "Epoch 1251/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12410.1631 - val_loss: 13987.5850\n",
      "Epoch 1252/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13877.0459 - val_loss: 16213.1016\n",
      "Epoch 1253/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12640.6260 - val_loss: 15949.9209\n",
      "Epoch 1254/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11815.2227 - val_loss: 15698.1914\n",
      "Epoch 1255/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12195.3340 - val_loss: 20193.5840\n",
      "Epoch 1256/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14075.5850 - val_loss: 19322.4902\n",
      "Epoch 1257/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14498.1094 - val_loss: 20071.5645\n",
      "Epoch 1258/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13821.3701 - val_loss: 20162.6172\n",
      "Epoch 1259/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13102.5801 - val_loss: 18612.7441\n",
      "Epoch 1260/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14297.9150 - val_loss: 24844.5742\n",
      "Epoch 1261/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15001.7529 - val_loss: 19165.7656\n",
      "Epoch 1262/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11280.4014 - val_loss: 19175.8477\n",
      "Epoch 1263/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13234.8389 - val_loss: 19904.7891\n",
      "Epoch 1264/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13433.5967 - val_loss: 21572.0137\n",
      "Epoch 1265/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13112.9092 - val_loss: 20232.5039\n",
      "Epoch 1266/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13316.4395 - val_loss: 19827.4844\n",
      "Epoch 1267/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11480.2520 - val_loss: 21030.4473\n",
      "Epoch 1268/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12857.5537 - val_loss: 20237.8223\n",
      "Epoch 1269/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11753.4053 - val_loss: 19529.9785\n",
      "Epoch 1270/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13333.6689 - val_loss: 21120.8574\n",
      "Epoch 1271/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15544.1875 - val_loss: 13694.5898\n",
      "Epoch 1272/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13523.7998 - val_loss: 17866.3418\n",
      "Epoch 1273/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9820.6709 - val_loss: 20632.3672\n",
      "Epoch 1274/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10024.7588 - val_loss: 21130.8203\n",
      "Epoch 1275/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9691.0947 - val_loss: 17443.9023\n",
      "Epoch 1276/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10215.9297 - val_loss: 19391.6992\n",
      "Epoch 1277/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 9578.7871 - val_loss: 21307.6250\n",
      "Epoch 1278/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10247.1143 - val_loss: 15402.6289\n",
      "Epoch 1279/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9034.4824 - val_loss: 16750.5625\n",
      "Epoch 1280/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9805.9912 - val_loss: 22217.7090\n",
      "Epoch 1281/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11496.0244 - val_loss: 16121.4443\n",
      "Epoch 1282/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9385.7666 - val_loss: 17488.1719\n",
      "Epoch 1283/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10849.1426 - val_loss: 22541.7090\n",
      "Epoch 1284/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11951.0039 - val_loss: 23854.6797\n",
      "Epoch 1285/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11737.0342 - val_loss: 18838.8574\n",
      "Epoch 1286/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10253.8926 - val_loss: 15819.6924\n",
      "Epoch 1287/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8828.4570 - val_loss: 17909.5547\n",
      "Epoch 1288/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9864.7373 - val_loss: 16816.6914\n",
      "Epoch 1289/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10499.0303 - val_loss: 15132.9443\n",
      "Epoch 1290/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9920.9883 - val_loss: 14784.1982\n",
      "Epoch 1291/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9360.4932 - val_loss: 18045.5352\n",
      "Epoch 1292/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11206.3535 - val_loss: 14733.5986\n",
      "Epoch 1293/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9870.1338 - val_loss: 15122.3438\n",
      "Epoch 1294/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9648.3418 - val_loss: 16459.4492\n",
      "Epoch 1295/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10779.6514 - val_loss: 14306.5977\n",
      "Epoch 1296/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9687.4951 - val_loss: 14326.3730\n",
      "Epoch 1297/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10067.2002 - val_loss: 19742.0879\n",
      "Epoch 1298/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12309.2930 - val_loss: 22885.0371\n",
      "Epoch 1299/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10881.5146 - val_loss: 15502.5078\n",
      "Epoch 1300/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9377.6387 - val_loss: 14327.8887\n",
      "Epoch 1301/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10188.4932 - val_loss: 16021.2510\n",
      "Epoch 1302/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10359.7422 - val_loss: 14524.7705\n",
      "Epoch 1303/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9936.7236 - val_loss: 14210.5996\n",
      "Epoch 1304/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9799.1924 - val_loss: 17860.6074\n",
      "Epoch 1305/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9592.1387 - val_loss: 13756.7793\n",
      "Epoch 1306/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9984.6504 - val_loss: 16060.5459\n",
      "Epoch 1307/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10290.8223 - val_loss: 16273.3662\n",
      "Epoch 1308/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10457.5908 - val_loss: 18662.6270\n",
      "Epoch 1309/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10578.8506 - val_loss: 19225.6172\n",
      "Epoch 1310/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11556.4209 - val_loss: 16020.4834\n",
      "Epoch 1311/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13393.7783 - val_loss: 17048.0039\n",
      "Epoch 1312/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11025.3008 - val_loss: 21129.2520\n",
      "Epoch 1313/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11699.6172 - val_loss: 15192.7451\n",
      "Epoch 1314/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9527.2754 - val_loss: 19363.8613\n",
      "Epoch 1315/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12425.1309 - val_loss: 16391.5449\n",
      "Epoch 1316/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10438.2070 - val_loss: 14275.9375\n",
      "Epoch 1317/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10227.5928 - val_loss: 14352.3770\n",
      "Epoch 1318/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10284.0107 - val_loss: 14873.4258\n",
      "Epoch 1319/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10100.8047 - val_loss: 14255.6504\n",
      "Epoch 1320/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10605.2637 - val_loss: 17671.6953\n",
      "Epoch 1321/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11591.2725 - val_loss: 15766.4248\n",
      "Epoch 1322/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10551.6611 - val_loss: 14390.2354\n",
      "Epoch 1323/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9641.4111 - val_loss: 14087.4268\n",
      "Epoch 1324/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10316.8779 - val_loss: 18160.8691\n",
      "Epoch 1325/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10538.2197 - val_loss: 13054.4297\n",
      "Epoch 1326/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9910.7471 - val_loss: 16282.2061\n",
      "Epoch 1327/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10739.8662 - val_loss: 13626.1328\n",
      "Epoch 1328/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9969.6162 - val_loss: 20389.8418\n",
      "Epoch 1329/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11621.2109 - val_loss: 15391.7871\n",
      "Epoch 1330/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10515.9883 - val_loss: 15221.9854\n",
      "Epoch 1331/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10211.1182 - val_loss: 21601.9473\n",
      "Epoch 1332/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11512.0645 - val_loss: 15138.7080\n",
      "Epoch 1333/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12463.0615 - val_loss: 12424.1523\n",
      "Epoch 1334/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16838.2383 - val_loss: 12388.2012\n",
      "Epoch 1335/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16819.0957 - val_loss: 16399.6602\n",
      "Epoch 1336/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16947.3789 - val_loss: 15373.2646\n",
      "Epoch 1337/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16572.0625 - val_loss: 14828.3457\n",
      "Epoch 1338/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16876.1426 - val_loss: 13187.3818\n",
      "Epoch 1339/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16597.5078 - val_loss: 12919.4775\n",
      "Epoch 1340/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18152.9141 - val_loss: 14716.6318\n",
      "Epoch 1341/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14866.1182 - val_loss: 13360.9766\n",
      "Epoch 1342/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12753.6152 - val_loss: 15177.8984\n",
      "Epoch 1343/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15063.5215 - val_loss: 13933.4580\n",
      "Epoch 1344/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11968.7197 - val_loss: 13070.5420\n",
      "Epoch 1345/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13999.6289 - val_loss: 12007.4961\n",
      "Epoch 1346/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12868.0508 - val_loss: 21031.2637\n",
      "Epoch 1347/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14386.4971 - val_loss: 10923.8057\n",
      "Epoch 1348/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10112.1621 - val_loss: 10239.1113\n",
      "Epoch 1349/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12476.7656 - val_loss: 10770.2803\n",
      "Epoch 1350/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10190.0508 - val_loss: 10776.4053\n",
      "Epoch 1351/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11814.5605 - val_loss: 11136.4727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1352/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10741.3945 - val_loss: 10579.0371\n",
      "Epoch 1353/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9928.6689 - val_loss: 14264.9229\n",
      "Epoch 1354/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10069.7236 - val_loss: 10721.9805\n",
      "Epoch 1355/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10853.6846 - val_loss: 12030.3428\n",
      "Epoch 1356/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11419.0518 - val_loss: 12370.6064\n",
      "Epoch 1357/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12870.6318 - val_loss: 12377.0088\n",
      "Epoch 1358/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9676.2832 - val_loss: 12006.1982\n",
      "Epoch 1359/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9336.8486 - val_loss: 17067.4043\n",
      "Epoch 1360/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11593.5088 - val_loss: 11712.2383\n",
      "Epoch 1361/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11313.9111 - val_loss: 10726.8174\n",
      "Epoch 1362/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11734.1787 - val_loss: 11240.1943\n",
      "Epoch 1363/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12591.0615 - val_loss: 17944.7832\n",
      "Epoch 1364/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13817.8213 - val_loss: 15156.2383\n",
      "Epoch 1365/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10375.8682 - val_loss: 12991.9912\n",
      "Epoch 1366/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10536.5449 - val_loss: 14438.5605\n",
      "Epoch 1367/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9076.9883 - val_loss: 14152.0459\n",
      "Epoch 1368/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9586.7227 - val_loss: 18544.3281\n",
      "Epoch 1369/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11052.7002 - val_loss: 13848.7998\n",
      "Epoch 1370/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9112.4346 - val_loss: 13968.1455\n",
      "Epoch 1371/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10552.9922 - val_loss: 12233.0703\n",
      "Epoch 1372/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8530.6182 - val_loss: 13091.0557\n",
      "Epoch 1373/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11317.5693 - val_loss: 21972.2773\n",
      "Epoch 1374/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10528.3369 - val_loss: 14627.7852\n",
      "Epoch 1375/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10261.9014 - val_loss: 14366.0791\n",
      "Epoch 1376/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10387.4990 - val_loss: 17963.3398\n",
      "Epoch 1377/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11232.3330 - val_loss: 15339.5830\n",
      "Epoch 1378/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9261.6758 - val_loss: 15244.0547\n",
      "Epoch 1379/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10304.5625 - val_loss: 12835.9238\n",
      "Epoch 1380/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10251.4492 - val_loss: 11748.8545\n",
      "Epoch 1381/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9738.0957 - val_loss: 18170.8379\n",
      "Epoch 1382/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10981.2852 - val_loss: 15542.9727\n",
      "Epoch 1383/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10031.6689 - val_loss: 15326.5674\n",
      "Epoch 1384/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10044.9561 - val_loss: 15514.8789\n",
      "Epoch 1385/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9839.3115 - val_loss: 19301.1602\n",
      "Epoch 1386/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11666.8389 - val_loss: 19014.4453\n",
      "Epoch 1387/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10912.9990 - val_loss: 14773.6416\n",
      "Epoch 1388/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10877.7695 - val_loss: 21272.8965\n",
      "Epoch 1389/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11632.9199 - val_loss: 15377.5205\n",
      "Epoch 1390/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10618.9922 - val_loss: 14631.6572\n",
      "Epoch 1391/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9743.8506 - val_loss: 15832.0850\n",
      "Epoch 1392/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9677.4131 - val_loss: 23341.3203\n",
      "Epoch 1393/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11581.7539 - val_loss: 13976.3691\n",
      "Epoch 1394/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10206.8301 - val_loss: 13203.8926\n",
      "Epoch 1395/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11226.2998 - val_loss: 16419.0703\n",
      "Epoch 1396/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10507.7461 - val_loss: 14744.6318\n",
      "Epoch 1397/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9360.5264 - val_loss: 14535.0586\n",
      "Epoch 1398/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10185.9160 - val_loss: 16930.6465\n",
      "Epoch 1399/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9990.2598 - val_loss: 16594.9238\n",
      "Epoch 1400/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9724.1699 - val_loss: 16901.3984\n",
      "Epoch 1401/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10514.9795 - val_loss: 15705.3057\n",
      "Epoch 1402/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8842.6016 - val_loss: 16001.5186\n",
      "Epoch 1403/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10468.6357 - val_loss: 16249.9756\n",
      "Epoch 1404/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9577.7412 - val_loss: 14390.0576\n",
      "Epoch 1405/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9795.4854 - val_loss: 18456.4277\n",
      "Epoch 1406/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9733.6162 - val_loss: 15604.0762\n",
      "Epoch 1407/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8426.0137 - val_loss: 18810.0762\n",
      "Epoch 1408/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10599.3066 - val_loss: 16364.9014\n",
      "Epoch 1409/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8930.5566 - val_loss: 17162.7285\n",
      "Epoch 1410/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10146.8057 - val_loss: 15382.9434\n",
      "Epoch 1411/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10541.4834 - val_loss: 16766.2559\n",
      "Epoch 1412/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9575.0137 - val_loss: 16945.4551\n",
      "Epoch 1413/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11687.4355 - val_loss: 20355.4727\n",
      "Epoch 1414/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10924.0635 - val_loss: 15094.7002\n",
      "Epoch 1415/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9127.4551 - val_loss: 17716.2637\n",
      "Epoch 1416/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10308.7432 - val_loss: 15781.3076\n",
      "Epoch 1417/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9057.7998 - val_loss: 21324.3105\n",
      "Epoch 1418/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10171.0293 - val_loss: 17367.3027\n",
      "Epoch 1419/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10693.4414 - val_loss: 13902.9795\n",
      "Epoch 1420/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8696.7764 - val_loss: 17104.5703\n",
      "Epoch 1421/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9730.0322 - val_loss: 18079.9707\n",
      "Epoch 1422/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9378.8760 - val_loss: 25408.2129\n",
      "Epoch 1423/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10337.4688 - val_loss: 14847.9004\n",
      "Epoch 1424/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10197.5264 - val_loss: 15036.7520\n",
      "Epoch 1425/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9784.4258 - val_loss: 16979.7852\n",
      "Epoch 1426/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 8947.9844 - val_loss: 19351.2441\n",
      "Epoch 1427/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10881.7607 - val_loss: 16875.1758\n",
      "Epoch 1428/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10603.1152 - val_loss: 19034.3535\n",
      "Epoch 1429/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11092.2891 - val_loss: 15942.5703\n",
      "Epoch 1430/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9812.4541 - val_loss: 15899.2920\n",
      "Epoch 1431/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8451.9346 - val_loss: 16592.8242\n",
      "Epoch 1432/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9672.4639 - val_loss: 21306.5020\n",
      "Epoch 1433/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9629.2119 - val_loss: 21216.8340\n",
      "Epoch 1434/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10745.7949 - val_loss: 15368.4883\n",
      "Epoch 1435/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9559.0107 - val_loss: 15651.3936\n",
      "Epoch 1436/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8966.6309 - val_loss: 17330.9961\n",
      "Epoch 1437/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10207.8467 - val_loss: 14987.6982\n",
      "Epoch 1438/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10415.4561 - val_loss: 18253.6367\n",
      "Epoch 1439/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10667.6338 - val_loss: 19047.2715\n",
      "Epoch 1440/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9611.9307 - val_loss: 15754.9072\n",
      "Epoch 1441/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8821.1396 - val_loss: 14194.4697\n",
      "Epoch 1442/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8896.4287 - val_loss: 15075.6182\n",
      "Epoch 1443/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9096.6865 - val_loss: 18620.6641\n",
      "Epoch 1444/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 25484.4824 - val_loss: 23663.5391\n",
      "Epoch 1445/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18984.9609 - val_loss: 21487.3457\n",
      "Epoch 1446/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18467.6582 - val_loss: 25758.7168\n",
      "Epoch 1447/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18489.5332 - val_loss: 20110.6250\n",
      "Epoch 1448/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17056.1191 - val_loss: 22681.4082\n",
      "Epoch 1449/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17655.7969 - val_loss: 22745.8906\n",
      "Epoch 1450/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15949.5830 - val_loss: 34601.9023\n",
      "Epoch 1451/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 19307.1074 - val_loss: 24415.9082\n",
      "Epoch 1452/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18285.2305 - val_loss: 20297.5469\n",
      "Epoch 1453/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18190.0332 - val_loss: 19759.4453\n",
      "Epoch 1454/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17462.4590 - val_loss: 19349.9219\n",
      "Epoch 1455/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15735.2275 - val_loss: 19004.8379\n",
      "Epoch 1456/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16342.7607 - val_loss: 18475.6016\n",
      "Epoch 1457/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17838.4473 - val_loss: 19620.4531\n",
      "Epoch 1458/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17712.8164 - val_loss: 20542.2988\n",
      "Epoch 1459/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18316.9473 - val_loss: 19381.5273\n",
      "Epoch 1460/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16661.5078 - val_loss: 21977.5781\n",
      "Epoch 1461/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 18030.4121 - val_loss: 30442.4121\n",
      "Epoch 1462/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 18790.3125 - val_loss: 22542.5000\n",
      "Epoch 1463/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17986.3574 - val_loss: 27751.5234\n",
      "Epoch 1464/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20996.2207 - val_loss: 18032.3320\n",
      "Epoch 1465/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 13580.5801 - val_loss: 19324.3691\n",
      "Epoch 1466/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 15057.4014 - val_loss: 18772.8613\n",
      "Epoch 1467/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15632.2334 - val_loss: 19870.0039\n",
      "Epoch 1468/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15698.6631 - val_loss: 17915.6113\n",
      "Epoch 1469/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15002.9346 - val_loss: 17218.6973\n",
      "Epoch 1470/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15333.2588 - val_loss: 22618.5508\n",
      "Epoch 1471/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15083.1787 - val_loss: 23437.0273\n",
      "Epoch 1472/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14053.4365 - val_loss: 19673.5254\n",
      "Epoch 1473/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13631.5527 - val_loss: 19730.6113\n",
      "Epoch 1474/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12819.8506 - val_loss: 19769.5996\n",
      "Epoch 1475/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13560.5996 - val_loss: 19908.8203\n",
      "Epoch 1476/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13429.1953 - val_loss: 22035.3535\n",
      "Epoch 1477/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11267.4150 - val_loss: 21191.9277\n",
      "Epoch 1478/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11975.0498 - val_loss: 18244.7891\n",
      "Epoch 1479/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11657.2715 - val_loss: 14946.0488\n",
      "Epoch 1480/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11177.3301 - val_loss: 14657.7803\n",
      "Epoch 1481/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10659.4326 - val_loss: 13814.6357\n",
      "Epoch 1482/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11814.1914 - val_loss: 16607.2715\n",
      "Epoch 1483/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11712.1396 - val_loss: 14183.3770\n",
      "Epoch 1484/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10203.8057 - val_loss: 16347.1504\n",
      "Epoch 1485/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8886.9873 - val_loss: 17510.2031\n",
      "Epoch 1486/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10617.0557 - val_loss: 12936.8105\n",
      "Epoch 1487/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8024.6519 - val_loss: 11778.7949\n",
      "Epoch 1488/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9602.2305 - val_loss: 13862.8057\n",
      "Epoch 1489/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9731.9248 - val_loss: 15550.8633\n",
      "Epoch 1490/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10064.8379 - val_loss: 18111.6504\n",
      "Epoch 1491/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9038.5039 - val_loss: 17119.4277\n",
      "Epoch 1492/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9604.3193 - val_loss: 14788.6357\n",
      "Epoch 1493/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8122.7056 - val_loss: 14864.5322\n",
      "Epoch 1494/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8575.7002 - val_loss: 10024.7422\n",
      "Epoch 1495/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9469.9580 - val_loss: 11673.6475\n",
      "Epoch 1496/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11640.2246 - val_loss: 13336.2607\n",
      "Epoch 1497/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10310.0566 - val_loss: 14626.0811\n",
      "Epoch 1498/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13424.6562 - val_loss: 14378.5771\n",
      "Epoch 1499/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10677.2529 - val_loss: 12696.8984\n",
      "Epoch 1500/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11171.4961 - val_loss: 13799.5146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1501/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11362.4746 - val_loss: 13152.2246\n",
      "Epoch 1502/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11268.9316 - val_loss: 18240.8359\n",
      "Epoch 1503/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10940.3838 - val_loss: 12423.0488\n",
      "Epoch 1504/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8940.8652 - val_loss: 12276.1260\n",
      "Epoch 1505/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11408.8105 - val_loss: 12475.9521\n",
      "Epoch 1506/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12761.3457 - val_loss: 16734.4004\n",
      "Epoch 1507/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12477.0088 - val_loss: 15936.0117\n",
      "Epoch 1508/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10878.7207 - val_loss: 12835.7607\n",
      "Epoch 1509/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11099.5996 - val_loss: 18283.7051\n",
      "Epoch 1510/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11360.3662 - val_loss: 15857.4561\n",
      "Epoch 1511/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11230.6064 - val_loss: 15674.0117\n",
      "Epoch 1512/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10378.5879 - val_loss: 15757.8818\n",
      "Epoch 1513/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9874.8750 - val_loss: 14236.7207\n",
      "Epoch 1514/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9847.4736 - val_loss: 16359.9639\n",
      "Epoch 1515/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11054.3115 - val_loss: 13705.6787\n",
      "Epoch 1516/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10102.9551 - val_loss: 15385.0576\n",
      "Epoch 1517/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9960.0029 - val_loss: 13918.6494\n",
      "Epoch 1518/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9576.2920 - val_loss: 13890.0605\n",
      "Epoch 1519/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10229.1523 - val_loss: 14131.6670\n",
      "Epoch 1520/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9565.3486 - val_loss: 15031.1357\n",
      "Epoch 1521/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9705.7842 - val_loss: 20250.2871\n",
      "Epoch 1522/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11665.6543 - val_loss: 14223.6367\n",
      "Epoch 1523/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9493.2764 - val_loss: 14267.3379\n",
      "Epoch 1524/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9590.2002 - val_loss: 15301.3164\n",
      "Epoch 1525/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10024.6475 - val_loss: 14828.3428\n",
      "Epoch 1526/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10049.6738 - val_loss: 15304.3008\n",
      "Epoch 1527/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11885.1553 - val_loss: 17354.2051\n",
      "Epoch 1528/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12642.7920 - val_loss: 15314.5791\n",
      "Epoch 1529/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9113.9824 - val_loss: 16107.9609\n",
      "Epoch 1530/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10753.7129 - val_loss: 15998.2305\n",
      "Epoch 1531/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10009.2168 - val_loss: 13679.5879\n",
      "Epoch 1532/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8839.8389 - val_loss: 12252.5166\n",
      "Epoch 1533/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9571.0391 - val_loss: 14587.0508\n",
      "Epoch 1534/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10060.0625 - val_loss: 11787.4141\n",
      "Epoch 1535/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9130.9932 - val_loss: 11309.9307\n",
      "Epoch 1536/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7915.4331 - val_loss: 17074.4785\n",
      "Epoch 1537/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10392.4609 - val_loss: 16917.3770\n",
      "Epoch 1538/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9867.5947 - val_loss: 12746.1738\n",
      "Epoch 1539/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9083.9492 - val_loss: 11585.7637\n",
      "Epoch 1540/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9821.3857 - val_loss: 14900.7979\n",
      "Epoch 1541/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10471.0596 - val_loss: 11145.7695\n",
      "Epoch 1542/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9004.7578 - val_loss: 11046.8574\n",
      "Epoch 1543/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8448.2441 - val_loss: 21809.1172\n",
      "Epoch 1544/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10624.1309 - val_loss: 12679.0635\n",
      "Epoch 1545/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9372.4043 - val_loss: 18394.2812\n",
      "Epoch 1546/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9598.9473 - val_loss: 12088.3242\n",
      "Epoch 1547/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8248.9619 - val_loss: 11889.6855\n",
      "Epoch 1548/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8460.6904 - val_loss: 13343.1523\n",
      "Epoch 1549/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8399.2490 - val_loss: 11953.0742\n",
      "Epoch 1550/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8651.5762 - val_loss: 11285.8867\n",
      "Epoch 1551/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8883.7656 - val_loss: 11457.9453\n",
      "Epoch 1552/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9027.1191 - val_loss: 12010.8682\n",
      "Epoch 1553/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14342.5000 - val_loss: 14220.1572\n",
      "Epoch 1554/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13891.3398 - val_loss: 16356.7959\n",
      "Epoch 1555/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15280.5879 - val_loss: 17212.1953\n",
      "Epoch 1556/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15567.2256 - val_loss: 14061.7256\n",
      "Epoch 1557/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14502.4307 - val_loss: 14922.6826\n",
      "Epoch 1558/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14900.4980 - val_loss: 15880.0068\n",
      "Epoch 1559/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14801.8135 - val_loss: 15501.7227\n",
      "Epoch 1560/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16375.8574 - val_loss: 14600.9180\n",
      "Epoch 1561/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13309.5615 - val_loss: 20735.6152\n",
      "Epoch 1562/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15817.4502 - val_loss: 14621.3584\n",
      "Epoch 1563/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15523.6338 - val_loss: 16411.9004\n",
      "Epoch 1564/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14851.4814 - val_loss: 14625.8730\n",
      "Epoch 1565/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13868.5322 - val_loss: 14980.4268\n",
      "Epoch 1566/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13111.9941 - val_loss: 15262.1230\n",
      "Epoch 1567/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13887.2373 - val_loss: 17217.7148\n",
      "Epoch 1568/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10748.4062 - val_loss: 13001.2568\n",
      "Epoch 1569/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10733.5049 - val_loss: 13399.1826\n",
      "Epoch 1570/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10077.7207 - val_loss: 12283.3945\n",
      "Epoch 1571/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9877.2734 - val_loss: 12469.8213\n",
      "Epoch 1572/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9866.8691 - val_loss: 13778.8389\n",
      "Epoch 1573/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12194.7666 - val_loss: 12812.1318\n",
      "Epoch 1574/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9720.4043 - val_loss: 15623.3887\n",
      "Epoch 1575/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10435.7910 - val_loss: 15068.5801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1576/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10166.7451 - val_loss: 12267.2012\n",
      "Epoch 1577/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11094.6299 - val_loss: 14915.2422\n",
      "Epoch 1578/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10586.3125 - val_loss: 12737.4980\n",
      "Epoch 1579/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9041.3223 - val_loss: 13178.2588\n",
      "Epoch 1580/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9279.8721 - val_loss: 13203.4697\n",
      "Epoch 1581/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9212.2305 - val_loss: 13140.7939\n",
      "Epoch 1582/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10120.8613 - val_loss: 13489.3135\n",
      "Epoch 1583/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8963.0586 - val_loss: 12976.3057\n",
      "Epoch 1584/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8206.4580 - val_loss: 14151.9600\n",
      "Epoch 1585/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12670.5938 - val_loss: 16439.2148\n",
      "Epoch 1586/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12497.7080 - val_loss: 18132.9102\n",
      "Epoch 1587/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11369.0508 - val_loss: 17756.8828\n",
      "Epoch 1588/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11832.1465 - val_loss: 15759.8799\n",
      "Epoch 1589/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11855.5156 - val_loss: 15644.9639\n",
      "Epoch 1590/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10093.8135 - val_loss: 20218.2207\n",
      "Epoch 1591/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13196.7578 - val_loss: 16653.3438\n",
      "Epoch 1592/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11207.3857 - val_loss: 22169.4746\n",
      "Epoch 1593/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12582.5801 - val_loss: 19698.0645\n",
      "Epoch 1594/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11005.5625 - val_loss: 15602.3887\n",
      "Epoch 1595/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10935.2148 - val_loss: 17740.4258\n",
      "Epoch 1596/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11407.0967 - val_loss: 15673.1074\n",
      "Epoch 1597/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11380.2744 - val_loss: 15782.1299\n",
      "Epoch 1598/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10454.5986 - val_loss: 16895.9590\n",
      "Epoch 1599/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11721.1064 - val_loss: 19233.6289\n",
      "Epoch 1600/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11124.7305 - val_loss: 11748.5293\n",
      "Epoch 1601/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15241.6523 - val_loss: 17783.5801\n",
      "Epoch 1602/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15546.9609 - val_loss: 29529.9395\n",
      "Epoch 1603/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 21476.1504 - val_loss: 21708.3984\n",
      "Epoch 1604/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17267.6816 - val_loss: 19618.8125\n",
      "Epoch 1605/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16745.3926 - val_loss: 24355.6035\n",
      "Epoch 1606/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 16936.5625 - val_loss: 26131.6758\n",
      "Epoch 1607/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14702.4814 - val_loss: 18305.1035\n",
      "Epoch 1608/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14604.4980 - val_loss: 18225.9102\n",
      "Epoch 1609/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12781.6680 - val_loss: 19689.1758\n",
      "Epoch 1610/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12303.8857 - val_loss: 17268.7656\n",
      "Epoch 1611/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13056.4014 - val_loss: 16572.3203\n",
      "Epoch 1612/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9377.9453 - val_loss: 17530.9648\n",
      "Epoch 1613/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13650.6738 - val_loss: 22515.2207\n",
      "Epoch 1614/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14403.0088 - val_loss: 19223.6094\n",
      "Epoch 1615/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17405.3516 - val_loss: 21646.9219\n",
      "Epoch 1616/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11575.9941 - val_loss: 19896.4824\n",
      "Epoch 1617/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9542.6777 - val_loss: 18785.7402\n",
      "Epoch 1618/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12163.3750 - val_loss: 25139.4590\n",
      "Epoch 1619/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12373.6611 - val_loss: 22467.2539\n",
      "Epoch 1620/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15706.2578 - val_loss: 22102.6777\n",
      "Epoch 1621/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16099.2021 - val_loss: 20417.3496\n",
      "Epoch 1622/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15270.4551 - val_loss: 21740.5234\n",
      "Epoch 1623/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16650.2246 - val_loss: 14167.0107\n",
      "Epoch 1624/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11180.2354 - val_loss: 19570.8594\n",
      "Epoch 1625/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11318.5303 - val_loss: 16487.9258\n",
      "Epoch 1626/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11218.4531 - val_loss: 15357.6895\n",
      "Epoch 1627/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10410.2598 - val_loss: 14689.3516\n",
      "Epoch 1628/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8498.6084 - val_loss: 14365.1514\n",
      "Epoch 1629/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9473.5596 - val_loss: 14343.1924\n",
      "Epoch 1630/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9421.1055 - val_loss: 21406.5977\n",
      "Epoch 1631/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11130.3389 - val_loss: 18394.2910\n",
      "Epoch 1632/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11789.8740 - val_loss: 13570.8105\n",
      "Epoch 1633/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11219.0381 - val_loss: 13170.2012\n",
      "Epoch 1634/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10076.3447 - val_loss: 13620.3701\n",
      "Epoch 1635/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10481.2920 - val_loss: 18888.4844\n",
      "Epoch 1636/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10920.0352 - val_loss: 14644.5742\n",
      "Epoch 1637/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11462.0518 - val_loss: 14769.1416\n",
      "Epoch 1638/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9625.5264 - val_loss: 13992.6123\n",
      "Epoch 1639/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9396.5000 - val_loss: 17339.8652\n",
      "Epoch 1640/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10690.5605 - val_loss: 15227.2061\n",
      "Epoch 1641/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10646.9805 - val_loss: 27117.5703\n",
      "Epoch 1642/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11721.0430 - val_loss: 14511.1963\n",
      "Epoch 1643/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9663.2832 - val_loss: 26380.8281\n",
      "Epoch 1644/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15684.1963 - val_loss: 16091.8174\n",
      "Epoch 1645/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10420.7305 - val_loss: 17273.5059\n",
      "Epoch 1646/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10635.9502 - val_loss: 19757.4746\n",
      "Epoch 1647/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10980.7539 - val_loss: 18109.2773\n",
      "Epoch 1648/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10468.3418 - val_loss: 16432.5312\n",
      "Epoch 1649/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10285.3906 - val_loss: 16763.7852\n",
      "Epoch 1650/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 10692.0312 - val_loss: 15919.3477\n",
      "Epoch 1651/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9656.2520 - val_loss: 16635.1426\n",
      "Epoch 1652/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9346.0449 - val_loss: 20474.4473\n",
      "Epoch 1653/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11344.0088 - val_loss: 22372.2129\n",
      "Epoch 1654/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9595.6465 - val_loss: 18851.5039\n",
      "Epoch 1655/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9979.5879 - val_loss: 15732.0742\n",
      "Epoch 1656/10000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10439.9902 - val_loss: 16013.1797\n",
      "Epoch 1657/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9290.0293 - val_loss: 25541.5957\n",
      "Epoch 1658/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13274.5430 - val_loss: 20826.9902\n",
      "Epoch 1659/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14392.8760 - val_loss: 15724.2861\n",
      "Epoch 1660/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10159.7871 - val_loss: 16593.8457\n",
      "Epoch 1661/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10110.6475 - val_loss: 16479.2207\n",
      "Epoch 1662/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10191.7363 - val_loss: 19903.6016\n",
      "Epoch 1663/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10817.5352 - val_loss: 15402.7988\n",
      "Epoch 1664/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9428.7930 - val_loss: 14356.9492\n",
      "Epoch 1665/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10073.3672 - val_loss: 14596.6318\n",
      "Epoch 1666/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8429.9678 - val_loss: 14133.0869\n",
      "Epoch 1667/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9672.2979 - val_loss: 15696.6484\n",
      "Epoch 1668/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9623.2461 - val_loss: 13298.7822\n",
      "Epoch 1669/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9349.7275 - val_loss: 13469.7666\n",
      "Epoch 1670/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9378.8301 - val_loss: 13099.7930\n",
      "Epoch 1671/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9035.3613 - val_loss: 20060.3867\n",
      "Epoch 1672/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12319.4619 - val_loss: 16210.5459\n",
      "Epoch 1673/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9194.8320 - val_loss: 24827.1602\n",
      "Epoch 1674/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12077.7832 - val_loss: 16850.3535\n",
      "Epoch 1675/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10270.0439 - val_loss: 16208.8232\n",
      "Epoch 1676/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9866.6162 - val_loss: 19310.6504\n",
      "Epoch 1677/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9944.0078 - val_loss: 19427.1367\n",
      "Epoch 1678/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11497.0967 - val_loss: 18674.4473\n",
      "Epoch 1679/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9868.0020 - val_loss: 19023.0801\n",
      "Epoch 1680/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12744.2979 - val_loss: 18614.3828\n",
      "Epoch 1681/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11085.9785 - val_loss: 18617.0293\n",
      "Epoch 1682/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10641.2178 - val_loss: 20318.1523\n",
      "Epoch 1683/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12228.6816 - val_loss: 21359.9004\n",
      "Epoch 1684/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 11371.0332 - val_loss: 18153.0664\n",
      "Epoch 1685/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9527.7607 - val_loss: 19118.2090\n",
      "Epoch 1686/10000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9438.0967 - val_loss: 18427.2539\n",
      "Epoch 1687/10000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10476.9961 - val_loss: 29375.8242\n",
      "Epoch 1688/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 16916.1191Restoring model weights from the end of the best epoch: 1188.\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 11403.3008 - val_loss: 18388.9160\n",
      "Epoch 1688: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>940.80011</td>\n",
       "      <td>940.80011</td>\n",
       "      <td>940.80011</td>\n",
       "      <td>975.919922</td>\n",
       "      <td>975.919922</td>\n",
       "      <td>940.80011</td>\n",
       "      <td>940.80011</td>\n",
       "      <td>940.80011</td>\n",
       "      <td>940.80011</td>\n",
       "      <td>940.80011</td>\n",
       "      <td>940.80011</td>\n",
       "      <td>837.918945</td>\n",
       "      <td>940.80011</td>\n",
       "      <td>940.80011</td>\n",
       "      <td>899.820679</td>\n",
       "      <td>899.81958</td>\n",
       "      <td>837.918945</td>\n",
       "      <td>942.229614</td>\n",
       "      <td>940.80011</td>\n",
       "      <td>975.919922</td>\n",
       "      <td>900.270996</td>\n",
       "      <td>899.820679</td>\n",
       "      <td>899.820679</td>\n",
       "      <td>899.820679</td>\n",
       "      <td>899.820679</td>\n",
       "      <td>899.820679</td>\n",
       "      <td>899.820679</td>\n",
       "      <td>894.860718</td>\n",
       "      <td>837.918945</td>\n",
       "      <td>837.918945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>910.653</td>\n",
       "      <td>937.696</td>\n",
       "      <td>871.611</td>\n",
       "      <td>795.853</td>\n",
       "      <td>804.767</td>\n",
       "      <td>712.733</td>\n",
       "      <td>763.665</td>\n",
       "      <td>727.397</td>\n",
       "      <td>855.245</td>\n",
       "      <td>855.042</td>\n",
       "      <td>648.867</td>\n",
       "      <td>1003.807</td>\n",
       "      <td>855.104</td>\n",
       "      <td>913.329</td>\n",
       "      <td>849.262</td>\n",
       "      <td>897.883</td>\n",
       "      <td>860.059</td>\n",
       "      <td>771.417</td>\n",
       "      <td>860.232</td>\n",
       "      <td>773.607</td>\n",
       "      <td>790.146</td>\n",
       "      <td>886.929</td>\n",
       "      <td>941.6</td>\n",
       "      <td>817.301</td>\n",
       "      <td>957.289</td>\n",
       "      <td>978.99</td>\n",
       "      <td>906.956</td>\n",
       "      <td>980.948</td>\n",
       "      <td>872.046</td>\n",
       "      <td>692.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>30.147095</td>\n",
       "      <td>3.104126</td>\n",
       "      <td>69.189087</td>\n",
       "      <td>180.066895</td>\n",
       "      <td>171.152893</td>\n",
       "      <td>228.067139</td>\n",
       "      <td>177.135132</td>\n",
       "      <td>213.403137</td>\n",
       "      <td>85.555115</td>\n",
       "      <td>85.758118</td>\n",
       "      <td>291.933105</td>\n",
       "      <td>165.888062</td>\n",
       "      <td>85.696106</td>\n",
       "      <td>27.47113</td>\n",
       "      <td>50.558655</td>\n",
       "      <td>1.936584</td>\n",
       "      <td>22.140076</td>\n",
       "      <td>170.812622</td>\n",
       "      <td>80.568115</td>\n",
       "      <td>202.312927</td>\n",
       "      <td>110.125</td>\n",
       "      <td>12.891663</td>\n",
       "      <td>41.779297</td>\n",
       "      <td>82.519653</td>\n",
       "      <td>57.468323</td>\n",
       "      <td>79.169312</td>\n",
       "      <td>7.135315</td>\n",
       "      <td>86.08728</td>\n",
       "      <td>34.127075</td>\n",
       "      <td>145.686951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1          2           3           4   \\\n",
       "Month         Month-1    Month-2    Month-3     Month-4     Month-5   \n",
       "Prediction  940.80011  940.80011  940.80011  975.919922  975.919922   \n",
       "Target        910.653    937.696    871.611     795.853     804.767   \n",
       "Error       30.147095   3.104126  69.189087  180.066895  171.152893   \n",
       "\n",
       "                    5           6           7          8          9   \\\n",
       "Month          Month-6     Month-7     Month-8    Month-9   Month-10   \n",
       "Prediction   940.80011   940.80011   940.80011  940.80011  940.80011   \n",
       "Target         712.733     763.665     727.397    855.245    855.042   \n",
       "Error       228.067139  177.135132  213.403137  85.555115  85.758118   \n",
       "\n",
       "                    10          11         12         13          14  \\\n",
       "Month         Month-11    Month-12   Month-13   Month-14    Month-15   \n",
       "Prediction   940.80011  837.918945  940.80011  940.80011  899.820679   \n",
       "Target         648.867    1003.807    855.104    913.329     849.262   \n",
       "Error       291.933105  165.888062  85.696106   27.47113   50.558655   \n",
       "\n",
       "                   15          16          17         18          19  \\\n",
       "Month        Month-16    Month-17    Month-18   Month-19    Month-20   \n",
       "Prediction  899.81958  837.918945  942.229614  940.80011  975.919922   \n",
       "Target        897.883     860.059     771.417    860.232     773.607   \n",
       "Error        1.936584   22.140076  170.812622  80.568115  202.312927   \n",
       "\n",
       "                    20          21          22          23          24  \\\n",
       "Month         Month-21    Month-22    Month-23    Month-24    Month-25   \n",
       "Prediction  900.270996  899.820679  899.820679  899.820679  899.820679   \n",
       "Target         790.146     886.929       941.6     817.301     957.289   \n",
       "Error          110.125   12.891663   41.779297   82.519653   57.468323   \n",
       "\n",
       "                    25          26          27          28          29  \n",
       "Month         Month-26    Month-27    Month-28    Month-29    Month-30  \n",
       "Prediction  899.820679  899.820679  894.860718  837.918945  837.918945  \n",
       "Target          978.99     906.956     980.948     872.046     692.232  \n",
       "Error        79.169312    7.135315    86.08728   34.127075  145.686951  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.99619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.12650836"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Ano-0: |Prediction[[11256.96]] - Target[9887.336000000001]| =  Error: [[1369.624]]; MAPE:[[0.13852306]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[10977.841]] - Target[10216.868999999999]| =  Error: [[760.9717]]; MAPE:[[0.07448188]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Ano-5: |Prediction[[5270.1606]] - Target[5388.461]| =  Error: [[118.30029]]; MAPE:[[0.02195437]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[1369.624]], dtype=float32),\n",
       " array([[760.9717]], dtype=float32),\n",
       " array([[118.30029]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "749.632"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.07831977"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
