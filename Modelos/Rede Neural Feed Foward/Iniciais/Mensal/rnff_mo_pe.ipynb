{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887ab6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "422e23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'Pernambuco - Consumo de Cimento (t)'\n",
    "split_index = 191 #Referente aos 230 anos de input  \n",
    "train_split = split_index + 1 -30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc652c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Pernambuco - value</th>\n",
       "      <th>Pernambuco - Produção de Cimento (t)</th>\n",
       "      <th>Pernambuco - PIB - Estadual</th>\n",
       "      <th>Pernambuco - PIB - Construção Civil</th>\n",
       "      <th>Pernambuco - PIB - Per Capita</th>\n",
       "      <th>Pernambuco - PIB - Preços de Mercado</th>\n",
       "      <th>Pernambuco - IDH</th>\n",
       "      <th>Pernambuco - Desemprego</th>\n",
       "      <th>Pernambuco - Consumo de Cimento (t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-1</td>\n",
       "      <td>0.724032</td>\n",
       "      <td>11.520143</td>\n",
       "      <td>1.639718</td>\n",
       "      <td>1.036534</td>\n",
       "      <td>1.772069e+08</td>\n",
       "      <td>7.330309e+06</td>\n",
       "      <td>0.969649</td>\n",
       "      <td>0.297418</td>\n",
       "      <td>34.266080</td>\n",
       "      <td>8.237381e+07</td>\n",
       "      <td>5.574893e+06</td>\n",
       "      <td>8.646979</td>\n",
       "      <td>7.571061e+07</td>\n",
       "      <td>0.688685</td>\n",
       "      <td>8.294029</td>\n",
       "      <td>99.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-2</td>\n",
       "      <td>0.690297</td>\n",
       "      <td>11.189862</td>\n",
       "      <td>1.378899</td>\n",
       "      <td>0.993449</td>\n",
       "      <td>1.773884e+08</td>\n",
       "      <td>7.335910e+06</td>\n",
       "      <td>0.950783</td>\n",
       "      <td>0.298912</td>\n",
       "      <td>34.126272</td>\n",
       "      <td>8.248102e+07</td>\n",
       "      <td>5.580364e+06</td>\n",
       "      <td>8.650960</td>\n",
       "      <td>7.575437e+07</td>\n",
       "      <td>0.689009</td>\n",
       "      <td>8.288006</td>\n",
       "      <td>86.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-3</td>\n",
       "      <td>0.669681</td>\n",
       "      <td>10.820792</td>\n",
       "      <td>1.924317</td>\n",
       "      <td>0.973020</td>\n",
       "      <td>1.775699e+08</td>\n",
       "      <td>7.341511e+06</td>\n",
       "      <td>0.938332</td>\n",
       "      <td>0.300346</td>\n",
       "      <td>34.414272</td>\n",
       "      <td>8.258823e+07</td>\n",
       "      <td>5.585835e+06</td>\n",
       "      <td>8.654941</td>\n",
       "      <td>7.579812e+07</td>\n",
       "      <td>0.689334</td>\n",
       "      <td>8.281983</td>\n",
       "      <td>83.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-4</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>10.417840</td>\n",
       "      <td>1.331174</td>\n",
       "      <td>0.940489</td>\n",
       "      <td>1.777514e+08</td>\n",
       "      <td>7.347112e+06</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>0.301729</td>\n",
       "      <td>34.576094</td>\n",
       "      <td>8.269544e+07</td>\n",
       "      <td>5.591305e+06</td>\n",
       "      <td>8.658922</td>\n",
       "      <td>7.584188e+07</td>\n",
       "      <td>0.689658</td>\n",
       "      <td>8.275960</td>\n",
       "      <td>82.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-5</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>9.959690</td>\n",
       "      <td>1.736072</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>1.779329e+08</td>\n",
       "      <td>7.352713e+06</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>0.302368</td>\n",
       "      <td>34.890197</td>\n",
       "      <td>8.280265e+07</td>\n",
       "      <td>5.596776e+06</td>\n",
       "      <td>8.662903</td>\n",
       "      <td>7.588563e+07</td>\n",
       "      <td>0.689983</td>\n",
       "      <td>8.269937</td>\n",
       "      <td>80.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2022-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.478890</td>\n",
       "      <td>26.779678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>2022-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.478683</td>\n",
       "      <td>26.996501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476012</td>\n",
       "      <td>26.919241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473486</td>\n",
       "      <td>27.026250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2022-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469719</td>\n",
       "      <td>27.052202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0       2003-1                                          0.724032   \n",
       "1       2003-2                                          0.690297   \n",
       "2       2003-3                                          0.669681   \n",
       "3       2003-4                                          0.660494   \n",
       "4       2003-5                                          0.648337   \n",
       "..         ...                                               ...   \n",
       "235     2022-8                                               NaN   \n",
       "236     2022-9                                               NaN   \n",
       "237    2022-10                                               NaN   \n",
       "238    2022-11                                               NaN   \n",
       "239    2022-12                                               NaN   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI     População  \\\n",
       "0                        11.520143        1.639718  1.036534  1.772069e+08   \n",
       "1                        11.189862        1.378899  0.993449  1.773884e+08   \n",
       "2                        10.820792        1.924317  0.973020  1.775699e+08   \n",
       "3                        10.417840        1.331174  0.940489  1.777514e+08   \n",
       "4                         9.959690        1.736072  0.917493  1.779329e+08   \n",
       "..                             ...             ...       ...           ...   \n",
       "235                            NaN             NaN       NaN           NaN   \n",
       "236                            NaN             NaN       NaN           NaN   \n",
       "237                            NaN             NaN       NaN           NaN   \n",
       "238                            NaN             NaN       NaN           NaN   \n",
       "239                            NaN             NaN       NaN           NaN   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Pernambuco - value  \\\n",
       "0                              7.330309e+06   0.969649            0.297418   \n",
       "1                              7.335910e+06   0.950783            0.298912   \n",
       "2                              7.341511e+06   0.938332            0.300346   \n",
       "3                              7.347112e+06   0.926401            0.301729   \n",
       "4                              7.352713e+06   0.951683            0.302368   \n",
       "..                                      ...        ...                 ...   \n",
       "235                                     NaN        NaN            0.478890   \n",
       "236                                     NaN        NaN            0.478683   \n",
       "237                                     NaN        NaN            0.476012   \n",
       "238                                     NaN        NaN            0.473486   \n",
       "239                                     NaN        NaN            0.469719   \n",
       "\n",
       "     Pernambuco - Produção de Cimento (t)  Pernambuco - PIB - Estadual  \\\n",
       "0                               34.266080                 8.237381e+07   \n",
       "1                               34.126272                 8.248102e+07   \n",
       "2                               34.414272                 8.258823e+07   \n",
       "3                               34.576094                 8.269544e+07   \n",
       "4                               34.890197                 8.280265e+07   \n",
       "..                                    ...                          ...   \n",
       "235                             26.779678                          NaN   \n",
       "236                             26.996501                          NaN   \n",
       "237                             26.919241                          NaN   \n",
       "238                             27.026250                          NaN   \n",
       "239                             27.052202                          NaN   \n",
       "\n",
       "     Pernambuco - PIB - Construção Civil  Pernambuco - PIB - Per Capita  \\\n",
       "0                           5.574893e+06                       8.646979   \n",
       "1                           5.580364e+06                       8.650960   \n",
       "2                           5.585835e+06                       8.654941   \n",
       "3                           5.591305e+06                       8.658922   \n",
       "4                           5.596776e+06                       8.662903   \n",
       "..                                   ...                            ...   \n",
       "235                                  NaN                            NaN   \n",
       "236                                  NaN                            NaN   \n",
       "237                                  NaN                            NaN   \n",
       "238                                  NaN                            NaN   \n",
       "239                                  NaN                            NaN   \n",
       "\n",
       "     Pernambuco - PIB - Preços de Mercado  Pernambuco - IDH  \\\n",
       "0                            7.571061e+07          0.688685   \n",
       "1                            7.575437e+07          0.689009   \n",
       "2                            7.579812e+07          0.689334   \n",
       "3                            7.584188e+07          0.689658   \n",
       "4                            7.588563e+07          0.689983   \n",
       "..                                    ...               ...   \n",
       "235                                   NaN               NaN   \n",
       "236                                   NaN               NaN   \n",
       "237                                   NaN               NaN   \n",
       "238                                   NaN               NaN   \n",
       "239                                   NaN               NaN   \n",
       "\n",
       "     Pernambuco - Desemprego  Pernambuco - Consumo de Cimento (t)  \n",
       "0                   8.294029                               99.743  \n",
       "1                   8.288006                               86.997  \n",
       "2                   8.281983                               83.033  \n",
       "3                   8.275960                               82.302  \n",
       "4                   8.269937                               80.217  \n",
       "..                       ...                                  ...  \n",
       "235                      NaN                              164.137  \n",
       "236                      NaN                              168.356  \n",
       "237                      NaN                              172.421  \n",
       "238                      NaN                              165.411  \n",
       "239                      NaN                              165.411  \n",
       "\n",
       "[240 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('2003_mo_model_input_PE.csv')\n",
    "data = data[[col for col in data.columns if col != subject] + [subject]] #Seta consumo (target) para a coluna final\n",
    "data =data.drop([' NFSP - Fluxo Mensal (Milhões de reais)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9a79f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Pernambuco - value</th>\n",
       "      <th>Pernambuco - Produção de Cimento (t)</th>\n",
       "      <th>Pernambuco - PIB - Estadual</th>\n",
       "      <th>Pernambuco - PIB - Construção Civil</th>\n",
       "      <th>Pernambuco - PIB - Per Capita</th>\n",
       "      <th>Pernambuco - PIB - Preços de Mercado</th>\n",
       "      <th>Pernambuco - IDH</th>\n",
       "      <th>Pernambuco - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.011454</td>\n",
       "      <td>-1.188910</td>\n",
       "      <td>-1.754154</td>\n",
       "      <td>-0.181030</td>\n",
       "      <td>-2.511326</td>\n",
       "      <td>-2.321118</td>\n",
       "      <td>-2.100972</td>\n",
       "      <td>-0.864836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-0.964614</td>\n",
       "      <td>-1.195377</td>\n",
       "      <td>-1.734705</td>\n",
       "      <td>-0.148206</td>\n",
       "      <td>-2.462275</td>\n",
       "      <td>-2.280399</td>\n",
       "      <td>-2.067858</td>\n",
       "      <td>-0.866889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-0.919667</td>\n",
       "      <td>-1.182056</td>\n",
       "      <td>-1.715257</td>\n",
       "      <td>-0.115382</td>\n",
       "      <td>-2.413223</td>\n",
       "      <td>-2.239680</td>\n",
       "      <td>-2.034743</td>\n",
       "      <td>-0.868942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-0.876288</td>\n",
       "      <td>-1.174571</td>\n",
       "      <td>-1.695809</td>\n",
       "      <td>-0.082559</td>\n",
       "      <td>-2.364172</td>\n",
       "      <td>-2.198961</td>\n",
       "      <td>-2.001628</td>\n",
       "      <td>-0.870995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-0.856283</td>\n",
       "      <td>-1.160042</td>\n",
       "      <td>-1.676361</td>\n",
       "      <td>-0.049735</td>\n",
       "      <td>-2.315120</td>\n",
       "      <td>-2.158242</td>\n",
       "      <td>-1.968514</td>\n",
       "      <td>-0.873048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.720800</td>\n",
       "      <td>-1.281757</td>\n",
       "      <td>1.016740</td>\n",
       "      <td>-1.416488</td>\n",
       "      <td>-0.070259</td>\n",
       "      <td>0.355961</td>\n",
       "      <td>1.324101</td>\n",
       "      <td>1.183158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.802101</td>\n",
       "      <td>-1.271596</td>\n",
       "      <td>1.004554</td>\n",
       "      <td>-1.402870</td>\n",
       "      <td>-0.093306</td>\n",
       "      <td>0.336941</td>\n",
       "      <td>1.314733</td>\n",
       "      <td>1.181904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.813469</td>\n",
       "      <td>-1.268136</td>\n",
       "      <td>0.992368</td>\n",
       "      <td>-1.389252</td>\n",
       "      <td>-0.116354</td>\n",
       "      <td>0.317922</td>\n",
       "      <td>1.305366</td>\n",
       "      <td>1.180650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.843043</td>\n",
       "      <td>-1.270527</td>\n",
       "      <td>0.980182</td>\n",
       "      <td>-1.375634</td>\n",
       "      <td>-0.139402</td>\n",
       "      <td>0.298902</td>\n",
       "      <td>1.295999</td>\n",
       "      <td>1.179397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.878446</td>\n",
       "      <td>-1.273952</td>\n",
       "      <td>0.967996</td>\n",
       "      <td>-1.362016</td>\n",
       "      <td>-0.162450</td>\n",
       "      <td>0.279883</td>\n",
       "      <td>1.286631</td>\n",
       "      <td>1.178143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Pernambuco - value  \\\n",
       "0                                 -2.389042   3.122582           -1.011454   \n",
       "1                                 -2.352139   2.970356           -0.964614   \n",
       "2                                 -2.315236   2.869895           -0.919667   \n",
       "3                                 -2.278333   2.773628           -0.876288   \n",
       "4                                 -2.241431   2.977624           -0.856283   \n",
       "..                                      ...        ...                 ...   \n",
       "187                                0.389193  -1.749976            1.720800   \n",
       "188                                0.370392  -1.593005            1.802101   \n",
       "189                                0.351592  -1.351489            1.813469   \n",
       "190                                0.332791  -1.198492            1.843043   \n",
       "191                                0.313991  -1.100894            1.878446   \n",
       "\n",
       "     Pernambuco - Produção de Cimento (t)  Pernambuco - PIB - Estadual  \\\n",
       "0                               -1.188910                    -1.754154   \n",
       "1                               -1.195377                    -1.734705   \n",
       "2                               -1.182056                    -1.715257   \n",
       "3                               -1.174571                    -1.695809   \n",
       "4                               -1.160042                    -1.676361   \n",
       "..                                    ...                          ...   \n",
       "187                             -1.281757                     1.016740   \n",
       "188                             -1.271596                     1.004554   \n",
       "189                             -1.268136                     0.992368   \n",
       "190                             -1.270527                     0.980182   \n",
       "191                             -1.273952                     0.967996   \n",
       "\n",
       "     Pernambuco - PIB - Construção Civil  Pernambuco - PIB - Per Capita  \\\n",
       "0                              -0.181030                      -2.511326   \n",
       "1                              -0.148206                      -2.462275   \n",
       "2                              -0.115382                      -2.413223   \n",
       "3                              -0.082559                      -2.364172   \n",
       "4                              -0.049735                      -2.315120   \n",
       "..                                   ...                            ...   \n",
       "187                            -1.416488                      -0.070259   \n",
       "188                            -1.402870                      -0.093306   \n",
       "189                            -1.389252                      -0.116354   \n",
       "190                            -1.375634                      -0.139402   \n",
       "191                            -1.362016                      -0.162450   \n",
       "\n",
       "     Pernambuco - PIB - Preços de Mercado  Pernambuco - IDH  \\\n",
       "0                               -2.321118         -2.100972   \n",
       "1                               -2.280399         -2.067858   \n",
       "2                               -2.239680         -2.034743   \n",
       "3                               -2.198961         -2.001628   \n",
       "4                               -2.158242         -1.968514   \n",
       "..                                    ...               ...   \n",
       "187                              0.355961          1.324101   \n",
       "188                              0.336941          1.314733   \n",
       "189                              0.317922          1.305366   \n",
       "190                              0.298902          1.295999   \n",
       "191                              0.279883          1.286631   \n",
       "\n",
       "     Pernambuco - Desemprego  \n",
       "0                  -0.864836  \n",
       "1                  -0.866889  \n",
       "2                  -0.868942  \n",
       "3                  -0.870995  \n",
       "4                  -0.873048  \n",
       "..                       ...  \n",
       "187                 1.183158  \n",
       "188                 1.181904  \n",
       "189                 1.180650  \n",
       "190                 1.179397  \n",
       "191                 1.178143  \n",
       "\n",
       "[192 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = data.iloc[:split_index + 1,1:-1]\n",
    "mean = np.mean(input_data, axis=0)\n",
    "stddev =  np.std(input_data, axis=0)\n",
    "input_data = ((input_data - mean) /stddev)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb83d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      76.341\n",
       "1      65.040\n",
       "2      88.306\n",
       "3      74.323\n",
       "4      78.114\n",
       "        ...  \n",
       "235       NaN\n",
       "236       NaN\n",
       "237       NaN\n",
       "238       NaN\n",
       "239       NaN\n",
       "Name: Pernambuco - Consumo de Cimento (t), Length: 240, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift para prever futuro e não presente\n",
    "target_data = data[subject].shift(-12)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bdb2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Pernambuco - value</th>\n",
       "      <th>Pernambuco - Produção de Cimento (t)</th>\n",
       "      <th>Pernambuco - PIB - Estadual</th>\n",
       "      <th>Pernambuco - PIB - Construção Civil</th>\n",
       "      <th>Pernambuco - PIB - Per Capita</th>\n",
       "      <th>Pernambuco - PIB - Preços de Mercado</th>\n",
       "      <th>Pernambuco - IDH</th>\n",
       "      <th>Pernambuco - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.723741</td>\n",
       "      <td>4.398348</td>\n",
       "      <td>2.052494</td>\n",
       "      <td>3.890153</td>\n",
       "      <td>-2.042341</td>\n",
       "      <td>-2.389042</td>\n",
       "      <td>3.122582</td>\n",
       "      <td>-1.011454</td>\n",
       "      <td>-1.188910</td>\n",
       "      <td>-1.754154</td>\n",
       "      <td>-0.181030</td>\n",
       "      <td>-2.511326</td>\n",
       "      <td>-2.321118</td>\n",
       "      <td>-2.100972</td>\n",
       "      <td>-0.864836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.350880</td>\n",
       "      <td>4.222509</td>\n",
       "      <td>1.242280</td>\n",
       "      <td>3.551840</td>\n",
       "      <td>-2.014760</td>\n",
       "      <td>-2.352139</td>\n",
       "      <td>2.970356</td>\n",
       "      <td>-0.964614</td>\n",
       "      <td>-1.195377</td>\n",
       "      <td>-1.734705</td>\n",
       "      <td>-0.148206</td>\n",
       "      <td>-2.462275</td>\n",
       "      <td>-2.280399</td>\n",
       "      <td>-2.067858</td>\n",
       "      <td>-0.866889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.123016</td>\n",
       "      <td>4.026019</td>\n",
       "      <td>2.936580</td>\n",
       "      <td>3.391423</td>\n",
       "      <td>-1.987179</td>\n",
       "      <td>-2.315236</td>\n",
       "      <td>2.869895</td>\n",
       "      <td>-0.919667</td>\n",
       "      <td>-1.182056</td>\n",
       "      <td>-1.715257</td>\n",
       "      <td>-0.115382</td>\n",
       "      <td>-2.413223</td>\n",
       "      <td>-2.239680</td>\n",
       "      <td>-2.034743</td>\n",
       "      <td>-0.868942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.021477</td>\n",
       "      <td>3.811492</td>\n",
       "      <td>1.094024</td>\n",
       "      <td>3.135979</td>\n",
       "      <td>-1.959598</td>\n",
       "      <td>-2.278333</td>\n",
       "      <td>2.773628</td>\n",
       "      <td>-0.876288</td>\n",
       "      <td>-1.174571</td>\n",
       "      <td>-1.695809</td>\n",
       "      <td>-0.082559</td>\n",
       "      <td>-2.364172</td>\n",
       "      <td>-2.198961</td>\n",
       "      <td>-2.001628</td>\n",
       "      <td>-0.870995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.887113</td>\n",
       "      <td>3.567576</td>\n",
       "      <td>2.351810</td>\n",
       "      <td>2.955412</td>\n",
       "      <td>-1.932017</td>\n",
       "      <td>-2.241431</td>\n",
       "      <td>2.977624</td>\n",
       "      <td>-0.856283</td>\n",
       "      <td>-1.160042</td>\n",
       "      <td>-1.676361</td>\n",
       "      <td>-0.049735</td>\n",
       "      <td>-2.315120</td>\n",
       "      <td>-2.158242</td>\n",
       "      <td>-1.968514</td>\n",
       "      <td>-0.873048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.214006</td>\n",
       "      <td>-0.607704</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-1.233012</td>\n",
       "      <td>1.031384</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>-0.883659</td>\n",
       "      <td>0.354413</td>\n",
       "      <td>-0.165538</td>\n",
       "      <td>1.170965</td>\n",
       "      <td>-1.488331</td>\n",
       "      <td>0.445555</td>\n",
       "      <td>0.786479</td>\n",
       "      <td>1.391411</td>\n",
       "      <td>1.357017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-0.434717</td>\n",
       "      <td>-0.620523</td>\n",
       "      <td>0.222389</td>\n",
       "      <td>-1.299304</td>\n",
       "      <td>1.042716</td>\n",
       "      <td>0.808136</td>\n",
       "      <td>-0.950771</td>\n",
       "      <td>0.374652</td>\n",
       "      <td>-0.236996</td>\n",
       "      <td>1.172520</td>\n",
       "      <td>-1.494202</td>\n",
       "      <td>0.438851</td>\n",
       "      <td>0.781348</td>\n",
       "      <td>1.390568</td>\n",
       "      <td>1.349817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.524091</td>\n",
       "      <td>-0.631530</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>-1.248662</td>\n",
       "      <td>1.054049</td>\n",
       "      <td>0.796969</td>\n",
       "      <td>-1.028465</td>\n",
       "      <td>0.400582</td>\n",
       "      <td>-0.309267</td>\n",
       "      <td>1.174075</td>\n",
       "      <td>-1.500073</td>\n",
       "      <td>0.432147</td>\n",
       "      <td>0.776217</td>\n",
       "      <td>1.389726</td>\n",
       "      <td>1.342617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.614500</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>0.385687</td>\n",
       "      <td>-1.068274</td>\n",
       "      <td>1.065381</td>\n",
       "      <td>0.785801</td>\n",
       "      <td>-1.103668</td>\n",
       "      <td>0.422300</td>\n",
       "      <td>-0.382346</td>\n",
       "      <td>1.175630</td>\n",
       "      <td>-1.505943</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>0.771086</td>\n",
       "      <td>1.388883</td>\n",
       "      <td>1.335417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.552198</td>\n",
       "      <td>-0.649685</td>\n",
       "      <td>0.712055</td>\n",
       "      <td>-1.035336</td>\n",
       "      <td>1.076713</td>\n",
       "      <td>0.774634</td>\n",
       "      <td>-0.978419</td>\n",
       "      <td>0.461503</td>\n",
       "      <td>-0.447486</td>\n",
       "      <td>1.177184</td>\n",
       "      <td>-1.511814</td>\n",
       "      <td>0.418738</td>\n",
       "      <td>0.765955</td>\n",
       "      <td>1.388041</td>\n",
       "      <td>1.328216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "0                                            2.723741   \n",
       "1                                            2.350880   \n",
       "2                                            2.123016   \n",
       "3                                            2.021477   \n",
       "4                                            1.887113   \n",
       "..                                                ...   \n",
       "157                                         -0.214006   \n",
       "158                                         -0.434717   \n",
       "159                                         -0.524091   \n",
       "160                                         -0.614500   \n",
       "161                                         -0.552198   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "0                         4.398348        2.052494  3.890153  -2.042341   \n",
       "1                         4.222509        1.242280  3.551840  -2.014760   \n",
       "2                         4.026019        2.936580  3.391423  -1.987179   \n",
       "3                         3.811492        1.094024  3.135979  -1.959598   \n",
       "4                         3.567576        2.351810  2.955412  -1.932017   \n",
       "..                             ...             ...       ...        ...   \n",
       "157                      -0.607704        0.059280 -1.233012   1.031384   \n",
       "158                      -0.620523        0.222389 -1.299304   1.042716   \n",
       "159                      -0.631530        0.191929 -1.248662   1.054049   \n",
       "160                      -0.640320        0.385687 -1.068274   1.065381   \n",
       "161                      -0.649685        0.712055 -1.035336   1.076713   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Pernambuco - value  \\\n",
       "0                                 -2.389042   3.122582           -1.011454   \n",
       "1                                 -2.352139   2.970356           -0.964614   \n",
       "2                                 -2.315236   2.869895           -0.919667   \n",
       "3                                 -2.278333   2.773628           -0.876288   \n",
       "4                                 -2.241431   2.977624           -0.856283   \n",
       "..                                      ...        ...                 ...   \n",
       "157                                0.819304  -0.883659            0.354413   \n",
       "158                                0.808136  -0.950771            0.374652   \n",
       "159                                0.796969  -1.028465            0.400582   \n",
       "160                                0.785801  -1.103668            0.422300   \n",
       "161                                0.774634  -0.978419            0.461503   \n",
       "\n",
       "     Pernambuco - Produção de Cimento (t)  Pernambuco - PIB - Estadual  \\\n",
       "0                               -1.188910                    -1.754154   \n",
       "1                               -1.195377                    -1.734705   \n",
       "2                               -1.182056                    -1.715257   \n",
       "3                               -1.174571                    -1.695809   \n",
       "4                               -1.160042                    -1.676361   \n",
       "..                                    ...                          ...   \n",
       "157                             -0.165538                     1.170965   \n",
       "158                             -0.236996                     1.172520   \n",
       "159                             -0.309267                     1.174075   \n",
       "160                             -0.382346                     1.175630   \n",
       "161                             -0.447486                     1.177184   \n",
       "\n",
       "     Pernambuco - PIB - Construção Civil  Pernambuco - PIB - Per Capita  \\\n",
       "0                              -0.181030                      -2.511326   \n",
       "1                              -0.148206                      -2.462275   \n",
       "2                              -0.115382                      -2.413223   \n",
       "3                              -0.082559                      -2.364172   \n",
       "4                              -0.049735                      -2.315120   \n",
       "..                                   ...                            ...   \n",
       "157                            -1.488331                       0.445555   \n",
       "158                            -1.494202                       0.438851   \n",
       "159                            -1.500073                       0.432147   \n",
       "160                            -1.505943                       0.425442   \n",
       "161                            -1.511814                       0.418738   \n",
       "\n",
       "     Pernambuco - PIB - Preços de Mercado  Pernambuco - IDH  \\\n",
       "0                               -2.321118         -2.100972   \n",
       "1                               -2.280399         -2.067858   \n",
       "2                               -2.239680         -2.034743   \n",
       "3                               -2.198961         -2.001628   \n",
       "4                               -2.158242         -1.968514   \n",
       "..                                    ...               ...   \n",
       "157                              0.786479          1.391411   \n",
       "158                              0.781348          1.390568   \n",
       "159                              0.776217          1.389726   \n",
       "160                              0.771086          1.388883   \n",
       "161                              0.765955          1.388041   \n",
       "\n",
       "     Pernambuco - Desemprego  \n",
       "0                  -0.864836  \n",
       "1                  -0.866889  \n",
       "2                  -0.868942  \n",
       "3                  -0.870995  \n",
       "4                  -0.873048  \n",
       "..                       ...  \n",
       "157                 1.357017  \n",
       "158                 1.349817  \n",
       "159                 1.342617  \n",
       "160                 1.335417  \n",
       "161                 1.328216  \n",
       "\n",
       "[162 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input para treinamento\n",
    "train_input = input_data.iloc[:train_split]\n",
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a9e1f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       76.341\n",
       "1       65.040\n",
       "2       88.306\n",
       "3       74.323\n",
       "4       78.114\n",
       "        ...   \n",
       "157    143.388\n",
       "158    188.227\n",
       "159    143.049\n",
       "160    148.068\n",
       "161    133.872\n",
       "Name: Pernambuco - Consumo de Cimento (t), Length: 162, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo para treinamento\n",
    "train_target = target_data.iloc[:train_split]\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b094360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCA - Variação mensal durante o Plano Real (%)</th>\n",
       "      <th>NFSP - Porcentagem do PIB (%)</th>\n",
       "      <th>Taxa Selic (%)</th>\n",
       "      <th>IGP-DI</th>\n",
       "      <th>População</th>\n",
       "      <th>Estoque liquido de capital fixo - (R$)</th>\n",
       "      <th>INCC (%)</th>\n",
       "      <th>Pernambuco - value</th>\n",
       "      <th>Pernambuco - Produção de Cimento (t)</th>\n",
       "      <th>Pernambuco - PIB - Estadual</th>\n",
       "      <th>Pernambuco - PIB - Construção Civil</th>\n",
       "      <th>Pernambuco - PIB - Per Capita</th>\n",
       "      <th>Pernambuco - PIB - Preços de Mercado</th>\n",
       "      <th>Pernambuco - IDH</th>\n",
       "      <th>Pernambuco - Desemprego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-0.601510</td>\n",
       "      <td>-0.653307</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>-1.255326</td>\n",
       "      <td>1.088045</td>\n",
       "      <td>0.763466</td>\n",
       "      <td>-1.213929</td>\n",
       "      <td>0.502302</td>\n",
       "      <td>-0.514627</td>\n",
       "      <td>1.178739</td>\n",
       "      <td>-1.517685</td>\n",
       "      <td>0.412033</td>\n",
       "      <td>0.760824</td>\n",
       "      <td>1.387198</td>\n",
       "      <td>1.321016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.786068</td>\n",
       "      <td>-0.653814</td>\n",
       "      <td>0.548855</td>\n",
       "      <td>-1.118679</td>\n",
       "      <td>1.099377</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>-1.292173</td>\n",
       "      <td>0.558872</td>\n",
       "      <td>-0.579807</td>\n",
       "      <td>1.180294</td>\n",
       "      <td>-1.523555</td>\n",
       "      <td>0.405329</td>\n",
       "      <td>0.755693</td>\n",
       "      <td>1.386356</td>\n",
       "      <td>1.313816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-0.830387</td>\n",
       "      <td>-0.645656</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>-0.936336</td>\n",
       "      <td>1.110709</td>\n",
       "      <td>0.741131</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>0.618009</td>\n",
       "      <td>-0.637869</td>\n",
       "      <td>1.181849</td>\n",
       "      <td>-1.529426</td>\n",
       "      <td>0.398625</td>\n",
       "      <td>0.750563</td>\n",
       "      <td>1.385514</td>\n",
       "      <td>1.306616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-0.801089</td>\n",
       "      <td>-0.634274</td>\n",
       "      <td>0.420965</td>\n",
       "      <td>-0.931790</td>\n",
       "      <td>1.122042</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>-1.344446</td>\n",
       "      <td>0.677851</td>\n",
       "      <td>-0.700816</td>\n",
       "      <td>1.183404</td>\n",
       "      <td>-1.535296</td>\n",
       "      <td>0.391920</td>\n",
       "      <td>0.745432</td>\n",
       "      <td>1.384671</td>\n",
       "      <td>1.299416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-0.624035</td>\n",
       "      <td>0.548870</td>\n",
       "      <td>-1.168522</td>\n",
       "      <td>1.133374</td>\n",
       "      <td>0.718796</td>\n",
       "      <td>-1.381638</td>\n",
       "      <td>0.735370</td>\n",
       "      <td>-0.762356</td>\n",
       "      <td>1.184958</td>\n",
       "      <td>-1.541167</td>\n",
       "      <td>0.385216</td>\n",
       "      <td>0.740301</td>\n",
       "      <td>1.383829</td>\n",
       "      <td>1.292215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-1.022309</td>\n",
       "      <td>-0.619791</td>\n",
       "      <td>0.222499</td>\n",
       "      <td>-1.285611</td>\n",
       "      <td>1.144706</td>\n",
       "      <td>0.707629</td>\n",
       "      <td>-1.411208</td>\n",
       "      <td>0.805344</td>\n",
       "      <td>-0.819696</td>\n",
       "      <td>1.186513</td>\n",
       "      <td>-1.547038</td>\n",
       "      <td>0.378512</td>\n",
       "      <td>0.735170</td>\n",
       "      <td>1.382986</td>\n",
       "      <td>1.285015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-1.074401</td>\n",
       "      <td>-0.620112</td>\n",
       "      <td>-0.614754</td>\n",
       "      <td>-1.446316</td>\n",
       "      <td>1.156038</td>\n",
       "      <td>0.696461</td>\n",
       "      <td>-1.412953</td>\n",
       "      <td>0.862523</td>\n",
       "      <td>-0.868227</td>\n",
       "      <td>1.188068</td>\n",
       "      <td>-1.552908</td>\n",
       "      <td>0.371807</td>\n",
       "      <td>0.730039</td>\n",
       "      <td>1.382144</td>\n",
       "      <td>1.277815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-1.119597</td>\n",
       "      <td>-0.615973</td>\n",
       "      <td>-0.478229</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>1.167287</td>\n",
       "      <td>0.681823</td>\n",
       "      <td>-1.491464</td>\n",
       "      <td>0.919373</td>\n",
       "      <td>-0.920978</td>\n",
       "      <td>1.180899</td>\n",
       "      <td>-1.549484</td>\n",
       "      <td>0.348413</td>\n",
       "      <td>0.709961</td>\n",
       "      <td>1.382771</td>\n",
       "      <td>1.270658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-1.078648</td>\n",
       "      <td>-0.609777</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-1.235682</td>\n",
       "      <td>1.178536</td>\n",
       "      <td>0.667184</td>\n",
       "      <td>-1.573805</td>\n",
       "      <td>0.971509</td>\n",
       "      <td>-0.964738</td>\n",
       "      <td>1.173731</td>\n",
       "      <td>-1.546060</td>\n",
       "      <td>0.325019</td>\n",
       "      <td>0.689882</td>\n",
       "      <td>1.383399</td>\n",
       "      <td>1.263502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-1.055426</td>\n",
       "      <td>-0.602141</td>\n",
       "      <td>-0.557552</td>\n",
       "      <td>-1.065340</td>\n",
       "      <td>1.189784</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-1.564950</td>\n",
       "      <td>1.026374</td>\n",
       "      <td>-1.008836</td>\n",
       "      <td>1.166562</td>\n",
       "      <td>-1.542635</td>\n",
       "      <td>0.301625</td>\n",
       "      <td>0.669804</td>\n",
       "      <td>1.384026</td>\n",
       "      <td>1.256345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-1.101053</td>\n",
       "      <td>-0.593094</td>\n",
       "      <td>-1.033381</td>\n",
       "      <td>-0.826250</td>\n",
       "      <td>1.201033</td>\n",
       "      <td>0.637906</td>\n",
       "      <td>-1.581584</td>\n",
       "      <td>1.082250</td>\n",
       "      <td>-1.037483</td>\n",
       "      <td>1.159393</td>\n",
       "      <td>-1.539211</td>\n",
       "      <td>0.278230</td>\n",
       "      <td>0.649725</td>\n",
       "      <td>1.384653</td>\n",
       "      <td>1.249188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-1.211370</td>\n",
       "      <td>-0.583407</td>\n",
       "      <td>0.310838</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>1.212282</td>\n",
       "      <td>0.623268</td>\n",
       "      <td>-1.565976</td>\n",
       "      <td>1.140213</td>\n",
       "      <td>-1.077264</td>\n",
       "      <td>1.152224</td>\n",
       "      <td>-1.535786</td>\n",
       "      <td>0.254836</td>\n",
       "      <td>0.629647</td>\n",
       "      <td>1.385281</td>\n",
       "      <td>1.242031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-1.157198</td>\n",
       "      <td>-0.572795</td>\n",
       "      <td>-1.062966</td>\n",
       "      <td>-0.512365</td>\n",
       "      <td>1.223531</td>\n",
       "      <td>0.608629</td>\n",
       "      <td>-1.648556</td>\n",
       "      <td>1.213606</td>\n",
       "      <td>-1.113834</td>\n",
       "      <td>1.145056</td>\n",
       "      <td>-1.532362</td>\n",
       "      <td>0.231442</td>\n",
       "      <td>0.609569</td>\n",
       "      <td>1.385908</td>\n",
       "      <td>1.234875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-1.223444</td>\n",
       "      <td>-0.559889</td>\n",
       "      <td>-1.347961</td>\n",
       "      <td>-0.546480</td>\n",
       "      <td>1.234780</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>1.248633</td>\n",
       "      <td>-1.144015</td>\n",
       "      <td>1.137887</td>\n",
       "      <td>-1.528937</td>\n",
       "      <td>0.208047</td>\n",
       "      <td>0.589490</td>\n",
       "      <td>1.386535</td>\n",
       "      <td>1.227718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-1.311519</td>\n",
       "      <td>-0.555452</td>\n",
       "      <td>-0.609120</td>\n",
       "      <td>-0.504812</td>\n",
       "      <td>1.246029</td>\n",
       "      <td>0.579351</td>\n",
       "      <td>-1.653957</td>\n",
       "      <td>1.284332</td>\n",
       "      <td>-1.180814</td>\n",
       "      <td>1.130718</td>\n",
       "      <td>-1.525513</td>\n",
       "      <td>0.184653</td>\n",
       "      <td>0.569412</td>\n",
       "      <td>1.387163</td>\n",
       "      <td>1.220561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-1.362602</td>\n",
       "      <td>-0.546328</td>\n",
       "      <td>-0.215312</td>\n",
       "      <td>-0.515805</td>\n",
       "      <td>1.257277</td>\n",
       "      <td>0.564713</td>\n",
       "      <td>-1.652572</td>\n",
       "      <td>1.321438</td>\n",
       "      <td>-1.208751</td>\n",
       "      <td>1.123550</td>\n",
       "      <td>-1.522088</td>\n",
       "      <td>0.161259</td>\n",
       "      <td>0.549333</td>\n",
       "      <td>1.387790</td>\n",
       "      <td>1.213404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-1.380125</td>\n",
       "      <td>-0.529973</td>\n",
       "      <td>0.222485</td>\n",
       "      <td>-0.391158</td>\n",
       "      <td>1.268526</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-1.715349</td>\n",
       "      <td>1.356976</td>\n",
       "      <td>-1.232155</td>\n",
       "      <td>1.116381</td>\n",
       "      <td>-1.518664</td>\n",
       "      <td>0.137865</td>\n",
       "      <td>0.529255</td>\n",
       "      <td>1.388418</td>\n",
       "      <td>1.206248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-1.219296</td>\n",
       "      <td>-0.518885</td>\n",
       "      <td>-1.266605</td>\n",
       "      <td>-0.230121</td>\n",
       "      <td>1.279775</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>-1.750917</td>\n",
       "      <td>1.404546</td>\n",
       "      <td>-1.261665</td>\n",
       "      <td>1.109212</td>\n",
       "      <td>-1.515239</td>\n",
       "      <td>0.114470</td>\n",
       "      <td>0.509176</td>\n",
       "      <td>1.389045</td>\n",
       "      <td>1.199091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-1.300284</td>\n",
       "      <td>-0.513088</td>\n",
       "      <td>-1.588002</td>\n",
       "      <td>-0.318758</td>\n",
       "      <td>1.291024</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>-1.718448</td>\n",
       "      <td>1.449902</td>\n",
       "      <td>-1.274833</td>\n",
       "      <td>1.102043</td>\n",
       "      <td>-1.511815</td>\n",
       "      <td>0.091076</td>\n",
       "      <td>0.489098</td>\n",
       "      <td>1.389672</td>\n",
       "      <td>1.191934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-1.336476</td>\n",
       "      <td>-0.513451</td>\n",
       "      <td>-1.226154</td>\n",
       "      <td>-0.396427</td>\n",
       "      <td>1.301722</td>\n",
       "      <td>0.501996</td>\n",
       "      <td>-1.733426</td>\n",
       "      <td>1.488432</td>\n",
       "      <td>-1.285409</td>\n",
       "      <td>1.089857</td>\n",
       "      <td>-1.498197</td>\n",
       "      <td>0.068028</td>\n",
       "      <td>0.470078</td>\n",
       "      <td>1.380305</td>\n",
       "      <td>1.190680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-1.415774</td>\n",
       "      <td>-0.516743</td>\n",
       "      <td>-1.358090</td>\n",
       "      <td>-0.140581</td>\n",
       "      <td>1.312420</td>\n",
       "      <td>0.483195</td>\n",
       "      <td>-1.729362</td>\n",
       "      <td>1.522197</td>\n",
       "      <td>-1.290413</td>\n",
       "      <td>1.077671</td>\n",
       "      <td>-1.484579</td>\n",
       "      <td>0.044980</td>\n",
       "      <td>0.451059</td>\n",
       "      <td>1.370938</td>\n",
       "      <td>1.189427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-1.526021</td>\n",
       "      <td>-0.521796</td>\n",
       "      <td>-1.395002</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>1.323118</td>\n",
       "      <td>0.464395</td>\n",
       "      <td>-1.748544</td>\n",
       "      <td>1.554574</td>\n",
       "      <td>-1.292652</td>\n",
       "      <td>1.065485</td>\n",
       "      <td>-1.470961</td>\n",
       "      <td>0.021933</td>\n",
       "      <td>0.432039</td>\n",
       "      <td>1.361570</td>\n",
       "      <td>1.188173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-1.681806</td>\n",
       "      <td>-0.529878</td>\n",
       "      <td>-1.430606</td>\n",
       "      <td>-0.154798</td>\n",
       "      <td>1.333817</td>\n",
       "      <td>0.445594</td>\n",
       "      <td>-1.778060</td>\n",
       "      <td>1.584012</td>\n",
       "      <td>-1.302613</td>\n",
       "      <td>1.053299</td>\n",
       "      <td>-1.457343</td>\n",
       "      <td>-0.001115</td>\n",
       "      <td>0.413020</td>\n",
       "      <td>1.352203</td>\n",
       "      <td>1.186919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-1.735167</td>\n",
       "      <td>-0.540010</td>\n",
       "      <td>-1.511562</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>1.344515</td>\n",
       "      <td>0.426794</td>\n",
       "      <td>-1.773710</td>\n",
       "      <td>1.610280</td>\n",
       "      <td>-1.294466</td>\n",
       "      <td>1.041113</td>\n",
       "      <td>-1.443724</td>\n",
       "      <td>-0.024163</td>\n",
       "      <td>0.394000</td>\n",
       "      <td>1.342836</td>\n",
       "      <td>1.185665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-1.962315</td>\n",
       "      <td>-0.555482</td>\n",
       "      <td>-1.433584</td>\n",
       "      <td>0.013469</td>\n",
       "      <td>1.355213</td>\n",
       "      <td>0.407993</td>\n",
       "      <td>-1.757007</td>\n",
       "      <td>1.633724</td>\n",
       "      <td>-1.290011</td>\n",
       "      <td>1.028927</td>\n",
       "      <td>-1.430106</td>\n",
       "      <td>-0.047211</td>\n",
       "      <td>0.374981</td>\n",
       "      <td>1.333468</td>\n",
       "      <td>1.184412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-2.010387</td>\n",
       "      <td>-0.572934</td>\n",
       "      <td>-1.281958</td>\n",
       "      <td>0.589021</td>\n",
       "      <td>1.365911</td>\n",
       "      <td>0.389193</td>\n",
       "      <td>-1.749976</td>\n",
       "      <td>1.720800</td>\n",
       "      <td>-1.281757</td>\n",
       "      <td>1.016740</td>\n",
       "      <td>-1.416488</td>\n",
       "      <td>-0.070259</td>\n",
       "      <td>0.355961</td>\n",
       "      <td>1.324101</td>\n",
       "      <td>1.183158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-1.870713</td>\n",
       "      <td>-0.588777</td>\n",
       "      <td>-1.358588</td>\n",
       "      <td>1.043728</td>\n",
       "      <td>1.376610</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>-1.593005</td>\n",
       "      <td>1.802101</td>\n",
       "      <td>-1.271596</td>\n",
       "      <td>1.004554</td>\n",
       "      <td>-1.402870</td>\n",
       "      <td>-0.093306</td>\n",
       "      <td>0.336941</td>\n",
       "      <td>1.314733</td>\n",
       "      <td>1.181904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-1.806230</td>\n",
       "      <td>-0.612606</td>\n",
       "      <td>-1.511565</td>\n",
       "      <td>1.387010</td>\n",
       "      <td>1.387308</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>-1.351489</td>\n",
       "      <td>1.813469</td>\n",
       "      <td>-1.268136</td>\n",
       "      <td>0.992368</td>\n",
       "      <td>-1.389252</td>\n",
       "      <td>-0.116354</td>\n",
       "      <td>0.317922</td>\n",
       "      <td>1.305366</td>\n",
       "      <td>1.180650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.727496</td>\n",
       "      <td>-0.640956</td>\n",
       "      <td>-1.421708</td>\n",
       "      <td>1.815728</td>\n",
       "      <td>1.398006</td>\n",
       "      <td>0.332791</td>\n",
       "      <td>-1.198492</td>\n",
       "      <td>1.843043</td>\n",
       "      <td>-1.270527</td>\n",
       "      <td>0.980182</td>\n",
       "      <td>-1.375634</td>\n",
       "      <td>-0.139402</td>\n",
       "      <td>0.298902</td>\n",
       "      <td>1.295999</td>\n",
       "      <td>1.179397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.391283</td>\n",
       "      <td>-0.663358</td>\n",
       "      <td>-1.593676</td>\n",
       "      <td>2.181106</td>\n",
       "      <td>1.408704</td>\n",
       "      <td>0.313991</td>\n",
       "      <td>-1.100894</td>\n",
       "      <td>1.878446</td>\n",
       "      <td>-1.273952</td>\n",
       "      <td>0.967996</td>\n",
       "      <td>-1.362016</td>\n",
       "      <td>-0.162450</td>\n",
       "      <td>0.279883</td>\n",
       "      <td>1.286631</td>\n",
       "      <td>1.178143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IPCA - Variação mensal durante o Plano Real (%)  \\\n",
       "162                                         -0.601510   \n",
       "163                                         -0.786068   \n",
       "164                                         -0.830387   \n",
       "165                                         -0.801089   \n",
       "166                                         -0.959917   \n",
       "167                                         -1.022309   \n",
       "168                                         -1.074401   \n",
       "169                                         -1.119597   \n",
       "170                                         -1.078648   \n",
       "171                                         -1.055426   \n",
       "172                                         -1.101053   \n",
       "173                                         -1.211370   \n",
       "174                                         -1.157198   \n",
       "175                                         -1.223444   \n",
       "176                                         -1.311519   \n",
       "177                                         -1.362602   \n",
       "178                                         -1.380125   \n",
       "179                                         -1.219296   \n",
       "180                                         -1.300284   \n",
       "181                                         -1.336476   \n",
       "182                                         -1.415774   \n",
       "183                                         -1.526021   \n",
       "184                                         -1.681806   \n",
       "185                                         -1.735167   \n",
       "186                                         -1.962315   \n",
       "187                                         -2.010387   \n",
       "188                                         -1.870713   \n",
       "189                                         -1.806230   \n",
       "190                                         -1.727496   \n",
       "191                                         -1.391283   \n",
       "\n",
       "     NFSP - Porcentagem do PIB (%)  Taxa Selic (%)    IGP-DI  População  \\\n",
       "162                      -0.653307        0.157879 -1.255326   1.088045   \n",
       "163                      -0.653814        0.548855 -1.118679   1.099377   \n",
       "164                      -0.645656        0.385685 -0.936336   1.110709   \n",
       "165                      -0.634274        0.420965 -0.931790   1.122042   \n",
       "166                      -0.624035        0.548870 -1.168522   1.133374   \n",
       "167                      -0.619791        0.222499 -1.285611   1.144706   \n",
       "168                      -0.620112       -0.614754 -1.446316   1.156038   \n",
       "169                      -0.615973       -0.478229 -1.357832   1.167287   \n",
       "170                      -0.609777       -0.393157 -1.235682   1.178536   \n",
       "171                      -0.602141       -0.557552 -1.065340   1.189784   \n",
       "172                      -0.593094       -1.033381 -0.826250   1.201033   \n",
       "173                      -0.583407        0.310838 -0.657967   1.212282   \n",
       "174                      -0.572795       -1.062966 -0.512365   1.223531   \n",
       "175                      -0.559889       -1.347961 -0.546480   1.234780   \n",
       "176                      -0.555452       -0.609120 -0.504812   1.246029   \n",
       "177                      -0.546328       -0.215312 -0.515805   1.257277   \n",
       "178                      -0.529973        0.222485 -0.391158   1.268526   \n",
       "179                      -0.518885       -1.266605 -0.230121   1.279775   \n",
       "180                      -0.513088       -1.588002 -0.318758   1.291024   \n",
       "181                      -0.513451       -1.226154 -0.396427   1.301722   \n",
       "182                      -0.516743       -1.358090 -0.140581   1.312420   \n",
       "183                      -0.521796       -1.395002 -0.198662   1.323118   \n",
       "184                      -0.529878       -1.430606 -0.154798   1.333817   \n",
       "185                      -0.540010       -1.511562 -0.142566   1.344515   \n",
       "186                      -0.555482       -1.433584  0.013469   1.355213   \n",
       "187                      -0.572934       -1.281958  0.589021   1.365911   \n",
       "188                      -0.588777       -1.358588  1.043728   1.376610   \n",
       "189                      -0.612606       -1.511565  1.387010   1.387308   \n",
       "190                      -0.640956       -1.421708  1.815728   1.398006   \n",
       "191                      -0.663358       -1.593676  2.181106   1.408704   \n",
       "\n",
       "     Estoque liquido de capital fixo - (R$)   INCC (%)  Pernambuco - value  \\\n",
       "162                                0.763466  -1.213929            0.502302   \n",
       "163                                0.752299  -1.292173            0.558872   \n",
       "164                                0.741131  -1.324219            0.618009   \n",
       "165                                0.729964  -1.344446            0.677851   \n",
       "166                                0.718796  -1.381638            0.735370   \n",
       "167                                0.707629  -1.411208            0.805344   \n",
       "168                                0.696461  -1.412953            0.862523   \n",
       "169                                0.681823  -1.491464            0.919373   \n",
       "170                                0.667184  -1.573805            0.971509   \n",
       "171                                0.652545  -1.564950            1.026374   \n",
       "172                                0.637906  -1.581584            1.082250   \n",
       "173                                0.623268  -1.565976            1.140213   \n",
       "174                                0.608629  -1.648556            1.213606   \n",
       "175                                0.593990  -1.650049            1.248633   \n",
       "176                                0.579351  -1.653957            1.284332   \n",
       "177                                0.564713  -1.652572            1.321438   \n",
       "178                                0.550074  -1.715349            1.356976   \n",
       "179                                0.535435  -1.750917            1.404546   \n",
       "180                                0.520796  -1.718448            1.449902   \n",
       "181                                0.501996  -1.733426            1.488432   \n",
       "182                                0.483195  -1.729362            1.522197   \n",
       "183                                0.464395  -1.748544            1.554574   \n",
       "184                                0.445594  -1.778060            1.584012   \n",
       "185                                0.426794  -1.773710            1.610280   \n",
       "186                                0.407993  -1.757007            1.633724   \n",
       "187                                0.389193  -1.749976            1.720800   \n",
       "188                                0.370392  -1.593005            1.802101   \n",
       "189                                0.351592  -1.351489            1.813469   \n",
       "190                                0.332791  -1.198492            1.843043   \n",
       "191                                0.313991  -1.100894            1.878446   \n",
       "\n",
       "     Pernambuco - Produção de Cimento (t)  Pernambuco - PIB - Estadual  \\\n",
       "162                             -0.514627                     1.178739   \n",
       "163                             -0.579807                     1.180294   \n",
       "164                             -0.637869                     1.181849   \n",
       "165                             -0.700816                     1.183404   \n",
       "166                             -0.762356                     1.184958   \n",
       "167                             -0.819696                     1.186513   \n",
       "168                             -0.868227                     1.188068   \n",
       "169                             -0.920978                     1.180899   \n",
       "170                             -0.964738                     1.173731   \n",
       "171                             -1.008836                     1.166562   \n",
       "172                             -1.037483                     1.159393   \n",
       "173                             -1.077264                     1.152224   \n",
       "174                             -1.113834                     1.145056   \n",
       "175                             -1.144015                     1.137887   \n",
       "176                             -1.180814                     1.130718   \n",
       "177                             -1.208751                     1.123550   \n",
       "178                             -1.232155                     1.116381   \n",
       "179                             -1.261665                     1.109212   \n",
       "180                             -1.274833                     1.102043   \n",
       "181                             -1.285409                     1.089857   \n",
       "182                             -1.290413                     1.077671   \n",
       "183                             -1.292652                     1.065485   \n",
       "184                             -1.302613                     1.053299   \n",
       "185                             -1.294466                     1.041113   \n",
       "186                             -1.290011                     1.028927   \n",
       "187                             -1.281757                     1.016740   \n",
       "188                             -1.271596                     1.004554   \n",
       "189                             -1.268136                     0.992368   \n",
       "190                             -1.270527                     0.980182   \n",
       "191                             -1.273952                     0.967996   \n",
       "\n",
       "     Pernambuco - PIB - Construção Civil  Pernambuco - PIB - Per Capita  \\\n",
       "162                            -1.517685                       0.412033   \n",
       "163                            -1.523555                       0.405329   \n",
       "164                            -1.529426                       0.398625   \n",
       "165                            -1.535296                       0.391920   \n",
       "166                            -1.541167                       0.385216   \n",
       "167                            -1.547038                       0.378512   \n",
       "168                            -1.552908                       0.371807   \n",
       "169                            -1.549484                       0.348413   \n",
       "170                            -1.546060                       0.325019   \n",
       "171                            -1.542635                       0.301625   \n",
       "172                            -1.539211                       0.278230   \n",
       "173                            -1.535786                       0.254836   \n",
       "174                            -1.532362                       0.231442   \n",
       "175                            -1.528937                       0.208047   \n",
       "176                            -1.525513                       0.184653   \n",
       "177                            -1.522088                       0.161259   \n",
       "178                            -1.518664                       0.137865   \n",
       "179                            -1.515239                       0.114470   \n",
       "180                            -1.511815                       0.091076   \n",
       "181                            -1.498197                       0.068028   \n",
       "182                            -1.484579                       0.044980   \n",
       "183                            -1.470961                       0.021933   \n",
       "184                            -1.457343                      -0.001115   \n",
       "185                            -1.443724                      -0.024163   \n",
       "186                            -1.430106                      -0.047211   \n",
       "187                            -1.416488                      -0.070259   \n",
       "188                            -1.402870                      -0.093306   \n",
       "189                            -1.389252                      -0.116354   \n",
       "190                            -1.375634                      -0.139402   \n",
       "191                            -1.362016                      -0.162450   \n",
       "\n",
       "     Pernambuco - PIB - Preços de Mercado  Pernambuco - IDH  \\\n",
       "162                              0.760824          1.387198   \n",
       "163                              0.755693          1.386356   \n",
       "164                              0.750563          1.385514   \n",
       "165                              0.745432          1.384671   \n",
       "166                              0.740301          1.383829   \n",
       "167                              0.735170          1.382986   \n",
       "168                              0.730039          1.382144   \n",
       "169                              0.709961          1.382771   \n",
       "170                              0.689882          1.383399   \n",
       "171                              0.669804          1.384026   \n",
       "172                              0.649725          1.384653   \n",
       "173                              0.629647          1.385281   \n",
       "174                              0.609569          1.385908   \n",
       "175                              0.589490          1.386535   \n",
       "176                              0.569412          1.387163   \n",
       "177                              0.549333          1.387790   \n",
       "178                              0.529255          1.388418   \n",
       "179                              0.509176          1.389045   \n",
       "180                              0.489098          1.389672   \n",
       "181                              0.470078          1.380305   \n",
       "182                              0.451059          1.370938   \n",
       "183                              0.432039          1.361570   \n",
       "184                              0.413020          1.352203   \n",
       "185                              0.394000          1.342836   \n",
       "186                              0.374981          1.333468   \n",
       "187                              0.355961          1.324101   \n",
       "188                              0.336941          1.314733   \n",
       "189                              0.317922          1.305366   \n",
       "190                              0.298902          1.295999   \n",
       "191                              0.279883          1.286631   \n",
       "\n",
       "     Pernambuco - Desemprego  \n",
       "162                 1.321016  \n",
       "163                 1.313816  \n",
       "164                 1.306616  \n",
       "165                 1.299416  \n",
       "166                 1.292215  \n",
       "167                 1.285015  \n",
       "168                 1.277815  \n",
       "169                 1.270658  \n",
       "170                 1.263502  \n",
       "171                 1.256345  \n",
       "172                 1.249188  \n",
       "173                 1.242031  \n",
       "174                 1.234875  \n",
       "175                 1.227718  \n",
       "176                 1.220561  \n",
       "177                 1.213404  \n",
       "178                 1.206248  \n",
       "179                 1.199091  \n",
       "180                 1.191934  \n",
       "181                 1.190680  \n",
       "182                 1.189427  \n",
       "183                 1.188173  \n",
       "184                 1.186919  \n",
       "185                 1.185665  \n",
       "186                 1.184412  \n",
       "187                 1.183158  \n",
       "188                 1.181904  \n",
       "189                 1.180650  \n",
       "190                 1.179397  \n",
       "191                 1.178143  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input de test (Ano 2021)\n",
    "test_input = input_data.iloc[train_split:]\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb5a92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162    131.464\n",
       "163    151.370\n",
       "164    154.276\n",
       "165    153.331\n",
       "166    152.600\n",
       "167    136.567\n",
       "168    144.855\n",
       "169    126.352\n",
       "170    138.148\n",
       "171    129.978\n",
       "172    109.083\n",
       "173    147.440\n",
       "174    132.500\n",
       "175    158.533\n",
       "176    133.813\n",
       "177    155.827\n",
       "178    146.197\n",
       "179    122.278\n",
       "180    149.983\n",
       "181    123.483\n",
       "182    125.104\n",
       "183    129.633\n",
       "184    138.233\n",
       "185    109.657\n",
       "186    128.809\n",
       "187    140.408\n",
       "188    134.634\n",
       "189    189.040\n",
       "190    166.406\n",
       "191    155.456\n",
       "Name: Pernambuco - Consumo de Cimento (t), dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alvo de test (Ano 2021)\n",
    "test_target = target_data.iloc[train_split:split_index + 1]\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f831f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitter(df, div_factor):\n",
    "    split_factor = len(df)//div_factor\n",
    "    positions_to_drop = []\n",
    "    for i in range(split_factor):\n",
    "        pos = df.shape[0] - (i*div_factor + 1)\n",
    "        positions_to_drop.append(pos)\n",
    "    \n",
    "    return df.drop(positions_to_drop), df.iloc[positions_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a3842bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural feed-forward com optmizador Estocástico\n",
    "def neural_network_model(train_input, train_target, want_verbose=1, seed=0):\n",
    "    if seed != 0:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "    # Aṕos 500 epochs sem grandes melhoras no val_loss, interrompe.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                      patience=500, \n",
    "                                                      verbose=want_verbose, \n",
    "                                                      restore_best_weights=True,\n",
    "                                                      start_from_epoch=500)\n",
    "    # Método estocástico e learning rate=0.005\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(2048, activation='tanh', input_shape=(train_input.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1024, activation='tanh'),\n",
    "        tf.keras.layers.Dense(128, activation='tanh'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    train, train_val = validation_splitter(train_input, 6)\n",
    "    target,target_val = validation_splitter(train_target, 6)\n",
    "#     display(train)\n",
    "#     display(train_val)\n",
    "#     display(target)\n",
    "#     display(target_val)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')   \n",
    "    history = model.fit(train_input, \n",
    "                        train_target, \n",
    "                        epochs=10000,\n",
    "                        validation_data=(train_val, target_val),\n",
    "#                         validation_split=0.07,\n",
    "                        callbacks=[early_stopping], \n",
    "                        verbose=want_verbose)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67d5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_good_seed(train_input, train_target, test_target, test_input):\n",
    "\n",
    "    random_seeds = [random.randint(0, 2**32 - 1) for _ in range(25)]\n",
    "    print(random_seeds)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    winner_seed = None\n",
    "    i = 0\n",
    "    for seed in random_seeds:\n",
    "        print(f\"\\n\\nStep: {i} ___________________________________________\")\n",
    "        i += 1\n",
    "\n",
    "        model, history = neural_network_model(train_input, train_target, want_verbose=0, seed=seed)\n",
    "        current_loss = min(history.history['val_loss'][500:])\n",
    "        print(f\"val_loss: {current_loss}\")\n",
    "\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            winner_seed = seed\n",
    "            print(f\"winner_seed: {winner_seed}\")\n",
    "            if winner_seed == 0.0:\n",
    "                return winner_seed\n",
    "\n",
    "    return winner_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1acb58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[531077790, 1920377228, 1623047814, 2125771211, 3115464542, 3429880134, 4225001622, 3132872968, 2942341223, 2078227689, 3618974338, 2030182595, 2493022402, 1800086960, 3827629207, 2545598500, 1643889302, 1486655283, 3974757553, 2899745877, 3305859953, 398547712, 1158171961, 95807413, 3395698231]\n",
      "\n",
      "\n",
      "Step: 0 ___________________________________________\n",
      "val_loss: 278.6745910644531\n",
      "winner_seed: 531077790\n",
      "\n",
      "\n",
      "Step: 1 ___________________________________________\n",
      "val_loss: 242.3434600830078\n",
      "winner_seed: 1920377228\n",
      "\n",
      "\n",
      "Step: 2 ___________________________________________\n",
      "val_loss: 239.02346801757812\n",
      "winner_seed: 1623047814\n",
      "\n",
      "\n",
      "Step: 3 ___________________________________________\n",
      "val_loss: 304.3401184082031\n",
      "\n",
      "\n",
      "Step: 4 ___________________________________________\n",
      "val_loss: 249.42066955566406\n",
      "\n",
      "\n",
      "Step: 5 ___________________________________________\n",
      "val_loss: 247.76885986328125\n",
      "\n",
      "\n",
      "Step: 6 ___________________________________________\n",
      "val_loss: 265.76995849609375\n",
      "\n",
      "\n",
      "Step: 7 ___________________________________________\n",
      "val_loss: 269.998779296875\n",
      "\n",
      "\n",
      "Step: 8 ___________________________________________\n",
      "val_loss: 231.97804260253906\n",
      "winner_seed: 2942341223\n",
      "\n",
      "\n",
      "Step: 9 ___________________________________________\n",
      "val_loss: 393.8153076171875\n",
      "\n",
      "\n",
      "Step: 10 ___________________________________________\n",
      "val_loss: 188.90415954589844\n",
      "winner_seed: 3618974338\n",
      "\n",
      "\n",
      "Step: 11 ___________________________________________\n",
      "val_loss: 238.95196533203125\n",
      "\n",
      "\n",
      "Step: 12 ___________________________________________\n",
      "val_loss: 240.62750244140625\n",
      "\n",
      "\n",
      "Step: 13 ___________________________________________\n",
      "val_loss: 245.90670776367188\n",
      "\n",
      "\n",
      "Step: 14 ___________________________________________\n",
      "val_loss: 288.1823425292969\n",
      "\n",
      "\n",
      "Step: 15 ___________________________________________\n",
      "val_loss: 244.0939483642578\n",
      "\n",
      "\n",
      "Step: 16 ___________________________________________\n",
      "val_loss: 261.5802307128906\n",
      "\n",
      "\n",
      "Step: 17 ___________________________________________\n",
      "val_loss: 247.97207641601562\n",
      "\n",
      "\n",
      "Step: 18 ___________________________________________\n",
      "val_loss: 247.15887451171875\n",
      "\n",
      "\n",
      "Step: 19 ___________________________________________\n",
      "val_loss: 217.4121856689453\n",
      "\n",
      "\n",
      "Step: 20 ___________________________________________\n",
      "val_loss: 284.29730224609375\n",
      "\n",
      "\n",
      "Step: 21 ___________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 17:59:51.961607: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 296.44647216796875\n",
      "\n",
      "\n",
      "Step: 22 ___________________________________________\n",
      "val_loss: 1125.219482421875\n",
      "\n",
      "\n",
      "Step: 23 ___________________________________________\n",
      "val_loss: 223.82411193847656\n",
      "\n",
      "\n",
      "Step: 24 ___________________________________________\n",
      "val_loss: 222.43142700195312\n",
      "\n",
      "\n",
      "final_seed: 3618974338\n"
     ]
    }
   ],
   "source": [
    "winner_seed = get_a_good_seed(train_input, train_target, test_target, test_input)\n",
    "print(f\"\\n\\nfinal_seed: {winner_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "903643e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "6/6 [==============================] - 1s 23ms/step - loss: 27346.1074 - val_loss: 42323.7578\n",
      "Epoch 2/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 33149.3945 - val_loss: 57040.7695\n",
      "Epoch 3/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 24325.5469 - val_loss: 28751.0020\n",
      "Epoch 4/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 17796.5176 - val_loss: 15321.7305\n",
      "Epoch 5/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 6841.9268 - val_loss: 23482.0234\n",
      "Epoch 6/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16825.3496 - val_loss: 16768.5137\n",
      "Epoch 7/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8435.0449 - val_loss: 1134.7185\n",
      "Epoch 8/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 637.0102 - val_loss: 438.0541\n",
      "Epoch 9/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 610.8011 - val_loss: 957.7118\n",
      "Epoch 10/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 493.6480 - val_loss: 549.6645\n",
      "Epoch 11/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 449.7956 - val_loss: 944.8806\n",
      "Epoch 12/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 504.1280 - val_loss: 512.3892\n",
      "Epoch 13/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 468.5247 - val_loss: 602.1411\n",
      "Epoch 14/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 383.5657 - val_loss: 637.8289\n",
      "Epoch 15/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 384.8364 - val_loss: 756.9440\n",
      "Epoch 16/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 429.2396 - val_loss: 512.8160\n",
      "Epoch 17/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 316.5527 - val_loss: 696.3156\n",
      "Epoch 18/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 358.0597 - val_loss: 541.6525\n",
      "Epoch 19/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 409.9236 - val_loss: 581.5172\n",
      "Epoch 20/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 425.6678 - val_loss: 425.1753\n",
      "Epoch 21/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 329.2275 - val_loss: 367.2181\n",
      "Epoch 22/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 353.6157 - val_loss: 408.7721\n",
      "Epoch 23/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 302.9346 - val_loss: 412.5876\n",
      "Epoch 24/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 382.2994 - val_loss: 549.6392\n",
      "Epoch 25/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 353.2849 - val_loss: 456.1651\n",
      "Epoch 26/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 407.9254 - val_loss: 460.4451\n",
      "Epoch 27/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 408.8925 - val_loss: 651.4187\n",
      "Epoch 28/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 452.0880 - val_loss: 601.2717\n",
      "Epoch 29/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 322.2520 - val_loss: 715.0822\n",
      "Epoch 30/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 400.1962 - val_loss: 504.7763\n",
      "Epoch 31/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 370.4106 - val_loss: 552.2574\n",
      "Epoch 32/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 342.3825 - val_loss: 639.9340\n",
      "Epoch 33/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 405.7152 - val_loss: 747.6522\n",
      "Epoch 34/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 484.7334 - val_loss: 748.4844\n",
      "Epoch 35/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 482.8166 - val_loss: 570.1760\n",
      "Epoch 36/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 427.1800 - val_loss: 397.2809\n",
      "Epoch 37/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 365.1263 - val_loss: 510.5065\n",
      "Epoch 38/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 367.0841 - val_loss: 401.5061\n",
      "Epoch 39/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 362.2268 - val_loss: 367.1801\n",
      "Epoch 40/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 329.6855 - val_loss: 917.8284\n",
      "Epoch 41/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 505.8509 - val_loss: 467.4387\n",
      "Epoch 42/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 385.3573 - val_loss: 487.5267\n",
      "Epoch 43/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 316.0939 - val_loss: 472.4170\n",
      "Epoch 44/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 346.2214 - val_loss: 459.7834\n",
      "Epoch 45/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 315.9136 - val_loss: 458.2940\n",
      "Epoch 46/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 355.7343 - val_loss: 627.2436\n",
      "Epoch 47/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 331.0632 - val_loss: 2163.2246\n",
      "Epoch 48/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 881.1516 - val_loss: 617.3552\n",
      "Epoch 49/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 454.0414 - val_loss: 1092.3005\n",
      "Epoch 50/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 567.8726 - val_loss: 856.4184\n",
      "Epoch 51/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 579.9949 - val_loss: 536.2980\n",
      "Epoch 52/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 388.7555 - val_loss: 659.3340\n",
      "Epoch 53/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 483.5442 - val_loss: 352.8346\n",
      "Epoch 54/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 327.4677 - val_loss: 443.7618\n",
      "Epoch 55/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 361.7337 - val_loss: 719.6453\n",
      "Epoch 56/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 433.3268 - val_loss: 735.7963\n",
      "Epoch 57/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 404.9529 - val_loss: 517.3190\n",
      "Epoch 58/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 371.3594 - val_loss: 492.6613\n",
      "Epoch 59/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 362.8368 - val_loss: 836.8964\n",
      "Epoch 60/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 454.4834 - val_loss: 596.6660\n",
      "Epoch 61/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 350.1364 - val_loss: 453.7022\n",
      "Epoch 62/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 373.3921 - val_loss: 426.3153\n",
      "Epoch 63/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 349.4653 - val_loss: 371.3455\n",
      "Epoch 64/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 390.3446 - val_loss: 562.8930\n",
      "Epoch 65/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 396.9597 - val_loss: 483.6741\n",
      "Epoch 66/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 388.1727 - val_loss: 450.9519\n",
      "Epoch 67/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 319.9591 - val_loss: 478.9315\n",
      "Epoch 68/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 281.4096 - val_loss: 788.2976\n",
      "Epoch 69/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3031.9106 - val_loss: 20994.7344\n",
      "Epoch 70/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 7681.6978 - val_loss: 729.9962\n",
      "Epoch 71/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 572.6727 - val_loss: 475.2704\n",
      "Epoch 72/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 405.2621 - val_loss: 519.3661\n",
      "Epoch 73/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 362.5047 - val_loss: 705.9877\n",
      "Epoch 74/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 502.4332 - val_loss: 625.3721\n",
      "Epoch 75/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 477.2089 - val_loss: 593.5928\n",
      "Epoch 76/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 429.3927 - val_loss: 429.3337\n",
      "Epoch 77/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 364.8655 - val_loss: 582.5485\n",
      "Epoch 78/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 449.3708 - val_loss: 390.7290\n",
      "Epoch 79/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 370.4028 - val_loss: 356.5424\n",
      "Epoch 80/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 330.6968 - val_loss: 425.8486\n",
      "Epoch 81/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 383.5642 - val_loss: 756.8238\n",
      "Epoch 82/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 530.5408 - val_loss: 594.7144\n",
      "Epoch 83/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 395.0948 - val_loss: 545.9412\n",
      "Epoch 84/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 387.4770 - val_loss: 436.2207\n",
      "Epoch 85/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 306.2565 - val_loss: 558.6293\n",
      "Epoch 86/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 379.1378 - val_loss: 415.5315\n",
      "Epoch 87/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 328.7350 - val_loss: 485.4379\n",
      "Epoch 88/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 377.1017 - val_loss: 784.0031\n",
      "Epoch 89/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 399.8898 - val_loss: 310.3691\n",
      "Epoch 90/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 277.8463 - val_loss: 770.1339\n",
      "Epoch 91/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 389.8732 - val_loss: 441.9489\n",
      "Epoch 92/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 366.8290 - val_loss: 476.2796\n",
      "Epoch 93/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 322.0895 - val_loss: 440.6437\n",
      "Epoch 94/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 347.7253 - val_loss: 416.9426\n",
      "Epoch 95/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 487.0859 - val_loss: 882.4107\n",
      "Epoch 96/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 445.3470 - val_loss: 414.8795\n",
      "Epoch 97/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 370.6750 - val_loss: 801.7371\n",
      "Epoch 98/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 343.7914 - val_loss: 589.5880\n",
      "Epoch 99/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 319.1895 - val_loss: 744.3891\n",
      "Epoch 100/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 416.4449 - val_loss: 499.8108\n",
      "Epoch 101/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 309.3860 - val_loss: 533.6409\n",
      "Epoch 102/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 530.0151 - val_loss: 451.1404\n",
      "Epoch 103/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 314.1041 - val_loss: 788.2129\n",
      "Epoch 104/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 358.5800 - val_loss: 414.2004\n",
      "Epoch 105/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 316.4119 - val_loss: 1139.5820\n",
      "Epoch 106/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 381.0955 - val_loss: 637.8477\n",
      "Epoch 107/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 386.9393 - val_loss: 791.8523\n",
      "Epoch 108/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 400.1471 - val_loss: 505.6277\n",
      "Epoch 109/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 287.0882 - val_loss: 534.4449\n",
      "Epoch 110/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 354.5417 - val_loss: 382.4634\n",
      "Epoch 111/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 300.4825 - val_loss: 417.7105\n",
      "Epoch 112/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 293.6973 - val_loss: 593.2047\n",
      "Epoch 113/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 289.9680 - val_loss: 464.1438\n",
      "Epoch 114/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 257.4475 - val_loss: 459.0715\n",
      "Epoch 115/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 344.2737 - val_loss: 402.5727\n",
      "Epoch 116/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 324.5049 - val_loss: 457.8627\n",
      "Epoch 117/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 347.8292 - val_loss: 831.7937\n",
      "Epoch 118/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 405.8055 - val_loss: 435.8795\n",
      "Epoch 119/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 347.8243 - val_loss: 392.4381\n",
      "Epoch 120/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 345.5204 - val_loss: 516.6927\n",
      "Epoch 121/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 358.1778 - val_loss: 519.6747\n",
      "Epoch 122/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 342.4322 - val_loss: 892.0510\n",
      "Epoch 123/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 375.1620 - val_loss: 418.3392\n",
      "Epoch 124/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 336.8664 - val_loss: 556.4630\n",
      "Epoch 125/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 379.8044 - val_loss: 361.7933\n",
      "Epoch 126/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 347.1026 - val_loss: 654.5095\n",
      "Epoch 127/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 453.2553 - val_loss: 457.0333\n",
      "Epoch 128/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 346.2557 - val_loss: 403.6262\n",
      "Epoch 129/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 332.5872 - val_loss: 370.0060\n",
      "Epoch 130/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 319.5044 - val_loss: 611.6893\n",
      "Epoch 131/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 372.5146 - val_loss: 464.7710\n",
      "Epoch 132/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 306.5359 - val_loss: 333.3211\n",
      "Epoch 133/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 343.0267 - val_loss: 545.3360\n",
      "Epoch 134/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 374.2037 - val_loss: 486.2709\n",
      "Epoch 135/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 281.8417 - val_loss: 386.3619\n",
      "Epoch 136/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 312.5290 - val_loss: 421.4991\n",
      "Epoch 137/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 304.2258 - val_loss: 465.3943\n",
      "Epoch 138/10000\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 330.2898 - val_loss: 472.3830\n",
      "Epoch 139/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 346.6104 - val_loss: 463.5741\n",
      "Epoch 140/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 318.0869 - val_loss: 562.0120\n",
      "Epoch 141/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 290.8683 - val_loss: 477.0414\n",
      "Epoch 142/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 287.0657 - val_loss: 524.9552\n",
      "Epoch 143/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 285.8013 - val_loss: 474.1736\n",
      "Epoch 144/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 316.6101 - val_loss: 468.0645\n",
      "Epoch 145/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 322.3683 - val_loss: 1391.7930\n",
      "Epoch 146/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 414.9225 - val_loss: 527.4565\n",
      "Epoch 147/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 397.5043 - val_loss: 410.1727\n",
      "Epoch 148/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 339.6419 - val_loss: 365.8631\n",
      "Epoch 149/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 310.7239 - val_loss: 346.7746\n",
      "Epoch 150/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 341.3929 - val_loss: 722.2601\n",
      "Epoch 151/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 357.4327 - val_loss: 760.0548\n",
      "Epoch 152/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 351.5316 - val_loss: 488.5237\n",
      "Epoch 153/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 295.4368 - val_loss: 312.8575\n",
      "Epoch 154/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 288.9529 - val_loss: 412.5190\n",
      "Epoch 155/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 297.3300 - val_loss: 374.9091\n",
      "Epoch 156/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 303.6708 - val_loss: 676.3784\n",
      "Epoch 157/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 392.4398 - val_loss: 422.5421\n",
      "Epoch 158/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 284.3801 - val_loss: 393.7601\n",
      "Epoch 159/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 302.7841 - val_loss: 568.5237\n",
      "Epoch 160/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 392.3465 - val_loss: 895.7908\n",
      "Epoch 161/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 411.9248 - val_loss: 737.8949\n",
      "Epoch 162/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 323.2833 - val_loss: 737.8433\n",
      "Epoch 163/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 381.4066 - val_loss: 635.9763\n",
      "Epoch 164/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 358.3741 - val_loss: 461.9025\n",
      "Epoch 165/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 338.2469 - val_loss: 449.9329\n",
      "Epoch 166/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 297.6102 - val_loss: 443.6118\n",
      "Epoch 167/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 417.9323 - val_loss: 342.0005\n",
      "Epoch 168/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 315.9234 - val_loss: 537.1863\n",
      "Epoch 169/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 387.1615 - val_loss: 878.4321\n",
      "Epoch 170/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 401.6657 - val_loss: 607.4981\n",
      "Epoch 171/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 338.6500 - val_loss: 439.2739\n",
      "Epoch 172/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 318.8342 - val_loss: 578.7238\n",
      "Epoch 173/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 341.4196 - val_loss: 416.0638\n",
      "Epoch 174/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 310.3197 - val_loss: 301.5926\n",
      "Epoch 175/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 313.8330 - val_loss: 530.2597\n",
      "Epoch 176/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 319.3209 - val_loss: 324.9906\n",
      "Epoch 177/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 350.6583 - val_loss: 560.4366\n",
      "Epoch 178/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 328.9966 - val_loss: 665.1898\n",
      "Epoch 179/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 330.9209 - val_loss: 1519.0944\n",
      "Epoch 180/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 508.2398 - val_loss: 358.8183\n",
      "Epoch 181/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 372.6428 - val_loss: 349.0229\n",
      "Epoch 182/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 335.4740 - val_loss: 523.0970\n",
      "Epoch 183/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 344.8554 - val_loss: 929.1117\n",
      "Epoch 184/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 397.8203 - val_loss: 440.2514\n",
      "Epoch 185/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 364.6709 - val_loss: 387.5981\n",
      "Epoch 186/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 361.7494 - val_loss: 345.6688\n",
      "Epoch 187/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 298.7164 - val_loss: 666.6763\n",
      "Epoch 188/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 331.3342 - val_loss: 416.3510\n",
      "Epoch 189/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.5780 - val_loss: 439.7865\n",
      "Epoch 190/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 260.3779 - val_loss: 444.4828\n",
      "Epoch 191/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 266.6406 - val_loss: 423.4243\n",
      "Epoch 192/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.6316 - val_loss: 515.5466\n",
      "Epoch 193/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.3247 - val_loss: 674.2525\n",
      "Epoch 194/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 646.5389 - val_loss: 871.4789\n",
      "Epoch 195/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 424.0922 - val_loss: 672.6505\n",
      "Epoch 196/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 335.0027 - val_loss: 513.0392\n",
      "Epoch 197/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 283.6597 - val_loss: 400.5384\n",
      "Epoch 198/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 289.8319 - val_loss: 546.1866\n",
      "Epoch 199/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 296.0700 - val_loss: 525.7509\n",
      "Epoch 200/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 356.9377 - val_loss: 378.8946\n",
      "Epoch 201/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 321.5996 - val_loss: 491.9111\n",
      "Epoch 202/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 314.2962 - val_loss: 835.1176\n",
      "Epoch 203/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 384.4009 - val_loss: 403.6587\n",
      "Epoch 204/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 306.6600 - val_loss: 341.2049\n",
      "Epoch 205/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 288.5893 - val_loss: 339.9033\n",
      "Epoch 206/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 301.7041 - val_loss: 435.3934\n",
      "Epoch 207/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 324.5405 - val_loss: 415.2546\n",
      "Epoch 208/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 326.9309 - val_loss: 524.3650\n",
      "Epoch 209/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 394.8285 - val_loss: 340.7018\n",
      "Epoch 210/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 302.3652 - val_loss: 348.8029\n",
      "Epoch 211/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 280.2606 - val_loss: 390.6013\n",
      "Epoch 212/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 343.2345 - val_loss: 462.3339\n",
      "Epoch 213/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 396.7597 - val_loss: 636.7675\n",
      "Epoch 214/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 369.0126 - val_loss: 368.0875\n",
      "Epoch 215/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 251.3514 - val_loss: 382.7606\n",
      "Epoch 216/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 336.2897 - val_loss: 397.9364\n",
      "Epoch 217/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 315.3012 - val_loss: 576.3850\n",
      "Epoch 218/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 377.3495 - val_loss: 482.4285\n",
      "Epoch 219/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 292.9869 - val_loss: 413.4290\n",
      "Epoch 220/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 256.0504 - val_loss: 405.6212\n",
      "Epoch 221/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.8599 - val_loss: 405.4013\n",
      "Epoch 222/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 278.2421 - val_loss: 373.3977\n",
      "Epoch 223/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 293.8263 - val_loss: 470.8578\n",
      "Epoch 224/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 335.7578 - val_loss: 1549.1288\n",
      "Epoch 225/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 455.7257 - val_loss: 462.3699\n",
      "Epoch 226/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 317.4690 - val_loss: 416.0371\n",
      "Epoch 227/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 264.6364 - val_loss: 458.9595\n",
      "Epoch 228/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 281.0783 - val_loss: 436.5871\n",
      "Epoch 229/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 295.3306 - val_loss: 404.8511\n",
      "Epoch 230/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.4167 - val_loss: 431.3456\n",
      "Epoch 231/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 352.2356 - val_loss: 553.7311\n",
      "Epoch 232/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 282.6660 - val_loss: 475.5536\n",
      "Epoch 233/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 248.3126 - val_loss: 426.1057\n",
      "Epoch 234/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 291.0527 - val_loss: 629.0013\n",
      "Epoch 235/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 273.0449 - val_loss: 457.2561\n",
      "Epoch 236/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 255.6572 - val_loss: 362.4608\n",
      "Epoch 237/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 278.0210 - val_loss: 435.6871\n",
      "Epoch 238/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 325.3055 - val_loss: 469.0598\n",
      "Epoch 239/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 252.3091 - val_loss: 544.9775\n",
      "Epoch 240/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 314.3940 - val_loss: 428.1109\n",
      "Epoch 241/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 274.4034 - val_loss: 459.5818\n",
      "Epoch 242/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 347.8919 - val_loss: 694.9657\n",
      "Epoch 243/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 382.0259 - val_loss: 504.8380\n",
      "Epoch 244/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 287.2572 - val_loss: 818.8714\n",
      "Epoch 245/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 356.3391 - val_loss: 835.5406\n",
      "Epoch 246/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 334.1457 - val_loss: 464.2307\n",
      "Epoch 247/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 285.9453 - val_loss: 537.5185\n",
      "Epoch 248/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 297.3474 - val_loss: 573.2717\n",
      "Epoch 249/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 303.8219 - val_loss: 645.4458\n",
      "Epoch 250/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 324.5876 - val_loss: 498.6268\n",
      "Epoch 251/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 343.8246 - val_loss: 422.2426\n",
      "Epoch 252/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 291.5788 - val_loss: 695.3543\n",
      "Epoch 253/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 310.9917 - val_loss: 572.0914\n",
      "Epoch 254/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 274.9322 - val_loss: 568.3411\n",
      "Epoch 255/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 309.9008 - val_loss: 421.9021\n",
      "Epoch 256/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 264.8034 - val_loss: 558.8671\n",
      "Epoch 257/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 304.1634 - val_loss: 591.6216\n",
      "Epoch 258/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 290.7779 - val_loss: 445.5854\n",
      "Epoch 259/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.2654 - val_loss: 459.6313\n",
      "Epoch 260/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 293.9677 - val_loss: 576.4318\n",
      "Epoch 261/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.5727 - val_loss: 499.1566\n",
      "Epoch 262/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 328.0896 - val_loss: 762.7932\n",
      "Epoch 263/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 405.5955 - val_loss: 469.0848\n",
      "Epoch 264/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 266.0121 - val_loss: 477.2006\n",
      "Epoch 265/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 284.1248 - val_loss: 541.0469\n",
      "Epoch 266/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.0850 - val_loss: 574.5248\n",
      "Epoch 267/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 324.6508 - val_loss: 479.8049\n",
      "Epoch 268/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 260.6288 - val_loss: 406.0982\n",
      "Epoch 269/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 266.6875 - val_loss: 548.5159\n",
      "Epoch 270/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 284.7711 - val_loss: 449.2185\n",
      "Epoch 271/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 316.4375 - val_loss: 410.5742\n",
      "Epoch 272/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 302.3894 - val_loss: 408.9319\n",
      "Epoch 273/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 297.6736 - val_loss: 517.2851\n",
      "Epoch 274/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 257.9286 - val_loss: 412.7894\n",
      "Epoch 275/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 277.2568 - val_loss: 785.2610\n",
      "Epoch 276/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 277.7878 - val_loss: 468.5586\n",
      "Epoch 277/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 304.0122 - val_loss: 371.5887\n",
      "Epoch 278/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 286.3307 - val_loss: 450.9185\n",
      "Epoch 279/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 254.9696 - val_loss: 342.4688\n",
      "Epoch 280/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 266.7875 - val_loss: 367.6822\n",
      "Epoch 281/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 263.2400 - val_loss: 977.8845\n",
      "Epoch 282/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 361.4907 - val_loss: 780.9420\n",
      "Epoch 283/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 329.5678 - val_loss: 428.1600\n",
      "Epoch 284/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 272.9745 - val_loss: 370.0956\n",
      "Epoch 285/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 289.9889 - val_loss: 350.8063\n",
      "Epoch 286/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 292.6236 - val_loss: 417.7499\n",
      "Epoch 287/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 290.8430 - val_loss: 934.5317\n",
      "Epoch 288/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 308.4249 - val_loss: 508.4698\n",
      "Epoch 289/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 269.3820 - val_loss: 836.7062\n",
      "Epoch 290/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 287.3694 - val_loss: 444.3741\n",
      "Epoch 291/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 256.1258 - val_loss: 391.9850\n",
      "Epoch 292/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 300.8184 - val_loss: 727.1666\n",
      "Epoch 293/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 327.6011 - val_loss: 331.1659\n",
      "Epoch 294/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 254.5836 - val_loss: 666.3080\n",
      "Epoch 295/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 318.1219 - val_loss: 774.0351\n",
      "Epoch 296/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 346.1528 - val_loss: 600.4352\n",
      "Epoch 297/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 354.7098 - val_loss: 415.3143\n",
      "Epoch 298/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 255.0411 - val_loss: 458.7138\n",
      "Epoch 299/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 295.9948 - val_loss: 519.0390\n",
      "Epoch 300/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 281.3876 - val_loss: 442.4037\n",
      "Epoch 301/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 354.7060 - val_loss: 463.7159\n",
      "Epoch 302/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 330.5353 - val_loss: 479.0652\n",
      "Epoch 303/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 336.7196 - val_loss: 601.7818\n",
      "Epoch 304/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 332.9263 - val_loss: 508.8015\n",
      "Epoch 305/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 319.7626 - val_loss: 488.5380\n",
      "Epoch 306/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 295.7954 - val_loss: 417.6720\n",
      "Epoch 307/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 336.8999 - val_loss: 496.0045\n",
      "Epoch 308/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 286.9225 - val_loss: 577.7917\n",
      "Epoch 309/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 320.8209 - val_loss: 504.1915\n",
      "Epoch 310/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 285.8768 - val_loss: 365.8288\n",
      "Epoch 311/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.8223 - val_loss: 325.6516\n",
      "Epoch 312/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 257.8080 - val_loss: 707.1099\n",
      "Epoch 313/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 405.8154 - val_loss: 444.1183\n",
      "Epoch 314/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 286.8599 - val_loss: 302.4537\n",
      "Epoch 315/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.8092 - val_loss: 360.5768\n",
      "Epoch 316/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 275.7972 - val_loss: 316.4964\n",
      "Epoch 317/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 309.9977 - val_loss: 760.9093\n",
      "Epoch 318/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 351.3087 - val_loss: 399.2849\n",
      "Epoch 319/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 289.0125 - val_loss: 656.7007\n",
      "Epoch 320/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 391.3496 - val_loss: 375.8720\n",
      "Epoch 321/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 300.3432 - val_loss: 364.9591\n",
      "Epoch 322/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 290.2363 - val_loss: 393.8518\n",
      "Epoch 323/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 269.4463 - val_loss: 393.9030\n",
      "Epoch 324/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 282.4023 - val_loss: 516.2133\n",
      "Epoch 325/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 262.9178 - val_loss: 397.0840\n",
      "Epoch 326/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 286.0416 - val_loss: 499.8296\n",
      "Epoch 327/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 261.1855 - val_loss: 633.6859\n",
      "Epoch 328/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 284.8645 - val_loss: 318.4127\n",
      "Epoch 329/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 242.6034 - val_loss: 482.6268\n",
      "Epoch 330/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 262.0796 - val_loss: 448.4373\n",
      "Epoch 331/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 278.7836 - val_loss: 436.6559\n",
      "Epoch 332/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 256.5264 - val_loss: 355.8337\n",
      "Epoch 333/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 245.8781 - val_loss: 372.2700\n",
      "Epoch 334/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 285.5857 - val_loss: 391.8853\n",
      "Epoch 335/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 262.0563 - val_loss: 573.3068\n",
      "Epoch 336/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 289.8619 - val_loss: 390.0798\n",
      "Epoch 337/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 232.1899 - val_loss: 362.9161\n",
      "Epoch 338/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 302.0529 - val_loss: 565.1993\n",
      "Epoch 339/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 292.1568 - val_loss: 1034.5294\n",
      "Epoch 340/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 345.9175 - val_loss: 362.7549\n",
      "Epoch 341/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 265.0202 - val_loss: 362.1190\n",
      "Epoch 342/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 250.9646 - val_loss: 443.9219\n",
      "Epoch 343/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 259.4106 - val_loss: 289.9077\n",
      "Epoch 344/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 251.4834 - val_loss: 380.4881\n",
      "Epoch 345/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 352.6299 - val_loss: 427.0034\n",
      "Epoch 346/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 340.5055 - val_loss: 379.1024\n",
      "Epoch 347/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 251.7736 - val_loss: 350.0496\n",
      "Epoch 348/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 251.2463 - val_loss: 421.6306\n",
      "Epoch 349/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 247.5159 - val_loss: 444.4464\n",
      "Epoch 350/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 319.7589 - val_loss: 449.3961\n",
      "Epoch 351/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 290.8422 - val_loss: 626.9454\n",
      "Epoch 352/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 291.7631 - val_loss: 476.9224\n",
      "Epoch 353/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 284.7830 - val_loss: 583.6743\n",
      "Epoch 354/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.7982 - val_loss: 486.8539\n",
      "Epoch 355/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 375.6902 - val_loss: 489.3212\n",
      "Epoch 356/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 330.6949 - val_loss: 842.2039\n",
      "Epoch 357/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 347.1650 - val_loss: 468.5156\n",
      "Epoch 358/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 308.4572 - val_loss: 1881.1998\n",
      "Epoch 359/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 533.8127 - val_loss: 311.1979\n",
      "Epoch 360/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 300.2303 - val_loss: 339.3805\n",
      "Epoch 361/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 273.5248 - val_loss: 333.8636\n",
      "Epoch 362/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 311.1564 - val_loss: 1062.1196\n",
      "Epoch 363/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 369.4012 - val_loss: 374.2766\n",
      "Epoch 364/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 259.5316 - val_loss: 341.6023\n",
      "Epoch 365/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 273.6633 - val_loss: 429.4129\n",
      "Epoch 366/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 332.2505 - val_loss: 698.2444\n",
      "Epoch 367/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 286.1981 - val_loss: 404.9530\n",
      "Epoch 368/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 283.9179 - val_loss: 410.4686\n",
      "Epoch 369/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 269.0726 - val_loss: 349.2822\n",
      "Epoch 370/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.8842 - val_loss: 723.0527\n",
      "Epoch 371/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 328.9130 - val_loss: 443.5681\n",
      "Epoch 372/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 309.1391 - val_loss: 530.2558\n",
      "Epoch 373/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 299.9137 - val_loss: 398.1404\n",
      "Epoch 374/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 269.5418 - val_loss: 406.9868\n",
      "Epoch 375/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 311.2021 - val_loss: 739.7222\n",
      "Epoch 376/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 319.1737 - val_loss: 326.6620\n",
      "Epoch 377/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 291.1930 - val_loss: 376.5952\n",
      "Epoch 378/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 262.3186 - val_loss: 516.4945\n",
      "Epoch 379/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 278.1309 - val_loss: 362.4544\n",
      "Epoch 380/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 302.6983 - val_loss: 308.7509\n",
      "Epoch 381/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 244.9233 - val_loss: 365.0587\n",
      "Epoch 382/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.3838 - val_loss: 315.8558\n",
      "Epoch 383/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 244.5670 - val_loss: 431.1504\n",
      "Epoch 384/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 274.1136 - val_loss: 319.3766\n",
      "Epoch 385/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.4981 - val_loss: 770.5445\n",
      "Epoch 386/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 369.0457 - val_loss: 403.4500\n",
      "Epoch 387/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 274.3345 - val_loss: 396.3241\n",
      "Epoch 388/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 272.0654 - val_loss: 357.0053\n",
      "Epoch 389/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 249.2776 - val_loss: 368.6666\n",
      "Epoch 390/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 230.3268 - val_loss: 440.5267\n",
      "Epoch 391/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 253.8275 - val_loss: 397.6816\n",
      "Epoch 392/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 267.8472 - val_loss: 655.1395\n",
      "Epoch 393/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 300.1844 - val_loss: 937.0245\n",
      "Epoch 394/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 423.0774 - val_loss: 557.7984\n",
      "Epoch 395/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.1320 - val_loss: 380.2339\n",
      "Epoch 396/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 270.7189 - val_loss: 462.9967\n",
      "Epoch 397/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 299.8446 - val_loss: 319.9293\n",
      "Epoch 398/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 231.2273 - val_loss: 362.1577\n",
      "Epoch 399/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 284.2878 - val_loss: 695.6083\n",
      "Epoch 400/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 367.2672 - val_loss: 488.2990\n",
      "Epoch 401/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 274.7784 - val_loss: 401.2133\n",
      "Epoch 402/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.4222 - val_loss: 393.7130\n",
      "Epoch 403/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 306.4850 - val_loss: 313.1285\n",
      "Epoch 404/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 344.9965 - val_loss: 916.6988\n",
      "Epoch 405/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 337.5516 - val_loss: 538.5333\n",
      "Epoch 406/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 293.6535 - val_loss: 355.6754\n",
      "Epoch 407/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 267.2134 - val_loss: 847.0813\n",
      "Epoch 408/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 347.0144 - val_loss: 687.2532\n",
      "Epoch 409/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 371.5243 - val_loss: 356.8567\n",
      "Epoch 410/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 274.7327 - val_loss: 452.4865\n",
      "Epoch 411/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 300.7041 - val_loss: 1122.1370\n",
      "Epoch 412/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 520.0564 - val_loss: 388.5723\n",
      "Epoch 413/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 296.7268 - val_loss: 331.4308\n",
      "Epoch 414/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 286.6583 - val_loss: 411.6240\n",
      "Epoch 415/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 281.2919 - val_loss: 392.7289\n",
      "Epoch 416/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 261.5922 - val_loss: 491.3641\n",
      "Epoch 417/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 329.8086 - val_loss: 377.2432\n",
      "Epoch 418/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 376.6036 - val_loss: 870.3708\n",
      "Epoch 419/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 309.5034 - val_loss: 309.4504\n",
      "Epoch 420/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 278.1441 - val_loss: 344.9480\n",
      "Epoch 421/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 263.3965 - val_loss: 319.8337\n",
      "Epoch 422/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.8178 - val_loss: 358.6803\n",
      "Epoch 423/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 254.3046 - val_loss: 492.9757\n",
      "Epoch 424/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 264.8149 - val_loss: 675.0726\n",
      "Epoch 425/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 354.8705 - val_loss: 382.9012\n",
      "Epoch 426/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 305.4610 - val_loss: 415.0458\n",
      "Epoch 427/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 342.1143 - val_loss: 493.6253\n",
      "Epoch 428/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 324.0457 - val_loss: 795.4468\n",
      "Epoch 429/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 338.9273 - val_loss: 558.9036\n",
      "Epoch 430/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 344.4235 - val_loss: 576.6739\n",
      "Epoch 431/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 316.8875 - val_loss: 306.5701\n",
      "Epoch 432/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 309.2525 - val_loss: 445.1661\n",
      "Epoch 433/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 282.6589 - val_loss: 322.2920\n",
      "Epoch 434/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 296.0360 - val_loss: 424.1796\n",
      "Epoch 435/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 301.8450 - val_loss: 564.1285\n",
      "Epoch 436/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 286.1642 - val_loss: 524.1157\n",
      "Epoch 437/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 328.8025 - val_loss: 358.0742\n",
      "Epoch 438/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 313.8266 - val_loss: 368.6364\n",
      "Epoch 439/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 301.5648 - val_loss: 336.3051\n",
      "Epoch 440/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 301.1524 - val_loss: 542.4749\n",
      "Epoch 441/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 388.6274 - val_loss: 371.3398\n",
      "Epoch 442/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.2194 - val_loss: 855.8560\n",
      "Epoch 443/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 394.0533 - val_loss: 400.9314\n",
      "Epoch 444/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 366.3683 - val_loss: 513.9716\n",
      "Epoch 445/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 306.4768 - val_loss: 635.5064\n",
      "Epoch 446/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 416.5677 - val_loss: 545.9803\n",
      "Epoch 447/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 356.6721 - val_loss: 315.0330\n",
      "Epoch 448/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 326.4247 - val_loss: 416.8606\n",
      "Epoch 449/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 314.8719 - val_loss: 839.6610\n",
      "Epoch 450/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 369.5152 - val_loss: 561.2747\n",
      "Epoch 451/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 309.3289 - val_loss: 354.3768\n",
      "Epoch 452/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 265.3469 - val_loss: 367.4039\n",
      "Epoch 453/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 273.1396 - val_loss: 703.3959\n",
      "Epoch 454/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 316.2480 - val_loss: 406.8150\n",
      "Epoch 455/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 314.0557 - val_loss: 404.7357\n",
      "Epoch 456/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 250.7431 - val_loss: 804.4815\n",
      "Epoch 457/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 357.0559 - val_loss: 381.9063\n",
      "Epoch 458/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 302.8060 - val_loss: 532.0323\n",
      "Epoch 459/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 346.7292 - val_loss: 439.0286\n",
      "Epoch 460/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 330.6477 - val_loss: 374.2611\n",
      "Epoch 461/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 293.5214 - val_loss: 584.9458\n",
      "Epoch 462/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 269.6924 - val_loss: 440.3993\n",
      "Epoch 463/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 300.2826 - val_loss: 473.3676\n",
      "Epoch 464/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 356.3186 - val_loss: 299.5853\n",
      "Epoch 465/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.0843 - val_loss: 429.8019\n",
      "Epoch 466/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 315.9033 - val_loss: 429.0277\n",
      "Epoch 467/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 352.2229 - val_loss: 496.6661\n",
      "Epoch 468/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 362.9164 - val_loss: 588.4240\n",
      "Epoch 469/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 336.4590 - val_loss: 439.0351\n",
      "Epoch 470/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 282.5345 - val_loss: 339.5977\n",
      "Epoch 471/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 299.3737 - val_loss: 626.0868\n",
      "Epoch 472/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 406.9850 - val_loss: 856.3788\n",
      "Epoch 473/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 369.0693 - val_loss: 516.1376\n",
      "Epoch 474/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 314.1018 - val_loss: 701.4774\n",
      "Epoch 475/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 444.9231 - val_loss: 904.0667\n",
      "Epoch 476/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 426.1083 - val_loss: 327.1424\n",
      "Epoch 477/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 294.1842 - val_loss: 328.9754\n",
      "Epoch 478/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 302.6453 - val_loss: 639.5095\n",
      "Epoch 479/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 297.5416 - val_loss: 516.4765\n",
      "Epoch 480/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 326.1388 - val_loss: 644.0700\n",
      "Epoch 481/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 427.9948 - val_loss: 481.0730\n",
      "Epoch 482/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 357.3460 - val_loss: 358.0935\n",
      "Epoch 483/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 327.8012 - val_loss: 371.7549\n",
      "Epoch 484/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 351.8394 - val_loss: 554.0593\n",
      "Epoch 485/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 330.2016 - val_loss: 461.3167\n",
      "Epoch 486/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 395.0928 - val_loss: 379.0293\n",
      "Epoch 487/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 343.6884 - val_loss: 364.9959\n",
      "Epoch 488/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 313.1997 - val_loss: 646.4352\n",
      "Epoch 489/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 361.8928 - val_loss: 397.8274\n",
      "Epoch 490/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 325.0888 - val_loss: 406.3820\n",
      "Epoch 491/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 343.4660 - val_loss: 861.8062\n",
      "Epoch 492/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 420.0512 - val_loss: 319.8172\n",
      "Epoch 493/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 393.1001 - val_loss: 433.1521\n",
      "Epoch 494/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 397.7066 - val_loss: 273.6280\n",
      "Epoch 495/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 324.3815 - val_loss: 549.2800\n",
      "Epoch 496/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 312.7271 - val_loss: 437.5719\n",
      "Epoch 497/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 405.9913 - val_loss: 728.0652\n",
      "Epoch 498/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 362.9168 - val_loss: 324.9977\n",
      "Epoch 499/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 294.8889 - val_loss: 407.5682\n",
      "Epoch 500/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 296.4745 - val_loss: 393.8003\n",
      "Epoch 501/10000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 250.9752 - val_loss: 359.7415\n",
      "Epoch 502/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 286.1526 - val_loss: 1143.1533\n",
      "Epoch 503/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 415.6223 - val_loss: 846.6887\n",
      "Epoch 504/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 378.1443 - val_loss: 497.2481\n",
      "Epoch 505/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 390.3745 - val_loss: 381.5662\n",
      "Epoch 506/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 346.5052 - val_loss: 366.6861\n",
      "Epoch 507/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 319.6317 - val_loss: 327.2361\n",
      "Epoch 508/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 310.4461 - val_loss: 399.0699\n",
      "Epoch 509/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 349.5543 - val_loss: 783.3820\n",
      "Epoch 510/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 476.0367 - val_loss: 475.3917\n",
      "Epoch 511/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 331.6011 - val_loss: 407.9355\n",
      "Epoch 512/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 295.6301 - val_loss: 428.7688\n",
      "Epoch 513/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 278.5739 - val_loss: 557.3067\n",
      "Epoch 514/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 302.7931 - val_loss: 431.6241\n",
      "Epoch 515/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 283.2768 - val_loss: 545.4838\n",
      "Epoch 516/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 412.1842 - val_loss: 353.4952\n",
      "Epoch 517/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 259.4970 - val_loss: 355.5948\n",
      "Epoch 518/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.4055 - val_loss: 413.3250\n",
      "Epoch 519/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 281.2686 - val_loss: 366.8297\n",
      "Epoch 520/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 273.3939 - val_loss: 664.9884\n",
      "Epoch 521/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 379.9924 - val_loss: 588.2378\n",
      "Epoch 522/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.2946 - val_loss: 3882.1052\n",
      "Epoch 523/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1291.7250 - val_loss: 347.9221\n",
      "Epoch 524/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 406.3103 - val_loss: 584.0829\n",
      "Epoch 525/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 427.4989 - val_loss: 328.7231\n",
      "Epoch 526/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 332.9213 - val_loss: 325.6548\n",
      "Epoch 527/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 341.5648 - val_loss: 908.9579\n",
      "Epoch 528/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 366.3631 - val_loss: 363.2973\n",
      "Epoch 529/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 362.6146 - val_loss: 534.9270\n",
      "Epoch 530/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 354.4400 - val_loss: 742.4226\n",
      "Epoch 531/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 374.3586 - val_loss: 1319.6606\n",
      "Epoch 532/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 468.1918 - val_loss: 497.1342\n",
      "Epoch 533/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 347.8986 - val_loss: 554.1537\n",
      "Epoch 534/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 353.9172 - val_loss: 530.2875\n",
      "Epoch 535/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 321.8774 - val_loss: 461.1469\n",
      "Epoch 536/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 333.1723 - val_loss: 414.8355\n",
      "Epoch 537/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 294.9533 - val_loss: 295.6035\n",
      "Epoch 538/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 256.9987 - val_loss: 501.0505\n",
      "Epoch 539/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 328.0640 - val_loss: 653.4362\n",
      "Epoch 540/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 290.0088 - val_loss: 349.9699\n",
      "Epoch 541/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 311.1607 - val_loss: 357.5555\n",
      "Epoch 542/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 353.1813 - val_loss: 423.6400\n",
      "Epoch 543/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 328.7793 - val_loss: 367.6637\n",
      "Epoch 544/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 290.2922 - val_loss: 378.2462\n",
      "Epoch 545/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 312.2123 - val_loss: 533.6519\n",
      "Epoch 546/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 247.4198 - val_loss: 337.2531\n",
      "Epoch 547/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 240.9212 - val_loss: 462.5240\n",
      "Epoch 548/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 326.2458 - val_loss: 493.2713\n",
      "Epoch 549/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 334.2296 - val_loss: 380.0546\n",
      "Epoch 550/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 289.2464 - val_loss: 395.0608\n",
      "Epoch 551/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 268.6952 - val_loss: 390.0970\n",
      "Epoch 552/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 272.4166 - val_loss: 493.7363\n",
      "Epoch 553/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 315.3102 - val_loss: 1013.7507\n",
      "Epoch 554/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 412.0795 - val_loss: 325.7045\n",
      "Epoch 555/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 348.8991 - val_loss: 355.8621\n",
      "Epoch 556/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 272.4604 - val_loss: 369.6121\n",
      "Epoch 557/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 284.4088 - val_loss: 352.5067\n",
      "Epoch 558/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 297.6170 - val_loss: 478.7343\n",
      "Epoch 559/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 282.6187 - val_loss: 459.6002\n",
      "Epoch 560/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 354.5807 - val_loss: 485.0243\n",
      "Epoch 561/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 287.9918 - val_loss: 662.5450\n",
      "Epoch 562/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 377.8107 - val_loss: 334.0134\n",
      "Epoch 563/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 312.4527 - val_loss: 468.4840\n",
      "Epoch 564/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 321.7647 - val_loss: 519.8737\n",
      "Epoch 565/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 293.3724 - val_loss: 530.9147\n",
      "Epoch 566/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 315.8545 - val_loss: 455.4432\n",
      "Epoch 567/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 267.4603 - val_loss: 437.8393\n",
      "Epoch 568/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 311.0068 - val_loss: 600.7890\n",
      "Epoch 569/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 281.8426 - val_loss: 311.5497\n",
      "Epoch 570/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 279.7521 - val_loss: 337.3380\n",
      "Epoch 571/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 318.7932 - val_loss: 411.7744\n",
      "Epoch 572/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 289.1685 - val_loss: 899.2668\n",
      "Epoch 573/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 343.9061 - val_loss: 604.1631\n",
      "Epoch 574/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 298.5496 - val_loss: 354.4828\n",
      "Epoch 575/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 263.6081 - val_loss: 320.7974\n",
      "Epoch 576/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 287.0727 - val_loss: 452.9449\n",
      "Epoch 577/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 359.8105 - val_loss: 402.2151\n",
      "Epoch 578/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 322.6248 - val_loss: 520.2617\n",
      "Epoch 579/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 327.6373 - val_loss: 470.4301\n",
      "Epoch 580/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 319.6266 - val_loss: 458.1542\n",
      "Epoch 581/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 372.5681 - val_loss: 379.4905\n",
      "Epoch 582/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 331.6360 - val_loss: 373.3300\n",
      "Epoch 583/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 325.1704 - val_loss: 348.1722\n",
      "Epoch 584/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 269.0177 - val_loss: 453.7813\n",
      "Epoch 585/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 361.0717 - val_loss: 427.1934\n",
      "Epoch 586/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 320.1309 - val_loss: 382.5504\n",
      "Epoch 587/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 266.2409 - val_loss: 542.3542\n",
      "Epoch 588/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 307.2470 - val_loss: 269.5016\n",
      "Epoch 589/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 283.3267 - val_loss: 1021.5461\n",
      "Epoch 590/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 298.2516 - val_loss: 455.7656\n",
      "Epoch 591/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 260.5154 - val_loss: 416.6512\n",
      "Epoch 592/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 281.0596 - val_loss: 358.5786\n",
      "Epoch 593/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 276.6019 - val_loss: 1069.5714\n",
      "Epoch 594/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 366.8079 - val_loss: 353.2463\n",
      "Epoch 595/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 340.4255 - val_loss: 359.8704\n",
      "Epoch 596/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 293.5879 - val_loss: 447.8392\n",
      "Epoch 597/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 307.5054 - val_loss: 447.4016\n",
      "Epoch 598/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 373.7184 - val_loss: 908.9489\n",
      "Epoch 599/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 371.5765 - val_loss: 855.5734\n",
      "Epoch 600/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 434.9663 - val_loss: 395.8739\n",
      "Epoch 601/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 315.3388 - val_loss: 499.3990\n",
      "Epoch 602/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 314.4144 - val_loss: 392.8829\n",
      "Epoch 603/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 285.4536 - val_loss: 475.5271\n",
      "Epoch 604/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 389.8936 - val_loss: 416.4156\n",
      "Epoch 605/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 283.1895 - val_loss: 428.9529\n",
      "Epoch 606/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 274.8136 - val_loss: 352.3074\n",
      "Epoch 607/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 283.0815 - val_loss: 1265.8094\n",
      "Epoch 608/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 568.5245 - val_loss: 395.5547\n",
      "Epoch 609/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 285.6106 - val_loss: 387.0785\n",
      "Epoch 610/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 308.2485 - val_loss: 718.5960\n",
      "Epoch 611/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 318.2481 - val_loss: 347.0991\n",
      "Epoch 612/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 310.0125 - val_loss: 537.9348\n",
      "Epoch 613/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 405.0599 - val_loss: 371.5545\n",
      "Epoch 614/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 359.2997 - val_loss: 549.8185\n",
      "Epoch 615/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 337.0522 - val_loss: 412.4826\n",
      "Epoch 616/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 353.9080 - val_loss: 958.9044\n",
      "Epoch 617/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 370.1948 - val_loss: 530.2998\n",
      "Epoch 618/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 342.7380 - val_loss: 331.7504\n",
      "Epoch 619/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 283.4894 - val_loss: 307.6985\n",
      "Epoch 620/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 302.9871 - val_loss: 677.4506\n",
      "Epoch 621/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 357.7041 - val_loss: 1032.7976\n",
      "Epoch 622/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 353.1949 - val_loss: 538.6718\n",
      "Epoch 623/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 280.3592 - val_loss: 349.0042\n",
      "Epoch 624/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 318.6338 - val_loss: 647.9489\n",
      "Epoch 625/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 275.9550 - val_loss: 957.4112\n",
      "Epoch 626/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 452.1341 - val_loss: 333.8711\n",
      "Epoch 627/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 306.4505 - val_loss: 349.9972\n",
      "Epoch 628/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 300.0502 - val_loss: 364.1573\n",
      "Epoch 629/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 289.7579 - val_loss: 385.4670\n",
      "Epoch 630/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 292.2244 - val_loss: 430.0888\n",
      "Epoch 631/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 312.4796 - val_loss: 353.6949\n",
      "Epoch 632/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 340.9243 - val_loss: 495.0082\n",
      "Epoch 633/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 295.9497 - val_loss: 424.7700\n",
      "Epoch 634/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 304.2260 - val_loss: 348.2378\n",
      "Epoch 635/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 301.7535 - val_loss: 386.2415\n",
      "Epoch 636/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 288.0280 - val_loss: 689.5907\n",
      "Epoch 637/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 405.0675 - val_loss: 413.2132\n",
      "Epoch 638/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 341.3334 - val_loss: 332.2693\n",
      "Epoch 639/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 359.9217 - val_loss: 437.0655\n",
      "Epoch 640/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 341.4660 - val_loss: 613.7889\n",
      "Epoch 641/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 396.7444 - val_loss: 317.8976\n",
      "Epoch 642/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 327.0119 - val_loss: 541.7287\n",
      "Epoch 643/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 406.2980 - val_loss: 337.5697\n",
      "Epoch 644/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 280.6100 - val_loss: 523.8117\n",
      "Epoch 645/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 298.6661 - val_loss: 410.3930\n",
      "Epoch 646/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 279.7210 - val_loss: 528.4523\n",
      "Epoch 647/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 326.3072 - val_loss: 492.6163\n",
      "Epoch 648/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 285.5323 - val_loss: 642.4091\n",
      "Epoch 649/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 371.6506 - val_loss: 523.5528\n",
      "Epoch 650/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 314.1185 - val_loss: 501.2178\n",
      "Epoch 651/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 374.8979 - val_loss: 611.5878\n",
      "Epoch 652/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 348.3955 - val_loss: 479.5114\n",
      "Epoch 653/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 298.4097 - val_loss: 562.0967\n",
      "Epoch 654/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 281.7094 - val_loss: 617.0672\n",
      "Epoch 655/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 281.4032 - val_loss: 349.8618\n",
      "Epoch 656/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 334.5615 - val_loss: 370.5031\n",
      "Epoch 657/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 270.1434 - val_loss: 464.5025\n",
      "Epoch 658/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 289.1718 - val_loss: 652.4699\n",
      "Epoch 659/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 305.9028 - val_loss: 375.6869\n",
      "Epoch 660/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 297.7286 - val_loss: 452.7036\n",
      "Epoch 661/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 240.8305 - val_loss: 609.2591\n",
      "Epoch 662/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 442.3860 - val_loss: 520.7535\n",
      "Epoch 663/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 382.8674 - val_loss: 410.6552\n",
      "Epoch 664/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 246.5312 - val_loss: 326.3310\n",
      "Epoch 665/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 292.0852 - val_loss: 378.6088\n",
      "Epoch 666/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 260.1028 - val_loss: 384.6910\n",
      "Epoch 667/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 266.8663 - val_loss: 345.5964\n",
      "Epoch 668/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 269.5876 - val_loss: 544.8928\n",
      "Epoch 669/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 308.7066 - val_loss: 577.5081\n",
      "Epoch 670/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 304.9084 - val_loss: 402.3070\n",
      "Epoch 671/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 300.6889 - val_loss: 501.1573\n",
      "Epoch 672/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 341.5975 - val_loss: 375.3893\n",
      "Epoch 673/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 251.3734 - val_loss: 446.3294\n",
      "Epoch 674/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 256.7924 - val_loss: 356.1493\n",
      "Epoch 675/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 266.4590 - val_loss: 563.4324\n",
      "Epoch 676/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 333.4808 - val_loss: 463.6725\n",
      "Epoch 677/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 286.9019 - val_loss: 401.6602\n",
      "Epoch 678/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 272.8486 - val_loss: 355.5123\n",
      "Epoch 679/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 241.5794 - val_loss: 691.0008\n",
      "Epoch 680/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 293.7123 - val_loss: 547.0950\n",
      "Epoch 681/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 285.4362 - val_loss: 468.2247\n",
      "Epoch 682/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 326.1023 - val_loss: 376.0739\n",
      "Epoch 683/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 246.7546 - val_loss: 524.8761\n",
      "Epoch 684/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 303.0070 - val_loss: 321.7595\n",
      "Epoch 685/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 268.4317 - val_loss: 344.9883\n",
      "Epoch 686/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 278.6579 - val_loss: 376.1003\n",
      "Epoch 687/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 281.2699 - val_loss: 1017.3410\n",
      "Epoch 688/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 475.8712 - val_loss: 595.1733\n",
      "Epoch 689/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 378.0710 - val_loss: 1347.9209\n",
      "Epoch 690/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 738.8538 - val_loss: 556.8015\n",
      "Epoch 691/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 407.8058 - val_loss: 645.7383\n",
      "Epoch 692/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 400.1317 - val_loss: 880.6616\n",
      "Epoch 693/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 455.2173 - val_loss: 740.1122\n",
      "Epoch 694/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 376.8475 - val_loss: 682.4531\n",
      "Epoch 695/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 322.7076 - val_loss: 510.9625\n",
      "Epoch 696/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 299.5199 - val_loss: 557.6809\n",
      "Epoch 697/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 325.0230 - val_loss: 409.7112\n",
      "Epoch 698/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 279.5348 - val_loss: 536.0866\n",
      "Epoch 699/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 316.5986 - val_loss: 461.7921\n",
      "Epoch 700/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 241.6248 - val_loss: 401.5715\n",
      "Epoch 701/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 321.3441 - val_loss: 789.4091\n",
      "Epoch 702/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 380.9790 - val_loss: 948.5738\n",
      "Epoch 703/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 380.0206 - val_loss: 437.3379\n",
      "Epoch 704/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 366.5064 - val_loss: 708.4280\n",
      "Epoch 705/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 314.2555 - val_loss: 550.8692\n",
      "Epoch 706/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 301.7326 - val_loss: 425.1912\n",
      "Epoch 707/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 304.5084 - val_loss: 461.7466\n",
      "Epoch 708/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 300.0836 - val_loss: 423.0769\n",
      "Epoch 709/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 327.1277 - val_loss: 491.1322\n",
      "Epoch 710/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 345.3951 - val_loss: 616.4875\n",
      "Epoch 711/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 319.6834 - val_loss: 469.7096\n",
      "Epoch 712/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 277.7524 - val_loss: 345.8103\n",
      "Epoch 713/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 272.4012 - val_loss: 384.5220\n",
      "Epoch 714/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 300.7743 - val_loss: 1045.4379\n",
      "Epoch 715/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 356.3631 - val_loss: 378.1428\n",
      "Epoch 716/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 267.3824 - val_loss: 805.3524\n",
      "Epoch 717/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 311.5833 - val_loss: 390.6057\n",
      "Epoch 718/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 325.8259 - val_loss: 485.6272\n",
      "Epoch 719/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 268.5602 - val_loss: 514.0884\n",
      "Epoch 720/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 265.1177 - val_loss: 444.0675\n",
      "Epoch 721/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 314.9372 - val_loss: 396.0652\n",
      "Epoch 722/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 280.2141 - val_loss: 872.9204\n",
      "Epoch 723/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 251.3714 - val_loss: 476.5049\n",
      "Epoch 724/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 320.4916 - val_loss: 368.3455\n",
      "Epoch 725/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 269.4847 - val_loss: 339.3750\n",
      "Epoch 726/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 326.0198 - val_loss: 304.9827\n",
      "Epoch 727/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 272.6212 - val_loss: 581.2919\n",
      "Epoch 728/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 283.6155 - val_loss: 395.3241\n",
      "Epoch 729/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 267.1624 - val_loss: 335.0500\n",
      "Epoch 730/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 247.3899 - val_loss: 289.3325\n",
      "Epoch 731/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 279.0539 - val_loss: 416.4549\n",
      "Epoch 732/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 344.8583 - val_loss: 342.0355\n",
      "Epoch 733/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 278.5728 - val_loss: 322.9797\n",
      "Epoch 734/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 303.2075 - val_loss: 427.7946\n",
      "Epoch 735/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 299.2654 - val_loss: 647.2640\n",
      "Epoch 736/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 277.3219 - val_loss: 295.4384\n",
      "Epoch 737/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 286.7664 - val_loss: 637.1088\n",
      "Epoch 738/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 317.7189 - val_loss: 682.6819\n",
      "Epoch 739/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 273.5587 - val_loss: 364.3453\n",
      "Epoch 740/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.2079 - val_loss: 339.0889\n",
      "Epoch 741/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 240.6509 - val_loss: 428.0045\n",
      "Epoch 742/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 293.7280 - val_loss: 396.4778\n",
      "Epoch 743/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 339.3513 - val_loss: 387.9568\n",
      "Epoch 744/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 250.6881 - val_loss: 321.8634\n",
      "Epoch 745/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 225.3903 - val_loss: 371.7980\n",
      "Epoch 746/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 214.3468 - val_loss: 387.1148\n",
      "Epoch 747/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 222.6624 - val_loss: 366.8018\n",
      "Epoch 748/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 249.5549 - val_loss: 489.0718\n",
      "Epoch 749/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 280.3932 - val_loss: 498.4161\n",
      "Epoch 750/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 257.0308 - val_loss: 421.9673\n",
      "Epoch 751/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 255.1801 - val_loss: 347.8689\n",
      "Epoch 752/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 278.5822 - val_loss: 476.9871\n",
      "Epoch 753/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 258.3835 - val_loss: 430.1326\n",
      "Epoch 754/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 225.0869 - val_loss: 384.9099\n",
      "Epoch 755/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 314.7021 - val_loss: 563.5005\n",
      "Epoch 756/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 298.4740 - val_loss: 735.4136\n",
      "Epoch 757/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 391.5966 - val_loss: 411.3283\n",
      "Epoch 758/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 247.9130 - val_loss: 423.7004\n",
      "Epoch 759/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 256.9192 - val_loss: 700.8549\n",
      "Epoch 760/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 297.6516 - val_loss: 473.2690\n",
      "Epoch 761/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 302.0237 - val_loss: 469.0559\n",
      "Epoch 762/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 253.4477 - val_loss: 390.6713\n",
      "Epoch 763/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 233.2408 - val_loss: 386.2344\n",
      "Epoch 764/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 269.5357 - val_loss: 423.8888\n",
      "Epoch 765/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 263.4359 - val_loss: 371.5399\n",
      "Epoch 766/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 248.8548 - val_loss: 452.6664\n",
      "Epoch 767/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.5938 - val_loss: 461.5582\n",
      "Epoch 768/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 254.9386 - val_loss: 433.8287\n",
      "Epoch 769/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 278.5781 - val_loss: 665.4409\n",
      "Epoch 770/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 299.3141 - val_loss: 323.2504\n",
      "Epoch 771/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 262.9166 - val_loss: 354.9920\n",
      "Epoch 772/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 245.5010 - val_loss: 291.1622\n",
      "Epoch 773/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 263.5033 - val_loss: 396.8578\n",
      "Epoch 774/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 254.5317 - val_loss: 396.9855\n",
      "Epoch 775/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 269.2151 - val_loss: 1390.2034\n",
      "Epoch 776/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 407.0034 - val_loss: 401.7961\n",
      "Epoch 777/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 273.5806 - val_loss: 443.6250\n",
      "Epoch 778/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 344.1535 - val_loss: 359.4368\n",
      "Epoch 779/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 269.5479 - val_loss: 335.4885\n",
      "Epoch 780/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 256.8417 - val_loss: 528.3072\n",
      "Epoch 781/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 277.2216 - val_loss: 521.3362\n",
      "Epoch 782/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 280.0605 - val_loss: 479.2928\n",
      "Epoch 783/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 246.2150 - val_loss: 360.3774\n",
      "Epoch 784/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 252.6574 - val_loss: 273.2647\n",
      "Epoch 785/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 264.6771 - val_loss: 310.7045\n",
      "Epoch 786/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 238.3303 - val_loss: 299.8317\n",
      "Epoch 787/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 244.9954 - val_loss: 564.1422\n",
      "Epoch 788/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 293.7650 - val_loss: 477.6233\n",
      "Epoch 789/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 286.9262 - val_loss: 329.1422\n",
      "Epoch 790/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 297.6910 - val_loss: 729.2345\n",
      "Epoch 791/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 422.3376 - val_loss: 482.9355\n",
      "Epoch 792/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 279.4257 - val_loss: 305.5878\n",
      "Epoch 793/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 273.1091 - val_loss: 392.9317\n",
      "Epoch 794/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.0947 - val_loss: 382.2719\n",
      "Epoch 795/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 273.8029 - val_loss: 709.3931\n",
      "Epoch 796/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 285.2617 - val_loss: 364.5760\n",
      "Epoch 797/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 236.9658 - val_loss: 400.2547\n",
      "Epoch 798/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 258.2507 - val_loss: 364.8164\n",
      "Epoch 799/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 258.3375 - val_loss: 904.9013\n",
      "Epoch 800/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 333.4428 - val_loss: 367.4765\n",
      "Epoch 801/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 264.7173 - val_loss: 292.7303\n",
      "Epoch 802/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 261.2752 - val_loss: 399.6349\n",
      "Epoch 803/10000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 255.4934 - val_loss: 294.3232\n",
      "Epoch 804/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 299.6407 - val_loss: 294.0795\n",
      "Epoch 805/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 255.3186 - val_loss: 243.5647\n",
      "Epoch 806/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 250.8853 - val_loss: 527.3044\n",
      "Epoch 807/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 289.5873 - val_loss: 328.3929\n",
      "Epoch 808/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 218.3859 - val_loss: 320.7001\n",
      "Epoch 809/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 237.3875 - val_loss: 351.0894\n",
      "Epoch 810/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 232.1958 - val_loss: 476.9359\n",
      "Epoch 811/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 259.9474 - val_loss: 922.9285\n",
      "Epoch 812/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 292.0756 - val_loss: 377.2111\n",
      "Epoch 813/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 265.9742 - val_loss: 597.7056\n",
      "Epoch 814/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.1407 - val_loss: 295.0310\n",
      "Epoch 815/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 295.0808 - val_loss: 999.8793\n",
      "Epoch 816/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 401.9513 - val_loss: 396.8676\n",
      "Epoch 817/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 270.3271 - val_loss: 521.5890\n",
      "Epoch 818/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 303.4843 - val_loss: 513.9581\n",
      "Epoch 819/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 322.1396 - val_loss: 399.6903\n",
      "Epoch 820/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 238.4946 - val_loss: 421.4615\n",
      "Epoch 821/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 245.6337 - val_loss: 317.6225\n",
      "Epoch 822/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 286.6656 - val_loss: 1095.8162\n",
      "Epoch 823/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 363.5974 - val_loss: 370.6881\n",
      "Epoch 824/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 279.3242 - val_loss: 1293.1564\n",
      "Epoch 825/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 636.3346 - val_loss: 680.6975\n",
      "Epoch 826/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 506.4810 - val_loss: 493.9428\n",
      "Epoch 827/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 390.3231 - val_loss: 585.0133\n",
      "Epoch 828/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 327.6547 - val_loss: 378.8452\n",
      "Epoch 829/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 289.0863 - val_loss: 1099.1544\n",
      "Epoch 830/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 391.1453 - val_loss: 387.5666\n",
      "Epoch 831/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 366.3589 - val_loss: 835.3300\n",
      "Epoch 832/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 361.2320 - val_loss: 367.5936\n",
      "Epoch 833/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 307.4167 - val_loss: 439.7674\n",
      "Epoch 834/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 306.3680 - val_loss: 527.4203\n",
      "Epoch 835/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 311.6394 - val_loss: 359.1105\n",
      "Epoch 836/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 292.6722 - val_loss: 714.2100\n",
      "Epoch 837/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 310.8591 - val_loss: 330.5071\n",
      "Epoch 838/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 269.0307 - val_loss: 461.0339\n",
      "Epoch 839/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 255.5326 - val_loss: 378.1044\n",
      "Epoch 840/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 317.8070 - val_loss: 487.4227\n",
      "Epoch 841/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 317.2924 - val_loss: 395.5699\n",
      "Epoch 842/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 349.8269 - val_loss: 375.2027\n",
      "Epoch 843/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 277.6610 - val_loss: 504.9541\n",
      "Epoch 844/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 245.4810 - val_loss: 395.1663\n",
      "Epoch 845/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 263.1216 - val_loss: 394.8983\n",
      "Epoch 846/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 266.0039 - val_loss: 608.0155\n",
      "Epoch 847/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 345.8081 - val_loss: 426.7601\n",
      "Epoch 848/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 301.8677 - val_loss: 621.4606\n",
      "Epoch 849/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 295.4208 - val_loss: 375.9826\n",
      "Epoch 850/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 280.1605 - val_loss: 403.1184\n",
      "Epoch 851/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 268.4930 - val_loss: 387.7897\n",
      "Epoch 852/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 269.4388 - val_loss: 423.4555\n",
      "Epoch 853/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 271.3017 - val_loss: 494.6280\n",
      "Epoch 854/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 308.1317 - val_loss: 507.4140\n",
      "Epoch 855/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 257.0206 - val_loss: 440.2228\n",
      "Epoch 856/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 267.9802 - val_loss: 429.5280\n",
      "Epoch 857/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 247.4511 - val_loss: 451.7174\n",
      "Epoch 858/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 265.0512 - val_loss: 455.3371\n",
      "Epoch 859/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 257.0363 - val_loss: 477.7701\n",
      "Epoch 860/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 257.8878 - val_loss: 455.6514\n",
      "Epoch 861/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 266.7603 - val_loss: 863.5900\n",
      "Epoch 862/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 601.1968 - val_loss: 474.0839\n",
      "Epoch 863/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 350.6314 - val_loss: 542.2185\n",
      "Epoch 864/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 370.3309 - val_loss: 626.1864\n",
      "Epoch 865/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 386.1497 - val_loss: 494.2256\n",
      "Epoch 866/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.0281 - val_loss: 534.3220\n",
      "Epoch 867/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 339.2342 - val_loss: 400.5355\n",
      "Epoch 868/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.9470 - val_loss: 655.0656\n",
      "Epoch 869/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 315.6411 - val_loss: 364.6253\n",
      "Epoch 870/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 294.9890 - val_loss: 283.5420\n",
      "Epoch 871/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 623.6173 - val_loss: 549.7827\n",
      "Epoch 872/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 322.3087 - val_loss: 432.8309\n",
      "Epoch 873/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 330.2010 - val_loss: 435.6228\n",
      "Epoch 874/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 330.6235 - val_loss: 413.5455\n",
      "Epoch 875/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 297.0977 - val_loss: 364.3261\n",
      "Epoch 876/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 285.3956 - val_loss: 392.2485\n",
      "Epoch 877/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 294.4023 - val_loss: 430.4123\n",
      "Epoch 878/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 261.2549 - val_loss: 379.1936\n",
      "Epoch 879/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 295.0307 - val_loss: 352.0092\n",
      "Epoch 880/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 268.4478 - val_loss: 474.7897\n",
      "Epoch 881/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 274.7220 - val_loss: 490.5477\n",
      "Epoch 882/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 313.7118 - val_loss: 371.8663\n",
      "Epoch 883/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 320.5414 - val_loss: 340.6200\n",
      "Epoch 884/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 295.4444 - val_loss: 400.2469\n",
      "Epoch 885/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 308.6827 - val_loss: 519.2581\n",
      "Epoch 886/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 293.8119 - val_loss: 464.3375\n",
      "Epoch 887/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 310.7310 - val_loss: 530.7415\n",
      "Epoch 888/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 334.3258 - val_loss: 420.3726\n",
      "Epoch 889/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 291.3788 - val_loss: 411.3856\n",
      "Epoch 890/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 263.6366 - val_loss: 679.5270\n",
      "Epoch 891/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 312.4596 - val_loss: 517.8259\n",
      "Epoch 892/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 329.4171 - val_loss: 352.4126\n",
      "Epoch 893/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 290.4218 - val_loss: 436.4467\n",
      "Epoch 894/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 252.1610 - val_loss: 462.6371\n",
      "Epoch 895/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 245.5007 - val_loss: 398.2726\n",
      "Epoch 896/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 317.7831 - val_loss: 931.8351\n",
      "Epoch 897/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 466.1429 - val_loss: 397.6611\n",
      "Epoch 898/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 278.5116 - val_loss: 359.7312\n",
      "Epoch 899/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 231.1542 - val_loss: 446.0831\n",
      "Epoch 900/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 279.7232 - val_loss: 862.1038\n",
      "Epoch 901/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 332.6568 - val_loss: 347.7457\n",
      "Epoch 902/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.1157 - val_loss: 592.0404\n",
      "Epoch 903/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 374.3126 - val_loss: 364.2490\n",
      "Epoch 904/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.0573 - val_loss: 509.6321\n",
      "Epoch 905/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 308.9801 - val_loss: 422.8716\n",
      "Epoch 906/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 332.8873 - val_loss: 967.7305\n",
      "Epoch 907/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 376.3417 - val_loss: 837.2869\n",
      "Epoch 908/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 359.0238 - val_loss: 486.7492\n",
      "Epoch 909/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 300.2169 - val_loss: 962.4851\n",
      "Epoch 910/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 350.0035 - val_loss: 476.8968\n",
      "Epoch 911/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 326.9395 - val_loss: 588.7227\n",
      "Epoch 912/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 341.8121 - val_loss: 464.9034\n",
      "Epoch 913/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.1279 - val_loss: 603.3774\n",
      "Epoch 914/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 283.5261 - val_loss: 696.6646\n",
      "Epoch 915/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 379.0317 - val_loss: 557.0693\n",
      "Epoch 916/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 300.1498 - val_loss: 467.9259\n",
      "Epoch 917/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 276.2017 - val_loss: 355.1262\n",
      "Epoch 918/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 253.9645 - val_loss: 612.6942\n",
      "Epoch 919/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 353.5286 - val_loss: 376.0599\n",
      "Epoch 920/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 308.5184 - val_loss: 369.8041\n",
      "Epoch 921/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 252.8105 - val_loss: 511.1861\n",
      "Epoch 922/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 336.9081 - val_loss: 315.0697\n",
      "Epoch 923/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 388.8950 - val_loss: 455.0315\n",
      "Epoch 924/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 226.9326 - val_loss: 371.0879\n",
      "Epoch 925/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 258.4630 - val_loss: 339.5951\n",
      "Epoch 926/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 278.4755 - val_loss: 635.7665\n",
      "Epoch 927/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 392.5302 - val_loss: 585.5373\n",
      "Epoch 928/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 320.6152 - val_loss: 356.5794\n",
      "Epoch 929/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 265.8452 - val_loss: 363.2478\n",
      "Epoch 930/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 283.1212 - val_loss: 884.8585\n",
      "Epoch 931/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 342.3285 - val_loss: 364.7415\n",
      "Epoch 932/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 280.8664 - val_loss: 461.3673\n",
      "Epoch 933/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.2039 - val_loss: 370.6358\n",
      "Epoch 934/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 18:02:55.958956: W tensorflow/core/data/root_dataset.cc:286] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 241.2128 - val_loss: 399.0524\n",
      "Epoch 935/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 244.8136 - val_loss: 860.3004\n",
      "Epoch 936/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 455.7286 - val_loss: 297.6747\n",
      "Epoch 937/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 270.0189 - val_loss: 519.9092\n",
      "Epoch 938/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 344.0968 - val_loss: 430.6020\n",
      "Epoch 939/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 252.9184 - val_loss: 351.1209\n",
      "Epoch 940/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 285.0843 - val_loss: 329.9715\n",
      "Epoch 941/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 265.7555 - val_loss: 299.9825\n",
      "Epoch 942/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 244.2556 - val_loss: 372.1508\n",
      "Epoch 943/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 256.5317 - val_loss: 311.5416\n",
      "Epoch 944/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 238.3728 - val_loss: 402.9598\n",
      "Epoch 945/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 280.2842 - val_loss: 325.0412\n",
      "Epoch 946/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 270.6255 - val_loss: 494.9189\n",
      "Epoch 947/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 351.1904 - val_loss: 304.8816\n",
      "Epoch 948/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.9201 - val_loss: 311.0165\n",
      "Epoch 949/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 245.4328 - val_loss: 446.5554\n",
      "Epoch 950/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 304.0275 - val_loss: 427.3309\n",
      "Epoch 951/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 285.1453 - val_loss: 775.1127\n",
      "Epoch 952/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 373.0630 - val_loss: 449.5186\n",
      "Epoch 953/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.9891 - val_loss: 397.0236\n",
      "Epoch 954/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 265.9511 - val_loss: 494.5380\n",
      "Epoch 955/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 264.4033 - val_loss: 402.6451\n",
      "Epoch 956/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 287.6826 - val_loss: 545.3336\n",
      "Epoch 957/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 277.7624 - val_loss: 389.7209\n",
      "Epoch 958/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 231.2202 - val_loss: 336.9612\n",
      "Epoch 959/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 259.3419 - val_loss: 480.4914\n",
      "Epoch 960/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 260.4497 - val_loss: 386.5271\n",
      "Epoch 961/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 259.8997 - val_loss: 620.7164\n",
      "Epoch 962/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 328.7191 - val_loss: 522.3547\n",
      "Epoch 963/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 280.4698 - val_loss: 292.8526\n",
      "Epoch 964/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 229.2277 - val_loss: 274.0975\n",
      "Epoch 965/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 267.1299 - val_loss: 385.8978\n",
      "Epoch 966/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 275.1090 - val_loss: 684.8090\n",
      "Epoch 967/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 348.3510 - val_loss: 440.0731\n",
      "Epoch 968/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 283.9202 - val_loss: 255.5417\n",
      "Epoch 969/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 259.1337 - val_loss: 286.3548\n",
      "Epoch 970/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 265.7488 - val_loss: 365.3287\n",
      "Epoch 971/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 342.4685 - val_loss: 542.5607\n",
      "Epoch 972/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 313.1479 - val_loss: 404.2850\n",
      "Epoch 973/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 236.7184 - val_loss: 511.4217\n",
      "Epoch 974/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 218.1473 - val_loss: 411.5508\n",
      "Epoch 975/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 243.8134 - val_loss: 439.2996\n",
      "Epoch 976/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 254.1469 - val_loss: 394.9873\n",
      "Epoch 977/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 258.3153 - val_loss: 500.6631\n",
      "Epoch 978/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 250.4209 - val_loss: 485.1044\n",
      "Epoch 979/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 262.4510 - val_loss: 363.8989\n",
      "Epoch 980/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 362.2090 - val_loss: 448.7798\n",
      "Epoch 981/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 328.8886 - val_loss: 377.0833\n",
      "Epoch 982/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 244.7631 - val_loss: 447.3441\n",
      "Epoch 983/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 274.4511 - val_loss: 452.1038\n",
      "Epoch 984/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.2893 - val_loss: 383.5748\n",
      "Epoch 985/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 336.5833 - val_loss: 534.6110\n",
      "Epoch 986/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 369.1674 - val_loss: 749.5606\n",
      "Epoch 987/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 444.9049 - val_loss: 326.3421\n",
      "Epoch 988/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 272.6292 - val_loss: 522.8190\n",
      "Epoch 989/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 326.9431 - val_loss: 344.3089\n",
      "Epoch 990/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 307.2586 - val_loss: 291.2094\n",
      "Epoch 991/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 275.8103 - val_loss: 375.3555\n",
      "Epoch 992/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 334.3786 - val_loss: 934.8292\n",
      "Epoch 993/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 390.1508 - val_loss: 466.0291\n",
      "Epoch 994/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 266.1234 - val_loss: 494.7872\n",
      "Epoch 995/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 279.6683 - val_loss: 412.6010\n",
      "Epoch 996/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 259.3822 - val_loss: 391.7083\n",
      "Epoch 997/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 291.1905 - val_loss: 387.0259\n",
      "Epoch 998/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 290.8906 - val_loss: 438.9695\n",
      "Epoch 999/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 280.2567 - val_loss: 343.3817\n",
      "Epoch 1000/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 248.7431 - val_loss: 308.1572\n",
      "Epoch 1001/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 233.4832 - val_loss: 1002.3976\n",
      "Epoch 1002/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 430.2011 - val_loss: 334.3000\n",
      "Epoch 1003/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 272.1939 - val_loss: 532.1085\n",
      "Epoch 1004/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 302.3162 - val_loss: 477.7582\n",
      "Epoch 1005/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 255.1107 - val_loss: 521.4005\n",
      "Epoch 1006/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 285.0201 - val_loss: 542.6536\n",
      "Epoch 1007/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 267.0992 - val_loss: 296.8769\n",
      "Epoch 1008/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 297.4702 - val_loss: 394.7180\n",
      "Epoch 1009/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 272.7459 - val_loss: 365.4253\n",
      "Epoch 1010/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 270.3972 - val_loss: 392.6367\n",
      "Epoch 1011/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 281.3061 - val_loss: 396.2209\n",
      "Epoch 1012/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 248.9933 - val_loss: 374.7850\n",
      "Epoch 1013/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.2557 - val_loss: 539.9560\n",
      "Epoch 1014/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 308.3341 - val_loss: 257.5982\n",
      "Epoch 1015/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 249.4290 - val_loss: 391.0281\n",
      "Epoch 1016/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 250.4693 - val_loss: 742.4399\n",
      "Epoch 1017/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 322.6458 - val_loss: 366.6315\n",
      "Epoch 1018/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 236.8901 - val_loss: 536.6661\n",
      "Epoch 1019/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 284.8983 - val_loss: 565.4484\n",
      "Epoch 1020/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 359.8176 - val_loss: 320.6050\n",
      "Epoch 1021/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 253.3007 - val_loss: 319.0681\n",
      "Epoch 1022/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 215.8044 - val_loss: 275.6329\n",
      "Epoch 1023/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 233.8129 - val_loss: 388.2436\n",
      "Epoch 1024/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 305.1219 - val_loss: 326.0544\n",
      "Epoch 1025/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 252.4031 - val_loss: 473.4081\n",
      "Epoch 1026/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 249.0001 - val_loss: 436.4001\n",
      "Epoch 1027/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 277.9141 - val_loss: 621.1036\n",
      "Epoch 1028/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 326.3898 - val_loss: 538.1155\n",
      "Epoch 1029/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 287.9065 - val_loss: 660.1454\n",
      "Epoch 1030/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 381.3885 - val_loss: 430.2224\n",
      "Epoch 1031/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 242.6707 - val_loss: 747.3622\n",
      "Epoch 1032/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 355.9676 - val_loss: 358.4766\n",
      "Epoch 1033/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 294.4510 - val_loss: 346.1336\n",
      "Epoch 1034/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 243.2400 - val_loss: 356.4567\n",
      "Epoch 1035/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 320.9399 - val_loss: 624.6826\n",
      "Epoch 1036/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 328.5521 - val_loss: 611.0917\n",
      "Epoch 1037/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 310.3160 - val_loss: 405.2348\n",
      "Epoch 1038/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 254.9965 - val_loss: 373.6841\n",
      "Epoch 1039/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 223.2928 - val_loss: 369.7414\n",
      "Epoch 1040/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 301.9305 - val_loss: 523.2014\n",
      "Epoch 1041/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 287.8116 - val_loss: 521.3177\n",
      "Epoch 1042/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.0710 - val_loss: 457.7178\n",
      "Epoch 1043/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 256.9471 - val_loss: 340.9184\n",
      "Epoch 1044/10000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 221.6435 - val_loss: 311.7924\n",
      "Epoch 1045/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 246.2695 - val_loss: 304.4331\n",
      "Epoch 1046/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 241.0092 - val_loss: 304.9992\n",
      "Epoch 1047/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 247.8206 - val_loss: 498.2601\n",
      "Epoch 1048/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 256.0600 - val_loss: 424.8269\n",
      "Epoch 1049/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 236.2463 - val_loss: 355.1801\n",
      "Epoch 1050/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 200.7050 - val_loss: 613.9946\n",
      "Epoch 1051/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 314.2320 - val_loss: 298.1263\n",
      "Epoch 1052/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 206.8022 - val_loss: 419.4762\n",
      "Epoch 1053/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 218.1037 - val_loss: 336.4630\n",
      "Epoch 1054/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 215.0189 - val_loss: 354.0424\n",
      "Epoch 1055/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 252.6156 - val_loss: 300.1738\n",
      "Epoch 1056/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 267.4414 - val_loss: 287.4248\n",
      "Epoch 1057/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 225.8515 - val_loss: 325.1832\n",
      "Epoch 1058/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 255.1827 - val_loss: 337.3990\n",
      "Epoch 1059/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 250.2643 - val_loss: 479.3811\n",
      "Epoch 1060/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 254.4679 - val_loss: 510.9287\n",
      "Epoch 1061/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 303.0112 - val_loss: 579.0201\n",
      "Epoch 1062/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 310.6459 - val_loss: 364.9608\n",
      "Epoch 1063/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 237.1851 - val_loss: 570.5362\n",
      "Epoch 1064/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 357.6847 - val_loss: 432.5526\n",
      "Epoch 1065/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 221.5321 - val_loss: 575.2784\n",
      "Epoch 1066/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 255.1389 - val_loss: 301.7149\n",
      "Epoch 1067/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 201.5654 - val_loss: 403.9100\n",
      "Epoch 1068/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 229.6760 - val_loss: 311.6534\n",
      "Epoch 1069/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 287.8923 - val_loss: 315.7572\n",
      "Epoch 1070/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 304.6385 - val_loss: 347.8958\n",
      "Epoch 1071/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 270.8931 - val_loss: 330.7764\n",
      "Epoch 1072/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 309.3483 - val_loss: 334.5660\n",
      "Epoch 1073/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 270.2503 - val_loss: 465.8372\n",
      "Epoch 1074/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 243.2453 - val_loss: 426.7543\n",
      "Epoch 1075/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 255.9617 - val_loss: 365.5803\n",
      "Epoch 1076/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 244.1796 - val_loss: 574.0622\n",
      "Epoch 1077/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 307.7414 - val_loss: 554.2571\n",
      "Epoch 1078/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 318.4534 - val_loss: 391.6487\n",
      "Epoch 1079/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 227.9547 - val_loss: 316.9275\n",
      "Epoch 1080/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 230.9550 - val_loss: 538.1511\n",
      "Epoch 1081/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 243.7851 - val_loss: 487.1430\n",
      "Epoch 1082/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 329.5965 - val_loss: 320.7507\n",
      "Epoch 1083/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 233.6127 - val_loss: 438.1076\n",
      "Epoch 1084/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 263.4056 - val_loss: 310.1094\n",
      "Epoch 1085/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 252.3473 - val_loss: 296.7942\n",
      "Epoch 1086/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 288.2263 - val_loss: 332.7765\n",
      "Epoch 1087/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 240.5526 - val_loss: 466.9331\n",
      "Epoch 1088/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 265.3581 - val_loss: 589.5199\n",
      "Epoch 1089/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 302.6809 - val_loss: 476.7389\n",
      "Epoch 1090/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 279.3608 - val_loss: 835.0477\n",
      "Epoch 1091/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 365.8857 - val_loss: 322.8965\n",
      "Epoch 1092/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 237.2267 - val_loss: 630.1769\n",
      "Epoch 1093/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 280.1825 - val_loss: 316.8953\n",
      "Epoch 1094/10000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 294.8919 - val_loss: 361.4879\n",
      "Epoch 1095/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 290.5695 - val_loss: 327.9219\n",
      "Epoch 1096/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 229.7226 - val_loss: 343.6467\n",
      "Epoch 1097/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 221.1119 - val_loss: 382.8826\n",
      "Epoch 1098/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 180.5489 - val_loss: 361.9948\n",
      "Epoch 1099/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 221.2888 - val_loss: 441.0081\n",
      "Epoch 1100/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 238.2950 - val_loss: 355.5997\n",
      "Epoch 1101/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 212.3536 - val_loss: 237.1069\n",
      "Epoch 1102/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 218.0345 - val_loss: 484.5094\n",
      "Epoch 1103/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 232.5049 - val_loss: 469.3008\n",
      "Epoch 1104/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 245.4280 - val_loss: 471.6406\n",
      "Epoch 1105/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 308.3654 - val_loss: 633.2527\n",
      "Epoch 1106/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 289.4500 - val_loss: 569.8020\n",
      "Epoch 1107/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 277.4515 - val_loss: 503.8758\n",
      "Epoch 1108/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 356.5137 - val_loss: 440.7029\n",
      "Epoch 1109/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 270.8578 - val_loss: 426.4938\n",
      "Epoch 1110/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 228.7215 - val_loss: 553.2938\n",
      "Epoch 1111/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 236.8253 - val_loss: 424.1337\n",
      "Epoch 1112/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 241.7075 - val_loss: 338.6329\n",
      "Epoch 1113/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 239.6153 - val_loss: 434.4048\n",
      "Epoch 1114/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 273.2584 - val_loss: 965.2573\n",
      "Epoch 1115/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 478.6867 - val_loss: 520.7405\n",
      "Epoch 1116/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 266.4926 - val_loss: 383.1021\n",
      "Epoch 1117/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 297.1202 - val_loss: 426.9037\n",
      "Epoch 1118/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 265.4413 - val_loss: 392.3943\n",
      "Epoch 1119/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 241.1099 - val_loss: 348.9152\n",
      "Epoch 1120/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 258.3187 - val_loss: 758.0874\n",
      "Epoch 1121/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 360.1136 - val_loss: 570.6611\n",
      "Epoch 1122/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 292.7732 - val_loss: 723.6530\n",
      "Epoch 1123/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 364.2390 - val_loss: 368.2189\n",
      "Epoch 1124/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 255.0610 - val_loss: 418.3187\n",
      "Epoch 1125/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 337.7744 - val_loss: 483.9012\n",
      "Epoch 1126/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 283.7650 - val_loss: 387.0716\n",
      "Epoch 1127/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 274.6504 - val_loss: 428.5807\n",
      "Epoch 1128/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 262.5520 - val_loss: 731.5188\n",
      "Epoch 1129/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 323.2913 - val_loss: 356.3258\n",
      "Epoch 1130/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 250.0251 - val_loss: 409.4740\n",
      "Epoch 1131/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 256.0465 - val_loss: 394.6479\n",
      "Epoch 1132/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 320.3902 - val_loss: 331.4162\n",
      "Epoch 1133/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 245.8412 - val_loss: 576.3000\n",
      "Epoch 1134/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 320.8942 - val_loss: 369.2721\n",
      "Epoch 1135/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 256.2108 - val_loss: 385.0645\n",
      "Epoch 1136/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 230.7539 - val_loss: 331.9478\n",
      "Epoch 1137/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 226.2847 - val_loss: 406.1295\n",
      "Epoch 1138/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 247.0161 - val_loss: 346.4914\n",
      "Epoch 1139/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 286.3671 - val_loss: 441.1318\n",
      "Epoch 1140/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 315.5939 - val_loss: 986.2070\n",
      "Epoch 1141/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 406.7129 - val_loss: 472.7037\n",
      "Epoch 1142/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 378.5472 - val_loss: 903.3121\n",
      "Epoch 1143/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 435.9085 - val_loss: 317.8095\n",
      "Epoch 1144/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 271.2934 - val_loss: 373.5590\n",
      "Epoch 1145/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 246.3363 - val_loss: 483.8529\n",
      "Epoch 1146/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 222.3484 - val_loss: 383.2408\n",
      "Epoch 1147/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 229.6722 - val_loss: 937.7600\n",
      "Epoch 1148/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 303.0928 - val_loss: 442.5643\n",
      "Epoch 1149/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 246.0837 - val_loss: 400.1408\n",
      "Epoch 1150/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 278.8664 - val_loss: 425.2160\n",
      "Epoch 1151/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 259.6677 - val_loss: 522.1440\n",
      "Epoch 1152/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 258.3977 - val_loss: 504.4410\n",
      "Epoch 1153/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 215.5919 - val_loss: 563.9958\n",
      "Epoch 1154/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 265.1882 - val_loss: 424.1279\n",
      "Epoch 1155/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 245.1007 - val_loss: 548.5698\n",
      "Epoch 1156/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 235.8283 - val_loss: 312.3887\n",
      "Epoch 1157/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 219.0110 - val_loss: 316.7502\n",
      "Epoch 1158/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 232.6449 - val_loss: 389.1044\n",
      "Epoch 1159/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 230.7135 - val_loss: 881.7074\n",
      "Epoch 1160/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 404.5734 - val_loss: 294.3549\n",
      "Epoch 1161/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 379.7358 - val_loss: 233.4452\n",
      "Epoch 1162/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 297.4497 - val_loss: 273.6067\n",
      "Epoch 1163/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 261.6648 - val_loss: 452.9281\n",
      "Epoch 1164/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 300.3464 - val_loss: 346.2288\n",
      "Epoch 1165/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.4117 - val_loss: 637.9978\n",
      "Epoch 1166/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 295.6957 - val_loss: 378.0139\n",
      "Epoch 1167/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 234.9388 - val_loss: 338.9599\n",
      "Epoch 1168/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 229.1862 - val_loss: 321.3444\n",
      "Epoch 1169/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 215.9020 - val_loss: 512.6724\n",
      "Epoch 1170/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 313.2608 - val_loss: 546.1807\n",
      "Epoch 1171/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 314.4601 - val_loss: 475.6306\n",
      "Epoch 1172/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 304.5268 - val_loss: 898.9324\n",
      "Epoch 1173/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 354.2944 - val_loss: 450.0577\n",
      "Epoch 1174/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 307.5730 - val_loss: 442.1701\n",
      "Epoch 1175/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.7715 - val_loss: 449.0230\n",
      "Epoch 1176/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 269.1843 - val_loss: 434.9751\n",
      "Epoch 1177/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 254.4373 - val_loss: 875.4995\n",
      "Epoch 1178/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 354.6615 - val_loss: 465.6598\n",
      "Epoch 1179/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 252.8094 - val_loss: 627.5394\n",
      "Epoch 1180/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.8018 - val_loss: 424.4635\n",
      "Epoch 1181/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 220.6508 - val_loss: 492.6818\n",
      "Epoch 1182/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 260.2043 - val_loss: 375.0988\n",
      "Epoch 1183/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 227.4722 - val_loss: 444.9572\n",
      "Epoch 1184/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 250.9908 - val_loss: 523.4481\n",
      "Epoch 1185/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 259.9672 - val_loss: 388.6736\n",
      "Epoch 1186/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 293.5487 - val_loss: 486.3799\n",
      "Epoch 1187/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 245.5392 - val_loss: 836.9055\n",
      "Epoch 1188/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 313.8267 - val_loss: 502.3202\n",
      "Epoch 1189/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.5220 - val_loss: 702.4822\n",
      "Epoch 1190/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 282.2253 - val_loss: 459.7115\n",
      "Epoch 1191/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 342.8869 - val_loss: 595.1050\n",
      "Epoch 1192/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 266.1273 - val_loss: 514.1298\n",
      "Epoch 1193/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 244.5894 - val_loss: 621.4061\n",
      "Epoch 1194/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 275.0005 - val_loss: 366.8103\n",
      "Epoch 1195/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 230.9413 - val_loss: 474.1829\n",
      "Epoch 1196/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 271.6552 - val_loss: 390.0512\n",
      "Epoch 1197/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 211.7054 - val_loss: 500.1309\n",
      "Epoch 1198/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 241.9278 - val_loss: 417.6185\n",
      "Epoch 1199/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 258.8731 - val_loss: 331.6372\n",
      "Epoch 1200/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 226.5917 - val_loss: 576.3871\n",
      "Epoch 1201/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 263.7210 - val_loss: 359.8903\n",
      "Epoch 1202/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 242.6205 - val_loss: 721.4812\n",
      "Epoch 1203/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 287.0235 - val_loss: 538.3574\n",
      "Epoch 1204/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 298.4993 - val_loss: 979.9603\n",
      "Epoch 1205/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 334.1863 - val_loss: 468.0702\n",
      "Epoch 1206/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.6276 - val_loss: 321.6281\n",
      "Epoch 1207/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 256.9186 - val_loss: 617.4570\n",
      "Epoch 1208/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 304.0852 - val_loss: 354.1163\n",
      "Epoch 1209/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 260.2830 - val_loss: 348.7312\n",
      "Epoch 1210/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 290.0115 - val_loss: 298.8686\n",
      "Epoch 1211/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 285.6691 - val_loss: 356.1998\n",
      "Epoch 1212/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 285.4712 - val_loss: 252.5070\n",
      "Epoch 1213/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 239.7851 - val_loss: 587.1566\n",
      "Epoch 1214/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 245.0324 - val_loss: 297.4164\n",
      "Epoch 1215/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 291.7716 - val_loss: 236.2979\n",
      "Epoch 1216/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 254.7480 - val_loss: 234.8772\n",
      "Epoch 1217/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 239.4787 - val_loss: 292.7651\n",
      "Epoch 1218/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 280.8338 - val_loss: 188.9042\n",
      "Epoch 1219/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 229.5491 - val_loss: 343.8022\n",
      "Epoch 1220/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 258.7601 - val_loss: 329.0335\n",
      "Epoch 1221/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 270.4792 - val_loss: 413.0401\n",
      "Epoch 1222/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 249.7219 - val_loss: 608.0833\n",
      "Epoch 1223/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 270.7759 - val_loss: 328.3598\n",
      "Epoch 1224/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 203.0893 - val_loss: 254.1112\n",
      "Epoch 1225/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 220.4464 - val_loss: 290.0857\n",
      "Epoch 1226/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 215.3351 - val_loss: 333.7012\n",
      "Epoch 1227/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 255.4390 - val_loss: 343.1927\n",
      "Epoch 1228/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 235.5565 - val_loss: 309.9455\n",
      "Epoch 1229/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 239.5804 - val_loss: 329.6228\n",
      "Epoch 1230/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 207.2864 - val_loss: 699.1871\n",
      "Epoch 1231/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.3621 - val_loss: 417.5185\n",
      "Epoch 1232/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 213.3571 - val_loss: 454.2682\n",
      "Epoch 1233/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 235.8922 - val_loss: 386.2888\n",
      "Epoch 1234/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 240.5204 - val_loss: 334.6236\n",
      "Epoch 1235/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 260.9790 - val_loss: 669.8090\n",
      "Epoch 1236/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.8952 - val_loss: 326.4015\n",
      "Epoch 1237/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 251.8139 - val_loss: 324.8647\n",
      "Epoch 1238/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 244.7831 - val_loss: 389.3516\n",
      "Epoch 1239/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 247.3642 - val_loss: 315.4960\n",
      "Epoch 1240/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 219.6827 - val_loss: 339.7045\n",
      "Epoch 1241/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 223.8907 - val_loss: 293.5776\n",
      "Epoch 1242/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 231.0807 - val_loss: 432.8975\n",
      "Epoch 1243/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 256.4076 - val_loss: 299.0305\n",
      "Epoch 1244/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 214.7634 - val_loss: 271.6012\n",
      "Epoch 1245/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 237.7796 - val_loss: 345.0164\n",
      "Epoch 1246/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 211.4928 - val_loss: 380.8131\n",
      "Epoch 1247/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 219.5333 - val_loss: 280.1742\n",
      "Epoch 1248/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 235.1007 - val_loss: 371.5562\n",
      "Epoch 1249/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 236.4522 - val_loss: 720.6157\n",
      "Epoch 1250/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 294.5315 - val_loss: 592.2912\n",
      "Epoch 1251/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 286.1750 - val_loss: 363.7572\n",
      "Epoch 1252/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 238.9273 - val_loss: 512.2021\n",
      "Epoch 1253/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 236.3125 - val_loss: 429.4858\n",
      "Epoch 1254/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 237.3040 - val_loss: 424.7490\n",
      "Epoch 1255/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 249.9047 - val_loss: 601.2065\n",
      "Epoch 1256/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 286.8548 - val_loss: 343.6656\n",
      "Epoch 1257/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 260.1634 - val_loss: 423.2930\n",
      "Epoch 1258/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 219.1954 - val_loss: 401.4146\n",
      "Epoch 1259/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 219.7136 - val_loss: 444.7920\n",
      "Epoch 1260/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 326.3792 - val_loss: 715.5956\n",
      "Epoch 1261/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 246.1855 - val_loss: 426.4253\n",
      "Epoch 1262/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 304.4620 - val_loss: 491.2150\n",
      "Epoch 1263/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.2731 - val_loss: 551.6812\n",
      "Epoch 1264/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 274.7059 - val_loss: 402.0998\n",
      "Epoch 1265/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 245.8112 - val_loss: 322.8473\n",
      "Epoch 1266/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 233.5704 - val_loss: 851.0075\n",
      "Epoch 1267/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 357.9464 - val_loss: 623.5323\n",
      "Epoch 1268/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 272.7067 - val_loss: 414.5167\n",
      "Epoch 1269/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 243.5826 - val_loss: 378.7010\n",
      "Epoch 1270/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 273.0705 - val_loss: 370.6664\n",
      "Epoch 1271/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 224.7507 - val_loss: 334.5834\n",
      "Epoch 1272/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 235.4692 - val_loss: 389.3239\n",
      "Epoch 1273/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 290.8089 - val_loss: 405.9680\n",
      "Epoch 1274/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 257.0251 - val_loss: 500.4923\n",
      "Epoch 1275/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.9381 - val_loss: 1281.3486\n",
      "Epoch 1276/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 392.7023 - val_loss: 365.5631\n",
      "Epoch 1277/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 246.7678 - val_loss: 379.3529\n",
      "Epoch 1278/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 220.8203 - val_loss: 437.0721\n",
      "Epoch 1279/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 245.0595 - val_loss: 393.5900\n",
      "Epoch 1280/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 256.3734 - val_loss: 375.2171\n",
      "Epoch 1281/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 214.4520 - val_loss: 468.8762\n",
      "Epoch 1282/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 256.4458 - val_loss: 435.9712\n",
      "Epoch 1283/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 225.5804 - val_loss: 448.0625\n",
      "Epoch 1284/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.2679 - val_loss: 468.9693\n",
      "Epoch 1285/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 225.5293 - val_loss: 391.3701\n",
      "Epoch 1286/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 241.3089 - val_loss: 1426.4248\n",
      "Epoch 1287/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 416.1986 - val_loss: 545.9390\n",
      "Epoch 1288/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 249.5999 - val_loss: 419.7527\n",
      "Epoch 1289/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 262.7767 - val_loss: 463.2580\n",
      "Epoch 1290/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.2580 - val_loss: 671.8636\n",
      "Epoch 1291/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 254.3187 - val_loss: 556.9585\n",
      "Epoch 1292/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 251.8920 - val_loss: 398.5469\n",
      "Epoch 1293/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 270.1008 - val_loss: 368.2834\n",
      "Epoch 1294/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 209.7272 - val_loss: 467.5017\n",
      "Epoch 1295/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 278.7690 - val_loss: 449.9812\n",
      "Epoch 1296/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 222.9774 - val_loss: 400.5604\n",
      "Epoch 1297/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 245.9796 - val_loss: 464.1804\n",
      "Epoch 1298/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 239.5778 - val_loss: 429.7400\n",
      "Epoch 1299/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 234.0119 - val_loss: 419.2970\n",
      "Epoch 1300/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 232.9681 - val_loss: 457.4510\n",
      "Epoch 1301/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 238.1408 - val_loss: 416.0039\n",
      "Epoch 1302/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 225.5546 - val_loss: 585.1981\n",
      "Epoch 1303/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 255.1651 - val_loss: 540.5901\n",
      "Epoch 1304/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 240.0802 - val_loss: 358.3084\n",
      "Epoch 1305/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 260.1466 - val_loss: 353.7170\n",
      "Epoch 1306/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 225.0511 - val_loss: 406.4966\n",
      "Epoch 1307/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 240.3481 - val_loss: 448.1594\n",
      "Epoch 1308/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 231.3195 - val_loss: 477.6508\n",
      "Epoch 1309/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 219.1138 - val_loss: 381.2180\n",
      "Epoch 1310/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 212.4703 - val_loss: 399.2449\n",
      "Epoch 1311/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 249.4278 - val_loss: 419.0055\n",
      "Epoch 1312/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 225.9390 - val_loss: 354.1264\n",
      "Epoch 1313/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 243.2479 - val_loss: 308.0537\n",
      "Epoch 1314/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 185.5079 - val_loss: 524.8934\n",
      "Epoch 1315/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 234.5540 - val_loss: 293.3807\n",
      "Epoch 1316/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 231.5749 - val_loss: 512.9595\n",
      "Epoch 1317/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 275.4832 - val_loss: 693.9286\n",
      "Epoch 1318/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 314.2312 - val_loss: 462.2083\n",
      "Epoch 1319/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 252.2358 - val_loss: 557.8780\n",
      "Epoch 1320/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 246.4621 - val_loss: 619.6747\n",
      "Epoch 1321/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 283.9334 - val_loss: 400.8379\n",
      "Epoch 1322/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 250.1075 - val_loss: 415.7649\n",
      "Epoch 1323/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 343.5528 - val_loss: 441.2623\n",
      "Epoch 1324/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 236.1608 - val_loss: 417.8976\n",
      "Epoch 1325/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 212.1581 - val_loss: 373.8158\n",
      "Epoch 1326/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 230.3982 - val_loss: 360.2764\n",
      "Epoch 1327/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 243.4538 - val_loss: 414.0222\n",
      "Epoch 1328/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 264.7234 - val_loss: 538.7917\n",
      "Epoch 1329/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 275.5845 - val_loss: 554.9891\n",
      "Epoch 1330/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 302.0487 - val_loss: 496.8670\n",
      "Epoch 1331/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 251.0664 - val_loss: 546.9417\n",
      "Epoch 1332/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 242.8814 - val_loss: 517.3361\n",
      "Epoch 1333/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 270.3031 - val_loss: 553.8223\n",
      "Epoch 1334/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 263.0245 - val_loss: 373.0742\n",
      "Epoch 1335/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 238.9596 - val_loss: 362.8393\n",
      "Epoch 1336/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 256.8329 - val_loss: 397.1849\n",
      "Epoch 1337/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 232.6732 - val_loss: 685.4578\n",
      "Epoch 1338/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 341.9665 - val_loss: 395.9344\n",
      "Epoch 1339/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 223.4154 - val_loss: 324.3933\n",
      "Epoch 1340/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 205.3118 - val_loss: 425.5442\n",
      "Epoch 1341/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 255.6814 - val_loss: 421.4056\n",
      "Epoch 1342/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 251.9824 - val_loss: 421.5552\n",
      "Epoch 1343/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 242.7576 - val_loss: 442.1244\n",
      "Epoch 1344/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 233.0655 - val_loss: 421.9599\n",
      "Epoch 1345/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 287.9931 - val_loss: 537.2242\n",
      "Epoch 1346/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 282.8892 - val_loss: 459.4992\n",
      "Epoch 1347/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 274.0409 - val_loss: 812.1219\n",
      "Epoch 1348/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 374.4423 - val_loss: 411.6165\n",
      "Epoch 1349/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.6194 - val_loss: 490.2904\n",
      "Epoch 1350/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 289.8451 - val_loss: 732.3565\n",
      "Epoch 1351/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 371.4148 - val_loss: 583.2375\n",
      "Epoch 1352/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 316.9148 - val_loss: 579.1630\n",
      "Epoch 1353/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 284.2393 - val_loss: 600.3528\n",
      "Epoch 1354/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 304.2540 - val_loss: 657.7576\n",
      "Epoch 1355/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 333.4890 - val_loss: 431.9460\n",
      "Epoch 1356/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 258.3126 - val_loss: 384.8647\n",
      "Epoch 1357/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 235.7918 - val_loss: 394.9323\n",
      "Epoch 1358/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 235.7527 - val_loss: 384.4520\n",
      "Epoch 1359/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 237.7318 - val_loss: 339.0356\n",
      "Epoch 1360/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 234.8078 - val_loss: 400.9482\n",
      "Epoch 1361/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 258.8259 - val_loss: 515.0054\n",
      "Epoch 1362/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 262.8019 - val_loss: 670.1566\n",
      "Epoch 1363/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 396.0709 - val_loss: 422.0530\n",
      "Epoch 1364/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 234.3055 - val_loss: 445.3357\n",
      "Epoch 1365/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 270.9846 - val_loss: 375.8635\n",
      "Epoch 1366/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 229.1464 - val_loss: 446.7758\n",
      "Epoch 1367/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 239.6493 - val_loss: 373.9254\n",
      "Epoch 1368/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 262.3994 - val_loss: 459.5864\n",
      "Epoch 1369/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 235.2673 - val_loss: 362.4170\n",
      "Epoch 1370/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 234.7202 - val_loss: 469.1229\n",
      "Epoch 1371/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 244.8486 - val_loss: 295.2420\n",
      "Epoch 1372/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 257.0027 - val_loss: 564.4753\n",
      "Epoch 1373/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 263.4156 - val_loss: 424.7166\n",
      "Epoch 1374/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 201.6238 - val_loss: 364.8877\n",
      "Epoch 1375/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 242.7698 - val_loss: 395.6645\n",
      "Epoch 1376/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 191.2692 - val_loss: 344.1429\n",
      "Epoch 1377/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 219.3666 - val_loss: 317.7586\n",
      "Epoch 1378/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 229.5399 - val_loss: 434.3591\n",
      "Epoch 1379/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 237.6356 - val_loss: 460.9457\n",
      "Epoch 1380/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 221.0072 - val_loss: 378.9608\n",
      "Epoch 1381/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 191.3368 - val_loss: 373.4901\n",
      "Epoch 1382/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 234.0622 - val_loss: 394.9025\n",
      "Epoch 1383/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 242.2628 - val_loss: 395.7882\n",
      "Epoch 1384/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 255.2136 - val_loss: 398.6614\n",
      "Epoch 1385/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 273.5064 - val_loss: 358.5326\n",
      "Epoch 1386/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 230.8452 - val_loss: 387.5277\n",
      "Epoch 1387/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 226.4498 - val_loss: 611.9281\n",
      "Epoch 1388/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 232.2421 - val_loss: 297.9467\n",
      "Epoch 1389/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 205.2438 - val_loss: 287.4032\n",
      "Epoch 1390/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 219.0149 - val_loss: 403.3365\n",
      "Epoch 1391/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 236.7979 - val_loss: 429.7827\n",
      "Epoch 1392/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 235.1541 - val_loss: 367.4065\n",
      "Epoch 1393/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 192.4722 - val_loss: 944.5756\n",
      "Epoch 1394/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 306.7891 - val_loss: 415.6274\n",
      "Epoch 1395/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 231.1843 - val_loss: 414.2934\n",
      "Epoch 1396/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 199.5338 - val_loss: 369.0039\n",
      "Epoch 1397/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 232.4655 - val_loss: 410.0109\n",
      "Epoch 1398/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 212.8802 - val_loss: 422.3011\n",
      "Epoch 1399/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 247.6990 - val_loss: 460.1610\n",
      "Epoch 1400/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 219.7498 - val_loss: 565.0684\n",
      "Epoch 1401/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 309.5847 - val_loss: 842.2578\n",
      "Epoch 1402/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 290.4047 - val_loss: 480.1142\n",
      "Epoch 1403/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 211.6754 - val_loss: 489.6463\n",
      "Epoch 1404/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 254.0742 - val_loss: 495.4270\n",
      "Epoch 1405/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 223.0714 - val_loss: 401.0359\n",
      "Epoch 1406/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 219.7980 - val_loss: 400.0722\n",
      "Epoch 1407/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 239.5882 - val_loss: 410.0226\n",
      "Epoch 1408/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 266.7861 - val_loss: 431.6428\n",
      "Epoch 1409/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 240.2927 - val_loss: 397.1529\n",
      "Epoch 1410/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 222.6933 - val_loss: 362.4066\n",
      "Epoch 1411/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 221.9355 - val_loss: 335.9910\n",
      "Epoch 1412/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 219.5280 - val_loss: 637.8365\n",
      "Epoch 1413/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 240.9651 - val_loss: 590.8970\n",
      "Epoch 1414/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 238.9503 - val_loss: 510.5399\n",
      "Epoch 1415/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 269.0209 - val_loss: 798.8931\n",
      "Epoch 1416/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 303.8201 - val_loss: 530.4500\n",
      "Epoch 1417/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 303.2135 - val_loss: 428.3258\n",
      "Epoch 1418/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 260.8006 - val_loss: 460.8731\n",
      "Epoch 1419/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 279.9776 - val_loss: 436.7430\n",
      "Epoch 1420/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 238.2182 - val_loss: 634.3502\n",
      "Epoch 1421/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 244.1026 - val_loss: 479.5591\n",
      "Epoch 1422/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 248.0022 - val_loss: 391.8976\n",
      "Epoch 1423/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 237.9388 - val_loss: 376.6590\n",
      "Epoch 1424/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 239.3047 - val_loss: 415.7791\n",
      "Epoch 1425/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 225.6884 - val_loss: 348.7307\n",
      "Epoch 1426/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 234.0024 - val_loss: 625.0709\n",
      "Epoch 1427/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 257.2772 - val_loss: 441.7670\n",
      "Epoch 1428/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 239.5220 - val_loss: 521.0655\n",
      "Epoch 1429/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 295.2713 - val_loss: 343.3033\n",
      "Epoch 1430/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 232.0260 - val_loss: 363.0574\n",
      "Epoch 1431/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 229.0439 - val_loss: 827.1906\n",
      "Epoch 1432/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 347.9415 - val_loss: 472.3404\n",
      "Epoch 1433/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 251.1143 - val_loss: 485.2575\n",
      "Epoch 1434/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 260.9162 - val_loss: 379.9213\n",
      "Epoch 1435/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 220.8410 - val_loss: 386.8279\n",
      "Epoch 1436/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 233.8548 - val_loss: 475.6935\n",
      "Epoch 1437/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 240.3519 - val_loss: 417.7457\n",
      "Epoch 1438/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 348.1092 - val_loss: 401.9064\n",
      "Epoch 1439/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 243.1969 - val_loss: 704.5704\n",
      "Epoch 1440/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 253.0825 - val_loss: 420.7473\n",
      "Epoch 1441/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 295.9456 - val_loss: 1073.3320\n",
      "Epoch 1442/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 423.3331 - val_loss: 382.7174\n",
      "Epoch 1443/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 240.0494 - val_loss: 696.0190\n",
      "Epoch 1444/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 501.5027 - val_loss: 396.6696\n",
      "Epoch 1445/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 281.2102 - val_loss: 486.9712\n",
      "Epoch 1446/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 264.0748 - val_loss: 315.7762\n",
      "Epoch 1447/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 242.9366 - val_loss: 387.3918\n",
      "Epoch 1448/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 248.0135 - val_loss: 482.7214\n",
      "Epoch 1449/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 277.9677 - val_loss: 407.4087\n",
      "Epoch 1450/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 241.3779 - val_loss: 410.2873\n",
      "Epoch 1451/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 280.8234 - val_loss: 411.9674\n",
      "Epoch 1452/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 243.3228 - val_loss: 421.4625\n",
      "Epoch 1453/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 235.7274 - val_loss: 682.6629\n",
      "Epoch 1454/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 327.8578 - val_loss: 455.3178\n",
      "Epoch 1455/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 281.8864 - val_loss: 374.6137\n",
      "Epoch 1456/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 224.6726 - val_loss: 417.1164\n",
      "Epoch 1457/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 263.7613 - val_loss: 360.1035\n",
      "Epoch 1458/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 245.8365 - val_loss: 422.9332\n",
      "Epoch 1459/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 267.2449 - val_loss: 509.5352\n",
      "Epoch 1460/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 258.4892 - val_loss: 454.4469\n",
      "Epoch 1461/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 329.4514 - val_loss: 669.3953\n",
      "Epoch 1462/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 249.7514 - val_loss: 329.8244\n",
      "Epoch 1463/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 262.2924 - val_loss: 343.1456\n",
      "Epoch 1464/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 237.2424 - val_loss: 754.0959\n",
      "Epoch 1465/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 367.0264 - val_loss: 893.5603\n",
      "Epoch 1466/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 380.2000 - val_loss: 366.4625\n",
      "Epoch 1467/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 274.2188 - val_loss: 411.5790\n",
      "Epoch 1468/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 305.9099 - val_loss: 389.4481\n",
      "Epoch 1469/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 329.7727 - val_loss: 323.0318\n",
      "Epoch 1470/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 273.7867 - val_loss: 304.6255\n",
      "Epoch 1471/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 268.0428 - val_loss: 382.0044\n",
      "Epoch 1472/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 326.3984 - val_loss: 282.3174\n",
      "Epoch 1473/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 240.6594 - val_loss: 796.2610\n",
      "Epoch 1474/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 347.5450 - val_loss: 276.7278\n",
      "Epoch 1475/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 228.0770 - val_loss: 673.8903\n",
      "Epoch 1476/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 300.5188 - val_loss: 339.3644\n",
      "Epoch 1477/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 262.8594 - val_loss: 333.6434\n",
      "Epoch 1478/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 288.3243 - val_loss: 391.5688\n",
      "Epoch 1479/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 287.4507 - val_loss: 477.9944\n",
      "Epoch 1480/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 303.9768 - val_loss: 321.2682\n",
      "Epoch 1481/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 231.7488 - val_loss: 386.8142\n",
      "Epoch 1482/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 349.6195 - val_loss: 449.2727\n",
      "Epoch 1483/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 273.5561 - val_loss: 363.7129\n",
      "Epoch 1484/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 246.9246 - val_loss: 361.8625\n",
      "Epoch 1485/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 263.1577 - val_loss: 373.7091\n",
      "Epoch 1486/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 223.0672 - val_loss: 369.5297\n",
      "Epoch 1487/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 238.1142 - val_loss: 357.3282\n",
      "Epoch 1488/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 240.9539 - val_loss: 457.5294\n",
      "Epoch 1489/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 265.4755 - val_loss: 407.7045\n",
      "Epoch 1490/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 225.1935 - val_loss: 501.3182\n",
      "Epoch 1491/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 282.7654 - val_loss: 378.4500\n",
      "Epoch 1492/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 215.9693 - val_loss: 457.7537\n",
      "Epoch 1493/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 270.2931 - val_loss: 357.0972\n",
      "Epoch 1494/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 239.2184 - val_loss: 441.1979\n",
      "Epoch 1495/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 234.1865 - val_loss: 366.3688\n",
      "Epoch 1496/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 235.4565 - val_loss: 446.9766\n",
      "Epoch 1497/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 226.3514 - val_loss: 763.0204\n",
      "Epoch 1498/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 295.3701 - val_loss: 449.4755\n",
      "Epoch 1499/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 220.5134 - val_loss: 382.2502\n",
      "Epoch 1500/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 243.3716 - val_loss: 367.5039\n",
      "Epoch 1501/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 222.7697 - val_loss: 377.6678\n",
      "Epoch 1502/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 238.9575 - val_loss: 323.7517\n",
      "Epoch 1503/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 244.4465 - val_loss: 464.5193\n",
      "Epoch 1504/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 251.9457 - val_loss: 251.2475\n",
      "Epoch 1505/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 331.1706 - val_loss: 457.7883\n",
      "Epoch 1506/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 342.4982 - val_loss: 362.7238\n",
      "Epoch 1507/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 289.2400 - val_loss: 1058.8354\n",
      "Epoch 1508/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 380.3871 - val_loss: 308.3893\n",
      "Epoch 1509/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 238.2657 - val_loss: 268.4361\n",
      "Epoch 1510/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 238.9327 - val_loss: 349.0002\n",
      "Epoch 1511/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 212.4708 - val_loss: 485.2518\n",
      "Epoch 1512/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 338.7821 - val_loss: 508.6497\n",
      "Epoch 1513/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 256.7856 - val_loss: 346.0124\n",
      "Epoch 1514/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 230.8118 - val_loss: 309.1800\n",
      "Epoch 1515/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 219.1237 - val_loss: 399.9605\n",
      "Epoch 1516/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 197.6068 - val_loss: 307.8918\n",
      "Epoch 1517/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 217.0739 - val_loss: 546.7880\n",
      "Epoch 1518/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 655.5540 - val_loss: 370.6178\n",
      "Epoch 1519/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 255.2959 - val_loss: 371.7694\n",
      "Epoch 1520/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 292.4612 - val_loss: 338.2570\n",
      "Epoch 1521/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 239.0728 - val_loss: 384.1665\n",
      "Epoch 1522/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 234.5788 - val_loss: 307.2437\n",
      "Epoch 1523/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 265.9459 - val_loss: 317.4543\n",
      "Epoch 1524/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 267.7618 - val_loss: 367.7246\n",
      "Epoch 1525/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 249.9174 - val_loss: 401.5477\n",
      "Epoch 1526/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 269.2124 - val_loss: 380.5036\n",
      "Epoch 1527/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 246.7328 - val_loss: 453.3604\n",
      "Epoch 1528/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 244.9063 - val_loss: 884.9657\n",
      "Epoch 1529/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 345.4278 - val_loss: 396.9355\n",
      "Epoch 1530/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 269.5430 - val_loss: 322.7219\n",
      "Epoch 1531/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 240.6920 - val_loss: 346.8082\n",
      "Epoch 1532/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 458.4231 - val_loss: 423.0415\n",
      "Epoch 1533/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 297.4262 - val_loss: 507.6148\n",
      "Epoch 1534/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 315.8935 - val_loss: 477.7586\n",
      "Epoch 1535/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 238.1415 - val_loss: 494.1499\n",
      "Epoch 1536/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 270.3174 - val_loss: 462.9643\n",
      "Epoch 1537/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 332.5078 - val_loss: 467.7953\n",
      "Epoch 1538/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 306.7350 - val_loss: 473.8095\n",
      "Epoch 1539/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 323.9176 - val_loss: 468.9608\n",
      "Epoch 1540/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 339.7833 - val_loss: 726.3243\n",
      "Epoch 1541/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 443.6624 - val_loss: 407.8342\n",
      "Epoch 1542/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 328.3833 - val_loss: 444.7721\n",
      "Epoch 1543/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 276.0364 - val_loss: 475.4256\n",
      "Epoch 1544/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 294.8288 - val_loss: 461.4107\n",
      "Epoch 1545/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 271.2649 - val_loss: 403.0222\n",
      "Epoch 1546/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 422.7335 - val_loss: 1018.7563\n",
      "Epoch 1547/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 491.4460 - val_loss: 328.3191\n",
      "Epoch 1548/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 271.9433 - val_loss: 362.3474\n",
      "Epoch 1549/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 247.0878 - val_loss: 517.9171\n",
      "Epoch 1550/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 327.3183 - val_loss: 512.2304\n",
      "Epoch 1551/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 259.9221 - val_loss: 555.5159\n",
      "Epoch 1552/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 306.5136 - val_loss: 339.7154\n",
      "Epoch 1553/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 263.2043 - val_loss: 715.9855\n",
      "Epoch 1554/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 326.1284 - val_loss: 412.2155\n",
      "Epoch 1555/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 281.7176 - val_loss: 516.9923\n",
      "Epoch 1556/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 251.9067 - val_loss: 412.4727\n",
      "Epoch 1557/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 264.5924 - val_loss: 367.0853\n",
      "Epoch 1558/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 245.7843 - val_loss: 474.5104\n",
      "Epoch 1559/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 263.0805 - val_loss: 439.6995\n",
      "Epoch 1560/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 343.6270 - val_loss: 332.5751\n",
      "Epoch 1561/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 283.9780 - val_loss: 904.2581\n",
      "Epoch 1562/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 374.5144 - val_loss: 596.5576\n",
      "Epoch 1563/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 323.8201 - val_loss: 325.7527\n",
      "Epoch 1564/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 258.3797 - val_loss: 278.8304\n",
      "Epoch 1565/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 249.7291 - val_loss: 532.4186\n",
      "Epoch 1566/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 286.6926 - val_loss: 488.8126\n",
      "Epoch 1567/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 255.4894 - val_loss: 641.4336\n",
      "Epoch 1568/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 272.0391 - val_loss: 360.5385\n",
      "Epoch 1569/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 244.6241 - val_loss: 331.1934\n",
      "Epoch 1570/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 232.7828 - val_loss: 311.1749\n",
      "Epoch 1571/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 213.5103 - val_loss: 535.6339\n",
      "Epoch 1572/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 342.9325 - val_loss: 314.8069\n",
      "Epoch 1573/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 231.6927 - val_loss: 405.6137\n",
      "Epoch 1574/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 272.6627 - val_loss: 336.2443\n",
      "Epoch 1575/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 227.3378 - val_loss: 298.9345\n",
      "Epoch 1576/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 263.3727 - val_loss: 635.1409\n",
      "Epoch 1577/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 287.2312 - val_loss: 364.7632\n",
      "Epoch 1578/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 244.9221 - val_loss: 416.2130\n",
      "Epoch 1579/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 264.6979 - val_loss: 382.6288\n",
      "Epoch 1580/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 261.3239 - val_loss: 528.4253\n",
      "Epoch 1581/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 280.5177 - val_loss: 362.0660\n",
      "Epoch 1582/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 269.6884 - val_loss: 687.0093\n",
      "Epoch 1583/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 319.9309 - val_loss: 971.4620\n",
      "Epoch 1584/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 335.9603 - val_loss: 271.9508\n",
      "Epoch 1585/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 287.7926 - val_loss: 345.8810\n",
      "Epoch 1586/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 248.7709 - val_loss: 301.5944\n",
      "Epoch 1587/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 254.3792 - val_loss: 368.1672\n",
      "Epoch 1588/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 269.3022 - val_loss: 428.9988\n",
      "Epoch 1589/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 235.6027 - val_loss: 289.1454\n",
      "Epoch 1590/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 232.0588 - val_loss: 262.8574\n",
      "Epoch 1591/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 224.9877 - val_loss: 621.1027\n",
      "Epoch 1592/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 260.8676 - val_loss: 455.2366\n",
      "Epoch 1593/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 237.1808 - val_loss: 500.3920\n",
      "Epoch 1594/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 340.7811 - val_loss: 393.6733\n",
      "Epoch 1595/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 227.8215 - val_loss: 391.5472\n",
      "Epoch 1596/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 246.7798 - val_loss: 475.7782\n",
      "Epoch 1597/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 251.6590 - val_loss: 484.9431\n",
      "Epoch 1598/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 280.5411 - val_loss: 1374.1248\n",
      "Epoch 1599/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 414.7023 - val_loss: 405.1927\n",
      "Epoch 1600/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 267.0243 - val_loss: 350.5352\n",
      "Epoch 1601/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 258.0673 - val_loss: 374.7266\n",
      "Epoch 1602/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 267.0710 - val_loss: 400.0107\n",
      "Epoch 1603/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 234.6918 - val_loss: 449.4254\n",
      "Epoch 1604/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 252.8686 - val_loss: 373.5255\n",
      "Epoch 1605/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 228.1283 - val_loss: 318.9894\n",
      "Epoch 1606/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 267.6473 - val_loss: 513.9810\n",
      "Epoch 1607/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 256.0629 - val_loss: 702.5043\n",
      "Epoch 1608/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 302.0732 - val_loss: 357.8125\n",
      "Epoch 1609/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 251.6175 - val_loss: 341.8888\n",
      "Epoch 1610/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 286.7953 - val_loss: 418.0755\n",
      "Epoch 1611/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 249.3318 - val_loss: 494.9102\n",
      "Epoch 1612/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 277.4684 - val_loss: 437.0103\n",
      "Epoch 1613/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 244.0151 - val_loss: 367.3391\n",
      "Epoch 1614/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 223.5361 - val_loss: 398.7545\n",
      "Epoch 1615/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 248.7693 - val_loss: 562.2730\n",
      "Epoch 1616/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 288.4185 - val_loss: 470.5295\n",
      "Epoch 1617/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 290.4385 - val_loss: 454.9276\n",
      "Epoch 1618/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 225.9021 - val_loss: 483.7092\n",
      "Epoch 1619/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 271.2891 - val_loss: 490.7143\n",
      "Epoch 1620/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 256.8769 - val_loss: 438.5221\n",
      "Epoch 1621/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 271.8092 - val_loss: 452.5541\n",
      "Epoch 1622/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 247.9967 - val_loss: 350.9516\n",
      "Epoch 1623/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 261.0979 - val_loss: 374.8747\n",
      "Epoch 1624/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 216.8435 - val_loss: 570.5107\n",
      "Epoch 1625/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 309.0829 - val_loss: 632.0887\n",
      "Epoch 1626/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 260.2924 - val_loss: 935.5366\n",
      "Epoch 1627/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 335.6065 - val_loss: 315.0778\n",
      "Epoch 1628/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 246.1198 - val_loss: 363.5664\n",
      "Epoch 1629/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 239.2792 - val_loss: 418.6150\n",
      "Epoch 1630/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 319.7807 - val_loss: 371.5014\n",
      "Epoch 1631/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 237.5169 - val_loss: 393.3523\n",
      "Epoch 1632/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 232.5301 - val_loss: 376.5294\n",
      "Epoch 1633/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 251.5998 - val_loss: 367.4741\n",
      "Epoch 1634/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 239.2186 - val_loss: 551.0356\n",
      "Epoch 1635/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 313.4775 - val_loss: 326.2105\n",
      "Epoch 1636/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 225.1655 - val_loss: 441.5261\n",
      "Epoch 1637/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 243.8702 - val_loss: 373.6071\n",
      "Epoch 1638/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 271.8647 - val_loss: 367.3348\n",
      "Epoch 1639/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 248.7092 - val_loss: 521.5999\n",
      "Epoch 1640/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 280.7415 - val_loss: 388.4687\n",
      "Epoch 1641/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 259.3147 - val_loss: 552.9678\n",
      "Epoch 1642/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 294.0872 - val_loss: 512.4213\n",
      "Epoch 1643/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 253.5680 - val_loss: 594.7755\n",
      "Epoch 1644/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 371.8669 - val_loss: 443.1559\n",
      "Epoch 1645/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 292.9363 - val_loss: 351.5724\n",
      "Epoch 1646/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 235.0027 - val_loss: 493.3528\n",
      "Epoch 1647/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 246.0737 - val_loss: 364.7703\n",
      "Epoch 1648/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 218.0087 - val_loss: 455.8971\n",
      "Epoch 1649/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 241.0005 - val_loss: 400.2087\n",
      "Epoch 1650/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 226.1066 - val_loss: 390.3978\n",
      "Epoch 1651/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 224.4167 - val_loss: 329.5167\n",
      "Epoch 1652/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 247.6125 - val_loss: 339.9590\n",
      "Epoch 1653/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 218.7223 - val_loss: 406.4718\n",
      "Epoch 1654/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 248.1381 - val_loss: 332.3402\n",
      "Epoch 1655/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 255.9440 - val_loss: 381.0766\n",
      "Epoch 1656/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 251.8196 - val_loss: 453.2355\n",
      "Epoch 1657/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 241.2050 - val_loss: 343.0088\n",
      "Epoch 1658/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 229.1108 - val_loss: 324.4889\n",
      "Epoch 1659/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 238.0984 - val_loss: 383.0502\n",
      "Epoch 1660/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 227.2614 - val_loss: 274.4705\n",
      "Epoch 1661/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 205.2507 - val_loss: 398.3412\n",
      "Epoch 1662/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 244.6313 - val_loss: 614.6609\n",
      "Epoch 1663/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 264.3799 - val_loss: 411.6321\n",
      "Epoch 1664/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 243.4144 - val_loss: 356.5322\n",
      "Epoch 1665/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 241.7365 - val_loss: 343.7498\n",
      "Epoch 1666/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 241.3839 - val_loss: 518.9333\n",
      "Epoch 1667/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 327.4022 - val_loss: 451.5631\n",
      "Epoch 1668/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 216.1759 - val_loss: 329.7968\n",
      "Epoch 1669/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 205.8115 - val_loss: 320.4047\n",
      "Epoch 1670/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 259.9479 - val_loss: 1496.4445\n",
      "Epoch 1671/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 567.3946 - val_loss: 363.2751\n",
      "Epoch 1672/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 292.2038 - val_loss: 422.2621\n",
      "Epoch 1673/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 281.4124 - val_loss: 427.0658\n",
      "Epoch 1674/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 292.4564 - val_loss: 378.9602\n",
      "Epoch 1675/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 275.2952 - val_loss: 367.0981\n",
      "Epoch 1676/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 227.1034 - val_loss: 720.3196\n",
      "Epoch 1677/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 286.6034 - val_loss: 342.2730\n",
      "Epoch 1678/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 231.5270 - val_loss: 265.7981\n",
      "Epoch 1679/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 258.1346 - val_loss: 271.5071\n",
      "Epoch 1680/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 267.1278 - val_loss: 384.6300\n",
      "Epoch 1681/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 261.9091 - val_loss: 296.0452\n",
      "Epoch 1682/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 241.9662 - val_loss: 357.9484\n",
      "Epoch 1683/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 295.2567 - val_loss: 382.8750\n",
      "Epoch 1684/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 253.8999 - val_loss: 442.7380\n",
      "Epoch 1685/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 255.0072 - val_loss: 347.4148\n",
      "Epoch 1686/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 220.7334 - val_loss: 298.6761\n",
      "Epoch 1687/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 307.7162 - val_loss: 465.4492\n",
      "Epoch 1688/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 316.4899 - val_loss: 305.9091\n",
      "Epoch 1689/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 253.6636 - val_loss: 296.9104\n",
      "Epoch 1690/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 287.1474 - val_loss: 256.7801\n",
      "Epoch 1691/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 225.0918 - val_loss: 428.1633\n",
      "Epoch 1692/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 261.4459 - val_loss: 345.9778\n",
      "Epoch 1693/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 250.2136 - val_loss: 264.9094\n",
      "Epoch 1694/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 223.5685 - val_loss: 595.3436\n",
      "Epoch 1695/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 252.4651 - val_loss: 279.6559\n",
      "Epoch 1696/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 218.5520 - val_loss: 346.2961\n",
      "Epoch 1697/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 225.4564 - val_loss: 614.2325\n",
      "Epoch 1698/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 268.2883 - val_loss: 360.8969\n",
      "Epoch 1699/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 278.9284 - val_loss: 414.5478\n",
      "Epoch 1700/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 308.7014 - val_loss: 525.8705\n",
      "Epoch 1701/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 323.3105 - val_loss: 334.6252\n",
      "Epoch 1702/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 252.1896 - val_loss: 338.3605\n",
      "Epoch 1703/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 235.5109 - val_loss: 397.2103\n",
      "Epoch 1704/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 296.0290 - val_loss: 436.7625\n",
      "Epoch 1705/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 238.4120 - val_loss: 351.7244\n",
      "Epoch 1706/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 219.0640 - val_loss: 809.2628\n",
      "Epoch 1707/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 275.1613 - val_loss: 356.7110\n",
      "Epoch 1708/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 211.4200 - val_loss: 327.5567\n",
      "Epoch 1709/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 237.0913 - val_loss: 665.6968\n",
      "Epoch 1710/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 266.5270 - val_loss: 486.3304\n",
      "Epoch 1711/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 243.5673 - val_loss: 372.8746\n",
      "Epoch 1712/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 225.9658 - val_loss: 355.7498\n",
      "Epoch 1713/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 217.4989 - val_loss: 874.7770\n",
      "Epoch 1714/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 333.6483 - val_loss: 332.2859\n",
      "Epoch 1715/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 217.2569 - val_loss: 415.7141\n",
      "Epoch 1716/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 232.1494 - val_loss: 256.9116\n",
      "Epoch 1717/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 258.1674 - val_loss: 439.5867\n",
      "Epoch 1718/10000\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 512.6505Restoring model weights from the end of the best epoch: 1218.\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 312.6301 - val_loss: 530.9755\n",
      "Epoch 1718: early stopping\n"
     ]
    }
   ],
   "source": [
    "trained_model, history = neural_network_model(train_input, \n",
    "                                              train_target, \n",
    "                                              want_verbose=1, \n",
    "                                              seed=winner_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "867771c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    results_data = []\n",
    "\n",
    "    for i in range(len(test_target)):\n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target = test_target[start_target + i]\n",
    "        error = np.abs(prediction - target)\n",
    "        errors.append(error)\n",
    "        error_percent.append(error/target)\n",
    "        results_data.append([f\"Month-{i + 1}\", \n",
    "                             prediction[0][0], \n",
    "                             target, \n",
    "                             error[0][0]])\n",
    "\n",
    "    df_results = pd.DataFrame(results_data, columns=[\"Month\", \"Prediction\", \"Target\", \"Error\"])\n",
    "\n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return df_results, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09914e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>Month-1</td>\n",
       "      <td>Month-2</td>\n",
       "      <td>Month-3</td>\n",
       "      <td>Month-4</td>\n",
       "      <td>Month-5</td>\n",
       "      <td>Month-6</td>\n",
       "      <td>Month-7</td>\n",
       "      <td>Month-8</td>\n",
       "      <td>Month-9</td>\n",
       "      <td>Month-10</td>\n",
       "      <td>Month-11</td>\n",
       "      <td>Month-12</td>\n",
       "      <td>Month-13</td>\n",
       "      <td>Month-14</td>\n",
       "      <td>Month-15</td>\n",
       "      <td>Month-16</td>\n",
       "      <td>Month-17</td>\n",
       "      <td>Month-18</td>\n",
       "      <td>Month-19</td>\n",
       "      <td>Month-20</td>\n",
       "      <td>Month-21</td>\n",
       "      <td>Month-22</td>\n",
       "      <td>Month-23</td>\n",
       "      <td>Month-24</td>\n",
       "      <td>Month-25</td>\n",
       "      <td>Month-26</td>\n",
       "      <td>Month-27</td>\n",
       "      <td>Month-28</td>\n",
       "      <td>Month-29</td>\n",
       "      <td>Month-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction</th>\n",
       "      <td>162.714401</td>\n",
       "      <td>162.714386</td>\n",
       "      <td>162.714386</td>\n",
       "      <td>162.714355</td>\n",
       "      <td>162.714355</td>\n",
       "      <td>162.714294</td>\n",
       "      <td>162.279633</td>\n",
       "      <td>158.672943</td>\n",
       "      <td>158.628662</td>\n",
       "      <td>147.997742</td>\n",
       "      <td>31.130033</td>\n",
       "      <td>132.934448</td>\n",
       "      <td>12.686081</td>\n",
       "      <td>5.928772</td>\n",
       "      <td>12.686081</td>\n",
       "      <td>12.61084</td>\n",
       "      <td>12.427887</td>\n",
       "      <td>4.457733</td>\n",
       "      <td>1.9319</td>\n",
       "      <td>2.007286</td>\n",
       "      <td>1.924217</td>\n",
       "      <td>1.923828</td>\n",
       "      <td>1.923439</td>\n",
       "      <td>1.923431</td>\n",
       "      <td>1.923431</td>\n",
       "      <td>-12.451607</td>\n",
       "      <td>-12.45163</td>\n",
       "      <td>-24.349281</td>\n",
       "      <td>-31.062111</td>\n",
       "      <td>-31.065659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>131.464</td>\n",
       "      <td>151.37</td>\n",
       "      <td>154.276</td>\n",
       "      <td>153.331</td>\n",
       "      <td>152.6</td>\n",
       "      <td>136.567</td>\n",
       "      <td>144.855</td>\n",
       "      <td>126.352</td>\n",
       "      <td>138.148</td>\n",
       "      <td>129.978</td>\n",
       "      <td>109.083</td>\n",
       "      <td>147.44</td>\n",
       "      <td>132.5</td>\n",
       "      <td>158.533</td>\n",
       "      <td>133.813</td>\n",
       "      <td>155.827</td>\n",
       "      <td>146.197</td>\n",
       "      <td>122.278</td>\n",
       "      <td>149.983</td>\n",
       "      <td>123.483</td>\n",
       "      <td>125.104</td>\n",
       "      <td>129.633</td>\n",
       "      <td>138.233</td>\n",
       "      <td>109.657</td>\n",
       "      <td>128.809</td>\n",
       "      <td>140.408</td>\n",
       "      <td>134.634</td>\n",
       "      <td>189.04</td>\n",
       "      <td>166.406</td>\n",
       "      <td>155.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>31.250397</td>\n",
       "      <td>11.344391</td>\n",
       "      <td>8.438385</td>\n",
       "      <td>9.383362</td>\n",
       "      <td>10.114349</td>\n",
       "      <td>26.147293</td>\n",
       "      <td>17.424637</td>\n",
       "      <td>32.320946</td>\n",
       "      <td>20.480667</td>\n",
       "      <td>18.019745</td>\n",
       "      <td>77.952965</td>\n",
       "      <td>14.505554</td>\n",
       "      <td>119.813919</td>\n",
       "      <td>152.604233</td>\n",
       "      <td>121.126923</td>\n",
       "      <td>143.216156</td>\n",
       "      <td>133.769119</td>\n",
       "      <td>117.820267</td>\n",
       "      <td>148.051102</td>\n",
       "      <td>121.475716</td>\n",
       "      <td>123.179779</td>\n",
       "      <td>127.709167</td>\n",
       "      <td>136.30957</td>\n",
       "      <td>107.733566</td>\n",
       "      <td>126.885574</td>\n",
       "      <td>152.859619</td>\n",
       "      <td>147.085632</td>\n",
       "      <td>213.389282</td>\n",
       "      <td>197.468109</td>\n",
       "      <td>186.521652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1           2           3           4   \\\n",
       "Month          Month-1     Month-2     Month-3     Month-4     Month-5   \n",
       "Prediction  162.714401  162.714386  162.714386  162.714355  162.714355   \n",
       "Target         131.464      151.37     154.276     153.331       152.6   \n",
       "Error        31.250397   11.344391    8.438385    9.383362   10.114349   \n",
       "\n",
       "                    5           6           7           8           9   \\\n",
       "Month          Month-6     Month-7     Month-8     Month-9    Month-10   \n",
       "Prediction  162.714294  162.279633  158.672943  158.628662  147.997742   \n",
       "Target         136.567     144.855     126.352     138.148     129.978   \n",
       "Error        26.147293   17.424637   32.320946   20.480667   18.019745   \n",
       "\n",
       "                   10          11          12          13          14  \\\n",
       "Month        Month-11    Month-12    Month-13    Month-14    Month-15   \n",
       "Prediction  31.130033  132.934448   12.686081    5.928772   12.686081   \n",
       "Target        109.083      147.44       132.5     158.533     133.813   \n",
       "Error       77.952965   14.505554  119.813919  152.604233  121.126923   \n",
       "\n",
       "                    15          16          17          18          19  \\\n",
       "Month         Month-16    Month-17    Month-18    Month-19    Month-20   \n",
       "Prediction    12.61084   12.427887    4.457733      1.9319    2.007286   \n",
       "Target         155.827     146.197     122.278     149.983     123.483   \n",
       "Error       143.216156  133.769119  117.820267  148.051102  121.475716   \n",
       "\n",
       "                    20          21         22          23          24  \\\n",
       "Month         Month-21    Month-22   Month-23    Month-24    Month-25   \n",
       "Prediction    1.924217    1.923828   1.923439    1.923431    1.923431   \n",
       "Target         125.104     129.633    138.233     109.657     128.809   \n",
       "Error       123.179779  127.709167  136.30957  107.733566  126.885574   \n",
       "\n",
       "                    25          26          27          28          29  \n",
       "Month         Month-26    Month-27    Month-28    Month-29    Month-30  \n",
       "Prediction  -12.451607   -12.45163  -24.349281  -31.062111  -31.065659  \n",
       "Target         140.408     134.634      189.04     166.406     155.456  \n",
       "Error       152.859619  147.085632  213.389282  197.468109  186.521652  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results, mae, mape = mae_mape_calculator(trained_model, \n",
    "                                            test_input, \n",
    "                                            test_target, \n",
    "                                            train_split)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16807ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.14674"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6774221"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "447b6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_mae_mape_calculator(model, test_input, test_target, start_target):\n",
    "    \n",
    "    errors = []\n",
    "    error_percent = []\n",
    "    \n",
    "    target_sum = 0\n",
    "    prediction_sum = 0\n",
    "    \n",
    "    for i in range(len(test_target)):\n",
    "        if i % 12 == 0 and i != 0:\n",
    "            error = np.abs(target_sum - prediction_sum)\n",
    "            errors.append(error)\n",
    "            error_percent.append(error / target_sum)\n",
    "            print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "            target_sum = 0\n",
    "            prediction_sum = 0\n",
    "            \n",
    "        prediction = model.predict(test_input.iloc[i:i+1])\n",
    "        target_sum += test_target[start_target + i]\n",
    "        prediction_sum += prediction\n",
    "        \n",
    "    error = np.abs(target_sum - prediction_sum)\n",
    "    errors.append(error)\n",
    "    error_percent.append(error / target_sum)\n",
    "    print(f\"Ano-{i%12}: |Prediction{prediction_sum} - Target[{target_sum}]| =  Error: {error}; MAPE:{abs(prediction_sum - target_sum)/target_sum}\")\n",
    "        \n",
    "    mae = np.mean(errors)\n",
    "    mape = np.mean(error_percent) \n",
    "\n",
    "    return errors, mae, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04d784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[1767.9297]] - Target[1675.4640000000002]| =  Error: [[92.4657]]; MAPE:[[0.05518812]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Ano-0: |Prediction[[72.431496]] - Target[1625.241]| =  Error: [[1552.8094]]; MAPE:[[0.95543337]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Ano-5: |Prediction[[-109.456856]] - Target[914.753]| =  Error: [[1024.2098]]; MAPE:[[1.1196573]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[92.4657]], dtype=float32),\n",
       " array([[1552.8094]], dtype=float32),\n",
       " array([[1024.2098]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "889.8283"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.71009284"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors, mae, mape = year_mae_mape_calculator(trained_model, \n",
    "                                             test_input, \n",
    "                                             test_target, \n",
    "                                             train_split)\n",
    "display(errors)\n",
    "display(mae)\n",
    "display(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
